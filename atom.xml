<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coool&#39;s Blog</title>
  
  <subtitle>As we watch our love grow.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.liukui.tech/"/>
  <updated>2019-03-13T10:26:37.922Z</updated>
  <id>https://www.liukui.tech/</id>
  
  <author>
    <name>空腹吃早餐</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Promethues监控</title>
    <link href="https://www.liukui.tech/2019/01/15/Promethues%E7%9B%91%E6%8E%A7/"/>
    <id>https://www.liukui.tech/2019/01/15/Promethues监控/</id>
    <published>2019-01-15T00:00:00.000Z</published>
    <updated>2019-03-13T10:26:37.922Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="promethues" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/promethues/"/>
    
    
      <category term="promethues" scheme="https://www.liukui.tech/tags/promethues/"/>
    
  </entry>
  
  <entry>
    <title>httpd脚本</title>
    <link href="https://www.liukui.tech/2018/12/30/httpd%E8%84%9A%E6%9C%AC/"/>
    <id>https://www.liukui.tech/2018/12/30/httpd脚本/</id>
    <published>2018-12-30T11:28:24.082Z</published>
    <updated>2019-01-07T11:23:00.341Z</updated>
    
    <content type="html"><![CDATA[<p>httpd服务<br><a id="more"></a></p><h3 id="httpd服务脚本"><a href="#httpd服务脚本" class="headerlink" title="httpd服务脚本"></a>httpd服务脚本</h3><pre><code>#!/bin/bash## httpd        Startup script for the Apache HTTP Server## chkconfig: - 85 15# description: The Apache HTTP Server is an efficient and extensible  \#              server implementing the current HTTP standards.# processname: httpd# config: /etc/httpd/conf/httpd.conf# config: /etc/sysconfig/httpd# pidfile: /var/run/httpd/httpd.pid#### BEGIN INIT INFO# Provides: httpd# Required-Start: $local_fs $remote_fs $network $named# Required-Stop: $local_fs $remote_fs $network# Should-Start: distcache# Short-Description: start and stop Apache HTTP Server# Description: The Apache HTTP Server is an extensible server #  implementing the current HTTP standards.### END INIT INFO# Source function library.. /etc/rc.d/init.d/functionsif [ -f /etc/sysconfig/httpd ]; then        . /etc/sysconfig/httpdfi# Start httpd in the C locale by default.HTTPD_LANG=${HTTPD_LANG-&quot;C&quot;}# This will prevent initlog from swallowing up a pass-phrase prompt if# mod_ssl needs a pass-phrase from the user.INITLOG_ARGS=&quot;&quot;# Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server# with the thread-based &quot;worker&quot; MPM; BE WARNED that some modules may not# work correctly with a thread-based MPM; notably PHP will refuse to start.# Path to the apachectl script, server binary, and short-form for messages.apachectl=/usr/sbin/apachectlhttpd=${HTTPD-/usr/sbin/httpd}prog=httpdpidfile=${PIDFILE-/var/run/httpd/httpd.pid}lockfile=${LOCKFILE-/var/lock/subsys/httpd}RETVAL=0STOP_TIMEOUT=${STOP_TIMEOUT-10}# The semantics of these two functions differ from the way apachectl does# things -- attempting to start while running is a failure, and shutdown# when not running is also a failure.  So we just do it the way init scripts# are expected to behave here.start() {        echo -n $&quot;Starting $prog: &quot;        LANG=$HTTPD_LANG daemon --pidfile=${pidfile} $httpd $OPTIONS        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; touch ${lockfile}        return $RETVAL}# When stopping httpd, a delay (of default 10 second) is required# before SIGKILLing the httpd parent; this gives enough time for the# httpd parent to SIGKILL any errant children.stop() {        status -p ${pidfile} $httpd &gt; /dev/null        if [[ $? = 0 ]]; then                echo -n $&quot;Stopping $prog: &quot;                killproc -p ${pidfile} -d ${STOP_TIMEOUT} $httpd        else                echo -n $&quot;Stopping $prog: &quot;                success        fi        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; rm -f ${lockfile} ${pidfile}}reload() {    echo -n $&quot;Reloading $prog: &quot;    if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then        RETVAL=6        echo $&quot;not reloading due to configuration syntax error&quot;        failure $&quot;not reloading $httpd due to configuration syntax error&quot;    else        # Force LSB behaviour from killproc        LSB=1 killproc -p ${pidfile} $httpd -HUP        RETVAL=$?        fi    fi    echo}# See how we were called.case &quot;$1&quot; in  start)        start        ;;  stop)        stop        ;;  status)        status -p ${pidfile} $httpd        RETVAL=$?        ;;  restart)        stop        start        ;;  condrestart|try-restart)        if status -p ${pidfile} $httpd &gt;&amp;/dev/null; then                stop                start        fi        ;;  force-reload|reload)        reload        ;;  graceful|help|configtest|fullstatus)        $apachectl $@        RETVAL=$?        ;;  *)        echo $&quot;Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|reload|status|fullstatus|graceful|help|configtest}&quot;        RETVAL=2esacexit $RETVAL  </code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;httpd服务&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>HTTP协议</title>
    <link href="https://www.liukui.tech/2018/12/18/HTTP%E5%8D%8F%E8%AE%AE/"/>
    <id>https://www.liukui.tech/2018/12/18/HTTP协议/</id>
    <published>2018-12-18T00:00:00.000Z</published>
    <updated>2019-01-22T11:55:18.830Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HTTP协议和APACHE原理"><a href="#HTTP协议和APACHE原理" class="headerlink" title="HTTP协议和APACHE原理"></a>HTTP协议和APACHE原理</h3><p>Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等<br>本文说的是HTTP SERVER<a href="http://www.apache.org/" target="_blank" rel="noopener">apache</a><br><a id="more"></a><br>HTTP2.4的官方文档<a href="http://httpd.apache.org/docs/2.4/" target="_blank" rel="noopener">http2.4文档：安装，模块，指令等说明</a><br>HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a><br><!--more--></p><h3 id="http协议-应用层协议-主流http-1-1版本"><a href="#http协议-应用层协议-主流http-1-1版本" class="headerlink" title="http协议:应用层协议,主流http/1.1版本"></a>http协议:应用层协议,主流http/1.1版本</h3><h4 id="http协议的版本区别"><a href="#http协议的版本区别" class="headerlink" title="http协议的版本区别"></a>http协议的版本区别</h4><p>http0.9、http1.0、http1.1和http2.0的版本区别</p><ul><li><p>http/0.9:</p><blockquote><p>只有一个GET命令，且只能回应<em>.html文件格式，像</em>.txt等都不支持</p></blockquote></li><li><p>http/1.0:效率太低</p><blockquote><p>1.支持cache, MIME(支持各种资源类型), method<br>2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低<br>3.引入了POST命令和HEAD命令，头部信息和<br>4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用</p></blockquote></li><li><p>http/1.1:主流使用版本</p><blockquote><p>1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭，<br>  对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性</p><pre><code>这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求</code></pre><p>2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率<br>3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)<br>4.缺点：<br>  同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象<br>5.解决队头堵塞的办法：<br>  为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等<br>6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度:</p><pre><code>不带状态怎么理解？http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点</code></pre></blockquote></li><li><p>http/2.0：解决 HTTP/1.1效率不高的问题</p><blockquote><p>1.头信息和数据体都是二进制，称为头信息帧和数据帧<br>2.和http1.1区别：请求不需要排队，提高效率<br>  复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）<br>3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度<br>4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息)</p></blockquote></li></ul><h3 id="HTTP工作机制"><a href="#HTTP工作机制" class="headerlink" title="HTTP工作机制"></a>HTTP工作机制</h3><ul><li>工作机制主要分为两步：请求和响应<blockquote><p>http请求：http request<br>http响应：http response<br>一次http事务：请求<-->响应</--></p></blockquote></li><li>Web资源：web resource<br>一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资<br>源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源<br>的集合<blockquote><p>静态页面/文件：无需服务端做出额外处理;</p><pre><code>服务器端是什么样传到客户端就是什么样，比如下面这些比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi只不过浏览器有时会解析出来以好看的页面展示给用户</code></pre><p>动态页面/文件：服务端执行程序，返回执行的结果</p><pre><code>服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果文件后缀：.php, .jsp ,.asp,.sh等将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户</code></pre></blockquote></li><li><p>提高HTTP连接性能</p><blockquote><p>并行连接：通过开多个TCP连接发起并发的HTTP请求<br>持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，<br>管道化连接：通过共享TCP连接发起并发的HTTP请求<br>复用的连接：交替传送请求和响应报文（实验阶段）</p></blockquote></li><li><p>HTTP协议的其他相关技术</p></li><li><p>1.URI：一般把URI认为是URL<br>URI: Uniform Resource Identifier 统一资源标识，分为URL和URN</p><blockquote><p>1.URN: Uniform Resource Naming，统一资源命名</p><pre><code>如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名</code></pre><p>2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置</p><pre><code>如输入一个网址，能具体体现出这个资源在互联网上的位置</code></pre><p>两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址</p></blockquote></li><li><p>URL的组成<br>scheme://user:password@host:port/path;params?query#frag</p><blockquote><p>scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等<br>user:用户，某些方案访问资源时需要的用户名<br>password:密码，用户对应的密码，中间用：分隔<br>Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析<br>port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080<br>/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔<br>params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对<br>query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能<br>frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔</p></blockquote></li><li><p>网站访问量</p><blockquote><p>1.IP(独立IP)：即Internet Protocol,指独立IP数。</p><pre><code>如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个</code></pre><p>2.PV(访问量)： 即Page View, </p><pre><code>页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量一般为了博客为了好看的访问量，都是统计PV量</code></pre><p>3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。</p><pre><code>网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1</code></pre></blockquote></li></ul><h3 id="Web服务请求处理步骤"><a href="#Web服务请求处理步骤" class="headerlink" title="Web服务请求处理步骤"></a>Web服务请求处理步骤</h3><p>很切合实际生活：比如<br>当我们打开一个浏览器，输入一个<a href="http://www.taobao.com，在互联网后台发生了什么？" target="_blank" rel="noopener">www.taobao.com，在互联网后台发生了什么？</a><br>这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图<br><img src="/2018/12/18/HTTP协议/web服务请求处理步骤.png" alt="web请求步骤"></p><p>当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程<br>每个过程都是一段需要原理详细描述的.</p><h4 id="一次完整的http请求处理过程"><a href="#一次完整的http请求处理过程" class="headerlink" title="一次完整的http请求处理过程"></a>一次完整的http请求处理过程</h4><pre><code>1.建立连接：接收或拒绝连接请求2.接收请求：接收客户端请求报文中对某资源的一次请求的过程Web访问响应模型（Web I/O）    单进程I/O模型：访问量不大        启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应        会造成请求排队现象，只适用于访问并发不大的情况    多进程I/O模型：        系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求        如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点        而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的    复用I/O结构：        开启多个进程进程，而一个进程又同时监控N个连接请求        只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗        实现方法：多线程模型和事件驱动        多线程模型：一个进程生成N个线程，每线程响应一个连接请求        事件驱动：一个进程处理N个请求    复用的多进程I/O模型：        启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求        充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的        nginx使用的复用多进程I/O模型</code></pre><font size="3" color="#FF0000"><br>    1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程<br>    2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应<br>    避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费<br>    同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题<br></font><p><img src="/2018/12/18/HTTP协议/web访问响应的四种模型.png" alt="web访问响应四种模型"><br>参考下面的HTTP的MPM三种工作模式<a href=""></a></p><pre><code>3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理    分析元数据：请求报文首部信息获得method    &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt;    HEADERS 格式 name:value    &lt;request body&gt;    通过method来响应用户请求，比如下载(get)，上传等信息    HTTP常用请求方式，Method        GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS4.访问资源：    服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源    在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件    web服务器资源路径映射方式：        (a) docroot        (b) alias        (c) 虚拟主机docroot        (d) 用户家目录docroot5.构建响应报文：    一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体   1）响应实体        描述了响应主体MIME类型的Content-Type首部        描述了响应主体长度的Content-Length   2）URL重定向        web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径   3）MIME类型   当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文    将构建完的响应报文发送给用户    将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户    用户再层层解封装获得index.html的内容7.记录日志    最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务    通过在/var/log/httpd/acess_log日志中记录http的响应记录数    方便分析日志统计该网站的IP，PV量等信息</code></pre><h3 id="Http协议"><a href="#Http协议" class="headerlink" title="Http协议"></a>Http协议</h3><pre><code>http协议    http/0.9, http/1.0, http/1.1, http/2.0http协议：stateless 无状态    服务器无法持续追踪访问者来源解决http协议无状态方法    cookie 客户端存放    session 服务端存放http事务：一次访问的过程    请求：request    响应：response</code></pre><h3 id="Session和Cookie的区别"><a href="#Session和Cookie的区别" class="headerlink" title="Session和Cookie的区别"></a>Session和Cookie的区别</h3><pre><code>前言:    HTTP是一种无状态的协议，为了分辨链接是谁发起的，就需要我们自己去解决这个问题。    不然有些情况下即使是同一个网站我们每打开一个页面也都要登录一下。而Session和    Cookie就是为解决这个问题而提出来的两个机制。应用场景:    1.日常登录一个网站，今天输入用户名密码登录了，第二天再打开很多情况下就直接打开      了。这个时候用到的一个机制就是cookie。    2.session的一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而      服务器端如何判别呢，所以也需要存储一些信息，这里就用到了session。Cookie的原理：    HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。    也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。    这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设    计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行    保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在    请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服    务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端    保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报    文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，    会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，    最后得到之前的状态信息。    通俗讲，Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时    候减少一些步骤。另外一个更准确的说法是：Cookies是服务器在本地机器上存储的小段文    本并随每一个请求发送至同一个服务器，是一种在客户端保持状态的方案。session的原理：    session就是一种保存上下文信息的机制，她是针对每一个用户的，session的内容在服    务器端，通过sessionId来区分不同的客户，session是以cookie或url重写为基础的，    默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie，我们成为session     cookie，以区分persistent coookies，注意session cookie是存储于浏览器内存中的    ，并不是写到硬盘上的；我们通常是看不见JSESSIONID的，但是当我们禁用浏览器的    cookie后，web服务器会采用url重写的方式传递sessionid，我们就可以在浏览器看到    sessionid=HJHADKSFHKAJSHFJ之类的字符串；session cookie针对某一次会话而言，会话结束session cookie也就消失了　session与cookie的区别：　　1.session保存在服务器，客户端不知道其中的信息；cookie保存在客户端，服务端可以        知道其中的信息　　2.session中保存的是对象，cookie中保存的是字符串　　3.session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个    地方都可以访问到；而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不道德session与cookie的联系：　　session是需要借助cookie才能正常工作的，如果客户端完全禁止cookie，session将失    效</code></pre><h3 id="Http应用层的报文头部-又分请求报文和响应报文两种"><a href="#Http应用层的报文头部-又分请求报文和响应报文两种" class="headerlink" title="Http应用层的报文头部:又分请求报文和响应报文两种"></a>Http应用层的报文头部:又分请求报文和响应报文两种</h3><p>-HTTP请求报文头部<br><img src="/2018/12/18/HTTP协议/请求报文头部.png" alt="HTTP请求报文头部"></p><pre><code>开始行    方法：method        GET： 从服务器获取一个资源        HEAD： 只从服务器获取文档的响应首部        POST： 向服务器输入数据，通常会再由网关程序继续处理        PUT： 将请求的主体部分存储在服务器中，如上传文件        DELETE： 请求删除服务器上指定的文档        TRACE： 追踪请求到达服务器中间经过的代理服务器        OPTIONS：请求服务器返回对指定资源支持使用的请求方法    URL:路径首部行实体行</code></pre><p>-HTTP响应报文头部<br><img src="/2018/12/18/HTTP协议/响应报文头部.png" alt="HTTP响应报文头部"></p><pre><code>开始行    版本：version        HTTP/&lt;major&gt;.&lt;minor&gt;1.1/2等等    状态码：        三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况    短语：        状态码所标记的状态的简要描述首部行实体行</code></pre><h3 id="Http常见的状态码和状态码分类"><a href="#Http常见的状态码和状态码分类" class="headerlink" title="Http常见的状态码和状态码分类"></a>Http常见的状态码和状态码分类</h3><pre><code>status(状态码)：    1xx：100-101 信息提示    2xx：200-206 成功    3xx：300-305 重定向    4xx：400-415 错误类信息，客户端错误    5xx：500-505 错误类信息，服务器端错误200： 成功，请求数据通过响应报文的entity-body部分发送;OK301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资      源现在所处的新位置；Moved Permanently302： 响应报文Location指明资源临时新位置 Moved Temporarily304： 如果之前访问一个网站，在本机上有缓存了，当再次访问时，就会出现304的状态码，      提示本地有不需要再去服务器上下载页面401： 需要输入账号和密码认证方能访问资源；Unauthorized403： 没有权限访问，请求被禁止了；Forbidden404： 服务器无法找到客户端请求的资源；要访问的文件不存在500： 服务器内部错误；Internal Server Error502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；Bad Gateway503： 服务不可用，临时服务器维护或过载，服务器无法处理请求      可能是服务器down机了，或者http服务关闭了504： 网关超时；转给后端服务器时，时间太长</code></pre><h3 id="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"><a href="#curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因" class="headerlink" title="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"></a>curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因</h3><pre><code>curl是基于URL语法在命令行方式下工作的文件传输工具1.它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。2.curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器，cookies，用户名/密码认证,下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling）3.还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等4.curl的强大在于能模拟各种浏览器自定义请求报文头部等信息，来访问某些控制严格的网站curl [options] [URL...]    -A/--user-agent &lt;string&gt; 冒充浏览器类型，实际上在请求报文修改了User-Agent        curl -A &apos;IE20&apos; http://192.168.34.103在http日志中可看到        一般用于测试访问网站或者爬虫功能要使用不同浏览器访问    -e/--referer &lt;URL&gt; 来源网址，防盗链相关        比如，伪装从百度跳转的192.168.34.103        curl -e &apos;www.baidu.com&apos; http://192.168.34.103    --cacert &lt;file&gt; CA证书 (SSL)    -k/--insecure 允许忽略证书进行 SSL 连接    --compressed 要求返回是压缩的格式    -H/--header &lt;line&gt;自定义首部信息访问网站    -i 显示页面内容，包括报文首部信息    -I/--head 只显示响应报文首部信息    -D/--dump-header &lt;file&gt; 将url的header信息存放在指定文件中，重定向    --basic 使用HTTP基本认证，401认证    -u/--user &lt;user[:password]&gt;设置服务器的用户和密码    -L 如果有3xx响应码，重新发请求到新位置        如果访问的网页被重定向到其他地方时，系统只会提示网页被重定向了，并不会跳转        -L就可以请求到新的页面上    -O 使用URL中默认的文件名保存文件到本地    -o &lt;file&gt; 将网络文件保存为指定的文件中    --limit-rate &lt;rate&gt; 设置传输速度    -0/--http1.0 数字0，使用HTTP 1.0    -v/--verbose 更详细    -C 选项可对文件使用断点续传功能    -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中    -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址    -X/--request &lt;command&gt; 向服务器发送指定请求方法    -U/--proxy-user &lt;user:password&gt; 代理服务器用户和密码    -T 选项可将指定的本地文件上传到FTP服务器上    --data/-d 方式指定使用POST方式传递数据    -b name=data 从服务器响应set-cookie得到值，返回给服务器elinks工具：    字符界面的浏览器，显示页面内容和源码等    elinks [OPTION]... [URL]...    -dump: 非交互式模式，将URL的内容输出至标准输出        比如有些网站是不允许复制的，通过-dump就可以把网站页面文字抓取到本地了        elinks -dump www.baidu.com        不过一般都是用js脚本限制了复制功能，在浏览器关闭js，或查看源码都可以    -source:打印源码</code></pre><h3 id="HTTP介绍"><a href="#HTTP介绍" class="headerlink" title="HTTP介绍"></a>HTTP介绍</h3><p>特性：<br>高度模块化：core + modules<br>DSO: Dynamic Shared Object 动态加/卸载<br>MPM：multi-processing module多路处理模块</p><h3 id="HTTP的三种工作模型：MPM工作模式"><a href="#HTTP的三种工作模型：MPM工作模式" class="headerlink" title="HTTP的三种工作模型：MPM工作模式"></a>HTTP的三种工作模型：MPM工作模式</h3><font size="3" color="#FF0000"><br>多用途的处理模块，三种模型分别是，默认使用prefork模型<br>因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型<br></font><h3 id="1-prefork：多进程I-O模型，每个进程响应一个请求，默认模型"><a href="#1-prefork：多进程I-O模型，每个进程响应一个请求，默认模型" class="headerlink" title="1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型"></a>1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型</h3><pre><code>一个主进程：生成和回收n个子进程，创建套接字，不响应请求多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个，消耗比较大内存资源受限于并发访问控制的内部系统调用机制：        select()；内生使用限制最多只能使用1024个描述符，所以最多也就1024个进程        epoll();Prefork MPM: 预派生模式，有一个主控制进程，然后生成多个子进程，使用select模型，最大并发1024，每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定，可以设置最大和最小进程数，是最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景。优点：稳定缺点：慢，占用资源，不适用于高并发场景配置文件原内容：&lt;IfModule mpm_prefork_module&gt;    StartServers           5 #定义apache服务在启动时启动的子进程数量    MinSpareServers         5 #定义最小空闲进程数，空闲进程就是没有处理用户请求的进程数    MaxSpareServers        10 #定义最大空闲进程数    MaxRequestWorkers      250 #定义在prefork模式下的最大并发连接数，表示了apache的最大并发处理能力，超过的连接请求将被排队等候处理。    MaxConnectionsPerChild   0  #进程生命周期内，处理的最大请求数目。达到该数目后，进程将死掉。如果设置    为0，表示没有限制。该参数的意义在于，避免了可能存在的内存泄露带来的系统问题。&lt;/IfModule&gt;如果确定合适的MaxRequestWorkers呢？首先，通过top命令查看apache进程占用的资源，主要看%CPU和%MEM这两个指标，例如，每个进程的CPU占用率不超过1%，每个进程的内存占用率不超过2%，考虑内存限制，比较合适的apache进程数量为50个，然后，逐步测试最大值。通过观测得来的CPU和内存的指标有一定的误差，一般可以适当调节这个数值，例如调到1.5或者2倍，再通过峰值场景下的机器是否卡顿来判断是继续上调还是下调。</code></pre><p><img src="/2018/12/18/HTTP协议/Prefork.png" alt="Prefork"></p><h3 id="2-worker：复用的多进程I-O模型-多进程多线程，IIS使用此模型"><a href="#2-worker：复用的多进程I-O模型-多进程多线程，IIS使用此模型" class="headerlink" title="2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型"></a>2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型</h3><pre><code>一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！woker MPM：是一种多进程和多线程混合的模型，有一个控制进程，启动多个子进程，每个子进程里面包含固定的线程，使用线程程来处理请求，当线程不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求，由于其使用了线程处理请求，因此可以承受更高的并发。优点：相比prefork 占用的内存较少，可以同时处理更多的请求缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生）配置文件原内容详解：&lt;IfModule mpm_worker_module&gt;    StartServers         3   # #定义apache服务在启动时启动的子进程数量，默认是3个     MinSpareThreads      75   # 整个控制进程保持最小数的空闲线程数    MaxSpareThreads      250  # 整个控制进程保持最大数的空闲线程数    #ThreadLimit        64   # 每个子进程可以启动的线程数量上限值，默认没有设置    ThreadsPerChild      25   # 每个子进程启动的线程默认数量，开启启动两个子进程每个子进程25个 线程，就是apache 启动后开启25个线程。    MaxRequestWorkers    400   # 所有子进程加起来的线程数量最大值，数量等于最大启动的进程数*ThreadsPerChild(每个进程的线程数)    MaxConnectionsPerChild   0  # 每个子进程被请求多少次服务后被kill掉重新生成一个新的子进程，为了解决内存回收方面的问题，0为不设置&lt;/IfModule&gt;</code></pre><p><img src="/2018/12/18/HTTP协议/Worker.png" alt="Worker"></p><h3 id="3-event：事件驱动模型（worker模型的优化-worker模型的变种）"><a href="#3-event：事件驱动模型（worker模型的优化-worker模型的变种）" class="headerlink" title="3.event：事件驱动模型（worker模型的优化,worker模型的变种）"></a>3.event：事件驱动模型（worker模型的优化,worker模型的变种）</h3><pre><code>event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用每一个cpu核心生成一个进程；一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n            注意这里的m*n和work的m*n是不同的机制相比较worker的有点：有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力event MPM：Apache中最新的模式，属于事件驱动模型(epoll)，每个进程响应多个请求，在现在版本里的已经是稳定可用的模式。它和worker模式很像，最大的区别在于，它解决了keep-alive场景下，长期被占用的线程的资源浪费问题（某些线程因为被keep-alive，空挂在哪里等待，中间几乎没有请求过来，甚至等到超时）。event MPM中，会有一个专门的线程来管理这些keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放。这样增强了高并发场景下的请求处理能力。event只在有数据发送的时候才开始建立连接，连接请求才会触发工作线程，即使用了TCP的一个选项，叫做延迟接受连接TCP_DEFER_ACCEPT，加了这个选项后，若客户端只进行TCP连接，不发送请求，则不会触发Accept操作，也就不会触发工作线程去干活，进行了简单的防攻击（TCP连接）,可以使用Telnet进行测试验证：主机192.168.10.130为客户端机器，192.168.10.131为apache服务器机器使用event模式：     在192.168.10.130上telnet 192.168.10.131 80，然后在192.168.10.130客户端机器上使用netstat查看，发现连接已经建立，处于ESTABLISHED状态，然后再到apache服务器192.168.10.131使用netstat查看，发现是处于SYN_RECV状态。优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放 缺点：没有线程安全控制配置文件内容：&lt;IfModule mpm_event_module&gt;    StartServers           3  #apache服务启动的子进程数，默认3个    MinSpareThreads         75  #控制进程保持最小的空闲线程数    MaxSpareThreads        250  #控制进程保持的最大空闲线程数    ThreadsPerChild         25  #每个子进程启动的线程数    MaxRequestWorkers       400  #并发最大请求数，也就是所有子进程加起来的线程数量，woker模式下的    400就是并发400，但是由于是异步处理请求的，因此这里的400比woker模型下的并发处理速度要快很多，因为event省略了工作线程的会话保持。    MaxConnectionsPerChild    0  #每个子进程请求多少次以后被kill掉重新生成一个新的子进程。&lt;/IfModule&gt;</code></pre><p><img src="/2018/12/18/HTTP协议/event.png" alt="event"></p><pre><code>注意：    event模型的强大的I/O机制    httpd从设计上就默认支持prefork    而nginx从设计上就支持event事件驱动模型</code></pre><h3 id="进程工作的角色切换"><a href="#进程工作的角色切换" class="headerlink" title="进程工作的角色切换"></a>进程工作的角色切换</h3><p><img src="/2018/12/18/HTTP协议/进程角色切换原理.png" alt="进程间的角色切换"></p><h3 id="Httpd的功能特性"><a href="#Httpd的功能特性" class="headerlink" title="Httpd的功能特性"></a>Httpd的功能特性</h3><p>httpd的常见特性：</p><ul><li>虚拟主机：在一个物理服务器上搭建多个网站<br>  IP、Port、FQDN</li><li>CGI：Common Gateway Interface，通用网关接口<br>  通过CGI接口处理动态的程序处理</li><li>反向代理<br>  当有用户访问量大时，在前端有一个服务器充当调度器的角色<br>  通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息<br>  看不到后端真正提供服务的服务器群</li><li>负载均衡</li><li>路径别名</li><li>丰富的用户认证机制<br>  basic<br>  digest</li><li>支持第三方模块</li></ul><h3 id="Httpd2-4新特性和安装以及配置"><a href="#Httpd2-4新特性和安装以及配置" class="headerlink" title="Httpd2.4新特性和安装以及配置"></a>Httpd2.4新特性和安装以及配置</h3><pre><code>新特性    MPM支持运行为DSO机制；以模块形式按需加载        在centos7上的httpd2.4上只有一个二进制程序            /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可        但是在centos6上的httpd2.2版本：            每个MPM模式都有各自对应的二进制程序                /usr/sbin/httpd                /usr/sbin/httpd.event                /usr/sbin/httpd.worker            如果更改MPM的模式，是需要改对应的二进制程序的    event MPM生产环境可用    异步读写机制    支持每模块及每目录的单独日志级别定义    每请求相关的专用配置    增强版的表达式分析式    毫秒级持久连接时长定义：httpd2.2只能精确到秒级别        上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的        所以在http中是可以定义连接时长(时长和传输请求两种方式)的    基于FQDN的虚拟主机不需要NameVirutalHost指令        httpd2.2创建虚拟主机时还需要NameVirutalHost指令        httpd2.4就不需要了    新指令，AllowOverrideList    支持用户自定义变量    更低的内存消耗</code></pre><h3 id="Httpd2-4的具体安装和配置"><a href="#Httpd2-4的具体安装和配置" class="headerlink" title="Httpd2.4的具体安装和配置"></a>Httpd2.4的具体安装和配置</h3><p>Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了<br>还支持第三方的模块，按需加载模块<br>存放模块的路径：/etc/httpd/modules</p><pre><code>CentOS7程序环境安装：httpd-2.4    yum install httpd     yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档主要配置文件：    /usr/sbin/httpd     httpd的主程序文件    /usr/lib/systemd/system/httpd.service   httpd的启动单元文件    /etc/httpd/conf/httpd.conf              主要配置文件        配置文件里的路径都是以/etc/httpd/为参考点的    /etc/httpd/conf.d/*.conf    /etc/httpd/conf.modules.d/00-mpm.conf    mpm相关    /etc/httpd/conf.modules.d/00-proxy.conf  配置代理相关    /etc/httpd/conf.modules.d/00-systemd.conf     /etc/httpd/conf.modules.d/01-cgi.conf    CGI相关    /var/cache/httpd    httpd的缓存目录    /var/log/httpd      httpd的日志文件目录            access_log: 访问日志            error_log：错误日志    /etc/httpd/modules  httpd的模块存放路径，软件比较复杂    /usr/lib64/httpd/modules   也是httpd的模块存放路径        两个模块的路径实际上是软链接关系    /var/www/html       httpd存放网页的目录：默认index.html帮助文档包：在没有网络时查看帮助文档，建议安装    httpd-manual检查配置文件语法：    httpd –t    类似DNS的rndc语法检查功能    sudo：visudo功能    ansible:ansible -C|--check 执行前检查语法功能    cobbler 也有httpd的控制和启动命令    systemctl enable|disable httpd.service    systemctl {start|stop|restart|status|reload} httpd.service    备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作        有时reload是无效的，只能restart服务</code></pre><h3 id="Httpd2-4的常见配置"><a href="#Httpd2-4的常见配置" class="headerlink" title="Httpd2.4的常见配置"></a>Httpd2.4的常见配置</h3><ul><li><p>1.显示服务器版本信息HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a></p><p>  主要组成:</p><pre><code>Global Environment   全局配置Main server configuration   一个服务器上搭建一个网站叫主服务器virtual host   虚拟主机，一台主机上搭建多个网站</code></pre></li></ul><p>练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)<br>egrep -v ‘^ <em>#.</em>|^$’ /etc/httpd/conf/httpd.conf</p><font size="3" color="#FF0000"><br>常见配置一般都在/etc/httpd/conf/httpd.conf的文件中<br>没有的配置选项可以加在httpd.conf文件最后，也可以放在<br>/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf<br>下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加<br></font><ul><li>1.显示服务器版本信息<br>  访问<a href="http://192.168.34.103" target="_blank" rel="noopener">http://192.168.34.103</a><br>  打开f12调试模式，可以看到回应头的信息中带有apache的版本信息<br>  也可以通过curl -I <a href="http://192.168.34.103来显示头信息" target="_blank" rel="noopener">http://192.168.34.103来显示头信息</a><br>  可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全<br>  查看指令参考文档：修改ServerTokens选项<pre><code>建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全</code></pre></li><li><p>2.修改监听的IP和Port<br>  Listen [IP:]PORT<br>  (1) 省略IP表示为本机所有IP<br>  (2) Listen监听端口至少一个，可以有多个端口<br>  (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口</p><pre><code>test.conf添加listen端口：listen 172.18.132.151:6666 6666端口只能通过此IP才能访问</code></pre></li><li><p>3.持久连接：默认KeepAlive是开启的<br>  Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接<br>  断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级<br>  副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞<br>  折衷：使用较短的持久连接时间</p><pre><code>设置：    KeepAlive On|Off       设置持久连接开启或者关闭    KeepAliveTimeout 15    设置持久连接为15s测试：telnet WEB_SERVER_IP PORT    GET /index.html HTTP/1.1    Host: WEB_SERVER_IP  host可以随便填写，但是在虚拟主机中是有区别的</code></pre></li><li><p>4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event<br>  默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf  修改mpm的文件<br>  建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的<br>  查看静态编译的模块<br>  httpd -l<br>  查看当前系统中httpd的静态编译及动态装载的加载的模块<br>  httpd –M<br>  动态模块加载：不需重启即生效<br>  动态模块路径<br>   /usr/lib64/httpd/modules/</p><pre><code>切换使用的MPM模块    在/etc/httpd/conf.modules.d/00-mpm.conf中    选择要启用的MPM相关的LoadModule指令即可prefork的配置：    StartServers 8               MinSpareServers 5       保留5个空闲子进程处理新的请求    MaxSpareServers 20      允许的最大空闲进程数    ServerLimit 256         最多进程数,最大20000，并发量建议最多10000         MaxRequestsPerChild     4000 子进程最多能处理的请求数量。在处理    MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进    程占用的内存就会释放(为0时永远不释放）worker和prefork配置类似，只不过会有线程数量的限制</code></pre><p>从下面ps auxf的进程图可以看书httpd是使用的prefork模型，而且因为端口是80，开启需要特殊<br>权限，所以父进程是root,子进程是apache</p></li></ul><p><img src="/2018/12/18/HTTP协议/HTTPD的prefork模型.png" alt=""></p><ul><li><p>5.DSO： Dynamic Shared Object<br>  加载动态模块配置<br>  /etc/httpd/conf/httpd.conf<br>  Include conf.modules.d/*.conf<br>  配置指定实现模块加载格式：<br>  LoadModule &lt;mod_name&gt; &lt;mod_path&gt;<br>  模块文件路径可使用相对路径：<br>  相对于ServerRoot（默认/etc/httpd）</p></li><li><p>6.定义’Main’ server的文档页面路径：存放页面的主目录<br>  主目录是由DocumentRoot指令来设置的<br>  网页文件默认是存在/var/www/html/下的，此处可以自定义<br>  在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html”</p><pre><code>如果要自定义主目录，还需要设置该目录为允许访问在httpd2.2上是不需要设置权限访问的但是在httpd2.4上是需要设置该目录允许访问的修改格式如下：#DocumentRoot &quot;/var/www/html&quot;DocumentRoot &quot;/data/www&quot;&lt;directory /data/www&gt;    Require all granted&lt;/directory&gt; </code></pre></li><li><p>7.定义站点默认主页面<br>  访问192.168.34.103默认显示的是index.html的内容，<br>  这一项是由DirectoryIndex指令设置的</p><pre><code>在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件</code></pre><font color="#FF0000"><br>此处需要了解httpd的权限和访问报错的相关问题和默认主页面：<br>1.访问192.168.34.103跳出的页面默认是index.html页面，如果不存在，则去找conf.d/welcome.conf文件，即报错提示，如果两个都不存在，显示的是/var/www/html目录下的文件列表，因为在httpd.conf配置文件中，定义options indexes选项<br>2.默认页面和默认访问目录都是可以通过指令来指定的<br>3.如果没有index.html文件，没有welcome.conf文件，没有options indexes配置，访问时会报错You don’t have permission to access / on this server.的提示.<br>4.上面三条在下面第12条配置别名时，可以体现的很明显<br>5.所以如果自定义目录和用别名，有时是需要设置目录访问权限、设置目录对应的index.html文件或者跳转的html文件(如果该文件存在就不需要设置了)，设置options indexes选项<br></font></li><li><p>8.站点访问控制常见机制<br>  可基于两种机制指明对哪些资源进行何种访问控制<br>  访问控制机制有两种：1.客户端来源地址，2.用户账号<br>  而文件系统路径：可以是<br>  1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配<br>  示例：<br>  ‘<filesmatch "\.(gif|jpe?g|png)$"="">‘’   用的是扩展的正则表达式<br>  <files “?at.*”="">                     通配符<br>  &lt;Location /status&gt;</files></filesmatch></p>  <locationmatch "="" (extra|special)="" data"=""></locationmatch></li><li><p>9.<directory>中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制<br>   (1) Options：后跟1个或多个以空白字符分隔的选项列<br>  在选项前的+，- 表示增加或删除指定选项<br>  常见选项：<br>  Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制<br>  适用于下载网站和镜像网站，不适合电商网站<br>  FollowSymLinks：允许访问符号链接文件所指向的源文件,<br>  None：全部禁用<br>  All： 全部允许</directory></p><pre><code>Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站    &lt;directory &quot;/data/www&quot;&gt;    options Indexes                                              Require all granted    &lt;/directory&gt;FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件    &lt;directory &quot;/data/www&quot;&gt;    options Indexes  FollowSymLinks           Require all granted    &lt;/directory&gt;</code></pre><font size="4" color="#FF0000"><br>实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.conf文件，welcome.conf文件就是页面上经常看到的测试123页面，把welcome.conf文件改名或删除，就会显示主目录下的所有列表文件了.<br></font><p>  (2) AllowOverride<br>  allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可<br>  只对<directory>语句有效;<br>  allowoverride权限时卸载httpd的*.conf配置文件中的<br>  AllowOverride All: .htaccess中所有指令都有效<br>  AllowOverride None： .htaccess 文件无效<br>  AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它</directory></p><pre><code>配置allowoverride示例：/etc/httpd/conf.d/test.conf中添加访问控制的目录    &lt;directory /data/www&gt;    allowoverride all  --&gt;这条必须写，代表.htaccess文件中的options生效    Require all granted    &lt;/directory&gt;在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中    options indexes FollowSymLinks</code></pre><p>  (3) 基于IP的访问控制:<br>  无明确授权的目录，默认拒绝<br>  允许所有主机访问：Require all granted<br>  拒绝所有主机访问：Require all denied<br>  控制特定的IP访问：<br>  Require ip IPADDR：授权指定来源的IP访问<br>  Require not ip IPADDR：拒绝特定的IP访问<br>  控制特定的主机访问：<br>  Require host HOSTNAME：授权特定主机访问<br>  Require not host HOSTNAME：拒绝<br>  HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机</p><pre><code>基于IP的访问控制示例：如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表除了/data/www/ceshi文件夹    &lt;directory /data/www&gt;    options indexes                                                      &lt;RequireAll&gt;    Require all granted    Require not ip 192.168.34.107    &lt;/RequireAll&gt;    &lt;/directory&gt;2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问&lt;directory /data/www&gt;options indexesRequire all granted&lt;/directory&gt;&lt;directory /data/www/ceshi&gt;&lt;RequireAny&gt;Require all deniedRequire ip 192.168.34.107&lt;/RequireAny&gt;                                                 &lt;/directory&gt;</code></pre></li><li><p>10.日志设定：日志默认/var/log/httpd/下<br><a href="http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats" target="_blank" rel="noopener">format官方说明文档</a><br>  日志类型：访问日志(access_log)和错误日志(error_log)<br>  日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式</p><pre><code>在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined   --&gt;由Logformat指令定义完起一个combined名CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式ErrorLog &quot;logs/error_log&quot;</code></pre><p>  可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径</p><pre><code>日志中的格式各个项说明%h 客户端IP地址%l 远程用户,启用mod_ident才有效，通常为减号“-”%u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-”%t 服务器收到请求时的时间%r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本%&gt;s 响应状态码%b 响应报文的大小，单位是字节；不包括响应报文http首部%{Referer}i     请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页    是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源，所以网站一般要加防盗链，防止资源被盗和占用服务器资源%{User-Agent}i 指客户端的浏览器版本</code></pre></li><li><p>11.设定默认字符集<br>  一般不需要设置：基本上使用的是utf-8;<br>  AddDefaultCharset UTF-8 此为默认值</p><pre><code>如果需要修改字符集，在test.conf或者httpd.conf下添加AddDefaultCharset gb2312 即可</code></pre></li><li><p>12.定义路径别名<br>作用：默认访问的文件夹是设置的DocumentRoot文件夹，如果不是在默认文件夹下，而需求要实现把其他路径下的目录共享出来，这就用到了定义路径别名的功能</p><p>  把一个URL起一个别名不指向真正的目录<br>  在httpd2.4里目录如果没有开启允许时，默认是不允许访问的</p><pre><code>例如：访问 /var/www/html/111,111这个目录可有可无，只是充当别名    实际上访问的是/data/www/ceshi目录         directoryindex ceshi.html        alias /111 /data/www/ceshi        &lt;directory /data/www/ceshi&gt;        options indexes        Require all granted        &lt;/directory&gt;         </code></pre></li></ul><font color="#FF0000"><br>注意：<br>1.111只是一个别名，在/var/www/html下不需要创建；但是如果/var/www/html下有111的文件夹，如果设置别名后，则访问的是/data/www/ceshi目录，原目录下的111文件夹就失效了。<br>2.在这里和上文第7条设置权限时有联系的，httpd2.4设置路径别名的时候，真正的路径也是需要在test.conf下设置权限的(/data/www/ceshi目录)<br>3.如果/data/www/ceshi/下没有index.html会报权限不允许的错误，所以要设置默认主页面directoryindex，当然可以设置options indexes选项<br></font><ul><li><p>13.基于虚拟账户的登录访问控制：提示401状态码<br>  认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码<br>  认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源<br>  两种认证方式：<br>  basic：用的多，缺点是明文，后面可以用https进行加密<br>  digest：兼容性差，用的少<br>  用户的账号和密码:非linux用户密码<br>  虚拟账号：多种存储方式，只用于httpd服务的，类似vsftp，samba服务的虚拟用户<br>  存储：账号可放在文本文件，SQL数据库，ldap目录存储，nis等</p><pre><code>因为basic使用的多，下文以basic认证配置示例1.提供账号和密码存储（文本文件），如创建一个tom虚拟账户管理httpd    htpasswd --&gt;可以指定加密算法        -c 自动创建文件，仅应该在文件不存在时使用        -p 明文密码        -d CRYPT格式加密，默认        -m md5格式加密        -s sha格式加密        -D 删除指定用户    htpasswd -c httpdpass tom :设定密码即可;目录可指定，后面改配置文件即可    htpasswd -s httpdpass jerry 再添加jerry用户，就不需要-c选项了    htpasswd -D httpdpass jerry 从文件中删除jerry用户    修改httpdpass权限，加固安全 chmod 600 httpdpass     或者也可以创建组文件httpdgroup，通过组来管理,组文件组和成员列表    testgroup: tom jerry2. 在test.conf或者httpd.conf下定义安全域    &lt;directory /var/www/html/ksdir&gt;    AuthType Basic          ---&gt;使用的认证方式    AuthName &quot;Login&quot;        ----&gt;登录提示信息    AuthUserFile &quot;/etc/httpd/conf/httpdpass&quot;  --&gt;加密账户文件    AuthGroupFile &quot;/etc/httpd/conf/httpdgroup&quot; --&gt;组账户    Require user tom        ---&gt;允许用户访问的列表    Require group testgroup  ---&gt;允许访问的组    &lt;/directory&gt;    但是：因为httpd线程是以apache运行的，而httpdpass是600权限，所以默认tom登录是没有权限的，让apache对httpdpass有读权限：    setfacl -m u:apache:r httpdpass 即可</code></pre></li><li><p>14.实现用户家目录的http共享;并实现账户机密访问<br>  实现基础：基于模块mod_userdir.so实现<br>  httpd -M |grep user 可以看出user加密的模块是已经加载的，直接改配置文件即可<br>  在/etc/httpd/conf.d/userdir.conf文件中定义了家目录共享的格式，只需要启用就行了</p><pre><code>实现步骤：1. vim /etc/httpd/conf.d/userdir.conf    &lt;IfModule mod_userdir.c&gt;     UserDir enabled      ---&gt;启用即可；默认不启用    UserDir public_html  ---&gt;创建一个public_html文件    &lt;/IfModule&gt;2.在test家目录下，创建public_html文件夹和public_html文件    su test    mkdir public_html/    echo 23333 &gt; /public_html/public_html3.因为httpd线程是apache身份登录的，所以要允许apache访问test用户的家目录    setfacl -m u:apache:x /home/test4.设置test家目录访问权限及用户加密    &lt;directory /home/test/public_html&gt;        authtype basic    authname &quot;test home&quot;    authuserfile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;调用之前创建的虚拟账户文件即可    Require user haha    &lt;/directory&gt;5.http访问test家目录方式,即可用加密账户登录    192.168.34.103/~test</code></pre></li><li><p>15.ServerSignature On|Off|EMail<br>  作用：当用户访问的页面不存在的情况下服务器会产生错误文档，而当ServerSignature选项是打开的情况下，错误文档会将服务器的名字，apahce的版本信息，显示在页面上，某种程度上会对web服务器产生不安全因素，所以一般建议关闭</p><pre><code>在配置文件添加一行：ServerSignature off 即可</code></pre></li><li><p>16.status页面<br>  作用：显示apache的工作状态，有助于判断apache是否正常工作<br>  status页面功能是由下面这个模块实现的：httpd<br>  LoadModule status_module modules/mod_status.so</p><pre><code>实现步骤：在配置文件添加&lt;Location &quot;/status&quot;&gt; SetHandler server-status&lt;/Location&gt;ExtendedStatus ON   #显示扩展信息</code></pre><p>  记录的信息包括：启动时间，线程数，等待连接数，cpu，进程，MPM等信息<br>  在实际生产中，由于apache服务器很多，就可以通过curl 192.168.34.103/status来抓取页面，分析apache某个指标是不是正常的；</p><pre><code>比如编写简单一个脚本：    curl 192.168.34.103/status |grep &quot;Apache Status&quot; || systemctl start httpd</code></pre></li><li><p><font size="5" color="#FF0000">17.实现http的虚拟主机</font><br>  作用：一个物理服务器上实现多台虚拟主机，至于为什么会用到虚拟主机，有可能是因为要上线的同一网站的有多个域名，却只有一个公网IP地址，也有可能是主机不多啊..，所以虚拟主机的价值就体现出来了…</p><p>  实现虚拟主机有三种方式</p><pre><code>基于ip：为每个虚拟主机准备至少一个ip地址，一个主机可以配多个内网IP地址基于port：为每个虚拟主机使用至少一个独立的port；80,8081,8082等等基于FQDN：为每个虚拟主机使用至少一个FQDN</code></pre><p>  当然这三种方式，基于IP和port的对于用户来说不太现实，一般都是通过输入域名方式来实现虚拟主机搭建.</p><pre><code>1.基于IP的虚拟主机搭建：但是这种方式用的比较少先准备三个网站目录，和在本机上添加三个IP地址    &lt;virtualhost 192.168.34.103&gt;    DocumentRoot &quot;/data/asite&quot;    &lt;directory /data/asite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_a.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.200&gt;    DocumentRoot &quot;/data/bsite&quot;    &lt;directory /data/bsite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_b.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.210&gt;    DocumentRoot &quot;/data/csite&quot;    &lt;directory /data/csite&gt;    Require all granted    &lt;/directory&gt;重启服务即可通过curl 192.168.34.103      curl 192.168.34.200    curl 192.168.34.210即可获取到各自的index.html文件内容，对应的日志也都生成了</code></pre><p>  2.基于port的虚拟主机搭建，监听三个port即可;使用的不多</p><pre><code>listen 8081listen 8082listen 8083&lt;virtualhost *:8081&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8082&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8083&gt;                                                                                                      servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;</code></pre><p>  通过本机IP+port获得不同网站的信息</p><pre><code>curl 192.168.34.103:8081curl 192.168.34.103:8082curl 192.168.34.103:8083</code></pre><p>  3.基于FQDN的虚拟主机搭建：用的最多<br>  前提：这里就不搭建DNS服务器了，使用本机的hosts文件进行域名解析</p><pre><code>&lt;virtualhost *:80&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;                                                                                                     servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_c.log combined&lt;/virtualhost&gt;</code></pre><p>  测试：curl <a href="http://www.a.com" target="_blank" rel="noopener">www.a.com</a></p><pre><code>curl www.b.cncurl www.c.net</code></pre><p>  就可获得各自的主页面信息<br>从这telnet就可以理解出，如果在互联网通过域名访问时(同一IP)，返回的结果是不同网站的信息<br>  [root@node7-1 ~]#telnet 192.168.34.103 80</p><pre><code>Trying 192.168.34.103...Connected to 192.168.34.103.Escape character is &apos;^]&apos;.GET /index.html HTTP/1.1HOST: www.a.com</code></pre></li></ul><font size="4" color="#FF0000"><br>当访问192.168.34.103时 HOST：即网站的域名，返回的结果就是其对应的页面信息<br>在互联网上，一般是先在本地服务器上通过第三种方式搭建多个网站，然后再通过服务商的智能DNS解析，可以通过访问不同的域名，解析到IP地址，服务器根据输入的HOST：域名判断访问的是哪个网站，进而返回对应网站站点的信息，对于主机较少或者IP有限的环境中，使用http虚拟主机还是很方便的。<br></font>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;a href=&quot;#HTTP协议和APACHE原理&quot; class=&quot;headerlink&quot; title=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;/a&gt;HTTP协议和APACHE原理&lt;/h3&gt;&lt;p&gt;Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等&lt;br&gt;本文说的是HTTP SERVER&lt;a href=&quot;http://www.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;apache&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="http" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/http/"/>
    
    
      <category term="Web服务" scheme="https://www.liukui.tech/tags/Web%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>编译安装LAMP</title>
    <link href="https://www.liukui.tech/2018/12/10/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85LAMP/"/>
    <id>https://www.liukui.tech/2018/12/10/编译安装LAMP/</id>
    <published>2018-12-10T00:00:00.000Z</published>
    <updated>2019-01-22T08:46:48.428Z</updated>
    
    <content type="html"><![CDATA[<p>LAMP<br><a id="more"></a></p><p><img src="/2018/12/10/编译安装LAMP/LAMP架构.png" alt=""></p><h3 id="Centos7上编译安装LAMP"><a href="#Centos7上编译安装LAMP" class="headerlink" title="Centos7上编译安装LAMP"></a>Centos7上编译安装LAMP</h3><pre><code>    备注：本文编译PHP是基于fastCGI方式，php-fpm编译准备：    在192.168.34.105上实现，准备安装包都放在/data/src下        apr-1.6.5.tar.bz2        apr-util-1.6.1.tar.bz2        httpd-2.4.37.tar.bz2        php-7.1.18.tar.bz2        wordpress-5.0-zh_CN.zip        mariadb-10.2.19-linux-x86_64.tar.gz    准备开发包组：        yum install &apos;develoment tools&apos; -y    1.编译安装httpd和apr        准备依赖包和解压安装包        yum install pcre-devel openssl-devel expat-devel apr-util-devel -y        tar xvf apr-1.6.5.tar.bz2        tar xvf apr-util-1.6.1.tar.bz2         tar xvf httpd-2.4.37.tar.bz2        cp -r apr-1.6.5 httpd-2.4.37/srclib/apr        cp -r apr-util-1.6.1 httpd-2.4.37/srclib/apr-util        a.编译            cd httpd-2.4.37            ./configure \            --prefix=/data/httpd24 \            --enable-so \            --enable-ssl \            --enable-cgi \            --enable-rewrite \            --with-zlib \            --with-pcre \            --with-included-apr \            --enable-modules=most \            --enable-mpms-shared=all \            --with-mpm=prefork            make &amp;&amp; make install        b.准备环境变量            用自带的服务控制脚本：/app/httpd24/bin/apachectl就需要设置环境变量了            echo &apos;PATH=/mysql/httpd24/bin:$PATH&apos; &gt; /etc/profile.d/httpd24.sh            . /etc/profile.d/httpd24.sh        c.修改配置文件，为了安全以apache用户运行，并监听在本地            useradd -r -s /sbin/nologin apache            vim /data/httpd24/conf/httpd.conf                User apache                Group apache                ServerName localhost:80    2.二进制安装mariadb-10.2.19        a.准备用户和mysql数据库目录                useradd -r -s /sbin/nologin -d /data/mysql mysql                mkdir /data/mysql                chown mysql.mysql mysql/        b.解压二进制安装包：            tar xvf mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local/            cd /usr/local            ln -s mariadb-10.2.19-linux-x86_64/ mysql            chown -R root.mysql /usr/local/mysql/        c.创建数据库文件:(通过自带脚本工具)            cd /usr/local/mysql/            scripts/mysql_install_db --datadir=/mysql/data --user=mysql        d.准备配置文件(不修改/etc/my.cnf)拷贝解压完的文件            mkdir /etc/mysql/            cp support-files/my-huge.cnf /etc/mysql/my.cnf                                路径优先级高于/etc/my.cnf                根据性能来拷贝配置文件            [mysqld]中添加三个选项：/etc/mysql/my.cnf            datadir = /mysql/data            innodb_file_per_table = on            skip_name_resolve = on 禁止主机名解析，建议使用        e.准备服务脚本，并启动服务            cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld            chkconfig --add mysqld            service mysqld start        f.准备PATH路径            echo &apos;PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh            . /etc/profile.d/mysql.sh            systemctl start mysqld        为wordpress准备数据库和账号密码            mysql -e &apos;create database wordpress&apos;            mysql -e &quot;grant all on *.* to php1@&apos;192.168.34.%&apos; identified by &apos;php123&apos;&quot;    3.FastCGI方式编译安装php-7.1.18        tar xf php-7.1.18.tar.bz2        安装依赖包            yum install libxml2-devel bzip2-devel libmcrypt-devel -y         a.编译，指定安装数据路劲和配置文件路径                   cd php-7.1.18            ./configure --prefix=/data/php \            --enable-mysqlnd \            --with-mysqli=mysqlnd \            --with-openssl \            --with-pdo-mysql=mysqlnd \            --enable-mbstring \            --with-freetype-dir \            --with-jpeg-dir \            --with-png-dir \            --with-zlib \            --with-libxml-dir=/usr \            --enable-xml \            --enable-sockets \            --enable-fpm \            --with-config-file-path=/etc \            --with-config-file-scan-dir=/etc/php.d \            --enable-maintainer-zts \            --disable-fileinfo            make &amp;&amp; make install        b.准备php配置文件            cd php-7.1.18            cp php.ini-production /etc/php.ini                可以修改当前时区和按照生产环境修改并发连接数等信息        c.创建nginx用户            useradd -s /sbin/nologin nginx        d.准备php的conf文件            cd /data/php            cp php-fpm.conf.default php-fpm.conf            cp php-fpm.d/www.conf.default php-fpm.d/www.conf            修改监听地址和允许连接地址，因为是在一台编译的，监听地址不用改了                vim php-fpm.d/www.conf                    listen = 127.0.0.1:9000                    ;listen.allowed_clients = 127.0.0.1                    user = nginx                    group = nginx        e.准备服务脚本:            cp /data/src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm            chmod +x /etc/init.d/php-fpm            chkconfig --add php-fpm            chkconfig php-fpm on    4.修改httpd文件，支持php和启用代理        编辑apache配置文件httpd.conf，以使apache支持php,并启用代理        vim /data/httpd24/conf/httpd.conf            1.取消下面两行的注释                LoadModule proxy_module modules/mod_proxy.so                LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so            2.定位至DirectoryIndex index.html                修改为DirectoryIndex index.php index.html            3.最后添加4行        AddType application/x-httpd-php .php        AddType application/x-httpd-php-source .phps        ProxyRequests Off        ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1             重启apache服务，apachectl restart    5.准备wordpress,把wordpress文件全部移动到httpd24/htdocs下        cd /data/src        unzip wordpress-5.0-zh_CN.zip        cd wordpress        mv * /data/httpd24/htdocs        为wordpress准备配置文件和数据库连接            cd /data/httpd24/htdocs            mv wp-config-sample.php wp-config.php            vim wp-config.php                define(&apos;DB_NAME&apos;, &apos;wordpress&apos;);                define(&apos;DB_USER&apos;, &apos;php&apos;);                define(&apos;DB_PASSWORD&apos;, &apos;php123&apos;);                define(&apos;DB_HOST&apos;, &apos;192.168.34.105&apos;);        修改/data/httpd24/htdocs的所有者和所属组            cd /data/httpd24            chown -R nginx.nginx htdocs/    到此所以的编译安装和准备工作都做完了，把mysql,php-fpm,httpd启动即可            apachectl start            systemctl start php-fpm            systemctl start mysqld        http://192.168.34.105 配置wordpress即可    备注：        创建的文章和账户是放在wordpress数据库中的;        图片是放在/data/httpd24/htdocs/wp-content/uploads下的</code></pre><p><font size="4" color="#23238E"><br>然后把这套系统搬到自己的云服务上就可以轻松的实现了,本文是基于LAMP架构实现的<br>不过推荐使用LNMP架构，毕竟Nginx的强大可不是吹出来的..<br></font> </p><p><font size="4" color="#FF0000">安装完成后，开启了一个新的世界，就可以开心的玩耍了,helloworld！</font><br><img src="/2018/12/10/编译安装LAMP/haha.png"><br><img src="/2018/12/10/编译安装LAMP/wordpress.png" width="80%" height="80%"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LAMP&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="个人博客搭建" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="web" scheme="https://www.liukui.tech/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>docker存储卷</title>
    <link href="https://www.liukui.tech/2018/10/18/docker%E5%AD%98%E5%82%A8%E5%8D%B7/"/>
    <id>https://www.liukui.tech/2018/10/18/docker存储卷/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-07T11:44:05.627Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Data-Volume：docker存储卷"><a href="#Docker-Data-Volume：docker存储卷" class="headerlink" title="Docker Data Volume：docker存储卷"></a>Docker Data Volume：docker存储卷</h3><a id="more"></a><pre><code>存储卷是什么：    存储卷是容器上一个或者多个“目录”，并将此“目录”与宿主机上的某目录建立关联关系，    存储卷在容器初始化之时会被创建，由baseimage提供的卷中的数据数据会在此时完成复制为什么需要用到存储卷:    docker启动一个容器是基于镜像的只读层，并在其上添加一个读写层，而镜像是由多个只读层叠加而来。如果运行中    的容器修改了现有一个已存在的文件，那该文件将会从只读层复制到读写层，而该文件的只读版本仍然存在，只是    被读写层中该文件的副本所隐藏而已，而此时关闭该容器，该容器所修改的文件的将会丢失且不能被其它容器共享、复用，因而需要一个存储卷。如何实现容器内的路径与容器外的存储建立关联关系？    实际应用场景：        1.通常在可写层上只保存临时数据，有效数据保存在和宿主机关联的目录下，这样就        剥离了程序和产生的数据间紧密的耦合关系，即程序在容器的名称空间上，数据在        宿主机或存储上，数据就独立于容器的生命周期之外        2.当容器down后，再启动一个新容器，指定数据路径为宿主机或存储上的路径，则        又恢复了数据，这就叫做Docker的存储卷存储卷存在的问题：    存在的问题        •存储于联合文件系统中，不易于宿主机访问；        •容器间数据共享不便        •删除容器其数据会丢失    解决方案：“卷(volume)”        •“卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机            上的某目录“绑定(关联)”        •Volume于容器初始化之时即会创建，由base image提供的卷中的数据会于此期间            完成复制        •Volume的初衷是独立于容器的生命周期实现数据持久化，因此删除容器之时既不会        删除卷，也不会对哪怕未被引用的卷做垃圾回收操作；存储卷的type:    1. Bind mount volume        绑定挂载卷，永久生效        容器内目录和宿主机中的目录都是由用户自己指定的，    2. Docker-managed volume：        称为docker自己指定的卷        容器中的卷是用户自己指定的，而宿主机上的目录是由docker-daemon进程自行        决定与宿主机的哪个目录建立        关联关系的存储卷，只能用于临时挂载。存储卷的相关命令:    docker run         -v 运行时，指定存储卷        --volumes-from list 复制其他容器的卷，达到共享卷的目的        --sorkdir string    docker volume         ls：列出当前已和宿主建立关联关系的存储卷        create：        inspect name:查看一个卷的详细信息        prune        rm: 因为docker container inspect c1看到的容器内的详细信息是JSON格式的    所以就可以通过过滤特殊字段显示查询的信息    docker container inspect CONTAINER_NAME -f {{.JSON_VALUE}}     Docker-managed volume        • ~]# docker run -it -name c1 –v /data busybox        • ~]# docker inspect -f {{.Mounts}} c1        • 查看c1容器的卷、卷标识符及挂载的主机目录            和docker container inspect c1的过滤效果一样    Bind-mount Volume        • ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name c1 busybox        • ~]# docker inspect -f {{.Mounts}} c1如图以过滤IP地址为例，其他信息类似</code></pre><p><img src="/2018/10/18/docker存储卷/JSON格式的过滤.png" alt="JSON格式过滤"></p><pre><code>示例1.Docker-managed volume    临时创建挂载一个mydata卷        docker run --name c1 -it  --rm -v /mydata busybox:latest        并通过docker container inspect c1 探测        mydata被docker指定与宿主机的哪个目录建立了关联关系</code></pre><p><img src="/2018/10/18/docker存储卷/docker管理的卷.png" alt="docker管理的卷"></p><font size="3" color="#FF0000"><br>从上图看mydata是被docker-manager指定与该容器目录下的_data建立了关系<br>注意：<br>创建容器的时候加–rm选项时，停止容器后，宿主机上的卷也会被删除的<br>不加–rm选项，停止容器，并rm容器，宿主机上的卷是不会被删除的<br>缺点是对应的宿主机上的目录难查找<br></font><pre><code>示例2.Bind mount volume    现在宿主机上创建卷的目录 mkdir /data/volume/c1docker run --name c1 -it  --rm -v /data/volumes/c1:/mydata busybox:latest     并通过docker container inspect c1 </code></pre><p><img src="/2018/10/18/docker存储卷/bind卷.png" alt="bind卷"></p><font size="3" color="#FF0000"><br>可以看出宿主机的/data/volumes/c1与容器内的/mydata是建立的bind类型的卷<br>即使容器被删除，数据还在存在的<br>而且如果/data/volume/c1是在NFS网络文件系统上的话，即使宿主机down了，数据也是无损的<br></font><pre><code>示例3：多容器之间的数据共享1.先创建容器c1docker run --name c1 -it  --rm -v /data/volumes/c1:/mydata busybox:latest 2.创建容器c2时，共享容器c1的卷    docker run --name c2 -it  --rm --volumes-from c1 busybox:latest    此时c1和c2上看到的mydata卷看的数据都是一样的，达到共享卷的目的示例4.用docker实现类似于k8s上的pod组件机制    要求：        1.c1上挂载多个NFS存储上的卷和bridge桥        2.c3和c4使用c1的网络名称空间和c1上的卷    实现：    c1:        docker run --name c1 -v /data/volumes/c1:/mydata -v /data/volume2:/mydata2 busybox:latest     c3.    docker run --name c3 -it --rm --network container:c1 --volumes-from c1  busybox:latest    c4.    docker run --name c4 -it --rm --network container:c1 --volumes-from c1  busybox:latest</code></pre><p><img src="/2018/10/18/docker存储卷/实现docker的pod组件模型.png" alt="实现docker的pod组件模型"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Data-Volume：docker存储卷&quot;&gt;&lt;a href=&quot;#Docker-Data-Volume：docker存储卷&quot; class=&quot;headerlink&quot; title=&quot;Docker Data Volume：docker存储卷&quot;&gt;&lt;/a&gt;Docker Data Volume：docker存储卷&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile</title>
    <link href="https://www.liukui.tech/2018/10/18/Dockerfile/"/>
    <id>https://www.liukui.tech/2018/10/18/Dockerfile/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-22T08:38:18.043Z</updated>
    
    <content type="html"><![CDATA[<h3 id="DockerFile：构建镜像"><a href="#DockerFile：构建镜像" class="headerlink" title="DockerFile：构建镜像"></a>DockerFile：构建镜像</h3><a id="more"></a><pre><code>前面说过：    1.镜像是分层的，当基于这个镜像创建一个容器时，docker是通过联合挂载机制把镜像层    进行叠加作为容器的只读层，而后又在这个镜像栈上构建了一个可写层作为这个容器的工    作目录.    2.所有的底层数据在第一次发生修改操作时，是通过CoW写时复制机制，把数据复制到读    写层进行修改并保存在读写层，覆盖底层的原始文件；写入新数据时，则直接保存在读写    层，而在读写层看到的数据就是全部的镜像层数据(镜像栈)    3.而Graph Driver则又在构建在本地文件系统之上的二级文件系统(aufs,overlay2)    4.基于Graph Driver这种特有的图形驱动程序，就可以把分成构建的镜像堆积在存储    空间当中，紧邻的镜像是有依赖关系的    5.docker commit可以把当前的读写层及其底层依赖的镜像关系打包成一个镜像层存储    在Graph Driver当中，并且指向底层依赖的镜像层，形成一个新的镜像层，如果基于    同一个镜像commit多个可写层，这些新的镜像层都是指向之前的底层镜像的，这也是    docker镜像不是很大的原因。    6.所以在制作镜像时，完全不必基于某个基础镜像显示启动一个新容器，然后在上面创建    修改可写层并打包成镜像；commit只是一种方式，也可以使用dokcerfile    7.如果再本地将软件源码编译/二进制编译到容器也是可以的</code></pre><h3 id="dockerfile基本要求"><a href="#dockerfile基本要求" class="headerlink" title="dockerfile基本要求"></a>dockerfile基本要求</h3><pre><code>1.dockerfile的工作逻辑：    制作镜像无非就是基于某个基础镜像创建一个可写层修改后再commit成一层新的镜像    这个过程可以由docker自身完成，只需要在dockerfile配置文件中写清楚，基于哪个基础镜像，    按需修改(通过各种指令生成)，而docker build可以读取dockerfile文件，隐    式的执行这些指令集生成一个新的镜像层保存在Graph Driver中2.工作目录    构建docker镜像时，必须有一个工作目录docker,这个目录下只存在dockerfile和在    dockerfile中定义要复制的文件，是起始目录3.dockerfile format：语法    dockerfile就是一个纯文本文件;        注释行        dockerfile instruction args:指令要纯大写        第一条指令必须是FROM：基础镜像名称        docker build是按顺序读取执行dockerfile中的指令集的4.dockerfile中的每一条指令都会生成一个新的镜像层    如果指令比较多，生成的镜像层就比较多，就会造成第一次的CoW从底层读取数据时很慢    但是镜像层比较多又容易被分享和易控，较少又会比较繁琐    所以一般是把做同一个件事的多个操作通过\换行符，用一条指令完成(见下文)5.镜像内唯一要运行的程序一定必须要运行在前台</code></pre><h3 id="dockerfile中的环境变量"><a href="#dockerfile中的环境变量" class="headerlink" title="dockerfile中的环境变量"></a>dockerfile中的环境变量</h3><pre><code>1.docker为了满足同一镜像在不同环境下的使用场景引入了环境变量的方式    某个容器基于镜像启动时，通过传递环境变量参数，来生成容器内的不同的配置文件    docker container run --name CONTAINER_NAME -e VAR -it IMAGE_NAME COMMAND    这样一来，就可以用基于同一基础镜像，传递不同的环境变量作为参数值，创建适应    于不同环境的容器2.entrypoint.sh脚本    但是传统的代码不支持传环境变量作为参数，而在docker中又需要传参，这时就有了衔接    层也就是shell脚本，这个脚本作为容器第一个要运行的程序然后运行完退出，再退出去    之前读取用户传的环境变量，将环境变量的值写到程序的配置文件中；    而且很多镜像通过docker image inspect mysql:8.0 |grep entrypoint过滤是可以    看到有这个脚本的3.环境变量的两类用法：    a.在构建dockerfile中使用    b.以dockerfile构建的镜像为基础镜像，启动容器时使用    而dockerfile中的指令的生命周期是有两个阶段的        build：基于基础镜像构建镜像的阶段        run: 启动容器的阶段        dockerfile中的一些指令或者环境变量在不同阶段使用发挥的价值是不一样的4.环境变量的设定和引用    设置：ENV statement    两种引用方式：    1.${variable:-word}         如果变量variable为空或不存在时，就使用word值        如果设置了variable，就使用该变量值    2.${variable:+word}         如果变量有值，就使用word值，如有没值就是空值</code></pre><h3 id="dockerignore-file"><a href="#dockerignore-file" class="headerlink" title=".dockerignore file"></a>.dockerignore file</h3><pre><code>1.dockerignore是工作目录中专门记录需要忽略的文件列表2.而且docker build会自动忽略.dockerignore自身和记录在其中的所有文件</code></pre><h3 id="Dockerfile基本语法"><a href="#Dockerfile基本语法" class="headerlink" title="Dockerfile基本语法"></a>Dockerfile基本语法</h3><pre><code>FROM：    FROM必须是文件的第一指令    FROM &lt;repository&gt;[:&lt;tag&gt;  镜像的标签    或者&lt;resository&gt;@&lt;digest&gt; 镜像的ID号校验码        推荐使用digest因为校验码是安全的，而且最好不要使用lastedLABLE:    authtor&apos;s infomation;提供该镜像的标签信息    语法： maintainer &quot;liu &lt;liu@163.com&gt;&quot;COPY:    从宿主机复制文件至创建的新镜像    COPY &lt;src&gt;... &lt;dest&gt;    COPY [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]         &lt;src&gt;：要复制的源文件或目录，支持使用通配符        &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则，COPY指定则以WORKDIR为其起始路径；        注意：在路径中有空白字符时，通常使用第二种格式    注意：    1. src：必须为build上下文中的路径，可使用相对路径    2.如果src是目录，其内部的文件或子目录会自动被递归复制，但src自身不会被复制            等于cp -r /src/* /dest/    3. src有多个，或者src使用通配符，则dest必须是一个目录，且必须以/结尾    4. 如果dest事先不存在，它将会被自动创建ADD:    类似于COPY，但是额外支持tar文件和URL路径    ADD &lt;src&gt;... &lt;dest&gt;    ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]    1. 如src为URL时且dest不以/结尾，ADD会自动将指定的文件下载并创建为dest，        如dest以/结尾，则会下载指定的文件并保存为dest/FILENAME        即一个是下载并改名，一个是下载到这个文件目录下    2. 如src是一个本地的tar文件，则会被自动展开为一个目录，但通过URL获取到的文件        则不会自动展开，即在本地的就展开，互联网的就不展开    3. 如src有多个，或使用通配符，则dest必须是目录且以/结尾，如dest不以/结尾，        则被视为一个普通文件，src的内容将被直接追加写入到dest文件中WORKDIR：    1.用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录    2.WORKDIR指令可出现多次，表示下个指令可以以此目录为父目录，路径可以表示为相对    路径，也可以写成绝对路径    3.WORKDIR的有效范围当前workdir向下，下一个workdir之前的范围    4.另外，WORKDIR也可调用由ENV定义的环境变量的值，如果下次修改环境变量的值，响应生成信息的镜像层    5.而且如果设定了WORKDIR，容器启动时，默认就进入到workdir路径了VOLUME：    用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷    注意：        1.在dockerfile中定义的卷，启动容器时，是被docker管理的卷与宿主机的某个            路径建立关联关系        2.如果需要定义的卷与宿主机特定的目录建立关联关系，还需要在run container时            指定-v选项        3.如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此            前的所有文件复制到新挂载的卷中EXPOSE:都是动态端口暴露    用于为容器打开指定要监听的端口以实现与外部通信    EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...]       &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议    注意：        1.即使在dockerfile中定义了暴露的端口，启动为容器时，端口也不会暴露的            因为是有安全风险的；        但可以用run container时加 -P选项强行暴露端口，但这是个动态端口暴露        用起来极其鸡肋！ENV：    build阶段使用的：        用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令        如ENV、ADD、COPY等）所调用，调用格式为$variable_name或${variable_name}    两种语法：    1.ENV &lt;key&gt; &lt;value&gt;         &lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只        能设置一个变量；    2.ENV &lt;key&gt;=&lt;value&gt; ...        可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果        &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另外，反斜线也可用于续行；    定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能    缺点：如果想修改ENV定义的值，只能修改dockerfile中的值，比价麻烦，此时    就可以使用ARG来代替ENVARG：    arg是在build阶段进行传值，替换dockerfile中的值        ARG &lt;name&gt; [=&lt;default&gt;] 可以设置默认值    当build创建镜像时没有传值，则使用在dockerfile中设置的默认值    既可以弥补ENV的缺点也可以和RUN，CMD的ENV传环境变量区别开    如：在build时更改home的值    docker image build --build-arg home=&quot;/webdata/&quot; /data/dockerfile/ -t myimg:v0.4</code></pre><h4 id="RUN-CMD-ENTRYPOINT的区别"><a href="#RUN-CMD-ENTRYPOINT的区别" class="headerlink" title="RUN,CMD,ENTRYPOINT的区别"></a>RUN,CMD,ENTRYPOINT的区别</h4><p><img src="/2018/10/18/Dockerfile/三者区别.png" alt="三者的区别"></p><p>区别：</p><pre><code>RUN：    用于指定docker build过程中运行的程序，可以是任何命令                (这就意味着RUN的命令必须是使用的基础镜像支持的命令)    1.是指在docker build过程中通过运行RUN定义的shell命令，以达到在镜像中安装软件等操作    2.RUN可以设定多次，而且每一个都会在build的时执行    语法：        RUN &lt;command&gt;            通常运行的是一个shell命令，且以&quot;/bin/sh -c&quot;运行，且/bin/sh是PID为1的进程，command是作为shell的子进程存在        RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;]            此种格式指定的命令不会以&quot;/bin/sh -c&quot;，因此无法支持shell的诸多特性，如要依赖于shell特性，可替换成如下格式：            RUN [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;]CMD：    1.当把镜像运行容器时，需要指定默认运行的程序，这在dockerfile中需要用CMD命令来        指定，ENTRYPOINT也可以    2.默认运行的程序必须运行在前台    3.由于CMD设定的是容器启动默认运行的程序，所以必须只有一个，如果有多个，        则最后一个CMD生效    语法：        CMD &lt;command&gt; 或        CMD [“&lt;executable&gt;”, “&lt;param1&gt;”, “&lt;param2&gt;”] 或        CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]        前两种语法格式的意义同RUN        第三种则用于为ENTRYPOINT指令提供默认参数    systemctl start httpd启动是运行在systemd的前台上，所以启动就会退出ENTRYPOINT：    1.CMD和ENTRYPOINT都表示镜像启动为容器时，容器默认运行的程序，而且CMD和ENTRYPOINT有多个，也都是最后一个生效    2.如果CMD和ENTRYPOINT同时存在，CMD和ENTRYPONIT需要组合起来，则CMD指定的内容    都作为ENTRYPOINT所指定内容的参数    语法：        ENTRYPOINT &lt;command&gt;或者        ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;]    docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到    ENTRYPOINT命令最后做为其参数使用    Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效</code></pre><p>示例：<br>    docker run –name c1 -P -d myimg:v0.1 以后台运行容器</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;DockerFile：构建镜像&quot;&gt;&lt;a href=&quot;#DockerFile：构建镜像&quot; class=&quot;headerlink&quot; title=&quot;DockerFile：构建镜像&quot;&gt;&lt;/a&gt;DockerFile：构建镜像&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker的资源限制</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%9A%84%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker的资源限制/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-26T13:44:29.460Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker资源限制"><a href="#Docker资源限制" class="headerlink" title="Docker资源限制"></a>Docker资源限制</h3><a id="more"></a><pre><code>docker容器得以实现的三个组件：    Namespace:内核中的名称空间是实现容器技术非常重要的组件    CGroups：实现容器的资源配额        1.如果没有资源配额的限定，比如恶意代码会占用宿主机上的很多资源，会造成其他容器无法运行的情况，        默认是宿主机上的所有资源.        2.cgroup允许将宿主机上的所有技术资源(CPU,内存等)做资源分割,以指定方式进行分配，而CPU和内存又分别支持两种不同的配额方式        3.CPU属于可压缩型资源，如果程序运行的cpu不够，只需要等待cpu资源即可，不会造成容器崩溃。        4.内存属于不可压缩型资源，如果一个进程依赖于3g内存来运行，宿主机只分配给它1g，则会造成OOM，这个进程就会因为内存耗尽而被终止.内存的限制方式：    -m|--memory= 限制容器的最大内存使用量，进程并不是一启动就占用最大内存的，而是            运行一段时间慢慢增长的，所以要分配给进程运行的最大内存.    --memory-swap * 当前容器所允许使用的交换分区大小(生产环境是禁止启用交换内存            的，因为性能会急剧下降.)    --memory-swappiness 使用交换分区的倾向性：因为使用交换分区会极大影响性能，        只有到万不得已才使用交换分区，数值越小,越会较晚使用交换分区，所以一般这个        值建议调小，默认是0-100    --memory-reservation 为系统保留多的内存空间，保证系统的正常运行    --kernel-memory  为内核保留多少内存空间    --oom-kill-disable  一旦某个容器发生OOM是否立刻kill这个容器，建议设置，因为        会造成整个宿主机的崩溃，也可以事先设定好内核和系统的内存空间，然后手动处理            发生OOM的容器，以便分析发生OOM的原因.    注意：        1.在容器内使用free命令可以看到的swap空间并不具有其所展现的空间指示意义.        2.-m|--memory=和 --memory-swap *一般是结合起来生效的CPU的限制方式：    主流的分两种：共享式和CPU绑定式    --cpu-shares 共享方式是基于权重分配的，而且是根据容器的数量和CPU的权重动态            分配调整的.如果只有一个容器在运行，那么这个容器也会尽可能的占用宿主机的CPU资源，这种分配方式依然会有可能造成系统崩溃.    --cpus &lt;value&gt; 定义容器最多跑满宿主机的几个核心数，例如宿主机有8核，限制容器        最多跑满2个核心数，而且这个2核可以跑在8个核心上加起来是2个核心数，也可以是        在2个核心上跑满.真正限制了容器使用的最大核心数.        docker的1.13版以后都使用这个选项来定义.    --cpuset-cpus         定义容器只能跑在宿主机核心的几号核心上，例如只允许跑在1号和3号核心上，那么        这个容器最多也就只能跑满这两个核心,也叫CPU绑定.</code></pre><p>所以在创建启动容器一定要做资源限制，即使不清楚容器中某个程序要占用多大的资源时，也应该设置只允许占用宿主机一半的资源.</p><h3 id="资源限制压测"><a href="#资源限制压测" class="headerlink" title="资源限制压测"></a>资源限制压测</h3><pre><code>在docker hub上的lorel/docker-stress-ng镜像    -c N 启动几个进程对CPU进行压测    -vm N 启动几个进程对内存做压测示例：通过该镜像进行压测    限制只能跑在cpu的0号和3号上，最多只能跑满2个核心数    限制最多占用512m的内存大小docker run --name stress --cpus 2 --cpuset-cpus 0,3 -m 512m --rm lorel/docker-stress-ng -c 2 -vm 2</code></pre><p>-docker stats命令查看结果<br><img src="/2018/10/18/Docker的资源限制/docker-stats.png" alt="docker status"></p><p>-top命令显示宿主机资源(安装1显示全部的CPU核心数信息)<br><img src="/2018/10/18/Docker的资源限制/top命令.png" alt="top命令"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker资源限制&quot;&gt;&lt;a href=&quot;#Docker资源限制&quot; class=&quot;headerlink&quot; title=&quot;Docker资源限制&quot;&gt;&lt;/a&gt;Docker资源限制&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker镜像</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E9%95%9C%E5%83%8F/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker镜像/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-02-15T05:54:46.540Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Images"><a href="#Docker-Images" class="headerlink" title="Docker Images"></a>Docker Images</h3><a id="more"></a><font size="3" color="#FF0000"><br>1.docker image是docker贡献给容器极具创造性的使用方式！<br>2.分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！<br>3.容器编排技术：<br>—Docker通过镜像机制极富创造性的解决了应用程序打包的根本性难题，它推动了容器技术的快速普及和生产落地<br>—容器本身仅提供托管运行应用的底层逻辑，而容器编排(Orchestration)才是真正产生价值的位置所在；<br></font><p>-docker-image和读写机制<br><img src="/2018/10/18/Docker镜像/docker读写机制.png" alt="docker-image和读写机制"></p><pre><code>1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器    a.docker镜像就像KVM镜像一样，包含了启动容器/虚拟机所依赖的所有文件，文件系统        包括程序文件，库文件，配置文件,数据目录等等    b.dokcer采用分层构建机制，最底层为bootfs，其上是rootfs        bootfs：在创建的容器中是看不到的，只是用于系统引导的文件系统，包括                bootloader和kernel，因为在创建启动容器时，其实是用到内核的，                只不过只是启动引导容器启动的，当容器启动完成后会被卸载以节约内存资源;                而且把对应的对容器的管理委托给宿主机的内核，所以容器镜像的内核只                是启动时有用，而且看不到，所以bootfs叫引导文件系统        rootfs:位于bootfs之上，表现为docker容器的根文件系统;                1.在传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只                    读&quot;模式，完整性自检完成后将其重新挂载为读写模式；也就是fstab                    的最后两项，只有通过自检次序时，才会把根文件系统重新以&quot;读写&quot;方式挂载.                2.但是在docker中，rootfs由内核挂载为&quot;只读&quot;模式，就算容器启动完成                    ，rootfs也不会以读写方式重新挂载！也就是说docker容器的用户空                    间和根文件系统一直都是只读的！                3.docker是通过&quot;联合挂载&quot;技术额外挂载一个“可写”层；docker image layer2.Docker Images Layer    如上图    a.完整的docker镜像包括bootfs,rootfs    b.而rootfs又包括Base Image+自定义的镜像层+可写层writable        除了writable是可写层，其他都是只读层    c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加        一个可写层，这个可写层writable是属于容器的    d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的</code></pre><h4 id="容器的读写原理："><a href="#容器的读写原理：" class="headerlink" title="容器的读写原理："></a>容器的读写原理：</h4><p>如上图示： </p><ul><li>1.对于docker来说有一个专门存放镜像的路径叫Graph Driver，而这个文件系统必须是特殊<br>  格式的(aufs或者overlay2),在linux系统内默认是/var/lib/docker/image/overlay2；<br>  overlay2目录就是构建在宿主机(xfs或ext4)的/var/lib/docker/image/目录的二级文件系统</li></ul><ul><li>2.前面说镜像数据文件都放在bootfs和rootfs上的，可写层writbale是创建时创建的<br>  那么在可写层上是如何看到底层的数据目录？又是怎么把数据增删改到容器内的？<br>  默认xfs和ext4是不支持COW机制的</li></ul><blockquote><p>如何看到镜像目录的？</p></blockquote><pre><code>a.在创建容器时，是把镜像内的多层镜像通过联合挂载方式作为可写层的底层，也就是这个容器内部的可访问文件系统接    口b.所谓联合挂载，是通过把镜像内的多层一层一层叠加上去的，而这个叠加方式的原理是：    第一层上有数据时，而第二层没相同数据，在第二层是可以看到第一层数据的;如果第二层有第一层相同数据，    则会覆盖第一层上的相同数据，在第二层上看到的是第一层和第二层总的文件，以此类推，在可写层上就可以看到    镜像内的数据目录了，</code></pre><blockquote><p>如何修改和写文件？</p></blockquote><pre><code>a.对于修改文件，因为文件是放在只读层的，只能是通过COW写时复制机制，先把文件从只读层复制到可写层上再进行修改    然后保存在可写层,当然是首次修改，第二次再修改因为在可写层有文件了，在可写层修改即可，而只读层的该文件    版本仍然存在，只不过是被读写层中该文件的副本所隐藏了.b.对于写文件，新创建的文件是保存在可写层的，所以最终用户看到的是只读层和可写层的全    部数据文件，这就是镜像的工作逻辑</code></pre><blockquote><p>通过上面的分析可以得出：</p></blockquote><pre><code>1.这就是为什么基于同一镜像创建的两个容器，用户在不同的容器上看到的相同的数据都是只读层的，不同的数据是可写    层上各自独有的，因为可写层是独占的，只读层是共享的2.这就是为什么镜像背后必须要求特殊文件系统的原因：因为ext4和xfs默认是不支持联合挂载和写时复制机制的3.因为可写层是可以自定义修改的，把可写层保存为镜像，然后再和原始镜像进行叠加成一个自定义的镜像，    就可以作为基础镜像使用了，不过一般不这么做，而是通过dockerfile自定义镜像</code></pre><h3 id="docker-imge相关命令"><a href="#docker-imge相关命令" class="headerlink" title="docker imge相关命令"></a>docker imge相关命令</h3><pre><code>docker image 相关命令    docker imges:镜像的管理命令    ls： 查看本地所有的镜像列表    build:    import:    inspect: 查看下载/创建的镜像详细信息            可以查看下载的某个镜像的具体信息                    如：CMD:镜像启动默认运行的命令                        Volume:                        network:            下文中构建docker file时这些都可以自定义    load:    prune:    pull：从远程仓库拉取镜像到本地    push: 把本地镜像推到远程的Registry    rm:  docker image rm = docker rmi 删除镜像    tag: 给镜像打标签    save:2.将当前容器可写层保存为镜像并上传docker hub上    docker container commit [options] container [repository:[tag]]         选项：            -a:指定作者            -c:镜像内部默认运行的命名            -p|--pause:因为制作镜像时，容器还在运行，可能制作出的镜像和当前容器不                一致，可以在制作时，暂停容器，保持数据一致    比如：        1.在docker hub上注册用户，并创建镜像仓库            创建的仓库：myimg        2.把centos1容器做成镜像仓库下的myimg：v0.1版本            docker container commit -p -a &quot;liu &lt;liu@163.com&gt;&quot; -c &quot;CMD [&apos;/bin/httpd -f&apos;]&quot; centos1 liukkui/myimg:v0.1            然后新容器就可以基于这个镜像启动了        3.上传docker hub            docker login 登录到docker hub                输入账号密码，正常登录后        4.push镜像            docker image push liukkui/myimg:v0.1            正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Images&quot;&gt;&lt;a href=&quot;#Docker-Images&quot; class=&quot;headerlink&quot; title=&quot;Docker Images&quot;&gt;&lt;/a&gt;Docker Images&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker仓库管理工具Harbor</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7Harbor/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker仓库管理工具Harbor/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-27T03:25:41.692Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker仓库管理工具Harbor"><a href="#Docker仓库管理工具Harbor" class="headerlink" title="Docker仓库管理工具Harbor"></a>Docker仓库管理工具Harbor</h3><a id="more"></a><p><img src="/2018/10/18/Docker仓库管理工具Harbor/harbor架构.png" alt="harbor架构"></p><p><a href="https://goharbor.io/" target="_blank" rel="noopener">HARBOR</a><br><a href="https://github.com/goharbor/harbor" target="_blank" rel="noopener">github上的harbor</a></p><pre><code>harbor官方功能介绍：    1.基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可        以对多个镜像仓库在同一命名空间（project）里有不同的权限。    2.镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡，        高可用，混合云和多云的场景。    3.图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，        管理项目和命名空间.    4.Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。    5.AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。    6.审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。依赖环境和使用介绍：    1.harbor是基于distribution二次开发的企业级私有仓库，云原生registry，多租户机制，允许用户创建自己的名称空间    2.因为harbor内置了mysql,nginx等服务才能构建一个harbor,所以依赖于docker-compose进行容器编排和依赖于至少docker-17.03.0版本    3.harbor为了安全，也需要以https运行，需要在harbor服务器提供证书，而且也需要为        其他客户端提供证书，为harbor验证使用，当然可以关闭https功能    4.因为需要实时下载镜像，提供了离线安装和在线安装，也可以安装到vSphere平台(OVA方式)虚拟设备。</code></pre><h3 id="离线版安装和配置："><a href="#离线版安装和配置：" class="headerlink" title="离线版安装和配置："></a>离线版安装和配置：</h3><p><a href="https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.1.tgz" target="_blank" rel="noopener">harbor离线安装包下载</a><br><a href="https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md" target="_blank" rel="noopener">离线版安装部署文档</a></p><pre><code>1.先安装docker-compose，docker-ce    yum install docker-compose docker-ce -y2.tar xf harbor-offline-installer-v1.4.0.tgz -C /usr/local/3.cd /usr/local/harbor并修改主配置文件harbor.cfg    [root@mysql_2 harbor]# grep &quot;^[a-Z]&quot; harbor.cfg         hostname = mysql_2      #设置主机名/IP        ui_url_protocol = http      #访问协议，支持http和https        max_job_workers = 10        #最大进程连接数    #####设置使用https协议的证书和路径#####        customize_crt = on          #是否使用自定义证书        ssl_cert = /data/cert/server.crt        ssl_cert_key = /data/cert/server.key        secretkey_path = /data        log_rotate_count = 50       #本地最多保存50次日志滚动        log_rotate_size = 200M      #当日志达到200M时滚动一次        http_proxy =                #是否使用代理        https_proxy =        no_proxy = 127.0.0.1,localhost,core,registry    ####设置用户上下载镜像时，是否启用发邮件功能#########        email_identity =         email_server = smtp.mydomain.com        email_server_port = 25        email_username = sample_admin@mydomain.com        email_password = abc        email_from = admin &lt;sample_admin@mydomain.com&gt;        email_ssl = false        email_insecure = false    ####使用互联网上的邮箱##############        harbor_admin_password = Harbor12345    #harbor默认的管理员密码        auth_mode = db_auth                    #默认使用的数据库类型        db_host = mysql         #设置连接mysql的端口和用户密码        db_password = root123        db_port = 3306        db_user = root         #这里还支持 ldap 以及 本地文件存储方式。    #####修改数据库类型和用户和密码#########4.运行install.sh    因为是离线安装包，会从tar文件中装入所需的镜像文件并启动，启动时会检查    docker-ce和docker-compose的版本开始加载镜像(mysql,redis,nginx等等)    [root@mysql_2 harbor]# ./install.sh     [Step 0]: checking installation environment ...    Note: docker version: 18.09.0    Note: docker-compose version: 1.18.0    [Step 1]: loading Harbor images ...</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/harbor安装过程.png" alt="创建并启动的所有容器"><br><img src="/2018/10/18/Docker仓库管理工具Harbor/和harbor相关的所有容器.png" alt="创建并启动的所有容器2"></p><pre><code>5.启用的容器可能会使用宿主机的名称空间6.通过docker-compose管理harbor    cd /usr/local/harbor/    docker-compose stop    docker-compose start</code></pre><p>登录web管理界面：<a href="http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码" target="_blank" rel="noopener">http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码</a><br><img src="/2018/10/18/Docker仓库管理工具Harbor/登录页面.png" alt="登录页面"></p><pre><code>7.创建用户和测试仓库：    创建lk用户，测试登录    创建test仓库用于测试上传镜像 直接创建test仓库即可</code></pre><h3 id="内网服务器登录harbor"><a href="#内网服务器登录harbor" class="headerlink" title="内网服务器登录harbor"></a>内网服务器登录harbor</h3><p>-登录报错<br>–Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。<br>如果配置文件中启用了https，而且也有证书等信息，就不会有这个报错<br><img src="/2018/10/18/Docker仓库管理工具Harbor/登录报错.png" alt="docker login报错"></p><pre><code>解决方法：    1.在所有的内网需要上传下载镜像的服务器上都创建daemon.json文件        vim /etc/docker/daemon.json        {           &quot;insecure-registries&quot;:[&quot;192.168.100.17&quot;]           ###该选项表示从不安全的仓库下载或上传镜像        }    2.还要注意：        如果[&quot;192.168.100.17&quot;]中使用的主机名，那么需要在本地hosts文件或者局域网DNS        服务器上进行主机名解析    3.也可以修改vim /usr/lib/systemd/system/docker.service文件        vim /usr/lib/systemd/system/docker.service             ExecStart=/usr/bin/dockerd  --insecure-registry 192.168.100.17        重启docker            systemctl daemon-reload            systemctl restart docker    4.docker login 192.168.100.17|主机名 #登录私有harbor仓库      docker logout 192.168.100.17|主机名 #退出私有harbor仓库</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/成功登录.png" alt="成功登录"></p><pre><code>4.制作镜像并测试上传    制作镜像：docker tag httpd:v0.1 192.168.100.17/test/httpd:v1                将之前制作好的镜像改标签再上传上去            docker image build . -t 192.168.100.17/test/httpd:v2.0                也可以通过dockerfile重新制作一个再上传    上传到test仓库中: docker push 192.168.100.17/test/httpd:v1</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/上传.png" alt="上传镜像"><br><img src="/2018/10/18/Docker仓库管理工具Harbor/上传镜像.png" alt="上传镜像"></p><pre><code>5.测试拉取镜像    在页面上点击复按钮，在命令行中就可以拉取镜像了</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/拉取镜像.png" alt="拉取镜像"></p><h3 id="如何修改配置："><a href="#如何修改配置：" class="headerlink" title="如何修改配置："></a>如何修改配置：</h3><pre><code>[root@linux-host1 harbor]# /usr/local/harbor[root@linux-host1 harbor]# docker-compose   stop #先停止服务[root@linux-host1 harbor]# vim harbor.cfg  #编辑配置[root@linux-host1 harbor]# docker-compose start #重新启动服务</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker仓库管理工具Harbor&quot;&gt;&lt;a href=&quot;#Docker仓库管理工具Harbor&quot; class=&quot;headerlink&quot; title=&quot;Docker仓库管理工具Harbor&quot;&gt;&lt;/a&gt;Docker仓库管理工具Harbor&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker网络</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%BD%91%E7%BB%9C/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker网络/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-02-15T08:21:33.861Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Network"><a href="#Docker-Network" class="headerlink" title="Docker Network"></a>Docker Network</h3><a id="more"></a><p><img src="/2018/10/18/Docker网络/docker的四种网络.png" alt="docker的四种网络"></p><pre><code>KVM上虚拟桥接式网络类型：        隔离桥：只能与连接到同一个桥上的主机通信，IP地址还需要在同一网段        仅主机桥：可以和连接的桥地址进行通信        路由桥：            1.打开宿主机核心转发功能            2.虚拟机的网关都指向这个桥的地址            就可以与宿主机通信，不能与外网通信        NAT桥：在路由桥的基础上，在宿主机上做SNAT规则，即可访问外网地址    Docker提供的四种网络：    桥网络：桥接网络            bridge，默认就是docker0桥，docker0是SNAT桥            查看网络定义：docker network inspect bridge            大多数的容器还是使用bridge网络            而且这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器    共享桥：联盟式网络         每一个容器都是靠在内核级虚拟资源分配的独立的6种名称空间来支撑的        这6种名称空间是IPC,Net,Mount,UTS,PID,USER        虽然每个容器都有各自独立的名称空间，但是确可以共享，于是就有了这种方式        共享桥的原理：                共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈            而mount user PID还是隔离的，文件系统也是隔离的        这样做的效果就可以构建出一个模型            httpd---&gt;fpm127.0.0.1:9000---&gt;mysql127.0.0.1:3306            那么对于fpm和mysql来说只监听在本地端口上，保证了安全性    host宿主机网络：共享宿主机网络        既然多个容器可以使用同一个容器的网络名称空间，而且宿主机在内核中也有自己的        网络名称空间，那么容器也理所当然的可以使用宿主机的网络名称空间        容器使用宿主机的网络和DNAT方式有关系        作用：可以做日志收集主机，host一般在特殊环境下使用    none网络：封闭式网络        当容器不需要网络服务时，不创建网卡，只有本地lo网卡除了bridge桥之外，其他三种网络都是docker所独有的</code></pre><h3 id="Docker网络的相关命令"><a href="#Docker网络的相关命令" class="headerlink" title="Docker网络的相关命令"></a>Docker网络的相关命令</h3><pre><code>docker run 命令中涉及网络的相关命令    --network 启动容器时，指定使用的网络        [bridge|host|none|container:name]    --hostname 启动容器时，指定容器的主机名    --add-host list 启动容器时，指定内部的hosts解析文件        如：docker run --add-host c1:192.168.10.1 busybox:latest            cat /etc/hosts可以看到添加的解析    --dns 启动容器时，指定DNS地址        如：docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest            cat /etc/resolve可以看到指定的DNS地址    --ip string 启动容器时，指定容器的iPv4地址    -p|--publish         因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则docker network:    ls：显示docker内部的全部网络    connect: 让容器连接到某个网络上    disconnect: 把容器从某个网络断开    create: 创建自定义网络，和KVM创建网络类似    inspect:查看某个网络是怎么定义的    prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令    rm: 删除docker内部的网络</code></pre><h3 id="Docker-network的端口暴露"><a href="#Docker-network的端口暴露" class="headerlink" title="Docker network的端口暴露"></a>Docker network的端口暴露</h3><pre><code>docker run --network [bridge|host|none] -p|--publish     作为一个容器，是要提供web服务的，而docker默认的桥是bridge，而且是个SNAT桥    容器只能访问外网，而不能被外网所访问，那么就失去了web服务器对外提供服务的初衷    而docker提供了一个-p选项来自动生成DNAT规则，来避免每次都手写DNAT规则带来的麻烦-p选项的用法和使用格式：    •-p &lt;containerPort&gt;        将指定的容器端口映射至主机所有地址的一个动态端口    •-p &lt;hostPort&gt;:&lt;containerPort&gt;        将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt;    •-p &lt;ip&gt;::&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口    •-p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt;    “动态端口”指随机端口，具体的映射结果可使用docker port命令查看    不过一般还是要使用第四种方式指定宿主机的端口    指定了映射的端口后，可以使用命令查看映射关系：        docker container port [name]示例：1.docker run --name c1 -it --rm --network bridge -p 80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:327682.docker run --name c1 -it --rm --network bridge -p 80:80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:803.docker run --name c1 -it --rm --network bridge -p 192.168.34.103::80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:327684.docker run --name c1 -it --rm --network bridge -p 192.168.34.103:80:80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:80</code></pre><h3 id="Docker的自定义网络"><a href="#Docker的自定义网络" class="headerlink" title="Docker的自定义网络"></a>Docker的自定义网络</h3><pre><code>docker network create     connect:相当于创建一对网卡，一半在桥上，一半在容器中    而且默认创建的网络都是SNAT桥    选项：    -d|--driver string 创建时，要指定桥的类型        默认是bridge，当然还有 host macvlan null overlay四种类型    --gateway strings 默认是定义的子网的第一个IP地址    --subnet strings 子网地址    --ip-range strings 地址分配的IP地址范围修改默认的bridge，docker0桥的子网    自定义docker0桥的网络属性信息：也就是镜像加速的文件    vim /etc/docker/daemon.json文件    {        &quot;bip&quot;: &quot;192.168.1.5/24&quot;,        &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;,        &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,        &quot;mtu&quot;: 1500,        &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,        &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,        &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]    }     核心选项为bip，即bridge 桥接口的IP地址    ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。示例：    1.创建一个mybr2的网络，并指定子网地址        docker network create --subnet 10.0.0.0/8 mybr2    2.创建容器c1指定加入到mybr2网络中        docker run --name c1 -it --rm --network mybr2  busybox:latest    3.给容器c1再加入一个bridge网络中        docker network connect bridge c1        此时c1就有了两个网络地址    4.删除容器c1的网卡        docker network disconnect mybr2 c1</code></pre><h3 id="Docker指定容器启动的网路类型"><a href="#Docker指定容器启动的网路类型" class="headerlink" title="Docker指定容器启动的网路类型"></a>Docker指定容器启动的网路类型</h3><pre><code>1.启动为none类型的网络    docker run --name c1 -it --rm --network none busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/none网络.png" alt="none网络"></p><pre><code>2.启动为bridge类型的网络:docker默认的网络模型    docker run --name c2 -it --rm --network bridge busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/bridge网络.png" alt="bridge网络"></p><pre><code>3.启动为joined类型的网络    启动的c3共享的是c2的Net,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的</code></pre><p><img src="/2018/10/18/Docker网络/共享桥网络.png" alt="共享桥网络"></p><p>因为共享桥只是共享了Net网络，UTS主机名，IPC，<br>此时IP地址和hostname都是一样，就可以通过127.0.0.1进行通信了<br>而mount(文件系统)，user,PID还是隔离的，所以在1上创建一个文件，2上是看不到的<br>这就是共享桥的工作机制</p><pre><code>4.启动为host宿主机类型的网络    docker run --name c4 -it --rm --network host busybox:latest    可以看出hostname,Net都是和宿主机是一样的    此时在容器内部启动httpd服务，其他主机是可以通过宿主机提供服务的</code></pre><p><img src="/2018/10/18/Docker网络/host网络.png" alt="host网络"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Network&quot;&gt;&lt;a href=&quot;#Docker-Network&quot; class=&quot;headerlink&quot; title=&quot;Docker Network&quot;&gt;&lt;/a&gt;Docker Network&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>k8s-volumes</title>
    <link href="https://www.liukui.tech/2018/08/10/k8s-volumes/"/>
    <id>https://www.liukui.tech/2018/08/10/k8s-volumes/</id>
    <published>2018-08-10T00:00:00.000Z</published>
    <updated>2019-02-28T12:34:40.561Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Kubernetes-Volumes"><a href="#Kubernetes-Volumes" class="headerlink" title="Kubernetes Volumes"></a>Kubernetes Volumes</h3><a id="more"></a><p><img src="/2018/08/10/k8s-volumes/k8s支持的存储卷类型.png" alt="k8s支持的存储卷类型"></p><pre><code>k8s上的volumes和docker中的volumes都是为了保存数据，但还是有区别的：    1.docker上因为是在单机上运行容器的，删除容器只要加载本地之前挂载的卷就可以了。    2.在k8s集群上，如果删除一个Pod,则这个pod的卷数据会保存在之前的这个node节点上了，而scheduler的调度是随机的，        有可能不会运行在之前的node上，那么之前保存的数据是无意义，不能利用的.    3.k8s是分布式集群，如果所有节点都挂载网络文件系统，那么数据就可以跨节点使用了.数据冗余实现方式：    1.存储设备做镜像，主备模式    2.分布式存储        不会对存储节点设备做冗余，而是在软件数据管理级别上对每个数据对象做冗余；        根据调度规则和冗余级别在当前集群的多个节点上都存放一份数据        还支持向外扩展如何挂载：    1.pod中是有个基础容器pause的,同一个pod中是共享pause容器的UTS(主机名),Network(网络名称空间),IPC(进程间通信，网络协议栈).    2.因为在节点上的pod是共享节点内核的，驱动也是在内核，所以节点本身需要先识别适配外部的各种存储系统.    3.节点是可以挂载多种外部存储系统的，所以pause挂载存储时，需要指明挂载的是哪种文件系统类型的存储并有相应的存储插件驱动.    4.同一Pod中的其他容器要想使用pause中的volumes,需要先通过volumes定义pause中定义卷，pod再通过volumeMounts复制并挂载pause定义的卷.CSI:    Container Storage interface，通过容器存储接口自定义存储卷    k8s中内置的存储卷类型        kubectl explain pod.spec.volumes定义存储卷    详见：kubectl explain pod.spec.volumes #如何定义挂载卷    要用存储卷需要现在pod.spec字段定义挂载卷类型和目录等信息挂载存储：    详见：        kubectl explain pod.spec.containers.volumeMounts #定义如何挂载卷        是使用挂载卷，需要在pod.spec.containers中挂载上去才能用spec中的详细定义说明：    spec:      volumes:          #先定义pause中的挂载卷      - name                    #必须定义存储卷名称,以便挂载时引用    下面根据存储类型不同定义方式也不同，按需修改        hostPath/nfs            #必须指定存储类型        - path                  #定义宿主机或者网络存储的路径          type                  #指定的目录/文件不存在时，应该怎么创建            DirectoryOrCreate   #不存在则创建            Directory           #目录必须事先存在            File                #文件可以挂载，但是必须事先存在            FileOrCreate        #文件不存在则自动创建            Socket              #必须是套接字文件，必须事先存在            CharDevice          #字符设备文件，必须事先存在            BlockDevice         #块设备文件，必须事先存在      containers:      - name:        image:        volumeMounts:   #复制并挂载pause中定义的卷        - name:                 #引用volumes中定义的1个或多个卷的卷名          mountPath             #挂载在容器的哪个路径(应用程序的文件路径)          readOnly：true|false  #挂载的路径是否只读，默认是读写权限          mountPropagation      #</code></pre><h3 id="本地存储：hostPath和local"><a href="#本地存储：hostPath和local" class="headerlink" title="本地存储：hostPath和local"></a>本地存储：hostPath和local</h3><pre><code>示例1：hostPath类型            #节点级的目录    vim myapp-hostpath-volumes.yaml         apiVersion: v1        kind: Pod        metadata:          name: myapp          namespace: volumes-test        spec:          containers:          - name: myapp            image: ikubernetes/myapp:v1            volumeMounts:            - name: website              mountPath: /usr/share/nginx/html              readOnly: true          volumes:          - name: website            hostPath:              path: /volumes/myapp              type: DirectoryOrCreate示例2：local类型    k8s1.10版本之后的类型，且是节点级的设备或者节点级目录</code></pre><h3 id="临时存储：emptyDir"><a href="#临时存储：emptyDir" class="headerlink" title="临时存储：emptyDir"></a>临时存储：emptyDir</h3><pre><code>临时存储作用：    1.为容器提供缓存存储空间        1.支持在节点的内存中切分一部分空间作为缓存来用    2.为没有持久存储必要的同一Pod中的两个容器共享数据    3.临时存储随着Pod的删除自动删除用法：    kubectl explain pod.spec.volumes.emptyDir        medium      #默认是disk磁盘，还可以是Memory内存        sizeLimit   #当medium是memory时，则必须进行限制简单示例：    volumes:    - name: ceshi#      emptyDir: {}  #如果medium和sizelimit都不定义，则为磁盘的任意空间      emptyDir:        medium: Memeory  #使用内存当空间        sizeLimit: 200Mi #使用内存空间为200M</code></pre><h3 id="网络存储：NFS"><a href="#网络存储：NFS" class="headerlink" title="网络存储：NFS"></a>网络存储：NFS</h3><pre><code>用法：    kubectl explain pods.spec.volumes.nfs        path：                #nfs的共享目录：如/vols/v1        readOnly：true|false  #是否只读，默认读写        server:               #nfs服务IP或者主机名缺点：    1.需要事先知道nfs服务器的地址    2.nfs导出的存储空间目录示例：    先准备nfs的共享目录:在10.10.0.29上测试    vim /etc/exports        /vols/v1 10.10.0.0/8(rw,no_root_squash)[root@master01 manifsets]# vim redis-nfs-volumes.yaml apiVersion: v1kind: Podmetadata:  name: redis  namespace: volumes-testspec:  nodeName: node03  containers:  - name: redis    image: redis:alpine    ports:    - name: redis      containerPort: 6379    volumeMounts:    - name: redisdata      mountPath: /data      readOnly: false  volumes:  - name: redisdata    nfs:      path: /vols/v1     #nfs导出的共享目录      server: 10.10.0.29 #nfs服务器的地址</code></pre><h3 id="持久卷申请存储：PV-amp-PVC"><a href="#持久卷申请存储：PV-amp-PVC" class="headerlink" title="持久卷申请存储：PV&amp;PVC"></a>持久卷申请存储：PV&amp;PVC</h3><pre><code>为了使用存储方便，为volumeMounts和后端存储设备加加了两个中间层在spec.volumes和存储间加了一个persistentVolume中间层把存储系统的所提供的存储能力抽象成k8s上的标准资源：persistentVolume持久存储卷persistentVolume：    1.PV和存储系统之间不是一一对应关系，而是与对应后端存储系统上可被单独访问的逻辑单元；    2.一个PV对应nfs的一个导出目录、ceph的一个image、云存储的一个云盘;    3.把后端存储的一个个逻辑单元映射为k8s上的一个个PV;    4.PV是集群级别的资源，不属于任何名称空间;PV的lifecycle:    provisioning: #PV的动态供给    bingding      #PV被绑定    using         #PV被使用    reclaiming    #PV被回收PV的供给方式：    动态供给：        1.存储系统上需要事先有逻辑存储单元，根据PVC的空间需求，在底层存储上选择适合空间需求的存储单元动态得创建为PV.        2.底层存储的逻辑单元不存在，只有存储空间            1.PVC向SC请求调用存储系统的API存储接口，临时创建需求空间大小的逻辑存储单元.            2.然后在SC内部把此存储单元创建为PV，与PVC进行binding.        3.动态供给是创建SC，而不是PV    静态供给：        存储系统上事先有存储，手动创建PV，再手动创建PVC与之绑定.PV的回收策略：reclaim    Pod删除时，PVC也可以删除，则引用的PV就处于回收状态，PV删除有二种策略        Delete:   #PVC删除时连带PV一起删除        Retain    #PV和PV上的数据都保留    备注：        1.如果是retain的，PV上仍然会有数据，但是不能被其他PVC所绑定了        2.可以手动删除PV，并手动删除存储上逻辑单元下的数据persistentVolumeClaim    1.PV属于集群级别资源，Pod属于名称空间级别资源，如果pod想使用PV就需要把PV注册到名称空间中;    2.Pod是通过PVC请求占用PV，来使用PV的，一旦名称空间A占用PV1，其他名称空间就不能再用PV1了;    3.PVC占用PV称为binding;为被PVC占用的PV称为avaiable(可用的PV);    4.Pod通过volumes.persistentVolumeClaim使用PVC，进而间接使用PVC所占用的PV的.    5.PVC是属于某个名称空间，可以由管理员手动创建的.PVC和存储系统的多路访问模型：    1.单路读写： RW0:ReadWriteOnce      iscsi    2.多路读写: RWX:ReadWriteMany    3.多路只读: ROX:ReadOnlyMany    作用：        PV是与后端存储的逻辑单元做映射的，存储系统是否支持多路读写应该体现在PV的定义上，才能避免PVC关联PV是否能多路读写出现存储故障.PV和PVC的删除保护：    当PVC和PV被Pod使用时，在k8s的1.10版本之后，即使PVC和PV被删除，此时也不会真的被删除，只有Pod被删除时，    PVC和PV才会被允许删除，这就是PVC和PV的删除保护.定义PV：    pv.spec和pod.spec.volumes是一样的，这样在创建pod时就不要再定义volumes了直接在containers.volumeMounts进行复制挂载就行了.    kubectl explain persistentVolume.spec    spec:      accessModes               #定义存储系统的访问模型的字符串列表            RW0/RWZ/ROX      capacity:                 #定义存储容量        storage   #单位是Ki Mi Gi等等      volumeMode:               #存储设备的访问接口(文件系统接口和块设备接口)            Fileystem|block      persistentVolumeReclaimPolicy  #定义PV的回收策略            Delete|Retain      storageClassName:           #定义使用哪种存储类      mountOptions:          #自定义挂载选项,下面这两项是默认的        - hard        - nfsvers=4.1      nfs/ceph:                  #定义PV关联的存储类型        下面选项根据不同存储系统定义不同的属性值        server:                   path:        定义PVC：    kubectl explain pvc.spec        accessModes          #访问权限必须要要绑定的PV权限的子集        volumeMode           #存储设备的访问接口(文件系统接口和块设备接口)        resources            #资源请求            requests:               #资源需求                storage:   #具体的需求存储空间大小            limit                  #资源上限        storageClassName     #存储类(PVC和PV必须在同一存储类中)        selector             #通过标签选择器去选PV                不定义选择器，则从所有PV中选择合适的PV        volumeName           #        dataSource           #</code></pre><h3 id="存储类SC：StorageClass"><a href="#存储类SC：StorageClass" class="headerlink" title="存储类SC：StorageClass"></a>存储类SC：StorageClass</h3><p><img src="/2018/08/10/k8s-volumes/SC.png" alt="SC"></p><pre><code>SC:Storageclass是k8s上的标准资源    SC是实现PVC动态创建存储单元PV的基础        1.SC上定义了如何连接外部存储API管理接口的方式        2.PVC只能向同一个SC中的PV请求绑定，不能跨SC.定义SC：    详见：kubectl explain sc        apiVersion        kind        metadata        parameters     #对接外部存储时的参数        reclaimPolicy  #在此SC中的PV回收策略        provisioner    #指明后端存储设备-----必须项        volumeBindingMode #后端存储支持的访问模型(RWX,ROX,RWO)        allowVolumeExpansion   #后端存储系统是否支持空间拉伸官方示例：    glusterfs类型的SC          apiVersion: storage.k8s.io/v1        kind: StorageClass        metadata:          name: slow        provisioner: kubernetes.io/glusterfs        parameters:          resturl: &quot;http://127.0.0.1:8081&quot;          clusterid: &quot;630372ccdc720a92c681fb928f27b53f&quot;          restauthenabled: &quot;true&quot;          restuser: &quot;admin&quot;          secretNamespace: &quot;default&quot;          secretName: &quot;heketi-secret&quot;          gidMin: &quot;40000&quot;          gidMax: &quot;50000&quot;          volumetype: &quot;replicate:3&quot;    ceph-rbd类型的SC:        kind: StorageClass        apiVersion: storage.k8s.io/v1        metadata:          name: fast        provisioner: kubernetes.io/rbd        parameters:          monitors: 10.16.153.105:6789          adminId: kube          adminSecretName: ceph-secret          adminSecretNamespace: kube-system          pool: kube          userId: kube          userSecretName: ceph-secret-user          userSecretNamespace: default          fsType: ext4          imageFormat: &quot;2&quot;          imageFeatures: &quot;layering&quot;</code></pre><h3 id="示例-创建静态供给PV和PVC"><a href="#示例-创建静态供给PV和PVC" class="headerlink" title="示例-创建静态供给PV和PVC"></a>示例-创建静态供给PV和PVC</h3><pre><code>以nfs为例定义一个PV：    [root@master01 manifsets]# vim pv-test.yaml    apiVersion: v1    kind: PersistentVolume    metadata:      name: pv-nfs-v1      labels:        storagefs: nfs    spec:    #  accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;]      accessModes:      - ReadWriteMany      - ReadWriteOnce      - ReadOnlyMany      capacity:        storage: 1Gi                #定义PV能提供多大存储空间      volumeMode: Filesystem      persistentVolumeReclaimPolicy: Retain     #定义PV回收策略      nfs:        path: /vols/v2        server: 10.10.0.29创建PVC：    apiVersion: v1    kind: PersistentVolumeClaim    metadata:      name: redis-pvc            #定义PVC的名称，以便Pod中引用      namespace: volumes-test    spec:      selector:   #定义关联到哪个PV，不指定则根据需求空间找相近空间大小的PV        matchLabels:          storagefs: nfs2      accessModes:      - ReadWriteMany      volumeMode: Filesystem      resources:        requests:          storage: 500Mi          #根据PV的存储空间定义PVC有多少空间创建Pod挂载PVC    apiVersion: v1    kind: Pod    metadata:      name: redis      namespace: volumes-test    spec:      nodeName: node03      containers:      - name: redis        image: redis:alpine        ports:        - name: redis          containerPort: 6379        volumeMounts:              #容器复制挂载volumes        - name: redisdata          mountPath: /data          readOnly: false      volumes:      - name: redisdata        persistentVolumeClaim:          claimName: redis-pvc           #挂载PVC测试：    [root@master01 ~]# kubectl get pv    NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                      STORAGECLASS   REASON   AGE    pv-nfs-v1   1Gi        RWO,ROX,RWX    Retain           Available                                                      8m14s    pv-nfs-v2   2Gi        RWO,ROX,RWX    Retain           Released    volumes-test/redis-pvc-1                           8m14s    pv-nfs-v3   3Gi        RWO,ROX,RWX    Retain           Bound       volumes-test/redis-pvc                             8m14s    [root@master01 ~]# kubectl get pvc -n volumes-test    NAME        STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE    redis-pvc   Bound    pv-nfs-v3   3Gi        RWO,ROX,RWX                   5m55s</code></pre><h3 id="特殊存储：ConfigMap和Secret"><a href="#特殊存储：ConfigMap和Secret" class="headerlink" title="特殊存储：ConfigMap和Secret"></a>特殊存储：ConfigMap和Secret</h3><p>都是为pod中的容器提供配置变更，扮演了k8s系统上一组控制器控制的pod的配置中心</p><pre><code>docker中的应用程序根据不同的环境配置不同的配置文件是依靠两种方式：    1.应用程序镜像是云原生或者支持通过enterpoint脚本可以传递环境变量来适应不同的场景使用.        缺点是：要修改传的值需要删除容器重新创建    2.先配置好不同的配置文件，通过挂载卷将文件传递到容器中.        缺点是：在本地映射的路径下修改了配置文件，容器是不会自动加载新的配置文件的.        k8s上面临相同的问题，为了解决修改配置文件或参数值能够使Pod自动重载配置信息，就将配置文件做成了k8s上的configMap资源.ConfigMap和Secret    1.Pod中的容器提供配置信息    2.配置中心：配置发生变更，测试完成后，通知方式(灰度)    区别：        configMap用来保存非敏感数据，Secret用来保存敏感数据的configMap和Secret是如何将配置传递至Pod中的？    先定义configMap和secret类型的资源，而这种资源时K/V键值对存在的        1.如果是环境变量，则定义这两种资源时，指定key和value        2.如果是配置文件，则文件名为Key,文件内容为值value创建pod时，只需要引用此资源的Key即可：    1.把configmap和secret资源的key映射给pod容器中的环境变量或者文件名    2.给环境变量传key的名称，通过k/v替换，获得v的值，如果想变更配置，只需要修改pod外部configmap中的value的值即可    ，pod会在一段时间内自动传递新的value值，进行配置更新.</code></pre><h3 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h3><pre><code>注意：    1.命令行创建configmap比资源清单更简单，但是配置清单更易维护.    2.通过资源清单配置的configMap中嵌套的是K/V数值还比较简单如果嵌套的是文件内容    的话，配置格式还是有些麻烦的.创建ConfigMap的两种方式    1.基于命令行的    kubectl create configmap -h        --from-literal  #手动指定K/V值，定义多个K/V值需要有多个--from-literal        --from-file     #从文件中读取创建    2.配置清单(比命令行麻烦，但是更易维护)        kubectl explain configmap            data:       #只有data字段，而没有spec字段两种引用configMap的方式: pod和configMap必须在同一名称空间    1.基于环境变量方式引用configMap (用于传递环境变量)    [root@master01 ~]#pod.spec.containers.env        env       #直接手动给变量        - name         #镜像中所能接收的变量名          value        #手动给值(一般用valuefrom)          valuefrom    #从其他位置引用值            configMapKeyRef     #引用一个configMap的键key                name                 #configMap的名称                key                  #configMap中的一个键名                optional        #被引用的configMap资源存在就可以，不存在则报错                    true|false  #默认是必须存在            secretKeyRef        #引用一个Secret的键key,用于敏感数据传输        envfrom   #从其他地方加载环境变量    缺点：        1.如果修改configmap中的环境变量的值，pod是不会更新环境变量的，除非删除重建pod，新的环境变量才会生效.    2.基于存储卷方式引用configMap (用于传递文件)        是把configmap资源当成存储卷来用的        kubectl explain pods.spec.volumes.configMap        volumes:        - name           #定义存储卷名称以便挂载时使用          configMap:            name         #configMap资源的名称            items        #要引用configmap中的那些键映射为本地的文件            - key          #configmap中的键名              mode         #映射的文件权限时多少，没定义则使用外部的defaultMode              path      #映射到pod中叫什么文件名(可以和key一样，也可以随意更改)                    必须是相对路径，而且是相对于挂载点而言            defaultMode  #映射到本地的文件权限为多少                        默认是0644读写权限，可以自己指定            optional     #引用的configMap资源或者引用的键不存在是否报错注意：    1.相对于环境变量方式引用configmap，存储卷方式的pod会根据configmap内容的变化而更新自己pod中的配置信息.    2.如果一个deploy控制的多个pod，并定义挂载了configMap类型的存储，如果修改configMap文件中的内容，这些pod一般会在一分钟之内都更新到最新configmap中新的值.    3.在deploy控制的后端pod众多的情况下，需要借助互联网上的配置中心组件实现pod的滚动更新或者金丝雀更新.    4.后端pod较少的情况下，可以用ansible或者puppet进行灰度更新.</code></pre><h4 id="创建并引用ConfigMap示例"><a href="#创建并引用ConfigMap示例" class="headerlink" title="创建并引用ConfigMap示例"></a>创建并引用ConfigMap示例</h4><pre><code>1.基于命令行的--from-literal创建    kubectl create configmap filebeat-cfg -n config-ns --from-literal=redis_host=&quot;filebeat.defalut.svc.cluster.local&quot; --from-literal=log_level=&quot;Info&quot;    创建名为filebeat-cfg的cm,并设定两个key和他的值2.基于命令行的--from-file创建    kubectl create cm nginx-cfg --from-file=nginx-./server1.conf --from-file=server-zhihui.conf=./nginx-server2.conf -n config-ns引用示例：    1.基于环境变量引用configMap        此处手动创建一个Pod，用来演示使用env属性值引用configMap：filebeat-cfg        apiVersion: v1        kind: Pod        metadata:          name: filebeat          namespace: config-ns    #pod和configMap必须在同一名称空间        spec:          containers:          - name: filebeat            image: ikubernetes/filebeat:5.6.5-alpine            env:            - name: REDIS_HOST              valueFrom:                configMapKeyRef:                  name: filebeat-cfg                  key: redis_host            - name: LOG_LEVEL              valueFrom:                configMapKeyRef:                  name: filebeat-cfg                  key: log_level    2.基于存储卷方式引用configMap        此处手动创建一个Pod，用来演示挂载configMap类型的存储        apiVersion: v1        kind: Pod        metadata:          name: nginx          namespace: config-ns    #pod和configMap必须在同一名称空间        spec:          containers:          - name: nginx            image: ikubernetes/myapp:v1            volumeMounts:            - name: config              mountPath: /etc/nginx/conf.d     #挂载的目录          volumes:          - name: config            configMap:              name: nginx-cfg                          items:              - key: nginx-server1.conf          #本地文件名                path: server1.conf      #映射到pod中的文件名              - key: server-zhihui.conf          #本地文件名                path: server2.conf      #映射到pod中的文件名测试：    通过手动修改configmap的值，查看pod中的文件是否也会发生改变    kubectl edit cm/nginx-cfg -n config-ns    测试看出基于存储卷方式引用configMap的pod的文件内容也会自动更新.</code></pre><h3 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h3><pre><code>1.Secret和configMap在功能上是一样的，只不过Secret是保存敏感数据的.2.Secret的数据是通过base64编码处理过的，不是真正意义上的加密，可以通过base64进行解码.3.Secret资源一般是通过命令行创建，而不是配置清单，因为如果通过配置清单配置时，需要手动将敏感数据(密码)进行base64编码，是很麻烦的，而命令行创建，会自动把敏感数据进行base64编码后保存到secret中.Secret的三种类型：    详见：kubectl create secret -h    1.docker-registry         私有镜像仓库需要登录才能够访问，docker-registry就是将账号密码进行加密认证，以便kubelet可以认证到镜像仓库服务器上.        认证方式有两种：            1.kubectl explain pod.spec.imagePullSecrets                name:可以定义多个列表用于认证                缺点：如果想使用不同的账户时，是不易修改Secret的            2.kubectl explain pod.spec.serviceAccountName                服务账号：可以使用pod之外的系统认证方式                即使修改账号只需要修改serviceAccountName就可以了.    2.generic        非证书的私有敏感信息都用generic类型,通用型    3.tls          #tls是专用于把ssl的tls中的x509格式的证书和私钥打包到一个secret中        而且不管原来的*.key和*.crt都被转成名为tls.key和tls.crt创建secret-generic资源:    1.命令行创建，类似于configmap        kubectl create secret [secret类型] secret名称 --from-literal=        --from-file=[key=]source    2.资源清单创建，要注意将密码进行base64编码后填到data资源中的key:value中        kubectl explain secret创建secret-tls资源:    1.命令行创建：        kubectl create secret tls NAME --cert=path/to/cert/file --key=path/to/key/file -n namespace        #需要先创建证书和私钥，再在创建secret-tls时引用即可.创建docker-registry资源:    1.命令行创建：        kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL          # 创建docker-registry类型的资源时，要指定连接的私有docker仓库的IP/域名，用户名，密码，注册时使用的账号引用secret的方式    1.通过env环境变量引用        kubectl explain pod.spec.containers.env            env:            - name                  #Pod镜像中的存在的变量名              valueFrom:                secretKeyRef:       #表示从secret类型资源引用键                  name:           #引用的Secret资源的名称                  key             #secret资源中的键名                  optional:   #secret资源或者引用的key不存在时报错                    true|false    2.通过存储卷引用Secret资源        kubectl explain pod.spec.volumes.secret        volumes:        - name:              #定义存储卷名称以便挂载时使用          secret:            secretName        #引用的secret资源名称              items:           #引用的多个键对象              - key            #引用的secret资源中的键名                mode:    #文件权限，私密数据建议600权限，不指定则使用外部默认的                path:    #映射到pod中叫什么文件名(可以和key一样，也可以随意更改)          defaultMode      #引用资源的默认权限，0644          optional注意：    1.tls类型的证书和私钥一般要用存储卷方式进行引用，不然value的值太长的.示例：    1.generic类型的secret引用示例        apiVersion: v1        kind: Pod        metadata:          name: mysql          namespace: config-ns        spec:          containers:          - name: mysql            image: mysql:5.6            env:            - name: MYSQL_ROOT_PASSWORD              valueFrom:                secretKeyRef:                  name: mysql-root-password                  key: passwd                  optional: true    2.tls类型secret引用示例        apiVersion: v1            kind: Pod            metadata:              name: nginx              namespace: config-ns            spec:              containers:              - name: nginx                image: nginx:1.14-alpine                volumeMounts:            - name: tls              mountPath: /etc/nginx/ssl          volumes:          - name: tls            secret:            - secretName: nginx-tls              items:              - key: nginx.crt              #原来的证书名                path: nginx-server.crt #映射到pod中的证书名              - key: nginx.key              #原来的私钥名                path: nginx-server.key  #映射到pod中的私钥名                    mode: 0600</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Kubernetes-Volumes&quot;&gt;&lt;a href=&quot;#Kubernetes-Volumes&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes Volumes&quot;&gt;&lt;/a&gt;Kubernetes Volumes&lt;/h3&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.liukui.tech/categories/kubernetes/"/>
    
    
      <category term="k8s" scheme="https://www.liukui.tech/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现四层和七层负载均衡</title>
    <link href="https://www.liukui.tech/2018/03/26/nginx%E5%AE%9E%E7%8E%B0%E5%9B%9B%E5%B1%82%E5%92%8C%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>https://www.liukui.tech/2018/03/26/nginx实现四层和七层负载均衡/</id>
    <published>2018-03-26T00:00:00.000Z</published>
    <updated>2019-03-09T08:23:52.909Z</updated>
    
    <content type="html"><![CDATA[<h3 id="nginx实现七层负载均衡"><a href="#nginx实现七层负载均衡" class="headerlink" title="nginx实现七层负载均衡"></a>nginx实现七层负载均衡</h3><a id="more"></a><p>–nginx实现七层调度的动静分离架构和调度算法分析<br><img src="/2018/03/26/nginx实现四层和七层负载均衡/nginx七层代理.png" alt="nginx实现七层调度的动静分离架构和调度算法分析"></p><pre><code>1.先通过upstream模块将多个后端服务器定义成server服务器组，再使用proxy_pass向后端    代理到这个server组2.upstream模块实现模块级的负载均衡算法调度3.upstream模块可以实现对后端服务器集群的健康状态监测，当有服务器down机了自动从这个    组中剔除，服务器恢复正常也会重新加入到这个组中，还支持所有服务器down机，然后由    一台sorry server提供服务4.session保持的三种方式：    session sticky:        1.基于客户端IP做hash将seesion保存在一台服务器上，如果是SNAT网络则IP是            一样的，seesion的颗粒度过于粗糙.        2.cookie机制即使是在通过SNAT网络中，不同的浏览器客户端也会被识别为不同            客户端，seesion的颗粒度精细的多.nginx可以识别应用层的cookie信息，            完全可以基于cookie信息做会话绑定的.但是只有nginx商业版支持.    seesion replication:        在同一集群中，session是共享的，但是对内存的消耗比较大        把自己的seesion复制给集群的其他主机    session server:        把用户访问的seesion保存单独的一台服务器，但是session的冗余实现比较麻烦        和cookie</code></pre><h3 id="ngx-http-upstream-module模块"><a href="#ngx-http-upstream-module模块" class="headerlink" title="ngx_http_upstream_module模块"></a>ngx_http_upstream_module模块</h3><pre><code>作用于server之外的http上下文1.upstream name {...}    定义后端服务器组；引入一个新的上下文；只能用于http{}上下文中；    默认调度算法是round robin，也就是加权轮询wrr；默认权重是12.server address [parameters];    定义服务器地址和相关的参数；        地址格式：            IP[:PORT]            HOSTNAME[:PORT]            unix:/PATH/TO/SOME_SOCK_FILE                server的修饰参数：            weight=number                权重，默认为1；            max_fails=number                失败尝试连接的最大次数；默认是1次            fail_timeout=time                设置服务器为不可用状态的超时时长；                失败的默认健康状态检测超时时长，默认10s    备注：max_fails和fail_timeout的乘机算一个周期，比如下面这个例子            backup                把服务器标记为“备用”状态；用于say sorry服务器            down                手动标记其为不可用；手动下线服务器，用于发布更新服务支持的算法：                3.least_conn;        1.短连接最好使用轮询wrr，长连接最好使用wlc;        2.如果不启用保持连接，即使改成least conn,效果也不是很明显.        3.最少连接调度算法，当server拥有不同的权重时其为wlc，当所有后端主机连接数            相同时，则使用wrr，适用于长连接    4.ip_hash;静态hash算法        对源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server；         1.ip_hash是对源地址进行hash，然后对后端服务器的权重之和取模，模是多少，            就把对应的结果映射到第几台服务器上，如果有服务器down了，那么权重            之和也会变，那么原来的hash结果大概率不能命中，所以ip_hash的调度算法存在很大的缺陷.        2.如果采用ip_hash算法，一旦后端有一台缓存服务器down了，由于是取模法，会造            成后台缓存服务器集群全部不能命中，并发请求数10W时，会把请求压力全部集            中到后端服务器上，造成系统崩溃        3.所以生产环境下一般不用ip_hash，而是采用一致性hash算法.    5.hash key [consistent];        consistent,虚拟主机的一致性hash算法；        此处可以对任意的key进行hash,所选取的key的值不同，hash的结果可以实现不同的            请求调度功能.而且此处的key可以是文本，变量或者二者的组合    例如：        hash $remote_addr consistent = ip_hash             即还是对源地址进行hash，但是效果确实一致性hash        hash $request_uri consistent             后端服务器是缓存服务器时，对静态内容的请求资源request_uri进行hash，            极有可能在缓存中命中,从而缓解了并加大了服务器的并发访问数.        hash $cookie_name consistent             对cookie的hash，首先服务端需要给客户端端强行插入cookie,就需要用到            sticky_cookie_insert,而这个功能只有在nginx plus版本中才能够使用    6.keepalive connections;    可使用长连接的连接数量；每worker与后端服务保持的最大空闲长连接数量；    为每个worker进程保留的空闲的长连接数量，可节约nginx端口，并减少连接管理的消耗    长连接的作用：    connections意思代理服务器与后端服务器之前先建立一定数量的始终不断开的长连接数量，当有用户请求时，这些长连接相当于一个一直处于连接状态管道，即一个连接上可以    发N个请求，既可以提升响应速度又可以减少代理服务器的套接字占用，避免了重复建立、断开、再建立的消耗资源的步骤,属于一种优化方式.示例：    upstream staticwebservs {        #   ip_hash;        #   hash $remote_addr consistent;            hash $request_uri consistent;            server 172.17.0.2 weight=2 fail_timeout=2 max_fails=2;            server 172.17.0.3 fail_timeout=2 max_fails=2;             keepalive 32；    }    server {    listen 8083;    location / {            proxy_pass http://staticwebservs/;    }这样就可以检测后端服务器集群健康状态的时长，在4s内检测到服务器有问题，就标记为down而且建立不断开的长连接总结：    1.对静态资源的请求，因为是短连接，要用weight round robin,加权轮询算法:wrr    2.对动态资源的请求，因为要有会话保持seesion sticky，所以要用ip_hash或者        hash $remote_addr consistent 算法，但是对IP hash的颗粒度较为粗糙，可以        对cookie进行hash,但是nginx社区版不支持.    3.如果网站有缓存层，要用hash $request_uri consistent一致性hash的绑定机制算        法,避免因为后端的一台缓存服务器down机，而影响全局的缓存层!</code></pre><h3 id="nginx实现四层负载均衡-调度-功能"><a href="#nginx实现四层负载均衡-调度-功能" class="headerlink" title="nginx实现四层负载均衡(调度)功能"></a>nginx实现四层负载均衡(调度)功能</h3><p><img src="/2018/03/26/nginx实现四层和七层负载均衡/" alt="nginx实现四层负载均衡原理"></p><pre><code>1.nginx实现四层调度，在nginx和后端服务器集群中建立一个四层的转发通道，对客户端发来    的请求报文不做任何解析，而是对客户端请求的地址和端口转发.2.如果后端有服务器集群，可以通过upstream模块实现不同算法的负载均衡调度效果.3.四层负载调度功能，作用于stream上下文，需要单独定义4.对数据存储等有状态的一类的应用一定不能做负载均衡，而是通过一种数据分发路由机制的    高级组件来完成，比如mysql的读写分离，mysql的分片框架等5.如上图示，因为只是实现四层调度，不存在什么动静分离资源，只是简单的四层调度功能</code></pre><h3 id="ngx-stream-core-module"><a href="#ngx-stream-core-module" class="headerlink" title="ngx_stream_core_module"></a>ngx_stream_core_module</h3><pre><code>The ngx_stream_core_module module is available since version 1.9.0. This module is not built by default, it should be enabled with the --with-stream configuration parameter.(1) listen address:port [ssl] [udp] [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];    监听的端口；        默认为tcp协议；        udp: 监听udp协议的端口；</code></pre><h3 id="ngx-stream-upstream-module"><a href="#ngx-stream-upstream-module" class="headerlink" title="ngx_stream_upstream_module"></a>ngx_stream_upstream_module</h3><pre><code>实现四层调度需要在upstream中定义，负载均衡调度的组    upstream name {...}，作用于stream上下文    server address [parmameters]        修饰符：            weight=number            max_conns=number            max_fails=number            fail_timeout=time            backup            down</code></pre><h3 id="ngx-stream-proxy-module"><a href="#ngx-stream-proxy-module" class="headerlink" title="ngx_stream_proxy_module"></a>ngx_stream_proxy_module</h3><pre><code>(1) proxy_pass address; (2) proxy_timeout timeout;    默认为10m;    (3) proxy_connect_timeout time;                设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s；示例：stream {    upstream sshsrvs {        server 192.168.10.130:22;        server 192.168.10.131:22;        hash $remote_addr consistent;    }    server {        listen 172.16.100.6:22202;        proxy_pass sshsrvs;         proxy_timeout 60s;        proxy_connect_timeout 10s;    }} </code></pre><h3 id="实现Nginx高并发的Linux入门级内核优化"><a href="#实现Nginx高并发的Linux入门级内核优化" class="headerlink" title="实现Nginx高并发的Linux入门级内核优化"></a>实现Nginx高并发的Linux入门级内核优化</h3><p>虽然nginx本身就支持高性能的并发访问，除了在配置文件级别的一些性能调优的必要参数之外<br>有时也需要在linux内核级进行简单的调优.</p><pre><code>优化说明：    优化是很复杂的一个问题，不是明显的设置缺点的话，不建议对nginx进行优化，因为不确定哪个是导致nginx明显短板的因素，有时也可以通过nginx的二级调度来实现高并发的    访问.    1.由于默认的Linux内核参数考虑的是最通用场景，这明显不符合用于支持高并发访问的        Web服务器的定义，所以需要修改Linux内核参数    2.Nginx可以拥有更高的性能,根据业务特点来进行调整，当Nginx作为静态web内容服务器、反向代理或者提供压缩服务器的服务器时，期内核参数的调整都是不同的，这里针对最通用的、使Nginx支持更多并发请求的TCP网络参数做简单的配置,修改/etc/sysctl.conf来更改内核参数    3.sysctl的用法：        sysctl命令：            默认配置文件：/etc/sysctl.conf            (1) 设置某参数            sysctl -w parameter=VALUE            (2) 通过读取配置文件设置参数            sysctl -p [/path/to/conf_file]            (3) 查看所有生效参数            sysctl -a        最好是写在/etc/sysctl.conf中，再通过sysctl -p /etc/sysctl.conf生效即可    比如：        进制本机被ping的设置            sysctl -w net.ipv4.icmp_echo_ignore_all=1fs.file-max = 999999：单个进程较大可以打开的文件描述符数量    ulimit -n 999999net.ipv4.tcp_tw_reuse = 1 (必调)    参数设置为1，表示允许将TIME_WAIT状态的socket重新用于新的TCP连接，因为在服务器端有大量的处于TCP中的TIME_WAIT状态的链接存在，能够复用这个socket对于繁忙的服务器来说意义重大.    echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse (sysctl)net.ipv4.tcp_keepalive_time = 600     当keepalive启动时，TCP发送keepalive消息的频度，默认为2小时，将其设置10分钟，可以更快的清理无效连接net.ipv4.tcp_fin_timeout = 30    当服务器主动关闭连接是，socket保持在FIN_WAIT2状态的较大时间net.ipv4.tcp_max_tw_buckets = 5000    默认是8000，建议调小    允许TIME_WAIT套接字数量的较大值，如果超过这个数字，TIME_WAIT套接字将立刻清除并打印警告信息，默认为8000，过多TIME_WAIT套接字会使web服务器变慢net.ipv4.ip_local_port_range = 1024 65000    TCP和UDP连接的本地端口取值范围net.ipv4.tcp_rmem = 1024 87380 12582912    TCP接收缓存的最小值、默认值、最大值net.ipv4.tcp_wmen = 1024 87380 12582912    TCP发送缓冲的最小值、默认值、最大值net.core.netdev_max_backlog = 8096    网卡接收队列最大值net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_sync_backlog = 8192    TCP三次握手建立阶段接收SYN请求队列的最大长度，默认为1024net.ipv4.tcp_tw_recyle = 1    启用timewait的快速回收</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;nginx实现七层负载均衡&quot;&gt;&lt;a href=&quot;#nginx实现七层负载均衡&quot; class=&quot;headerlink&quot; title=&quot;nginx实现七层负载均衡&quot;&gt;&lt;/a&gt;nginx实现七层负载均衡&lt;/h3&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>基于lnnmp搭建个人博客</title>
    <link href="https://www.liukui.tech/2018/03/22/%E5%9F%BA%E4%BA%8Elnnmp%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>https://www.liukui.tech/2018/03/22/基于lnnmp搭建个人博客/</id>
    <published>2018-03-22T00:00:00.000Z</published>
    <updated>2019-01-28T06:49:21.656Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基于openstack-docker搭建LNNMP"><a href="#基于openstack-docker搭建LNNMP" class="headerlink" title="基于openstack/docker搭建LNNMP"></a>基于openstack/docker搭建LNNMP</h3><a id="more"></a><p>-个人网站基本架构图<br><img src="/2018/03/22/基于lnnmp搭建个人博客/lnnmp架构图.png" alt="LNNMP架构图"></p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><pre><code>1.所有服务器时间要同步2.proxysql要和mysql所有服务器在同一个网段，不然会影响mysql的性能    nginx调度服务器：192.168.100.10    nginx+fpm-1服务器：192.168.100.3    nginx+fpm-2服务器：192.168.100.4    proxysql数据库读写分离：192.168.100.30    mysql_1服务器:192.168.100.9    mysql_2服务器:192.168.100.16    mysql_3服务器:192.168.100.17    NFS主：在mysql_2服务器上192.168.100.16    NFS备：在mysql_3服务器上192.168.100.17软件版本：     wordpress:         wordpress-5.0-zh_CN.zip (默认安装再升级)        wordpress-5.0.2-zh_CN.zip(用于测试升级版本)        依赖于php7.3版本之上和mysql5.6或者mariadb10.0版本之上    mysql:mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz(和一键安装脚本)    nginx:nginx-1.12.2.tar.gz    php-fpm:php-7.2.14.tar.gz    nfs: nfs-utils</code></pre><h3 id="1-搭建一主二从数据库"><a href="#1-搭建一主二从数据库" class="headerlink" title="1.搭建一主二从数据库"></a>1.搭建一主二从数据库</h3><pre><code>二进制安装mysql，此处用事先准备好的脚本进行安装(供参考)；</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql_1 ~]# vim mysql-install.sh   </span><br><span class="line">#!/bin/bash</span><br><span class="line">DIR=`pwd`</span><br><span class="line">NAME=&quot;mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz&quot;</span><br><span class="line">FULL_NAME=$&#123;DIR&#125;/$&#123;NAME&#125;</span><br><span class="line">DATA_DIR=&quot;/data/mysql&quot;</span><br><span class="line"></span><br><span class="line">yum install vim gcc gcc-c++ wget autoconf  net-tools lrzsz iotop lsof iotop bash-completion -y</span><br><span class="line">yum install curl policycoreutils openssh-server openssh-clients postfix -y</span><br><span class="line"></span><br><span class="line">if [ -f $&#123;FULL_NAME&#125; ];then</span><br><span class="line">    echo &quot;安装文件存在&quot;</span><br><span class="line">else</span><br><span class="line">    echo &quot;安装文件不存在&quot;</span><br><span class="line">    exit 3</span><br><span class="line">fi</span><br><span class="line">if [ -h /usr/local/mysql ];then</span><br><span class="line">    echo &quot;Mysql已经安装&quot;</span><br><span class="line">    exit 3</span><br><span class="line">else</span><br><span class="line">    tar xvf $&#123;FULL_NAME&#125;   -C /usr/local/src</span><br><span class="line">    ln -sv /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64  /usr/local/mysql</span><br><span class="line">    if id  mysql;then</span><br><span class="line">        echo &quot;mysql用户已经存在&quot;</span><br><span class="line">    fi</span><br><span class="line">        useradd  mysql  -s /sbin/nologin</span><br><span class="line">    if  id  mysql;then</span><br><span class="line">        chown  -R mysql.mysql  /usr/local/mysql/* -R</span><br><span class="line">        if [ ! -d  /data/mysql ];then</span><br><span class="line">            mkdir -pv /data/mysql &amp;&amp; chown -R mysql.mysql  /data   -R</span><br><span class="line">            /usr/local/mysql/scripts/mysql_install_db  --user=mysql --datadir=/data/mysql  --basedir=/usr/local/mysql/</span><br><span class="line">            cp  /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64/support-files/mysql.server /etc/init.d/mysqld</span><br><span class="line">            chmod a+x /etc/init.d/mysqld</span><br><span class="line">            cp $&#123;DIR&#125;/my.cnf   /etc/my.cnf</span><br><span class="line">            ln -sv /usr/local/mysql/bin/mysql  /usr/bin/mysql</span><br><span class="line">            chkconfig --add mysqld</span><br><span class="line">            service mysqld start</span><br><span class="line">        else</span><br><span class="line">            echo &quot;MySQL数据目录已经存在&quot;</span><br><span class="line">            exit 2</span><br><span class="line">        fi</span><br><span class="line">    fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><pre><code>主节点数据库：    1.启用二进制日志和跳过主机名称解析        server-id=1        log_bin=/data/mysql/master-log        skip_name_resolve = on    2.授权主从复制账号        grant replication slave on *.* to repluser@&apos;192.168.100.%&apos; identified by &apos;root123&apos;;    3.show master logs;        查看二进制日志位置，准备change master to信息    4.创建wordpress数据库        create database wordpress;    5.创建php连接mysql的用户和proxysql读写分离的用户         grant all on *.* to wordpress@&apos;192.168.100.%&apos; identified by &apos;wordpress123&apos;        此账号既作为php连接数据库的账号，又作为proxysql中读写分离的账户从节点数据库：    1.每个从节点都需要如下设置，设置只读，启用中继日志        server-id=2|3        read-only        relay_log=/data/mysql    2.设置change master to:        CHANGE MASTER TO          MASTER_HOST=&apos;192.168.100.9&apos;,          MASTER_USER=&apos;repluser&apos;,          MASTER_PASSWORD=&apos;root123&apos;,          MASTER_PORT=3306,          MASTER_LOG_FILE=&apos;master-log.000001&apos;,          MASTER_LOG_POS=4,          MASTER_CONNECT_RETRY=120;    3.start slave;启动MySQL主从    service mysqld start</code></pre><h3 id="安装配置proxysql读写分离器"><a href="#安装配置proxysql读写分离器" class="headerlink" title="安装配置proxysql读写分离器"></a>安装配置proxysql读写分离器</h3><pre><code>1.基于YUM仓库安装    vim /etc/yum.repos.d/proxysql.repo    [proxysql_repo]    name= ProxySQL YUM repository    baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever    gpgcheck=1    gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key2.安装启动    yum install proxysql &amp;&amp; systemctl start proxysql3.向ProxySQL中添加MySQL所有节点，以下操作不需要use main也可成功    MySQL &gt; select * from mysql_servers;    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.9&apos;,3306);    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.16&apos;,3306);    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)    values(10,&apos;192.168.100.17&apos;,3306);    MySQL &gt; load mysql servers to runtime;    MySQL &gt; save mysql servers to disk;4.配置监控账号：    a.在主节点上，创建监控账号        grant replication client on *.* to monitor@&apos;192.168.100.%&apos; identified by &apos;root123&apos;;        备注：replication client权限是负责监控的，和replication slave是不同的权限    b.Proxysql上配置监控        实际上是保存在global_variables表中，可以查看是否修改成功        MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;;        MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;;    c.使global_variables表生效        MySQL [mian]&gt; load mysql variables to runtime;        MySQL [mian]&gt; save mysql variables to disk;5.设置分组信息和读写规则    main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20    插入读写组的编号：        insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;);    生效和保存：        MySQL [monitor]&gt; load mysql servers to runtime;        MySQL [monitor]&gt; save mysql servers to disk;    再次查看        select hostgroup_id,hostname,port,status,weight from mysql_servers;6.创建用于测试读写分离的账号    主节点上创建访问用户：        用上面创建的wordpress账户即可    在ProxySQL配置，将用户wordpress添加到mysql_users表中：        insert into mysql_users(username,password,default_hostgroup)values(&apos;wordpress&apos;,&apos;wordpress123&apos;,10);    生效和保存：        MySQL [monitor]&gt; load mysql users to runtime;        MySQL [monitor]&gt; save mysql users to disk;7.配置路由规则，实现读写分离    与规则相关的表：mysql_qeury_rules    插入路由规则,实现读写分离的规则        insert into mysql_query_rules        (rule_id,active,match_digest,destination_hostgroup,apply)        VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1);    生效和保存到磁盘：        load mysql query rules to runtime;        save mysql query rules to disk;8.可以现在本机用wordpress测试是否可以实现读写分离    读：因为是读操作会在2和3上随机选择    mysql -wordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos;    写：事务是非select开头的，所以查询的都是1上    mysql -uwordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos;  </code></pre><h3 id="编译安装php"><a href="#编译安装php" class="headerlink" title="编译安装php"></a>编译安装php</h3><pre><code>1.准备环境依赖包：    yum -y install wget vim pcre pcre-devel openssl openssl-devel libicu-devel gcc gcc-c++     autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2     libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel ncurses ncurses-devel     curl curl-devel krb5-devel libidn libidn-devel openldap openldap-devel nss_ldap     jemalloc-devel cmake boost-devel bison automake libevent libevent-devel gd gd-devel     libtool* libmcrypt libmcrypt-devel mcrypt mhash libxslt libxslt-devel readline     readline-devel gmp gmp-devel libcurl libcurl-devel openjpeg-devel2.编译php:    ./configure  --prefix=/usr/local/php \    --with-config-file-path=/usr/local/php/etc \    --with-config-file-scan-dir=/usr/local/php/etc/conf.d \    --enable-fpm --with-fpm-user=www \    --with-fpm-group=www --with-pear \    --with-curl  --with-png-dir --with-freetype-dir \    --with-iconv   --with-mhash   --with-zlib --with-xmlrpc \    --with-xsl --with-openssl  --with-mysqli --with-pdo-mysql \    --disable-debug --enable-zip --enable-sockets \    --enable-soap   --enable-inline-optimization  --enable-xml \    --enable-ftp --enable-exif --enable-wddx \    --enable-bcmath --enable-calendar   --enable-shmop \    --enable-dba --enable-sysvsem --enable-sysvshm --enable-sysvmsg    make &amp;&amp; make install3.创建用户    useradd www4.准备配置文件    cd /usr/local/php/etc/    cp php-fpm.conf.default php-fpm.conf    cp php-fpm.d/www.conf.default php-fpm.d/www.conf    1.修改php-fpm.d/www.conf配置文件，使用dynamic动态模式，并设置最大，最少        空闲进程等信息    2.修改启动php的用户为www5.准备启动脚本    cp /root/ php-7.2.14/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm        chmod +x /etc/init.d/php-fpm        chkconfig --add php-fpm        chkconfig php-fpm on    也可以使用编译生成的        /usr/local/php/sbin/php-fpm直接启动</code></pre><h3 id="编译安装nginx实现web服务"><a href="#编译安装nginx实现web服务" class="headerlink" title="编译安装nginx实现web服务"></a>编译安装nginx实现web服务</h3><pre><code>因为在上文架构图中nginx既做web服务，又作为前端负载均衡服务器在这两台服务器上编译安装nginx,实现转发wordpress请求    nginx+fpm-1服务器：192.168.100.3    nginx+fpm-2服务器：192.168.100.41.解压并编译    tar xf nginx-1.12.2.tar.gz    cd nginx-1.12.2    ./configure \    --prefix=/usr/local/nginx  \    --with-pcre \    --with-http_stub_status_module \    --with-http_ssl_module    make &amp; make install2.修改配置文件将php资源请求调度到php-fpm    在server的上下文定义：因为nginx和php在同一台服务器，所以直接写127.0.0.1:9000    location / {    root   /data/nginx/wordpress;    index  index.php index.html index.htm;    }    location ~ \.php$ {        root          /data/nginx/wordpress;(可不写)        fastcgi_pass   127.0.0.1:9000;        fastcgi_index  index.php;        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;            include        fastcgi_params;    }    如果location中不写root，$document_root就要写/data/nginx/wordpress$fastcgi_script_name;3.启动服务    /usr/local/nginx/sbin/nginx </code></pre><h3 id="部署wordpress-5-0"><a href="#部署wordpress-5-0" class="headerlink" title="部署wordpress-5.0"></a>部署wordpress-5.0</h3><pre><code>在两台nginxweb服务器上安装同样的wordpress和配置1.创建存放wordpress目录    mkdir -pv /data/nginx/wordpress2.解压并将全部文件拷贝到/data/nginx/wordpress下    tar xf wordpress-5.0-zh_CN.zip    mv wordpress/* /data/nginx/wordpress/3.修改/data/nginx/wordpress的所有者和所属组    chown -R www.www /data/nginx/wordpress4.准备连接数据库的文件    cp wp-config-sample.php wp-config.php    vim wp-config.php        /** WordPress数据库的名称 */        define(&apos;DB_NAME&apos;, &apos;wordpress&apos;);        /** MySQL数据库用户名 */        define(&apos;DB_USER&apos;, &apos;wordpress&apos;);        /** MySQL数据库密码 */        define(&apos;DB_PASSWORD&apos;, &apos;wordpress123&apos;);        /** MySQL主机 */        define(&apos;DB_HOST&apos;, &apos;192.168.100.30:6033&apos;);    此处连接的mysql数据库主机是proxysql读写分离的IP和端口</code></pre><h3 id="通过NFS共享图片目录"><a href="#通过NFS共享图片目录" class="headerlink" title="通过NFS共享图片目录"></a>通过NFS共享图片目录</h3><pre><code>准备NFS主备后端存储：    1.这里nfs主备用mysql的两台从服务来实现        yum install nfs-utils -y        一定要安装nfs-utils，实际环境测试不安装utils，访问nfs的速度很慢        准备共享目录：            mkdir -pv /nfsdata/images        设置权限nfs共享目录权限            vim /etc/exports            /nfsdata/images *(rw,no_root_squash)    2.实现主备NFS的图片同步    rsync -avrlopg /nfsdata/images/* 192.168.100.17:/nfsdata/images/在nginx+pfp-fpm的两台服务器挂载nfs的共享目录    showmount -e 192.168.100.16    显示该主机上可以挂载的nfs目录1.挂载目录并设置开机自动挂载    因为wordpress的图片是保存在/data/nginx/wordpress/wp-content/uploads中的    所以要把该目录用nfs共享    1.vim /etc/fstab        192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads/ nfs defaults,_netdev 0 0        写在fstab文件中一定要加_netdev选项,刚开机没有IP地址时，即使挂载不上也可以启动    2.也可以写在/etc/rc.d/rc.local中，因为该文件是系统启动最后加载的文件，此时        已经获取到IP地址了，当然可以实现自动挂载,要设置执行权限        vim /etc/rc.d/rc.local        mount -t nfs 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads        chmod +x /etc/rc.d/rc.local3.备注：    NFS共享，为了避免IP地址的问题，最好要配置一个DNS服务器来主机名和IP地址    挂载的时候最好使用主机名取挂载，即使IP地址出问题了，也可以临时在DNS服务器上    修改主机名和IP地址的对应关系.</code></pre><h3 id="编译安装nginx实现负载均衡"><a href="#编译安装nginx实现负载均衡" class="headerlink" title="编译安装nginx实现负载均衡"></a>编译安装nginx实现负载均衡</h3><pre><code>nginx调度服务器：192.168.100.101.解压并编译    tar xf nginx-1.12.2.tar.gz    cd nginx-1.12.2    ./configure \    --prefix=/usr/local/nginx  \    --with-pcre \    --with-http_stub_status_module \    --with-http_ssl_module    make &amp; make install2.修改配置文件实现七层调度    在http上下文定义：vim /usr/local/nginx/conf/nginx.confupstream blogs {server 192.168.100.3:80 weight=1 max_fails=3 fail_timeout=100s;server 192.168.100.4:80 weight=1 max_fails=3 fail_timeout=100s;hash $remote_addr consistent; (做会话保持)}server {    listen 80;    server_name www.lkblog.net;    index index.html index.php;    location / {        proxy_pass http://blogs;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        add_header X-Via  $server_addr;        proxy_next_upstream http_502 http_504 error timeout invalid_header;    }}3.启动服务    /usr/local/nginx/sbin/nginx     /usr/local/nginx/sbin/nginx -t     /usr/local/nginx/sbin/nginx -s reload 配置完后重新加载</code></pre><h3 id="启动各服务，并测试读写"><a href="#启动各服务，并测试读写" class="headerlink" title="启动各服务，并测试读写"></a>启动各服务，并测试读写</h3><p>-<br><img src="/2018/03/22/基于lnnmp搭建个人博客/初次登录注册.png" alt="初次登录注册页面"><br>注册完后生成数据库各表<br><img src="/2018/03/22/基于lnnmp搭建个人博客/数据库表.png" alt="数据库"><br>-<br><img src="/2018/03/22/基于lnnmp搭建个人博客/上传图片测试.png" alt="上传图片测试"><br>上传图片测试，在nfs也是可以看到的，说明挂载是成功的</p><p>-浏览站点，因为是普通的http请求，用轮询的方式是没问题的<br><img src="/2018/03/22/基于lnnmp搭建个人博客/后台日志.png" alt="后台日志"></p><p>-对于登录页面，如果没有做会话保持是登不上去的，这也是为什么Nginx负载均衡器上做源地址hash的原因.<br><img src="/2018/03/22/基于lnnmp搭建个人博客/用户登录测试.png" alt="用户登录测试"></p><h3 id="升级wordpress版本"><a href="#升级wordpress版本" class="headerlink" title="升级wordpress版本"></a>升级wordpress版本</h3><pre><code>版本更新需要注意最好不要跨大版本进行更新，一般更新也是在大版本下进行小版本的更新以下以wordpress-5.0--&gt;wordpress-5.0.2步骤：    1.停止Nginx服务    2.备份元数据或删除    3.升级版本    4.启动服务简单的以脚本方式实现一台wordpress升级    vim updates.sh        ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx -s stop&quot;        ssh 192.168.100.4 &quot;rm -rf /data/nginx/wordpress/*&quot;        scp wordpress-5.0.2-zh_CN.zip 192.168.100.4:/data        ssh 192.168.100.4 &quot;unzip wordpress-5.0.2-zh_CN.zip -d /data/nginx/wordpress/&quot;        ssh 192.168.100.4 &quot;chown -R www.www /data/nginx/wordpress/&quot;        ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx&quot;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;基于openstack-docker搭建LNNMP&quot;&gt;&lt;a href=&quot;#基于openstack-docker搭建LNNMP&quot; class=&quot;headerlink&quot; title=&quot;基于openstack/docker搭建LNNMP&quot;&gt;&lt;/a&gt;基于openstack/docker搭建LNNMP&lt;/h3&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现反向代理功能</title>
    <link href="https://www.liukui.tech/2018/03/22/nginx%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%8A%9F%E8%83%BD/"/>
    <id>https://www.liukui.tech/2018/03/22/nginx实现反向代理功能/</id>
    <published>2018-03-22T00:00:00.000Z</published>
    <updated>2019-01-22T12:20:49.758Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Nginx实现反向代理服务器的配置"><a href="#Nginx实现反向代理服务器的配置" class="headerlink" title="Nginx实现反向代理服务器的配置"></a>Nginx实现反向代理服务器的配置</h3><a id="more"></a><p><img src="/2018/03/22/nginx实现反向代理功能/nginx代理原理.png" alt="nginx实现反向代理原理"></p><pre><code>nginx实现反代的工作原理：    1.代理服务器需要注册监听端口，用来接收用户请求，而监听端口是可以被复用的，且一个端口可以接收N路请求.    2.代理服务器本地没有资源，当请求报文送达时，由于代理服务本身就是个web服务器，所以能够充分理解请求报        文的MIME类型，URL等，差别只是本来是需要通过IO加载本地资源的，但是由于本地没有，则会向后端服务器        去取资源，但是此时请求报文已经被完完整整的拆开了，是不能把请求报文发往后端的    3.所以在nginx中是由一个模块扮演成类似客户端浏览器角色的，把自己模拟成客户端程序，封装一个新的http请求，    向后端服务器发起请求.    4.而后端服务器会把响应报文发送给代理服务器，代理服务器则又会拆掉网络层封装，传输成封装，应用层封装，        看到响应报文的body主体部分，把主体部分拿出来重新封装成一个响应报文发回给客户端》    5.只要是向后端请求必然会再占用一个端口    6.代理服务器要维持两路连接，而且是彼此隔离且独立的    7.那么向后端发送的请求报文要不要带客户端请求中所独有的私有的信息数据？        如果不传递，后端服务器是无法识别并相应的，必要时要把客户端的属性信息:请求        的url,用户认证信息等等重新封装到向后端发送的请求报文中，还是引用了客户端        发来的数据，而且代理服务器是可以修改请求报文的信息和响应报文中的信息    8.代理服务器可以操纵发往后端的请求和操纵响应给客户端的请求    9.这些也只有工作在应用层并且能识别应用层协议才可以实现的，如果再加一些访问控制        的功能，那么就可以做到四层防火墙做不到的访问控制能力，这也是代理服务器叫做        代理网关的原因，对于iptables和LVS是做不到的    10.面向客户端工作http/https协议，面向后端工作http,tcp,fastCGI,memcache，uwsgi(python的web框架)        等协议，那么这个能模拟客户端的模块就需要是多种专用模块1.nginx作为代理服务器来说，面向于客户端和服务端可以代理多种协议  代理服务器又叫代理网关，因为工作在应用层可以控制用户访问请求的资源，具有防护功能    面向客户端：        一般是http/https协议：通过http模块实现        mail:简单邮件传输协议等        stream:stream模块实现代理四层协议：tcp/udp            (nginx从1.9版本后可以实现四层负载均衡的)    代理后端服务器：        nginx内嵌了很多客户端模块来适配不同的后端协议：            http协议的服务器：ngx_http_proxy_modules模块            fpm服务器：ngx_http_fastcgi_module模块            memche服务器：</code></pre><h3 id="代理后端http协议的模块：专门代理后端是http协议的服务器集群-httpd和nginx"><a href="#代理后端http协议的模块：专门代理后端是http协议的服务器集群-httpd和nginx" class="headerlink" title="代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx)"></a>代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx)</h3><p><img src="/2018/03/22/nginx实现反向代理功能/" alt="nginx代理逻辑"></p><p>1.nginx作为代理服务器是，代理客户端和后端服务器，在数据报文是有两段的：<br>    1.客户端—&gt;代理服务器<br>    2.代理服务器作为客户端—&gt;后端的httpd/fpm/memche服务器<br>    而且代理服务器可以把客户端发来的数据报文进行修改重新封装发给后端服务器，<br>    后端服务器响应给代理服务器的报文也可以被代理服务器修改，再响应给客户端<br>    在设置中，可以通过不能功能体现出数据报文被如何修改的！</p><p>2.作为代理配置和nginx作为web服务器差不多，只不过要把root/alias缓存proxy_pass<br>    如果同时又root和proxy_pass，proxy_pass的优先级高</p><p>3.在location中将<em>.php或者</em>.jpg代理到不同的后端服务器上，可以实现资源请求的动静分离<br>    实现了在一台代理服务器上的资源路由.</p><h3 id="ngx-http-proxy-module模块："><a href="#ngx-http-proxy-module模块：" class="headerlink" title="ngx_http_proxy_module模块："></a>ngx_http_proxy_module模块：</h3><pre><code>1.proxy_pass URL     代理http协议的主要功能，是将客户端的请求代理至后端服务的路径上        Context: location, if in location, limit_except；        server {            ...            server_name HOSTNAME;            location / {                proxy http://hos[:port]; 优先级高于server的root                }            location /uri/ {                    proxy http://host/new_uri/;                }            location ~|~* /uri/ {                    proxy http://host;                }            ...        }          http://HOSTNAME/uri --&gt; http://host/uri     http://HOSTNAME/uri/ --&gt; http://host/new_uri/    http://HOSTNAME/uri/ --&gt; http://host/uri/；    路径映射，前后端的location和proxy_pass是映射关系,必要加/    如果location是正则表达式路径，proxy_pass的路径必须没有/和URI，因为是正则表达        式，无法判断路径</code></pre><p>-前后端路径映射<br><img src="/2018/03/22/nginx实现反向代理功能/前后端路径映射.png" alt="前后端路径映射"> </p><pre><code>2.proxy_set_header field value;    前面说过代理服务器可以修改客户端请求数据报文的信息发送给后端服务器，而对于后端    服务器来说看到的请求报文的源IP一直是代理服务器，但是可以通过修改参数是的后端    服务器看到的IP地址是真正的客户端地址而不是代理服务器！    设定发往后端主机的请求报文的请求首部的值；Context:http,server,location    设置代理服务器：        proxy_set_header X-Real-IP  $remote_addr;        或者        proxy_set_header X-Real-HOST  $host;将        或者        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    然后修改后端服务器的日志格式：        LogFormat &quot;%{X-Real-IP}i %l %u %t \&quot;%r\&quot; %&gt;s %b&quot;重启httpd服务即可    此时，后端服务器看到的IP就是客户端的IP了，所以可以设置任何真实的信息传递给后端服务器</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/proxy_set_header.png" alt="proxy_set_header"></p><h3 id="Nginx代理Web服务的Proxy缓存功能"><a href="#Nginx代理Web服务的Proxy缓存功能" class="headerlink" title="Nginx代理Web服务的Proxy缓存功能"></a>Nginx代理Web服务的Proxy缓存功能</h3><p>Nginx是一个高性能的web服务器，尤其在高并发和处理静态页面的时候有先天的优势；很大一部分得益于缓存的开启，缓存的实现逻辑</p><pre><code>* 此处是作用于http的上下文，因为每个代理模块都有缓存功能，但是不能混用* 要想使用proxy的缓存功能，必须先定义再引用* 定义缓存所以列表：对文件进行hash生成hash串，hash串是16进制数字，如果把hash串的前三位数字，按照数字放在对应的层级生成一个三级索引列表* 根据实际情况定义缓存层级，每多一次就是对磁盘IO的消耗，灵活定义缓存层级很有必要，比如一层以1个16进制数就是16个目录，2个16进制数就是2^8=256个目录，可以通过增加每次的级数，减小层数，对磁盘的IO消耗就降低了nginx的缓存功能： 不一定启用nginx缓存，可以使用varnish,或者CDN        只有真正需要启用时，才会启用nginx缓存    3.proxy_cache_path        nginx作为代理服务器是可以使用缓存功能的        定义缓存功能键也就是索引，是放在内存中的        定义可用于proxy功能的缓存；Context:http的上下文                   proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time];    4.proxy_cache ksys_zone的name | off;        指明要调用的缓存，或关闭缓存机制；Context:http, server, location    5.proxy_cache_key string;        虽然定义了缓存，还需要定义键，而这个键就是用户访问的地址;        1.为了避免后端有两台server_name有一模一样的URI,造成缓存索引出错，这里引入            了更多的差别数据，把整个访问路径都引入进来进行hash值缓存.        2.然而把整个url都引入进来，也会有问题，比如一个server有两个主机名，路径本            来就应该是相同的，如果引入了全路径则造成缓存不能命中了        3.所以如何定义这个&quot;键&quot;是根据不同场景使用的        默认值：proxy_cache_key $scheme$proxy_host$request_uri;                有时也可以定义为：$request_uri        所以根据不同使用场景proxy_cache_key的值需要修改    6.proxy_cache_valid [code ...] time;        通过定义不同的响应码来定义不同的缓存时长；(也可以统一为一个值)    7.proxy_cache_use_stale        当后端服务器有问题时，是否能够用过期的缓存资源响应客户端请求，默认是关闭的        proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...;    8.proxy_cache_methods GET | HEAD | POST ...;        设置客户端通过什么方法查询时，才调用缓存功能    9.proxy_hide_header field;        隐藏发送给客户端的响应报文的信息；f12中的header中看到的        默认nginx在响应报文中不传递后端服务器的首部字段Date, Server, X-Pad,         X-Accel-等，用于隐藏后端服务器特定的响应首部代理服务器请求后端服务器的几个超时时长：    10.proxy_connect_timeout time;        定义代理服务器后端服务器发请求的三次握手的连接时长        默认为60s，最长75s,不需要调    11.proxy_read_timeout time;        从后端接收响应报文的超时时长    12.proxy_send_timeout time;        连接建立后，向后端发送请求报文的超时时长示例：            先在http上下文中定义缓存；        proxy_cache_path /data/cache/nginx  levels=1:1:2；keys_zone webcache:10m max_size=2G;    再在server或者location中调用缓存和设置&quot;键&quot;以及过期时长；        location ~* \.(jpg|gif|jpeg)$ {           proxy_pass http://172.17.0.2;           proxy_cache webcache;           proxy_cache_key $request_uri;(这里根据不同场景定义)           proxy_cache_valid 200 302 301 1h;           proxy_cache_valid any 1m;           proxy_cache_methods GET HEAD;           proxy_cache_use_stale error timeout http_500 http_502 http_503;    这样就表示把缓存放在/data/cache/nginx中,最好是固态硬盘，磁盘IO越快，索引    查询的速度越快，定义了1:1:2三层路由索引，第一层16个目录，第二层16个子目录    第三次256个子目录</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/" alt="proxy_pass的缓存层级"></p><h3 id="ngx-http-headers-module模块：操纵响应报文首部"><a href="#ngx-http-headers-module模块：操纵响应报文首部" class="headerlink" title="ngx_http_headers_module模块：操纵响应报文首部"></a>ngx_http_headers_module模块：操纵响应报文首部</h3><pre><code>区别于proxy_set_header：    是代理服务器把客户端请求报文中的某些信息通过修改代理服务器请求报文首部的方式发送给后端服务器headers：    代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值；达到隐藏        某些信息不发给客户端。    1.add_header name value [always];        添加自定义首部；        add_header X-Via  $server_addr;        或者        add_header X-Accel $server_name;     发送给客户端的响应报文时，显示真正的后端服务器IP或者主机名    2.expires [modified] time;        expires epoch | max | off;        响应缓存的缓存时长        用于定义Expire或Cache-Control首部的值；</code></pre><h3 id="Nginx代理后端fastCGI协议"><a href="#Nginx代理后端fastCGI协议" class="headerlink" title="Nginx代理后端fastCGI协议"></a>Nginx代理后端fastCGI协议</h3><p><img src="/2018/03/22/nginx实现反向代理功能/LNMP的多种架构.png" alt="LA/NMP的几种架构"></p><pre><code>1.fpm其实就是一种类似于httpd的MPM模型中的prefork模型    启用一个fpm主进程，生成n个子进程，由子进程内部的php解释器负责处理并发的多路    请求，再将在本地运行完的php页面程序处理结果响应给请求的调用者2.fastcgi其实就是简装版的http协议，后端对应的php的fpm就是fastcgi协议的服务器后端    的解析fastcgi协议，而且还能够让fpm的子进程加载磁盘上的php程序文件在php解释器    中运行执行出结果3.Php并不支持编译成nginx的模块，那么Nginx只能调fastcgi模块与后端的fpm(php)服务器    进行通信，实现LNMP的架构4.真正与mysql等数据库通信的是php程序代码，即php到mysql的驱动模块，而不是php解释器5.如上图，因为fpm对进程的管理能力较弱，可以用nginx与全端调度器去连接，而且nginx可    以根据fastcgi处理请求的并发数，在nginx处限制向后端的请求连接数，nginx可以实现    中间件进行流量控制的效果.6.php管理自己子进程的方式有两种，static和dynamic动态和静态管理方式7.实现fpm的负载均衡调度，也是需要</code></pre><h3 id="ngx-http-fastcgi-module模块："><a href="#ngx-http-fastcgi-module模块：" class="headerlink" title="ngx_http_fastcgi_module模块："></a>ngx_http_fastcgi_module模块：</h3><pre><code>1.fastcgi_pass address;    address为fastcgi server的地址； location, if in location；    如：fastcgi_pass localhost:9000;    http://www.ilinux.io/admin/index.php --&gt; /admin/index.php (uri)        /data/application/admin/index.php2.fastcgi_index name;    fastcgi默认的主页资源; web的是index.html,php应该为index.php    如：fastcgi_index index.php3.fastcgi_param parameter value [if_not_empty];    1.由于动态站点在处理请求时，需要取得客户端在连接请求报文中的很多信息(IP,请求        方法,flag,param等)，所以nginx代理必须把保存在变量中与客户端连接状态的        数据，原样的传递给后端的fpm-server或fastcgi.    2.但是保存在nginx的变量名格式和fastcgi的变量名表示格式是不一样的，nginx的        是$+全小写的变量名，fpm是全大写的变量名    3.安装nginx默认就带有/etc/nginx/fastcgi_params,这个文件记录了需要向后端        fpm传递的所有变量.    4.除了传递变量，还需要将请求的uri与后端fpm服务器的路径建立映射关系，即定义        fpm上存放请求页面资源的真正路径.    配置示例：        比如先起一个fpm的容器：并且将动态资源保存在php容器的/data目录下        docker run --name php1 -d -v /data/php1:/data php:7-fpm-alpine    在nginx代理上如下设置：        location ~* \.php$ {            fastcgi_pass   172.17.0.4:9000;            fastcgi_index  index.php;            fastcgi_param  SCRIPT_FILENAME  /data$fastcgi_script_name;            include        fastcgi_params;        }</code></pre><h3 id="fpm的状态监控"><a href="#fpm的状态监控" class="headerlink" title="fpm的状态监控"></a>fpm的状态监控</h3><pre><code>4.php的状态监控    1.fpm的进程有static和dynamic两种管理方式，而且为了监控fpm是否正常工作，fpm的        配置文件中内嵌了/pm_status和/ping两个url来监控，status用来输出内嵌信息的        ，而默认是通过fastcgi协议显示的，不能直接看到状态信息，所以可以通过http协        议进行反代来检测fpm的工作状态.    2.可以通过显示监控状态的值，再通过ab,JMeter等工具进行压力测试，调整fpm的实际        场景下的并发访问量配置示例：通过/pm_status和/ping来获取fpm server状态信息；    location ~* ^/(status|ping)$ {            fastcgi_pass 172.17.0.2:9000;            fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;            include fastcgi_params;         }  测试： 如下图可以通过http://192.168.34.107:8082/status?xml&amp;full    或者html、json格式输出并显示出来，而且还可以通过接口调用加入到zabbix监控中</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/fpm状态监控.png" alt="fpm监控状态"> </p><h3 id="fastcgi的压力测试和缓存功能"><a href="#fastcgi的压力测试和缓存功能" class="headerlink" title="fastcgi的压力测试和缓存功能"></a>fastcgi的压力测试和缓存功能</h3><pre><code>a.fastcgi的动态资源缓存意义更大，因为php不用每次都执行代码了b.要使用缓存就需要先定义缓存；c.因为后端动态资源服务器是有用户认证和用户支付的资源的，为了信息安全对动态资源的缓    存一定不要缓存包含用户信息的资源定义缓存：和proxy的缓存是不能兼容的，需要单独定义(在server外,http的上下文定义)4.fastcgi_cache_path     path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number]     [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time]     [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time];    定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义；    levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE        leves=1:2:2    keys_zone=name:size        k/v映射的内存空间的名称及大小    inactive=time        非活动时长    max_size=size        磁盘上用于缓存数据的缓存空间上限调用缓存：        5.fastcgi_cache keys_zone的名称 | off;        调用指定的缓存空间来缓存数据；http, server, location        无定义默认使用的键，需要手动指定    6.fastcgi_cache_key string;        定义用作缓存项的key的字符串；              7.fastcgi_cache_methods GET | HEAD | POST ...;        为哪些请求方法使用缓存；               8.fastcgi_cache_min_uses number;        缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项；               9.fastcgi_cache_valid [code ...] time;        不同的响应码各自的缓存时长；    10.fastcgi_keep_conn on | off;        默认情况下，fastCGI响应一个请求后会立刻断开，如果是on状态会保持长连接fastcgi缓存定义示例：            http {        fastcgi_cache_path /data/cache/fcgi levels=1:2 keys_zone=fcgicache:10m max_size=2G;        server {            ...            location ~* \.php$ {            fastcgi_pass   172.17.0.4:9000;            fastcgi_index  index.php;            fastcgi_param  SCRIPT_FILENAME  /data$fastcgi_script_name;            include        fastcgi_params;            fastcgi_cache fcgicache;            fastcgi_cache_key $request_uri;            fastcgi_cache_valid 200 302 301 1h;            fastcgi_cache_valid any 1m;            fastcgi_cache_methods GET HEAD;        }缓存性能测试：                       ab -n 1000 -c 50 http://192.168.34.107:8082/index.php    在缓存前和缓存后通过模拟50路并发请求测试响应时间</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Nginx实现反向代理服务器的配置&quot;&gt;&lt;a href=&quot;#Nginx实现反向代理服务器的配置&quot; class=&quot;headerlink&quot; title=&quot;Nginx实现反向代理服务器的配置&quot;&gt;&lt;/a&gt;Nginx实现反向代理服务器的配置&lt;/h3&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现web服务配置</title>
    <link href="https://www.liukui.tech/2018/03/20/nginx%E5%AE%9E%E7%8E%B0web%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.liukui.tech/2018/03/20/nginx实现web服务配置/</id>
    <published>2018-03-20T00:00:00.000Z</published>
    <updated>2019-01-26T06:28:48.699Z</updated>
    
    <content type="html"><![CDATA[<h3 id="nginx安装和配置文件"><a href="#nginx安装和配置文件" class="headerlink" title="nginx安装和配置文件"></a>nginx安装和配置文件</h3><p><a href="http://nginx.org/en/docs/" target="_blank" rel="noopener">Nginx下载安装和模块使用说明手册</a><br><a id="more"></a></p><pre><code>nginx安装：    源码编译,二进制安装，yum安装，要注意使用次版本为偶数的版本        nginx所说的高度模块化是指静态模块，如果编译安装了很多模块，启动时不管在配        置文件是否使用该模块，默认都是加载的，不过在Nginx的新版本中少量的动态模块        是可以按需加载的        而httpd是可以通过modprobe安装加载模块的配置文件的组成部分：    主配置文件：        /etc/nginx/nginx.conf 还包括 conf.d/*.conf和default.d/*.conf            对于同以功能的配置最好放到一个*.conf中，方便管理        /usr/lib/systemd/system/nginx.service   Unit file文件        /usr/sbin/nginx                         主程序文件        /usr/share/nginx/html/404.html        /usr/share/nginx/html/50x.html        /usr/share/nginx/html/index.html        页面文件            fastcgi， uwsgi，scgi等协议相关的配置文件            mime.types：支持的mime类型   启动和配置：    yum install nginx -y （编译时按需加载模块即可）    systemctl start nginx / nginx备注：    在生产环境下只要是修改nginx相关的配置文件,一定要nginx -t先进行测试    再nginx -s reload使配置文件生效配置：    主配置文件的配置指令：    指定生效的范围，三个上下文中        directive value [value2 ...];        注意：            (1) 指令必须以分号结尾；            (2) 支持使用配置变量；                内建变量：由Nginx模块引入，可直接引用；                自定义变量：由用户使用set命令定义；                    set variable_name value;                    引用变量：$variable_name主配置文件结构：        main block：主配置段，也即全局配置段；都是顶格写的        event {                ...            }：事件驱动相关的配置；        http {            server {}                root                proxy_pass            server {}            ...        }：http/https 协议相关的配置段；        mail {            ...        }        stream {            ...        }主配置段都不管是web服务、mail服务还是四层代理是都需要配置的，而且这三个功能一般是    不会一起使用的，至少http和mail功能是不一起使用的</code></pre><h3 id="Nginx的全局配置和优化必调参数项"><a href="#Nginx的全局配置和优化必调参数项" class="headerlink" title="Nginx的全局配置和优化必调参数项"></a>Nginx的全局配置和优化必调参数项</h3><pre><code>配置指令：    main配置段常见的配置指令：全局配置        分类：            正常运行必备的配置            优化性能相关的配置            用于调试及定位问题相关的配置            事件驱动相关的配置        正常运行必备的配置：    1、user，group,是默认运行nginx的用户和组，按需修改    2、pid /PATH/TO/PID_FILE;        指定存储nginx主进程进程号码的文件路径；    3、include file | mask;        指明包含进来的其它配置文件片断；    4、load_module file;        指明要装载的动态模块；性能优化相关的配置：    1、worker_processes number | auto;        worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数；        auto：当前主机物理CPU核心数；    2、worker_cpu_affinity cpumask ...;        worker_cpu_affinity auto [cpumask];        nginx进程的CPU亲缘性解释；        1.因为CPU有三级缓存，一级和二级是每个CPU所独有的，只有三级缓存是共享的；        2.将worker进程与cpu绑定，这个进程会在cpu本地缓存很多数据和状态信息        3.如果把这个进程调到其他cpu上，那么之前的缓存就失效了，从而影响了性能，而cpu的绑定则起到刚好的负载效果和性能        CPU MASK：            00000000：            0000 0001：0号CPU            0000 0010：1号CPU            0000 0100：2号CPU            0000 1000：3号CPU            ... ...            0000 0111：表示0和1号和2号CPU；    3、worker_priority number;        指定worker进程的nice值，设定worker进程优先级；[-20,19]                4、worker_rlimit_nofile number;        worker进程所能够打开的文件数量上限；        对于高并发的服务器来说至关重要，每一个连接都需要打开一个套接字，每一个套接        字的维持都需要一个文件描述符，默认情况下linux限制每个用户最多同时打开1024        个文件，所以并发数量很高时，并发数量受限于文件数量，因此对于高并发服务器来        说都需要修改ulimit数量(ulmit -a/-n number)事件驱动相关的配置:    events {        ...    }    1.worker_connections number;        事件驱动决定了单个worker进程所能够打开的最大并发连接数数量；        所以nginx最大并发连接上限=            [worker_processes] * [worker_connections]           在要求高并发的服务器上这两个是必调参数    2.use method;        指明并发连接请求的处理方法；            use epoll；是事件驱动模型得以运行的根本                       3.accept_mutex on | off;是否打开mutex互斥锁        处理新的连接请求的方法；            on意味着由各worker轮流处理新请求，默认为on            Off意味着每个新请求的到达都会通知所有的worker进程；会造成进程抢夺请求的情况调试、定位问题：    1、daemon on|off;            是否以守护进程方式运行Nignx；默认为on                2、master_process on|off;        是否以master/worker模型运行nginx；默认为on；        调试时，把只有主进程处理请求和以前台运行来查找错误原因              3、error_log file [level];        默认级别</code></pre><h3 id="Nginx实现web服务的全局配置和主要模块"><a href="#Nginx实现web服务的全局配置和主要模块" class="headerlink" title="Nginx实现web服务的全局配置和主要模块"></a>Nginx实现web服务的全局配置和主要模块</h3><pre><code>1.Nginx无论是作为web服务器或者是web服务器的代理服务器，所有配置都在http的上下文2.location和directory的区别    1.httpd和nginx作为web服务器都可以对用户访问的资源进行限制    2.&lt;Directory &quot;/var/www/html/images/&quot;&gt; 也可以写成        &lt;Location &quot;/images/&quot;&gt;</code></pre><h4 id="http协议的全局配置"><a href="#http协议的全局配置" class="headerlink" title="http协议的全局配置"></a>http协议的全局配置</h4><p>匹配检查顺序：server_name和Port–&gt;location–&gt;if in location–&gt;匹配路径(root和alias)</p><h4 id="ngx-http-core-module-Nginx的核心模块"><a href="#ngx-http-core-module-Nginx的核心模块" class="headerlink" title="ngx_http_core_module:Nginx的核心模块"></a>ngx_http_core_module:Nginx的核心模块</h4><p>Nginx不管作为什么功能，都要使用core核心模块</p><pre><code>http协议上下文的相关配置：    http {        ... ...  是http的全局配置，共享给多个server使用        server {            ...            listen            server_name            root/proxy_pass                 (root是作为web服务器的，proxy_pass是作为代理服务器使用的)            location [OPERATOR] /uri/ (类似于httpd的directory）                ...            }        }        server {            ...        }    }与套接字相关的配置：    1、server { ... }        配置一个虚拟主机；            server {            listen address[:PORT]|PORT;            server_name SERVER_NAME;            root /PATH/TO/DOCUMENT_ROOT;                                    }          server只能出现在http的上下文中，而且不能嵌套server    2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE          listen address[:port] [default_server] [ssl] [http2 | spdy]  [backlog=number] [rcvbuf=size] [sndbuf=size]        特殊设置：前两个尤为重要            default_server：设定为默认虚拟主机；                如httpd基于主机名配置的多个虚拟主机，访问时是由上而下匹配的            ssl：强制只能通过ssl连接提供服务；            backlog=number：后援队列长度；            rcvbuf=size：接收缓冲区大小；            sndbuf=size：发送缓冲区大小；(默认值足以满足需求)    3、server_name name ...;        必然要使用通配符来设置虚拟主机名和设置优先级        1.支持*通配任意长度的任意字符；server_name *.baidu.com  www.baidu.*        2.支持~起始的字符做正则表达式模式匹配；server_name ~^www\d+\.baidu\.com$   (\d匹配单个数字)        匹配机制优先级：            (1) 首先是字符串精确匹配;            (2) 左侧*通配符；            (3) 右侧*通配符；            (4) 正则表达式；            (并发访问多时，不建议使用正则表达式匹配主机名，对服务器性能有很大消耗)    4、tcp_nodelay on | off;        在keepalived模式下的连接是否启用TCP_NODELAY选项        当为off时，延迟发送，合并多个请求后再发送        默认On时，不延迟发送        可用于：http, server, location    5.tcp_nopush on|off;        在sendfile模式下，是否启用TCP_CORK选项；    5.sendfile on | off;        是否启用sendfile功能；和定义路径相关的配置：    6.root path;         设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径；        root可以作用在http, server, location, if in location上下文中，        如果多有多层级的root，则精确到最内层的root生效    7.location [ = | ^~ | ~ | ~* ] uri { ... }                    在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置；        用户请求server_name--&gt;server--&gt;Location--&gt;if in Location                    会根据正则表达式匹配的优先级匹配到一个最佳的路径    修饰符号： 修饰符匹配优先级：=, ^~, ~/~*，不带符号；        1.=：对URI做精确匹配；        2.^~：对URI的左半部分做匹配检查，不区分字符大小写；            左半部分是指scheme中不包含path和它之后的部分            如https://www.lk.tech/images/1.jpg的左半部分是https://www.lk.tech        3.~：对URI做正则表达式模式匹配，区分字符大小写；        4.~*：对URI做正则表达式模式匹配，不区分字符大小写；        5.不带符号：以URI为前缀的所有uri；通配性最高级location /                还可以在location中定义if这种三级路由选择        root /vhosts/www/htdocs/        http://www.lk.tech/index.html --&gt; /vhosts/www/htdocs/index.html         server {            root  /vhosts/www/htdocs/            location /admin/ {                root /webapps/app1/data/            }        }</code></pre><p>–官方示例<br><img src="/2018/03/20/nginx实现web服务配置/正则表达式优先级.png" alt="nginx的正则表达式优先级"></p><pre><code>    8.alias path;        定义路径别名，文档映射的另一种机制；仅能用于location上下文；        注意：location中使用root指令和alias指令的意义不同；            (a) root，给定的路径对应于location中的/uri/左侧的/；            (b) alias，给定的路径对应于location中的/uri/右侧的/；            如：                location /images/                 alias &quot;/data/www/&quot;;             alias定义的意思是即 /images/* = /data/www/*                location /images/ {                alias &quot;/data/www/&quot;;             root定义的意思就是访问 /data/www/images/*    9、设置默认主页：index file ...;        默认资源；http, server, location；    10、error_page code ... [=[response]] uri;       例如：error_page 404 /404.html;            location = /404.html {                root &quot;/www/error_pages&quot;;            }                           11、try_files file ... uri;        定义客户端请求的相关配置定义客户端请求的相关配置    12、keepalive_timeout timeout [header_timeout];        设定保持连接的超时时长，0表示禁止长连接；默认为75s；    13、keepalive_requests number;        在一次长连接上所允许请求的资源的最大数量，默认为100;     14、keepalive_disable none | browser ...;        对哪种浏览器禁用长连接；    15、send_timeout time;        向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长；    16、client_body_buffer_size size;        用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置；    17、client_body_temp_path path [level1 [level2 [level3]]];        设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量；            16进制的数字；            client_body_temp_path   /var/tmp/client_body  1 2 2                1：表示用一位16进制数字表示一级子目录；0-f                2：表示用2位16进程数字表示二级子目录：00-ff                2：表示用2位16进程数字表示三级子目录：00-ff对客户端进行限制的相关配置：    18、limit_rate rate;        限制响应给客户端的传输速率，单位是bytes/second，0表示无限制；    19、limit_except method ... { ... }        限制对指定的请求方法之外的其它方法的使用客户端；        limit_except GET {            allow 192.168.1.0/24;            deny  all;        } 文件操作优化的配置</code></pre><h4 id="访问控制和认证的两个模块"><a href="#访问控制和认证的两个模块" class="headerlink" title="访问控制和认证的两个模块"></a>访问控制和认证的两个模块</h4><pre><code>ngx_http_access_module模块：实现基于ip的访问控制功能，比httpd的控制更简单    1.allow address | CIDR | unix: | all;    2.deny address | CIDR | unix: | all;        http, server, location, limit_exceptngx_http_auth_basic_module模块    实现基于用户的访问控制，使用basic机制进行用户认证；    1.auth_basic string | off;    2.auth_basic_user_file file;    需要先生成账号密码，而且htpasswd命令由httpd-tools所提供；        htpasswd -c -m /data/.nginxpasswd tom        htpasswd -b -m /data/.nginxpasswd haha haha123        如：            location /admin/ {            auth_basic &quot;需要提供用户密码&quot;;(提示信息)            auth_basic_user_file /etc/nginx/.ngxpasswd;            }</code></pre><h4 id="ngx-http-stub-status-module模块：状态监控"><a href="#ngx-http-stub-status-module模块：状态监控" class="headerlink" title="ngx_http_stub_status_module模块：状态监控"></a>ngx_http_stub_status_module模块：状态监控</h4><pre><code>一般和监控系统一起用，可以在编译安装nginx时加上这个选项可以通过脚本函数监控这七个数值，纳入到zabbix中进行图形化监控为了不影响其他location，一般定义专用的location来监控nginx状态，放在server内即可用于输出nginx的基本状态信息；    Active connections: 291         当前的活动连接    server accepts handled requests  连接数，接收并处理的，，        16630948 16630948 31070465     Reading: 6 Writing: 179 Waiting: 106        中间三个是统计数据，其他四个是当前数据；        Active connections: 正在处理活动状态的连接数；        accepts：已经接受的客户端请求的总数；(tcp建立的连接数)        handled：已经处理完成的客户端请求的总数；(客户端发送，nginx处理过的)        requests：客户端发来的总的请求数；(建立tcp连接并发送的请求数)        Reading：处于读取客户端请求报文首部的连接的连接数；(接收报文)        Writing：处于向客户端发送响应报文过程中的连接数；(nginx发送报文)        Waiting：处于等待客户端发出请求的空闲连接数； (已经读取未发送的)        用于监控nginx的连接数脚本    1.stub_status;        配置示例：            location = /status {                stub_status;            }</code></pre><h4 id="ngx-http-log-module模块：日志分析展示"><a href="#ngx-http-log-module模块：日志分析展示" class="headerlink" title="ngx_http_log_module模块：日志分析展示"></a>ngx_http_log_module模块：日志分析展示</h4><p><a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#var_remote_addr" target="_blank" rel="noopener">nginx官方日志变量说明</a></p><pre><code>1.log_format name string ...;    string可以使用nginx核心模块及其它模块内嵌的变量；    日志格式：        $remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;              &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;              &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;        http_x_forward_for 表示被代理服务器的日志记录的访问的IP地址是代理服务器，为了在后端服务器上记录真实的客户端，需要启用这一项    实现：1.为nginx定义使用类似于httpd的combined格式的访问日志；         2.把combined的日志格式定义输出成json格式(KV键值对)2.access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];    access_log off;    访问日志文件路径，格式及相关的缓冲的配置；        buffer=size        flush=time 3.open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];    open_log_file_cache off;    缓存各日志文件相关的元数据信息；    max：缓存的最大文件描述符数量；    min_uses：在inactive指定的时长内访问次数低于min_uses就认为是无效的；    inactive：非活动时长；    valid：验正缓存中各缓存项是否为活动项的时间间隔；检查inactive的间隔</code></pre><h4 id="ngx-http-gzip-module：文本资源压缩传输节约带宽"><a href="#ngx-http-gzip-module：文本资源压缩传输节约带宽" class="headerlink" title="ngx_http_gzip_module：文本资源压缩传输节约带宽"></a>ngx_http_gzip_module：文本资源压缩传输节约带宽</h4><pre><code>在CPU等硬件资源不稀缺的情况下，带宽流量的稀缺使得资源压缩必须启用启用资源压缩功能，虽然可以大大减小了带宽的消耗，要注意适用的场景；    1.比如当前服务器CPU负载较大，压缩功能本身就会消耗更多的CPU资源，如果启用        对服务器的压力就会更大    2.应该只对文本内容进行压缩，视频、图片、流媒体等本身就已经是有压缩比的资源    3.实现逻辑：先使用压缩过滤器过滤出来有很好压缩比的资源(css,js,html)等文本        再定义压缩规则    1.gzip on | off;        需要先开启gzip压缩功能    2.gzip_comp_level level;        设置压缩比1~9,压缩比越大对CPU的消耗越大    3.gzip_disable regex ...;         过滤User_Agent浏览器类型，禁用较老的浏览器版本不启用压缩功能。    4.gzip_min_length length;        当响应报文大小达到某个值，才压缩，太小就不值得压缩了        比如：低于100k不压缩，高于这个值才进行资源压缩，单位:byte字节    5.gzip_buffers number size;        支持实现压缩功能时为其配置的缓冲区数量(number)及每个缓存区的大小(size)；        在服务器的内存资源充沛时，启用缓冲区可以更快的对资源进行压缩    6、gzip_proxied off | expired | no-cache | no-store | private |         no_last_modified | no_etag | auth | any ...;        nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的；            off：对代理的请求不启用            no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能；            any:任何内容不压缩    7.gzip_types mime-type ...;        压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能；        过滤需要压缩的类型，纯文本和html不需要，因为默认就对其压缩    示例：        gzip  on;        gzip_comp_level 6;        gzip_min_length 64;        gzip_proxied any;        gzip_types text/xml text/css  application/javascript; </code></pre><h4 id="ngx-http-ssl-module模块："><a href="#ngx-http-ssl-module模块：" class="headerlink" title="ngx_http_ssl_module模块："></a>ngx_http_ssl_module模块：</h4><pre><code>如上图，代理服务用nginx不采用LVS的一个原因就是LVS不支持SSL的代理，nginx可以实现    面对客户端使用https协议，面对后端服务器集群使用http协议，所以有时nginx反代也叫https的会话卸载器如果是四层调度，https访问必须是客户端与后端服务器之间建立；如果两段式连接，对内调度是明文的，把压力放在前端代理服务器上，本身前端调度器岁CPU资源消耗不是很大    1.ssl on | off;        Enables the HTTPS protocol for the given virtual server.      2.ssl_certificate file;        当前虚拟主机使用PEM格式的证书文件；    3.ssl_certificate_key file;        当前虚拟主机上与其证书匹配的私钥文件；    4.ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2];        支持ssl协议版本，默认为后三个；    5.ssl_session_cache off | none | [builtin[:size]] [shared:name:size];        nginx的ssl会话有两种：        1.builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有；        2.[shared:name:size]：在各worker之间使用一个共享的缓存；        ssl的session建立是很慢的,所以要启用ssl的缓存，而且还是shared类型的共享缓存方式    6、ssl_session_timeout time;        客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长；实现https加密：            生成私钥和证书：        openssl genrsa -out nginx.key 2048        openssl req -new -x509 -key nginx.key -out nginx.crt -days 3650 -subj &quot;/CN=www.lk.tech&quot;    配置https主体：        server {            listen 443 ssl;            server_name www.lk.tech;            root /data/lk;            ssl on;            ssl_certificate /etc/nginx/ssl/nginx.crt;            ssl_certificate_key /etc/nginx/ssl/nginx.key;            ssl_session_cache shared:sslcache:20m;            ssl_session_timeout 10m;        }                           </code></pre><h4 id="ngx-http-rewrite-module模块：实现URL重写"><a href="#ngx-http-rewrite-module模块：实现URL重写" class="headerlink" title="ngx_http_rewrite_module模块：实现URL重写"></a>ngx_http_rewrite_module模块：实现URL重写</h4><p><img src="/2018/03/20/nginx实现web服务配置/官网rewrite1.png" alt="rewrite官方示例1"><br><img src="/2018/03/20/nginx实现web服务配置/官网rewrite2.png" alt="rewrite官方示例2"></p><pre><code>什么是url重写？为什么要用到url重写？    1.客户端访问URL被重写到另外一个路径了    http://www.lk.tech/photos/1.jpg ---&gt; http://images.lk.tech/1.jpg    2.全站ssl加密时，将用户访问的http://请求全部被重写到https://的虚拟主机上    http://www.lk.tech/images/1.jpg---&gt;https://www.lk.tech/1.jpgrewirte的处理逻辑：    1.将用户请求的URL基于(regex)正则表达式的查找，而后完成替换即可(replacement)    2.如果出现server中两个location互相rewrite，则会出现死循环的现象，所以就引入        了last和break的两个机制    3.last表示接着检查其他rewrite，break表示匹配到当前的rewrite.就不检查其他的        rewrite了这样就避免了死循环。1.rewrite regex replacement [flag]    a.将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement        指定的新的URI；    b.rewrite重写的路径可以是相对路径也可以是绝对路径    注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制；    如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端    ；用的比较多的是301和302        301：permanent,永久重定向；        302：redirect,临时重定向；    [flag]：        last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环；         break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环；        redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；302        permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；301       2.return：类似于重定向的操作    return code [text];    return code URL;    return URL;    Stops processing and returns the specified code to a client. 3.rewrite_log on | off;    是否开启重写日志；可能出现安全风险，所以没有必要时不用开启4.if (condition) { ... }    引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令；    一般用于server, location；    condition：        比较操作符：            ==            !=            ~：模式匹配，区分字符大小写；            ~*：模式匹配，不区分字符大小写；            !~：模式不匹配，区分字符大小写；            !~*：模式不匹配，不区分字符大小写；        文件及目录存在性判断：            -e, !-e            -f, !-f            -d, !-d            -x, !-x            5.set $variable value;    用户自定义变量；示例：    location ~* ^/(photos|pictures) {    ##      rewrite ^/photos/(.*)$ /image/$1 last;    #       rewrite ^/photos/(.*)$ http://images.lk.tech:8081/$1;    #       rewrite ^/(photos|pictures)/(.*)$ http://images.lk.tech:8081/$2 permanent;                                       #       }</code></pre><p>-redirect和permanent的示例演示<br><img src="/2018/03/20/nginx实现web服务配置/rewrite规则.png" alt="rewrite机制"></p><h4 id="ngx-http-referer-module模块：网站防盗链"><a href="#ngx-http-referer-module模块：网站防盗链" class="headerlink" title="ngx_http_referer_module模块：网站防盗链"></a>ngx_http_referer_module模块：网站防盗链</h4><pre><code>检查客户端的请求数据报文首部，实际就是防盗链的过滤器，所以在日志中记录referer    referer来源：        1.        2.    1.valid_referers none | blocked | server_names | string ...;        定义referer首部的合法有效的值            none：请求报文首部没有referer首部；        blocked：请求报文的referer首部没有值；        server_names：参数，其可以有值作为主机名或主机名模式；            arbitrary_string：直接字符串，但可使用*作通配符；            regular expression：被指定的正则表达式模式匹配到的字符串；                要使用~打头，例如 ~.*\.lk.com；使用说明和示例：    先定义valid_referers的允许连接网站，再通过if判断如果不是在    valid_referers中定义的网站，就返回一张图片或者文字说明        valid_referers none block server_names *.lk.com lk.* ~\.lk\.;        if ($invalid_referer) {            return http://www.lk.tech/hello.html;        } </code></pre><p><img src="/2018/03/20/nginx实现web服务配置/referer防盗机制.png" alt="referer防盗机制"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;nginx安装和配置文件&quot;&gt;&lt;a href=&quot;#nginx安装和配置文件&quot; class=&quot;headerlink&quot; title=&quot;nginx安装和配置文件&quot;&gt;&lt;/a&gt;nginx安装和配置文件&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://nginx.org/en/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Nginx下载安装和模块使用说明手册&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>ansible</title>
    <link href="https://www.liukui.tech/2018/03/06/ansible/"/>
    <id>https://www.liukui.tech/2018/03/06/ansible/</id>
    <published>2018-03-05T16:00:00.000Z</published>
    <updated>2019-01-07T11:23:00.413Z</updated>
    
    <content type="html"><![CDATA[<h1 id="运维自动化管理工具之Ansible"><a href="#运维自动化管理工具之Ansible" class="headerlink" title="运维自动化管理工具之Ansible"></a>运维自动化管理工具之Ansible</h1><p><img src="/2018/03/06/ansible/ansible.png" alt=""><br><a id="more"></a></p><h3 id="内容：1-软件发布环境机制优势对比-和-2-ansible的应用"><a href="#内容：1-软件发布环境机制优势对比-和-2-ansible的应用" class="headerlink" title="内容：1.软件发布环境机制优势对比  和   2.ansible的应用"></a>内容：1.软件发布环境机制优势对比  和   2.ansible的应用</h3><p><font color="#FF0000">ansible的相关的文档</font><br>ansible的中文权威指南：<a href="http://ansible.com.cn/" target="_blank" rel="noopener">ansible中文指南</a><br>Github上的ansible-galaxy示例：<a href="http://galaxy.ansible.com" target="_blank" rel="noopener">ansible-galaxy</a></p><p>其他相关运维管理工具使用方法：<br>pssh的使用方法参照链接文章：<a href="https://www.jianshu.com/p/d15b6b8f17a5" target="_blank" rel="noopener">pssh</a><br>saltstack介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">saltstack</a><br>puppet介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">puppet</a></p><pre><code>当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric常用自动化运维工具    PSSH：适用于主机数量很少的环境(基础ssh的key验证)    Ansible:python,Agentless,中小型应用环境(自带代理功能)    Saltstack:python，一般需部署agent，执行效率更高    Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境    Fabric：python，agentless    Chef: ruby,国内应用少    Cfengine    func</code></pre><h3 id="发布更新环境"><a href="#发布更新环境" class="headerlink" title="发布更新环境"></a>发布更新环境</h3><h4 id="灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机"><a href="#灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机" class="headerlink" title="灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)"></a>灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)</h4><pre><code>比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器    而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径     如：     软件路径为:/data/app     正在用的软件版本V1.0：/data/app1.0     更新的软件版本V2.0：/data/app2.0    则需要把删除原来的软链接：/data/app1.0---&gt;/data/app    创建新的软链接：/data/app2.0---&gt;/data/app10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线发布步骤：    1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。    2.从负载均衡列表中移除掉「金丝雀」服务器。    3.升级「金丝雀」应用（排掉原有流量并进行部署）。    4.对应用进行自动化测试。    5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。    6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。A/B Testing    A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。优势与不足：    优势：用户体验影响小，灰度发布过程出现问题只影响少量用户    不足：发布自动化程度不够，发布期间可引发服务中断预发布验证：    新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器灰度发布：    可以基于主机，用户或者业务，又细分为地区，VIP和普通用户</code></pre><h4 id="蓝绿发布：核心：主备两套环境"><a href="#蓝绿发布：核心：主备两套环境" class="headerlink" title="蓝绿发布：核心：主备两套环境"></a>蓝绿发布：核心：主备两套环境</h4><pre><code>定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同     时也升级到新版本主：绿色环境-活动环境：负责对外提供服务，版本：v1.0备：绿色环境-非活动环境：版本：v2.0工作机制：    先把备环境升级v1.0---&gt;v2.0版本，然后上线    把主环境的v1.0版本下线，已经升级的备环境进行替换特点：    蓝绿部署无需停机，并且风险较小.注意事项：    1.需要提前考虑数据库与应用部署同步迁移/回滚的问题    2.蓝绿部署需要有基础设施支持    3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境      和绿色环境有被摧毁的风险.优势与不足：    优势：升级切换和回退速度非常快    不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响</code></pre><h4 id="滚动发布：在灰度发布的基础上进行进一步优化"><a href="#滚动发布：在灰度发布的基础上进行进一步优化" class="headerlink" title="滚动发布：在灰度发布的基础上进行进一步优化"></a>滚动发布：在灰度发布的基础上进行进一步优化</h4><pre><code>定义：    一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式.特点：    1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数.  可以部分部署，例如每次只取出集群的20%进行升级。    2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出优势和不足:    优势：用户体验影响小，体验较平滑    不足：发布和回退时间比较缓慢。         发布工具比较复杂，LB需要平滑的流量摘除和拉入能力滚动发布目前成熟型技术组织所采用的主流发布方式</code></pre><h1 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h1><p><img src="/2018/03/06/ansible/ansible架构.png" alt="ansible架构"></p><h4 id="ansible特性：-最多管理500台主机，更多效率会降低"><a href="#ansible特性：-最多管理500台主机，更多效率会降低" class="headerlink" title="ansible特性：-最多管理500台主机，更多效率会降低"></a>ansible特性：-最多管理500台主机，更多效率会降低</h4><pre><code>1.模块化：调用特定的模块，完成特定任务   -类似linux中的小命令2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块3.支持自定义模块4.基于Python语言实现5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务)6.安全，基于OpenSSH7.支持playbook编排任务   -类似于脚本功能，多个脚本的集合成为Roles8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况9.无需代理不依赖PKI（无需ssl）10.可使用任何编程语言写模块11.YAML格式，编排任务，支持丰富的数据结构12.较强大的多层解决方案</code></pre><h3 id="Ansible的学习过程："><a href="#Ansible的学习过程：" class="headerlink" title="Ansible的学习过程："></a>Ansible的学习过程：</h3><pre><code>1.ansible基本命令使用2.ansible常用模块详解，介绍ansible单个命令的使用3.YAML语法介绍4.ansible playbook基础：剧本初体验，类似于写脚本5.playbook中的变量：tags，handlers使用6.plsybook模板：templates7.playbook的条件判断：when8.playbook的字典：with_items9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合</code></pre><p>会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。</p><h3 id="ansible命令执行过程"><a href="#ansible命令执行过程" class="headerlink" title="ansible命令执行过程"></a>ansible命令执行过程</h3><pre><code>ansible命令执行过程1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg2. 加载自己对应的模块文件，如command3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件4. 给文件+x执行5. 执行并返回结果6. 删除临时py文件，sleep 0退出执行状态：(颜色定义在/etc/ansible/ansible.cfg中)    绿色：执行成功并且不需要做改变的操作    黄色：执行成功并且对目标主机做变更    红色：执行失败</code></pre><h3 id="CMDB作用介绍"><a href="#CMDB作用介绍" class="headerlink" title="CMDB作用介绍:"></a>CMDB作用介绍:</h3><pre><code>CMDB:Configuration Management Database 配置管理数据库        将服务器的配置，网络配置写到数据库里CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管理等流程提供准确的配置信息.</code></pre><p>了解更多CMDB可参照文章：<a href="">CMDB</a></p><h2 id="1-ansible基本命令使用"><a href="#1-ansible基本命令使用" class="headerlink" title="1.ansible基本命令使用"></a>1.ansible基本命令使用</h2><h3 id="ansible软件安装：多种安装方法"><a href="#ansible软件安装：多种安装方法" class="headerlink" title="ansible软件安装：多种安装方法"></a>ansible软件安装：多种安装方法</h3><pre><code>1.基于epel源安装：    yum install ansible,非服务，只是一个管理工具2.编译安装：3.Github方式安装：可以同步安装4.pip安装：pip是安装Python包的管理器，类似yum</code></pre><h4 id="ansible的重要-amp-主要文件"><a href="#ansible的重要-amp-主要文件" class="headerlink" title="ansible的重要&amp;主要文件"></a>ansible的重要&amp;主要文件</h4><pre><code>配置文件：    /etc/ansible/ansible.cfg  配置ansible的工作特性    /etc/ansible/hosts  主机清单    /etc/ansible/roles  存放的角色目录程序文件：    /usr/bin/ansible   ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想    /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助    /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台    /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务    /usr/bin/ansible-vault 文件加密工具    /usr/bin/ansible-console 基于Console界面与用户交互的执行工具常用命令：    ansible all --list 查看ansible管理的主机群    ansible all -m &quot;模块名&quot; -a &apos;执行的命令&apos;   用什么模块执行什么命令        all也可以换成定义的--list中组的名字    ansible-playbook -C &apos;*.yml&apos; 对所有主机执行剧本    ansible-plsybook -C -t &apos;标签&apos; &apos;*.yml&apos; 对所有主机执行哪个标签的剧本</code></pre><h4 id="ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法"><a href="#ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法" class="headerlink" title="ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)"></a>ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)</h4><pre><code>支持不分组，分组，等方式    如：        192.168.34.100        [webservers]        192.168.34.101        192.168.34.102        [dbservers]        192.168.34.[1:6]7 (17,27..67)        db[01:100].cenntos.com</code></pre><h4 id="ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）"><a href="#ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）" class="headerlink" title="ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）"></a>ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）</h4><pre><code>配置文件只提供默认值，但可以通过playbook的设置进行覆盖配置文件可以放在/etc/ansible/ansible.cfg中也可以放到一个工作目录下命名为.ansible.cfg[defaults]inventory = /etc/ansible/hosts - 主机列表配置文件library = /usr/share/my_modules/ - 库文件存放目录remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录forks = 5 - 默认并发数sudo_user = root - 默认sudo 用户ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码ask_pass = Trueremote_port = 22host_key_checking = False  -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错[color] 定义ansible命令的执行结果颜色的</code></pre><h3 id="配置文件说明和建议修改的项："><a href="#配置文件说明和建议修改的项：" class="headerlink" title="配置文件说明和建议修改的项："></a>配置文件说明和建议修改的项：</h3><pre><code>local_tmp和remote_tmp：    本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地    家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除.host_key_checking = False -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错module_name = command   -默认使用的命令模块，可以修改成shell    module_name = shell</code></pre><h2 id="2-ansible常用模块详解，介绍ansible单个命令的使用"><a href="#2-ansible常用模块详解，介绍ansible单个命令的使用" class="headerlink" title="2.ansible常用模块详解，介绍ansible单个命令的使用"></a>2.ansible常用模块详解，介绍ansible单个命令的使用</h2><h3 id="ansible模块的使用查询方法"><a href="#ansible模块的使用查询方法" class="headerlink" title="ansible模块的使用查询方法"></a>ansible模块的使用查询方法</h3><pre><code>ansible-doc: 显示模块帮助ansible-doc [options] [module...]    -a 显示所有模块的文档    -l, --list 列出可用模块    -s, --snippet显示指定模块的playbook片段示例：    ansible-doc –l 列出所有功能模块    ansible-doc ping 查看ansible中的ping用法    ansible-doc -s shell 查看shell模块的使用方法</code></pre><h3 id="ansible的常用基本选项"><a href="#ansible的常用基本选项" class="headerlink" title="ansible的常用基本选项"></a>ansible的常用基本选项</h3><pre><code>ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible    端能基于密钥认证的方式联系各被管理节点ansible语法：    ansible &lt;host-pattern&gt; [-m module_name] [-a args]    --version 显示版本    -m module 指定模块，默认为command，主要使用选项    -v 详细过程 –vv -vvv更详细    --list-hosts 显示主机列表，可简写 --list    -k, --ask-pass 提示输入ssh连接密码，默认Key验证    -K, --ask-become-pass 提示输入sudo时的口令    -C, --check 检查，并不执行    -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s    -u, --user=REMOTE_USER 执行远程执行的用户    -b, --become 代替旧版的sudo 切换</code></pre><h3 id="ansible的主机清单表示方法-Host-pattern"><a href="#ansible的主机清单表示方法-Host-pattern" class="headerlink" title="ansible的主机清单表示方法:Host-pattern"></a>ansible的主机清单表示方法:Host-pattern</h3><pre><code>1.All ：表示所有Inventory中的所有主机    如：ansible all -m ping        ansible all --list-hosts列出所有主机清单        ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP2.* :通配符    如：ansible &quot;*&quot; = ansible all        ansible 192.168.34.* 表示34网段的所有IP3.或的关系    如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作        ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作4.与的关系(且)    如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机5.非，取反    如：ansible &apos;websrvs:!dbsrvs&apos;        在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号6.正则表达式    如：ansible &quot;~(web|db).*\.centos\.com&quot; </code></pre><h2 id="ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块"><a href="#ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块" class="headerlink" title="ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)"></a>ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)</h2><h5 id="ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项"><a href="#ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项" class="headerlink" title="ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项"></a>ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项</h5><pre><code>1.Command：在远程主机执行命令，默认模块，可忽略-m选项    可以在ansible.cfg中修改默认模块项    支持：chdir(切换目录)    command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现使用示例：    ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh    ansible all -a &apos;useradd test&apos; 所有主机上创建test用户2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项    支持功能：支持$ &lt; &gt; | ; &amp; 等            chdir 执行前，先切换到该文件夹示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos;        显示appsrvs组的主机名    ansible all -m shell -a &apos;chdir=/data rm -rf *&apos;    先切换到/data目录下，再执行删除命令3.Script: 批量运行脚本    可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理    功能：creates:远程主机的文件存在，则不运行        removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令示例：ansible all -m script -a &quot;/data/test.sh&quot;    ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot;        因为fstab文件存在，则不执行rm -rf /data/*命令    ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot;        因为fstab文件存在，则执行rm -rf /data/*命令4.Copy:从服务器复制文件到目标主机    src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos;    根据自己写的字符串生成文件5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取    src，dest(抓取到本机目录)示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;        将远程主机fstab2文件抓取到本机/data下    如果抓取的是目录，先打包再抓取    打包：ansible all -a &apos;tar cf /root/data.tar /data&apos;     抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;6.File：设置文件属性，创建/删除文件    src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos;     创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos;     删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos;7.Hostname：管理主机名     可以通过后面的变量来实现    a.先在hosts后定义hostname变量名        [centos6]        192.168.34.106 hostname=mini6-2        192.168.34.101 hostname=node6-1         [centos7]        192.168.34.107 hostname=mini7-1    b.再通过hostname模块批量修改        ansible all -m hostname -a &apos;name={{hostname}}&apos;8.Cron：计划任务    支持：minute，hour，day，month，weekday示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate        172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务     ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名     ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名9.Yum：管理包    支持：name,state=(started stopped reloaded restarted),absent    更新缓存：update_cache=yes，示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包      ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包10.Service：管理服务(同一systemctl&amp;service)    name，state(stopped,started,reloaded,restarted) enable(设置开启启动)示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务     ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务     ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务     ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动11.User：管理用户    name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录)示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos;    创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录12.Group：管理组    支持：group,name,gid,system,state=(absent)示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组    ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 </code></pre><h2 id="ansible系列的一些模块-用的不多"><a href="#ansible系列的一些模块-用的不多" class="headerlink" title="ansible系列的一些模块(用的不多)"></a>ansible系列的一些模块(用的不多)</h2><pre><code>简单介绍与了解：ansible-galaxy 互联网上的角色分享ansible-pull      推送命令至远程，效率无限提升，对运维要求较高  Ansible-vault管理yaml文件    功能：管理加密解密yml文件        ansible-vault [create|decrypt|edit|encrypt|rekey|view]        ansible-vault encrypt hello.yml 加密        ansible-vault decrypt hello.yml 解密        ansible-vault view hello.yml 查看        ansible-vault edit hello.yml 编辑加密文件        ansible-vault rekey hello.yml 修改口令        ansible-vault create new.yml 创建新文件Ansible-console</code></pre><h2 id="ansible重要知识之playbook-上面的各种模块的组合"><a href="#ansible重要知识之playbook-上面的各种模块的组合" class="headerlink" title="ansible重要知识之playbook(上面的各种模块的组合)"></a>ansible重要知识之playbook(上面的各种模块的组合)</h2><p><img src="/2018/03/06/ansible/" alt="playbook原理"></p><h3 id="YAML语言（编写playbook的专门语言）"><a href="#YAML语言（编写playbook的专门语言）" class="headerlink" title="YAML语言（编写playbook的专门语言）"></a>YAML语言（编写playbook的专门语言）</h3><pre><code>YAML语法：     在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三    个点号( ... )用来表示档案结尾    次行开始正常写Playbook的内容，一般建议写明该Playbook的功能    使用#号注释代码    缩进必须是统一的，不能空格和tab混用    缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过    缩进结合换行来实现的    YAML文件内容是区别大小写的，k/v的值均需大小写敏感    k/v的值可同行写也可换行写。同行使用:分隔    v可是个字符串，也可是另一个列表    一个完整的代码块功能需最少元素需包括 name: task    一个name只能包括一个task    YAML文件扩展名通常为yml或yaml    List：列表，其所有元素均使用“-”打头    Dictionary：字典，通常由多个key与value构成</code></pre><h2 id="Playbook中的核心元素"><a href="#Playbook中的核心元素" class="headerlink" title="Playbook中的核心元素:"></a>Playbook中的核心元素:</h2><pre><code>1.Hosts 执行的远程主机列表2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远    程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使    用sudo_user指定sudo时切换的用户3.Tasks 任务集4.Varniables 内置变量或自定义变量在playbook中调用5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断8.handlers和notify  </code></pre><h2 id="运行playbook"><a href="#运行playbook" class="headerlink" title="运行playbook"></a>运行playbook</h2><pre><code>运行playbook的方式ansible-playbook &lt;filename.yml&gt; ... [options]常见选项    -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测    --list-hosts 列出运行任务的主机    --limit 主机列表 只针对主机列表中的主机执行    -v 显示过程 -vv -vvv 更详细 备注：    执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误    ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行</code></pre><h3 id="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"><a href="#执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。" class="headerlink" title="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"></a>执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。</h3><h2 id="示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验"><a href="#示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验" class="headerlink" title="示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验"></a>示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验</h2><h4 id="将centos7的httpd-conf复制到centos7主机，6上的配置文件不同"><a href="#将centos7的httpd-conf复制到centos7主机，6上的配置文件不同" class="headerlink" title="将centos7的httpd.conf复制到centos7主机，6上的配置文件不同"></a>将centos7的httpd.conf复制到centos7主机，6上的配置文件不同</h4><pre><code>示例1：写一个安装启动httpd的playbook:install_httpd.yml        包括创建用户，安装httpd包，开启服务，并设置开机启动- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd    - name: copy config      copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf    - name: install package      yum: name=httpd    - name: service      service: name=httpd state=started enabled=yes备注：    执行完通过以下命令判断每个任务都否都执行成功了    1.ansible all -a &apos;getent passwd httpd&apos;    2.ansible all -a &apos;rpm -q httpd&apos;    3..ansible all -a &apos;ss -ntlp|grep 80&apos;示例2：写一个删除上面的playbook:remove_httpd.yml        包括：删除用户，卸载httpd包- hosts: all  remote_user: root  tasks:    - name: del user      user: name=httpd state=absent remove=yes    - name: remove package      yum: name=httpd state=absent备注：    如果只删除特定主机的httpd，而不是全部，需要加--limit选项    ansible-playbook --limit 192.168.34.105 remove_httpd.yml        只限制在192.168.34.105的主机执行</code></pre><h4 id="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"><a href="#上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。" class="headerlink" title="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"></a>上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。</h4><h3 id="handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。"><a href="#handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。" class="headerlink" title="handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。"></a>handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。</h3><pre><code>Handlers:    是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生        变化时，才会采取一定的操作Notify:    此action可用于在每个play的最后被触发，这样可避免多次有改变发生    时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。    在notify中列出的操作称为handler，也即notify中调用handler中定义的操作</code></pre><h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><pre><code>示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200）- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted 备注：停止并删除用户和安装包    ansible all -a &apos;service memcached stop&apos;    ansible all -a &apos;ss -ntl&apos;    ansible all -a &apos;rpm -q memcached&apos;    ansible all -a &apos;getent passwd memcached&apos;</code></pre><h3 id="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"><a href="#可以多个notify对应一个handlers，也可以多个motify对应多个handlers" class="headerlink" title="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"></a>可以多个notify对应一个handlers，也可以多个motify对应多个handlers</h3><pre><code>示例4：多个notify对应一个handlers- hosts: websrvs  remote_user: root  tasks:    - name: Install httpd      yum: name=httpd state=present    - name: Install configure file      copy: src=files/httpd.conf dest=/etc/httpd/conf/      notify: restart httpd  第一个notify    - name: ensure apache is running      service: name=httpd state=started enabled=yes      notify: restart httpd  第二个notify  handlers:      - name: restart httpd   对应一个handlers      service: name=httpd status=restarted</code></pre><h3 id="示例5：多个notify对应多个handlers"><a href="#示例5：多个notify对应多个handlers" class="headerlink" title="示例5：多个notify对应多个handlers"></a>示例5：多个notify对应多个handlers</h3><pre><code>- hosts: websrvs  remote_user: root  tasks:    - name: config      copy: src=/root/config.txt dest=/etc/nginx/nginx.conf      notify:        - Restart Nginx        - Check Nginx Process  多个notify的写法  handlers:    - name: Restart Nginx     对应写多个handlers      service: name=nginx state=restarted enabled=yes    - name: Check Nginx process      shell: killall -0 nginx &gt; /tmp/nginx.log</code></pre><h3 id="tags的用法：作用：挑选某一段的task来执行"><a href="#tags的用法：作用：挑选某一段的task来执行" class="headerlink" title="tags的用法：作用：挑选某一段的task来执行"></a>tags的用法：作用：挑选某一段的task来执行</h3><pre><code>将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行然后执行：ansible-plsybook -t ceshi install_memcached.yml        只会触发拷贝文件和handlers的动作---#test yaml file- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致      tags: ceshi   对拷贝动作加一个标签    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted</code></pre><h2 id="Playbook中变量使用-可以多出定义，但是存在优先级"><a href="#Playbook中变量使用-可以多出定义，但是存在优先级" class="headerlink" title="Playbook中变量使用:可以多出定义，但是存在优先级"></a>Playbook中变量使用:可以多出定义，但是存在优先级</h2><h4 id="优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量"><a href="#优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量" class="headerlink" title="优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量"></a>优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量</h4><pre><code>变量名：仅能由字母、数字和下划线组成，且只能以字母开头变量来源：1 ansible setup facts 远程主机的所有变量都可直接调用    setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的        代码块，然后用代码块当变量    比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的          ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量3 通过命令行指定变量，优先级最高    可以对单个变量赋值：ansible-playbook –e varname=value     也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot;4 在playbook中定义    vars:         - var1: value1         - var2: value25 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件            很适合在roles中进行单独定义6 在role中定义（下文中有介绍）</code></pre><h3 id="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令"><a href="#从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令" class="headerlink" title="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令"></a>从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令</h3><p>#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作<br>        ansible_fqdn 主机名的变量<br>        ansible_hostname 主机名<br>        ansible_distribution_major_version: “6” 版本名变量<br>        ansible_processor_vcpus 虚拟cpu个数变量<br>        ansible_memtotal_mb 内存的变量<br>    示例：<br>    ansible all -m setup -a “filter=ansible_memtotal_mb”<br>        用此命令来查看系统内变量的值</p><h4 id="调用不同变量来源的示例：得出变量的优先级顺序"><a href="#调用不同变量来源的示例：得出变量的优先级顺序" class="headerlink" title="调用不同变量来源的示例：得出变量的优先级顺序"></a>调用不同变量来源的示例：得出变量的优先级顺序</h4><pre><code>示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml- hosts: all  remote_user: root  tasks:    - name: touch file      file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量    /etc/ansible/hosts：中定义的变量：        [websrvs]        192.168.34.105 port1=80        192.168.34.106 port1=90   -普通变量        [websrvs:vars]   -公共组变量        mark=&quot;-&quot;        [appsrvs]        192.168.34.101 port1=100        [appsrvs:vars]        mark=&quot;=&quot;    vars.yml中书写格式：        - hosts: all          remote_user: root          tasks:            - name: touch file              file: name=/data/app{{mark}}{{ port1 }}.log state=touch最后生成的文件为：            app=100.log，app-80.logapp-90.log示例3：在示例1的基础上，再通过命令行中定义变量:    在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果：    ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml    可以看出，最后新建的文件名为hahaha.log示例4：在playbook中定义变量    - hosts: all      remote_user: root      vars:        - port1: 200        - mark: +++      tasks:        - name: touch file          file: name=/data/app{{mark}}{{ port1 }}.log state=touch    生成的文件：        app+++200.log示例5：先写在var.yml中定义变量，    1.先准备cat vars.yml:文件内容格式        var1: httpd        var2: nginx    2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义        - hosts: web          remote_user: root          vars_files:            - vars.yml         tasks:           - name: create httpd log             file: name=/app/{{ var1 }}.log state=touch           - name: create nginx log             file: name=/app/{{ var2 }}.log state=touch</code></pre><h2 id="模板templates，作用："><a href="#模板templates，作用：" class="headerlink" title="模板templates，作用："></a>模板templates，作用：</h2><pre><code>文本文件，嵌套有脚本（使用模板编程语言编写）Jinja2语言，使用字面量，有下面形式字符串：使用单引号或双引号数字：整数，浮点数列表：[item1, item2, ...]元组：(item1, item2, ...)字典：{key1:value1, key2:value2, ...}布尔型：true/false算术运算：+, -, *, /, //, %, **比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;=逻辑运算：and, or, not流表达式：For If When</code></pre><h3 id="templates功能：根据模块文件动态生成对应的配置文件"><a href="#templates功能：根据模块文件动态生成对应的配置文件" class="headerlink" title="templates功能：根据模块文件动态生成对应的配置文件"></a>templates功能：根据模块文件动态生成对应的配置文件</h3><p>   templates文件必须存放于templates目录下，且命名为 .j2 结尾</p><pre><code>yaml/yml 文件需和templates目录平级，目录结构如下：./├── temnginx.yml└── templates   └── nginx.conf.j2</code></pre><h4 id="示例1：通过templates模板nginx"><a href="#示例1：通过templates模板nginx" class="headerlink" title="示例1：通过templates模板nginx"></a>示例1：通过templates模板nginx</h4><pre><code>1.先生成nginx.conf.j2模板cp /etc/nginx/nginx.conf templates/nginx.conf.j22.创建playbook- hosts: all  remote_user: root  tasks:    - name: inastll nginx      yum: name=nginx    - name: template      template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf                                       notify: service    - name: start service      service: name=nginx state=started  handlers:    - name: service      service: name=nginx state=restarted</code></pre><h3 id="when配合templates实现根据不同版本执行不同的功能"><a href="#when配合templates实现根据不同版本执行不同的功能" class="headerlink" title="when配合templates实现根据不同版本执行不同的功能"></a>when配合templates实现根据不同版本执行不同的功能</h3><pre><code>条件测试:    如果需要根据变量、facts或此前任务的执行结果来做为某task执行与    否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法    格式when语句    在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法示例：tasks:     - name: &quot;shutdown RedHat flavored systems&quot;     command: /sbin/shutdown -h now     when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值</code></pre><h4 id="示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when"><a href="#示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when" class="headerlink" title="示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when"></a>示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when</h4><pre><code>步骤：涉及到多个notify对应一个handlers,定义端口变量1.hosts文件配置：修改了4台主机httpd的端口    [centos6]    192.168.34.105 http_port=86    192.168.34.106 http_port=87    192.168.34.101 http_port=88    [centos7]    192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件    httpd_6.conf.j2      httpd_7.conf.j23.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的    Listen {{http_port}} 调用hosts列表中的端口变量4.plsybook如下：---- hosts: all  remote_user: root  tasks:    - name: install httpd      yum: name=httpd    - name: templates 6      template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf      notify: restart service      when: ansible_distribution_major_version == &quot;6&quot;    - name: templates 7      template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf                                when: ansible_distribution_major_version == &quot;7&quot;      notify: restart service    - name: service      service: name=httpd state=started  handlers:    - name: restart service      service: name=httpd state=restarted</code></pre><h2 id="迭代：with-items，类似于shell中的for循环"><a href="#迭代：with-items，类似于shell中的for循环" class="headerlink" title="迭代：with_items，类似于shell中的for循环"></a>迭代：with_items，类似于shell中的for循环</h2><pre><code>迭代：当有需要重复性执行的任务时，可以使用迭代机制对迭代项的引用，固定变量名为”item“要在task中使用with_items给定要迭代的元素列表列表格式：    字符串    字典   字典构成一个键值对{key:vavul},如示例3</code></pre><h4 id="迭代的示例："><a href="#迭代的示例：" class="headerlink" title="迭代的示例："></a>迭代的示例：</h4><pre><code>示例1：比如创建user1.user2.user3个用户    - hosts: all      remote_user: root      tasks:        - name: touch users          user: name={{item}}          with_items:            - haha1            - haha2            - haha3示例2：拷贝3个文件，file1 file2 file3    - hosts: all     remote_user: root    tasks:      - name: copy files        copy: src=/data/playbook/{{item}} dest=/data/        with_items:          - file1          - file2          - file3</code></pre><h2 id="迭代嵌套子变量-涉及到多个键值对的表达方式"><a href="#迭代嵌套子变量-涉及到多个键值对的表达方式" class="headerlink" title="迭代嵌套子变量:涉及到多个键值对的表达方式"></a>迭代嵌套子变量:涉及到多个键值对的表达方式</h2><pre><code>示例3：创建3个组，再创建3个用户，指定加入一一对应的组    - hosts: all      remote_user: root      tasks:        - name: creat groups          group: name={{item}}          with_items:            - group1            - group2            - group3        - name: creat users          user: name={{item.name}} group={{item.group}}          with_items:            - { name: &apos;haha1&apos;, group: &apos;group1&apos; }            - { name: &apos;haha2&apos;, group: &apos;group2&apos; }            - { name: &apos;haha3&apos;, group: &apos;group3&apos; }备注：注意创建用户时，键值对的表达和使用方法    上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3;</code></pre><h3 id="Playbook中template结合for循环生成具有重复性的代码段"><a href="#Playbook中template结合for循环生成具有重复性的代码段" class="headerlink" title="Playbook中template结合for循环生成具有重复性的代码段"></a>Playbook中template结合for循环生成具有重复性的代码段</h3><pre><code>语法:for的写法：    {% for vhost in nginx_vhosts %}        server {        listen {{ vhost.listen | default('80 default_server') }}### Playbook中template结合for循环生成具有重复性的代码段         if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用                        如果没定义，则不执行接下来的代码：示例2        {% if vhost.server_name is defined %}                server_name {{ vhost.server_name }};        {% endif %}        {% if vhost.root is defined %}                root {{ vhost.root }};        {% endif %}### for和if的示例，帮助理解其要执行语句的含义        示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成    先创建for.j2文件：                {% for i in ports %}                server{                        listen {{i.listen}}                        name {{i.name}}                        root {{i.root}}                }                {% endfor %}        创建playbook:再其中调用for.j2文件            - hosts: all              remote_user: root              vars:                ports:                  - web1:                    listen: 81                    name: www.baidu.com                    root: /data/web1                  - web2:                    listen: 82                    name: www.baidu1.com                    root: /data/web2              tasks:                - name: test for                  template: src=for.j2 dest=/data/for1.conf    效果为：        server{            listen 81            name www.baidu.com            root /data/web1        }        server{            listen 82            name www.baidu1.com            root /data/web2        }示例2：template配合if的涵义：    在示例1中的playbook中，把name注释掉，即不定义name的值            - web1:                    listen: 81                   # name: www.baidu.com                    root: /data/web1    然后playbook:再调用for.j2文件        {% for i in ports %}            server{                    listen {{i.listen}}            {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用                    name {{i.name}}            {% endif %}                    root {{i.root}}            }            {% endfor %}    结果：则web1没有name的值，即可以理解if的用法        server{            listen 81            root /data/web1  少了web1的name的值        }        server{            listen 82            name www.baidu1.com            root /data/web2        }</code></pre><h3 id="Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？"><a href="#Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？" class="headerlink" title="Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？"></a>Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？</h3><h2 id="ansible重要内容之Roles；playbook的集合和拆分"><a href="#ansible重要内容之Roles；playbook的集合和拆分" class="headerlink" title="ansible重要内容之Roles；playbook的集合和拆分"></a>ansible重要内容之Roles；playbook的集合和拆分</h2><pre><code> ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles    能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需    要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、    文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一    种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程    等场景中复杂场景：建议使用roles，代码复用度高变更指定主机或主机组如命名不规范维护和传承成本大某些功能需多个Playbook，通过Includes即可实现</code></pre><h3 id="roles的意义和适用场景："><a href="#roles的意义和适用场景：" class="headerlink" title="roles的意义和适用场景："></a>roles的意义和适用场景：</h3><pre><code>角色(roles)：角色集合    适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把    同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了，    当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。        如系统内会存在如下的各类服务，可以先编排好角色        roles/        ├── httpd/        ├── memcached/        ├── mysql/        └── nginx/</code></pre><h3 id="roles的目录结构（一般分成以下目录进行存放一类的文件）"><a href="#roles的目录结构（一般分成以下目录进行存放一类的文件）" class="headerlink" title="roles的目录结构（一般分成以下目录进行存放一类的文件）"></a>roles的目录结构（一般分成以下目录进行存放一类的文件）</h3><pre><code>Roles各目录作用：/roles/project/ :项目名称,有以下子目录    如创建http，memcached，nginx等目录files/ ：存放由copy或script模块等调用的文件    保存需要拷贝的配置文件templates/：template模块查找所需要模板文件的目录    保存通过template的jinja2模板调用的配置文件tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；        其它的文件需要在此文件中通过include进行包含handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此           文件中通过include进行包含vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要       在此文件中通过include进行包含，可以单独定义变量的目录meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，其它文件需在此文件中通过include进行包含            tasks目录下，组合任务顺序的文件default/：设定默认变量时使用此目录中的main.yml文件</code></pre><h3 id="roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色"><a href="#roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色" class="headerlink" title="roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色."></a>roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.</h3><pre><code>- hosts: all  remote_user: root  roles:    - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]}       - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}    - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}</code></pre><h3 id="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"><a href="#playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量" class="headerlink" title="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"></a>playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量</h3><pre><code>方法一：把需要调用的角色写在一个playbook里    - hosts: all      remote_user: root      roles:        - role: httpd        - role: memcached        - role: nginx    弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活方法二；可以把变量在角色中定义    传递变量给角色    - hosts:      remote_user:      roles:        - mysql        - { role: nginx, username: nginx }          键role用于指定角色名称          后续的k/v用于传递变量给角色          调用角色方法3：还可基于条件测试实现角色调用方法三：还可基于条件测试实现角色调用    roles:      - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ }</code></pre><h2 id="roles示例："><a href="#roles示例：" class="headerlink" title="roles示例："></a>roles示例：</h2><h3 id="以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml"><a href="#以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml" class="headerlink" title="以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml"></a>以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml</h3><h4 id="roles的目录结构下的httpd-amp-nginxmemcached"><a href="#roles的目录结构下的httpd-amp-nginxmemcached" class="headerlink" title="roles的目录结构下的httpd&amp;nginxmemcached"></a>roles的目录结构下的httpd&amp;nginxmemcached</h4><pre><code>roles├── httpd│   ├── files│   │   ├── index_6.html│   │   └── index_7.html│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── copyhtml_6.yml│   │   ├── copyhtml_7.yml│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig_6.yml│   │   ├── tempconfig_7.yml│   │   └── user.yml│   ├── templates│   │   ├── httpd_6.conf.j2│   │   └── httpd_7.conf.j2│   └── vars├── memcached│   ├── files│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig.yml│   │   └── user.yml│   ├── templates│   │   └── memcached.j2│   └── vars└── nginx    ├── files    │   ├── index_6.html    │   └── index_7.html    ├── handlers    │   └── main.yml    ├── tasks    │   ├── copyhtml_6.yml    │   ├── copyhtml_7.yml    │   ├── group.yml    │   ├── main.yml    │   ├── package.yml    │   ├── service.yml    │   ├── tempconfig.yml    │   └── user.yml    ├── templates    │   └── nginx.conf.j2    └── vars       └── main.yml</code></pre><h3 id="调用角色的playbook-roles-yml"><a href="#调用角色的playbook-roles-yml" class="headerlink" title="调用角色的playbook:roles.yml"></a>调用角色的playbook:roles.yml</h3><h5 id="可以通过加变量和标签和条件测试调用更灵活的调用各种角色"><a href="#可以通过加变量和标签和条件测试调用更灵活的调用各种角色" class="headerlink" title="可以通过加变量和标签和条件测试调用更灵活的调用各种角色)"></a>可以通过加变量和标签和条件测试调用更灵活的调用各种角色)</h5><pre><code>    vim /data/roles.yml            - hosts: all            remote_user: root          roles:        - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“}        - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}        - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}比如：     1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法     2.ansible-playbook -t httpd roles.yml 只选择安装httpd     3.ansible-playbook -t nginx roles.yml 只选择安装nginx     4.ansible-playbook -t web roles.yml 安装httpd和memcached     5.ansible-playbook -t web1 roles.yml 只选择安装nginx</code></pre><h3 id="下图为每个role的各个文件内容："><a href="#下图为每个role的各个文件内容：" class="headerlink" title="下图为每个role的各个文件内容："></a>下图为每个role的各个文件内容：</h3><p>图一：参照roles的httpd的目录各个文件内容</p><p><img src="/2018/03/06/ansible/roles.png" alt="roles_memcached"></p><p>图二：参照roles的nginx的目录各个文件内容</p><pre><code>涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有    跨角色调用配置文件写法：   - name: copy index6  copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html</code></pre><p><img src="/2018/03/06/ansible/roles_nginx.png" alt="roles_nginx"><br>图三：参照roles的memcached的目录各个文件内容<br><img src="/2018/03/06/ansible/roles_memcached.png" alt="roles_memcached"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;a href=&quot;#运维自动化管理工具之Ansible&quot; class=&quot;headerlink&quot; title=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;/a&gt;运维自动化管理工具之Ansible&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2018/03/06/ansible/ansible.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="自动化运维" scheme="https://www.liukui.tech/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="ansible,运维技术" scheme="https://www.liukui.tech/tags/ansible-%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>zabbix监控系统</title>
    <link href="https://www.liukui.tech/2018/02/05/zabbix%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"/>
    <id>https://www.liukui.tech/2018/02/05/zabbix监控系统/</id>
    <published>2018-02-05T00:00:00.000Z</published>
    <updated>2019-03-13T09:23:13.769Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Zabbix监控进阶-监控常用服务-自定义模板"><a href="#Zabbix监控进阶-监控常用服务-自定义模板" class="headerlink" title="Zabbix监控进阶-监控常用服务(自定义模板)"></a>Zabbix监控进阶-监控常用服务(自定义模板)</h3><a id="more"></a><h3 id="1-监控TCP连接数"><a href="#1-监控TCP连接数" class="headerlink" title="1.监控TCP连接数"></a>1.监控TCP连接数</h3><pre><code>[root@node04 ~]# cd /usr/local/zabbix/etc/zabbix_agentd.conf.d/</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@node04 zabbix_agentd.conf.d]# vim tcp_conn.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">tcp_conn_status()&#123;</span><br><span class="line">        TCP_STAT=$1</span><br><span class="line">        ss -ant | awk &apos;NR&gt;1 &#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;&apos; &gt; /usr/local/zabbix/tcp_conn.txt</span><br><span class="line">        TCP_STAT_VALUE=$(grep &quot;$TCP_STAT&quot; /usr/local/zabbix/tcp_conn.txt | cut -d &apos; &apos; -f2)</span><br><span class="line">        if [ -z $TCP_STAT_VALUE ];then</span><br><span class="line">                TCP_STAT_VALUE=0</span><br><span class="line">        fi</span><br><span class="line">        echo $TCP_STAT_VALUE</span><br><span class="line">&#125;</span><br><span class="line">main()&#123;</span><br><span class="line">        case $1 in</span><br><span class="line">            tcp_status)</span><br><span class="line">                tcp_conn_status $2;</span><br><span class="line">                ;;</span><br><span class="line">                *)</span><br><span class="line">                echo &quot;$0 + tcp_status + STATUS&quot;</span><br><span class="line">        esac</span><br><span class="line">&#125;</span><br><span class="line">main $1 $2</span><br></pre></td></tr></table></figure><pre><code>1.由于TCP三次握手和TCP四次挥手是有11种状态，最多的就是TIME_WAIT和ESTABLISHED的    和SYN_RCVD;2.脚本准备好了，还需要在zabbix-agent.conf中去调用此脚本    LogFile=/usr/local/zabbix/zabbix_agentd.log    DebugLevel=3    Server=172.18.140.5,172.18.140.97          #proxy和server的IP    ListenPort=10050                           #agent的端口    ListenIP=0.0.0.0    StartAgents=3    ServerActive=172.18.140.97                 #proxy的IP    Hostname=172.18.140.97                     #客户端自己的IP    Timeout=30    UnsafeUserParameters=1              #启用特殊字符    UserParameter=linux_status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/tcp_conn.sh &quot;$1&quot; &quot;$2&quot;        #设置键和参数，以及脚本的路径3.授权    1.zabbix用户要tcp_conn.sh脚本授权zabbix用户访问，不然agent日志文件中会有权限问题的报错    或者    2.被监控服务器为zabbix 用户授权：    [root@node01 ~]# vim /etc/sudoers    99 zabbix ALL =(ALL) NOPASSWD: ALL    3.如果是使用root用户先生成的测试文件，zabbix是没有权限读取的，所以要把测试的文件先删除，不然会采集不到数据.4.在zabbix web上添加监控TCP连接的11种状态的模板    因为，要监控的主机众多，不能每个主机里手动添加监控项的，所以一般是先定义一个TCP连接的模板，其他主机再在模板中调用即可;    步骤：        配置-&gt;模板-&gt;创建模板-&gt;添加应用集-&gt;添11个监控项--&gt;为11个监控项添加图形生产环境：    1.生产环境会发现ESTABLISHED已连接的值特别大，不同的负载服务器一般都是3w、5w以上，见过nginx最多是7-8w连接，因为VIP有很多，80端口只有一个；</code></pre><p>–tcp模板监控报错<br><img src="/2018/02/05/zabbix监控系统/tcp模板监控.png" alt="tcp模板监控"><br>–TCP监控状态<br><img src="/2018/02/05/zabbix监控系统/TCP监控状态.png" alt="TCP监控状态"></p><h3 id="2-监控memcached"><a href="#2-监控memcached" class="headerlink" title="2.监控memcached"></a>2.监控memcached</h3><pre><code>memcached一般监控curr_connections当前连接数的值</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 zabbix_agentd.conf.d]# vim memcached.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">    memcached_status()&#123;</span><br><span class="line">        M_PORT=$1</span><br><span class="line">        M_COMMAND=$2</span><br><span class="line">        echo -e &quot;stats\nquit&quot; | nc 127.0.0.1 &quot;$M_PORT&quot; | grep &quot;STAT $M_COMMAND &quot; | awk &apos;&#123;print $3&#125;&apos;</span><br><span class="line">&#125;</span><br><span class="line">main()&#123;</span><br><span class="line">    case $1 in</span><br><span class="line">        memcached_status)</span><br><span class="line">        memcached_status $2 $3</span><br><span class="line">            ;;</span><br><span class="line">    esac</span><br><span class="line">&#125;</span><br><span class="line">main $1 $2 $3</span><br></pre></td></tr></table></figure><pre><code>1.准备配置文件和memcached.sh    [root@node01 zabbix]# vim etc/zabbix_agentd.conf    Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf    [root@node01 zabbix_agentd.conf.d]# vim all.conf    UserParameter=memcached_status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/memcached.sh &quot;$1&quot; &quot;$2&quot; &quot;$3&quot;2.在zabbix web上添加memcached_status监控模板    监控项有：curr_connections和threads等等    图形：把监控的多个项创建各自的图形    设置触发器：在触发器项添加触发值，    聚合图形：在memcached的聚合图形标签</code></pre><p>–memcached模板配置<br><img src="/2018/02/05/zabbix监控系统/memcached模板配置.png" alt="memcached模板配置"><br>–memcached触发器<br><img src="/2018/02/05/zabbix监控系统/memcached触发器.png" alt="memcached触发器"><br>–memcached监控状态<br><img src="/2018/02/05/zabbix监控系统/memcached监控状态.png" alt="memcached监控状态"></p><h3 id="3-监控redis"><a href="#3-监控redis" class="headerlink" title="3.监控redis"></a>3.监控redis</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 zabbix_agentd.conf.d]# vim redis.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">redis_status()&#123;</span><br><span class="line">    R_PORT=$1</span><br><span class="line">    R_COMMAND=$2</span><br><span class="line">    (echo -en &quot;INFO \r\n&quot;;sleep 1;) | nc 127.0.0.1 &quot;$R_PORT&quot; &gt; /usr/local/zabbix/redis_&quot;$R_PORT&quot;.tmp</span><br><span class="line">    REDIS_STAT_VALUE=$(grep &quot;&quot;$R_COMMAND&quot;:&quot; /usr/local/zabbix/redis_&quot;$R_PORT&quot;.tmp | cut -d &apos;:&apos; -f2)</span><br><span class="line">    echo $REDIS_STAT_VALUE </span><br><span class="line">&#125;</span><br><span class="line">help()&#123;</span><br><span class="line">    echo &quot;$&#123;0&#125; + redis_status + PORT + COMMAND&quot;</span><br><span class="line">&#125;</span><br><span class="line">main()&#123;</span><br><span class="line">    case $1 in</span><br><span class="line">        redis_status)</span><br><span class="line">            redis_status $2 $3</span><br><span class="line">                ;;</span><br><span class="line">*)</span><br><span class="line">        help</span><br><span class="line">            ;;</span><br><span class="line">    esac</span><br><span class="line">&#125;</span><br><span class="line">main $1 $2 $3</span><br></pre></td></tr></table></figure><pre><code>1.准备配置文件和redis.sh    [root@node01 zabbix]# vim etc/zabbix_agentd.conf    Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf    [root@node01 zabbix_agentd.conf.d]# vim all.conf    UserParameter=memcached_status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/redis.sh &quot;$1&quot; &quot;$2&quot; &quot;$3&quot;2.在zabbix web上添加redis_status监控模板    监控项有：        used_memory    #        used_cpu_sys   #CPU的信息类型必须是浮点数不能是字符串或者其他    图形：把监控的多个项创建各自的图形    设置触发器：在触发器项添加触发值，    聚合图形：在redis的聚合图形标签</code></pre><p>–redis监控模板<br><img src="/2018/02/05/zabbix监控系统/redis监控模板.png" alt="redis监控模板"><br>–redis图形监控<br><img src="/2018/02/05/zabbix监控系统/redis图形监控.png" alt="redis图形监控"></p><h3 id="4-监控mysql"><a href="#4-监控mysql" class="headerlink" title="4.监控mysql"></a>4.监控mysql</h3><p>监控mysql的方案有很多，这里列出procona和自定义监控mysql数据库两种方案.</p><pre><code>1.部署mysql主从(太简单,省略了)2.采用procona的插件来监控mysql</code></pre><p><a href="https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.8/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.8-1.noarch.rpm" target="_blank" rel="noopener">下载地址：</a><br><a href="https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html#installation-instructions" target="_blank" rel="noopener">安装说明</a></p><pre><code>3.安装并修改配置    [root@mysql ~]# yum install php php-mysql -y #安装php    [root@mysql ~]# rpm -ivh percona-zabbix-templates-1.1.8-1.noarch.rpm    [root@mysql zabbix_agentd.conf.d]# cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /usr/local/zabbix/etc/zabbix_agentd.conf.d/    [root@mysql ~]# vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf    &lt;?php    $mysql_user = &apos;root&apos;;    $mysql_pass = &apos;&apos;;    [root@node01 zabbix_agentd.conf.d]# /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gg    140        #配置完之后使用此命令测试是否配置成功    注意：        使用脚本测试完后会在/tmp下生成/tmp/localhost-mysql_cacti_stats.txt监控        测试文件，如果是4.将准备好的mysql监控模板导入到zabbix    由于procona插件安装时自带的模板有问题，在其基础上根据生产环境修改后再导入到zabbix上.    zbx_mysql_export_templates.xml.xml(模板文件名)    注意：        这个模板上监控项达到200多个，根据实际情况删除或禁止即可！5.关联到mysql主机上即可！</code></pre><p>–procona监控mysql<br><img src="/2018/02/05/zabbix监控系统/procona监控mysql.png" alt="procona监控mysql.png"><br>–procona监控mysql进程<br><img src="/2018/02/05/zabbix监控系统/procona监控mysql进程.png" alt="procona监控mysql进程"></p><pre><code>二：自定义监控项监控mysql主从    ##主要是监控mysql主从同步及延时!!!    ### 使用此脚本放在mysql的slave上，连接的账户密码按实际情况修改!!!</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@node04 zabbix_agentd.conf.d]# vim mysql_monitor.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">Seconds_Behind_Master()&#123;</span><br><span class="line">    NUM=`mysql -uroot -hlocalhost   -e &quot;show slave status\G;&quot;  | grep &quot;Seconds_Behind_Master:&quot; | awk -F: &apos;&#123;print $2&#125;&apos;`</span><br><span class="line">    echo $NUM</span><br><span class="line">&#125;</span><br><span class="line">master_slave_check()&#123;</span><br><span class="line">NUM1=`mysql -uroot -hlocalhost   -e &quot;show slave status\G;&quot;  | grep &quot;Slave_IO_Running&quot; | awk -F:  &apos;&#123;print $2&#125;&apos; | sed &apos;s/^[ \t]*//g&apos;`</span><br><span class="line">#echo $NUM1</span><br><span class="line">NUM2=`mysql -uroot -hlocalhost   -e &quot;show slave status\G;&quot;  | grep &quot;Slave_SQL_Running:&quot; | awk -F:  &apos;&#123;print $2&#125;&apos; | sed &apos;s/^[ \t]*//g&apos;`</span><br><span class="line">#echo $NUM2</span><br><span class="line">if test $NUM1 == &quot;Yes&quot; &amp;&amp;  test $NUM2 == &quot;Yes&quot;;then</span><br><span class="line">    echo 50</span><br><span class="line">else</span><br><span class="line">    echo 100</span><br><span class="line">fi</span><br><span class="line">&#125;</span><br><span class="line">main()&#123;</span><br><span class="line">    case $1 in</span><br><span class="line">        Seconds_Behind_Master)</span><br><span class="line">           Seconds_Behind_Master;</span><br><span class="line">           ;;</span><br><span class="line">    master_slave_check)</span><br><span class="line">       master_slave_check</span><br><span class="line">       ;;</span><br><span class="line">    esac</span><br><span class="line">&#125;</span><br><span class="line">main $1</span><br></pre></td></tr></table></figure><pre><code>1.在/usr/local/zabbix/etc/zabbix_agentd.conf.d下创建all.conf    [root@node04 zabbix_agentd.conf.d]# vim all.conf    UserParameter=mysql_monitor[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/mysql_monitor.sh &quot;$1&quot;2.修改agent.conf文件    [root@node04 zabbix_agentd.conf.d]# vim ../zabbix_agentd.conf    Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf3.在zabbix-web上添加mysql_monitor模板    如下图4.定义触发器报警值</code></pre><p>–mysql主从复制监控<br><img src="/2018/02/05/zabbix监控系统/mysql主从复制监控.png" alt="mysql主从复制监控"></p><h3 id="5-自定义监控端口和进程"><a href="#5-自定义监控端口和进程" class="headerlink" title="5.自定义监控端口和进程"></a>5.自定义监控端口和进程</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">vim process_port_check.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">    check_process()&#123;</span><br><span class="line">    NUM=`ps -ef  | grep  -v grep  | grep -v bash | grep $&#123;NAME&#125; | wc -l`</span><br><span class="line">    echo $&#123;NUM&#125;</span><br><span class="line">&#125;</span><br><span class="line">check_port()&#123;</span><br><span class="line">    ss -tnl  | grep  $&#123;PORT&#125; &amp;&gt; /dev/null</span><br><span class="line">    if [ $? -eq 0 ];then</span><br><span class="line">        echo 50</span><br><span class="line">    else </span><br><span class="line">        echo 100</span><br><span class="line">fi</span><br><span class="line">&#125;</span><br><span class="line">main()&#123;</span><br><span class="line">    case $1 in</span><br><span class="line">        process)</span><br><span class="line">            NAME=$2</span><br><span class="line">            check_process;</span><br><span class="line">            ;;</span><br><span class="line">        port)</span><br><span class="line">            PORT=$2</span><br><span class="line">            check_port;</span><br><span class="line">            ;;</span><br><span class="line">    esac</span><br><span class="line">&#125;</span><br><span class="line">main $1 $2</span><br></pre></td></tr></table></figure><pre><code>1.在/usr/local/zabbix/etc/zabbix_agentd.conf.d下创建all.conf    [root@node04 zabbix_agentd.conf.d]# vim all.conf    UserParameter=process_port[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/process_port_check.sh &quot;$1&quot; &quot;$2&quot;2.修改agent.conf文件    [root@node04 zabbix_agentd.conf.d]# vim ../zabbix_agentd.conf    Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf3.在zabbix-web上添加process_port模板    如下图，测试只添加mysql的进程和端口4.监控porthe process测试    如下图</code></pre><p>–端口和进程监控.png<br><img src="/2018/02/05/zabbix监控系统/端口和进程监控.png" alt=""></p><h3 id="6-邮件报警通知功能"><a href="#6-邮件报警通知功能" class="headerlink" title="6.邮件报警通知功能"></a>6.邮件报警通知功能</h3><pre><code>1.修改成中文报警：    报警:{TRIGGER.STATUS}    报警服务器:{HOST.NAME},IP:{HOSTNAME1},详情{ITEM.NAME}:{ITEM.VALUE}    恢复:{TRIGGER.STATUS}    恢复服务器:{HOST.NAME},IP:{HOSTNAME1},详情{ITEM.NAME}:{ITEM.VALUE}2.前三次报警发给运维，过了三次发给领导    前3分钟发给运维,且每分钟发一次    第4-8分钟发给运维部领导    第9--分钟发给开发部门领导检查：    先检查网络问题    再检查服务是不是正常</code></pre><p>–配置动作<br><img src="/2018/02/05/zabbix监控系统/配置动作.png" alt="配置动作"><br>–配置操作<br><img src="/2018/02/05/zabbix监控系统/配置操作.png" alt="配置操作"><br>–配置恢复动作<br><img src="/2018/02/05/zabbix监控系统/配置恢复动作.png" alt="配置恢复动作"><br>–邮件提示<br><img src="/2018/02/05/zabbix监控系统/邮件报警.png" alt="邮件报警"></p><h3 id="7-完善zabbix系统基础监控-CPU-内存-磁盘-模板"><a href="#7-完善zabbix系统基础监控-CPU-内存-磁盘-模板" class="headerlink" title="7.完善zabbix系统基础监控(CPU/内存/磁盘)模板"></a>7.完善zabbix系统基础监控(CPU/内存/磁盘)模板</h3><p>由于zabbix自带的系统基础监控模板不是很全，所以需要在其基础上进行优化</p><p>编写脚本替代默认模板监控系统<br>新建模板添加监控项<br>根据原有模板添加自动发现规则、图形原形和触发值原形<br>重启服务<br>验证数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#zabbix自带的Template OS Linux是没有监控磁盘读取和写入的，所以需要额外添加</span><br><span class="line">1.磁盘IO监控</span><br><span class="line">    服务器IO的写入速率和读取速率：iotop</span><br><span class="line">    #尤其是web服务器受到攻击时，web日志会瞬间达到很大；</span><br><span class="line">    [root@node04 ~]# vim /etc/sudoers</span><br><span class="line">        #Defaults   !visiblepw        #允许zabbix用户登录tty执行命令</span><br><span class="line">        zabbix  ALL = NOPASSWD: /sbin/iotop   #允许zabbix用户执行iotop命令</span><br><span class="line">    vim iotop.sh</span><br><span class="line">    #!/bin/bash</span><br><span class="line">    disk_read()&#123;</span><br><span class="line">        NUM=`/usr/bin/sudo iotop -b -n 1 | grep &quot;Total DISK READ&quot; | grep -v grep | awk  -F &quot;|&quot; &apos;&#123;print $1&#125;&apos; | awk -F &quot;:&quot; &apos;&#123;print $2&#125;&apos; | awk &apos;&#123;print $1&#125;&apos; | awk -F &quot;.&quot; &apos;&#123;print $1&#125;&apos;`</span><br><span class="line">        echo $&#123;NUM&#125;    </span><br><span class="line">    &#125;</span><br><span class="line">    disk_write()&#123;</span><br><span class="line">        NUM=`/usr/bin/sudo iotop -b -n 1 | grep &quot;Total DISK WRITE&quot;  | grep -v grep  | awk  -F &quot;|&quot; &apos;&#123;print $2&#125;&apos; | awk -F &quot;:&quot; &apos;&#123;print $2&#125;&apos; | awk &apos;&#123;print $1&#125;&apos; | awk -F &quot;.&quot; &apos;&#123;print $1&#125;&apos;`</span><br><span class="line">        echo $&#123;NUM&#125;    </span><br><span class="line">    &#125;</span><br><span class="line">    main()&#123;</span><br><span class="line">        case $1 in</span><br><span class="line">            disk_read)</span><br><span class="line">               disk_read;</span><br><span class="line">               ;;</span><br><span class="line">            disk_write)</span><br><span class="line">                disk_write;</span><br><span class="line">                ;;</span><br><span class="line">        esac</span><br><span class="line">    &#125;</span><br><span class="line">    main $1</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">##还需要做一个内存总大小，内存使用百分比，已用内存，剩余内存都监控到</span><br><span class="line">###监控脚本是把centos6和7分开来写的</span><br><span class="line">2.内存监控</span><br><span class="line">[root@node04 zabbix_agentd.conf.d]# vim memory.sh</span><br><span class="line">    #!/bin/bash</span><br><span class="line">    grep 7 /etc/redhat-release &amp;&gt; /dev/null</span><br><span class="line">    if [ $? -eq 0 ];then</span><br><span class="line">    mem_total()&#123;</span><br><span class="line">        TOTAL=`free |grep -i mem |awk &apos;&#123;print $2&#125;&apos;`</span><br><span class="line">        echo $&#123;TOTAL&#125;</span><br><span class="line">    &#125;    </span><br><span class="line">    mem_use()&#123;</span><br><span class="line">        USE=`free  |grep -i mem | awk &apos;&#123;print $3&#125;&apos;`</span><br><span class="line">        echo $&#123;USE&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mem_free()&#123;</span><br><span class="line">        FREE=`free  |grep -i mem |awk &apos;&#123;print ($4+$6)&#125;&apos;`</span><br><span class="line">        echo $&#123;FREE&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mem_usage()&#123;</span><br><span class="line">        USAGE=`free  |grep -i mem | awk &apos;&#123;print  ($3)/$2*100&#125;&apos; | awk -F &quot;.&quot; &apos;&#123;print $1&#125;&apos;`</span><br><span class="line">        echo $&#123;USAGE&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    else</span><br><span class="line">    mem_total()&#123;</span><br><span class="line">        TOTAL=`free |grep -i mem |awk &apos;&#123;print $2&#125;&apos;`</span><br><span class="line">        echo $&#123;TOTAL&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mem_use()&#123;</span><br><span class="line">        USE=`free  |grep -i mem | awk &apos;&#123;print $3&#125;&apos;`</span><br><span class="line">        echo $&#123;USE&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mem_free()&#123;</span><br><span class="line">        #FREE=`free  |grep -i mem |awk &apos;&#123;print $3+$5&#125;&apos;`</span><br><span class="line">        FREE=`free  |grep -i mem |awk &apos;&#123;print ($4+$6+$7)&#125;&apos;`</span><br><span class="line">        echo $&#123;FREE&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mem_usage()&#123;</span><br><span class="line">        USAGE=`free  |grep -i mem | awk  &apos;&#123;print  ($3)/$2*100&#125;&apos; | awk -F &quot;.&quot; &apos;&#123;print $1&#125;&apos;`</span><br><span class="line">        echo $&#123;USAGE&#125;</span><br><span class="line">    &#125;      </span><br><span class="line">    fi</span><br><span class="line">    main()&#123;</span><br><span class="line">        case $1 in </span><br><span class="line">            mem_total)</span><br><span class="line">           mem_total;</span><br><span class="line">           ;;</span><br><span class="line">        mem_use)</span><br><span class="line">            mem_use;</span><br><span class="line">            ;;</span><br><span class="line">        mem_free)</span><br><span class="line">            mem_free;</span><br><span class="line">            ;;</span><br><span class="line">        mem_usage)</span><br><span class="line">            mem_usage;</span><br><span class="line">            ;;</span><br><span class="line">        esac</span><br><span class="line">    &#125;</span><br><span class="line">    main $1</span><br></pre></td></tr></table></figure><pre><code>3.脚本准备好了(将脚本加权限)，需要准备配置文件    [root@node04 zabbix_agentd.conf.d]# vim all.conf    UserParameter=disk_total[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/iotop.sh &quot;$1&quot; &quot;$2&quot;    UserParameter=mem_status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/memory.sh &quot;$1&quot; &quot;$2&quot;4.创建zabbix web监控模板    这次是将生成环境下的内存/cpu/磁盘的导入到这里了    zbx_export_Basic_system_monitor.xml.xml    将此模板关联到需要监控的主机上即可!备注：一：磁盘的寻道时间、旋转延迟和数据传输时间：常见的机械磁盘平均寻道时间值：    7200转/分的磁盘平均物理寻道时间：9毫秒    10000转/分的磁盘平均物理寻道时间：6毫秒    15000转/分的磁盘平均物理寻道时间：4毫秒常见磁盘的平均延迟时间：    7200转的机械盘平均延迟：60*1000/7200/2 = 4.17ms    10000转的机械盘平均延迟：60*1000/10000/2 = 3ms    15000转的机械盘平均延迟：60*1000/15000/2 = 2ms每秒最大IOPS的计算方法：    7200转的磁盘IOPS计算方式：1000毫秒/(9毫秒的寻道时间+4.17毫秒的平均旋转延迟时    间)=1000/13.13=75.9 IOPS    10000转的磁盘的IOPS计算方式：1000毫秒/(6毫秒的寻道时间+3毫秒的平均旋转延迟时    间)=1000/9=111 IOPS    15000转的磁盘的IOPS计算方式：15000毫秒/(4毫秒的寻道时间+2毫秒的平均旋转延迟时    间)=1000/6=166.6 IOPS</code></pre><p>–内存使用率监控<br><img src="/2018/02/05/zabbix监控系统/自定义内存使用率监控.png" alt=""><br>–磁盘读取和写入检测<br><img src="/2018/02/05/zabbix监控系统/磁盘读取和写入.png" alt=""></p><h3 id="8-监控nginx"><a href="#8-监控nginx" class="headerlink" title="8.监控nginx"></a>8.监控nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">1.[root@node04 zabbix_agentd.conf.d]# vim nginx_status.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">nginx_status_fun()&#123;</span><br><span class="line">        NGINX_PORT=$1 #端口，函数的第一个参数是脚本的第二个参数，即脚本的第二个参数是端口号</span><br><span class="line">        NGINX_COMMAND=$2 #命令，函数的第二个参数是脚本的第三个参数，即脚本的第三个单数是命令</span><br><span class="line">        nginx_active()&#123; #获取nginx_active数量，以下相同，这是开启了nginx状态但是只能从本机看到</span><br><span class="line">                /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | grep &apos;Active&apos; | awk &apos;&#123;print $NF&#125;&apos;</span><br><span class="line">        &#125;</span><br><span class="line">        nginx_reading()&#123; #$获取nginx_reading状态的数量</span><br><span class="line">                /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | grep &apos;Reading&apos; | awk &apos;&#123;print $2&#125;&apos;</span><br><span class="line">        &#125;</span><br><span class="line">        nginx_writing()&#123;</span><br><span class="line">                /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | grep &apos;Writing&apos; | awk &apos;&#123;print $4&#125;&apos;</span><br><span class="line">        &#125;</span><br><span class="line">        nginx_waiting()&#123;</span><br><span class="line">                /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | grep &apos;Waiting&apos; | awk &apos;&#123;print $6&#125;&apos;</span><br><span class="line">        &#125;</span><br><span class="line">        nginx_accepts()&#123;</span><br><span class="line">                /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | awk NR==3 | awk &apos;&#123;print $1&#125;&apos;</span><br><span class="line">        &#125;</span><br><span class="line">        nginx_handled()&#123;</span><br><span class="line">                /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | awk NR==3 | awk &apos;&#123;print $2&#125;&apos;</span><br><span class="line">        &#125;</span><br><span class="line">        nginx_requests()&#123;</span><br><span class="line">                /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | awk NR==3 | awk &apos;&#123;print $3&#125;&apos;</span><br><span class="line">        &#125;</span><br><span class="line">        case $NGINX_COMMAND in</span><br><span class="line">                active)</span><br><span class="line">                        nginx_active;</span><br><span class="line">                        ;;</span><br><span class="line">                reading)</span><br><span class="line">                        nginx_reading;</span><br><span class="line">                        ;;</span><br><span class="line">                writing)</span><br><span class="line">                        nginx_writing;</span><br><span class="line">                        ;;</span><br><span class="line">                waiting)</span><br><span class="line">                        nginx_waiting;</span><br><span class="line">                        ;;</span><br><span class="line">                accepts)</span><br><span class="line">                        nginx_accepts;</span><br><span class="line">                        ;;</span><br><span class="line">                handled)</span><br><span class="line">                        nginx_handled;</span><br><span class="line">                        ;;</span><br><span class="line">                requests)</span><br><span class="line">                        nginx_requests;</span><br><span class="line">                        ;;</span><br><span class="line">                esac</span><br><span class="line">&#125;</span><br><span class="line">main()&#123; #主函数内容</span><br><span class="line">        case $1 in #分支结构，用于判断用户的输入而进行响应的操作</span><br><span class="line">                nginx_status) #当输入nginx-status就调用nginx_status_fun,并第二和第三个参数</span><br><span class="line">                        nginx_status_fun $2 $3;</span><br><span class="line">                        ;;</span><br><span class="line">                *) #其他输入的打印帮助信息</span><br><span class="line">                        echo $&quot;Usage: $0 &#123;tcp_status key|redis_status key | nginx_status key&#125;&quot;</span><br><span class="line">        esac #分支结束符</span><br><span class="line">&#125;</span><br><span class="line">main $1 $2 $3</span><br></pre></td></tr></table></figure><pre><code>2.脚本准备好了(将脚本加权限)，需要准备配置文件    [root@node04 zabbix_agentd.conf.d]# vim all.conf    UserParameter=nginx.status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/nginx_status.sh &quot;$1&quot; &quot;$2&quot; &quot;$3&quot;3.创建zabbix web监控模板    这次是将生成环境下的内存/cpu/磁盘的导入到这里了    nginx_status.xml    将此模板关联到需要监控的主机上即可!</code></pre><p>–nginx监控模板<br><img src="/2018/02/05/zabbix监控系统/nginx监控模板.png" alt="nginx监控模板"><br>–nginx检测1<br><img src="/2018/02/05/zabbix监控系统/nginx检测1.png" alt="nginx检测1"><br>–nginx检测2<br><img src="/2018/02/05/zabbix监控系统/nginx检测2.png" alt="nginx检测2"></p><h3 id="9-编写脚本一键安装zabbix-agent"><a href="#9-编写脚本一键安装zabbix-agent" class="headerlink" title="9.编写脚本一键安装zabbix agent"></a>9.编写脚本一键安装zabbix agent</h3><pre><code>已上传网盘</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Zabbix监控进阶-监控常用服务-自定义模板&quot;&gt;&lt;a href=&quot;#Zabbix监控进阶-监控常用服务-自定义模板&quot; class=&quot;headerlink&quot; title=&quot;Zabbix监控进阶-监控常用服务(自定义模板)&quot;&gt;&lt;/a&gt;Zabbix监控进阶-监控常用服务(自定义模板)&lt;/h3&gt;
    
    </summary>
    
      <category term="监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="zabbix监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/zabbix%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="zabbix" scheme="https://www.liukui.tech/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix基础</title>
    <link href="https://www.liukui.tech/2018/02/05/zabbix%E5%9F%BA%E7%A1%80/"/>
    <id>https://www.liukui.tech/2018/02/05/zabbix基础/</id>
    <published>2018-02-05T00:00:00.000Z</published>
    <updated>2019-03-13T09:21:26.248Z</updated>
    
    <content type="html"><![CDATA[<h3 id="zabbix介绍"><a href="#zabbix介绍" class="headerlink" title="zabbix介绍"></a>zabbix介绍</h3><a id="more"></a><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><pre><code>主要工作：    1.解决生产和测试环境遇到的问题    2.部署业务；    3.查看监控系统        查看服务是否出现问题和即将出现瓶颈等问题        如：mysql连接达到1500~2000时就变慢了；最近三个月的趋势        web服务的并发数达到一定值，就要考虑扩容了        实时监控服务是否down机，服务是否不可用，比如java服务内存溢出，tomcat由于内存溢出，导致访问异常，出现503，500等异常服务代码，如果zabbix对其做了监控，就可以实时及时的看到报警和展示，及时进行修复    4.监控系统是随着业务增加和服务器增加，在监控上不能出现瓶颈，不能因为监控系统的资源不够，导致监控项采集不完整和出故障时报警不及时等问题2.如何规划监控    在大规模集群中是通过不同的群组来管理：        1.根据不同业务分组        2.根据虚拟机/物理机分组        3.虚拟机内部又根据业务划分很多组</code></pre><h3 id="Zabbix核心任务"><a href="#Zabbix核心任务" class="headerlink" title="Zabbix核心任务"></a>Zabbix核心任务</h3><pre><code>主流监控系统功能介绍：    数据采集：周期性时序数据        1.主机/对象：服务器、路由器、交换机、存储、防火墙、IP、URL、自定义监控对象...        2.采集目标：监控项，指标数据（metrics data）    数据存储：        存储系统：            SQL: MySQL、PostgreSQL            NoSQL：MongoDB、HBase、InfluxDB、Prometheus、redis ...            rrd: Round Robin Database    数据：        历史数据: 每个监控项采集到的每个监控值        趋势数据:             趋势表里主要保留某个监控项一个小时内历史数据的最大值、最小值和平均值以及该监控项一个小时内所采集到的数据个数。    阈值：severity，可按照等级实现层级报警    告警：通过email, 短信, 微信,语音,故障自治愈            通过脚本将报警信息发送到公众号上Zabbix四大核心任务：    采集：zabbix-server, zabbix-proxy,zabbix-agent    1.agentless SNMP、Telnet、ssh、IPMI、JMX(监控tomcat)        #不能安装agent客户端的只能通过特殊协议来采集        #IPMI:服务器上的特殊接口，用来采集CPU温度和风扇转速等硬件进行监控    2.zabbix-server        核心组件，负责数据的存储、管理、查看    3.zabbix-agent        负责各节点的数据采集发送给server    4.zabbix-proxy        用于非常庞大的环境下是需要的：超过几百台服务器        多个agent--&gt;proxy--server  #可以有效减少server端的端口和CPU性能消耗;    存储:         zabbix database--&gt;mysql    展示：        zabbix web：支持图形聚合        graph -&gt; screen -&gt; slideshow(将多个screen以幻灯片的方式进行轮流展示)    告警：        host (host groups) &lt;---templates        host --&gt; items --&gt; triggers --&gt; action (conditions, operations)        #先创建模板，在模板里设置告警，然后把模板关联到某个主机上，使用模板的好处        是不需要在每个主机上都设置告警信息了.</code></pre><h3 id="1-安装Zabbix-server和数据库"><a href="#1-安装Zabbix-server和数据库" class="headerlink" title="1.安装Zabbix-server和数据库"></a>1.安装Zabbix-server和数据库</h3><pre><code>源码安装：zabbix-4.0.3.tar.gz版本1.环境准备：    安装常用命令：        [root@zabbix-server ~]# yum install vim iotop bc gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel zip unzip zlib-devel net-tools lrzsz tree ntpdate telnet lsof tcpdump wget libevent libevent-devel   安装依赖包：        [root@zabbix-server ~]# yum install gcc libxml2-devel net-snmp net-snmp-devel libevent-devel  curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel –y        [root@zabbix-server ~]# yum install /root/jdk-8u191-linux-x64.rpm            #安装java-jdk2.安装mariadb数据库    [root@mysql ~]# yum install mariadb-server mariadb -y    [root@mysql ~]# systemctl start mariadb    [root@mysql ~]# systemctl enable mariadb    [root@mysql ~]# mysql -proot123    [root@mysql ~]# MariaDB [(none)]&gt; create database zabbix character set utf8 collate utf8_bin;        #创建一个zabbix库，专门存放监控数据    [root@mysql ~]# MariaDB [(none)]&gt; grant all privileges on zabbix.* to zabbix@&quot;192.168.34.%&quot; identified by &apos;zabbix123&apos;;        #授权zabbix用户有权限访问zabbix库任何操作3.编译安装zabbix-server端    [root@zabbix-server ~]# cd /usr/local/src/    [root@zabbix-server src]# tar xf zabbix-4.0.3.tar.gz     [root@zabbix-server src]# cd zabbix-4.0.3    [root@zabbix-server zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java    [root@zabbix-server zabbix-4.0.3]# make &amp;&amp; make install    [root@zabbix-server zabbix-4.0.3]# cd /usr/local/zabbix/    [root@zabbix-server zabbix]# cd etc/    修改配置文件：        [root@zabbix-server etc]# grep &quot;^[a-Z]&quot; zabbix_server.conf        LogFile=/usr/local/zabbix//zabbix_server.log  #日志路径        DebugLevel=3                                  #日志级别        PidFile=/usr/local/zabbix/zabbix_server.pid   #pid路径        SocketDir=/usr/local/zabbix                   #zabbix目录        DBHost=192.168.34.126                     #mysql的IP地址        DBName=zabbix                             #连接的数据名        DBUser=zabbix                             #连接数据的用户                  DBPassword=zabbix123                      #连接数据库的密码        DBPort=3306                               #数据库的端口        Timeout=4                                 #        LogSlowQueries=3000                       #    准备启动脚本：        [root@node02 zabbix-4.0.3]# cp  misc/init.d/fedora/core/zabbix_* /etc/init.d/        [root@node02 zabbix-4.0.3]# cd /etc/init.d/        [root@node02 zabbix-4.0.3]# vim zabbix_server        BASEDIR=/usr/local/zabbix        PIDFILE=/usr/local/zabbix/$BINARY_NAME.pid            #将启动脚本里的zabbix的目录修改为编译安装的路径            #将pid路径修改和配置文件的路径一致(编译目录)    创建用户：        [root@node02 init.d]# useradd zabbix -s /sbin/nologin    修改zabbix编译目录权限：        [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R    初始化zabbix数据库：        [root@node02 ~]# cd /usr/local/src/zabbix-4.0.3        [root@node02 zabbix-4.0.3]# cd database/mysql/        [root@node02 mysql]# mysql -uzabbix -pzabbix123 -h192.168.34.126 zabbix &lt; schema.sql    启动zabbix:        [root@node02 zabbix]# /usr/local/zabbix/sbin/zabbix_server -c /usr/local/zabbix/etc/zabbix_server.conf            #通过编译生成目录下的二进制命令指定配置文件启动zabbix    查看端口：        [root@node02 zabbix]# ss -tnl        LISTEN     0      128               *:10051               #zabbix-server启动后监听在10051端口     </code></pre><h3 id="2-安装zabbix-web页面"><a href="#2-安装zabbix-web页面" class="headerlink" title="2.安装zabbix-web页面"></a>2.安装zabbix-web页面</h3><pre><code>zabbix的前端服务是PHP程序，需要安装httpd[root@node02 zabbix]# yum install php httpd    #安装php和httpd[root@node02 zabbix-4.0.3]# mkdir /var/www/html/zabbix    #创建zabbix目录[root@node02 zabbix]# cd /usr/local/src/zabbix-4.0.3[root@node02 zabbix-4.0.3]# cp -a frontends/php/* /var/www/html/zabbix/    #因为zabbix的前端程序都在解压的目录下，所以把其拷贝到httpd下的目录启动httpd:    [root@node02 zabbix]# systemctl start httpd访问：    http://192.168.34.118/zabbix</code></pre><p>–启动报错<br><img src="/2018/02/05/zabbix基础/启动报错.png" alt="启动报错"></p><pre><code>解决报错信息：1.安装依赖包：    [root@node02 zabbix]# yum install php-gettext php-session php-ctype php-xmlreader php-xmlwriter php-xml php-net-socket php-gd php-mysql2.更改vim /etc/php.ini参数：    post_max_size = 8M 改为 post_max_size = 16M     max_execution_time = 30 改为 max_execution_time = 300    max_input_time = 60 改为 max_input_time = 300    date.timezone = 改为 date.timezone = date.timezone = Asia/Shanghai 3.重启httpd,进入zabbix配置    注意：        如果在页面上连接mysql时出错，可以检查一下httpd_can_network_connect的值是不是on的；        [root@node02 conf]# getsebool -a | grep httpd_can_network_connect        httpd_can_network_connect --&gt; off        如果是off，需要修改成on        [root@node02 conf]# setsebool httpd_can_network_connect 1        上述状态改变只是暂时性的，一旦系统重启，该变量状态将改变回初始状态，因此，可以使用如下命令永久性改变状态：        [root@node02 conf]# setsebool -P httpd_can_network_connect_db on4.配置完成后将zabbix.conf.php放到/var/www/html/zabbix/conf下    zabbix.conf.php保存了刚才在页面上填写的信息，可以修改5.登录    账户：Admin 密码：zabbix6.登录后：    1.确认zabbix server是running状态；    2.默认会有一个报警，因为zabbix-server上的zabbix-agent进程没启动;    3.在Administartion-Users-ADMIN模板中修改语言和默认账户密码7.启动zabbix-server的agent服务    [root@node02 etc]# vim zabbix_agentd.conf    Server=127.0.0.1            #被动模式下的Server的IP    StartAgents=3               #agent进程起来之后，启动几个子进程收集日志                                #需要启动起来    ServerActive=127.0.0.1        #主动模式下的Server的IP    Hostname=Zabbix server     #当前主机的IP地址        #hostname是zabbix中用于区分监控主机的有效值，必须保留且不能重复        即一定要与web页面上的配置--&gt;主机--&gt;模板--&gt;主机名称保持一致，基于设置的hostname来监控，一般是改成IP地址8.启动zabbix-agent    [root@node02 etc]# /etc/init.d/zabbix_agentd start        #监听在10050端口    然后再web页面就可以看到主机zabbix server的ZBX为绿色正常状态了.9.字体优化    将windows下或者网上下载合适的字体上传到zabbix上    [root@node02 ~]# cd /var/www/html/zabbix/fonts/    DejaVuSans.ttf    root@node02 fonts]# grep &quot;DejaVuSans&quot; ../* -R    Binary file ../fonts/DejaVuSans.ttf matches    ../include/defines.inc.php:define(&apos;ZBX_GRAPH_FONT_NAME&apos;,        &apos;DejaVuSans&apos;); // font file name    ../include/defines.inc.php:define(&apos;ZBX_FONT_NAME&apos;, &apos;DejaVuSans&apos;);    修改方式：        1.将上传的字体改成DejaVuSans.ttf把原来的字体删除        2.将上面两个文件中调用的字体修改为上传的字体名</code></pre><h3 id="在需要监控的主机上部署zabbix-agent"><a href="#在需要监控的主机上部署zabbix-agent" class="headerlink" title="在需要监控的主机上部署zabbix-agent"></a>在需要监控的主机上部署zabbix-agent</h3><pre><code>1.环境准备：    [root@zabbix-server ~]# yum install gcc libxml2-devel net-snmp net-snmp-devel libevent-devel  curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel –y        [root@zabbix-server ~]# yum install /root/jdk-8u191-linux-x64.rpm            #安装java-jdk2.安装zabbix-agent    [root@node01 src]# tar xf zabbix-4.0.3.tar.gz    [root@node01 src]# cd zabbix-4.0.3    [root@node01 zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-agent    [root@node01 zabbix-4.0.3]# make &amp;&amp; make install    [root@node01 zabbix-4.0.3]# cd /usr/local/zabbix/3.配置zabbix-agent    [root@node01 zabbix]# cd etc/    [root@node03 etc]# vim zabbix_agentd.conf    PidFile=/usr/local/zabbix/zabbix_agentd.pid    LogFile=/usr/local/zabbix/zabbix_agentd.log    DebugLevel=3    Server=172.18.140.5        #被动模式下的server的IP    ListenPort=10050           #agent的端口    ListenIP=0.0.0.0           #agent本机监听的地址    StartAgents=3              #启用几个agent子进程用于收集数据    ServerActive=127.0.0.1     #主动模式的IP(可以是server或者proxy)    Timeout=30              #收集数据的超时时长，一定要设置成最长的30s        ##上面的选项都是agent客户端的通用配置    Hostname=192.168.34.107    ##一定要写成每个agent客户端自己的IP地址                                #因为server是依靠Hostname来区分客户端的    #AllowRoot=0    # User=zabbix    # Include=/usr/local/etc/zabbix_agentd.userparams.conf    # Include=/usr/local/etc/zabbix_agentd.conf.d/    # Include=/usr/local/etc/zabbix_agentd.conf.d/*.conf        #用于存放自定义监控项和脚本的    UnsafeUserParameters=1        #需要改成1即启用特殊字符，因为脚本里需要特殊字符    # UserParameter=        #自定义监控项(启用)4.准备启动脚本并修改    ##此处在公司是通过ansible推送到各个主机上的    ##安装的zabbix路径都是/usr/local/zabbix的，所以启动脚本也都一样    ###创建用户也是通过ansible来管理的    [root@node03 etc]# cp /usr/local/src/zabbix-4.0.3/misc/init.d/fedora/core/zabbix_agentd /etc/init.d/    ##此处在公司是通过ansible推送到各个主机上的5.创建用户    [root@node03 init.d]# useradd zabbix -s /sbin/nologin 6.修改zabbix目录权限    [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R   7.启动zabbix-agent    [root@node03 init.d]# /etc/init.d/zabbix_agentd start测试相关命令：    当把主机加入server时没有数据，可以先通过zabbix-get进行测试    [root@node02 bin]# cp /usr/local/zabbix/bin/zabbix_get /usr/bin/    [root@node02 bin]# zabbix_get -s 172.18.140.7 -p10050 -k &quot;agent.ping&quot;    1        #1表示172.18.140.7客户端时正常的</code></pre><h3 id="1-监控tomcat"><a href="#1-监控tomcat" class="headerlink" title="1.监控tomcat"></a>1.监控tomcat</h3><p>注意：<br>    1.java gateway如果要监控的后端java程序比较多，最好部署在一台单独的服务器上；<br>    2.使用阿里云上的java-gateway安装包，直接yum安装即可<br>        <a href="https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-java-gateway-4.0.1-1.el7.x86_64.rpm" target="_blank" rel="noopener">https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-java-gateway-4.0.1-1.el7.x86_64.rpm</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">1.要想监控java-tomcat,需要先在编译安装zabbix-server时加--enable-java选项;</span><br><span class="line">2.监控逻辑：</span><br><span class="line">    zabbix监控java服务的时候很特殊，并不是有agent和server直接监控的，而是在中间加</span><br><span class="line">    了一个代理层叫做java gateway，需要在tomcat服务中开启JMX服务(监听在TCP：12345</span><br><span class="line">        端口)，然后java gateway连接到JMX：12345端口，将监控项发给JMX，再将采集的数据发给zabbix-server.</span><br><span class="line"></span><br><span class="line">3.修改启动java-getway服务：</span><br><span class="line">    [root@node02 ~]# cd /usr/local/zabbix/sbin/zabbix_java/</span><br><span class="line">    [root@node02 zabbix_java]# vim settings.sh </span><br><span class="line">    LISTEN_IP=&quot;0.0.0.0&quot;         #java-gateway监听的地址</span><br><span class="line">    LISTEN_PORT=10052           #java-gateway端口</span><br><span class="line">    PID_FILE=&quot;/usr/local/zabbix/zabbix_java.pid&quot;</span><br><span class="line">    START_POLLERS=5             #启动多少线程数</span><br><span class="line">        #因为如果有后端100个java(tomcat)程序，最好设置20个线程，那就采集5次，</span><br><span class="line">        避免采集的很慢，根据实际情况修改</span><br><span class="line">    TIMEOUT=30                  ##采集数据的超时时长，一定要设置成最长的30s</span><br><span class="line">    启动：</span><br><span class="line">        [root@node02 zabbix_java]# /usr/local/zabbix/sbin/zabbix_java/startup.sh</span><br><span class="line">            #监听在10052端口</span><br><span class="line">    备注：</span><br><span class="line">        如果是以单独的服务安装的java-gateway,可以通过systemctl来控制启动关闭！</span><br><span class="line"></span><br><span class="line">4.在zabbix-server上配置java-getway服务的地址和端口</span><br><span class="line">    [root@node02 etc]# vim zabbix_server.conf</span><br><span class="line">    JavaGateway=172.18.140.5    #Java-gate的IP地址</span><br><span class="line">    JavaGatewayPort=10052       #Java-gate的端口</span><br><span class="line">    StartJavaPollers=5          #启动多少线程数要和java-gate配置文件中一致</span><br><span class="line"></span><br><span class="line">5.配置JDK环境：</span><br><span class="line">    [root@node01 ~]# tar xf jdk-8u191-linux-x64.tar.gz -C /usr/local/src/</span><br><span class="line">    [root@node01 src]# ln -sv /usr/local/src/jdk1.8.0_191/ /usr/local/jdk</span><br><span class="line">        #为了JDK升级方便，将其创建一个软链接，后期只要创建一个新的软链接即可</span><br><span class="line">    [root@node01 local]# vim /etc/profile</span><br><span class="line">    export JAVA_HOME=/usr/local/jdk</span><br><span class="line">    export TOMCAT_HOME=/apps/tomcat</span><br><span class="line">    export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$TOMCAT_HOME/bin:$PATH</span><br><span class="line">    export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar</span><br><span class="line">    [root@node01 local]# source /etc/profile</span><br><span class="line">        #是配置生效</span><br><span class="line">    [root@node01 local]# java -version  #查看是否为安装的JDK版本</span><br><span class="line"></span><br><span class="line">6.配置tomcat</span><br><span class="line">    [root@node01]# tar xf apache-tomcat-8.5.37.tar.gz -C /usr/local/src/</span><br><span class="line">    [root@node01]# cd /usr/local/src/apache-tomcat-8.5.37/</span><br><span class="line">    [root@node01 apache-tomcat-8.5.37]# cd webapps/</span><br><span class="line">    [root@node01 apache-tomcat-8.5.37]# bin/startup.sh </span><br><span class="line">        #启动tomcat服务</span><br><span class="line">7.配置tomcat监控参数</span><br><span class="line">    #修改catalina.sh启动脚本，放在第一个非注释行的前面</span><br><span class="line">    [root@node01 apache-tomcat-8.5.37]# vim bin/catalina.sh </span><br><span class="line">    CATALINA_OPTS=&quot;$CATALINA_OPTS </span><br><span class="line">    -Dcom.sun.management.jmxremote  #启用远程监控JMX</span><br><span class="line">    -Dcom.sun.management.jmxremote.port=12345   </span><br><span class="line">            #默认启动的JMX端口号，要和zabbix添加主机时候的端口一致即可</span><br><span class="line">    -Dcom.sun.management.jmxremote.authenticate=false #不使用用户名密码认证</span><br><span class="line">    -Dcom.sun.management.jmxremote.ssl=false #不使用ssl认证</span><br><span class="line">    -Djava.rmi.server.hostname=172.18.140.6&quot; </span><br><span class="line">            #tomcat主机自己的IP地址，不要写zabbix服务器的地址</span><br><span class="line">8.重新启动tomcat即可</span><br><span class="line">    [root@node01 etc]# /usr/local/tomcat/bin/startup.sh</span><br><span class="line">9.在zabbix监控页面配置</span><br><span class="line">    1.填写JMX的IP和端口</span><br><span class="line">    2.关联tomcat监控模板</span><br><span class="line">    3.导入制作好的tomcat模板，然后将主机关联到此模板即可.</span><br><span class="line">10.测试</span><br><span class="line">    如果window上安装了JDK，可以使用jconsole.exe进行登录测试JMX服务是否采集到数据</span><br><span class="line">    C:\Program Files\Java\jdk1.8.0_191\bin\jconsole.exe</span><br><span class="line">11.监控java排错方法</span><br><span class="line">    测试能否获取到java 当前已经分配的 线程数</span><br><span class="line">    # java -jar cmdline-jmxclient-0.10.3.jar - 192.168.15.203:12345 &apos;Catalina:name=&quot;http-bio-8080&quot;,type=ThreadPool&apos; currentThreadCount</span><br><span class="line">12.自制tomcat监控模板</span><br><span class="line">        busy-nio  #nio线程达到某个值时，通知给管理员</span><br></pre></td></tr></table></figure></p><p>–正常的tomcat的JMX状态<br><img src="/2018/02/05/zabbix基础/正常的tomcat的JMX状态.png" alt="正常的tomcat的JMX状态.png"></p><h3 id="2-zabbix的主动模式和被动模式"><a href="#2-zabbix的主动模式和被动模式" class="headerlink" title="2.zabbix的主动模式和被动模式"></a>2.zabbix的主动模式和被动模式</h3><p>–zabbix监控架构<br><img src="/2018/02/05/zabbix基础/zabbix监控架构.png" alt="zabbix监控架构"></p><pre><code>1.主动与被动    这是对于zabbix agent来说的工作模式    1.被动模式就是由zabbix server向zabbix agent发出指令获取数据，即zabbix     agent被动的去获取数据并返回给zabbix server，zabbix server周期性的向agent     索取数据，这种模式的最大问题就是会加大zabbix server的工作量，在数百台服务器的    环境下zabbix server不能及时获取到最新数据，但这也是默认的工作方式;        而且在server上回打开很多随机端口；    2.主动模式是有zabbix agent主动向server索取监控项，根据拿到的监控项再去采集数据然后返回给zabbix server，不再需要zabbix serve进行干预，因此主动模式在一定程度上可减轻zabbix server的压力；        主动模式下，只会向zabbix server的10051端口发出请求连接，就不会有随机端口</code></pre><h3 id="3-基于zabbix-proxy代理实现监控"><a href="#3-基于zabbix-proxy代理实现监控" class="headerlink" title="3.基于zabbix-proxy代理实现监控"></a>3.基于zabbix-proxy代理实现监控</h3><p>–zabbix主动模式<br><img src="/2018/02/05/zabbix基础/zabbix-proxy主动模式.png" alt="zabbix主动模式"></p><pre><code>1.zabbix_proxy    zabbix 是一个分布式的监控系统，支持通过代理服务器zabbix proxy收集zabbix agent的数据，然后把收集保存在本地数据库并发送给zabbix server进行统一存储和展示；2.优点：    1.更轻量，无图形化界面    2.临时保存在本地        可以独立采集数据并存储，临时的    3.易维护：配置完成后基本无需管理    4.报警通知：        代理服务器不发送邮件通知     5.独立数据库         保留少量最近数据3.编译安装zabbix-proxy</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">    1.环境准备：</span><br><span class="line">        [root@node01]#yum install gcc libxml2-devel net-snmp net-snmp-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel java-1.8.0-openjdk-devel</span><br><span class="line">    2.创建数据库</span><br><span class="line">       MariaDB [(none)]&gt; create database zabbix_proxy character set utf8 collate utf8_bin;</span><br><span class="line">       MariaDB [(none)]&gt; grant all privileges on zabbix_proxy.* to proxy@&apos;172.18.140.%&apos; identified by &apos;zabbix123&apos;;</span><br><span class="line">    3.安装zabbix-proxy</span><br><span class="line">        [root@node04 zabbix-4.0.3]# useradd zabbix -s /sbin/nologin</span><br><span class="line">        [root@node04 src]# tar xf zabbix-4.0.3.tar.gz</span><br><span class="line">        [root@node04 src]# c zabbix-4.0.3</span><br><span class="line">        [root@node04 zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-proxy --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java</span><br><span class="line">        [root@node04 zabbix-4.0.3]# make &amp;&amp; make install</span><br><span class="line">    4.初始化数据库</span><br><span class="line">        [root@node02 mysql]# mysql -uproxy -pzabbix123 -h172.18.140.7 zabbix_proxy &lt; schema.sql</span><br><span class="line"></span><br><span class="line">4.修改zabbix-proxy配置文件</span><br><span class="line">    ProxyMode=1                 #0为主动，1为被动</span><br><span class="line">    Server=172.18.140.5         #被动模式下zabbix server服务器的地址或主机名</span><br><span class="line">                    #如果proxyMode是0，就不需要填此地址</span><br><span class="line">    Hostname=zabbix-proxy-active</span><br><span class="line">        #代理服务器名称，需要与zabbix server添加代理时候的proxy name是一致的！</span><br><span class="line">    LogFile=/tmp/zabbix_proxy.log</span><br><span class="line">    DBHost=172.18.140.7         #数据库服务器地址</span><br><span class="line">    DBName=zabbix_proxy         #使用的数据库名称</span><br><span class="line">    DBUser=proxy                #连接数据库的用户名称</span><br><span class="line">    DBPassword=zabbix123        #数据库用户密码</span><br><span class="line">    DBPort=3306                 #数据库端口</span><br><span class="line">    ###################################################################</span><br><span class="line">        框中的配置只会在主动模式下生效，被动模式不生效</span><br><span class="line">    ###################################################################</span><br><span class="line">    ProxyLocalBuffer=3 </span><br><span class="line">                #已经提交到zabbix server的数据保留时间(单位小时，最大720)</span><br><span class="line">    ProxyOfflineBuffer=24 </span><br><span class="line">                #未提交到zabbix server的时间保留时间(单位小时，最大720)</span><br><span class="line">    HeartbeatFrequency=60 </span><br><span class="line">                #心跳间隔检测时间，默认60秒，范围0-3600秒，被动模式不使用</span><br><span class="line">    ConfigFrequency=5           #建议时间短一点</span><br><span class="line">                #间隔多久从zabbix server索取获取监控信息</span><br><span class="line">    DataSenderFrequency=5 #需要改长</span><br><span class="line">                #数据发送时间间隔，默认为1秒，范围为1-3600秒，被动模式不使用</span><br><span class="line">    ###################################################################    </span><br><span class="line">    StartPollers=20             #启动的数据采集器线程数量(生产环境下尽量多点)</span><br><span class="line">    StartHTTPPollers=5          #启动多少线程响应http的请求</span><br><span class="line">    JavaGateway=172.18.140.5 </span><br><span class="line">        #java gateway服务器地址,当需要监控java的时候必须配置否则监控不到数据</span><br><span class="line">    JavaGatewayPort=10052       #Javagatewa服务端口</span><br><span class="line">    StartJavaPollers=5         #启动多少个线程采集数据和java-gate一致</span><br><span class="line">    ###################################################################</span><br><span class="line">            !!!和性能相关的非常重要的两项优化!!!</span><br><span class="line">            !!!zabbix-server和zabbix-proxy都需要优化这两项!!!</span><br><span class="line">        zabbix保存监控项是放在内存中的，所以CacheSize默认的8M内存空间是不够的</span><br><span class="line">        在zabbix-proxy服务器内存较大时，一定要把这个值调大(2G/4G)！！</span><br><span class="line">    ###################################################################</span><br><span class="line">    CacheSize=2G                #保存所有主机的监控项而占用的最大内存</span><br><span class="line">    HistoryCacheSize=2G         #保存监控历史数据占用的最大内存</span><br><span class="line">    HistoryIndexCacheSize=4M   #建议改成128M</span><br><span class="line">    TrendCacheSize=128M     #建议改成128M</span><br><span class="line">    ValueCacheSize=128M     #建议改成128M</span><br><span class="line">    ###################################################################</span><br><span class="line">    HistoryCacheSize默认才16M，建议一定要改成做大的2G内存</span><br><span class="line">    ###################################################################</span><br><span class="line">    Timeout=30                  #监控项超时时间，单位为秒</span><br><span class="line">    LogSlowQueries=3000         #毫秒，多久的数据库查询会被记录到日志</span><br></pre></td></tr></table></figure><pre><code>5.授权并启动：    [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R    [root@node04 zabbix]# /usr/local/zabbix/sbin/zabbix_proxy -c /usr/local/zabbix/etc/zabbix_proxy.conf        #这里直接使用二进制命令指定配置文件启动了    或者        将yum安装的zabbix-proxy的启动脚本拷贝过来，修改里面的配置文件路径和二进制命令的路径即可启动.</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;zabbix介绍&quot;&gt;&lt;a href=&quot;#zabbix介绍&quot; class=&quot;headerlink&quot; title=&quot;zabbix介绍&quot;&gt;&lt;/a&gt;zabbix介绍&lt;/h3&gt;
    
    </summary>
    
      <category term="监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="zabbix监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/zabbix%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="zabbix" scheme="https://www.liukui.tech/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>haproxy高级配置</title>
    <link href="https://www.liukui.tech/2017/10/20/haproxy%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.liukui.tech/2017/10/20/haproxy高级配置/</id>
    <published>2017-10-20T00:00:00.000Z</published>
    <updated>2019-03-15T10:00:15.502Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Haproxy高级配置"><a href="#Haproxy高级配置" class="headerlink" title="Haproxy高级配置"></a>Haproxy高级配置</h3><a id="more"></a><h3 id="四层和七层实现透传地址"><a href="#四层和七层实现透传地址" class="headerlink" title="四层和七层实现透传地址"></a>四层和七层实现透传地址</h3><p>–四层和七层的区别<br><img src="/2017/10/20/haproxy高级配置/四层和七层的区别.png" alt="四层和七层区别"></p><p>haproxy占用内存很小 4core8G 支持几千几万的并发也就占用1~2G内存</p><pre><code>四层：    在四层负载设备中，把client发送的报文目标地址(原来是负载均衡设备的IP地址)，根据    均衡设备设置的选择web服务器的规则选择对应的web服务器IP地址，这样client就可以直接跟此服务器建立TCP连接并发送数据；七层：    七层负载均衡服务器起了一个代理服务器的作用，服务器建立一次TCP连接要三次握手，    而client要访问webserver要先与七层负载设备进行三次握手后建立TCP连接，把要访问    的报文信息发送给七层负载均衡；然后七层负载均衡再根据设置的均衡规则选择特定的we    bserver，然后通过三次握手与此台webserver建立TCP连接，然后webserver把需要的数    据发送给七层负载均衡设备，负载均衡设备再把数据发送给client；所以，七层负载均衡设备起到了代理服务器的作用；四层IP透传实现    配置段：    listen web-port-80-listen    bind 192.168.34.126:80    mode tcp                   #http七层IP透传    option  forwardfor           #如果是四层IP透传，即使开启这个也不会生效的，但不影响haproxy启动    server 172.20.141.45 172.20.141.45:8080 check inter 2000 fall 3 rise 5    server 172.20.141.44 172.20.141.44:8080 check inter 2000 fall 3 rise 5但是需要修改后端nginx的配置：    Nginx配置：    listen       80 proxy_protocol;    &apos;&quot;tcp_ip&quot;:&quot;$proxy_protocol_addr&quot;,&apos;   #TCP获取客户端真实IP日志格式</code></pre><p>–四层IP透传<br><img src="/2017/10/20/haproxy高级配置/四层IP透传.png" alt="四层IP透传"></p><pre><code>七层IP透传实现    配置段：    listen web-port-80-listen    bind 192.168.34.126:80    mode http                   #http七层IP透传    option  forwardfor          #开启IP透传选项    server 172.20.141.45 172.20.141.45:8080 check inter 2000 fall 3 rise 5    server 172.20.141.44 172.20.141.44:8080 check inter 2000 fall 3 rise 5    前提：        前提是后端的nginx/tomcat的日志中开启支持的选项!!!</code></pre><p>–七层IP透传<br><img src="/2017/10/20/haproxy高级配置/七层IP透传.png" alt="七层IP透传"></p><h3 id="基于cookie实现会话保持"><a href="#基于cookie实现会话保持" class="headerlink" title="基于cookie实现会话保持"></a>基于cookie实现会话保持</h3><pre><code>为什么要用到haproxy的cookie？    1.会话保持是当用户在一段时间之内访问前端的负载均衡时，然后就把用户调度到和上次同一个后端web服务器上，实现方式有很多种，如ip_hash,hash consistent等调度    算法！    2.ip_hash等算法调度的颗粒度过于粗糙，对于SNAT网络模型来说就更是如此；    3.但是cookie不同，cookie是由服务器发给每一个浏览器的，而且即使是在SNAT网络下        cookie也不会重复，所以说cookie的颗粒度就更适合网站了；    4.nginx只有商业版支持，haproxy却可以,基于cookie做会话保持就相当好了!Cookie实现:    1.为当前server指定cookie值，实现基于cookie的会话黏性；而且    2.cookie一定是在负载均衡上做判断的！    cookie &lt;name&gt; [ rewrite | insert | prefix ] [ indirect ] [ nocache ]  [ postonly ] [ preserve ] [ httponly ] [ secure ]  [ domain &lt;domain&gt; ]* [ maxidle &lt;idle&gt; ] [ maxlife &lt;life&gt; ]    &lt;name&gt;：cookie名称，用于实现持久连接        rewrite：重写   #之前如果有cookie就会被覆盖掉        insert：插入        prefix：前缀        nocache：当client和hapoxy之间有缓存时，不缓存cookie，如CDN具体示例：    listen web-port-80-listen    bind 192.168.34.126:80    mode http    option  forwardfor    cookie  SERVER-COOKIE  insert indirect nocache    server 172.20.141.45 172.20.141.45:8080 cookie web45 weight 2 check inter 2000 fall 3 rise 5    server 172.20.141.44 172.20.141.44:8080 cookie web44 weight 1 check inter 2000 fall 3 rise 5    server 172.20.141.43 172.20.141.43:8080 cookie web43 weight 1 check inter 2000 fall 3 rise 5    server 172.20.141.42 172.20.141.42:8080 cookie web42 weight 1 check inter 2000 fall 3 rise 5    #生产环境下的cookie我们一般在根据业务和端口来区分的!!!</code></pre><p>–cookie配置<br><img src="/2017/10/20/haproxy高级配置/cookie配置.png" alt="cookie配置"><br>–cookie调度效果<br><img src="/2017/10/20/haproxy高级配置/基于cookie的会话保持.png" alt="基于cookie的会话保持"></p><h3 id="配置HAProxy状态页"><a href="#配置HAProxy状态页" class="headerlink" title="配置HAProxy状态页"></a>配置HAProxy状态页</h3><pre><code>stats enable            #基于默认的参数启用stats pagestats hide-version      #haproxy隐藏版本stats refresh &lt;delay&gt;   #设定自动刷新时间间隔stats uri &lt;prefix&gt;      #自定义stats page uri，默认值：/haproxy?stats stats realm &lt;realm&gt;     #账户认证时的提示信息，示例：stats realm : HAProxy\ Statisticsstats auth &lt;user&gt;:&lt;passwd&gt; #认证时的账号和密码，可使用多次，    默认：no authenticationstats admin { if | unless } &lt;cond&gt; #启用stats page中的管理功能配置示例：    listen stats    mode http    bind 192.168.34.126:9999     #只允许内网IP访问    stats enable                 #启用status监控页面    log global    stats hide-version            #为了安全，隐藏版本    stats uri     /status    stats auth    admin:admin123  #验证用户和密码    stats admin if TRUE           #启用页面上的管理功能</code></pre><p>–管理页面<br><img src="/2017/10/20/haproxy高级配置/haproxy管理页面.png" alt="haproxy管理页面"></p><h3 id="修改报文首部"><a href="#修改报文首部" class="headerlink" title="修改报文首部"></a>修改报文首部</h3><pre><code>注意：    请求报文头部时http层的，所以需要定义mode http,而不是tcp在请求报文尾部添加指定首部    reqadd  &lt;string&gt; [{if | unless} &lt;cond&gt;]   #支持条件判断从请求报文中删除匹配正则表达式的首部    reqdel  &lt;search&gt; [{if | unless} &lt;cond&gt;]    reqidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 不分大小写        示例：            reqdel User-Agent:*                   #删除请求报文中的浏览器类型，这样在后端的tomcat上就看不到了在响应报文尾部添加指定首部    rspadd &lt;string&gt; [{if | unless} &lt;cond&gt;]           示例：rspadd X-Via:\ HAPorxy 从响应报文中删除匹配正则表达式的首部    rspdel  &lt;search&gt; [{if | unless} &lt;cond&gt;]    rspidel &lt;search&gt; [{if | unless} &lt;cond&gt;]     示例：         rspidel  server.* #从相应报文删除server信息        rspidel X-Powered-By:.*  #从响应报文删除X-Powered-By信息</code></pre><h3 id="HAProxy的日志配置–一般是不开启的"><a href="#HAProxy的日志配置–一般是不开启的" class="headerlink" title="HAProxy的日志配置–一般是不开启的"></a>HAProxy的日志配置–一般是不开启的</h3><pre><code>注意：    1.haroxy的日志是基于rsyslog来传输的，所以需要配置rsyslog.conf    2.haproxy虽然可以配置日志，但是不建议开启，影响haproxy性能，而且生产环境下是        通过ELK直接收集后端nginx/tomcat的日志进行分析的！1.在default配置项定义：    log 127.0.0.1  local{1-7} info #基于syslog记录日志到指定设备，级别有(err、warning、info、debug)2.配置rsyslog：    [root@haproxy]# vim /etc/rsyslog.conf     $ModLoad imudp    $UDPServerRun 514    local6.*    /var/log/haproxy.log        #打开上面两个UDP配置和日志级别以及日志存放的位置        #要注意local6必须和haproxy.conf中是一致的！3.配置HAProxy：    listen  web_port    bind 127.0.0.1:80    mode http    log global      #要注意listen和backend上要配置log global才可以记录访问信息    option tcplog    server web1  127.0.0.1:8080  check inter 3000 fall 2 rise 54.重启rsyslog服务和haproxy并访问haproxy状态页</code></pre><p>–日志信息<br><img src="/2017/10/20/haproxy高级配置/日志信息.png" alt="日志信息"></p><h3 id="对HAProxy的后端服务集群检测"><a href="#对HAProxy的后端服务集群检测" class="headerlink" title="对HAProxy的后端服务集群检测"></a>对HAProxy的后端服务集群检测</h3><pre><code>option httpchkoption httpchk &lt;uri&gt;option httpchk &lt;method&gt; &lt;uri&gt;option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt;生产配置示例：listen  web_prot_http_nodes    bind  192.168.7.102:80    mode  http    log global    option httpchk HEAD /wp-includes/js/jquery/jquery.js?ver=1.12.4 HTTP/1.0\r\nHost:\ 192.168.7.102         #通过request获取的头部信息进行匹配进行健康检测     server 192.168.7.102  192.168.7.102:80  cookie web1 check inter 3000 fall 3 rise 5     server 192.168.7.101  192.168.7.101:80  cookie web2 check inter 3000 fall 3 rise 5</code></pre><p>–健康状态检测<br><img src="/2017/10/20/haproxy高级配置/健康状态检测.png" alt="健康状态检测.png"></p><h3 id="haproxy-ACL"><a href="#haproxy-ACL" class="headerlink" title="haproxy ACL"></a>haproxy ACL</h3><pre><code>作用：    1.对接收到的报文进行匹配和过滤，基于请求报文头部中的源地址、源端口、目标地址、目标端口、请求方法、URL、文件后缀等信息内容进行匹配并执行进一步操作;acl &lt;aclname&gt;  &lt;criterion&gt;   [flags]           [operator]        [&lt;value&gt;]    acl   规则名称   匹配条件     条件标记位          具体操作符     操作对象类型ACL名称：可以使用大字母A-Z、小写字母a-z、数字0-9、冒号：、点.、中横线和下划线，并且严格区分大小写，必须Image_site和image_site完全是两个acl。Criterion-acl    &lt;criterion&gt; ：匹配条件        dst         目标IP        dst_port    目标PORT        src         源IP        src_port    源PORT        hdr &lt;string&gt; 用于测试请求头部首部指定内容        hdr_dom(host)  请求的host名称，如 www.test.com        hdr_beg(host)  请求的host开头，如 www. img. video. download. ftp.        hdr_end(host)  请求的host结尾，如 .com .net .cn        path_beg   请求的URL开头，如/static、/images、/img、/css        path_end   请求的URL中资源的结尾，如 .gif  .png  .css  .js .jpg .jpeg    &lt;flags&gt;-条件标记        -i 不区分大小写        -m 使用指定的pattern匹配方法        -n 不做DNS解析        -u 禁止acl重名，否则多个同名ACL匹配或关系        --  强制flag结束. 当字符串和某个flag相似时使用    [operator]-操作符：      整数比较：eq、ge、gt、le、lt      字符比较：      - exact match     (-m str) :字符串必须完全匹配模式      - substring match (-m sub) :在提取的字符串中查找模式，如果其中任何一个被发现，ACL将匹配      - prefix match    (-m beg) :在提取的字符串首部中查找模式，如果其中任何一个被发现，ACL将匹配      - suffix match    (-m end) :将模式与提取字符串的尾部进行比较，如果其中任何一个匹配，则ACL进行匹配      - subdir match    (-m dir) :查看提取出来的用斜线分隔（“/”）的字符串，如果其中任何一个匹配，则ACL进行匹配      - domain match    (-m dom) :查找提取的用点（“.”）分隔字符串，如果其中任何一个匹配，则ACL进行匹配     &lt;value&gt;的类型：        - Boolean #布尔值        - integer or integer range #整数或整数范围，比如用于匹配端口范围        - IP address / network #IP地址或IP范围        - string              exact –精确比较                substring—子串    www.test.com                  suffix-后缀比较                prefix-前缀比较                subdir-路径， /wp-includes/js/jquery/jquery.js                domain-域名，www.test.com        - regular expression #正则表达式        - hex block #16进制acl作为条件时的逻辑关系：- 与：隐式（默认）使用- 或：使用“or” 或 “||”表示- 否定：使用“!“ 表示   示例：    if   invalid_src invalid_port      与关系    if invalid_src || invalid_port      或    if ! invalid_src            非Acl 示例-域名匹配：  listen  web_port  bind 192.168.50.113  mode http  log global  acl  test_host  hdr_dom(host)   www.test.com  use_backend   test_host   if   test_host  default_backend default_web #以上都没有匹配到的时候使用默认backend  backend test_host    mode http    server web1 www.test.com check inter 2000 fall 3 rise 5  backend default_web    mode http    server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5Acl-源地址子网匹配    listen  web_port    bind 192.168.50.113    mode http    log global    acl ip_range_test src 192.168.4.0/24    use_backend   web2   if  ip_range_test    default_backend web1    backend web1      mode http      server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5    backend web2      mode http      server web1 192.168.50.81:8080 check inter 2000 fall 3 rise 5Acl示例-源地址访问控制    listen  web_port    bind 192.168.50.113    mode http    log global    acl block_test src 192.168.50.178     block  if  block_test    default_backend web1    backend web1      mode http      log global      server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5Acl示例-匹配浏览器    listen  web_port    bind 192.168.50.113    mode http    log global    acl block_test src 192.168.50.178    acl redirect_test hdr(User-Agent) -m sub  -i &quot;Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;    block  if  block_test    redirect prefix   http://192.168.50.178:8080 if redirect_test    default_backend web2    backend web1      mode http      log global      server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5基于Acl+文件后缀实现动静分离    listen  web_port    bind 192.168.50.113:80    mode http    acl php_server path_end  -i .php    use_backend php_server_host if php_server        #对动态资源(php)的资源请求转发到后端的php_server_host上    acl image_server path_end  -i .jpg .png .jpeg -gif      use_backend image_server_host if image_server        #对图片(忽略大小写)的访问全部转发到image_server_host上    default_backend default_host   #其他的转发到默认的后端default_host    backend default_host        mode http        server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5    backend php_server_host        mode http        server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5    backend image_server_host        mode http        server web1 192.168.50.81:8080 check inter 2000 fall 3 rise 5Acl-匹配访问路径    listen  web_port    bind 192.168.50.113:80    mode http    acl static_path  path_beg  -i  /static /images /javascript    use_backend static_path_host if static_path    default_backend default_host    backend default_host        mode http        server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5    backend static_path_host         mode http        server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5基于策略的访问控制    listen  web_port    bind 192.168.50.81:80    mode http        acl badguy_deny src 192.168.4.1    http-request deny if badguy_deny    http-request allow    default_backend default_host    backend default_host        mode http        server web1 192.168.50.81:8080 check inter 2000 fall 3 rise 5    backend static_path_host         mode http        server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5    backend image_server_host        mode http        server web1 192.168.50.81:8080 check inter 2000 fall 3 rise 5预定义acl    ACL name    Equivalent to   Usage    FALSE   always_false    never match    HTTP    req_proto_http  match if protocol is valid HTTP    HTTP_1.0    req_ver 1.0 match HTTP version 1.0    HTTP_1.1    req_ver 1.1 match HTTP version 1.1    HTTP_CONTENT    hdr_val(content-length) gt 0    match an existing content-length    HTTP_URL_ABS    url_reg ^[^/:]*://  match absolute URL with scheme    HTTP_URL_SLASH  url_beg /   match URL beginning with &quot;/&quot;    HTTP_URL_STAR   url *   match URL equal to &quot;*&quot;    LOCALHOST   src 127.0.0.1/8 match connection from local host    METH_CONNECT    method CONNECT  match HTTP CONNECT method    METH_DELETE method DELETE   match HTTP DELETE method    METH_GET    method GET HEAD match HTTP GET or HEAD method    METH_HEAD   method HEAD match HTTP HEAD method    METH_OPTIONS    method OPTIONS  match HTTP OPTIONS method    METH_POST   method POST match HTTP POST method    METH_PUT    method PUT  match HTTP PUT method    METH_TRACE  method TRACE    match HTTP TRACE method    RDP_COOKIE  req_rdp_cookie_cnt gt 0 match presence of an RDP cookie    REQ_CONTENT req_len gt 0    match data in the request buffer    TRUE    always_true always match    WAIT_END    wait_end    wait for end of content analysis示例    listen  web_port    bind 192.168.50.81:80    mode http    acl static_path  path_beg  -i  /static /images /javascript    use_backend static_path_host if  HTTP_1.1 TRUE static_path    default_backend default_hostbackend default_host    mode http    server web1 192.168.50.81:8080 check inter 2000 fall 3 rise 5backend static_path_host     mode http    server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5</code></pre><h3 id="haproxy自定义错误页面"><a href="#haproxy自定义错误页面" class="headerlink" title="haproxy自定义错误页面"></a>haproxy自定义错误页面</h3><pre><code>自定义错误页面：    defaults    option http-keep-alive    option  forwardfor    maxconn 100000    mode http    timeout connect 300000ms    timeout client  300000ms    timeout server  300000ms    errorfile 500  /usr/local/haproxy/html/500.html #自定义错误页面跳转    errorfile 502  /usr/local/haproxy/html/502.html        #502是指haproxy向后端server发请求超时了！    errorfile 503  /usr/local/haproxy/html/503.html        #503是指后端的server全down了；    #自定义完，然后创建对应目录下的各种状态码的html文件！临时重定向跳转：    errorloc 503  http://192.168.50.113/error_page/503.html        #自定义跳转到事先定义的网站上</code></pre><h3 id="haproxy支持负载https"><a href="#haproxy支持负载https" class="headerlink" title="haproxy支持负载https"></a>haproxy支持负载https</h3><pre><code>生成证书    # mkdir /usr/local/haproxy/certs    # cd /usr/local/haproxy/cert    # openssl genrsa -out haproxy.key 2048    # openssl req -new -x509 -key haproxy.key -out haproxy.crt -subj &quot;/CN=www.test.com&quot;    # cat haproxy.key  haproxy.crt &gt; haproxy.pem    # openssl x509 -in haproxy.pem -noout -text #查看证书支持ssl会话；bind *:443 ssl crt /PATH/TO/SOME_PEM_FILE   crt 后证书文件为PEM格式，且同时包含证书和所有私钥        cat  demo.crt demo.key &gt; demo.pem 把80端口的请求重向定443    bind *:80    redirect scheme https if !{ ssl_fc }    向后端传递用户请求的协议和端口（frontend或backend）    http_request set-header X-Forwarded-Port %[dst_port]    http_request add-header X-Forwared-Proto https if { ssl_fc }示例  frontend https  bind 192.168.50.113:443 ssl crt  /usr/local/haproxy/certs/haproxy.pem  use_backend web_hostbackend default_host    mode http    server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5    server web2 192.168.50.81:8080 check inter 2000 fall 3 rise 5backend web_host    mode http    http-request set-header X-Forwarded-Port %[dst_port]    http-request add-header X-Forwarded-Proto https if { ssl_fc }    server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5    server web2 192.168.50.81:8080 check inter 2000 fall 3 rise 5</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Haproxy高级配置&quot;&gt;&lt;a href=&quot;#Haproxy高级配置&quot; class=&quot;headerlink&quot; title=&quot;Haproxy高级配置&quot;&gt;&lt;/a&gt;Haproxy高级配置&lt;/h3&gt;
    
    </summary>
    
      <category term="负载均衡" scheme="https://www.liukui.tech/categories/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
      <category term="haproxy" scheme="https://www.liukui.tech/categories/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/haproxy/"/>
    
    
      <category term="LB负载均衡" scheme="https://www.liukui.tech/tags/LB%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
  </entry>
  
  <entry>
    <title>haproxy配置</title>
    <link href="https://www.liukui.tech/2017/10/20/haproxy%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.liukui.tech/2017/10/20/haproxy配置/</id>
    <published>2017-10-20T00:00:00.000Z</published>
    <updated>2019-03-15T09:29:48.827Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HAProxy"><a href="#HAProxy" class="headerlink" title="HAProxy"></a>HAProxy</h3><a id="more"></a><p><img src="/2017/10/20/haproxy配置/公有云架构.png" alt="私有云架构"></p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><pre><code>1.如上图，一般在防火墙后先是经过4层负载，只基于TCP协议的源IP、目标IP、源port、目标Port做转发；2.用户请求的url是在下面的nginx服务器上做七层负载，所以在整个架构中就有了两层负载；3.而且在HAProxy四层负载上，我们会把很多业务都放在四层负载上，所以haproxy上会根据    不同业务定义很多VIP地址(BACKEND);一个VIP再对应一个公网的IP地址；一个公网    IP再对应一个域名，这样就实现了一个负载均衡器复用的功能；4.如何避免DDOS攻击    1.如上图，可以将域名解析成多个A记录，A记录对应不同的机房，平时80%的用户请求        转发到主机房入口，备用入口可以是阿里云的SLB或者同城机房的另外一套高可用负载；    2.或者直接使用CDN，优点很明显!什么是负载均衡：    LB是一种服务或基于硬件设备等实现的高可用反向代理技术，负载均衡将特定的业务    (web服务、网络流量等)分担给指定的一个或多个后端特定的服务器或设备，从而提高了    公司业务的并发处理能力、保证了业务的高可用性、方便了业务后期的水平动态扩展。负载均衡优点：    1.Web服务器的动态水平扩展        对用户无感知    2.增加业务并发访问及处理能力        解决单服务器瓶颈问题    3.节约公网IP地址        降低IT支出成本    4.隐藏内部服务器IP        提高内部服务器安全性    5.配置简单        固定格式的配置文件    6.功能丰富        支持四层和七层，支持动态下线主机    7.性能较强        并发数万甚至数十万负载均衡软件比较：    四层负载：        LVS &gt; Haproxy &gt; nginx(1.9.0版本之后的stream功能)    七层负载        Haproxy &gt; nginx应用场景：    四层：Redis、Mysql、RabbitMQ、Memcache等    七层：Nginx、Tomcat、Apache、PHP 、图片、动静分离、API等</code></pre><h3 id="HAProxy-1"><a href="#HAProxy-1" class="headerlink" title="HAProxy"></a>HAProxy</h3><p><a href="https://www.haproxy.org/" target="_blank" rel="noopener">HAProxy官网</a></p><pre><code>1.HAProxy是一款具备高并发、高性能的TCP和HTTP负载均衡器，支持基于cookie的持久性，自动故障切换，支持正则表达式及web状态统计2.HAProxy是TCP/HTTP反向代理服务器，尤其适合于高可用性高并发环境    可以针对HTTP请求添加cookie，进行路由后端服务器        #基于cookie的会话保持颗粒度更高,nginx商业版才支持；    可平衡负载至后端服务器，并支持持久连接        #持久连接意味着会话保持可以在haproxy实现    支持基于cookie进行调度    支持所有主服务器故障切换至备用服务器        #say sorry服务器    支持专用端口实现监控服务    支持不影响现有连接情况下停止接受新连接请求        #可以对服务器打标签，不再接收请求，处理完旧请求后进行下线更新或重启    可以在双向添加，修改或删除HTTP报文首部        #修改头部报文信息达到隐藏后端web服务器版本的目的    支持基于pattern实现连接请求的访问控制        #基于正则表达式    通过特定的URI为授权用户提供详细的状态信息        #基于web页面监控服务器的状态和动态上下线服务器haproxy组成：    程序环境：        主程序：/usr/sbin/haproxy        配置文件：/etc/haproxy/haproxy.cfg        Unit file：/usr/lib/systemd/system/haproxy.service    配置段：        global：全局配置段            进程及安全配置相关的参数            性能调整相关参数            Debug参数        proxies：代理配置段            defaults：为frontend, backend, listen提供默认配置            frontend：前端，相当于nginx中的server {}            backend：后端，相当于nginx中的upstream {}            listen：同时拥有前端和后端,适用于一对一环境</code></pre><h3 id="安装HAproxy"><a href="#安装HAproxy" class="headerlink" title="安装HAproxy"></a>安装HAproxy</h3><pre><code>1.haproxy的版本区别：    1.进程管理方式不同        1.7版本之前是伪多进程，1.8以上是多进程(和nginx一样)        主进程会把内存空间共享给其他子进程，在做会话保持时，多个工作进程间的数据是共享的；如果进程之间是独立的就无法做数据共享；2.yum安装：    [root@node04 ~]# yum install haproxy -y编译安装haproxy-1.8.17:1.安装依赖包：    [root@node04 ~]# yum install gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl  openssl-devel systemd-devel net-tools vim iotop bc zip unzip zlib-devel lrzsz tree screen lsof tcpdump wget ntpdate        #由于1.8版本启动方式不同，必须安装systemd-devel包2.编译    [root@node04 src]# tar xvf haproxy-1.8.17.tar.gz &amp;&amp; cd haproxy-1.8.17    [root@node03 haproxy-1.8.17]# make ARCH=x86_64 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1  USE_CPU_AFFINITY=1  PREFIX=/usr/local/haproxy    [root@node03 haproxy-1.8.17]# make install PREFIX=/usr/local/haproxy    [root@node03 haproxy-1.8.17]# cp haproxy  /usr/sbin/        #将编译生成的二进制命令拷贝到/usr/sbin/下    [root@node03 haproxy-1.8.17]# haproxy -v        #通过命令查看编译安装的版本是否正确3.创建启动脚本：    [root@node04 ]# vim /usr/lib/systemd/system/haproxy.service    [Unit]    Description=HAProxy Load Balancer    After=syslog.target network.target    [Service]    ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg  -c -q    ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg  -p /run/haproxy.pid    ExecReload=/bin/kill -USR2 $MAINPID    [Install]    WantedBy=multi-user.target  4.准备配置文件：    [root@node04 haproxy-1.8.17]# mkdir /etc/haproxy    haproxy不支持像nginx一样的include配置文件，而是把所有的后端负载都写在一个文件中；5.创建用户：    [root@node04 haproxy-1.8.17]# useradd haproxy -s /sbin/nologin6.启动：    [root@node03 haproxy-1.8.17]# systemctl start haproxy        #haproxy支持reload，会启动一个新的进程调用新的配置，处理新的请求        老的请求处理完请求后就被回收了，和nginx一样</code></pre><h3 id="haproxy-cfg配置文件详解"><a href="#haproxy-cfg配置文件详解" class="headerlink" title="haproxy.cfg配置文件详解"></a>haproxy.cfg配置文件详解</h3><p><a href="https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#3" target="_blank" rel="noopener">详细字段说明参考</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">#########################################################################</span><br><span class="line">                    Haproxy 配置-global</span><br><span class="line">#########################################################################</span><br><span class="line">global配置参数</span><br><span class="line">        #进程及安全配置相关的参数</span><br><span class="line">        #性能调整相关参数</span><br><span class="line">pidfile  /usr/local/haproxy/haproxy.pid     #指定pid文件路径</span><br><span class="line">log 127.0.0.1  local3 info #定义全局的syslog服务器；最多可以定义两个</span><br><span class="line">chroot   /usr/local/haproxy</span><br><span class="line">            #锁定运行目录，类似于bind如果有漏洞，即使被攻击也只能访问这个目录</span><br><span class="line">deamon                  #以守护进程运行</span><br><span class="line">#stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin #socket文件</span><br><span class="line">    ##做服务器动态上下线摘除/开启服务器时，需要调用此socket文件，需要手动打开这个</span><br><span class="line">    配置，并且这个文件level必须是admin;</span><br><span class="line">user, group, uid, gid    #运行haproxy的用户身份</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">                下面这几个选项在不同版本有可能不支持</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">nbproc &lt;number&gt; #开启的haproxy进程数，与CPU物理核心数保持一致，新版本支持</span><br><span class="line">cpu-map 1 0   </span><br><span class="line">cpu-map 2 1  </span><br><span class="line">    #绑定haproxy1号、2号进程与CPU核心0、1绑定，类似于nginx的affinity</span><br><span class="line">nbthread        #指定每个haproxy进程开启的线程数，默认为每个进程一个线程；</span><br><span class="line">                #新版本可配置，配置在1.5版本，haproxy是识别不了此字段的!!</span><br><span class="line">maxconn   #1.每个haproxy进程的最大并发连接数；maxconn要设置很大(100000/65536)</span><br><span class="line">          #2.只支持配置在defaults、frontend、listen字段生效</span><br><span class="line">          #3.需要先修改limit.conf优化内核参数；</span><br><span class="line">maxsslconn      #SSL每个haproxy进程ssl最大连接数</span><br><span class="line">maxconnrate     #1.每个haproxy进程每秒最大连接数；</span><br><span class="line">                #2.只是有些业务需要限制速率时才会设置，平时是不设置的</span><br><span class="line">spread-checks   #对后端server做健康状态检查的延迟时间</span><br><span class="line">            #后端server状态check随机提前或延迟百分比时间，建议2-5(20%-50%)之间</span><br><span class="line"></span><br><span class="line">#########################################################################</span><br><span class="line">                        HAProxy Proxies配置</span><br><span class="line">#########################################################################</span><br><span class="line">defaults    </span><br><span class="line">    #1.默认配置项，针对以下的frontend、backend和lsiten生效，可以多个name</span><br><span class="line">    #2.defaults是代理后端的全局配置,最终由frontend、backend和lsiten内部再次定义的参数生效；</span><br><span class="line">    #3.根据实际情况，在default和frontend等字段设置不同的参数值</span><br><span class="line">option redispatch    </span><br><span class="line">            #当server Id对应的服务器挂掉后，强制重定向到其他健康的服务器  </span><br><span class="line">option abortonclose   </span><br><span class="line">            #当服务器CPU负载很高的时候，自动结束掉当前队列处理比较久的链接</span><br><span class="line">            #类似于内核保护机制，某个进程消耗较大的资源时会被kill掉来保证系统运行</span><br><span class="line">option  forwardfor      #开启IP透传</span><br><span class="line">            #将用户的客户端IP传递给后端web服务器上，以便web服务的日志分析</span><br><span class="line">option http-keep-alive &lt;60s&gt;  #开启会话保持</span><br><span class="line">            #在60s之内连接A服务器上如果过来不做任何操作，就会调度到后端其他服务器</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">mode http/tcp       #1.需要指定默认工作类型</span><br><span class="line">                    #2.如果default没设置，在frontend等字段一定要设置！</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">            和502代码错误相关的timeout参数</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">timeout http-keep-alive 60s #session 会话保持时间</span><br><span class="line">timeout connect 120s/300000ms    #连接到一台后端server的最长时间</span><br><span class="line">timeout client  600s/300000ms    #与客户端的最长空闲时间</span><br><span class="line">    #在keep-alive 60s内-client 600s内如果客户端没有请求，就会强制断开！</span><br><span class="line">    #如果client time设置特别短时，就会出现很多TIME_OUT的状态，因为在TCP4次断开时，哪一方先断开连接，水才会出现TIME_OUT状态！</span><br><span class="line">timeout server  600s/300000ms    #1.等待服务端的超时时长，一般要设置长一点！</span><br><span class="line">        #2.如果在600s时间内还没响应，就会报502的时间超时代码，一般是指服务间相互调用</span><br><span class="line">        #3.503是指haproxy没有检测到后端web服务器，就会返回503</span><br><span class="line"></span><br><span class="line">#timeout check 5s  #1.对后端服务器的检测超时时间</span><br><span class="line">                   #2.一般在default不配置，而是在backend上配置</span><br><span class="line">-------------------------------------------------------------------------</span><br><span class="line">                    haproxy的状态统计页面</span><br><span class="line">-------------------------------------------------------------------------</span><br><span class="line">listen stats</span><br><span class="line">mode http</span><br><span class="line">bind 0.0.0.0:9999</span><br><span class="line">stats enable</span><br><span class="line">log global</span><br><span class="line">stats uri     /haproxy-status</span><br><span class="line">stats auth    haadmin:q1w2e3r4ys</span><br><span class="line">-------------------------------------------------------------------------</span><br><span class="line">#########################################################################</span><br><span class="line">frontend &lt;name&gt;     #前端servername，类似于Nginx的一个虚拟主机server&#123;&#125;</span><br><span class="line">        #而且一定要写指定VIP和端口，不能写0.0.0.0/*:端口</span><br><span class="line">        #因为haproxy是会有N多VIP对应不同的业务；</span><br><span class="line">    &lt;name&gt;      #name一般写web-port-80易于区分是负载哪类业务！</span><br><span class="line">    bind IP:port        #前端server的IP和端口(一般写keepalived的VIP地址)</span><br><span class="line">    use_backend &lt;name&gt;  #要关联的后端哪一组backend的名称</span><br><span class="line">    mode  http/tcp      #指定负载协议类型/优先级高于default字段定义</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">backend  &lt;name&gt;     #后端服务器组，等于nginx的upstream&#123;&#125;</span><br><span class="line">    &lt;name&gt;      #backend的名称，用于在frontend中调用</span><br><span class="line">    mode  http/tcp      #指定负载协议类型/优先级高于default字段定义</span><br><span class="line">        #frontend和backend必须成对出现；类似于nginx的server和upstream</span><br><span class="line">    balance          #定义调度算法</span><br><span class="line">    server servername(IP1) IP1:PORT  check option</span><br><span class="line">    server servername(IP2) IP2:PORT  check option</span><br><span class="line">        #1.经过生成环境测试，servername是要写IP地址，自动化上下线服务器时只要取得</span><br><span class="line">        其IP地址，上下线就很方便了！</span><br><span class="line">        #2.需要要server后添加check开启健康状态检测</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">                后端server健康状态检测配置</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">check #对指定real进行健康状态检查，默认不开启</span><br><span class="line">    addr IP     #可指定的健康状态监测IP</span><br><span class="line">    port num    #指定的健康状态监测端口</span><br><span class="line">    --------------------------------------------------</span><br><span class="line">                    常用配置项</span><br><span class="line">    --------------------------------------------------</span><br><span class="line">    inter num   #健康状态检查间隔时间，默认2000ms</span><br><span class="line">    fall  num   #后端服务器失效检查次数，默认为3</span><br><span class="line">    rise num    #后端服务器从下线恢复检查次数，默认为2，一般改为5</span><br><span class="line">         #不过生产环境下，恢复次数要比下线次数要长，因为网络流量突然激增造成的网络</span><br><span class="line">         不稳定，导致可能交换机流量被打满，在网络波动没恢复之前一般多检查几次，确</span><br><span class="line">         保网络正常再加入进去！</span><br><span class="line">    weight      #默认为1，最大值为256，0表示不参与负载均衡</span><br><span class="line">    backup      #将后端服务器标记为备份状态</span><br><span class="line">    disabled    #将后端服务器标记为不可用状态</span><br><span class="line">    redir http://www.cre.tech/ </span><br><span class="line">            #1.将请求临时重定向至其它URL，只适用于http模式</span><br><span class="line">            #2.类似于nginx的url-rewrite</span><br><span class="line">    --------------------------------------------------</span><br><span class="line">    maxconn &lt;maxconn&gt;： #当前后端server的最大并发连接数</span><br><span class="line">    backlog &lt;backlog&gt;： #当server的连接数达到上限后的后援队列长度    </span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">                        listen配置</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">listen   &lt;name&gt;      #将frontend和backend合并在一起配置</span><br><span class="line">            #一个listen可以不用定义frontend和backend了！</span><br><span class="line">    &lt;name&gt;    #name一般写web-port-80-listen易于区分是负载哪类业务！</span><br><span class="line">    mode  http/tcp      #指定负载协议类型/优先级高于default字段定义</span><br><span class="line">    bind IP:port</span><br><span class="line">    balance          #定义调度算法</span><br><span class="line">    server servername(IP1) IP1:PORT  check option</span><br><span class="line">    server servername(IP2) IP2:PORT  check option </span><br><span class="line">#########################################################################</span><br><span class="line">定义注意事项： </span><br><span class="line">    1.name字段只能使用&apos;-&apos;、&quot;_&quot;、&quot;.&quot;、和&quot;:&quot;，并且严格区分大小写</span><br><span class="line">        例如：AAA和aaa是完全不同的两组服务器</span><br><span class="line">#########################################################################</span><br></pre></td></tr></table></figure><h3 id="HAproxy的调度算法"><a href="#HAproxy的调度算法" class="headerlink" title="HAproxy的调度算法"></a>HAproxy的调度算法</h3><p>–HAproxy的九种算法区别<br><img src="/2017/10/20/haproxy配置/九种算法区别.png" alt="九种算法区别"></p><pre><code>balance：     1.指明对后端服务器的调度算法，配置在default,backend,listen    2.可以现在default指定一个默认调度算法，而且haproxy的默认调度算法是轮询静态算法：    按照事先定义好的规则轮询公平调度，不关心后端服务器的当前负载、链接数和响应速度等，且无法实时修改权重，只能重启后生效;动态算法：    基于后端服务器 状态进行调度适当调整，比如优先调度至当前负载较低的服务器，且权重可以在haproxy运行时动态调整无需重启；-----------------------------------------------------------------------                        两个不常用的静态算法-----------------------------------------------------------------------1.first：    1.根据服务器在backend或者listen中的位置，自上而下进行调度，只有当第一台服务器的连接数达到上限，新请求才会分配给下一台服务，因此会忽略服务器的权重设置；    2.可以在server上指定maxconn &lt;number&gt;最大连接数2.static-rr：    基于权重的轮询调度，不支持权重的运行时调整及后端服务器慢启动，其后端主机数量没有限制；-----------------------------------------------------------------------3.source:-会话保持，小型业务    1.源地址hash，基于用户源地址hash并将请求转发到后端服务器;    2.默认为静态即取模方式，但是可以通过hash-type支持的选项更改，后续同一个源地址        请求将被转发至同一个后端web服务器，比较适用于session保持等场景    3.类似于nginx的ip_hash;    4.适用场景：        适合于访问量比较少的场景，而且不适应于SNAT网络    hash-type map-based：        取模法，基于服务器权重的hash数组取模，该hash是静态的即不支持在线调整权重        ，不支持慢启动，其对后端服务器调度均衡，缺点是当服务器的总权重发生变化时，        即有服务器上线或下线，都会因权重发生变化而导致调度结果整体改变;        缺点：            SNAT网络，ip_hash的颗粒度过于粗糙!!!    hash-type consistent：        1.一致性哈希，该hash是动态的，支持在线调整权重，支持慢启动，优点在于当服务器的总权重发生变化时，对调度结果影响是局部的，不会引起大的变动；        2.支持慢启动：            新增一台服务器时，请求是逐步调度到此服务器而不是一次性全部调度的！    hash的缺点：        不管是取模法还是一致性hash都很容易导致后端服务器负载不均衡，但是比较适合        session保持!!!-----------------------------------------------------------------------    4.uri:--缓存    基于对用户请求的uri做hash并将请求转发到后端指定服务器    mode http       #负载协议类型是http才能分析用户的uri    balance   uri    hash-type map-based：取模法    hash-type consistent：一致性哈希----------------------------------------------------------------------- 5.roundrobin：    轮询调度，适用于无状态，seesion共享或者会话保持----------------------------------------------------------------------- 6.leastconn: --适用于数据库,长连接    leastconn会根据后端服务器的负载算出最少连接的服务器，然后再调度上去，    适合于长连接----------------------------------------------------------------------- 7.url_param:    对用户请求的url中的&lt;params&gt;部分中的参数name作hash计算，并由服务器总权重相除以    后派发至某挑出的服务器；通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server；    适用场景：        适用于电商单点登录需要认证后的下一步操作！配置示例：listen  web_prot_http_nodesbind  192.168.34.117:80mode http #不支持tcp，会切换到tcp的roundrobin负载模式balance url_param  name  #基于参数name做hashhash-type consistentlog globaloption  forwardforserver 192.168.7.101   192.168.7.101:8080   check inter 3000 fall 3 rise 5server 192.168.7.102   192.168.7.102:8080   check inter 3000 fall 3 rise 5测试：    [root@node01 ~]# curl http://192.168.34.117/index.html?name=jack    tomcat1    [root@node01 ~]# curl http://192.168.34.117/index.html?name=tomcat    tomcat2----------------------------------------------------------------------- 8.hdr(&lt;name&gt;):---基于请求头部做hash(一般是host)    针对用户每个http头部(header)请求中的指定信息做hash，此处由&lt;name&gt;指定的http首    部将会被取出并做hash计算，然后由服务器总权重相除以后派发至某挑出的服务器，假如无有效的值，则会被轮询调度    hdr( Cookie、 User-Agent、host )配置示例：isten  web_prot_http_nodesbind  192.168.7.101:80mode httpbalance hdr(User-Agent)   #根据不同的浏览调度到不同的后端服务器hash-type consistentlog globaloption  forwardforserver 192.168.7.101   192.168.7.101:8080   check inter 3000 fall 3 rise 5server 192.168.7.102   192.168.7.102:8080   check inter 3000 fall 3 rise 5----------------------------------------------------------------------- 9.rdp-cookie    远程桌面的负载，使用cookie保持会话----------------------------------------------------------------------- </code></pre><h3 id="haproxy后端服务器的动态上下线"><a href="#haproxy后端服务器的动态上下线" class="headerlink" title="haproxy后端服务器的动态上下线"></a>haproxy后端服务器的动态上下线</h3><pre><code>1.需要安装socat软件    [root@node03 ~]# yum install socat2.在配置文件中启用socket    [root@node03 ~]# vim /etc/haproxy/haproxy.cfg        stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin            #启用socket    [root@node03 ~]# mkdir  /var/lib/haproxy3.动态修改    echo &quot;set weight web-port-80-listen/172.20.141.44 1&quot; | socat stdio /var/lib/haproxy/haproxy.sock# echo &quot;show info&quot; | socat stdio /var/lib/haproxy/haproxy.sock# echo &quot;get weight web_host/192.168.7.101&quot; | socat stdio /var/lib/haproxy/haproxy.sock # echo &quot;disable server  web_host/192.168.7.101&quot; | socat stdio /var/lib/haproxy/haproxy.sock # echo &quot;enable  server  web_host/192.168.7.101&quot; | socat stdio /var/lib/haproxy/haproxy.sock    注意：        在新版本中动态修改一直是一个bug!</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;HAProxy&quot;&gt;&lt;a href=&quot;#HAProxy&quot; class=&quot;headerlink&quot; title=&quot;HAProxy&quot;&gt;&lt;/a&gt;HAProxy&lt;/h3&gt;
    
    </summary>
    
      <category term="负载均衡" scheme="https://www.liukui.tech/categories/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
      <category term="haproxy" scheme="https://www.liukui.tech/categories/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/haproxy/"/>
    
    
      <category term="LB负载均衡" scheme="https://www.liukui.tech/tags/LB%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
  </entry>
  
</feed>
