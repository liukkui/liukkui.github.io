<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coool&#39;s Blog</title>
  
  <subtitle>As we watch our love grow.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.liukui.tech/"/>
  <updated>2019-04-02T13:19:04.933Z</updated>
  <id>https://www.liukui.tech/</id>
  
  <author>
    <name>空腹吃早餐</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ceph存储</title>
    <link href="https://www.liukui.tech/2019/01/18/Ceph%E5%AD%98%E5%82%A8/"/>
    <id>https://www.liukui.tech/2019/01/18/Ceph存储/</id>
    <published>2019-01-18T00:00:00.000Z</published>
    <updated>2019-04-02T13:19:04.933Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="存储" scheme="https://www.liukui.tech/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="https://www.liukui.tech/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Promethues监控</title>
    <link href="https://www.liukui.tech/2019/01/15/Promethues%E7%9B%91%E6%8E%A7/"/>
    <id>https://www.liukui.tech/2019/01/15/Promethues监控/</id>
    <published>2019-01-15T00:00:00.000Z</published>
    <updated>2019-03-13T10:26:37.922Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="promethues" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/promethues/"/>
    
    
      <category term="promethues" scheme="https://www.liukui.tech/tags/promethues/"/>
    
  </entry>
  
  <entry>
    <title>httpd脚本</title>
    <link href="https://www.liukui.tech/2018/12/30/httpd%E8%84%9A%E6%9C%AC/"/>
    <id>https://www.liukui.tech/2018/12/30/httpd脚本/</id>
    <published>2018-12-30T11:28:24.082Z</published>
    <updated>2019-01-07T11:23:00.341Z</updated>
    
    <content type="html"><![CDATA[<p>httpd服务<br><a id="more"></a></p><h3 id="httpd服务脚本"><a href="#httpd服务脚本" class="headerlink" title="httpd服务脚本"></a>httpd服务脚本</h3><pre><code>#!/bin/bash## httpd        Startup script for the Apache HTTP Server## chkconfig: - 85 15# description: The Apache HTTP Server is an efficient and extensible  \#              server implementing the current HTTP standards.# processname: httpd# config: /etc/httpd/conf/httpd.conf# config: /etc/sysconfig/httpd# pidfile: /var/run/httpd/httpd.pid#### BEGIN INIT INFO# Provides: httpd# Required-Start: $local_fs $remote_fs $network $named# Required-Stop: $local_fs $remote_fs $network# Should-Start: distcache# Short-Description: start and stop Apache HTTP Server# Description: The Apache HTTP Server is an extensible server #  implementing the current HTTP standards.### END INIT INFO# Source function library.. /etc/rc.d/init.d/functionsif [ -f /etc/sysconfig/httpd ]; then        . /etc/sysconfig/httpdfi# Start httpd in the C locale by default.HTTPD_LANG=${HTTPD_LANG-&quot;C&quot;}# This will prevent initlog from swallowing up a pass-phrase prompt if# mod_ssl needs a pass-phrase from the user.INITLOG_ARGS=&quot;&quot;# Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server# with the thread-based &quot;worker&quot; MPM; BE WARNED that some modules may not# work correctly with a thread-based MPM; notably PHP will refuse to start.# Path to the apachectl script, server binary, and short-form for messages.apachectl=/usr/sbin/apachectlhttpd=${HTTPD-/usr/sbin/httpd}prog=httpdpidfile=${PIDFILE-/var/run/httpd/httpd.pid}lockfile=${LOCKFILE-/var/lock/subsys/httpd}RETVAL=0STOP_TIMEOUT=${STOP_TIMEOUT-10}# The semantics of these two functions differ from the way apachectl does# things -- attempting to start while running is a failure, and shutdown# when not running is also a failure.  So we just do it the way init scripts# are expected to behave here.start() {        echo -n $&quot;Starting $prog: &quot;        LANG=$HTTPD_LANG daemon --pidfile=${pidfile} $httpd $OPTIONS        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; touch ${lockfile}        return $RETVAL}# When stopping httpd, a delay (of default 10 second) is required# before SIGKILLing the httpd parent; this gives enough time for the# httpd parent to SIGKILL any errant children.stop() {        status -p ${pidfile} $httpd &gt; /dev/null        if [[ $? = 0 ]]; then                echo -n $&quot;Stopping $prog: &quot;                killproc -p ${pidfile} -d ${STOP_TIMEOUT} $httpd        else                echo -n $&quot;Stopping $prog: &quot;                success        fi        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; rm -f ${lockfile} ${pidfile}}reload() {    echo -n $&quot;Reloading $prog: &quot;    if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then        RETVAL=6        echo $&quot;not reloading due to configuration syntax error&quot;        failure $&quot;not reloading $httpd due to configuration syntax error&quot;    else        # Force LSB behaviour from killproc        LSB=1 killproc -p ${pidfile} $httpd -HUP        RETVAL=$?        fi    fi    echo}# See how we were called.case &quot;$1&quot; in  start)        start        ;;  stop)        stop        ;;  status)        status -p ${pidfile} $httpd        RETVAL=$?        ;;  restart)        stop        start        ;;  condrestart|try-restart)        if status -p ${pidfile} $httpd &gt;&amp;/dev/null; then                stop                start        fi        ;;  force-reload|reload)        reload        ;;  graceful|help|configtest|fullstatus)        $apachectl $@        RETVAL=$?        ;;  *)        echo $&quot;Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|reload|status|fullstatus|graceful|help|configtest}&quot;        RETVAL=2esacexit $RETVAL  </code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;httpd服务&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>HTTP协议</title>
    <link href="https://www.liukui.tech/2018/12/18/HTTP%E5%8D%8F%E8%AE%AE/"/>
    <id>https://www.liukui.tech/2018/12/18/HTTP协议/</id>
    <published>2018-12-18T00:00:00.000Z</published>
    <updated>2019-01-22T11:55:18.830Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HTTP协议和APACHE原理"><a href="#HTTP协议和APACHE原理" class="headerlink" title="HTTP协议和APACHE原理"></a>HTTP协议和APACHE原理</h3><p>Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等<br>本文说的是HTTP SERVER<a href="http://www.apache.org/" target="_blank" rel="noopener">apache</a><br><a id="more"></a><br>HTTP2.4的官方文档<a href="http://httpd.apache.org/docs/2.4/" target="_blank" rel="noopener">http2.4文档：安装，模块，指令等说明</a><br>HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a><br><!--more--></p><h3 id="http协议-应用层协议-主流http-1-1版本"><a href="#http协议-应用层协议-主流http-1-1版本" class="headerlink" title="http协议:应用层协议,主流http/1.1版本"></a>http协议:应用层协议,主流http/1.1版本</h3><h4 id="http协议的版本区别"><a href="#http协议的版本区别" class="headerlink" title="http协议的版本区别"></a>http协议的版本区别</h4><p>http0.9、http1.0、http1.1和http2.0的版本区别</p><ul><li><p>http/0.9:</p><blockquote><p>只有一个GET命令，且只能回应<em>.html文件格式，像</em>.txt等都不支持</p></blockquote></li><li><p>http/1.0:效率太低</p><blockquote><p>1.支持cache, MIME(支持各种资源类型), method<br>2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低<br>3.引入了POST命令和HEAD命令，头部信息和<br>4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用</p></blockquote></li><li><p>http/1.1:主流使用版本</p><blockquote><p>1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭，<br>  对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性</p><pre><code>这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求</code></pre><p>2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率<br>3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)<br>4.缺点：<br>  同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象<br>5.解决队头堵塞的办法：<br>  为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等<br>6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度:</p><pre><code>不带状态怎么理解？http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点</code></pre></blockquote></li><li><p>http/2.0：解决 HTTP/1.1效率不高的问题</p><blockquote><p>1.头信息和数据体都是二进制，称为头信息帧和数据帧<br>2.和http1.1区别：请求不需要排队，提高效率<br>  复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）<br>3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度<br>4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息)</p></blockquote></li></ul><h3 id="HTTP工作机制"><a href="#HTTP工作机制" class="headerlink" title="HTTP工作机制"></a>HTTP工作机制</h3><ul><li>工作机制主要分为两步：请求和响应<blockquote><p>http请求：http request<br>http响应：http response<br>一次http事务：请求<-->响应</--></p></blockquote></li><li>Web资源：web resource<br>一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资<br>源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源<br>的集合<blockquote><p>静态页面/文件：无需服务端做出额外处理;</p><pre><code>服务器端是什么样传到客户端就是什么样，比如下面这些比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi只不过浏览器有时会解析出来以好看的页面展示给用户</code></pre><p>动态页面/文件：服务端执行程序，返回执行的结果</p><pre><code>服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果文件后缀：.php, .jsp ,.asp,.sh等将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户</code></pre></blockquote></li><li><p>提高HTTP连接性能</p><blockquote><p>并行连接：通过开多个TCP连接发起并发的HTTP请求<br>持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，<br>管道化连接：通过共享TCP连接发起并发的HTTP请求<br>复用的连接：交替传送请求和响应报文（实验阶段）</p></blockquote></li><li><p>HTTP协议的其他相关技术</p></li><li><p>1.URI：一般把URI认为是URL<br>URI: Uniform Resource Identifier 统一资源标识，分为URL和URN</p><blockquote><p>1.URN: Uniform Resource Naming，统一资源命名</p><pre><code>如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名</code></pre><p>2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置</p><pre><code>如输入一个网址，能具体体现出这个资源在互联网上的位置</code></pre><p>两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址</p></blockquote></li><li><p>URL的组成<br>scheme://user:password@host:port/path;params?query#frag</p><blockquote><p>scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等<br>user:用户，某些方案访问资源时需要的用户名<br>password:密码，用户对应的密码，中间用：分隔<br>Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析<br>port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080<br>/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔<br>params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对<br>query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能<br>frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔</p></blockquote></li><li><p>网站访问量</p><blockquote><p>1.IP(独立IP)：即Internet Protocol,指独立IP数。</p><pre><code>如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个</code></pre><p>2.PV(访问量)： 即Page View, </p><pre><code>页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量一般为了博客为了好看的访问量，都是统计PV量</code></pre><p>3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。</p><pre><code>网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1</code></pre></blockquote></li></ul><h3 id="Web服务请求处理步骤"><a href="#Web服务请求处理步骤" class="headerlink" title="Web服务请求处理步骤"></a>Web服务请求处理步骤</h3><p>很切合实际生活：比如<br>当我们打开一个浏览器，输入一个<a href="http://www.taobao.com，在互联网后台发生了什么？" target="_blank" rel="noopener">www.taobao.com，在互联网后台发生了什么？</a><br>这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图<br><img src="/2018/12/18/HTTP协议/web服务请求处理步骤.png" alt="web请求步骤"></p><p>当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程<br>每个过程都是一段需要原理详细描述的.</p><h4 id="一次完整的http请求处理过程"><a href="#一次完整的http请求处理过程" class="headerlink" title="一次完整的http请求处理过程"></a>一次完整的http请求处理过程</h4><pre><code>1.建立连接：接收或拒绝连接请求2.接收请求：接收客户端请求报文中对某资源的一次请求的过程Web访问响应模型（Web I/O）    单进程I/O模型：访问量不大        启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应        会造成请求排队现象，只适用于访问并发不大的情况    多进程I/O模型：        系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求        如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点        而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的    复用I/O结构：        开启多个进程进程，而一个进程又同时监控N个连接请求        只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗        实现方法：多线程模型和事件驱动        多线程模型：一个进程生成N个线程，每线程响应一个连接请求        事件驱动：一个进程处理N个请求    复用的多进程I/O模型：        启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求        充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的        nginx使用的复用多进程I/O模型</code></pre><font size="3" color="#FF0000"><br>    1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程<br>    2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应<br>    避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费<br>    同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题<br></font><p><img src="/2018/12/18/HTTP协议/web访问响应的四种模型.png" alt="web访问响应四种模型"><br>参考下面的HTTP的MPM三种工作模式<a href=""></a></p><pre><code>3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理    分析元数据：请求报文首部信息获得method    &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt;    HEADERS 格式 name:value    &lt;request body&gt;    通过method来响应用户请求，比如下载(get)，上传等信息    HTTP常用请求方式，Method        GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS4.访问资源：    服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源    在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件    web服务器资源路径映射方式：        (a) docroot        (b) alias        (c) 虚拟主机docroot        (d) 用户家目录docroot5.构建响应报文：    一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体   1）响应实体        描述了响应主体MIME类型的Content-Type首部        描述了响应主体长度的Content-Length   2）URL重定向        web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径   3）MIME类型   当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文    将构建完的响应报文发送给用户    将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户    用户再层层解封装获得index.html的内容7.记录日志    最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务    通过在/var/log/httpd/acess_log日志中记录http的响应记录数    方便分析日志统计该网站的IP，PV量等信息</code></pre><h3 id="Http协议"><a href="#Http协议" class="headerlink" title="Http协议"></a>Http协议</h3><pre><code>http协议    http/0.9, http/1.0, http/1.1, http/2.0http协议：stateless 无状态    服务器无法持续追踪访问者来源解决http协议无状态方法    cookie 客户端存放    session 服务端存放http事务：一次访问的过程    请求：request    响应：response</code></pre><h3 id="Session和Cookie的区别"><a href="#Session和Cookie的区别" class="headerlink" title="Session和Cookie的区别"></a>Session和Cookie的区别</h3><pre><code>前言:    HTTP是一种无状态的协议，为了分辨链接是谁发起的，就需要我们自己去解决这个问题。    不然有些情况下即使是同一个网站我们每打开一个页面也都要登录一下。而Session和    Cookie就是为解决这个问题而提出来的两个机制。应用场景:    1.日常登录一个网站，今天输入用户名密码登录了，第二天再打开很多情况下就直接打开      了。这个时候用到的一个机制就是cookie。    2.session的一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而      服务器端如何判别呢，所以也需要存储一些信息，这里就用到了session。Cookie的原理：    HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。    也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。    这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设    计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行    保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在    请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服    务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端    保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报    文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，    会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，    最后得到之前的状态信息。    通俗讲，Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时    候减少一些步骤。另外一个更准确的说法是：Cookies是服务器在本地机器上存储的小段文    本并随每一个请求发送至同一个服务器，是一种在客户端保持状态的方案。session的原理：    session就是一种保存上下文信息的机制，她是针对每一个用户的，session的内容在服    务器端，通过sessionId来区分不同的客户，session是以cookie或url重写为基础的，    默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie，我们成为session     cookie，以区分persistent coookies，注意session cookie是存储于浏览器内存中的    ，并不是写到硬盘上的；我们通常是看不见JSESSIONID的，但是当我们禁用浏览器的    cookie后，web服务器会采用url重写的方式传递sessionid，我们就可以在浏览器看到    sessionid=HJHADKSFHKAJSHFJ之类的字符串；session cookie针对某一次会话而言，会话结束session cookie也就消失了　session与cookie的区别：　　1.session保存在服务器，客户端不知道其中的信息；cookie保存在客户端，服务端可以        知道其中的信息　　2.session中保存的是对象，cookie中保存的是字符串　　3.session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个    地方都可以访问到；而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不道德session与cookie的联系：　　session是需要借助cookie才能正常工作的，如果客户端完全禁止cookie，session将失    效</code></pre><h3 id="Http应用层的报文头部-又分请求报文和响应报文两种"><a href="#Http应用层的报文头部-又分请求报文和响应报文两种" class="headerlink" title="Http应用层的报文头部:又分请求报文和响应报文两种"></a>Http应用层的报文头部:又分请求报文和响应报文两种</h3><p>-HTTP请求报文头部<br><img src="/2018/12/18/HTTP协议/请求报文头部.png" alt="HTTP请求报文头部"></p><pre><code>开始行    方法：method        GET： 从服务器获取一个资源        HEAD： 只从服务器获取文档的响应首部        POST： 向服务器输入数据，通常会再由网关程序继续处理        PUT： 将请求的主体部分存储在服务器中，如上传文件        DELETE： 请求删除服务器上指定的文档        TRACE： 追踪请求到达服务器中间经过的代理服务器        OPTIONS：请求服务器返回对指定资源支持使用的请求方法    URL:路径首部行实体行</code></pre><p>-HTTP响应报文头部<br><img src="/2018/12/18/HTTP协议/响应报文头部.png" alt="HTTP响应报文头部"></p><pre><code>开始行    版本：version        HTTP/&lt;major&gt;.&lt;minor&gt;1.1/2等等    状态码：        三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况    短语：        状态码所标记的状态的简要描述首部行实体行</code></pre><h3 id="Http常见的状态码和状态码分类"><a href="#Http常见的状态码和状态码分类" class="headerlink" title="Http常见的状态码和状态码分类"></a>Http常见的状态码和状态码分类</h3><pre><code>status(状态码)：    1xx：100-101 信息提示    2xx：200-206 成功    3xx：300-305 重定向    4xx：400-415 错误类信息，客户端错误    5xx：500-505 错误类信息，服务器端错误200： 成功，请求数据通过响应报文的entity-body部分发送;OK301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资      源现在所处的新位置；Moved Permanently302： 响应报文Location指明资源临时新位置 Moved Temporarily304： 如果之前访问一个网站，在本机上有缓存了，当再次访问时，就会出现304的状态码，      提示本地有不需要再去服务器上下载页面401： 需要输入账号和密码认证方能访问资源；Unauthorized403： 没有权限访问，请求被禁止了；Forbidden404： 服务器无法找到客户端请求的资源；要访问的文件不存在500： 服务器内部错误；Internal Server Error502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；Bad Gateway503： 服务不可用，临时服务器维护或过载，服务器无法处理请求      可能是服务器down机了，或者http服务关闭了504： 网关超时；转给后端服务器时，时间太长</code></pre><h3 id="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"><a href="#curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因" class="headerlink" title="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"></a>curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因</h3><pre><code>curl是基于URL语法在命令行方式下工作的文件传输工具1.它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。2.curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器，cookies，用户名/密码认证,下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling）3.还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等4.curl的强大在于能模拟各种浏览器自定义请求报文头部等信息，来访问某些控制严格的网站curl [options] [URL...]    -A/--user-agent &lt;string&gt; 冒充浏览器类型，实际上在请求报文修改了User-Agent        curl -A &apos;IE20&apos; http://192.168.34.103在http日志中可看到        一般用于测试访问网站或者爬虫功能要使用不同浏览器访问    -e/--referer &lt;URL&gt; 来源网址，防盗链相关        比如，伪装从百度跳转的192.168.34.103        curl -e &apos;www.baidu.com&apos; http://192.168.34.103    --cacert &lt;file&gt; CA证书 (SSL)    -k/--insecure 允许忽略证书进行 SSL 连接    --compressed 要求返回是压缩的格式    -H/--header &lt;line&gt;自定义首部信息访问网站    -i 显示页面内容，包括报文首部信息    -I/--head 只显示响应报文首部信息    -D/--dump-header &lt;file&gt; 将url的header信息存放在指定文件中，重定向    --basic 使用HTTP基本认证，401认证    -u/--user &lt;user[:password]&gt;设置服务器的用户和密码    -L 如果有3xx响应码，重新发请求到新位置        如果访问的网页被重定向到其他地方时，系统只会提示网页被重定向了，并不会跳转        -L就可以请求到新的页面上    -O 使用URL中默认的文件名保存文件到本地    -o &lt;file&gt; 将网络文件保存为指定的文件中    --limit-rate &lt;rate&gt; 设置传输速度    -0/--http1.0 数字0，使用HTTP 1.0    -v/--verbose 更详细    -C 选项可对文件使用断点续传功能    -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中    -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址    -X/--request &lt;command&gt; 向服务器发送指定请求方法    -U/--proxy-user &lt;user:password&gt; 代理服务器用户和密码    -T 选项可将指定的本地文件上传到FTP服务器上    --data/-d 方式指定使用POST方式传递数据    -b name=data 从服务器响应set-cookie得到值，返回给服务器elinks工具：    字符界面的浏览器，显示页面内容和源码等    elinks [OPTION]... [URL]...    -dump: 非交互式模式，将URL的内容输出至标准输出        比如有些网站是不允许复制的，通过-dump就可以把网站页面文字抓取到本地了        elinks -dump www.baidu.com        不过一般都是用js脚本限制了复制功能，在浏览器关闭js，或查看源码都可以    -source:打印源码</code></pre><h3 id="HTTP介绍"><a href="#HTTP介绍" class="headerlink" title="HTTP介绍"></a>HTTP介绍</h3><p>特性：<br>高度模块化：core + modules<br>DSO: Dynamic Shared Object 动态加/卸载<br>MPM：multi-processing module多路处理模块</p><h3 id="HTTP的三种工作模型：MPM工作模式"><a href="#HTTP的三种工作模型：MPM工作模式" class="headerlink" title="HTTP的三种工作模型：MPM工作模式"></a>HTTP的三种工作模型：MPM工作模式</h3><font size="3" color="#FF0000"><br>多用途的处理模块，三种模型分别是，默认使用prefork模型<br>因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型<br></font><h3 id="1-prefork：多进程I-O模型，每个进程响应一个请求，默认模型"><a href="#1-prefork：多进程I-O模型，每个进程响应一个请求，默认模型" class="headerlink" title="1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型"></a>1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型</h3><pre><code>一个主进程：生成和回收n个子进程，创建套接字，不响应请求多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个，消耗比较大内存资源受限于并发访问控制的内部系统调用机制：        select()；内生使用限制最多只能使用1024个描述符，所以最多也就1024个进程        epoll();Prefork MPM: 预派生模式，有一个主控制进程，然后生成多个子进程，使用select模型，最大并发1024，每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定，可以设置最大和最小进程数，是最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景。优点：稳定缺点：慢，占用资源，不适用于高并发场景配置文件原内容：&lt;IfModule mpm_prefork_module&gt;    StartServers           5 #定义apache服务在启动时启动的子进程数量    MinSpareServers         5 #定义最小空闲进程数，空闲进程就是没有处理用户请求的进程数    MaxSpareServers        10 #定义最大空闲进程数    MaxRequestWorkers      250 #定义在prefork模式下的最大并发连接数，表示了apache的最大并发处理能力，超过的连接请求将被排队等候处理。    MaxConnectionsPerChild   0  #进程生命周期内，处理的最大请求数目。达到该数目后，进程将死掉。如果设置    为0，表示没有限制。该参数的意义在于，避免了可能存在的内存泄露带来的系统问题。&lt;/IfModule&gt;如果确定合适的MaxRequestWorkers呢？首先，通过top命令查看apache进程占用的资源，主要看%CPU和%MEM这两个指标，例如，每个进程的CPU占用率不超过1%，每个进程的内存占用率不超过2%，考虑内存限制，比较合适的apache进程数量为50个，然后，逐步测试最大值。通过观测得来的CPU和内存的指标有一定的误差，一般可以适当调节这个数值，例如调到1.5或者2倍，再通过峰值场景下的机器是否卡顿来判断是继续上调还是下调。</code></pre><p><img src="/2018/12/18/HTTP协议/Prefork.png" alt="Prefork"></p><h3 id="2-worker：复用的多进程I-O模型-多进程多线程，IIS使用此模型"><a href="#2-worker：复用的多进程I-O模型-多进程多线程，IIS使用此模型" class="headerlink" title="2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型"></a>2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型</h3><pre><code>一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！woker MPM：是一种多进程和多线程混合的模型，有一个控制进程，启动多个子进程，每个子进程里面包含固定的线程，使用线程程来处理请求，当线程不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求，由于其使用了线程处理请求，因此可以承受更高的并发。优点：相比prefork 占用的内存较少，可以同时处理更多的请求缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生）配置文件原内容详解：&lt;IfModule mpm_worker_module&gt;    StartServers         3   # #定义apache服务在启动时启动的子进程数量，默认是3个     MinSpareThreads      75   # 整个控制进程保持最小数的空闲线程数    MaxSpareThreads      250  # 整个控制进程保持最大数的空闲线程数    #ThreadLimit        64   # 每个子进程可以启动的线程数量上限值，默认没有设置    ThreadsPerChild      25   # 每个子进程启动的线程默认数量，开启启动两个子进程每个子进程25个 线程，就是apache 启动后开启25个线程。    MaxRequestWorkers    400   # 所有子进程加起来的线程数量最大值，数量等于最大启动的进程数*ThreadsPerChild(每个进程的线程数)    MaxConnectionsPerChild   0  # 每个子进程被请求多少次服务后被kill掉重新生成一个新的子进程，为了解决内存回收方面的问题，0为不设置&lt;/IfModule&gt;</code></pre><p><img src="/2018/12/18/HTTP协议/Worker.png" alt="Worker"></p><h3 id="3-event：事件驱动模型（worker模型的优化-worker模型的变种）"><a href="#3-event：事件驱动模型（worker模型的优化-worker模型的变种）" class="headerlink" title="3.event：事件驱动模型（worker模型的优化,worker模型的变种）"></a>3.event：事件驱动模型（worker模型的优化,worker模型的变种）</h3><pre><code>event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用每一个cpu核心生成一个进程；一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n            注意这里的m*n和work的m*n是不同的机制相比较worker的有点：有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力event MPM：Apache中最新的模式，属于事件驱动模型(epoll)，每个进程响应多个请求，在现在版本里的已经是稳定可用的模式。它和worker模式很像，最大的区别在于，它解决了keep-alive场景下，长期被占用的线程的资源浪费问题（某些线程因为被keep-alive，空挂在哪里等待，中间几乎没有请求过来，甚至等到超时）。event MPM中，会有一个专门的线程来管理这些keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放。这样增强了高并发场景下的请求处理能力。event只在有数据发送的时候才开始建立连接，连接请求才会触发工作线程，即使用了TCP的一个选项，叫做延迟接受连接TCP_DEFER_ACCEPT，加了这个选项后，若客户端只进行TCP连接，不发送请求，则不会触发Accept操作，也就不会触发工作线程去干活，进行了简单的防攻击（TCP连接）,可以使用Telnet进行测试验证：主机192.168.10.130为客户端机器，192.168.10.131为apache服务器机器使用event模式：     在192.168.10.130上telnet 192.168.10.131 80，然后在192.168.10.130客户端机器上使用netstat查看，发现连接已经建立，处于ESTABLISHED状态，然后再到apache服务器192.168.10.131使用netstat查看，发现是处于SYN_RECV状态。优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放 缺点：没有线程安全控制配置文件内容：&lt;IfModule mpm_event_module&gt;    StartServers           3  #apache服务启动的子进程数，默认3个    MinSpareThreads         75  #控制进程保持最小的空闲线程数    MaxSpareThreads        250  #控制进程保持的最大空闲线程数    ThreadsPerChild         25  #每个子进程启动的线程数    MaxRequestWorkers       400  #并发最大请求数，也就是所有子进程加起来的线程数量，woker模式下的    400就是并发400，但是由于是异步处理请求的，因此这里的400比woker模型下的并发处理速度要快很多，因为event省略了工作线程的会话保持。    MaxConnectionsPerChild    0  #每个子进程请求多少次以后被kill掉重新生成一个新的子进程。&lt;/IfModule&gt;</code></pre><p><img src="/2018/12/18/HTTP协议/event.png" alt="event"></p><pre><code>注意：    event模型的强大的I/O机制    httpd从设计上就默认支持prefork    而nginx从设计上就支持event事件驱动模型</code></pre><h3 id="进程工作的角色切换"><a href="#进程工作的角色切换" class="headerlink" title="进程工作的角色切换"></a>进程工作的角色切换</h3><p><img src="/2018/12/18/HTTP协议/进程角色切换原理.png" alt="进程间的角色切换"></p><h3 id="Httpd的功能特性"><a href="#Httpd的功能特性" class="headerlink" title="Httpd的功能特性"></a>Httpd的功能特性</h3><p>httpd的常见特性：</p><ul><li>虚拟主机：在一个物理服务器上搭建多个网站<br>  IP、Port、FQDN</li><li>CGI：Common Gateway Interface，通用网关接口<br>  通过CGI接口处理动态的程序处理</li><li>反向代理<br>  当有用户访问量大时，在前端有一个服务器充当调度器的角色<br>  通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息<br>  看不到后端真正提供服务的服务器群</li><li>负载均衡</li><li>路径别名</li><li>丰富的用户认证机制<br>  basic<br>  digest</li><li>支持第三方模块</li></ul><h3 id="Httpd2-4新特性和安装以及配置"><a href="#Httpd2-4新特性和安装以及配置" class="headerlink" title="Httpd2.4新特性和安装以及配置"></a>Httpd2.4新特性和安装以及配置</h3><pre><code>新特性    MPM支持运行为DSO机制；以模块形式按需加载        在centos7上的httpd2.4上只有一个二进制程序            /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可        但是在centos6上的httpd2.2版本：            每个MPM模式都有各自对应的二进制程序                /usr/sbin/httpd                /usr/sbin/httpd.event                /usr/sbin/httpd.worker            如果更改MPM的模式，是需要改对应的二进制程序的    event MPM生产环境可用    异步读写机制    支持每模块及每目录的单独日志级别定义    每请求相关的专用配置    增强版的表达式分析式    毫秒级持久连接时长定义：httpd2.2只能精确到秒级别        上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的        所以在http中是可以定义连接时长(时长和传输请求两种方式)的    基于FQDN的虚拟主机不需要NameVirutalHost指令        httpd2.2创建虚拟主机时还需要NameVirutalHost指令        httpd2.4就不需要了    新指令，AllowOverrideList    支持用户自定义变量    更低的内存消耗</code></pre><h3 id="Httpd2-4的具体安装和配置"><a href="#Httpd2-4的具体安装和配置" class="headerlink" title="Httpd2.4的具体安装和配置"></a>Httpd2.4的具体安装和配置</h3><p>Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了<br>还支持第三方的模块，按需加载模块<br>存放模块的路径：/etc/httpd/modules</p><pre><code>CentOS7程序环境安装：httpd-2.4    yum install httpd     yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档主要配置文件：    /usr/sbin/httpd     httpd的主程序文件    /usr/lib/systemd/system/httpd.service   httpd的启动单元文件    /etc/httpd/conf/httpd.conf              主要配置文件        配置文件里的路径都是以/etc/httpd/为参考点的    /etc/httpd/conf.d/*.conf    /etc/httpd/conf.modules.d/00-mpm.conf    mpm相关    /etc/httpd/conf.modules.d/00-proxy.conf  配置代理相关    /etc/httpd/conf.modules.d/00-systemd.conf     /etc/httpd/conf.modules.d/01-cgi.conf    CGI相关    /var/cache/httpd    httpd的缓存目录    /var/log/httpd      httpd的日志文件目录            access_log: 访问日志            error_log：错误日志    /etc/httpd/modules  httpd的模块存放路径，软件比较复杂    /usr/lib64/httpd/modules   也是httpd的模块存放路径        两个模块的路径实际上是软链接关系    /var/www/html       httpd存放网页的目录：默认index.html帮助文档包：在没有网络时查看帮助文档，建议安装    httpd-manual检查配置文件语法：    httpd –t    类似DNS的rndc语法检查功能    sudo：visudo功能    ansible:ansible -C|--check 执行前检查语法功能    cobbler 也有httpd的控制和启动命令    systemctl enable|disable httpd.service    systemctl {start|stop|restart|status|reload} httpd.service    备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作        有时reload是无效的，只能restart服务</code></pre><h3 id="Httpd2-4的常见配置"><a href="#Httpd2-4的常见配置" class="headerlink" title="Httpd2.4的常见配置"></a>Httpd2.4的常见配置</h3><ul><li><p>1.显示服务器版本信息HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a></p><p>  主要组成:</p><pre><code>Global Environment   全局配置Main server configuration   一个服务器上搭建一个网站叫主服务器virtual host   虚拟主机，一台主机上搭建多个网站</code></pre></li></ul><p>练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)<br>egrep -v ‘^ <em>#.</em>|^$’ /etc/httpd/conf/httpd.conf</p><font size="3" color="#FF0000"><br>常见配置一般都在/etc/httpd/conf/httpd.conf的文件中<br>没有的配置选项可以加在httpd.conf文件最后，也可以放在<br>/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf<br>下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加<br></font><ul><li>1.显示服务器版本信息<br>  访问<a href="http://192.168.34.103" target="_blank" rel="noopener">http://192.168.34.103</a><br>  打开f12调试模式，可以看到回应头的信息中带有apache的版本信息<br>  也可以通过curl -I <a href="http://192.168.34.103来显示头信息" target="_blank" rel="noopener">http://192.168.34.103来显示头信息</a><br>  可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全<br>  查看指令参考文档：修改ServerTokens选项<pre><code>建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全</code></pre></li><li><p>2.修改监听的IP和Port<br>  Listen [IP:]PORT<br>  (1) 省略IP表示为本机所有IP<br>  (2) Listen监听端口至少一个，可以有多个端口<br>  (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口</p><pre><code>test.conf添加listen端口：listen 172.18.132.151:6666 6666端口只能通过此IP才能访问</code></pre></li><li><p>3.持久连接：默认KeepAlive是开启的<br>  Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接<br>  断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级<br>  副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞<br>  折衷：使用较短的持久连接时间</p><pre><code>设置：    KeepAlive On|Off       设置持久连接开启或者关闭    KeepAliveTimeout 15    设置持久连接为15s测试：telnet WEB_SERVER_IP PORT    GET /index.html HTTP/1.1    Host: WEB_SERVER_IP  host可以随便填写，但是在虚拟主机中是有区别的</code></pre></li><li><p>4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event<br>  默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf  修改mpm的文件<br>  建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的<br>  查看静态编译的模块<br>  httpd -l<br>  查看当前系统中httpd的静态编译及动态装载的加载的模块<br>  httpd –M<br>  动态模块加载：不需重启即生效<br>  动态模块路径<br>   /usr/lib64/httpd/modules/</p><pre><code>切换使用的MPM模块    在/etc/httpd/conf.modules.d/00-mpm.conf中    选择要启用的MPM相关的LoadModule指令即可prefork的配置：    StartServers 8               MinSpareServers 5       保留5个空闲子进程处理新的请求    MaxSpareServers 20      允许的最大空闲进程数    ServerLimit 256         最多进程数,最大20000，并发量建议最多10000         MaxRequestsPerChild     4000 子进程最多能处理的请求数量。在处理    MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进    程占用的内存就会释放(为0时永远不释放）worker和prefork配置类似，只不过会有线程数量的限制</code></pre><p>从下面ps auxf的进程图可以看书httpd是使用的prefork模型，而且因为端口是80，开启需要特殊<br>权限，所以父进程是root,子进程是apache</p></li></ul><p><img src="/2018/12/18/HTTP协议/HTTPD的prefork模型.png" alt=""></p><ul><li><p>5.DSO： Dynamic Shared Object<br>  加载动态模块配置<br>  /etc/httpd/conf/httpd.conf<br>  Include conf.modules.d/*.conf<br>  配置指定实现模块加载格式：<br>  LoadModule &lt;mod_name&gt; &lt;mod_path&gt;<br>  模块文件路径可使用相对路径：<br>  相对于ServerRoot（默认/etc/httpd）</p></li><li><p>6.定义’Main’ server的文档页面路径：存放页面的主目录<br>  主目录是由DocumentRoot指令来设置的<br>  网页文件默认是存在/var/www/html/下的，此处可以自定义<br>  在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html”</p><pre><code>如果要自定义主目录，还需要设置该目录为允许访问在httpd2.2上是不需要设置权限访问的但是在httpd2.4上是需要设置该目录允许访问的修改格式如下：#DocumentRoot &quot;/var/www/html&quot;DocumentRoot &quot;/data/www&quot;&lt;directory /data/www&gt;    Require all granted&lt;/directory&gt; </code></pre></li><li><p>7.定义站点默认主页面<br>  访问192.168.34.103默认显示的是index.html的内容，<br>  这一项是由DirectoryIndex指令设置的</p><pre><code>在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件</code></pre><font color="#FF0000"><br>此处需要了解httpd的权限和访问报错的相关问题和默认主页面：<br>1.访问192.168.34.103跳出的页面默认是index.html页面，如果不存在，则去找conf.d/welcome.conf文件，即报错提示，如果两个都不存在，显示的是/var/www/html目录下的文件列表，因为在httpd.conf配置文件中，定义options indexes选项<br>2.默认页面和默认访问目录都是可以通过指令来指定的<br>3.如果没有index.html文件，没有welcome.conf文件，没有options indexes配置，访问时会报错You don’t have permission to access / on this server.的提示.<br>4.上面三条在下面第12条配置别名时，可以体现的很明显<br>5.所以如果自定义目录和用别名，有时是需要设置目录访问权限、设置目录对应的index.html文件或者跳转的html文件(如果该文件存在就不需要设置了)，设置options indexes选项<br></font></li><li><p>8.站点访问控制常见机制<br>  可基于两种机制指明对哪些资源进行何种访问控制<br>  访问控制机制有两种：1.客户端来源地址，2.用户账号<br>  而文件系统路径：可以是<br>  1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配<br>  示例：<br>  ‘<filesmatch "\.(gif|jpe?g|png)$"="">‘’   用的是扩展的正则表达式<br>  <files “?at.*”="">                     通配符<br>  &lt;Location /status&gt;</files></filesmatch></p>  <locationmatch "="" (extra|special)="" data"=""></locationmatch></li><li><p>9.<directory>中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制<br>   (1) Options：后跟1个或多个以空白字符分隔的选项列<br>  在选项前的+，- 表示增加或删除指定选项<br>  常见选项：<br>  Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制<br>  适用于下载网站和镜像网站，不适合电商网站<br>  FollowSymLinks：允许访问符号链接文件所指向的源文件,<br>  None：全部禁用<br>  All： 全部允许</directory></p><pre><code>Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站    &lt;directory &quot;/data/www&quot;&gt;    options Indexes                                              Require all granted    &lt;/directory&gt;FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件    &lt;directory &quot;/data/www&quot;&gt;    options Indexes  FollowSymLinks           Require all granted    &lt;/directory&gt;</code></pre><font size="4" color="#FF0000"><br>实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.conf文件，welcome.conf文件就是页面上经常看到的测试123页面，把welcome.conf文件改名或删除，就会显示主目录下的所有列表文件了.<br></font><p>  (2) AllowOverride<br>  allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可<br>  只对<directory>语句有效;<br>  allowoverride权限时卸载httpd的*.conf配置文件中的<br>  AllowOverride All: .htaccess中所有指令都有效<br>  AllowOverride None： .htaccess 文件无效<br>  AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它</directory></p><pre><code>配置allowoverride示例：/etc/httpd/conf.d/test.conf中添加访问控制的目录    &lt;directory /data/www&gt;    allowoverride all  --&gt;这条必须写，代表.htaccess文件中的options生效    Require all granted    &lt;/directory&gt;在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中    options indexes FollowSymLinks</code></pre><p>  (3) 基于IP的访问控制:<br>  无明确授权的目录，默认拒绝<br>  允许所有主机访问：Require all granted<br>  拒绝所有主机访问：Require all denied<br>  控制特定的IP访问：<br>  Require ip IPADDR：授权指定来源的IP访问<br>  Require not ip IPADDR：拒绝特定的IP访问<br>  控制特定的主机访问：<br>  Require host HOSTNAME：授权特定主机访问<br>  Require not host HOSTNAME：拒绝<br>  HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机</p><pre><code>基于IP的访问控制示例：如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表除了/data/www/ceshi文件夹    &lt;directory /data/www&gt;    options indexes                                                      &lt;RequireAll&gt;    Require all granted    Require not ip 192.168.34.107    &lt;/RequireAll&gt;    &lt;/directory&gt;2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问&lt;directory /data/www&gt;options indexesRequire all granted&lt;/directory&gt;&lt;directory /data/www/ceshi&gt;&lt;RequireAny&gt;Require all deniedRequire ip 192.168.34.107&lt;/RequireAny&gt;                                                 &lt;/directory&gt;</code></pre></li><li><p>10.日志设定：日志默认/var/log/httpd/下<br><a href="http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats" target="_blank" rel="noopener">format官方说明文档</a><br>  日志类型：访问日志(access_log)和错误日志(error_log)<br>  日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式</p><pre><code>在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined   --&gt;由Logformat指令定义完起一个combined名CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式ErrorLog &quot;logs/error_log&quot;</code></pre><p>  可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径</p><pre><code>日志中的格式各个项说明%h 客户端IP地址%l 远程用户,启用mod_ident才有效，通常为减号“-”%u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-”%t 服务器收到请求时的时间%r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本%&gt;s 响应状态码%b 响应报文的大小，单位是字节；不包括响应报文http首部%{Referer}i     请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页    是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源，所以网站一般要加防盗链，防止资源被盗和占用服务器资源%{User-Agent}i 指客户端的浏览器版本</code></pre></li><li><p>11.设定默认字符集<br>  一般不需要设置：基本上使用的是utf-8;<br>  AddDefaultCharset UTF-8 此为默认值</p><pre><code>如果需要修改字符集，在test.conf或者httpd.conf下添加AddDefaultCharset gb2312 即可</code></pre></li><li><p>12.定义路径别名<br>作用：默认访问的文件夹是设置的DocumentRoot文件夹，如果不是在默认文件夹下，而需求要实现把其他路径下的目录共享出来，这就用到了定义路径别名的功能</p><p>  把一个URL起一个别名不指向真正的目录<br>  在httpd2.4里目录如果没有开启允许时，默认是不允许访问的</p><pre><code>例如：访问 /var/www/html/111,111这个目录可有可无，只是充当别名    实际上访问的是/data/www/ceshi目录         directoryindex ceshi.html        alias /111 /data/www/ceshi        &lt;directory /data/www/ceshi&gt;        options indexes        Require all granted        &lt;/directory&gt;         </code></pre></li></ul><font color="#FF0000"><br>注意：<br>1.111只是一个别名，在/var/www/html下不需要创建；但是如果/var/www/html下有111的文件夹，如果设置别名后，则访问的是/data/www/ceshi目录，原目录下的111文件夹就失效了。<br>2.在这里和上文第7条设置权限时有联系的，httpd2.4设置路径别名的时候，真正的路径也是需要在test.conf下设置权限的(/data/www/ceshi目录)<br>3.如果/data/www/ceshi/下没有index.html会报权限不允许的错误，所以要设置默认主页面directoryindex，当然可以设置options indexes选项<br></font><ul><li><p>13.基于虚拟账户的登录访问控制：提示401状态码<br>  认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码<br>  认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源<br>  两种认证方式：<br>  basic：用的多，缺点是明文，后面可以用https进行加密<br>  digest：兼容性差，用的少<br>  用户的账号和密码:非linux用户密码<br>  虚拟账号：多种存储方式，只用于httpd服务的，类似vsftp，samba服务的虚拟用户<br>  存储：账号可放在文本文件，SQL数据库，ldap目录存储，nis等</p><pre><code>因为basic使用的多，下文以basic认证配置示例1.提供账号和密码存储（文本文件），如创建一个tom虚拟账户管理httpd    htpasswd --&gt;可以指定加密算法        -c 自动创建文件，仅应该在文件不存在时使用        -p 明文密码        -d CRYPT格式加密，默认        -m md5格式加密        -s sha格式加密        -D 删除指定用户    htpasswd -c httpdpass tom :设定密码即可;目录可指定，后面改配置文件即可    htpasswd -s httpdpass jerry 再添加jerry用户，就不需要-c选项了    htpasswd -D httpdpass jerry 从文件中删除jerry用户    修改httpdpass权限，加固安全 chmod 600 httpdpass     或者也可以创建组文件httpdgroup，通过组来管理,组文件组和成员列表    testgroup: tom jerry2. 在test.conf或者httpd.conf下定义安全域    &lt;directory /var/www/html/ksdir&gt;    AuthType Basic          ---&gt;使用的认证方式    AuthName &quot;Login&quot;        ----&gt;登录提示信息    AuthUserFile &quot;/etc/httpd/conf/httpdpass&quot;  --&gt;加密账户文件    AuthGroupFile &quot;/etc/httpd/conf/httpdgroup&quot; --&gt;组账户    Require user tom        ---&gt;允许用户访问的列表    Require group testgroup  ---&gt;允许访问的组    &lt;/directory&gt;    但是：因为httpd线程是以apache运行的，而httpdpass是600权限，所以默认tom登录是没有权限的，让apache对httpdpass有读权限：    setfacl -m u:apache:r httpdpass 即可</code></pre></li><li><p>14.实现用户家目录的http共享;并实现账户机密访问<br>  实现基础：基于模块mod_userdir.so实现<br>  httpd -M |grep user 可以看出user加密的模块是已经加载的，直接改配置文件即可<br>  在/etc/httpd/conf.d/userdir.conf文件中定义了家目录共享的格式，只需要启用就行了</p><pre><code>实现步骤：1. vim /etc/httpd/conf.d/userdir.conf    &lt;IfModule mod_userdir.c&gt;     UserDir enabled      ---&gt;启用即可；默认不启用    UserDir public_html  ---&gt;创建一个public_html文件    &lt;/IfModule&gt;2.在test家目录下，创建public_html文件夹和public_html文件    su test    mkdir public_html/    echo 23333 &gt; /public_html/public_html3.因为httpd线程是apache身份登录的，所以要允许apache访问test用户的家目录    setfacl -m u:apache:x /home/test4.设置test家目录访问权限及用户加密    &lt;directory /home/test/public_html&gt;        authtype basic    authname &quot;test home&quot;    authuserfile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;调用之前创建的虚拟账户文件即可    Require user haha    &lt;/directory&gt;5.http访问test家目录方式,即可用加密账户登录    192.168.34.103/~test</code></pre></li><li><p>15.ServerSignature On|Off|EMail<br>  作用：当用户访问的页面不存在的情况下服务器会产生错误文档，而当ServerSignature选项是打开的情况下，错误文档会将服务器的名字，apahce的版本信息，显示在页面上，某种程度上会对web服务器产生不安全因素，所以一般建议关闭</p><pre><code>在配置文件添加一行：ServerSignature off 即可</code></pre></li><li><p>16.status页面<br>  作用：显示apache的工作状态，有助于判断apache是否正常工作<br>  status页面功能是由下面这个模块实现的：httpd<br>  LoadModule status_module modules/mod_status.so</p><pre><code>实现步骤：在配置文件添加&lt;Location &quot;/status&quot;&gt; SetHandler server-status&lt;/Location&gt;ExtendedStatus ON   #显示扩展信息</code></pre><p>  记录的信息包括：启动时间，线程数，等待连接数，cpu，进程，MPM等信息<br>  在实际生产中，由于apache服务器很多，就可以通过curl 192.168.34.103/status来抓取页面，分析apache某个指标是不是正常的；</p><pre><code>比如编写简单一个脚本：    curl 192.168.34.103/status |grep &quot;Apache Status&quot; || systemctl start httpd</code></pre></li><li><p><font size="5" color="#FF0000">17.实现http的虚拟主机</font><br>  作用：一个物理服务器上实现多台虚拟主机，至于为什么会用到虚拟主机，有可能是因为要上线的同一网站的有多个域名，却只有一个公网IP地址，也有可能是主机不多啊..，所以虚拟主机的价值就体现出来了…</p><p>  实现虚拟主机有三种方式</p><pre><code>基于ip：为每个虚拟主机准备至少一个ip地址，一个主机可以配多个内网IP地址基于port：为每个虚拟主机使用至少一个独立的port；80,8081,8082等等基于FQDN：为每个虚拟主机使用至少一个FQDN</code></pre><p>  当然这三种方式，基于IP和port的对于用户来说不太现实，一般都是通过输入域名方式来实现虚拟主机搭建.</p><pre><code>1.基于IP的虚拟主机搭建：但是这种方式用的比较少先准备三个网站目录，和在本机上添加三个IP地址    &lt;virtualhost 192.168.34.103&gt;    DocumentRoot &quot;/data/asite&quot;    &lt;directory /data/asite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_a.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.200&gt;    DocumentRoot &quot;/data/bsite&quot;    &lt;directory /data/bsite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_b.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.210&gt;    DocumentRoot &quot;/data/csite&quot;    &lt;directory /data/csite&gt;    Require all granted    &lt;/directory&gt;重启服务即可通过curl 192.168.34.103      curl 192.168.34.200    curl 192.168.34.210即可获取到各自的index.html文件内容，对应的日志也都生成了</code></pre><p>  2.基于port的虚拟主机搭建，监听三个port即可;使用的不多</p><pre><code>listen 8081listen 8082listen 8083&lt;virtualhost *:8081&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8082&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8083&gt;                                                                                                      servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;</code></pre><p>  通过本机IP+port获得不同网站的信息</p><pre><code>curl 192.168.34.103:8081curl 192.168.34.103:8082curl 192.168.34.103:8083</code></pre><p>  3.基于FQDN的虚拟主机搭建：用的最多<br>  前提：这里就不搭建DNS服务器了，使用本机的hosts文件进行域名解析</p><pre><code>&lt;virtualhost *:80&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;                                                                                                     servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_c.log combined&lt;/virtualhost&gt;</code></pre><p>  测试：curl <a href="http://www.a.com" target="_blank" rel="noopener">www.a.com</a></p><pre><code>curl www.b.cncurl www.c.net</code></pre><p>  就可获得各自的主页面信息<br>从这telnet就可以理解出，如果在互联网通过域名访问时(同一IP)，返回的结果是不同网站的信息<br>  [root@node7-1 ~]#telnet 192.168.34.103 80</p><pre><code>Trying 192.168.34.103...Connected to 192.168.34.103.Escape character is &apos;^]&apos;.GET /index.html HTTP/1.1HOST: www.a.com</code></pre></li></ul><font size="4" color="#FF0000"><br>当访问192.168.34.103时 HOST：即网站的域名，返回的结果就是其对应的页面信息<br>在互联网上，一般是先在本地服务器上通过第三种方式搭建多个网站，然后再通过服务商的智能DNS解析，可以通过访问不同的域名，解析到IP地址，服务器根据输入的HOST：域名判断访问的是哪个网站，进而返回对应网站站点的信息，对于主机较少或者IP有限的环境中，使用http虚拟主机还是很方便的。<br></font>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;a href=&quot;#HTTP协议和APACHE原理&quot; class=&quot;headerlink&quot; title=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;/a&gt;HTTP协议和APACHE原理&lt;/h3&gt;&lt;p&gt;Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等&lt;br&gt;本文说的是HTTP SERVER&lt;a href=&quot;http://www.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;apache&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="http" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/http/"/>
    
    
      <category term="Web服务" scheme="https://www.liukui.tech/tags/Web%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>编译安装LAMP</title>
    <link href="https://www.liukui.tech/2018/12/10/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85LAMP/"/>
    <id>https://www.liukui.tech/2018/12/10/编译安装LAMP/</id>
    <published>2018-12-10T00:00:00.000Z</published>
    <updated>2019-01-22T08:46:48.428Z</updated>
    
    <content type="html"><![CDATA[<p>LAMP<br><a id="more"></a></p><p><img src="/2018/12/10/编译安装LAMP/LAMP架构.png" alt=""></p><h3 id="Centos7上编译安装LAMP"><a href="#Centos7上编译安装LAMP" class="headerlink" title="Centos7上编译安装LAMP"></a>Centos7上编译安装LAMP</h3><pre><code>    备注：本文编译PHP是基于fastCGI方式，php-fpm编译准备：    在192.168.34.105上实现，准备安装包都放在/data/src下        apr-1.6.5.tar.bz2        apr-util-1.6.1.tar.bz2        httpd-2.4.37.tar.bz2        php-7.1.18.tar.bz2        wordpress-5.0-zh_CN.zip        mariadb-10.2.19-linux-x86_64.tar.gz    准备开发包组：        yum install &apos;develoment tools&apos; -y    1.编译安装httpd和apr        准备依赖包和解压安装包        yum install pcre-devel openssl-devel expat-devel apr-util-devel -y        tar xvf apr-1.6.5.tar.bz2        tar xvf apr-util-1.6.1.tar.bz2         tar xvf httpd-2.4.37.tar.bz2        cp -r apr-1.6.5 httpd-2.4.37/srclib/apr        cp -r apr-util-1.6.1 httpd-2.4.37/srclib/apr-util        a.编译            cd httpd-2.4.37            ./configure \            --prefix=/data/httpd24 \            --enable-so \            --enable-ssl \            --enable-cgi \            --enable-rewrite \            --with-zlib \            --with-pcre \            --with-included-apr \            --enable-modules=most \            --enable-mpms-shared=all \            --with-mpm=prefork            make &amp;&amp; make install        b.准备环境变量            用自带的服务控制脚本：/app/httpd24/bin/apachectl就需要设置环境变量了            echo &apos;PATH=/mysql/httpd24/bin:$PATH&apos; &gt; /etc/profile.d/httpd24.sh            . /etc/profile.d/httpd24.sh        c.修改配置文件，为了安全以apache用户运行，并监听在本地            useradd -r -s /sbin/nologin apache            vim /data/httpd24/conf/httpd.conf                User apache                Group apache                ServerName localhost:80    2.二进制安装mariadb-10.2.19        a.准备用户和mysql数据库目录                useradd -r -s /sbin/nologin -d /data/mysql mysql                mkdir /data/mysql                chown mysql.mysql mysql/        b.解压二进制安装包：            tar xvf mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local/            cd /usr/local            ln -s mariadb-10.2.19-linux-x86_64/ mysql            chown -R root.mysql /usr/local/mysql/        c.创建数据库文件:(通过自带脚本工具)            cd /usr/local/mysql/            scripts/mysql_install_db --datadir=/mysql/data --user=mysql        d.准备配置文件(不修改/etc/my.cnf)拷贝解压完的文件            mkdir /etc/mysql/            cp support-files/my-huge.cnf /etc/mysql/my.cnf                                路径优先级高于/etc/my.cnf                根据性能来拷贝配置文件            [mysqld]中添加三个选项：/etc/mysql/my.cnf            datadir = /mysql/data            innodb_file_per_table = on            skip_name_resolve = on 禁止主机名解析，建议使用        e.准备服务脚本，并启动服务            cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld            chkconfig --add mysqld            service mysqld start        f.准备PATH路径            echo &apos;PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh            . /etc/profile.d/mysql.sh            systemctl start mysqld        为wordpress准备数据库和账号密码            mysql -e &apos;create database wordpress&apos;            mysql -e &quot;grant all on *.* to php1@&apos;192.168.34.%&apos; identified by &apos;php123&apos;&quot;    3.FastCGI方式编译安装php-7.1.18        tar xf php-7.1.18.tar.bz2        安装依赖包            yum install libxml2-devel bzip2-devel libmcrypt-devel -y         a.编译，指定安装数据路劲和配置文件路径                   cd php-7.1.18            ./configure --prefix=/data/php \            --enable-mysqlnd \            --with-mysqli=mysqlnd \            --with-openssl \            --with-pdo-mysql=mysqlnd \            --enable-mbstring \            --with-freetype-dir \            --with-jpeg-dir \            --with-png-dir \            --with-zlib \            --with-libxml-dir=/usr \            --enable-xml \            --enable-sockets \            --enable-fpm \            --with-config-file-path=/etc \            --with-config-file-scan-dir=/etc/php.d \            --enable-maintainer-zts \            --disable-fileinfo            make &amp;&amp; make install        b.准备php配置文件            cd php-7.1.18            cp php.ini-production /etc/php.ini                可以修改当前时区和按照生产环境修改并发连接数等信息        c.创建nginx用户            useradd -s /sbin/nologin nginx        d.准备php的conf文件            cd /data/php            cp php-fpm.conf.default php-fpm.conf            cp php-fpm.d/www.conf.default php-fpm.d/www.conf            修改监听地址和允许连接地址，因为是在一台编译的，监听地址不用改了                vim php-fpm.d/www.conf                    listen = 127.0.0.1:9000                    ;listen.allowed_clients = 127.0.0.1                    user = nginx                    group = nginx        e.准备服务脚本:            cp /data/src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm            chmod +x /etc/init.d/php-fpm            chkconfig --add php-fpm            chkconfig php-fpm on    4.修改httpd文件，支持php和启用代理        编辑apache配置文件httpd.conf，以使apache支持php,并启用代理        vim /data/httpd24/conf/httpd.conf            1.取消下面两行的注释                LoadModule proxy_module modules/mod_proxy.so                LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so            2.定位至DirectoryIndex index.html                修改为DirectoryIndex index.php index.html            3.最后添加4行        AddType application/x-httpd-php .php        AddType application/x-httpd-php-source .phps        ProxyRequests Off        ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1             重启apache服务，apachectl restart    5.准备wordpress,把wordpress文件全部移动到httpd24/htdocs下        cd /data/src        unzip wordpress-5.0-zh_CN.zip        cd wordpress        mv * /data/httpd24/htdocs        为wordpress准备配置文件和数据库连接            cd /data/httpd24/htdocs            mv wp-config-sample.php wp-config.php            vim wp-config.php                define(&apos;DB_NAME&apos;, &apos;wordpress&apos;);                define(&apos;DB_USER&apos;, &apos;php&apos;);                define(&apos;DB_PASSWORD&apos;, &apos;php123&apos;);                define(&apos;DB_HOST&apos;, &apos;192.168.34.105&apos;);        修改/data/httpd24/htdocs的所有者和所属组            cd /data/httpd24            chown -R nginx.nginx htdocs/    到此所以的编译安装和准备工作都做完了，把mysql,php-fpm,httpd启动即可            apachectl start            systemctl start php-fpm            systemctl start mysqld        http://192.168.34.105 配置wordpress即可    备注：        创建的文章和账户是放在wordpress数据库中的;        图片是放在/data/httpd24/htdocs/wp-content/uploads下的</code></pre><p><font size="4" color="#23238E"><br>然后把这套系统搬到自己的云服务上就可以轻松的实现了,本文是基于LAMP架构实现的<br>不过推荐使用LNMP架构，毕竟Nginx的强大可不是吹出来的..<br></font> </p><p><font size="4" color="#FF0000">安装完成后，开启了一个新的世界，就可以开心的玩耍了,helloworld！</font><br><img src="/2018/12/10/编译安装LAMP/haha.png"><br><img src="/2018/12/10/编译安装LAMP/wordpress.png" width="80%" height="80%"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LAMP&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="个人博客搭建" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="web" scheme="https://www.liukui.tech/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>GlusterFS存储</title>
    <link href="https://www.liukui.tech/2018/12/06/GlusterFS%E5%AD%98%E5%82%A8/"/>
    <id>https://www.liukui.tech/2018/12/06/GlusterFS存储/</id>
    <published>2018-12-06T00:00:00.000Z</published>
    <updated>2019-04-02T13:19:38.907Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="存储" scheme="https://www.liukui.tech/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="https://www.liukui.tech/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>TiDB基础</title>
    <link href="https://www.liukui.tech/2018/12/03/TiDB%E5%9F%BA%E7%A1%80/"/>
    <id>https://www.liukui.tech/2018/12/03/TiDB基础/</id>
    <published>2018-12-02T16:00:00.000Z</published>
    <updated>2019-04-05T10:46:51.650Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="数据库" scheme="https://www.liukui.tech/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="TiDB" scheme="https://www.liukui.tech/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/TiDB/"/>
    
    
      <category term="database" scheme="https://www.liukui.tech/tags/database/"/>
    
  </entry>
  
  <entry>
    <title>ceph存储基础</title>
    <link href="https://www.liukui.tech/2018/11/03/ceph%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    <id>https://www.liukui.tech/2018/11/03/ceph存储基础/</id>
    <published>2018-11-03T00:00:00.000Z</published>
    <updated>2019-04-03T15:05:11.485Z</updated>
    
    <content type="html"><![CDATA[<h3 id="存储基础"><a href="#存储基础" class="headerlink" title="存储基础"></a>存储基础</h3><a id="more"></a><pre><code>存储设备：1.DAS:IDE，SATA，SCSI，SAS，USB    #DAS直接附加存储是直接接到计算机的主板总线上去的；2.NAS: NFS，CIFS，    #1.NAS(Network Attacked Storage)网络附加存储，文件系统级别的存储；    #2.把一个文件系统挂载到本地的文件系统树上的某一个挂载点上就可以直接访问，因为    它是通过网络附加到当前主机文件系统之上的一个存储空间就称为网络附加存储；    #3.网络附加存储的特点都是文件系统接口(filesystem),本身就是一个做好的文件    系统，通过nfs/cifs接口基于内核级的nfs/cifs模块与远程主机进行通信，把它转    为像本地文件系统一样来使用；    #4.对于这种存储设备我们是没办法对它进行再一次的分区格式化等操作的3.SAN:SCSI    #1.SAN(Storage Area Network)称为存储区域局域网络    #2.与NAS不同的是SAN提供给客户端使用的接口是块(block)级别的，所以SAN大多数使用    的是SCSI协议；    SCSI协议：        SCSI协议也是分层的和tcp/ip协议很像也分数据链路，物理层，传输层，应用层的，不过SCSI只是用来传输数据的存        取，SCSI的物理层早期也是使用并行的线缆传输SCSI信号来实现的，SCSI协议的分层设计意味着某一层是可以被替代的；    FC-SAN:        把SCSI的物理层替换成光纤和它对应的协议，就是FC-SAN的形成    ISCSI:        把SCSI的物理层替换成tcp/ip协议和它对应的底层设备(以太网),就是ISCSI    它们其实就是把SCSI协议底层的物理传输接口改换成了另外一种传输信道；    而且SCSI协议本身的传输距离有限，如果是通过以太网传输就大大增加了距离；    所以这种网络提供给客户端的存储接口就称为存储区域网络；大多数SSD使用如SATA、SAS或光纤通道等接口与计算机接口的总线连接。随着固态硬盘在大众市场上的流行，SATA已成为个人电脑中连接SSD的最典型方式；但是，SATA的设计主要是作为机械硬盘驱动器（HDD）的接口，并随着时间的推移越来越难满足速度日益提高的SSD。随着在大众市场的流行，许多固态硬盘的数据速率提升已经放缓。不同于机械硬盘，部分SSD已受到SATA最大吞吐量的限制。在NVMe出现之前，高端SSD只得以采用PCI Express总线制造，但需使用非标准规范的接口。若使用标准化的SSD接口，操作系统只需要一个驱动程序就能使用匹配规范的所有SSD。这也意味着每个SSD制造商不必用额外的资源来设计特定接口的驱动程序</code></pre><h3 id="HDFS分布式存储-文件系统接口"><a href="#HDFS分布式存储-文件系统接口" class="headerlink" title="HDFS分布式存储(文件系统接口)"></a>HDFS分布式存储(文件系统接口)</h3><p>–HDFS分布式存储<br><img src="/2018/11/03/ceph存储基础/HDFS分布式存储.png" alt="HDFS分布式存储"></p><pre><code>前提：    设计成分布式文件系统的根本目的就是为了能够做到按需扩展有状态应用：    如果一个服务的第二次访问请求和第一次请求是有关系的，就是有状态的应用分布式存储：    1.所以分布式存储也是一种有状态应用的一种，如果存储是分布和扩展到多个节点上，以mysql为例，数据第一次写到Storage-A节点,    查的时候在分布式存储内部必须要有一个路由机制使得查询的时候还是到Storage-A节点查询，而不是Storage-B|C|D节点;    2.可能你会想把Storage-A节点的数据同步到B|C|D上，查询数据的时候不就路由到哪个节点都可以了？    如果是这样每个存储节点都会拥有全部一样的数据了，这样就不符合分布式存储的定义了；元数据、数据的实现？    元数据就是负责路由的，    以ext4文件系统为例：        inode信息是存储在元数据区的        元数据就是让我们找到所需文件的路由表，但是当我们使用分布式存储时，就不能使用这种传统的在一个分区上来组织        数据和元数据了，而是把数据和元数据分开存放分布式存储方式：    1.元数据服务器：(NameNode)        分布式存储的元数据和数据不能像ext4那样，但是可以在存储集群中找一个固定的节点存放元数据    2.写数据：(DataNode)        当客户端想要存储2G的数据请求发给元数据节点后，元数据负责将这2G的数据做指定大小规模进行切块，每一块当做独        立的文件进行路由和调度从而达到分散存储的目的，而且还可以并发调度存储到不同的节点充分利用多个节点的磁盘和网络I/O；    3.读数据：(DataNode)        用户读数据时只需要联系元数据服务器，根据在元数据中记录的某一文件切块大小、数量、每一块所在的节点以及块之        间的偏移量然后元数据从各个节点上并行的加载这些数据块然后按照元数据中的逻辑由客户端将其组合起来得到完整的数据；NameNode的高可用：    1.如果只有一台元数据服务器就有单点故障，所以要实现NameNode的高可用；    2.但是文件系统的元数据是一类非常密集但是I/O量非常小的数据，所以为了实现请求元数据时的高效，一般是把它放到内    存当中，但是当服务器down机时会丢失数据的，所以又需要一种机制持久同步存储到磁盘上；    3.但是当文件修改时，元数据也会被修改，因为无法判断哪个文件会被修改，所以就会造成大量的修改操作同步到磁盘上是    随机的，大家都知道随机I/O操作会非常慢；    4.因此为了能够对这些非常密集的文件元数据的修改操作进行高效的同步到磁盘上，一般都不是直接去改那个元数据的，而    是像mysql的binlog一样把每一次的操作请求记下来，而不是真正的去修改元数据，将来想要还原回来只需要把日志重放一    遍就行了，这样就比较像redis的AOF顺序追加记录机制，这样就把随机I/O改成顺序I/O能够快速的进行同步    磁盘进行保存；    5.顺序I/O(AOF)的缺点就是只能通过重放记录在文件中的指令才能把数据还原回来，而不    是复制，所以恢复速度非常慢；    6.为了避免将元数据同步到磁盘上时恢复时比较慢，现在的方案都是持久放在第三方存储上，第三方存储集群使用    zookeeper,这样一来NameNode1宕机了之后，NameNode2就可以快速的从zookeeper中恢复数据；    (这样的解决方案就很类似于把有状态的k8s-apiserver放到etcd集群中一样，不过        zookeepr主要作用于java编程领域，etcd作用于go编程领域)；DataNode的高可用：    由于数据文件是被切成很多块分散存储到多个datanode的，当其中任何一个DataNode宕机都会造成此文件的丢失；    数据存储区的两种高可用方案：    1.在DataNode的节点级做冗余，即每个DataNode都有一个从节点，这样代价有点大；    2.分片级的冗余：        1.可以对存在DataNode上的单个数据块做副本，将副本放到存储集群中的其他DataNode节点上，冗余级别取决于每个数据块的副本数量；        2.这样一来，就可以在NameNode中定义任意个数据块都必须有3个副本数量存在，主分片(primary shard)负责数据        复制(replica shard)到事先选择好的其他节点上；把即使任何一个DataNode宕机了也不会影响数据文件的完整性；    3.机架的规划        DataNodeA DataNodeB DataNodeC一般是不在一个机柜的，避免因为一台断电数据        全部丢失；        机柜1：DataNodeA+DataNodeB        机柜2：DataNodeC            A--&gt;B-&gt;C #这样一来至少保证以一台数据的安全性，提高冗余级别；TFS(淘宝)&lt;--HDFS&lt;--GFS(谷歌文件系统)    特点：        这种分布式文件系统的特点是读写接口是受限的，可以随机的/顺序的读，但只能顺        序的写，不能随机的写!!!</code></pre><h3 id="块级别设备存储"><a href="#块级别设备存储" class="headerlink" title="块级别设备存储"></a>块级别设备存储</h3><p>–块设备接口逻辑<br><img src="/2018/11/03/ceph存储基础/块设备接口逻辑.png" alt="块设备接口逻辑"></p><pre><code>区别：    1.块级别的存储就是一个裸设备，提供给我们的就是一个没有被组织过的存储空间，而文件系统存储让我们只能以文件形式来存放数据；    2.但是要注意的是&quot;数据并不一定都是文件形式的，也可以是数据流形式的&quot;，只有把数据流组织起来放在一个特定的文件系统上时的一种表现形式；    3.所以文件系统只是数据的组织存放接口，所有数据流存进来以后都表现为我们看到的、所理解的&quot;一种文件&quot;；而文件系统    接口一般是建立在块级别存储接口之上的，我们在一个块级别的存储空间上创建出文件系统来。就可以存放数据流了；    4.像HDFS这种分布式存储最常见的就是文件系统接口，因为在计算机发展中文件系统接口是最经典的接口，因为在计算机中    大量的存储都是以文件形式存放的！虽然文件系统接口是最经典最常用的，但有些应用程序确实要求不应该使用文件系统接口，比如KVM,VMware虚拟机启动时使用的磁盘镜像文件，如果提供给它的是文件系统接口它还需要再将文件虚拟成磁盘进行挂载就会影响它的性能，如果是直接提供块设备作为磁盘，它启动时直接加载磁盘不是更好吗;</code></pre><h3 id="对象存储"><a href="#对象存储" class="headerlink" title="对象存储"></a>对象存储</h3><p>–对象存储的存储方式<br><img src="/2018/11/03/ceph存储基础/对象存储的存储方式.png" alt="对象存储的存储方式"></p><pre><code>如上图示：    和文件系统中把数据和元数据分开存放的不同在于：对象存储中每一个数据流都自带数据data和元数据metadata，每一个这样的数据流都被叫做一个对象；    1.这样一来只要找到这个对象就可以知道它的元数据信息不需要再访问元数据区了；    2.这样一来每一个数据对象内部都应该有自己的管理格式用来标记它的数据和元数据所在的位置    3.因此对象是直接放到磁盘之上的，而不是像文件系统那样分开存放；</code></pre><p>–对象的组织格式<br><img src="/2018/11/03/ceph存储基础/对象的组织格式.png" alt="对象的组织格式"></p><pre><code>每一个object是如何被存下来的？    如上图对象是自带数据data和元数据metadata被统一存储的    ID用于集群内部引用    元数据是K/V类型的</code></pre><p>–filestore和bluestore<br><img src="/2018/11/03/ceph存储基础/filestore和bluestore.png" alt="filestore和bluestore"></p><pre><code>FileStore存储方式：    1.将对象转换成文件进行存储，转换成的文件的元数据放在元数据区    2.原来对象自己的元数据都被放在levelDB中        #levelDB也是高性能的K/V类型数据库是直接放在xfs文件系统上    3.对象数据直接存在文件系统上    非标准的文件系统键入元数据BlueStore存储方式：    1.BlueStore=BlueFS+RocksDB        #因为此时OSD是一个裸设备，而RocksDB数据库必须运行在一个文件系统之上，所以在其下也必须有文件系统叫做        BlueFS支撑RocksDB数据库运行；    2.此时对象本身就直接存放在OSD裸设备磁盘内，对象的元数据放在RocksDB内    3.而RocksDB为了实现它的安全性需要进行数据持久化保存，使用WAL的方式来写日志；    所以在BlueStore上存储的数据分为三类：        1.数据        2.元数据        3.元数据的元数据，就像redis的AOF文件一样    鉴于以上因素，BlueStore支持三种不同的存储设备，然后就有了这种方案        1.BlueFS和RocksDB放在固态硬盘上        2.对象数据放在机械硬盘上        3.RocksDB的持久化数据放在NVMe上</code></pre><h3 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a>Ceph</h3><p>–ceph微型架构<br><img src="/2018/11/03/ceph存储基础/ceph微型架构.png" alt="ceph微型架构"></p><pre><code>1.Ceph是什么？    Ceph也是分布式存储的一种解决方案，但是和HDFS还是有一点区别的：    1.Ceph是一个软件定义的存储SDS(software-defined storage),而且是一个开源的高    度可伸缩的平台；    2.Ceph是一个&quot;对象（object）&quot;式存储系统，它把每一个待管理的数据流（例如一个文件） 切分为一到多个&quot;固定大小&quot;的对象数据shard，并以其为&quot;原子单元&quot;完成数据存取；    默认的&quot;固定大小&quot;是4M，但可以自定义；    3.对象数据的底层存储服务是由多个主机（host）组成的存储集群，该集群也被称之为 RADOS（Reliable Automatic Distributed Object Store）存储集群，即可靠、    自动化、 分布式对象存储系统；    4.librados是RADOS存储集群的API（库接口），它支持C、C++、Java、Python、Ruby和PHP等编程 语言；    5.Ceph从设计上就是为了解决分布式存储所面临的元数据服务器很容易称为瓶颈的缺点；    备注：        要注意的是每一个固定大小的对象(每一个数据流)都自带数据data和元数据        metadata,这样每一个数据流都被叫做一个对象2.Ceph是如何解决元数据服务器瓶颈的问题的？    Ceph在存数据的时候，为了避免有一个元数据中心服务器成为整个系统的瓶颈所在，它也采用了计算方式来解决问题；    Ceph是没有文件元数据中心服务器的，因为它的所有数据访问都是通过CRUSH算法实时计算路由的，而且计算所需的资源量    很小而且是无状态的可以按需无限制扩展；    Crush组件：        1.即当存储一个文件时它要对文件做hash计算，然后映射到对应的存储节点上去，查和读的时候也是做计算去查的，这是依靠Crush算法来实现的.        2.CRUSH算法就是ceph内部通过计算方式用来完成对象路由的一个非常重要的算法；</code></pre><h3 id="Ceph-Architecture：ceph架构"><a href="#Ceph-Architecture：ceph架构" class="headerlink" title="Ceph Architecture：ceph架构"></a>Ceph Architecture：ceph架构</h3><p>–ceph的架构<br><img src="/2018/11/03/ceph存储基础/ceph的架构.png" alt="ceph的架构"></p><pre><code>由于从根本上来讲，Ceph存储在底层是一个由多节点组成的RADOS存储集群，而这个存储集群服务是librados的API;    1.而服务是一个API就意味着是无法挂载的，如果想要存一个文件必须自己写一个对接这个api的程序才行；    2.所以为了让用户使用方便，Ceph在其存储接口api之上开发提供了三种抽象接口以便用户能够像传统意义上的存储功能一样使用Ceph.三个接口：    1.CephFS        1.就像NFS,CIFS一样是一个做好的文件系统，可以挂在到客户端        2.CephFS其实是不依赖于librados的，因为它自身就集成在rados cluster之上的        3.CephFS是最早出现的，也是最后(J版本)投入生产使用的；        4.Cephfs因为是文件系统接口可以直接在客户端进行挂载，而且还可以再次抽象成NFS/CIFS接口来使用；        5.CephFS是依靠ceph-mds服务对外提供服务的；    2.RBD        #将ceph提供的存储空间模拟成一个个独立的块设备使用，每一个块设备叫做一个image磁盘,可以对这个磁盘做分区/格式然后挂载使用；        1.RBD是使用最广泛的接口；        2.RBD是块接口的需要映射到内核才能被使用，所以要基于内核模块(librbd),由客户端主机基于librbd与RBD接口进行交互完之后，再由客户端主机对其进行分区格式化进行挂载使用；        3.如果是KVM的virt可以直接使用RBD块存储；        4.RBD是不需要守护进程的，而是使用内核模块librbd对外提供服务；    3.RadosGW        #更加抽象的、能够跨互联网使用的对象(object)存储        区别：            1.这个所谓的对象不是指ceph内部的对象，ceph内部的对象是固定大小的存储块，而且通常只在ceph集群中使用，它是基于rpc接口调用的；            2.而互联网上的OSS对象存储是基于restful接口提供的存储，每一个文件都是一个对象，而且文件大小各不相同；        RadosGW提供的是http/https协议的接口；        RadosGW是依靠ceph-radosgw对外提供服务的注意：    1.RBD/RadosGW都是为了与librados-api交互写的创建，而且CephFS/RBD/RadosGW都是RADOS的客户端，他们底层都以rados作为存储后台，他们只是这个存储后台的一种抽象层而已；    2.任何一个客户端要想接入rados cluster服务，就必须经过pool存储池来实现；    3.而且这三种客户端都有各自的专用存储池，且所需的存储池个数都不一样；</code></pre><h3 id="Ceph存储底层的工作逻辑基础"><a href="#Ceph存储底层的工作逻辑基础" class="headerlink" title="Ceph存储底层的工作逻辑基础"></a>Ceph存储底层的工作逻辑基础</h3><p>–ceph存储的组成和逻辑<br><img src="/2018/11/03/ceph存储基础/ceph存储的组成和逻辑.png" alt="ceph存储的组成和逻辑"></p><pre><code>RADOS的组成：    rados最为最底层，是应该由很多主机host组织成一个rados cluster存储集群Rados Cluster    1.rados-cluster是ceph的核心组件，它以对象化的方式把每一个文件切分成固定大小的对象，然后基于对象进行管理的；    2.每一个对象都必须经过CRUSH算法实时计算后映射到集群中的某个osd上；Host:    1.每个主机上都应该运行一些守护进行来确保每个host能够提供存储空间；    2.Host主机本地的存储空间是以什么形式供给的？    FileStore:        我们都知道ceph是对象存储，每个对象存储自带数据和元数据的，而在早期的ceph上每个host中都是由已经格式化成        xfs系统的磁盘组成，如果把对象存进来，那么又回到了将数据和元数据分开存放的形式，它一定会降低存储性能的,这就是FileStore：文件管理引擎；    BlueStore:        在后来的ceph的Host内部是直接使用磁盘来存储对象了，而这个磁盘内部有自己的裸设备管理逻辑，这种形式叫做        BlueStore，BlueStore是Ceph的新存储引擎，是社区版的默认配置；因此RADOS才是把多个节点组织为一个集群，并利用对方的存储空间整合成一个更大的存储空间，从而提供分布式的存储服务的一个非常重要的底层存储机制；OSD:    1.每一个主机host上有多个OSD(Object Storage Device),每一个OSD可以认为是一个    磁盘(FileStore意味着它是一个目录，BlueStore意味着它是一个磁盘)；    2.OSD叫做对象存储设备，每一个磁盘叫做一个OSD；MON：集群元数据监视器    在RADOS cluster中除了Host之外，还有一类节点叫做Mon    1.mon是集群元数据节点，而在前面说过ceph为了实现没有性能瓶颈是没有元数据服务器的，这里的所说的元数据节点是指    它是用来管理整个集群的元数据；    2.mon有整个集群的运行图：host节点的数量和状态、每个host上的osd数量和健康状态，每个PG的健康状态等等；    3.所以mon需要做高可用，而且mon的高可用是内部直接使用Paxos协议来实现数据冗余，任何一个节点都有完整的副本，    为了使各节点上的数据冗余是强一致的，所以使用Paxos分布式协作协议实现；    (类似etcd使用Raft协议实现高可用一样)；    [Monitor and Paxos参考文章](https://www.jianshu.com/p/53dd30054c0f)Mgr:    因为mon对集群元数据采集是实时的查询的，这种实时查询的代价是很高的，因为在Ceph的新版本(从L版开始)中引用了一个新组件mgr；    1.mgr:manager专门维护查询的操作，根据内部的逻辑将查询操作缓存下来然后再响应给客户端；Pool:存储池    类似于k8s中的namspace思想一样，将Rados cluster所提供的存储空间切成多个pool    原因：        这里说一下存储在ceph中的所有对象都是在一个平面当中的，因为ceph中没有文件系统，没有目录，是没有分层管理        的概念的，这样一来所有对象都放一起了，代来的麻烦就是管理、分类、迁移就难！    1.基于以上的原因，rados把它的存储空间切成了类似于分区大小的磁盘方便管理；    2.每一个分区叫做一个存储池pool,每个pool的大小是取决于底层rados-cluster所提供的存储空间的；    3.存储池pool必须先创建才能使用,对象只需要向这个pool请求存储就行了；    4.pool存储池的类型：        所谓存储池类型就是如何做数据冗余的:前面说过数据冗余有节点级冗余和分片级冗余；        1.而pool的存储池类型就是分片级冗余，不过这里不叫主分片/副本分片；        2.pool是以PG为单位来管理的，所以它叫做主PG和副本PG；    5.ceph还支持纠正删码池存储池        纠删码池也会选择足量的osd来，不过多个osd不是用来存副本的，而是每一个osd存一部分，另外一份存的是校验码，        必要时可以通过校验码计算出来完整数据，这样做的好处就是存储空间的利用率高了；PG：归置组    1.每一个pool的空间如果太大了，当把1亿个对象(4M大小)存进pool之后，以对象为颗粒    度进行副本管理太过于精细，代价高且维护起来太麻烦；所以还可以进一步的切分成多个PG；    2.PG就是将对象映射到OSD之间的一个虚拟中间层，是不能被创建的;    3.放到一个PG内的所有对象是被统一管理的，而且是放到同一个OSD上的；以PG为颗粒度的管理就变得简单多了；    4.pool--&gt;PG        将放在pool中的对象名字做一致性hash计算，hash的结果映射到hash环上，而这个hash环上遍布着PG，再通过顺时针找到最近的PG，然后将对象归置到这个PG上；        这只是CRUSH算法的第一步实现；    5.PG--&gt;OSD        1.这是CRUSH算法的第二步实现：需要把PG根据pool的类型和冗余副本数量找到足量的osd来动态映射；        2.而PG的主、副本是由CURSH算法来区分的；那么外部文件是如何存储到rados cluster中OSD上的？    客户端接入(CephFS/RBD/RadosGW)-&gt;切分固定大小的存储对象-&gt;pool-&gt;PG-&gt;osd    究竟要放到哪个OSD上，这中间是依靠cursh来完成的；总结：    从上面的基础概念可以概括出Ceph存储的基本组件包括：    1.OSDs    2.Monitors        #一般是3~5~7个监视器    3.Managers        #2个以上的管理器    4.MdSs        #如果要用到CephFS文件系统的话，还需要有MDSs文件系统元数据服务器，而且为了实现元数据安全MDS是要做高可用的；        #从严格意义上来说，MDS只能算是构建在RADOS存储集群之上的文件存取接口，它同RBD/RadosGW属于同一级别，而非Ceph必要组件，使用CephFS接口时才是需要的；</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;存储基础&quot;&gt;&lt;a href=&quot;#存储基础&quot; class=&quot;headerlink&quot; title=&quot;存储基础&quot;&gt;&lt;/a&gt;存储基础&lt;/h3&gt;
    
    </summary>
    
      <category term="存储" scheme="https://www.liukui.tech/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="https://www.liukui.tech/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker的资源限制</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%9A%84%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker的资源限制/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-26T13:44:29.460Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker资源限制"><a href="#Docker资源限制" class="headerlink" title="Docker资源限制"></a>Docker资源限制</h3><a id="more"></a><pre><code>docker容器得以实现的三个组件：    Namespace:内核中的名称空间是实现容器技术非常重要的组件    CGroups：实现容器的资源配额        1.如果没有资源配额的限定，比如恶意代码会占用宿主机上的很多资源，会造成其他容器无法运行的情况，        默认是宿主机上的所有资源.        2.cgroup允许将宿主机上的所有技术资源(CPU,内存等)做资源分割,以指定方式进行分配，而CPU和内存又分别支持两种不同的配额方式        3.CPU属于可压缩型资源，如果程序运行的cpu不够，只需要等待cpu资源即可，不会造成容器崩溃。        4.内存属于不可压缩型资源，如果一个进程依赖于3g内存来运行，宿主机只分配给它1g，则会造成OOM，这个进程就会因为内存耗尽而被终止.内存的限制方式：    -m|--memory= 限制容器的最大内存使用量，进程并不是一启动就占用最大内存的，而是            运行一段时间慢慢增长的，所以要分配给进程运行的最大内存.    --memory-swap * 当前容器所允许使用的交换分区大小(生产环境是禁止启用交换内存            的，因为性能会急剧下降.)    --memory-swappiness 使用交换分区的倾向性：因为使用交换分区会极大影响性能，        只有到万不得已才使用交换分区，数值越小,越会较晚使用交换分区，所以一般这个        值建议调小，默认是0-100    --memory-reservation 为系统保留多的内存空间，保证系统的正常运行    --kernel-memory  为内核保留多少内存空间    --oom-kill-disable  一旦某个容器发生OOM是否立刻kill这个容器，建议设置，因为        会造成整个宿主机的崩溃，也可以事先设定好内核和系统的内存空间，然后手动处理            发生OOM的容器，以便分析发生OOM的原因.    注意：        1.在容器内使用free命令可以看到的swap空间并不具有其所展现的空间指示意义.        2.-m|--memory=和 --memory-swap *一般是结合起来生效的CPU的限制方式：    主流的分两种：共享式和CPU绑定式    --cpu-shares 共享方式是基于权重分配的，而且是根据容器的数量和CPU的权重动态            分配调整的.如果只有一个容器在运行，那么这个容器也会尽可能的占用宿主机的CPU资源，这种分配方式依然会有可能造成系统崩溃.    --cpus &lt;value&gt; 定义容器最多跑满宿主机的几个核心数，例如宿主机有8核，限制容器        最多跑满2个核心数，而且这个2核可以跑在8个核心上加起来是2个核心数，也可以是        在2个核心上跑满.真正限制了容器使用的最大核心数.        docker的1.13版以后都使用这个选项来定义.    --cpuset-cpus         定义容器只能跑在宿主机核心的几号核心上，例如只允许跑在1号和3号核心上，那么        这个容器最多也就只能跑满这两个核心,也叫CPU绑定.</code></pre><p>所以在创建启动容器一定要做资源限制，即使不清楚容器中某个程序要占用多大的资源时，也应该设置只允许占用宿主机一半的资源.</p><h3 id="资源限制压测"><a href="#资源限制压测" class="headerlink" title="资源限制压测"></a>资源限制压测</h3><pre><code>在docker hub上的lorel/docker-stress-ng镜像    -c N 启动几个进程对CPU进行压测    -vm N 启动几个进程对内存做压测示例：通过该镜像进行压测    限制只能跑在cpu的0号和3号上，最多只能跑满2个核心数    限制最多占用512m的内存大小docker run --name stress --cpus 2 --cpuset-cpus 0,3 -m 512m --rm lorel/docker-stress-ng -c 2 -vm 2</code></pre><p>-docker stats命令查看结果<br><img src="/2018/10/18/Docker的资源限制/docker-stats.png" alt="docker status"></p><p>-top命令显示宿主机资源(安装1显示全部的CPU核心数信息)<br><img src="/2018/10/18/Docker的资源限制/top命令.png" alt="top命令"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker资源限制&quot;&gt;&lt;a href=&quot;#Docker资源限制&quot; class=&quot;headerlink&quot; title=&quot;Docker资源限制&quot;&gt;&lt;/a&gt;Docker资源限制&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile</title>
    <link href="https://www.liukui.tech/2018/10/18/Dockerfile/"/>
    <id>https://www.liukui.tech/2018/10/18/Dockerfile/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-22T08:38:18.043Z</updated>
    
    <content type="html"><![CDATA[<h3 id="DockerFile：构建镜像"><a href="#DockerFile：构建镜像" class="headerlink" title="DockerFile：构建镜像"></a>DockerFile：构建镜像</h3><a id="more"></a><pre><code>前面说过：    1.镜像是分层的，当基于这个镜像创建一个容器时，docker是通过联合挂载机制把镜像层    进行叠加作为容器的只读层，而后又在这个镜像栈上构建了一个可写层作为这个容器的工    作目录.    2.所有的底层数据在第一次发生修改操作时，是通过CoW写时复制机制，把数据复制到读    写层进行修改并保存在读写层，覆盖底层的原始文件；写入新数据时，则直接保存在读写    层，而在读写层看到的数据就是全部的镜像层数据(镜像栈)    3.而Graph Driver则又在构建在本地文件系统之上的二级文件系统(aufs,overlay2)    4.基于Graph Driver这种特有的图形驱动程序，就可以把分成构建的镜像堆积在存储    空间当中，紧邻的镜像是有依赖关系的    5.docker commit可以把当前的读写层及其底层依赖的镜像关系打包成一个镜像层存储    在Graph Driver当中，并且指向底层依赖的镜像层，形成一个新的镜像层，如果基于    同一个镜像commit多个可写层，这些新的镜像层都是指向之前的底层镜像的，这也是    docker镜像不是很大的原因。    6.所以在制作镜像时，完全不必基于某个基础镜像显示启动一个新容器，然后在上面创建    修改可写层并打包成镜像；commit只是一种方式，也可以使用dokcerfile    7.如果再本地将软件源码编译/二进制编译到容器也是可以的</code></pre><h3 id="dockerfile基本要求"><a href="#dockerfile基本要求" class="headerlink" title="dockerfile基本要求"></a>dockerfile基本要求</h3><pre><code>1.dockerfile的工作逻辑：    制作镜像无非就是基于某个基础镜像创建一个可写层修改后再commit成一层新的镜像    这个过程可以由docker自身完成，只需要在dockerfile配置文件中写清楚，基于哪个基础镜像，    按需修改(通过各种指令生成)，而docker build可以读取dockerfile文件，隐    式的执行这些指令集生成一个新的镜像层保存在Graph Driver中2.工作目录    构建docker镜像时，必须有一个工作目录docker,这个目录下只存在dockerfile和在    dockerfile中定义要复制的文件，是起始目录3.dockerfile format：语法    dockerfile就是一个纯文本文件;        注释行        dockerfile instruction args:指令要纯大写        第一条指令必须是FROM：基础镜像名称        docker build是按顺序读取执行dockerfile中的指令集的4.dockerfile中的每一条指令都会生成一个新的镜像层    如果指令比较多，生成的镜像层就比较多，就会造成第一次的CoW从底层读取数据时很慢    但是镜像层比较多又容易被分享和易控，较少又会比较繁琐    所以一般是把做同一个件事的多个操作通过\换行符，用一条指令完成(见下文)5.镜像内唯一要运行的程序一定必须要运行在前台</code></pre><h3 id="dockerfile中的环境变量"><a href="#dockerfile中的环境变量" class="headerlink" title="dockerfile中的环境变量"></a>dockerfile中的环境变量</h3><pre><code>1.docker为了满足同一镜像在不同环境下的使用场景引入了环境变量的方式    某个容器基于镜像启动时，通过传递环境变量参数，来生成容器内的不同的配置文件    docker container run --name CONTAINER_NAME -e VAR -it IMAGE_NAME COMMAND    这样一来，就可以用基于同一基础镜像，传递不同的环境变量作为参数值，创建适应    于不同环境的容器2.entrypoint.sh脚本    但是传统的代码不支持传环境变量作为参数，而在docker中又需要传参，这时就有了衔接    层也就是shell脚本，这个脚本作为容器第一个要运行的程序然后运行完退出，再退出去    之前读取用户传的环境变量，将环境变量的值写到程序的配置文件中；    而且很多镜像通过docker image inspect mysql:8.0 |grep entrypoint过滤是可以    看到有这个脚本的3.环境变量的两类用法：    a.在构建dockerfile中使用    b.以dockerfile构建的镜像为基础镜像，启动容器时使用    而dockerfile中的指令的生命周期是有两个阶段的        build：基于基础镜像构建镜像的阶段        run: 启动容器的阶段        dockerfile中的一些指令或者环境变量在不同阶段使用发挥的价值是不一样的4.环境变量的设定和引用    设置：ENV statement    两种引用方式：    1.${variable:-word}         如果变量variable为空或不存在时，就使用word值        如果设置了variable，就使用该变量值    2.${variable:+word}         如果变量有值，就使用word值，如有没值就是空值</code></pre><h3 id="dockerignore-file"><a href="#dockerignore-file" class="headerlink" title=".dockerignore file"></a>.dockerignore file</h3><pre><code>1.dockerignore是工作目录中专门记录需要忽略的文件列表2.而且docker build会自动忽略.dockerignore自身和记录在其中的所有文件</code></pre><h3 id="Dockerfile基本语法"><a href="#Dockerfile基本语法" class="headerlink" title="Dockerfile基本语法"></a>Dockerfile基本语法</h3><pre><code>FROM：    FROM必须是文件的第一指令    FROM &lt;repository&gt;[:&lt;tag&gt;  镜像的标签    或者&lt;resository&gt;@&lt;digest&gt; 镜像的ID号校验码        推荐使用digest因为校验码是安全的，而且最好不要使用lastedLABLE:    authtor&apos;s infomation;提供该镜像的标签信息    语法： maintainer &quot;liu &lt;liu@163.com&gt;&quot;COPY:    从宿主机复制文件至创建的新镜像    COPY &lt;src&gt;... &lt;dest&gt;    COPY [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]         &lt;src&gt;：要复制的源文件或目录，支持使用通配符        &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则，COPY指定则以WORKDIR为其起始路径；        注意：在路径中有空白字符时，通常使用第二种格式    注意：    1. src：必须为build上下文中的路径，可使用相对路径    2.如果src是目录，其内部的文件或子目录会自动被递归复制，但src自身不会被复制            等于cp -r /src/* /dest/    3. src有多个，或者src使用通配符，则dest必须是一个目录，且必须以/结尾    4. 如果dest事先不存在，它将会被自动创建ADD:    类似于COPY，但是额外支持tar文件和URL路径    ADD &lt;src&gt;... &lt;dest&gt;    ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]    1. 如src为URL时且dest不以/结尾，ADD会自动将指定的文件下载并创建为dest，        如dest以/结尾，则会下载指定的文件并保存为dest/FILENAME        即一个是下载并改名，一个是下载到这个文件目录下    2. 如src是一个本地的tar文件，则会被自动展开为一个目录，但通过URL获取到的文件        则不会自动展开，即在本地的就展开，互联网的就不展开    3. 如src有多个，或使用通配符，则dest必须是目录且以/结尾，如dest不以/结尾，        则被视为一个普通文件，src的内容将被直接追加写入到dest文件中WORKDIR：    1.用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录    2.WORKDIR指令可出现多次，表示下个指令可以以此目录为父目录，路径可以表示为相对    路径，也可以写成绝对路径    3.WORKDIR的有效范围当前workdir向下，下一个workdir之前的范围    4.另外，WORKDIR也可调用由ENV定义的环境变量的值，如果下次修改环境变量的值，响应生成信息的镜像层    5.而且如果设定了WORKDIR，容器启动时，默认就进入到workdir路径了VOLUME：    用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷    注意：        1.在dockerfile中定义的卷，启动容器时，是被docker管理的卷与宿主机的某个            路径建立关联关系        2.如果需要定义的卷与宿主机特定的目录建立关联关系，还需要在run container时            指定-v选项        3.如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此            前的所有文件复制到新挂载的卷中EXPOSE:都是动态端口暴露    用于为容器打开指定要监听的端口以实现与外部通信    EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...]       &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议    注意：        1.即使在dockerfile中定义了暴露的端口，启动为容器时，端口也不会暴露的            因为是有安全风险的；        但可以用run container时加 -P选项强行暴露端口，但这是个动态端口暴露        用起来极其鸡肋！ENV：    build阶段使用的：        用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令        如ENV、ADD、COPY等）所调用，调用格式为$variable_name或${variable_name}    两种语法：    1.ENV &lt;key&gt; &lt;value&gt;         &lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只        能设置一个变量；    2.ENV &lt;key&gt;=&lt;value&gt; ...        可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果        &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另外，反斜线也可用于续行；    定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能    缺点：如果想修改ENV定义的值，只能修改dockerfile中的值，比价麻烦，此时    就可以使用ARG来代替ENVARG：    arg是在build阶段进行传值，替换dockerfile中的值        ARG &lt;name&gt; [=&lt;default&gt;] 可以设置默认值    当build创建镜像时没有传值，则使用在dockerfile中设置的默认值    既可以弥补ENV的缺点也可以和RUN，CMD的ENV传环境变量区别开    如：在build时更改home的值    docker image build --build-arg home=&quot;/webdata/&quot; /data/dockerfile/ -t myimg:v0.4</code></pre><h4 id="RUN-CMD-ENTRYPOINT的区别"><a href="#RUN-CMD-ENTRYPOINT的区别" class="headerlink" title="RUN,CMD,ENTRYPOINT的区别"></a>RUN,CMD,ENTRYPOINT的区别</h4><p><img src="/2018/10/18/Dockerfile/三者区别.png" alt="三者的区别"></p><p>区别：</p><pre><code>RUN：    用于指定docker build过程中运行的程序，可以是任何命令                (这就意味着RUN的命令必须是使用的基础镜像支持的命令)    1.是指在docker build过程中通过运行RUN定义的shell命令，以达到在镜像中安装软件等操作    2.RUN可以设定多次，而且每一个都会在build的时执行    语法：        RUN &lt;command&gt;            通常运行的是一个shell命令，且以&quot;/bin/sh -c&quot;运行，且/bin/sh是PID为1的进程，command是作为shell的子进程存在        RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;]            此种格式指定的命令不会以&quot;/bin/sh -c&quot;，因此无法支持shell的诸多特性，如要依赖于shell特性，可替换成如下格式：            RUN [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;]CMD：    1.当把镜像运行容器时，需要指定默认运行的程序，这在dockerfile中需要用CMD命令来        指定，ENTRYPOINT也可以    2.默认运行的程序必须运行在前台    3.由于CMD设定的是容器启动默认运行的程序，所以必须只有一个，如果有多个，        则最后一个CMD生效    语法：        CMD &lt;command&gt; 或        CMD [“&lt;executable&gt;”, “&lt;param1&gt;”, “&lt;param2&gt;”] 或        CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]        前两种语法格式的意义同RUN        第三种则用于为ENTRYPOINT指令提供默认参数    systemctl start httpd启动是运行在systemd的前台上，所以启动就会退出ENTRYPOINT：    1.CMD和ENTRYPOINT都表示镜像启动为容器时，容器默认运行的程序，而且CMD和ENTRYPOINT有多个，也都是最后一个生效    2.如果CMD和ENTRYPOINT同时存在，CMD和ENTRYPONIT需要组合起来，则CMD指定的内容    都作为ENTRYPOINT所指定内容的参数    语法：        ENTRYPOINT &lt;command&gt;或者        ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;]    docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到    ENTRYPOINT命令最后做为其参数使用    Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效</code></pre><p>示例：<br>    docker run –name c1 -P -d myimg:v0.1 以后台运行容器</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;DockerFile：构建镜像&quot;&gt;&lt;a href=&quot;#DockerFile：构建镜像&quot; class=&quot;headerlink&quot; title=&quot;DockerFile：构建镜像&quot;&gt;&lt;/a&gt;DockerFile：构建镜像&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>docker存储卷</title>
    <link href="https://www.liukui.tech/2018/10/18/docker%E5%AD%98%E5%82%A8%E5%8D%B7/"/>
    <id>https://www.liukui.tech/2018/10/18/docker存储卷/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-07T11:44:05.627Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Data-Volume：docker存储卷"><a href="#Docker-Data-Volume：docker存储卷" class="headerlink" title="Docker Data Volume：docker存储卷"></a>Docker Data Volume：docker存储卷</h3><a id="more"></a><pre><code>存储卷是什么：    存储卷是容器上一个或者多个“目录”，并将此“目录”与宿主机上的某目录建立关联关系，    存储卷在容器初始化之时会被创建，由baseimage提供的卷中的数据数据会在此时完成复制为什么需要用到存储卷:    docker启动一个容器是基于镜像的只读层，并在其上添加一个读写层，而镜像是由多个只读层叠加而来。如果运行中    的容器修改了现有一个已存在的文件，那该文件将会从只读层复制到读写层，而该文件的只读版本仍然存在，只是    被读写层中该文件的副本所隐藏而已，而此时关闭该容器，该容器所修改的文件的将会丢失且不能被其它容器共享、复用，因而需要一个存储卷。如何实现容器内的路径与容器外的存储建立关联关系？    实际应用场景：        1.通常在可写层上只保存临时数据，有效数据保存在和宿主机关联的目录下，这样就        剥离了程序和产生的数据间紧密的耦合关系，即程序在容器的名称空间上，数据在        宿主机或存储上，数据就独立于容器的生命周期之外        2.当容器down后，再启动一个新容器，指定数据路径为宿主机或存储上的路径，则        又恢复了数据，这就叫做Docker的存储卷存储卷存在的问题：    存在的问题        •存储于联合文件系统中，不易于宿主机访问；        •容器间数据共享不便        •删除容器其数据会丢失    解决方案：“卷(volume)”        •“卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机            上的某目录“绑定(关联)”        •Volume于容器初始化之时即会创建，由base image提供的卷中的数据会于此期间            完成复制        •Volume的初衷是独立于容器的生命周期实现数据持久化，因此删除容器之时既不会        删除卷，也不会对哪怕未被引用的卷做垃圾回收操作；存储卷的type:    1. Bind mount volume        绑定挂载卷，永久生效        容器内目录和宿主机中的目录都是由用户自己指定的，    2. Docker-managed volume：        称为docker自己指定的卷        容器中的卷是用户自己指定的，而宿主机上的目录是由docker-daemon进程自行        决定与宿主机的哪个目录建立        关联关系的存储卷，只能用于临时挂载。存储卷的相关命令:    docker run         -v 运行时，指定存储卷        --volumes-from list 复制其他容器的卷，达到共享卷的目的        --sorkdir string    docker volume         ls：列出当前已和宿主建立关联关系的存储卷        create：        inspect name:查看一个卷的详细信息        prune        rm: 因为docker container inspect c1看到的容器内的详细信息是JSON格式的    所以就可以通过过滤特殊字段显示查询的信息    docker container inspect CONTAINER_NAME -f {{.JSON_VALUE}}     Docker-managed volume        • ~]# docker run -it -name c1 –v /data busybox        • ~]# docker inspect -f {{.Mounts}} c1        • 查看c1容器的卷、卷标识符及挂载的主机目录            和docker container inspect c1的过滤效果一样    Bind-mount Volume        • ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name c1 busybox        • ~]# docker inspect -f {{.Mounts}} c1如图以过滤IP地址为例，其他信息类似</code></pre><p><img src="/2018/10/18/docker存储卷/JSON格式的过滤.png" alt="JSON格式过滤"></p><pre><code>示例1.Docker-managed volume    临时创建挂载一个mydata卷        docker run --name c1 -it  --rm -v /mydata busybox:latest        并通过docker container inspect c1 探测        mydata被docker指定与宿主机的哪个目录建立了关联关系</code></pre><p><img src="/2018/10/18/docker存储卷/docker管理的卷.png" alt="docker管理的卷"></p><font size="3" color="#FF0000"><br>从上图看mydata是被docker-manager指定与该容器目录下的_data建立了关系<br>注意：<br>创建容器的时候加–rm选项时，停止容器后，宿主机上的卷也会被删除的<br>不加–rm选项，停止容器，并rm容器，宿主机上的卷是不会被删除的<br>缺点是对应的宿主机上的目录难查找<br></font><pre><code>示例2.Bind mount volume    现在宿主机上创建卷的目录 mkdir /data/volume/c1docker run --name c1 -it  --rm -v /data/volumes/c1:/mydata busybox:latest     并通过docker container inspect c1 </code></pre><p><img src="/2018/10/18/docker存储卷/bind卷.png" alt="bind卷"></p><font size="3" color="#FF0000"><br>可以看出宿主机的/data/volumes/c1与容器内的/mydata是建立的bind类型的卷<br>即使容器被删除，数据还在存在的<br>而且如果/data/volume/c1是在NFS网络文件系统上的话，即使宿主机down了，数据也是无损的<br></font><pre><code>示例3：多容器之间的数据共享1.先创建容器c1docker run --name c1 -it  --rm -v /data/volumes/c1:/mydata busybox:latest 2.创建容器c2时，共享容器c1的卷    docker run --name c2 -it  --rm --volumes-from c1 busybox:latest    此时c1和c2上看到的mydata卷看的数据都是一样的，达到共享卷的目的示例4.用docker实现类似于k8s上的pod组件机制    要求：        1.c1上挂载多个NFS存储上的卷和bridge桥        2.c3和c4使用c1的网络名称空间和c1上的卷    实现：    c1:        docker run --name c1 -v /data/volumes/c1:/mydata -v /data/volume2:/mydata2 busybox:latest     c3.    docker run --name c3 -it --rm --network container:c1 --volumes-from c1  busybox:latest    c4.    docker run --name c4 -it --rm --network container:c1 --volumes-from c1  busybox:latest</code></pre><p><img src="/2018/10/18/docker存储卷/实现docker的pod组件模型.png" alt="实现docker的pod组件模型"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Data-Volume：docker存储卷&quot;&gt;&lt;a href=&quot;#Docker-Data-Volume：docker存储卷&quot; class=&quot;headerlink&quot; title=&quot;Docker Data Volume：docker存储卷&quot;&gt;&lt;/a&gt;Docker Data Volume：docker存储卷&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker网络</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%BD%91%E7%BB%9C/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker网络/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-02-15T08:21:33.861Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Network"><a href="#Docker-Network" class="headerlink" title="Docker Network"></a>Docker Network</h3><a id="more"></a><p><img src="/2018/10/18/Docker网络/docker的四种网络.png" alt="docker的四种网络"></p><pre><code>KVM上虚拟桥接式网络类型：        隔离桥：只能与连接到同一个桥上的主机通信，IP地址还需要在同一网段        仅主机桥：可以和连接的桥地址进行通信        路由桥：            1.打开宿主机核心转发功能            2.虚拟机的网关都指向这个桥的地址            就可以与宿主机通信，不能与外网通信        NAT桥：在路由桥的基础上，在宿主机上做SNAT规则，即可访问外网地址    Docker提供的四种网络：    桥网络：桥接网络            bridge，默认就是docker0桥，docker0是SNAT桥            查看网络定义：docker network inspect bridge            大多数的容器还是使用bridge网络            而且这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器    共享桥：联盟式网络         每一个容器都是靠在内核级虚拟资源分配的独立的6种名称空间来支撑的        这6种名称空间是IPC,Net,Mount,UTS,PID,USER        虽然每个容器都有各自独立的名称空间，但是确可以共享，于是就有了这种方式        共享桥的原理：                共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈            而mount user PID还是隔离的，文件系统也是隔离的        这样做的效果就可以构建出一个模型            httpd---&gt;fpm127.0.0.1:9000---&gt;mysql127.0.0.1:3306            那么对于fpm和mysql来说只监听在本地端口上，保证了安全性    host宿主机网络：共享宿主机网络        既然多个容器可以使用同一个容器的网络名称空间，而且宿主机在内核中也有自己的        网络名称空间，那么容器也理所当然的可以使用宿主机的网络名称空间        容器使用宿主机的网络和DNAT方式有关系        作用：可以做日志收集主机，host一般在特殊环境下使用    none网络：封闭式网络        当容器不需要网络服务时，不创建网卡，只有本地lo网卡除了bridge桥之外，其他三种网络都是docker所独有的</code></pre><h3 id="Docker网络的相关命令"><a href="#Docker网络的相关命令" class="headerlink" title="Docker网络的相关命令"></a>Docker网络的相关命令</h3><pre><code>docker run 命令中涉及网络的相关命令    --network 启动容器时，指定使用的网络        [bridge|host|none|container:name]    --hostname 启动容器时，指定容器的主机名    --add-host list 启动容器时，指定内部的hosts解析文件        如：docker run --add-host c1:192.168.10.1 busybox:latest            cat /etc/hosts可以看到添加的解析    --dns 启动容器时，指定DNS地址        如：docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest            cat /etc/resolve可以看到指定的DNS地址    --ip string 启动容器时，指定容器的iPv4地址    -p|--publish         因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则docker network:    ls：显示docker内部的全部网络    connect: 让容器连接到某个网络上    disconnect: 把容器从某个网络断开    create: 创建自定义网络，和KVM创建网络类似    inspect:查看某个网络是怎么定义的    prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令    rm: 删除docker内部的网络</code></pre><h3 id="Docker-network的端口暴露"><a href="#Docker-network的端口暴露" class="headerlink" title="Docker network的端口暴露"></a>Docker network的端口暴露</h3><pre><code>docker run --network [bridge|host|none] -p|--publish     作为一个容器，是要提供web服务的，而docker默认的桥是bridge，而且是个SNAT桥    容器只能访问外网，而不能被外网所访问，那么就失去了web服务器对外提供服务的初衷    而docker提供了一个-p选项来自动生成DNAT规则，来避免每次都手写DNAT规则带来的麻烦-p选项的用法和使用格式：    •-p &lt;containerPort&gt;        将指定的容器端口映射至主机所有地址的一个动态端口    •-p &lt;hostPort&gt;:&lt;containerPort&gt;        将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt;    •-p &lt;ip&gt;::&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口    •-p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt;    “动态端口”指随机端口，具体的映射结果可使用docker port命令查看    不过一般还是要使用第四种方式指定宿主机的端口    指定了映射的端口后，可以使用命令查看映射关系：        docker container port [name]示例：1.docker run --name c1 -it --rm --network bridge -p 80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:327682.docker run --name c1 -it --rm --network bridge -p 80:80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:803.docker run --name c1 -it --rm --network bridge -p 192.168.34.103::80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:327684.docker run --name c1 -it --rm --network bridge -p 192.168.34.103:80:80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:80</code></pre><h3 id="Docker的自定义网络"><a href="#Docker的自定义网络" class="headerlink" title="Docker的自定义网络"></a>Docker的自定义网络</h3><pre><code>docker network create     connect:相当于创建一对网卡，一半在桥上，一半在容器中    而且默认创建的网络都是SNAT桥    选项：    -d|--driver string 创建时，要指定桥的类型        默认是bridge，当然还有 host macvlan null overlay四种类型    --gateway strings 默认是定义的子网的第一个IP地址    --subnet strings 子网地址    --ip-range strings 地址分配的IP地址范围修改默认的bridge，docker0桥的子网    自定义docker0桥的网络属性信息：也就是镜像加速的文件    vim /etc/docker/daemon.json文件    {        &quot;bip&quot;: &quot;192.168.1.5/24&quot;,        &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;,        &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,        &quot;mtu&quot;: 1500,        &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,        &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,        &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]    }     核心选项为bip，即bridge 桥接口的IP地址    ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。示例：    1.创建一个mybr2的网络，并指定子网地址        docker network create --subnet 10.0.0.0/8 mybr2    2.创建容器c1指定加入到mybr2网络中        docker run --name c1 -it --rm --network mybr2  busybox:latest    3.给容器c1再加入一个bridge网络中        docker network connect bridge c1        此时c1就有了两个网络地址    4.删除容器c1的网卡        docker network disconnect mybr2 c1</code></pre><h3 id="Docker指定容器启动的网路类型"><a href="#Docker指定容器启动的网路类型" class="headerlink" title="Docker指定容器启动的网路类型"></a>Docker指定容器启动的网路类型</h3><pre><code>1.启动为none类型的网络    docker run --name c1 -it --rm --network none busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/none网络.png" alt="none网络"></p><pre><code>2.启动为bridge类型的网络:docker默认的网络模型    docker run --name c2 -it --rm --network bridge busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/bridge网络.png" alt="bridge网络"></p><pre><code>3.启动为joined类型的网络    启动的c3共享的是c2的Net,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的</code></pre><p><img src="/2018/10/18/Docker网络/共享桥网络.png" alt="共享桥网络"></p><p>因为共享桥只是共享了Net网络，UTS主机名，IPC，<br>此时IP地址和hostname都是一样，就可以通过127.0.0.1进行通信了<br>而mount(文件系统)，user,PID还是隔离的，所以在1上创建一个文件，2上是看不到的<br>这就是共享桥的工作机制</p><pre><code>4.启动为host宿主机类型的网络    docker run --name c4 -it --rm --network host busybox:latest    可以看出hostname,Net都是和宿主机是一样的    此时在容器内部启动httpd服务，其他主机是可以通过宿主机提供服务的</code></pre><p><img src="/2018/10/18/Docker网络/host网络.png" alt="host网络"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Network&quot;&gt;&lt;a href=&quot;#Docker-Network&quot; class=&quot;headerlink&quot; title=&quot;Docker Network&quot;&gt;&lt;/a&gt;Docker Network&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker仓库管理工具Harbor</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7Harbor/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker仓库管理工具Harbor/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-27T03:25:41.692Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker仓库管理工具Harbor"><a href="#Docker仓库管理工具Harbor" class="headerlink" title="Docker仓库管理工具Harbor"></a>Docker仓库管理工具Harbor</h3><a id="more"></a><p><img src="/2018/10/18/Docker仓库管理工具Harbor/harbor架构.png" alt="harbor架构"></p><p><a href="https://goharbor.io/" target="_blank" rel="noopener">HARBOR</a><br><a href="https://github.com/goharbor/harbor" target="_blank" rel="noopener">github上的harbor</a></p><pre><code>harbor官方功能介绍：    1.基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可        以对多个镜像仓库在同一命名空间（project）里有不同的权限。    2.镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡，        高可用，混合云和多云的场景。    3.图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，        管理项目和命名空间.    4.Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。    5.AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。    6.审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。依赖环境和使用介绍：    1.harbor是基于distribution二次开发的企业级私有仓库，云原生registry，多租户机制，允许用户创建自己的名称空间    2.因为harbor内置了mysql,nginx等服务才能构建一个harbor,所以依赖于docker-compose进行容器编排和依赖于至少docker-17.03.0版本    3.harbor为了安全，也需要以https运行，需要在harbor服务器提供证书，而且也需要为        其他客户端提供证书，为harbor验证使用，当然可以关闭https功能    4.因为需要实时下载镜像，提供了离线安装和在线安装，也可以安装到vSphere平台(OVA方式)虚拟设备。</code></pre><h3 id="离线版安装和配置："><a href="#离线版安装和配置：" class="headerlink" title="离线版安装和配置："></a>离线版安装和配置：</h3><p><a href="https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.1.tgz" target="_blank" rel="noopener">harbor离线安装包下载</a><br><a href="https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md" target="_blank" rel="noopener">离线版安装部署文档</a></p><pre><code>1.先安装docker-compose，docker-ce    yum install docker-compose docker-ce -y2.tar xf harbor-offline-installer-v1.4.0.tgz -C /usr/local/3.cd /usr/local/harbor并修改主配置文件harbor.cfg    [root@mysql_2 harbor]# grep &quot;^[a-Z]&quot; harbor.cfg         hostname = mysql_2      #设置主机名/IP        ui_url_protocol = http      #访问协议，支持http和https        max_job_workers = 10        #最大进程连接数    #####设置使用https协议的证书和路径#####        customize_crt = on          #是否使用自定义证书        ssl_cert = /data/cert/server.crt        ssl_cert_key = /data/cert/server.key        secretkey_path = /data        log_rotate_count = 50       #本地最多保存50次日志滚动        log_rotate_size = 200M      #当日志达到200M时滚动一次        http_proxy =                #是否使用代理        https_proxy =        no_proxy = 127.0.0.1,localhost,core,registry    ####设置用户上下载镜像时，是否启用发邮件功能#########        email_identity =         email_server = smtp.mydomain.com        email_server_port = 25        email_username = sample_admin@mydomain.com        email_password = abc        email_from = admin &lt;sample_admin@mydomain.com&gt;        email_ssl = false        email_insecure = false    ####使用互联网上的邮箱##############        harbor_admin_password = Harbor12345    #harbor默认的管理员密码        auth_mode = db_auth                    #默认使用的数据库类型        db_host = mysql         #设置连接mysql的端口和用户密码        db_password = root123        db_port = 3306        db_user = root         #这里还支持 ldap 以及 本地文件存储方式。    #####修改数据库类型和用户和密码#########4.运行install.sh    因为是离线安装包，会从tar文件中装入所需的镜像文件并启动，启动时会检查    docker-ce和docker-compose的版本开始加载镜像(mysql,redis,nginx等等)    [root@mysql_2 harbor]# ./install.sh     [Step 0]: checking installation environment ...    Note: docker version: 18.09.0    Note: docker-compose version: 1.18.0    [Step 1]: loading Harbor images ...</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/harbor安装过程.png" alt="创建并启动的所有容器"><br><img src="/2018/10/18/Docker仓库管理工具Harbor/和harbor相关的所有容器.png" alt="创建并启动的所有容器2"></p><pre><code>5.启用的容器可能会使用宿主机的名称空间6.通过docker-compose管理harbor    cd /usr/local/harbor/    docker-compose stop    docker-compose start</code></pre><p>登录web管理界面：<a href="http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码" target="_blank" rel="noopener">http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码</a><br><img src="/2018/10/18/Docker仓库管理工具Harbor/登录页面.png" alt="登录页面"></p><pre><code>7.创建用户和测试仓库：    创建lk用户，测试登录    创建test仓库用于测试上传镜像 直接创建test仓库即可</code></pre><h3 id="内网服务器登录harbor"><a href="#内网服务器登录harbor" class="headerlink" title="内网服务器登录harbor"></a>内网服务器登录harbor</h3><p>-登录报错<br>–Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。<br>如果配置文件中启用了https，而且也有证书等信息，就不会有这个报错<br><img src="/2018/10/18/Docker仓库管理工具Harbor/登录报错.png" alt="docker login报错"></p><pre><code>解决方法：    1.在所有的内网需要上传下载镜像的服务器上都创建daemon.json文件        vim /etc/docker/daemon.json        {           &quot;insecure-registries&quot;:[&quot;192.168.100.17&quot;]           ###该选项表示从不安全的仓库下载或上传镜像        }    2.还要注意：        如果[&quot;192.168.100.17&quot;]中使用的主机名，那么需要在本地hosts文件或者局域网DNS        服务器上进行主机名解析    3.也可以修改vim /usr/lib/systemd/system/docker.service文件        vim /usr/lib/systemd/system/docker.service             ExecStart=/usr/bin/dockerd  --insecure-registry 192.168.100.17        重启docker            systemctl daemon-reload            systemctl restart docker    4.docker login 192.168.100.17|主机名 #登录私有harbor仓库      docker logout 192.168.100.17|主机名 #退出私有harbor仓库</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/成功登录.png" alt="成功登录"></p><pre><code>4.制作镜像并测试上传    制作镜像：docker tag httpd:v0.1 192.168.100.17/test/httpd:v1                将之前制作好的镜像改标签再上传上去            docker image build . -t 192.168.100.17/test/httpd:v2.0                也可以通过dockerfile重新制作一个再上传    上传到test仓库中: docker push 192.168.100.17/test/httpd:v1</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/上传.png" alt="上传镜像"><br><img src="/2018/10/18/Docker仓库管理工具Harbor/上传镜像.png" alt="上传镜像"></p><pre><code>5.测试拉取镜像    在页面上点击复按钮，在命令行中就可以拉取镜像了</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/拉取镜像.png" alt="拉取镜像"></p><h3 id="如何修改配置："><a href="#如何修改配置：" class="headerlink" title="如何修改配置："></a>如何修改配置：</h3><pre><code>[root@linux-host1 harbor]# /usr/local/harbor[root@linux-host1 harbor]# docker-compose   stop #先停止服务[root@linux-host1 harbor]# vim harbor.cfg  #编辑配置[root@linux-host1 harbor]# docker-compose start #重新启动服务</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker仓库管理工具Harbor&quot;&gt;&lt;a href=&quot;#Docker仓库管理工具Harbor&quot; class=&quot;headerlink&quot; title=&quot;Docker仓库管理工具Harbor&quot;&gt;&lt;/a&gt;Docker仓库管理工具Harbor&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker镜像</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E9%95%9C%E5%83%8F/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker镜像/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-02-15T05:54:46.540Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Images"><a href="#Docker-Images" class="headerlink" title="Docker Images"></a>Docker Images</h3><a id="more"></a><font size="3" color="#FF0000"><br>1.docker image是docker贡献给容器极具创造性的使用方式！<br>2.分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！<br>3.容器编排技术：<br>—Docker通过镜像机制极富创造性的解决了应用程序打包的根本性难题，它推动了容器技术的快速普及和生产落地<br>—容器本身仅提供托管运行应用的底层逻辑，而容器编排(Orchestration)才是真正产生价值的位置所在；<br></font><p>-docker-image和读写机制<br><img src="/2018/10/18/Docker镜像/docker读写机制.png" alt="docker-image和读写机制"></p><pre><code>1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器    a.docker镜像就像KVM镜像一样，包含了启动容器/虚拟机所依赖的所有文件，文件系统        包括程序文件，库文件，配置文件,数据目录等等    b.dokcer采用分层构建机制，最底层为bootfs，其上是rootfs        bootfs：在创建的容器中是看不到的，只是用于系统引导的文件系统，包括                bootloader和kernel，因为在创建启动容器时，其实是用到内核的，                只不过只是启动引导容器启动的，当容器启动完成后会被卸载以节约内存资源;                而且把对应的对容器的管理委托给宿主机的内核，所以容器镜像的内核只                是启动时有用，而且看不到，所以bootfs叫引导文件系统        rootfs:位于bootfs之上，表现为docker容器的根文件系统;                1.在传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只                    读&quot;模式，完整性自检完成后将其重新挂载为读写模式；也就是fstab                    的最后两项，只有通过自检次序时，才会把根文件系统重新以&quot;读写&quot;方式挂载.                2.但是在docker中，rootfs由内核挂载为&quot;只读&quot;模式，就算容器启动完成                    ，rootfs也不会以读写方式重新挂载！也就是说docker容器的用户空                    间和根文件系统一直都是只读的！                3.docker是通过&quot;联合挂载&quot;技术额外挂载一个“可写”层；docker image layer2.Docker Images Layer    如上图    a.完整的docker镜像包括bootfs,rootfs    b.而rootfs又包括Base Image+自定义的镜像层+可写层writable        除了writable是可写层，其他都是只读层    c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加        一个可写层，这个可写层writable是属于容器的    d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的</code></pre><h4 id="容器的读写原理："><a href="#容器的读写原理：" class="headerlink" title="容器的读写原理："></a>容器的读写原理：</h4><p>如上图示： </p><ul><li>1.对于docker来说有一个专门存放镜像的路径叫Graph Driver，而这个文件系统必须是特殊<br>  格式的(aufs或者overlay2),在linux系统内默认是/var/lib/docker/image/overlay2；<br>  overlay2目录就是构建在宿主机(xfs或ext4)的/var/lib/docker/image/目录的二级文件系统</li></ul><ul><li>2.前面说镜像数据文件都放在bootfs和rootfs上的，可写层writbale是创建时创建的<br>  那么在可写层上是如何看到底层的数据目录？又是怎么把数据增删改到容器内的？<br>  默认xfs和ext4是不支持COW机制的</li></ul><blockquote><p>如何看到镜像目录的？</p></blockquote><pre><code>a.在创建容器时，是把镜像内的多层镜像通过联合挂载方式作为可写层的底层，也就是这个容器内部的可访问文件系统接    口b.所谓联合挂载，是通过把镜像内的多层一层一层叠加上去的，而这个叠加方式的原理是：    第一层上有数据时，而第二层没相同数据，在第二层是可以看到第一层数据的;如果第二层有第一层相同数据，    则会覆盖第一层上的相同数据，在第二层上看到的是第一层和第二层总的文件，以此类推，在可写层上就可以看到    镜像内的数据目录了，</code></pre><blockquote><p>如何修改和写文件？</p></blockquote><pre><code>a.对于修改文件，因为文件是放在只读层的，只能是通过COW写时复制机制，先把文件从只读层复制到可写层上再进行修改    然后保存在可写层,当然是首次修改，第二次再修改因为在可写层有文件了，在可写层修改即可，而只读层的该文件    版本仍然存在，只不过是被读写层中该文件的副本所隐藏了.b.对于写文件，新创建的文件是保存在可写层的，所以最终用户看到的是只读层和可写层的全    部数据文件，这就是镜像的工作逻辑</code></pre><blockquote><p>通过上面的分析可以得出：</p></blockquote><pre><code>1.这就是为什么基于同一镜像创建的两个容器，用户在不同的容器上看到的相同的数据都是只读层的，不同的数据是可写    层上各自独有的，因为可写层是独占的，只读层是共享的2.这就是为什么镜像背后必须要求特殊文件系统的原因：因为ext4和xfs默认是不支持联合挂载和写时复制机制的3.因为可写层是可以自定义修改的，把可写层保存为镜像，然后再和原始镜像进行叠加成一个自定义的镜像，    就可以作为基础镜像使用了，不过一般不这么做，而是通过dockerfile自定义镜像</code></pre><h3 id="docker-imge相关命令"><a href="#docker-imge相关命令" class="headerlink" title="docker imge相关命令"></a>docker imge相关命令</h3><pre><code>docker image 相关命令    docker imges:镜像的管理命令    ls： 查看本地所有的镜像列表    build:    import:    inspect: 查看下载/创建的镜像详细信息            可以查看下载的某个镜像的具体信息                    如：CMD:镜像启动默认运行的命令                        Volume:                        network:            下文中构建docker file时这些都可以自定义    load:    prune:    pull：从远程仓库拉取镜像到本地    push: 把本地镜像推到远程的Registry    rm:  docker image rm = docker rmi 删除镜像    tag: 给镜像打标签    save:2.将当前容器可写层保存为镜像并上传docker hub上    docker container commit [options] container [repository:[tag]]         选项：            -a:指定作者            -c:镜像内部默认运行的命名            -p|--pause:因为制作镜像时，容器还在运行，可能制作出的镜像和当前容器不                一致，可以在制作时，暂停容器，保持数据一致    比如：        1.在docker hub上注册用户，并创建镜像仓库            创建的仓库：myimg        2.把centos1容器做成镜像仓库下的myimg：v0.1版本            docker container commit -p -a &quot;liu &lt;liu@163.com&gt;&quot; -c &quot;CMD [&apos;/bin/httpd -f&apos;]&quot; centos1 liukkui/myimg:v0.1            然后新容器就可以基于这个镜像启动了        3.上传docker hub            docker login 登录到docker hub                输入账号密码，正常登录后        4.push镜像            docker image push liukkui/myimg:v0.1            正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Images&quot;&gt;&lt;a href=&quot;#Docker-Images&quot; class=&quot;headerlink&quot; title=&quot;Docker Images&quot;&gt;&lt;/a&gt;Docker Images&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>k8s-volumes</title>
    <link href="https://www.liukui.tech/2018/08/10/k8s-volumes/"/>
    <id>https://www.liukui.tech/2018/08/10/k8s-volumes/</id>
    <published>2018-08-10T00:00:00.000Z</published>
    <updated>2019-02-28T12:34:40.561Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Kubernetes-Volumes"><a href="#Kubernetes-Volumes" class="headerlink" title="Kubernetes Volumes"></a>Kubernetes Volumes</h3><a id="more"></a><p><img src="/2018/08/10/k8s-volumes/k8s支持的存储卷类型.png" alt="k8s支持的存储卷类型"></p><pre><code>k8s上的volumes和docker中的volumes都是为了保存数据，但还是有区别的：    1.docker上因为是在单机上运行容器的，删除容器只要加载本地之前挂载的卷就可以了。    2.在k8s集群上，如果删除一个Pod,则这个pod的卷数据会保存在之前的这个node节点上了，而scheduler的调度是随机的，        有可能不会运行在之前的node上，那么之前保存的数据是无意义，不能利用的.    3.k8s是分布式集群，如果所有节点都挂载网络文件系统，那么数据就可以跨节点使用了.数据冗余实现方式：    1.存储设备做镜像，主备模式    2.分布式存储        不会对存储节点设备做冗余，而是在软件数据管理级别上对每个数据对象做冗余；        根据调度规则和冗余级别在当前集群的多个节点上都存放一份数据        还支持向外扩展如何挂载：    1.pod中是有个基础容器pause的,同一个pod中是共享pause容器的UTS(主机名),Network(网络名称空间),IPC(进程间通信，网络协议栈).    2.因为在节点上的pod是共享节点内核的，驱动也是在内核，所以节点本身需要先识别适配外部的各种存储系统.    3.节点是可以挂载多种外部存储系统的，所以pause挂载存储时，需要指明挂载的是哪种文件系统类型的存储并有相应的存储插件驱动.    4.同一Pod中的其他容器要想使用pause中的volumes,需要先通过volumes定义pause中定义卷，pod再通过volumeMounts复制并挂载pause定义的卷.CSI:    Container Storage interface，通过容器存储接口自定义存储卷    k8s中内置的存储卷类型        kubectl explain pod.spec.volumes定义存储卷    详见：kubectl explain pod.spec.volumes #如何定义挂载卷    要用存储卷需要现在pod.spec字段定义挂载卷类型和目录等信息挂载存储：    详见：        kubectl explain pod.spec.containers.volumeMounts #定义如何挂载卷        是使用挂载卷，需要在pod.spec.containers中挂载上去才能用spec中的详细定义说明：    spec:      volumes:          #先定义pause中的挂载卷      - name                    #必须定义存储卷名称,以便挂载时引用    下面根据存储类型不同定义方式也不同，按需修改        hostPath/nfs            #必须指定存储类型        - path                  #定义宿主机或者网络存储的路径          type                  #指定的目录/文件不存在时，应该怎么创建            DirectoryOrCreate   #不存在则创建            Directory           #目录必须事先存在            File                #文件可以挂载，但是必须事先存在            FileOrCreate        #文件不存在则自动创建            Socket              #必须是套接字文件，必须事先存在            CharDevice          #字符设备文件，必须事先存在            BlockDevice         #块设备文件，必须事先存在      containers:      - name:        image:        volumeMounts:   #复制并挂载pause中定义的卷        - name:                 #引用volumes中定义的1个或多个卷的卷名          mountPath             #挂载在容器的哪个路径(应用程序的文件路径)          readOnly：true|false  #挂载的路径是否只读，默认是读写权限          mountPropagation      #</code></pre><h3 id="本地存储：hostPath和local"><a href="#本地存储：hostPath和local" class="headerlink" title="本地存储：hostPath和local"></a>本地存储：hostPath和local</h3><pre><code>示例1：hostPath类型            #节点级的目录    vim myapp-hostpath-volumes.yaml         apiVersion: v1        kind: Pod        metadata:          name: myapp          namespace: volumes-test        spec:          containers:          - name: myapp            image: ikubernetes/myapp:v1            volumeMounts:            - name: website              mountPath: /usr/share/nginx/html              readOnly: true          volumes:          - name: website            hostPath:              path: /volumes/myapp              type: DirectoryOrCreate示例2：local类型    k8s1.10版本之后的类型，且是节点级的设备或者节点级目录</code></pre><h3 id="临时存储：emptyDir"><a href="#临时存储：emptyDir" class="headerlink" title="临时存储：emptyDir"></a>临时存储：emptyDir</h3><pre><code>临时存储作用：    1.为容器提供缓存存储空间        1.支持在节点的内存中切分一部分空间作为缓存来用    2.为没有持久存储必要的同一Pod中的两个容器共享数据    3.临时存储随着Pod的删除自动删除用法：    kubectl explain pod.spec.volumes.emptyDir        medium      #默认是disk磁盘，还可以是Memory内存        sizeLimit   #当medium是memory时，则必须进行限制简单示例：    volumes:    - name: ceshi#      emptyDir: {}  #如果medium和sizelimit都不定义，则为磁盘的任意空间      emptyDir:        medium: Memeory  #使用内存当空间        sizeLimit: 200Mi #使用内存空间为200M</code></pre><h3 id="网络存储：NFS"><a href="#网络存储：NFS" class="headerlink" title="网络存储：NFS"></a>网络存储：NFS</h3><pre><code>用法：    kubectl explain pods.spec.volumes.nfs        path：                #nfs的共享目录：如/vols/v1        readOnly：true|false  #是否只读，默认读写        server:               #nfs服务IP或者主机名缺点：    1.需要事先知道nfs服务器的地址    2.nfs导出的存储空间目录示例：    先准备nfs的共享目录:在10.10.0.29上测试    vim /etc/exports        /vols/v1 10.10.0.0/8(rw,no_root_squash)[root@master01 manifsets]# vim redis-nfs-volumes.yaml apiVersion: v1kind: Podmetadata:  name: redis  namespace: volumes-testspec:  nodeName: node03  containers:  - name: redis    image: redis:alpine    ports:    - name: redis      containerPort: 6379    volumeMounts:    - name: redisdata      mountPath: /data      readOnly: false  volumes:  - name: redisdata    nfs:      path: /vols/v1     #nfs导出的共享目录      server: 10.10.0.29 #nfs服务器的地址</code></pre><h3 id="持久卷申请存储：PV-amp-PVC"><a href="#持久卷申请存储：PV-amp-PVC" class="headerlink" title="持久卷申请存储：PV&amp;PVC"></a>持久卷申请存储：PV&amp;PVC</h3><pre><code>为了使用存储方便，为volumeMounts和后端存储设备加加了两个中间层在spec.volumes和存储间加了一个persistentVolume中间层把存储系统的所提供的存储能力抽象成k8s上的标准资源：persistentVolume持久存储卷persistentVolume：    1.PV和存储系统之间不是一一对应关系，而是与对应后端存储系统上可被单独访问的逻辑单元；    2.一个PV对应nfs的一个导出目录、ceph的一个image、云存储的一个云盘;    3.把后端存储的一个个逻辑单元映射为k8s上的一个个PV;    4.PV是集群级别的资源，不属于任何名称空间;PV的lifecycle:    provisioning: #PV的动态供给    bingding      #PV被绑定    using         #PV被使用    reclaiming    #PV被回收PV的供给方式：    动态供给：        1.存储系统上需要事先有逻辑存储单元，根据PVC的空间需求，在底层存储上选择适合空间需求的存储单元动态得创建为PV.        2.底层存储的逻辑单元不存在，只有存储空间            1.PVC向SC请求调用存储系统的API存储接口，临时创建需求空间大小的逻辑存储单元.            2.然后在SC内部把此存储单元创建为PV，与PVC进行binding.        3.动态供给是创建SC，而不是PV    静态供给：        存储系统上事先有存储，手动创建PV，再手动创建PVC与之绑定.PV的回收策略：reclaim    Pod删除时，PVC也可以删除，则引用的PV就处于回收状态，PV删除有二种策略        Delete:   #PVC删除时连带PV一起删除        Retain    #PV和PV上的数据都保留    备注：        1.如果是retain的，PV上仍然会有数据，但是不能被其他PVC所绑定了        2.可以手动删除PV，并手动删除存储上逻辑单元下的数据persistentVolumeClaim    1.PV属于集群级别资源，Pod属于名称空间级别资源，如果pod想使用PV就需要把PV注册到名称空间中;    2.Pod是通过PVC请求占用PV，来使用PV的，一旦名称空间A占用PV1，其他名称空间就不能再用PV1了;    3.PVC占用PV称为binding;为被PVC占用的PV称为avaiable(可用的PV);    4.Pod通过volumes.persistentVolumeClaim使用PVC，进而间接使用PVC所占用的PV的.    5.PVC是属于某个名称空间，可以由管理员手动创建的.PVC和存储系统的多路访问模型：    1.单路读写： RW0:ReadWriteOnce      iscsi    2.多路读写: RWX:ReadWriteMany    3.多路只读: ROX:ReadOnlyMany    作用：        PV是与后端存储的逻辑单元做映射的，存储系统是否支持多路读写应该体现在PV的定义上，才能避免PVC关联PV是否能多路读写出现存储故障.PV和PVC的删除保护：    当PVC和PV被Pod使用时，在k8s的1.10版本之后，即使PVC和PV被删除，此时也不会真的被删除，只有Pod被删除时，    PVC和PV才会被允许删除，这就是PVC和PV的删除保护.定义PV：    pv.spec和pod.spec.volumes是一样的，这样在创建pod时就不要再定义volumes了直接在containers.volumeMounts进行复制挂载就行了.    kubectl explain persistentVolume.spec    spec:      accessModes               #定义存储系统的访问模型的字符串列表            RW0/RWZ/ROX      capacity:                 #定义存储容量        storage   #单位是Ki Mi Gi等等      volumeMode:               #存储设备的访问接口(文件系统接口和块设备接口)            Fileystem|block      persistentVolumeReclaimPolicy  #定义PV的回收策略            Delete|Retain      storageClassName:           #定义使用哪种存储类      mountOptions:          #自定义挂载选项,下面这两项是默认的        - hard        - nfsvers=4.1      nfs/ceph:                  #定义PV关联的存储类型        下面选项根据不同存储系统定义不同的属性值        server:                   path:        定义PVC：    kubectl explain pvc.spec        accessModes          #访问权限必须要要绑定的PV权限的子集        volumeMode           #存储设备的访问接口(文件系统接口和块设备接口)        resources            #资源请求            requests:               #资源需求                storage:   #具体的需求存储空间大小            limit                  #资源上限        storageClassName     #存储类(PVC和PV必须在同一存储类中)        selector             #通过标签选择器去选PV                不定义选择器，则从所有PV中选择合适的PV        volumeName           #        dataSource           #</code></pre><h3 id="存储类SC：StorageClass"><a href="#存储类SC：StorageClass" class="headerlink" title="存储类SC：StorageClass"></a>存储类SC：StorageClass</h3><p><img src="/2018/08/10/k8s-volumes/SC.png" alt="SC"></p><pre><code>SC:Storageclass是k8s上的标准资源    SC是实现PVC动态创建存储单元PV的基础        1.SC上定义了如何连接外部存储API管理接口的方式        2.PVC只能向同一个SC中的PV请求绑定，不能跨SC.定义SC：    详见：kubectl explain sc        apiVersion        kind        metadata        parameters     #对接外部存储时的参数        reclaimPolicy  #在此SC中的PV回收策略        provisioner    #指明后端存储设备-----必须项        volumeBindingMode #后端存储支持的访问模型(RWX,ROX,RWO)        allowVolumeExpansion   #后端存储系统是否支持空间拉伸官方示例：    glusterfs类型的SC          apiVersion: storage.k8s.io/v1        kind: StorageClass        metadata:          name: slow        provisioner: kubernetes.io/glusterfs        parameters:          resturl: &quot;http://127.0.0.1:8081&quot;          clusterid: &quot;630372ccdc720a92c681fb928f27b53f&quot;          restauthenabled: &quot;true&quot;          restuser: &quot;admin&quot;          secretNamespace: &quot;default&quot;          secretName: &quot;heketi-secret&quot;          gidMin: &quot;40000&quot;          gidMax: &quot;50000&quot;          volumetype: &quot;replicate:3&quot;    ceph-rbd类型的SC:        kind: StorageClass        apiVersion: storage.k8s.io/v1        metadata:          name: fast        provisioner: kubernetes.io/rbd        parameters:          monitors: 10.16.153.105:6789          adminId: kube          adminSecretName: ceph-secret          adminSecretNamespace: kube-system          pool: kube          userId: kube          userSecretName: ceph-secret-user          userSecretNamespace: default          fsType: ext4          imageFormat: &quot;2&quot;          imageFeatures: &quot;layering&quot;</code></pre><h3 id="示例-创建静态供给PV和PVC"><a href="#示例-创建静态供给PV和PVC" class="headerlink" title="示例-创建静态供给PV和PVC"></a>示例-创建静态供给PV和PVC</h3><pre><code>以nfs为例定义一个PV：    [root@master01 manifsets]# vim pv-test.yaml    apiVersion: v1    kind: PersistentVolume    metadata:      name: pv-nfs-v1      labels:        storagefs: nfs    spec:    #  accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;]      accessModes:      - ReadWriteMany      - ReadWriteOnce      - ReadOnlyMany      capacity:        storage: 1Gi                #定义PV能提供多大存储空间      volumeMode: Filesystem      persistentVolumeReclaimPolicy: Retain     #定义PV回收策略      nfs:        path: /vols/v2        server: 10.10.0.29创建PVC：    apiVersion: v1    kind: PersistentVolumeClaim    metadata:      name: redis-pvc            #定义PVC的名称，以便Pod中引用      namespace: volumes-test    spec:      selector:   #定义关联到哪个PV，不指定则根据需求空间找相近空间大小的PV        matchLabels:          storagefs: nfs2      accessModes:      - ReadWriteMany      volumeMode: Filesystem      resources:        requests:          storage: 500Mi          #根据PV的存储空间定义PVC有多少空间创建Pod挂载PVC    apiVersion: v1    kind: Pod    metadata:      name: redis      namespace: volumes-test    spec:      nodeName: node03      containers:      - name: redis        image: redis:alpine        ports:        - name: redis          containerPort: 6379        volumeMounts:              #容器复制挂载volumes        - name: redisdata          mountPath: /data          readOnly: false      volumes:      - name: redisdata        persistentVolumeClaim:          claimName: redis-pvc           #挂载PVC测试：    [root@master01 ~]# kubectl get pv    NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                      STORAGECLASS   REASON   AGE    pv-nfs-v1   1Gi        RWO,ROX,RWX    Retain           Available                                                      8m14s    pv-nfs-v2   2Gi        RWO,ROX,RWX    Retain           Released    volumes-test/redis-pvc-1                           8m14s    pv-nfs-v3   3Gi        RWO,ROX,RWX    Retain           Bound       volumes-test/redis-pvc                             8m14s    [root@master01 ~]# kubectl get pvc -n volumes-test    NAME        STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE    redis-pvc   Bound    pv-nfs-v3   3Gi        RWO,ROX,RWX                   5m55s</code></pre><h3 id="特殊存储：ConfigMap和Secret"><a href="#特殊存储：ConfigMap和Secret" class="headerlink" title="特殊存储：ConfigMap和Secret"></a>特殊存储：ConfigMap和Secret</h3><p>都是为pod中的容器提供配置变更，扮演了k8s系统上一组控制器控制的pod的配置中心</p><pre><code>docker中的应用程序根据不同的环境配置不同的配置文件是依靠两种方式：    1.应用程序镜像是云原生或者支持通过enterpoint脚本可以传递环境变量来适应不同的场景使用.        缺点是：要修改传的值需要删除容器重新创建    2.先配置好不同的配置文件，通过挂载卷将文件传递到容器中.        缺点是：在本地映射的路径下修改了配置文件，容器是不会自动加载新的配置文件的.        k8s上面临相同的问题，为了解决修改配置文件或参数值能够使Pod自动重载配置信息，就将配置文件做成了k8s上的configMap资源.ConfigMap和Secret    1.Pod中的容器提供配置信息    2.配置中心：配置发生变更，测试完成后，通知方式(灰度)    区别：        configMap用来保存非敏感数据，Secret用来保存敏感数据的configMap和Secret是如何将配置传递至Pod中的？    先定义configMap和secret类型的资源，而这种资源时K/V键值对存在的        1.如果是环境变量，则定义这两种资源时，指定key和value        2.如果是配置文件，则文件名为Key,文件内容为值value创建pod时，只需要引用此资源的Key即可：    1.把configmap和secret资源的key映射给pod容器中的环境变量或者文件名    2.给环境变量传key的名称，通过k/v替换，获得v的值，如果想变更配置，只需要修改pod外部configmap中的value的值即可    ，pod会在一段时间内自动传递新的value值，进行配置更新.</code></pre><h3 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h3><pre><code>注意：    1.命令行创建configmap比资源清单更简单，但是配置清单更易维护.    2.通过资源清单配置的configMap中嵌套的是K/V数值还比较简单如果嵌套的是文件内容    的话，配置格式还是有些麻烦的.创建ConfigMap的两种方式    1.基于命令行的    kubectl create configmap -h        --from-literal  #手动指定K/V值，定义多个K/V值需要有多个--from-literal        --from-file     #从文件中读取创建    2.配置清单(比命令行麻烦，但是更易维护)        kubectl explain configmap            data:       #只有data字段，而没有spec字段两种引用configMap的方式: pod和configMap必须在同一名称空间    1.基于环境变量方式引用configMap (用于传递环境变量)    [root@master01 ~]#pod.spec.containers.env        env       #直接手动给变量        - name         #镜像中所能接收的变量名          value        #手动给值(一般用valuefrom)          valuefrom    #从其他位置引用值            configMapKeyRef     #引用一个configMap的键key                name                 #configMap的名称                key                  #configMap中的一个键名                optional        #被引用的configMap资源存在就可以，不存在则报错                    true|false  #默认是必须存在            secretKeyRef        #引用一个Secret的键key,用于敏感数据传输        envfrom   #从其他地方加载环境变量    缺点：        1.如果修改configmap中的环境变量的值，pod是不会更新环境变量的，除非删除重建pod，新的环境变量才会生效.    2.基于存储卷方式引用configMap (用于传递文件)        是把configmap资源当成存储卷来用的        kubectl explain pods.spec.volumes.configMap        volumes:        - name           #定义存储卷名称以便挂载时使用          configMap:            name         #configMap资源的名称            items        #要引用configmap中的那些键映射为本地的文件            - key          #configmap中的键名              mode         #映射的文件权限时多少，没定义则使用外部的defaultMode              path      #映射到pod中叫什么文件名(可以和key一样，也可以随意更改)                    必须是相对路径，而且是相对于挂载点而言            defaultMode  #映射到本地的文件权限为多少                        默认是0644读写权限，可以自己指定            optional     #引用的configMap资源或者引用的键不存在是否报错注意：    1.相对于环境变量方式引用configmap，存储卷方式的pod会根据configmap内容的变化而更新自己pod中的配置信息.    2.如果一个deploy控制的多个pod，并定义挂载了configMap类型的存储，如果修改configMap文件中的内容，这些pod一般会在一分钟之内都更新到最新configmap中新的值.    3.在deploy控制的后端pod众多的情况下，需要借助互联网上的配置中心组件实现pod的滚动更新或者金丝雀更新.    4.后端pod较少的情况下，可以用ansible或者puppet进行灰度更新.</code></pre><h4 id="创建并引用ConfigMap示例"><a href="#创建并引用ConfigMap示例" class="headerlink" title="创建并引用ConfigMap示例"></a>创建并引用ConfigMap示例</h4><pre><code>1.基于命令行的--from-literal创建    kubectl create configmap filebeat-cfg -n config-ns --from-literal=redis_host=&quot;filebeat.defalut.svc.cluster.local&quot; --from-literal=log_level=&quot;Info&quot;    创建名为filebeat-cfg的cm,并设定两个key和他的值2.基于命令行的--from-file创建    kubectl create cm nginx-cfg --from-file=nginx-./server1.conf --from-file=server-zhihui.conf=./nginx-server2.conf -n config-ns引用示例：    1.基于环境变量引用configMap        此处手动创建一个Pod，用来演示使用env属性值引用configMap：filebeat-cfg        apiVersion: v1        kind: Pod        metadata:          name: filebeat          namespace: config-ns    #pod和configMap必须在同一名称空间        spec:          containers:          - name: filebeat            image: ikubernetes/filebeat:5.6.5-alpine            env:            - name: REDIS_HOST              valueFrom:                configMapKeyRef:                  name: filebeat-cfg                  key: redis_host            - name: LOG_LEVEL              valueFrom:                configMapKeyRef:                  name: filebeat-cfg                  key: log_level    2.基于存储卷方式引用configMap        此处手动创建一个Pod，用来演示挂载configMap类型的存储        apiVersion: v1        kind: Pod        metadata:          name: nginx          namespace: config-ns    #pod和configMap必须在同一名称空间        spec:          containers:          - name: nginx            image: ikubernetes/myapp:v1            volumeMounts:            - name: config              mountPath: /etc/nginx/conf.d     #挂载的目录          volumes:          - name: config            configMap:              name: nginx-cfg                          items:              - key: nginx-server1.conf          #本地文件名                path: server1.conf      #映射到pod中的文件名              - key: server-zhihui.conf          #本地文件名                path: server2.conf      #映射到pod中的文件名测试：    通过手动修改configmap的值，查看pod中的文件是否也会发生改变    kubectl edit cm/nginx-cfg -n config-ns    测试看出基于存储卷方式引用configMap的pod的文件内容也会自动更新.</code></pre><h3 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h3><pre><code>1.Secret和configMap在功能上是一样的，只不过Secret是保存敏感数据的.2.Secret的数据是通过base64编码处理过的，不是真正意义上的加密，可以通过base64进行解码.3.Secret资源一般是通过命令行创建，而不是配置清单，因为如果通过配置清单配置时，需要手动将敏感数据(密码)进行base64编码，是很麻烦的，而命令行创建，会自动把敏感数据进行base64编码后保存到secret中.Secret的三种类型：    详见：kubectl create secret -h    1.docker-registry         私有镜像仓库需要登录才能够访问，docker-registry就是将账号密码进行加密认证，以便kubelet可以认证到镜像仓库服务器上.        认证方式有两种：            1.kubectl explain pod.spec.imagePullSecrets                name:可以定义多个列表用于认证                缺点：如果想使用不同的账户时，是不易修改Secret的            2.kubectl explain pod.spec.serviceAccountName                服务账号：可以使用pod之外的系统认证方式                即使修改账号只需要修改serviceAccountName就可以了.    2.generic        非证书的私有敏感信息都用generic类型,通用型    3.tls          #tls是专用于把ssl的tls中的x509格式的证书和私钥打包到一个secret中        而且不管原来的*.key和*.crt都被转成名为tls.key和tls.crt创建secret-generic资源:    1.命令行创建，类似于configmap        kubectl create secret [secret类型] secret名称 --from-literal=        --from-file=[key=]source    2.资源清单创建，要注意将密码进行base64编码后填到data资源中的key:value中        kubectl explain secret创建secret-tls资源:    1.命令行创建：        kubectl create secret tls NAME --cert=path/to/cert/file --key=path/to/key/file -n namespace        #需要先创建证书和私钥，再在创建secret-tls时引用即可.创建docker-registry资源:    1.命令行创建：        kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL          # 创建docker-registry类型的资源时，要指定连接的私有docker仓库的IP/域名，用户名，密码，注册时使用的账号引用secret的方式    1.通过env环境变量引用        kubectl explain pod.spec.containers.env            env:            - name                  #Pod镜像中的存在的变量名              valueFrom:                secretKeyRef:       #表示从secret类型资源引用键                  name:           #引用的Secret资源的名称                  key             #secret资源中的键名                  optional:   #secret资源或者引用的key不存在时报错                    true|false    2.通过存储卷引用Secret资源        kubectl explain pod.spec.volumes.secret        volumes:        - name:              #定义存储卷名称以便挂载时使用          secret:            secretName        #引用的secret资源名称              items:           #引用的多个键对象              - key            #引用的secret资源中的键名                mode:    #文件权限，私密数据建议600权限，不指定则使用外部默认的                path:    #映射到pod中叫什么文件名(可以和key一样，也可以随意更改)          defaultMode      #引用资源的默认权限，0644          optional注意：    1.tls类型的证书和私钥一般要用存储卷方式进行引用，不然value的值太长的.示例：    1.generic类型的secret引用示例        apiVersion: v1        kind: Pod        metadata:          name: mysql          namespace: config-ns        spec:          containers:          - name: mysql            image: mysql:5.6            env:            - name: MYSQL_ROOT_PASSWORD              valueFrom:                secretKeyRef:                  name: mysql-root-password                  key: passwd                  optional: true    2.tls类型secret引用示例        apiVersion: v1            kind: Pod            metadata:              name: nginx              namespace: config-ns            spec:              containers:              - name: nginx                image: nginx:1.14-alpine                volumeMounts:            - name: tls              mountPath: /etc/nginx/ssl          volumes:          - name: tls            secret:            - secretName: nginx-tls              items:              - key: nginx.crt              #原来的证书名                path: nginx-server.crt #映射到pod中的证书名              - key: nginx.key              #原来的私钥名                path: nginx-server.key  #映射到pod中的私钥名                    mode: 0600</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Kubernetes-Volumes&quot;&gt;&lt;a href=&quot;#Kubernetes-Volumes&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes Volumes&quot;&gt;&lt;/a&gt;Kubernetes Volumes&lt;/h3&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.liukui.tech/categories/kubernetes/"/>
    
    
      <category term="k8s" scheme="https://www.liukui.tech/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>redis-cluster集群</title>
    <link href="https://www.liukui.tech/2018/07/20/redis-cluster%E9%9B%86%E7%BE%A4/"/>
    <id>https://www.liukui.tech/2018/07/20/redis-cluster集群/</id>
    <published>2018-07-20T00:00:00.000Z</published>
    <updated>2019-04-06T16:01:32.114Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Redis-cluster"><a href="#Redis-cluster" class="headerlink" title="Redis cluster"></a>Redis cluster</h3><a id="more"></a><pre><code>1.redis主从架构的缺点：    1.当master出现redis服务异常、主机断电、磁盘损坏等问题导致master无法使用，而redis高可用无法实现自故障    转移(将slave提升为master)，需要手动执行slave noone将slave切换成master,而且时间很长;    2.不管是主从模式还是sentinel机制都只是保证了数据跨主机备份的安全性，并没有提升Redis服务的并行写入性能；    3.所以当单台Redis服务器性能无法满足业务写入需求的时候就必须需要一种方式解决以上的两个核心问题.        1.master和slave角色的无缝切换，让业务无感知从而不影响业务使用;        2.可以横向动态扩展Redis服务器，从而实现多台服务器并行写入以实现更高并发的目的;2.Redis cluster集群实现方式：客户端分片、代理分片、Redis Cluster，但是各有区别；    1.客户端分区：        由客户端程序决定key写分配和写入的redis node，但是需要客户端自己处理写入        分配、高可用管理和故障转移等；    2.代理方案：        基于三方软件实现redis proxy，客户端先连接之代理层，由代理层实现key的写入分配，对客户端来说是有        比较简单，但是对于集群管节点增减相对比较麻烦，而且代理本身也是单点和性能瓶颈；    3.redis cluster</code></pre><h3 id="Redis-cluster主从实现原理"><a href="#Redis-cluster主从实现原理" class="headerlink" title="Redis cluster主从实现原理"></a>Redis cluster主从实现原理</h3><pre><code>为了解决单机的redis写入性能受限于单机的内存大小、并发数量、网卡速率等因素，因此redis官方在redis 3.0版本之后推出了无中心架构的redis cluster机制，在无中心的redis集群汇中，其每个节点保存当前节点数据和整个集群状态,每个节点都和其他所有节点连接，特点如下：    1：所有Redis节点使用(PING-PING机制)互联    2：集群中某个节点的实效是整个集群中超过半数的节点监测都实效才算真正的实效    3：客户端不需要proxy即可直接连接redis，且客户端不需要连接集群中的所有节点，只要连接集群中的任何一个节点即可。    4：redis cluster把所有的redisnode映射到 0-16383个槽位(slot)上，读写需要到指定的redis node上    进行操作，因此有多少个reids node相当于redis 并发扩展了多少倍。    5：Redis集群预先分配16384个(slot)槽位，当需要在redis集群中写入一个key -value的时候，    会使用CRC16(key)  mod 16384之后的值，决定将key写入值哪一个槽位从而决定写入哪一个Redis节点上，    从而有效解决单机瓶颈。1.假设三个主节点分别是：A, B, C 三个节点，采用哈希槽 (hash slot)的方式来分配16384个slot的话，它们三个节点分别承担的slot 区间是：    节点A覆盖0－5460    节点B覆盖5461－10922    节点C覆盖10923－163832.Redis cluster的架构虽然解决了并发的问题，但是又引入了一个新的问题，因为每个    Redis master上数据都是不一样的，所以为了保证数据的安全，每个master都需要一个slave来实现数据的高可用.</code></pre><h3 id="Redis-cluster主从架构部署"><a href="#Redis-cluster主从架构部署" class="headerlink" title="Redis cluster主从架构部署"></a>Redis cluster主从架构部署</h3><p><img src="/2018/07/20/redis-cluster集群/redis cluster主从架构.png" alt="redis cluster集群架构"></p><pre><code>1.环境准备：    1.每个redis node节点采用相同的硬件配置、相同的密码    2.每个节点必须开启参数    cluster-enabled yes #必须开启集群状态，开启后redis 进程会有cluster显示    cluster-config-file nodes-6380.conf #此文件有redis cluster集群自动创建和维护，不需要任何手动操作2.为了实验方便，slave都是在master上以6380端口启动，使用不同的Unitfile和配置文件    只列出 redis node master A的操作，其他两台master一样即可    准备配置文件：        [root@node02 ~]# vim /usr/local/redis/etc/redis.conf        cluster-enabled yes        cluster-config-file nodes-6379.conf            #启用创建cluster集群的两项        [root@node02 ~]# cp /usr/local/redis/etc/redis /usr/local/redis/etc/redis-6380.conf        [root@node02 ~]# vim /usr/local/redis/etc/redis-6380.conf        ：%s/6379/6380/g            #将6379端口全部替换成6380端口(此端口作为slave的端口)    准备启动服务：        [root@node02 ~]# cd /usr/lib/systemd/system/        [root@node02 ~]# cp redis.service redis-6380.service        [root@node02 ~]# vim redis-6380.service            #修改slave的Unitfile中加载的配置文件redis-6380.conf        [root@node02 ~]# systemctl start  redis redis-6380            #将一台服务器上的master和slave都启动    #其他两台Redis Node Master{B,C}一样配置即可；</code></pre><p>–每一台redis上应该有一主一从<br><img src="/2018/07/20/redis-cluster集群/每一台redis上应该有两个redis进程.png" alt="每一台redis上应该有两个redis进程"></p><pre><code>3.创建集群    redis-cli --cluster help  #客户端命令可以创建管理集群[root@node01 ~]# redis-cli -a root  --cluster create 192.168.34.121:6379 192.168.34.121:6380 192.168.34.124:6379 192.168.34.124:6380 192.168.34.123:6379 192.168.34.123:6380 --cluster-replicas 1</code></pre><p>–</p><h2 id=""><a href="#" class="headerlink" title=""></a><img src="/2018/07/20/redis-cluster集群/创建集群1.png" alt="创建集群1"></h2><p><img src="/2018/07/20/redis-cluster集群/创建集群2.png" alt="创建集群2"></p><pre><code>4.检查集群状态        #Cluster info可以查看当前集群的状态，集群规模和是否有master节点出现故障以及槽位分配是否是完整且连续的.    [root@node01 ~]# redis-cli -h 192.168.34.121 -p 6379 -a root    192.168.34.121:6379&gt; CLUSTER INFO    cluster_state:ok    cluster_slots_assigned:16384    cluster_slots_ok:16384    cluster_slots_pfail:0    cluster_slots_fail:0    cluster_known_nodes:6    cluster_size:3    cluster_current_epoch:6    cluster_my_epoch:1    cluster_stats_messages_ping_sent:1474    cluster_stats_messages_pong_sent:1507    cluster_stats_messages_sent:2981    cluster_stats_messages_ping_received:1502    cluster_stats_messages_pong_received:1474    cluster_stats_messages_meet_received:5    cluster_stats_messages_received:29815.查看集群node对应关系        #通过cluster nodes可以看到集群中的主从对应关系    [root@node01 ~]# redis-cli -h 192.168.34.121 -p 6380 -a root    192.168.34.121:6380&gt; cluster nodes    7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545659135000 4 connected    7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 myself,slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545659135000 6 conne    ctedf4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545659135000 1 connected 0-5460    116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545659136000 3 connected 5461-10922    70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545659134000 5 connected 10923-16383    2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545659135946 5 connected</code></pre><p>–cluster nodes<br><img src="/2018/07/20/redis-cluster集群/cluster nodes.png" alt="cluster nodes"></p><pre><code>6.查看集群槽位和主从的具体关系    使用redis-cli -a root --cluster check 192.168.34.101:6379    随机一个master的IP和端口可以看到对应关系</code></pre><p>–查看集群对应关系<br>![查看集群对应关系]redis-cluster集群/(查看集群对应关系.png)</p><pre><code>7.验证集群写入key    192.168.7.101:6379&gt; SET k1 v1          #经过算法计算，当前key的槽位需要写入指定的node     (error) MOVED 9189 192.168.7.103:6379   #因为槽位不在当前node所以无法写入    192.168.7.102:6379&gt; SET k1 v1      (error) MOVED 9189 192.168.7.102:6379      192.168.7.103:6379&gt; SET k1 v1    #指定的node就可以写入    OK    192.168.7.103:6379&gt; KEYS *    1) &quot;k1&quot;    192.168.7.101:6379&gt; KEYS *    (empty list or set)    192.168.7.102:6379&gt; KEYS *    (empty list or set)8.故障动态转移测试；    上一步已经将数据写入到192.168.7.103:6379的master上了现在关闭192.168.7.103上的master 6379的redis进程，测试192.168.7.103:6379的slave192.168.7.103:6380    是否能成为master，数据是否能查到.</code></pre><p>–103的slave<br><img src="/2018/07/20/redis-cluster集群/103的slave.png" alt="103的slave"><br>–103的slave会切换成master<br><img src="/2018/07/20/redis-cluster集群/103的slave会切换成master.png" alt="103的slave会切换成master"></p><pre><code>9.集群状态监控    # redis-cli -a 123456  --cluster check 192.168.7.101:6379</code></pre><p>–集群状态监控<br><img src="/2018/07/20/redis-cluster集群/集群状态监控.png" alt="集群状态监控"></p><h3 id="Redis-cluster集群管理维护"><a href="#Redis-cluster集群管理维护" class="headerlink" title="Redis cluster集群管理维护"></a>Redis cluster集群管理维护</h3><p>集群运行时间长久之后，难免由于硬件故障、网络规划、业务增长等原因对已有集群进行相应的调整， 比如增加Redis node节点、减少节点、节点迁移、更换服务器等。<br>增加节点和删除节点会涉及到已有的槽位重新分配及数据迁移。</p><h3 id="1-集群维护之动态添加节点"><a href="#1-集群维护之动态添加节点" class="headerlink" title="1.集群维护之动态添加节点"></a>1.集群维护之动态添加节点</h3><p>1.增加Redis node节点，需要与之前的Redis node版本相同、配置一致，然后分别<br>启动两台Redis node，因为一主一从;<br>2.现有的三主三从redis cluster架构可能无法满足现有业务的并发写入需求，新增一台服务器192.168.34.122，需要将其<br>动态添加到集群当中其不能影响业务使用和数据丢失，则添加过程如下:</p><pre><code>1.同步配置文件    同步之前Redis node的配置文件到192.168.7.104 Redis编译安装目录，    注意配置文件的监听IP，这是在一台服务器上模拟一主一从redis；    # scp redis.conf  192.168.34.104:/usr/local/redis/etc/    # scp redis_6380.conf  192.168.34.104:/usr/local/redis/etc/    分别启动redis服务：    # systemctl  daemon-reload    # systemctl  restart redis    # /usr/local/redis/bin/redis-server  /usr/local/redis/etc/redis_6380.conf2.新增新节点到集群(先新增一台master节点)    使用命令：redis-cli -a 123456 --cluster add-node 192.168.34.104:6379 192.168.7.101:6379      #注意： 前面是新增加的的redis节点IP和端口后面是已经存在的集群中的master IP:端口(可以是任意一个master的IP和端口)    注意：        增加到集群很快，但是新加的节点是没有数据的，需要对集群进行槽位重新分片，数据重新划分；</code></pre><p>–添加新节点到集群<br><img src="/2018/07/20/redis-cluster集群/添加新节点到集群.png" alt="添加新节点到集群"></p><pre><code>3.分配槽位    添加主机之后需要对添加至集群种的新主机重新分片否则其没有分片；将现有的三主三从上的数据重新分配到四主四从上；    重新分片机制：        将集群中的每个master抽出一部分给新增的节点使用；    命令：    [root@redis ~]# redis-cli -a 123456 --cluster reshard  192.168.7.104:6379 </code></pre><p>–重新分配槽位<br><img src="/2018/07/20/redis-cluster集群/重新分配槽位.png" alt="重新分配槽位"></p><pre><code>4.查看当前集群状态    查看重新划分之后集群是否是正常的.    此时因为只加入了一个master,没有把新的slave节点加进来，所以会有一个master没有slave</code></pre><p>–重新分配完成<br><img src="/2018/07/20/redis-cluster集群/重新分配完成.png" alt="重新分配完成"></p><pre><code>5.将新的slave也加入集群    [root@node01 ~]# redis-cli -a 123456 --cluster add-node 192.168.34.104:6380 192.168.7.101:6379    #新的节点加入集群默认都是master节点，需要把它变成一个192.168.34.104:6379的slave6.为新增的master192.168.34.104:6379添加slave192.168.34.104:6380节点    将新加slave192.168.34.104:6380，作为master192.168.34.104:6379的slave,    登录到192.168.34.104:6380上通过CLUSTER  REPLICATE ID更改新节点状态为slave        1.需要先登录到要成为slave的节点上；        2.取出要成为master的ID(cluster nodes命令查看)</code></pre><p>–添加slave<br><img src="/2018/07/20/redis-cluster集群/添加slave.png" alt="添加slave"></p><pre><code>7.验证当前集群状态</code></pre><p>–当前集群状态<br><img src="/2018/07/20/redis-cluster集群/当前集群状态.png" alt="当前集群状态"></p><h3 id="2-集群维护之动态删除节点"><a href="#2-集群维护之动态删除节点" class="headerlink" title="2.集群维护之动态删除节点"></a>2.集群维护之动态删除节点</h3><p>添加节点的时候是先添加node节点到集群，然后分配槽位，删除节点的操作与添加节点的操作正好相反，是先将被删除的<br>Redis node上的槽位迁移到集群中的其他Redis node节点上，然后再将其删除。</p><pre><code>1.迁移master192.168.7.102:6379的槽位之其他master    [root@redis-s1 ~]# redis-cli -a root  --cluster reshard  192.168.7.102:6379        #指定要删除的master节点的IP+端口</code></pre><p>–迁移节点<br><img src="/2018/07/20/redis-cluster集群/迁移节点.png" alt="迁移节点"></p><pre><code>2.验证槽位迁移完成</code></pre><p>–验证槽位迁移完成<br><img src="/2018/07/20/redis-cluster集群/验证槽位迁移完成.png" alt="验证槽位迁移完成"></p><pre><code>3.从集群删除服务器    虽然槽位已经迁移完成，但是服务器IP信息还在集群当中，因此还需要将IP信息从集群删除    命令格式:redis-cli -a root --cluster del-node IP:Port ID删除master：[root@redis1~]# redis-cli -a root --cluster del-node 192.168.7.101:6379f4cfc5cf821c0d855016488d6fbfb62c03a14fdaWarning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe.&gt;&gt;&gt; Removing node f4cfc5cf821c0d855016488d6fbfb62c03a14fda from cluster 192.168.7.101:6379&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node.删除slave：该节点上如果还有其他节点上master 的slave，但是由于服务器下架也要一并删除，因此要提前把保证每个master至少有一个slave[root@redis-s1 ~]# redis-cli -a root --cluster del-node 192.168.7.101:6380 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6Warning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe.&gt;&gt;&gt; Removing node 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 from cluster 192.168.7.101:6380&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node.4.验证node是否删除    发现192.168.7.101已经被删除，但是由于192.168.7.101:6380之前是192.168.7.103:6379的slave，所以删除    后会导致相应的master缺少slave，需要重新为没有slave的master分配slave。    可以发现下图的192.168.7.104有两个slave，分别是192.168.7.102:6380和192.168.7.104:6380，因此需要将    其中一个slave转移为192.168.7.103的slave。</code></pre><p>–验证node是否删除<br><img src="/2018/07/20/redis-cluster集群/验证node是否删除.png" alt="验证node是否删除"></p><pre><code>5.重新分配slave    将192.168.7.104:6380 转移为192.168.7.103的slave</code></pre><p>–重新分配slave<br><img src="/2018/07/20/redis-cluster集群/验证node是否删除.png" alt="重新分配slave"></p><pre><code>6.重新验证集群Master与Slave对应关系    Redis Slave节点一定不能和master在一个服务器，必须为跨主机交叉备份模式，避免主机故障后主备全部挂掉，如果出现Redis Slave与Redis master在同一台Redis node的情况，则需要安装以上步骤重新进行slave分配，直到不相互交叉备份为止。</code></pre><p>–master和slave对应关系<br><img src="/2018/07/20/redis-cluster集群/master和slave对应关系.png" alt="master和slave对应关系"></p><h3 id="3-集群维护之导入现有Redis数据"><a href="#3-集群维护之导入现有Redis数据" class="headerlink" title="3.集群维护之导入现有Redis数据"></a>3.集群维护之导入现有Redis数据</h3><p>将redis cluster部署完成之后，需要将之前的数据导入到Redis cluster集群，但是由于Redis cluster使用的分片保存key的机制，因此使用传统的AOF文件或RDB快照无法满足需求，因此需要使用集群数据导入命令完成。</p><pre><code>注意：导入数据需要redis cluster不能与被导入的数据有重复的key名称，否则导入不成功或中断。1.环境准备：    1.导入数据之前需要关闭各redis 服务器的密码，包括集群中的各node和源Redis server，避免认证带来的    环境不一致从而无法导入，但是可以加参数--cluster-replace 强制替换Redis cluster已有的key2.执行数据导入    将源Redis server的数据直接导入之redis cluster。    命令格式：#redis-cli  --cluster import  集群服务器IP:PORT --cluster-from 外部Redis node-IP:PORT --cluster-copy --cluster-replace</code></pre><p>–数据导入<br><img src="/2018/07/20/redis-cluster集群/数据导入.png" alt="数据导入"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Redis-cluster&quot;&gt;&lt;a href=&quot;#Redis-cluster&quot; class=&quot;headerlink&quot; title=&quot;Redis cluster&quot;&gt;&lt;/a&gt;Redis cluster&lt;/h3&gt;
    
    </summary>
    
      <category term="缓存" scheme="https://www.liukui.tech/categories/%E7%BC%93%E5%AD%98/"/>
    
      <category term="redis" scheme="https://www.liukui.tech/categories/%E7%BC%93%E5%AD%98/redis/"/>
    
    
      <category term="redis集群" scheme="https://www.liukui.tech/tags/redis%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>redis高可用</title>
    <link href="https://www.liukui.tech/2018/07/15/redis%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    <id>https://www.liukui.tech/2018/07/15/redis高可用/</id>
    <published>2018-07-15T00:00:00.000Z</published>
    <updated>2019-04-06T16:01:54.345Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Redis高可用"><a href="#Redis高可用" class="headerlink" title="Redis高可用"></a>Redis高可用</h3><a id="more"></a><p>虽然Redis可以实现单机的数据持久化，但无论是RDB也好或者AOF也好，都解决不了单点宕机问题，即一旦redis服务器本身<br>出现系统故障、硬件故障等问题后，就会直接造成数据的丢失，因此需要使用高可用和集群技术来解决单点问题.</p><h3 id="Redis主从实现"><a href="#Redis主从实现" class="headerlink" title="Redis主从实现"></a>Redis主从实现</h3><h3 id="主从复制过程"><a href="#主从复制过程" class="headerlink" title="主从复制过程"></a>主从复制过程</h3><p><img src="/2018/07/15/redis高可用/主从复制过程.png" alt="主从同步过程"></p><pre><code>Redis支持主从复制分为全量同步和增量同步，首次同步是全量同步，主从同步可以让从服务器从主服务器备份数据，而且从服务器还可与有从服务器，即另外一台redis服务器可以从一台从服务器进行数据同步，redis 的主从同步是非阻塞的，其收到从服务器的sync(2.8版本之前是PSYNC)命令会fork一个子进程在后台执行bgsave命令，并将新写入的数据写入到一个缓冲区里面，bgsave执行完成之后并生成的将RDB文件发送给客户端，客户端将收到后的RDB文件载入自己的内存，然后主redis将缓冲区的内容在全部发送给从redis，之后的同步从服务器会发送一个offset的位置(等同于MySQL的binlog    的位置)给主服务器，主服务器检查后位置没有错误将此位置之后的数据包括写在缓冲区的积压数据发送给redis从服务    器，从服务器将主服务器发送的挤压数据写入内存，这样一次完整的数据同步，再之后再同步的时候从服务器只要发送    当前的offset位 置给主服务器，然后主服务器根据响应的位置将之后的数据发送给从服务器保存到其内存即可。Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 1）从服务器连接主服务器，发送SYNC命令； 2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB快照文件并使用缓冲区记录此后执行的所有写命令； 3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；7）后期同步会先发送自己slave_repl_offset位置，只同步新增加的数据，不再全量同步。总结：    redis的主从复制比mysql的主从要简单的多了    当从节点接入主节点，由主节点直接做一快照RDB，并通过网络直接传给从节点，所以主节点边做快照边传输，从节点边    接收边恢复到本地内存中，等传输完成，从节点就拿到了完整了数据；    随后主节点每记录一个写操作语句，会同时把这个写操作发送给从节点一份，从节点接收后直接在本地重放(也不基于        二进制文件或者aof文件进行主从复制)而是把所有的写操作通过网络传输发送给每一个从节点；    一旦从节点长时间没接入主节点造成数据差异过大，从节点会放弃本地所有数据，然后从主节点进行完整数据复制，这个主从复制过程完全不需要管理员介入</code></pre><h3 id="主从配置参数及优化："><a href="#主从配置参数及优化：" class="headerlink" title="主从配置参数及优化："></a>主从配置参数及优化：</h3><pre><code>Redis在2.8版本之前没有提供增量部分复制的功能，当网络闪断或者slave Redis重启之后会导致主从之间的全量同步，即从2.8版本开始增加了部分复制的功能。repl-diskless-sync  no     #yes为支持disk，master将RDB文件先保存到磁盘在发送给slave，no为maste直接将RDB文件发送给slave，默认即为使用no，Master RDB文件不需要与磁盘交互。repl-diskless-sync-delay 5      #Master准备好RDB文件后等等待传输时间repl-ping-slave-period 10      #slave端向server端发送pings的时间区间设置，默认为10秒 repl-timeout 60 #设置超时时间repl-disable-tcp-nodelay no     #是否启用TCP_NODELAY，如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms），造成master与slave数据不一致，假如设置成no，则redis master会立即发送同步数据，没有延迟，前者关注性能，后者关注一致性repl-backlog-size 1mb      #master的写入数据缓冲区，用于记录自上一次同步后到下一次同步过程中间的写入命令，计算公式：b repl-backlog-size = 允许从节点最大中断时长 * 主实例offset每秒写入量，比如master每秒最大写入64mb，最大允许60秒，那么就要设置为64mb*60秒=3840mb(3.8G)=repl-backlog-ttl 3600     #如果一段时间后没有slave连接到master，则backlog size的内存将会被释放。如果值为0则表示永远不释放这部份内存。 slave-priority 100     #slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端进行恢复，如果值设置为0，则表示该slave永远不会被选择。 #min-slaves-to-write 0 #min-slaves-max-lag 10      #设置当一个master端的可用slave少于N个，延迟时间大于M秒时，不接收写操作。Master的重启会导致master_replid发生变化，slave之前的master_replid就和master不一致从而会引发所有slave的全量同步。套接字文件的产生：    我们的互联网本身是包转发的概念，包和包之间是没有关系的，所说的tcp是有连接的，那么tcp是怎么实现连接的？        在报文当中内置了一下能够判定此前前后状态数据的syn、ack，我们的服务器是根据客户端是否请求断开        根据客户端请求时的clientip+port,serverip+port信息创建成一个文件保存在内存中，当客户端再来时如果能查到这个文件说明此前连接过，而客户端关闭了连接，也会自动删除这个已连接的套接字文件，而如果是10w并发也会占用太大的资源，这就是为什么要断开空闲进程的原因；</code></pre><h4 id="配置redis一主二从"><a href="#配置redis一主二从" class="headerlink" title="配置redis一主二从"></a>配置redis一主二从</h4><p>–主从架构<br><img src="/2018/07/15/redis高可用/主从架构.png" alt="主从架构"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">实现主从的两种方式：</span><br><span class="line">    1.通过CONFIG和SLAVEOF命令配置</span><br><span class="line">        127.0.0.1:6379[1]&gt; SLAVEOF 192.168.34.118 6379 #master的IP+port</span><br><span class="line">        OK</span><br><span class="line">        127.0.0.1:6379[1]&gt; CONFIG SET masterauth root #master密码</span><br><span class="line">        OK</span><br><span class="line">        127.0.0.1:6379[1]&gt; CONFIG REWRITE  #保存在配置文件中</span><br><span class="line">        OK</span><br><span class="line">        [root@node03 ~]# tail /usr/local/redis/etc/redis.conf</span><br><span class="line">        replicaof 192.168.34.118 6379</span><br><span class="line">        masterauth &quot;root&quot;</span><br><span class="line">            #可以看到主从配置信息被写在配置文件的最后面了</span><br><span class="line">    2.修改配置文件</span><br><span class="line">        详见下文</span><br><span class="line">客户端连接redis:</span><br><span class="line">    1.主备模式，可以实现Redis数据的跨主机备份；</span><br><span class="line">    2.程序端连接到高可用负载的VIP，然后连接到负载服务器设置的Redis后端real server</span><br><span class="line">        ，此模式不需要在程序里面配置Redis服务器的真实IP地址，当后期Redis服务器IP</span><br><span class="line">        地址发生变更只需要更改redis 相应的后端real server即可，可避免更改程序中的</span><br><span class="line">        IP地址设置.</span><br><span class="line"></span><br><span class="line">1.配置2台slave：</span><br><span class="line">    1.Redis Slave也要开启数据持久化(RDB/AOF)并设置和master同样的连接密码，</span><br><span class="line">        因为后期slave会有提升为master的可能,Slave端切换master同步后会丢失之前的所有数据。</span><br><span class="line">    2.一旦某个Slave成为一个master的slave,Redis Slave服务会清空当前redis服务器上的所有数据并将master的数据导入到自己的内存，但是断开同步关系后不会删除当前已经同步过的数据；</span><br><span class="line">    redis早期的时候都是全量同步，后期支持增量同步</span><br><span class="line"></span><br><span class="line">2.修改两台从redis服务器的redis.conf配置文件</span><br><span class="line">    [root@node02 redis]# vim etc/redis.conf</span><br><span class="line">    replicaof 192.168.34.118 6379   #master的IP和端口</span><br><span class="line">        #注意：master的IP必须和master的bind监听的地址是一致的，如果有两个地址，而bind只监听在内网IP上，此处只能写内网的IP，写外网的IP也不会同步成功的.</span><br><span class="line">    masterauth root                 #master的验证密码</span><br><span class="line">    requirepass root     #每个redis数据库的验证密码都要和master一样</span><br><span class="line"></span><br><span class="line">3.重启从redis：</span><br><span class="line">    127.0.0.1:6379&gt; INFO</span><br><span class="line">    # Replication</span><br><span class="line">    role:slave                  #显示是从节点</span><br><span class="line">    master_host:192.168.34.118  #显示master的IP</span><br><span class="line">    master_port:6379            #显示master的端口</span><br><span class="line">    master_link_status:up       #显示是否为up状态，在此状态下才是正常的</span><br><span class="line">    master_last_io_seconds_ago:9</span><br><span class="line">    master_sync_in_progress:0</span><br><span class="line">    slave_repl_offset:462</span><br><span class="line">    slave_priority:100</span><br><span class="line">    slave_read_only:1</span><br><span class="line">    connected_slaves:0</span><br><span class="line">    master_replid:1f0cd49a266eaacc5c6bdd14f5c793d065207166  #master的ID</span><br><span class="line">    master_replid2:0000000000000000000000000000000000000000 </span><br><span class="line">        #如果有主从故障转移，master_replid2就成了master_replid的编号</span><br><span class="line">        #而master_replid会重新生成一个编号</span><br><span class="line">    master_repl_offset:462</span><br><span class="line">    second_repl_offset:-1</span><br><span class="line">    repl_backlog_active:1</span><br><span class="line">    repl_backlog_size:1048576</span><br><span class="line">    repl_backlog_first_byte_offset:1</span><br><span class="line">    repl_backlog_histlen:462</span><br><span class="line"></span><br><span class="line">4.验证master上的信息</span><br><span class="line">     Replication</span><br><span class="line">    role:master</span><br><span class="line">    connected_slaves:2    #显示当前有几个slave和IP及是否正常</span><br><span class="line">    slave0:ip=192.168.34.126,port=6379,state=online,offset=630,lag=0</span><br><span class="line">    slave1:ip=192.168.34.117,port=6379,state=online,offset=630,lag=0</span><br><span class="line">    master_replid:1f0cd49a266eaacc5c6bdd14f5c793d065207166</span><br><span class="line">    master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">    master_repl_offset:630</span><br><span class="line">    second_repl_offset:-1</span><br><span class="line">    repl_backlog_active:1</span><br><span class="line">    repl_backlog_size:1048576</span><br><span class="line">    repl_backlog_first_byte_offset:1</span><br><span class="line">    repl_backlog_histlen:630</span><br><span class="line"></span><br><span class="line">5.验证Slave从节点上的数据</span><br><span class="line">    127.0.0.1:6379&gt; keys *</span><br><span class="line">    1) &quot;myeky&quot;</span><br><span class="line">    2) &quot;mykey1&quot;</span><br><span class="line">    #显示已经从master上将数据同步成功了，如果slave上原来有数据，则会被清空！</span><br><span class="line">6.master和slave上的日志</span><br><span class="line">    在master和slave上的日志可以显示出是否同步成功，如果没有同步成功会显示原因，有时原因不会很清楚，需要将redis.conf下的loglevel日志级别调整为debug模式.</span><br></pre></td></tr></table></figure><h3 id="主从复制常见问题汇总"><a href="#主从复制常见问题汇总" class="headerlink" title="主从复制常见问题汇总"></a>主从复制常见问题汇总</h3><pre><code>1.master和slave的防火墙要关闭2.master密码不对    即配置的master密码不对，导致验证不通过而无法建立主从同步关系。3.Redis版本不一致    不同的redis 版本之间存在兼容性问题，因此各master和slave之间必须保持版本一致4.无法远程连接    在开启了安全模式情况下，没有设置bind地址和密码</code></pre><h3 id="应用程序如何连接redis？："><a href="#应用程序如何连接redis？：" class="headerlink" title="应用程序如何连接redis？："></a>应用程序如何连接redis？：</h3><pre><code>1.java客户端连接redis是通过jedis来实现的，java代码用的时候只要创建jedis对象就可以建多个jedis连接池来连接    redis，应用程序再直接调用连接池即可连接Redis。2.而Redis为了保障高可用,服务一般都是Sentinel部署方式，当Redis服务中的主服务挂掉之后,会仲裁出另外一台Slaves服务充当Master。这个时候,我们的应用即使使用了Jedis连接池,Master服务挂了,我们的应用将还是无法连接新的Master服务3.为了解决这个问题,Jedis也提供了相应的Sentinel实现,能够在Redis Sentinel主从切换时候,通知我们的应用,把我们的应用连接到新的Master服务。4.Jedis Sentinel的使用也是十分简单的,只是在JedisPool中添加了Sentinel和MasterName参数，Jedis Sentinel底层基于Redis订阅实现Redis主从服务的切换通知，当Reids发生主从切换时，Sentinel会发送通知主动通知Jedis进行连接的切换，JedisSentinelPool在每次从连接池中获取链接对象的时候,都要对连接对象进行检测,如果此链接和Sentinel的Master服务连接参数不一致,则会关闭此连接,重新获取新的Jedis连接对象。 </code></pre><h3 id="redis-Sentinel-哨兵-机制实现"><a href="#redis-Sentinel-哨兵-机制实现" class="headerlink" title="redis Sentinel(哨兵)机制实现"></a>redis Sentinel(哨兵)机制实现</h3><p>–sentinel监控架构<br><img src="/2018/07/15/redis高可用/sentinel监控架构.png" alt="sentinel监控架构"></p><pre><code>redis sentinel的作用：    主要完成三个功能：监控、通知、自动故障转移        选举：流言协议、投票协议    1.redis主从架构中，master宕机之后，是需要人为执行slave noone将slave切换成        master的；    2.而sentinel进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用；    3.master切换后，sentinel进程会通知给JAVA程序上一个与redis通信的jar包，java程序就会与新的master建立连接池进而正常工作.    4.sentinel可以监控1-N个redis主从集群；sentinel工作原理：    1.哨兵(Sentinel) 是一个分布式系统，你可以在一个架构中运行多个哨兵(sentinel)        进程，这些进程使用流言协议(gossipprotocols)来接收关于Master主服务器        是否下线的信息，并使用投票协议(Agreement Protocols)来决定是否执行自动        故障迁移,以及选择哪个Slave作为新的Master；    2.每个哨兵(Sentinel)进程会向其它哨兵(Sentinel)、Master、Slave定时发送消息，        以确认对方是否&quot;活&quot;着，如果发现对方在指定配置时间(可配置的)内未得到回应        ，则暂时认为对方已掉线，也就是所谓的”主观认为宕机” 简称SDOWN;    3.当&quot;哨兵群&quot;中的多数Sentinel进程在对Master主服务器做出SDOWN 的判断，并且        通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master         Server下线判断，这种方式就是“客观宕机”，简称 ODOWN。    4.然后通过一定的vote算法，从剩下的slave从服务器节点中，选一台提升为Master服务        器节点，然后自动修改相关配置，并开启故障转移(failover);redis集群变动：    1.sentinel是分布式集群，只有满足quorum数量判定主节点故障时，才会选举出新的从节点作为master主节点；    2.一旦主的redis宕机之后，sentinel集群会根据每个从节点的replica-priority优先级选择，如果优先级都一样再通过其他方式选择新的master;    3.一旦一个slave--&gt;变成master,数据则以这个slave为准，而其他的从节点都会清空自己的所有数据，重新从这个新的master上同步数据；配置项详解：    port 26379    sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;    sentinel auth-pass &lt;master-name&gt; &lt;password&gt;        &lt;quorum&gt;表示sentinel集群的quorum机制，即至少有quorum个sentinel节点同时判定主节点故障时，才认为其真的故障；            s_down: subjectively down            o_down: objectively down    sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;        监控到指定的集群的主节点异常状态持续多久方才将标记为&quot;故障&quot;；    sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;        指在failover过程中，能够被sentinel并行配置的从节点的数量；        #意思是：当slave成为master时，其他slave都要重新从master上复制数据，        当数据量和节点数量较大时，可以设置一次复制几个slave;即复制的并行度    sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;        sentinel必须在此指定的时长内完成故障转移操作，否则，将视为故障转移操作失败；    sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;        通知脚本，此脚本被自动传递多个参数，类似于keepalived；配置和连接：    sentinel只需要配置监控在主节点上即可,因为sentinel知道这个主从集群中都有哪些从节点；    redis-cli -h SENTINEL_HOST -p SENTINEL_PORT         redis-cli&gt;             SENTINEL masters            SENTINEL slaves &lt;MASTER_NAME&gt;            SENTINEL failover &lt;MASTER_NAME&gt;            SENTINEL get-master-addr-by-name &lt;MASTER_NAME&gt;注意：    哨兵只是解决了人为介入master和slave角色的切换问题，在Redis服务的并行写入性能上并没有任何作用.</code></pre><h4 id="Sentinel实现-在上面配置的一主二从上实现sentinel"><a href="#Sentinel实现-在上面配置的一主二从上实现sentinel" class="headerlink" title="Sentinel实现(在上面配置的一主二从上实现sentinel)"></a>Sentinel实现(在上面配置的一主二从上实现sentinel)</h4><pre><code>哨兵可以不和Redis服务器部署在一起,因为sentinel在生产环境下应该是独立的节点，这里是实验环境，三台sentinel都配置在redis上，生产环境下，redis集群可能是一主八从，可以挑选任意三台部署sentinel；</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">1.准备Sentinel的配置文件</span><br><span class="line">    [root@node01 redis]# cp /usr/local/src/redis-5.0.3/sentinel.conf /usr/local/redis/etc/</span><br><span class="line">2.编辑sentinel.conf配置文件</span><br><span class="line">    [root@node03 ~]# grep -v &quot;^$&quot; /usr/local/redis/etc/sentinel.conf | grep -v &quot;^#&quot;</span><br><span class="line">    bind 0.0.0.0                    #修改监听的地址为0.0.0.0</span><br><span class="line">    port 26379                      #sentinel的端口</span><br><span class="line">    daemonize no                    #修改为以守护进程方式运行 </span><br><span class="line">    pidfile &quot;/usr/local/redis/redis-sentinel.pid&quot;  #pid路径</span><br><span class="line">    logfile &quot;/usr/local/redis/logs/redis-sentinel.log&quot;  #log日志路径</span><br><span class="line">    dir &quot;/tmp&quot;                      #sentinel临时文件目录</span><br><span class="line">    sentinel monitor mymaster 192.168.34.126 6379 2</span><br><span class="line">        #监控的redis集群名字(可自定义)，master的IP和端口</span><br><span class="line">        2是代表3台中的2台sentinel认为master是down的就进行重新选举master</span><br><span class="line">    sentinel auth-pass mymaster root</span><br><span class="line">        #redis的密码</span><br><span class="line">    sentinel down-after-milliseconds mymaster 15000</span><br><span class="line">        #检测时长   </span><br><span class="line">    sentinel parallel-syncs mymaster 2</span><br><span class="line">        #新的slave的复制的并行度</span><br><span class="line">    sentinel failover-timeout mymaster 180000</span><br><span class="line">3.将此配置文件复制给其他sentinel节点</span><br><span class="line">    [root@redis etc]# scp sentinel.conf 192.168.34.126:/usr/local/redis/etc/</span><br><span class="line">    [root@redis etc]# scp sentinel.conf 192.168.34.117:/usr/local/redis/etc/</span><br><span class="line">4.启动每一台上的哨兵sentinel</span><br><span class="line">    [root@node01 redis]# redis-sentinel /usr/local/redis/etc/sentinel.conf</span><br><span class="line">        #因为没有sentinel的Unitfile,所以启动时指定配置文件路径即可;</span><br><span class="line">5.验证：</span><br><span class="line">    [root@node01 ~]# redis-cli -h 192.168.34.118 -a root</span><br><span class="line">    192.168.34.118:6379&gt; INFO replication</span><br><span class="line">    # Replication</span><br><span class="line">    role:master</span><br><span class="line">    connected_slaves:2</span><br><span class="line">    slave0:ip=192.168.34.117,port=6379,state=online,offset=393121,lag=1</span><br><span class="line">    slave1:ip=192.168.34.126,port=6379,state=online,offset=393407,lag=0</span><br><span class="line">    master_replid:42cbfee5a816a2cd95d002efed47878cda1fd351</span><br><span class="line">    master_replid2:ffac7a2cd6147d781c4fae196266b96dfa1cd9c4</span><br><span class="line">        #可以看到192.168.34.118有两个正常的slave;</span><br><span class="line">    在每一台哨兵sentinel都启动后，会在sentinel.conf文件中生成</span><br><span class="line">    1.所监控的mymaster，redis集群中的主从信息</span><br><span class="line">    2.sentinel集群的信息</span><br><span class="line">    [root@node01 ~]# tail /usr/local/redis/etc/sentinel.conf </span><br><span class="line">    protected-mode no</span><br><span class="line">    sentinel known-replica mymaster 192.168.34.118 6379</span><br><span class="line">    sentinel known-replica mymaster 192.168.34.117 6379</span><br><span class="line">        #上面两项是mymaster集群中的主从信息</span><br><span class="line">    sentinel known-sentinel mymaster 192.168.34.126 26379 7064908b82b7f81d820e1428e813efbf64b222b5</span><br><span class="line">    sentinel known-sentinel mymaster 192.168.34.118 26379 e9f530c38fe22f1c76d2cf5f8e52e048d946ec3a</span><br><span class="line">        #下面两项是sentinel集群中各sentinel的信息</span><br><span class="line">    sentinel current-epoch 0</span><br><span class="line">        #current-epoch 0表示是刚配置，redis集群没有故障转移，如果redis集群进行过</span><br><span class="line">        故障转移，current-epoch的值就会自动加1</span><br><span class="line">6.通过sentinel客户端命令验证</span><br><span class="line">    [root@node01 ~]# redis-cli -p 26379</span><br><span class="line">    127.0.0.1:26379&gt; SENTINEL masters</span><br><span class="line">    1)  1) &quot;name&quot;</span><br><span class="line">        2) &quot;mymaster&quot;</span><br><span class="line">        3) &quot;ip&quot;</span><br><span class="line">        4) &quot;192.168.34.118&quot;</span><br><span class="line">        5) &quot;port&quot;</span><br><span class="line">        6) &quot;6379&quot;</span><br><span class="line">        #此命令会显示集群中的master的信息</span><br><span class="line">    127.0.0.1:26379&gt; SENTINEL slaves mymaster</span><br><span class="line">    1)  1) &quot;name&quot;</span><br><span class="line">        2) &quot;192.168.34.118:6379&quot;</span><br><span class="line">        3) &quot;ip&quot;</span><br><span class="line">        4) &quot;192.168.34.118&quot;</span><br><span class="line">        #SENTINEL slaves mymaster会显示名为mymaster的redis集群中的主从信息</span><br><span class="line"></span><br><span class="line">7.故障转移模拟</span><br><span class="line">    1.关闭192.168.34.118这个redis主节点</span><br><span class="line">    2.再次查看名为mymaster的redis集群中的master是哪个节点</span><br><span class="line">        [root@node01 ~]# redis-cli -p 26379</span><br><span class="line">        127.0.0.1:26379&gt; SENTINEL masters</span><br><span class="line">        1)  1) &quot;name&quot;</span><br><span class="line">            2) &quot;mymaster&quot;</span><br><span class="line">            3) &quot;ip&quot;</span><br><span class="line">            4) &quot;192.168.34.126&quot;</span><br><span class="line">            5) &quot;port&quot;</span><br><span class="line">            6) &quot;6379&quot;</span><br><span class="line">            #此时看到新的master是192.168.34.126节点</span><br><span class="line">        [root@node01 ~]# tail /usr/local/redis/etc/sentinel.conf </span><br><span class="line">        protected-mode no</span><br><span class="line">        sentinel known-replica mymaster 192.168.34.118 6379</span><br><span class="line">        sentinel known-replica mymaster 192.168.34.117 6379</span><br><span class="line">        sentinel known-sentinel mymaster 192.168.34.126 26379 7064908b82b7f81d820e1428e813efbf64b222b5</span><br><span class="line">        sentinel known-sentinel mymaster 192.168.34.118 26379 e9f530c38fe22f1c76d2cf5f8e52e048d946ec3a</span><br><span class="line">        sentinel current-epoch 1   </span><br><span class="line">            #此时sentinel文件中也会记录进行了一次故障转移；</span><br><span class="line">    3.修改原来的master节点重新加入redis集群</span><br><span class="line">        如果故障的master被修复了，想要再次加入这个集群，就需要在redis.conf文件中设置主从同步信息就可以了；</span><br><span class="line">        [root@node01 ~]# vim /usr/local/redis/etc/redis.conf </span><br><span class="line">        replicaof 192.168.34.126 6379</span><br><span class="line">        masterauth &quot;root&quot;</span><br><span class="line">        启动redis:</span><br><span class="line">            [root@node01 ~]# systemctl start redis</span><br><span class="line">        4.验证：</span><br><span class="line">        [root@node01 ~]# redis-cli -h 192.168.34.126 -a root</span><br><span class="line">        192.168.34.126:6379&gt; INFO replication</span><br><span class="line">        # Replication</span><br><span class="line">        role:master</span><br><span class="line">        connected_slaves:2</span><br><span class="line">        slave0:ip=192.168.34.117,port=6379,state=online,offset=393121,lag=1</span><br><span class="line">        slave1:ip=192.168.34.118,port=6379,state=online,offset=393407,lag=0</span><br><span class="line">        master_replid:42cbfee5a816a2cd95d002efed47878cda1fd351</span><br><span class="line">        master_replid2:ffac7a2cd6147d781c4fae196266b96dfa1cd9c4</span><br><span class="line">            #可以看到新的master192.168.34.126有两个正常的slave;</span><br></pre></td></tr></table></figure><p>–当前redis状态<br><img src="/2018/07/15/redis高可用/当前redis状态.png" alt="当前redis状态"><br>–故障转移时sentinel信息<br><img src="/2018/07/15/redis高可用/故障转移时sentinel信息.png" alt="故障转移时sentinel信息"><br>–故障转移后的redis配置文件<br><img src="/2018/07/15/redis高可用/故障转移后的redis配置文件.png" alt="故障转移后的redis配置文件"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Redis高可用&quot;&gt;&lt;a href=&quot;#Redis高可用&quot; class=&quot;headerlink&quot; title=&quot;Redis高可用&quot;&gt;&lt;/a&gt;Redis高可用&lt;/h3&gt;
    
    </summary>
    
      <category term="缓存" scheme="https://www.liukui.tech/categories/%E7%BC%93%E5%AD%98/"/>
    
      <category term="redis" scheme="https://www.liukui.tech/categories/%E7%BC%93%E5%AD%98/redis/"/>
    
    
      <category term="redis高可用" scheme="https://www.liukui.tech/tags/redis%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>redis基础</title>
    <link href="https://www.liukui.tech/2018/06/26/redis%E5%9F%BA%E7%A1%80/"/>
    <id>https://www.liukui.tech/2018/06/26/redis基础/</id>
    <published>2018-06-26T00:00:00.000Z</published>
    <updated>2019-04-06T16:08:36.854Z</updated>
    
    <content type="html"><![CDATA[<h3 id="缓存基础介绍"><a href="#缓存基础介绍" class="headerlink" title="缓存基础介绍"></a>缓存基础介绍</h3><a id="more"></a><h3 id="1-系统缓存：buffer与cache"><a href="#1-系统缓存：buffer与cache" class="headerlink" title="1.系统缓存：buffer与cache"></a>1.系统缓存：buffer与cache</h3><pre><code>centos6是分开的，centos7放到一起了.buffer：    缓冲也叫写缓冲，一般用于写操作，可以将数据先写入内存再写入磁盘，buffer 一般用于写缓冲，用于解决不同介质    的速度不一致的缓冲，先将数据临时写入到里自己最近的地方，以提高写入速度，CPU会把数据线写到内存的磁盘缓冲    区，然后就认为数据已经写入完成看，然后内核的线程在后面的时间在写入磁盘，所以服务器突然断电会丢失内存中的    部分数据。    buffer是在内存中还没写到磁盘上，即将写到磁盘上的数据！cache：    缓存也叫读缓存，一般用于读操作，CPU读文件从内存读，如果内存没有就先从硬盘读到内存再读到CPU，将需要频繁读    取的数据放在里自己最近的缓存区域，下次读取的时候即可快速读取。    cache是vim/cat等打开的文件信息放到内存中的称为cache,是为了下次访问时加速的！cache的保存位置：    客户端：浏览器(每个浏览器的默认过期时间不一样)    内存：本地服务器、远程服务器    硬盘：本机硬盘、远程服务器硬盘    速度对比：    客户端浏览器-CPU-内存-远程内存-硬盘-远程硬盘。cache的特性:    1.过期时间    2.强制过期，源网站更新图片后CDN是不会更新的，需要强制是图片缓存过期    3.命中率，即缓存的读取命中率        在memcached中可以看到有多少缓存和缓存的命中率;Cache（缓存）位于CPU与内存之间的临时存储器，缓存容量比内存小的多但交换速度比内存要快得多。Cache通过缓存文件数据块，解决CPU运算速度与内存读写速度不匹配的矛盾，提高CPU和内存之间的数据交换速度。Cache缓存越大，CPU处理速度越快。Buffer（缓冲）高速缓冲存储器，通过缓存磁盘（I/O设备）数据块，加快对磁盘上数据的访问，减少I/O，提高内存和硬盘（或其他I/O设备）之间的数据交换速度。Buffer是即将要被写入磁盘的，而Cache是被从磁盘中读出来的。</code></pre><h3 id="2-CDN缓存"><a href="#2-CDN缓存" class="headerlink" title="2.CDN缓存"></a>2.CDN缓存</h3><p><img src="/2018/06/26/redis基础/用户请求CDN的流程.png" alt="用户请求CDN的流程"></p><pre><code>CDN内容分发网络（Content Delivery Network），通过将服务内容分发至全网加速节点，利用全球调度系统使用户能够就近获取，有效降低访问延迟，提升服务可用性.    1.CDN第一降低机房的使用带宽，因为很多资源通过CDN就直接返回用户了;    2.第二解决不同运营商之间的互联，因为可以让联通的网络访问联通让电信的网络访问电信，起到加速用户访问的目的;    3.第三解决用户访问的地域问题，就近返回用户资源;关于302调度：    如用的是是联通的网络，但是设置了一个电信的DNS，或者电信的用户设置了一个联通的DNS，在刚建立连接的时候CDN法获    取到用户的真实IP，而是只能获取到用户的local DNS而判定用户是联通还是电信的网络，假如设置了错误的运营商DNS会    被调度到错误的CDN 边缘节点，当和边缘节点连接之后就可以获取到用户的真实IP从而判断用户是联通还是电信的网络，如    果是电信的网络被调度到了联通的CDN边缘节点或者是电信的网络被调度到了联通的CND边缘节点，那么可以给用户再发送一    个302重定向的回复，用户的浏览器再根据新的地址进行连接，即可访问到正确的CND 边缘节点。用户请求CDN的流程：    提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根    据访问的热度不同而进行不同级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA，    再其次的放在云存储，这样兼顾了速度与成本。内容分发与分层：    提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根    据访问的热度不通而进行不通级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA，    再其次的放在云存储，这样兼顾了速度与成本CDN的主要优势：    1.提前对静态内容进行预缓存，避免当地用户大量的请求回源，导致主站网络带宽被打满而导致数据无法更新,变向的    减小了存储、Web服务器、数据库的压力；    2.CDN还可以将数据根据访问的热度不通而进行不通级别的缓存，例如访问量最高的资源访问CDN边缘节点的内存，其次    的放在SSD(经常访问的数据放到SSD)或者SATA(不经常访问的放到SATA)，再其次的放在云存储，这样兼顾了速度与成    本。缓存-缓存到最快的地方如内存，缓存的数据准确命中率高，访问速度就快    3.将用户准确调度到最近的边缘节点性能优化，加快访问速度;    4.CDN还可以进行安全相关-抵御攻击    5.最主要的还是节省带宽；自建CDN优缺点：    nginx+squid、nginx+varnish、nginx+ATS等方式可以自建    优点：        自建CDN 比较灵活，可以在访问用户较多的地方多部署服务器        成本比较容易控制    缺点：        费用高        团队技术要求高        问题不变排查，出问题不容易搞的定 </code></pre><h3 id="3-应用层缓存"><a href="#3-应用层缓存" class="headerlink" title="3.应用层缓存"></a>3.应用层缓存</h3><pre><code>Nginx、PHP、tomcat等web服务可以设置应用缓存以加速响应用户请求，另外有些解释性语言比如PHP/Python不能直接运行，需要先编译成字节码，但字节码需要解释器解释为机器码之后才能执行，因此字节码也是一种缓存，有时候会出现程序代码上线后字节码没有更新的现象。动态页面静态化：    将java的动态页面静态化，比如将每个具体产品的web页面静态化为html文件，然后通过nginx 的rewrite功能发布，    即用户最终访问到的某个产品的web 页面是静态的页面，静态页面的访问速度是比较快的，生成的静态页面可以通过nfs、    rsync、分布式存储等方式推送到各web服务器，如果静态页面生成的信息是错误的，可以将信息更改后通过推送平台重新生    成新的web页面并同步到各web服务器，平时可以通过每间隔几个小时自动生成静态页面，比如每6小时生成一次动态页面并同步到各web服务器;</code></pre><h3 id="4-其他缓存"><a href="#4-其他缓存" class="headerlink" title="4.其他缓存"></a>4.其他缓存</h3><pre><code>CPU缓存(L1的数据缓存和L1的指令缓存)、二级缓存、三级缓存磁盘缓存RAID卡缓存分布式缓存：redis、memcache # MegaCli64 -LDinfo -Lall -aAll 此命令可以监控到物理机的raid、磁盘等信息</code></pre><h3 id="Redis和Memcached"><a href="#Redis和Memcached" class="headerlink" title="Redis和Memcached"></a>Redis和Memcached</h3><p><img src="/2018/06/26/redis基础/分布式缓存架构.png" alt="分布式缓存架构"></p><pre><code>1.Redis和Memcached是非关系型数据库也称为NoSQL，2.redis是一个开源的、遵循BSD协议的、基于内存的而且目前比较流行的键值数据库(key-value database)，是一个非关系型数据库，redis提供将内存通过网络远程共享的一种服务，提供类似功能的还有memcache，但相比memcache，redis还提供了易扩展、高性能、具备数据持久性等功能；3.redis是单线程的，在高并发、低延迟环境要求比较高的环境使用量非常广泛，memcached是多进程的.redis和memcached的对比：    1.支持两种方式进行数据的持久化：可以将内存中的数据保持在磁盘中，重启redis服务或者服务器之后可以从备份文    件中恢复数据到内存继续使用。    2.支持更多的数据类型：支持string(字符串)、hash(哈希数据)、list(列表)、set(集合)、zet(有序集合)    3.支持数据的备份：可以实现类似于数据的master-slave模式的数据备份，另外也支持使用快照+AOF；    4.支持更大的value数据：memcache单个key value最大只支持1MB，而redis最大支持    512MB；    5.Redis 是单线程，而memcache是多线程，所以单机情况下没有memcache并发高，但redis         支持分布式集群以实现更高的并发，单Redis实例可以实现数万并发。    6.支持集群横向扩展：基于redis cluster的横向扩展，可以实现分布式集群，大幅提    升性能和数据安全性。    7.都是基于C语言开发。redis的典型应用场景：    Session共享：常见于web集群中的Tomcat或者PHP中多web服务器session共享            详见：tomcat的session cluster/server共享    消息队列：ELK的日志缓存、部分业务的订阅发布系统    计数器：访问排行榜、商品浏览数等和次数相关的场景    缓存：数据查询、电商网站商品信息、新闻内容    微博/微信社交场合：共同好友、点赞评论等redis的主要功能：    1.Redis支持多种数据结构，包括字符串、哈希表、链表、集合、有序集合、位图、Hyperloglogs等;    2.Redis具备LRU淘汰、事务实现、以及不同级别的硬盘持久化等能力，并且支持副本集和    通过Redis Sentinel实现的高可用方案，同时还支持通过Redis Cluster实现的数    据自动分片能力;    3.Redis的主要功能都基于单线程模型实现，也就是说Redis使用一个线程来服务所有的    客户端请求，同时Redis采用了非阻塞式IO，并精细地优化各种命令的算法时间复杂度，    这些信息意味着：        1.Redis是线程安全的（因为只有一个线程），其所有操作都是原子的，不会因并发产生数据异常;        2.Redis的速度非常快（因为使用非阻塞式IO，且大部分命令的算法时间复杂度都是O(1));        3.使用高耗时的Redis命令是很危险的，会占用唯一的一个线程的大量处理时间，导致所有的请求都被拖慢。        （例如时间复杂度为O(N)的KEYS命令，严格禁止在生产环境        中使用);</code></pre><h3 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a>Redis安装</h3><pre><code>版本：    公司现在一般用的是3.X 4.X版本的，最新是5.3版本了    http://download.redis.io/releases/    epel源上的redis版本是3.2.12，这里进行编译安装redis-5.0.3版本；编译安装：    [root@node01 ~]# cd /usr/local/src    [root@node01 src]# tar xf redis-5.0.3.tar.gz     [root@node01 src]# cd redis-5.0.3    [root@node01 redis-5.0.3]# make PREFIX=/usr/local/redis install         #将二进制命令放到/usr/local/redis下        编译安装的就不能使用systemctl进行启动了，可以根据yum安装的程序路径进行修改；    [root@node01 redis]# mkdir /usr/local/redis/etc/   #创建配置文件目录    [root@node01 redis]# mkdir /usr/local/redis/data/  #创建数据目录    [root@node01 redis]# mkdir /usr/local/redis/logs/  #创建日志存放目录    [root@node01 redis]# mkdir /usr/local/redis/run/   ##创建pid目录    [root@node01 redis]# cp /usr/local/src/redis-5.0.3/redis.conf /usr/local/redis/etc/        #将原来目录下的redis.conf文件拷贝到二进制命令的目录下redis相关命令:    [root@node01 bin]# ll    total 32672    -rwxr-xr-x. 1 root root 4366608 Mar 10 03:28 redis-benchmark    -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-check-aof            #用于检查aof文件异常状态    -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-check-rdb            #用于检查rbd文件异常状态    -rwxr-xr-x. 1 root root 4801864 Mar 10 03:28 redis-cli            #redis客户端命令    lrwxrwxrwx. 1 root root      12 Mar 10 03:28 redis-sentinel -&gt; redis-server  #哨兵命令    -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-server            #redis主程序用于启动redis启动：    [root@node01 redis]# pwd    /usr/local/redis    [root@node01 redis]# /usr/local/redis/bin/redis-server etc/redis.conf         #启动后会有三个警告信息一定要修改，不然运行后期会有错误解决启动时三个报警信息：    1.backlog参数控制的是三次握手的时候server端收到client ack确认号之后的队列值。        net.core.somaxconn = 512    2.vm.overcommit_memory：        0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存        申请失败，并把错误返回给应用进程。        1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。        2 表示内核允许分配超过所有物理内存和交换空间总和的内存        vm.overcommit_memory = 1        #因为memcached和redis是直接操作内存的，内存的参数不需要使用内核的参数来调了;    3.transparent hugepage：        开启大页内存动态分配，需要关闭让redis 负责内存管理。        echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled        #如果是虚拟化的情况下，需要打开；修改配置文件并开机自动生效：    [root@node01 etc]# vim /etc/rc.d/rc.local    echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled    [root@node01 etc]# chmod +x /etc/rc.d/rc.local    [root@node01 etc]# vim /etc/sysctl.conf    net.core.somaxconn = 512    vm.overcommit_memory = 1创建用户：    [root@node01 redis]# useradd redis -s /sbin/nologin设置目录权限：    [root@node01 redis]# chown redis.redis /usr/local/redis/ -R    #redis用户要对编译的路径有权限创建软链接：    [root@node01 bin]# ln -sv /usr/local/redis/bin/redis-* /usr/sbin/编辑redis服务启动脚本:    # cat  /usr/lib/systemd/system/redis.service    [Unit]    Description=Redis persistent key-value database    After=network.target    After=network-online.target    Wants=network-online.target    [Service]    ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf  --supervised systemd    ExecReload=/bin/kill -s HUP $MAINPID     ExecStop=/bin/kill -s QUIT $MAINPID    Type=notify    User=redis    Group=redis    RuntimeDirectory=redis    RuntimeDirectoryMode=0755    [Install]    WantedBy=multi-user.target启动：    systemctl start redis</code></pre><h3 id="Redis配置文件详解"><a href="#Redis配置文件详解" class="headerlink" title="Redis配置文件详解"></a>Redis配置文件详解</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line">登录：</span><br><span class="line">    [root@node01 bin]# redis-cli  -h host (设置了bind就需要指定IP地址)</span><br><span class="line">        info    #查看redis信息</span><br><span class="line">        select  #切换数据库，默认是16个库(编号0-15)</span><br><span class="line">redis配置文件主要配置项：</span><br><span class="line">######################## 网络配置项  #####################################</span><br><span class="line">bind 0.0.0.0 #监听地址，可以用空格隔开后多个监听IP</span><br><span class="line">    #一般只监听在redis服务器的内网IP上,redis强烈建议内网使用</span><br><span class="line">protected-mode yes  redis的保护模式</span><br><span class="line">    #redis3.2之后加入的新特性，在没有设置bind IP和密码的时候只允许访问</span><br><span class="line">    127.0.0.1:6379</span><br><span class="line">port 6379       #监听端口</span><br><span class="line">tcp-backlog 511 #三次握手的时候server端收到client ack确认号被占满后的等待队列</span><br><span class="line">                长度；</span><br><span class="line">timeout 0 </span><br><span class="line">    #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时，生产环境下是600。 </span><br><span class="line">tcp-keepalive 300   #tcp会话保持超时时间</span><br><span class="line">########################### 通用配置项 ################################</span><br><span class="line">daemonize no    #默认情况下redis不是作为守护进程运行的，如果你想让它在后台</span><br><span class="line">        运行，你就把它改成yes,当redis作为守护进程运行的时候，它会写一个pid</span><br><span class="line">        到/var/run/redis.pid文件里面；</span><br><span class="line">        在centos6上是yes，在centos7上都是no</span><br><span class="line">supervised no </span><br><span class="line">        #和操作系统相关参数，可以设置通过upstart和systemd管理Redis守护进程，</span><br><span class="line">        centos 7以后都使用systemd</span><br><span class="line">pidfile /usr/local/redis/redis_6379.pid #pid文件路径</span><br><span class="line">        #一般习惯放在编译的路径下(但是redis用户需要对此目录有读权限)</span><br><span class="line">loglevel notice     #日志级别</span><br><span class="line">#loglevel debug  #如果日志显示不详细，可以开启debug模式，但是debug的日志会很大；</span><br><span class="line">logfile &quot;/usr/local/redis/redis_6379.log&quot; #日志路径</span><br><span class="line">    #一般习惯放在编译的路径下(但是redis用户需要对此目录有读权限)</span><br><span class="line">databases 16  #设置db库数量，默认16个库，名称编号0-15</span><br><span class="line">            改成-1,表示支持无限个库</span><br><span class="line">####################### 和快照相关的参数/RBD ###############################</span><br><span class="line">###快照时从redis主进程复制出一个专门的进程做快照，不会影响redis的读写</span><br><span class="line">always-show-logo yes #在启动redis 时是否显示log</span><br><span class="line">save 900 1  #在900秒内有一个键内容发生更改就出就快照机制</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000  #也可以通过BGSAVE命令手工触发RDB快照保存。</span><br><span class="line">    #注意这是逆向生效的，启动一次全量备份</span><br><span class="line">    表示：三个策略满足其中任意一个均会触发SNAPSHOTTING操作；60s内至少有1W次key发生变化才触发备份，300s内至少</span><br><span class="line">    有10次key有变化才触发备份，900s内至少有一次key有变化，所以最迟是900s/15min分钟会做一次快照全量备份；</span><br><span class="line">stop-writes-on-bgsave-error no  #快照创建出错时是否禁止redis写入操作</span><br><span class="line">    #重要配置，一定要改成no,避免快照因为磁盘空间满了快照写不进去，使得redis</span><br><span class="line">    无法登陆；</span><br><span class="line">rdbcompression yes #持久化到RDB文件时，是否压缩，&quot;yes&quot;为压缩，&quot;no&quot;则反之</span><br><span class="line">            #启用压缩功能有时还是有必要的</span><br><span class="line">rdbchecksum yes  #是否开启RC64校验，默认是开启</span><br><span class="line">dbfilename dump.rdb #快照生成的文件名，一般给称redis_6379.rdb</span><br><span class="line">dir ./ #快照文件保存路径;一般放在二进制编译路径下/usr/loca/redis</span><br><span class="line">        #一般这个路径不会放在系统盘的而是放在数据盘/挂载存储</span><br><span class="line">        #像k8s中这个盘可能是放在ceph/nfs/glusterfs上的,即使云服务down，</span><br><span class="line">        也会自动启动一个容器/pod加载到这个盘和文件进行数据恢复</span><br><span class="line">##################### REPLICATION主从复制相关的参数####################</span><br><span class="line">replicaof &lt;masterip&gt; &lt;masterport&gt;  #修改为master的IP和端口</span><br><span class="line">    如：replicaof 192.168.34.118 6379</span><br><span class="line">masterauth &lt;master-password&gt;       #master的密码</span><br><span class="line">replica-serve-stale-data yes    #当主节点down了，是否使用过期数据提供给主节点</span><br><span class="line">replica-read-only yes           #作为从服务器必须要是只读的</span><br><span class="line">repl-diskless-sync no</span><br><span class="line">    no, Disk-backed, Diskless</span><br><span class="line">        新的从节点或某较长时间未能与主节点进行同步的从节点重新与主节点通信，需要做&quot;full synchronization&quot;，此时其同步方式有两种style：</span><br><span class="line">            Disk-backend：主节点新创建快照文件于磁盘中，而后将其发送给从节点；</span><br><span class="line">            Diskless：主节占新创建快照后直接通过网络套接字文件发送给从节点；为了实现并行复制，通常需要在复制启动前延迟一个时间段；</span><br><span class="line">repl-diskless-sync-delay 5  #Diskless模式下复制启动前延迟一个时间</span><br><span class="line">        #在第一个从节点连进来后等待5s，在这5s内其他从节点都连进来之后</span><br><span class="line">        主节点主做一次复制同时传给N个从节点，加快效率</span><br><span class="line">repl-ping-replica-period 10 #默认不开启</span><br><span class="line">    #slave端向server端发送ping的时间区间设置，默认为10秒</span><br><span class="line">repl-timeout 60  </span><br><span class="line">    #设置复制的超时时长，60s,超过这个时间，从节点再连到主节点就需要重新复制了；</span><br><span class="line">repl-disable-tcp-nodelay no  #不禁止tcp nodelay，也就是启用tcp nodelay</span><br><span class="line">replica-priority 100  #从节点的优先级</span><br><span class="line">    复制集群中，主节点故障时，sentinel应用场景中的主节点选举时使用的优先级；数字越小优先级越高，但0表示不参与选举； </span><br><span class="line">    #类似于keepalived的主从priority</span><br><span class="line">min-slaves-to-write 3</span><br><span class="line">        #主节点仅允许其能够通信的从节点数量大于等于此处的值时接受写操作；</span><br><span class="line">min-slaves-max-lag 10</span><br><span class="line">        #从节点延迟时长超出此处指定的时长时，主节点会拒绝写入操作；10s</span><br><span class="line">####################和安全相关的参数配置####################################</span><br><span class="line">requirepass root123456   #设置redis的登录密码</span><br><span class="line">    登录后，需要AUTH root23456验证后，才能set key</span><br><span class="line">    如果不设置密码，通过telnet就可以登录到redis进行删除等操作，所以生产环境下建议一定要设置密码.</span><br><span class="line">################# 和客户端相关的参数配置/limits #############################</span><br><span class="line">maxclients 10000    #最大的客户端并发连接数</span><br><span class="line">        #默认值就可以了，毕竟redis是面向应用程序服务器的，而不是客户端</span><br><span class="line">############### 内存管理与数据淘汰机制/极其重要 ##############################</span><br><span class="line">maxmemory 8589934592   #单位是字节(8g*1024*1024*1024)</span><br><span class="line">        #一旦设置了最大使用内存空间，当使用空间耗尽时，就需要定义策略了；</span><br><span class="line">        #注意一定要设置最大内存，如果不设置可能会启用swap交换内存,交换内存会降低</span><br><span class="line">        redis的性能，而且swap也使用完后就会导致OOM，内核会kill掉redis进程；</span><br><span class="line">maxmemory-policy noeviction  #默认使用的淘汰策略</span><br><span class="line">    1.volatile-lru  #对设置了过期时间的key使用LRU算法进行淘汰</span><br><span class="line">    2.allkeys-lru   #对所有键key使用LRU算法进行淘汰</span><br><span class="line">    3.volatile-random  #对过期的key进行随机算法进行淘汰</span><br><span class="line">    4.allkeys-random   #对所有键key基于随机算法进行淘汰</span><br><span class="line">    5.volatile-ttl  #比较设置了过期时间的key，越短的先被淘汰</span><br><span class="line">    6.noeviction    #不淘汰任何现有的数据项</span><br><span class="line">        #redis作为database时，一定要使用noeviction</span><br><span class="line">        #redis作为缓存时，应该使用volatile-lru或者noeviction，具体使用哪种策略取决于业务中的具体情况；</span><br><span class="line">配置解析：</span><br><span class="line">    1.默认情况下，在32位OS中，Redis最大使用3GB的内存，在64位OS中则没有限制。</span><br><span class="line">    2.在使用Redis时，应该对数据占用的最大空间有一个基本准确的预估，并为Redis设定最大使用的内存。否则在64位OS中</span><br><span class="line">    Redis会无限制地占用内存（当物理内存被占满后会使用swap空间），容易引发各种各样的问题；</span><br><span class="line">    3.在内存占用达到了maxmemory后，再向Redis写入数据时，Redis会：</span><br><span class="line">        1.根据配置的数据淘汰策略尝试淘汰数据，释放空间</span><br><span class="line">        2.如果没有数据可以淘汰，或者没有配置数据淘汰策略，那么Redis会对所有写请求返回错误，但读请求仍然可以正常执行</span><br><span class="line">    4.在为Redis设置maxmemory时，需要注意：</span><br><span class="line">        1.如果采用了Redis的主从同步，主节点向从节点同步数据时，会占用掉一部分内存空间，如果maxmemory过于接近</span><br><span class="line">        主机的可用内存，导致数据同步时内存不足。所以设置的maxmemory不要过于接近主机可用的内存，留出一部分预留用作主从同步。</span><br><span class="line">maxmemory-samples 5     #淘汰算法运行时的采样样本数；</span><br><span class="line">######################### AOF相关配置 #################################</span><br><span class="line">appendonly yes   #启用aof日志，类似于mysql的bin-log,一定要改成yes</span><br><span class="line">        #登录redis的select、Set等操作就会被记录在此日志中</span><br><span class="line">appendfilename &quot;appendonly.aof&quot;  #aof日志的路径和名称</span><br><span class="line">        #注意这个路径是以上面的dir路径为根的</span><br><span class="line">        #如果要保存在一个后端存储上，最好写成绝对路径</span><br><span class="line">    -----------------------------------------------------------</span><br><span class="line">#AOF提供了三种fsync配置，always/everysec/no，通过配置项[appendfsync]指定：</span><br><span class="line">#appendfsync always  </span><br><span class="line">        #每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢    </span><br><span class="line">appendfsync everysec</span><br><span class="line">        #折中的做法，交由后台线程每秒fsync一次</span><br><span class="line">#appendfsync no     </span><br><span class="line">        #不进行fsync，将flush文件的时机交给OS决定，速度最快</span><br><span class="line">    ----------------------------------------------------------</span><br><span class="line">#随着AOF不断地记录写操作日志，必定会出现一些无用的日志，例如某个时间点执行了命令SET key1 “abc”，在之后某个</span><br><span class="line">时间点又执行了SET key1 “bcd”，那么第一条命令很显然是没有用的。大量的无用日志会让AOF文件过大，也会让数据恢复的</span><br><span class="line">时间过长。</span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb    #触发aof日志rewrite</span><br><span class="line">    #上面两行配置的含义是，Redis在每次AOF rewrite时，会记录完成rewrite后的AOF日志大小，当AOF日志大小在该基础</span><br><span class="line">    上增长了100%后，自动进行AOF rewrite。同时如果增长的大小没有达到64mb，则不会进行rewrite。</span><br><span class="line">############################# 慢日志查询相关配置 ##########################</span><br><span class="line">Slow log是Redis用来记录查询执行时间的日志系统，slow log保存在内存里面，读写</span><br><span class="line">速度非常快，因此你可以放心地使用它，不必担心因为开启slow log而损害Redis的速度。</span><br><span class="line">slowlog-log-slower-than 10000(10毫秒10的负6次方)</span><br><span class="line">        #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作</span><br><span class="line">slowlog-max-len 128   </span><br><span class="line">        #记录多少条慢日志保存在队列，超出后会删除最早的，以此滚动删除</span><br><span class="line">####################### REDIS CLUSTER集群相关 ##############################</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes-6379.conf</span><br><span class="line">    #集群节点集群信息配置文件,每个节点都有一个,由redis生成和更新,配置时避免名称冲突</span><br><span class="line">    #直接指一个文件名即可，文件内容自动生成不需要填入任何配置参数</span><br><span class="line">cluster-node-timeout 15000</span><br><span class="line">    集群节点互连超时的阈值，单位毫秒</span><br><span class="line">cluster-slave-validity-factor 10</span><br><span class="line">    进行故障转移时,salve会申请成为master。有时slave会和master失联很久导致数据较旧，这样的slave不应该成为</span><br><span class="line">    master。这个配置用来判断slave是否和master失联时间过长。</span><br><span class="line">###########################################################################</span><br></pre></td></tr></table></figure><h3 id="Redis的数据结构和常用命令"><a href="#Redis的数据结构和常用命令" class="headerlink" title="Redis的数据结构和常用命令"></a>Redis的数据结构和常用命令</h3><pre><code>Key:1.Redis采用Key-Value型的基本数据结构，任何二进制序列都可以作为Redis的Key使用（例如普通的字符串或一张JPEG图片）2.关于Key的一些注意事项：    1.不要使用过长的Key。例如使用一个1024字节的key就不是一个好主意，不仅会消耗更多的内存，还会导致查找的效率降低    2.Key短到缺失了可读性也是不好的，例如”u1000flw”比起”user:1000:followers”来说，节省了寥寥的存储空间，却引发了可读性和可维护性上的麻烦    3.最好使用统一的规范来设计Key，比如”object-type:id:attr”，以这一规范设计出的Key可能是”user:1000″或    ”comment:1234:reply-to”    4.Redis允许的最大Key长度是512MB（对Value的长度限制也是512MB）</code></pre><h4 id="1-字符串-String"><a href="#1-字符串-String" class="headerlink" title="1.字符串:String"></a>1.字符串:String</h4><pre><code>1.String是Redis的基础数据类型，Redis没有Int、Float、Boolean等数据类型的概念，所有的基本类型在Redis中都以String体现;    SET：为一个key设置value，可以配合EX/PX参数指定key的有效期，通过NX/XX参数针对        key是否存在的情况进行区别操作，时间复杂度O(1)    GET：获取某个key对应的value，时间复杂度O(1)    GETSET：为一个key设置value，并返回该key的原value，时间复杂度O(1)    MSET：为多个key设置value，时间复杂度O(N)    MSETNX：同MSET，如果指定的key中有任意一个已存在，则不进行任何操作，时间复杂度O(N)    MGET：获取多个key对应的value，时间复杂度O(N)2.redis的基本数据类型只有String，但Redis可以把String作为整型或浮点型数字来使用，主要体现在INCR、DECR类的命令上：    1.INCR：将key对应的value值自增1，并返回自增后的值。只对可以转换为整型的String        数据起作用。时间复杂度O(1)    2.INCRBY：将key对应的value值自增指定的整型数值，并返回自增后的值。只对可以转换        为整型的String数据起作用。时间复杂度O(1)    3.DECR/DECRBY：同INCR/INCRBY，自增改为自减。备注：    1.INCR/DECR系列命令要求操作的value类型为String，并可以转换为64位带符号的整型        数字，否则会返回错误。    2.也就是说，进行INCR/DECR系列命令的value，必须在[-2^63 ~ 2^63 – 1]范围内。    3.前文提到过，Redis采用单线程模型，天然是线程安全的，这使得INCR/DECR命令可以        非常便利的实现高并发场景下的精确控制。例1：库存控制    在高并发场景下实现库存余量的精准校验，确保不出现超卖的情况。    设置库存总量：        SET inv:remain &quot;100&quot;     库存扣减+余量校验：        DECR inv:remain    当DECR命令返回值大于等于0时，说明库存余量校验通过，如果返回小于0的值，则说明库存已耗尽。    假设同时有300个并发请求进行库存扣减，Redis能够确保这300个请求分别得到99到-200的返回值，每个请求得到的    返回值都是唯一的，绝对不会找出现两个请求得到一样的返回值的情况。例2：自增序列生成    实现类似于RDBMS的Sequence功能，生成一系列唯一的序列号    设置序列起始值：        SET sequence &quot;10000&quot;     获取一个序列值：        INCR sequence          直接将返回值作为序列使用即可；    获取一批（如100个）序列值：        INCRBY sequence 100         假设返回值为N，那么[N – 99 ~ N]的数值都是可用的序列值。    当多个客户端同时向Redis申请自增序列时，Redis能够确保每个客户端得到的序列值或序        列范围都是全局唯一的，绝对不会出现不同客户端得到了重复的序列值的情况。</code></pre><h4 id="2-列表：和ELK相关，基于管道插入多个数据"><a href="#2-列表：和ELK相关，基于管道插入多个数据" class="headerlink" title="2.列表：和ELK相关，基于管道插入多个数据"></a>2.列表：和ELK相关，基于管道插入多个数据</h4><pre><code>Redis的List是链表型的数据结构，可以使用LPUSH/RPUSH/LPOP/RPOP等命令在List的两端执行插入元素和弹出元素的操作。虽然List也支持在特定index上插入和读取元素的功能，但其时间复杂度较高（O(N)），应小心使用；    1.LPUSH：向指定List的左侧（即头部）插入1个或多个元素，返回插入后的List长度。        时间复杂度O(N)，N为插入元素的数量    2.RPUSH：同LPUSH，向指定List的右侧（即尾部）插入1或多个元素    3.LPOP：从指定List的左侧（即头部）移除一个元素并返回，时间复杂度O(1)    4.RPOP：同LPOP，从指定List的右侧（即尾部）移除1个元素并返回    5.LPUSHX/RPUSHX：与LPUSH/RPUSH类似，区别在于，LPUSHX/RPUSHX操作的key        如果不存在，则不会进行任何操作    6.LLEN：返回指定List的长度，时间复杂度O(1)    7.LRANGE：返回指定List中指定范围的元素（双端包含，即LRANGE key 0 10会返回        11个元素），时间复杂度O(N)。应尽可能控制一次获取的元素数量，一次获取过大范        围的List元素会导致延迟，同时对长度不可预知的List，避免使用LRANGE key 0 -1这样的完整遍历操作。应谨慎使用的List相关命令：    1.LINDEX：返回指定List指定index上的元素，如果index越界，返回nil。index数值是        回环的，即-1代表List最后一个位置，-2代表List倒数第二个位置。时间复杂度O(N)    2.LSET：将指定List指定index上的元素设置为value，如果index越界则返回错误，        时间复杂度O(N)，如果操作的是头/尾部的元素，则时间复杂度为O(1)    3.LINSERT：向指定List中指定元素之前/之后插入一个新元素，并返回操作后的List长        度。如果指定的元素不存在，返回-1。如果指定key不存在，不会进行任何操作，时间复杂度O(N)由于Redis的List是链表结构的，上述的三个命令的算法效率较低，需要对List进行遍历，    命令的耗时无法预估，在List长度大的情况下耗时会明显增加，应谨慎使用。换句话说，Redis的List实际是设计来用于实现队列，而不是用于实现类似ArrayList这样的列表的。如果你不是想要实现一个双端出入的队列，那么请尽量不要使用Redis的List数据结构</code></pre><h4 id="3-集合-Set"><a href="#3-集合-Set" class="headerlink" title="3.集合:Set"></a>3.集合:Set</h4><pre><code>Redis Set是无序的，集合成员是唯一的，不可重复的String集合.与Set相关的常用命令：    1.SADD：向指定Set中添加1个或多个member，如果指定Set不存在，会自动创建一个。        时间复杂度O(N)，N为添加的member个数    2.SREM：从指定Set中移除1个或多个member，时间复杂度O(N)，N为移除的member个数    3.SRANDMEMBER：从指定Set中随机返回1个或多个member，时间复杂度O(N)，N为返回的        member个数;    4.SPOP：从指定Set中随机移除并返回count个member，时间复杂度O(N)，N为移除的        member个数;    5.SCARD：返回指定Set中的member个数，时间复杂度O(1)    6.SISMEMBER：判断指定的value是否存在于指定Set中，时间复杂度O(1)    7.SMOVE：将指定member从一个Set移至另一个Set           SADD set1 v1            #生成集合key        TYPE set1               #查询集合key        SADD set1 v2 v3 v4      #追加数值，追加的时候不能追加已经存在的数值        SMEMBERS set1           #查看集合的所有数据        SDIFF set1 set2         #获取集合的差集            #差集：已属于A而不属于B的元素称为A与B的差（集）        SINTER set1 set2        #获取集合的交集            #交集：已属于A且属于B的元素称为A与B的交（集）        SUNION  set1 set2       #获取集合的并集            #并集：已属于A或属于B的元素为称为A与B的并（集）慎用的Set相关命令：    1.SMEMBERS：返回指定Hash中所有的member，时间复杂度O(N)    2.SUNION/SUNIONSTORE：计算多个Set的并集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数    3.SINTER/SINTERSTORE：计算多个Set的交集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数    4.SDIFF/SDIFFSTORE：计算1个Set与1或多个Set的差集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的Set尺寸不可知的情况下，应严格避免使用</code></pre><h4 id="4-有序集合：sorted-set"><a href="#4-有序集合：sorted-set" class="headerlink" title="4.有序集合：sorted set"></a>4.有序集合：sorted set</h4><pre><code>1.Sorted Set非常适合用于实现排名。2.Redis Sorted Set和Set一样也是string类型元素的集合,且不允许重复的成员，不同的是    Sorted Set中的每个元素都会关联一个double(双精度浮点型)类型的分数(score)，Sorted Set会根据score对元素    进行升序排序。如果多个member拥有相同的score，则以字典序进行升序排序;序集合的成员是唯一的,但分数(score)    却可以重复，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)，集合中最大的成员数为 232     - 1 (4294967295, 每个集合可存储40多亿个成员);Sorted Set的主要命令：    1.ZADD：向指定Sorted Set中添加1个或多个member，时间复杂度O(Mlog(N))，M为添加的member数量，N为Sorted Set中的member数量    2.ZREM：从指定Sorted Set中删除1个或多个member，时间复杂度O(Mlog(N))，M为删除的member数量，N为Sorted Set中的member数量    3.ZCOUNT：返回指定Sorted Set中指定score范围内的member数量，时间复杂度：O(log(N))    4.ZCARD：返回指定Sorted Set中的member数量，时间复杂度O(1)    5.ZSCORE：返回指定Sorted Set中指定member的score，时间复杂度O(1)    6.ZRANK/ZREVRANK：返回指定member在Sorted Set中的排名，ZRANK返回按升序排序的排名，ZREVRANK则        返回按降序排序的排名。时间复杂度O(log(N))    7.ZINCRBY：同INCRBY，对指定Sorted Set中的指定member的score进行自增，    时间复杂度O(log(N));慎用的Sorted Set相关命令：    1.ZRANGE/ZREVRANGE：返回指定Sorted Set中指定排名范围内的所有member，ZRANGE为按score升序排序，        ZREVRANGE为按score降序排序，时间复杂度O(log(N)+M)，M为本次返回的member数    2.ZRANGEBYSCORE/ZREVRANGEBYSCORE：返回指定Sorted Set中指定score范围内的所有member，返回结果以        升序/降序排序，min和max可以指定为-inf和+inf，代表返回所有的member。时间复杂度O(log(N)+M)    3.ZREMRANGEBYRANK/ZREMRANGEBYSCORE：移除Sorted Set中指定排名范围/指定        score范围内的所有member。时间复杂度O(log(N)+M)            上述几个命令，应尽量避免传递[0 -1]或[-inf +inf]这样的参数，来对Sorted Set做一次性的完整遍历，特别是在Sorted Set的尺寸不可预知的情况下。可以通过ZSCAN命令来进行游标式的遍历.</code></pre><h4 id="5-Hash"><a href="#5-Hash" class="headerlink" title="5.Hash"></a>5.Hash</h4><pre><code>1.Hash即哈希表，Redis的Hash和传统的哈希表一样，是一种field-value型的数据结构，可以理解成将HashMap搬入Redis；2.Hash非常适合用于表现对象类型的数据，用Hash中的field对应对象的field即可，hash特别适合用于存储对象,Redis 中每个hash可以存储 232-1键值对(40多亿).    1.HSET：将key对应的Hash中的field设置为value。如果该Hash不存在，会自动创建一个。时间复杂度O(1)    2.HGET：返回指定Hash中field字段的值，时间复杂度O(1)    3.HMSET/HMGET：同HSET和HGET，可以批量操作同一个key下的多个field，时间        复杂度：O(N)，N为一次操作的field数量    4.HSETNX：同HSET，但如field已经存在，HSETNX不会进行任何操作，时间复杂度O(1)    5.HEXISTS：判断指定Hash中field是否存在，存在返回1，不存在返回0，时间复杂度O        (1)HDEL：删除指定Hash中的field（1个或多个），时间复杂度：O(N)，N为操作的field数量    6.HINCRBY：同INCRBY命令，对指定Hash中的一个field进行INCRBY，时间复杂度O(1)应谨慎使用的Hash相关命令：    1.HGETALL：返回指定Hash中所有的field-value对。返回结果为数组，数组中field和value交替出现。时间复杂度O(N)    2.HKEYS/HVALS：返回指定Hash中所有的field/value，时间复杂度O(N)上述三个命令都会对Hash进行完整遍历，Hash中的field数量与命令的耗时线性相关，对于尺寸不可预知的Hash，应严格避免使用上面三个命令，而改为使用HSCAN命令进行游标式的遍历</code></pre><h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><pre><code>redis除了支持数据类型之外还支持消息队列：生产者消费者模式和发布者订阅者模式.生产者消费者模式:    1.微服务架构是将比如多个war包分开部署作为独立的小服务，这些服务之间存在着相互    调用的关系，他们是通过特殊的管道发送消息，其他服务也会监听这个管道，当有消息过    来时会读取处理完后再发送到管道给其他服务去完成整个过程，然后再返回给用户.    2.常用的软件还有RabbitMQ、Kafka、RocketMQ、ActiveMQ等.redis实现生产者消费者模式：    1.生产者发布消息        192.168.34.117:6379&gt; LPUSH channel1 msg1 #从管道的左侧写入        (integer) 1        192.168.34.117:6379&gt; LPUSH channel1 msg2        (integer) 2        192.168.34.117:6379&gt; LPUSH channel1 msg3        (integer) 3    2.查看队列所有消息        192.168.34.117:6379&gt; LRANGE channel1  0  -1         1) &quot;msg3&quot;        2) &quot;msg2&quot;        3) &quot;msg1&quot;    3.消费者消费消息        192.168.34.117:6379&gt; RPOP channel1  #从管道的右侧消费        &quot;msg1&quot;    4.再次验证队列消息        192.168.34.117:6379&gt; LRANGE channel1  0  -1        1) &quot;msg3&quot;        2) &quot;msg2&quot;   #队列中的msg1消息已经被消费了，只剩两条消息了.发布者订阅模式：    在发布者订阅者模式下，发布者将消息发布到指定的channel里面，凡是监听该channel的消费者都会收到    同样的一份消息，这种模式类似于是收音机模式，即凡是收听某个频道的听众都会收到主持人发布的相同的消息内容redis实现发布者订阅模式：    1.订阅者监听频道        192.168.34.117:6379&gt; SUBSCRIBE channel2   #订阅消息        Reading messages... (press Ctrl-C to quit)        1) &quot;subscribe&quot;        2) &quot;channel2&quot;        3) (integer) 1    2.发布者发布消息        192.168.34.117:6379&gt; PUBLISH channel2 test1  #发布消息        (integer) 1    3.各订阅者得到验证消息        192.168.34.117:6379&gt; SUBSCRIBE channel2        Reading messages... (press Ctrl-C to quit)        1) &quot;subscribe&quot;        2) &quot;channel2&quot;        3) (integer) 1        1) &quot;message&quot;        2) &quot;channel2&quot;        3) &quot;test1&quot;        #此时订阅此频道的就可以看到消息了</code></pre><h3 id="Redis常用命令"><a href="#Redis常用命令" class="headerlink" title="Redis常用命令"></a>Redis常用命令</h3><pre><code>1.CONFIG：    config命令用于查看当前redis配置、以及不重启更改redis配置等。config可以完成绝大多数的redis.config文件中的配置.    示例：直接更改最大内存，而且是立即生效的        192.168.34.117:6379&gt; CONFIG set maxmemory 8589934592        OK        127.0.0.1:6379&gt; CONFIG get maxmemory         1) &quot;maxmemory&quot;        2) &quot;8589934592&quot;    示例：查看redis的配置信息        192.168.34.117:6379&gt; CONFIG GET *          1) &quot;dbfilename&quot;          2) &quot;redis_6379.rdb&quot;          3) &quot;requirepass&quot;          4) &quot;&quot;          5) &quot;masterauth&quot;          213) &quot;bind&quot;          214) &quot;192.168.34.117&quot;        #ONFIG GET *看到的奇数行是配置，偶数行是它的值    示例:更改密码        192.168.34.117:6379&gt; CONFIG SET requirepass 123456        OK2.INFO    显示当前节点redis运行状态信息    # Server            #server端配置信息    # Clients           #client端配置信息    # Memory            #Memory配置信息    # Persistence       #rbd和aof持久化配置信息    # Stats             #当前状态    # Replication       #集群相关信息(配置完集群查看是否正常)    # CPU               #CPU配置信息    # Cluster           #集群信息    # Keyspace          #redis的键时间通知3.SELECT    切换数据库        192.168.34.117:6379&gt; SELECT 6        OK        #redis是基于库做的隔离，不同的库是为了存放不同类型的key4.keys    查看当前库下的所有key    注意：        在redis数据量大的时候，禁止使用keys *命令，严重情况下回造成redis服务器的        IO爆满而出现故障！可以先用DBSIZE看一下有多少个key!5.BGSAVE：非阻塞    手动在后台执行RDB持久化操作，会立即启动一个后台进程做快照    192.168.34.117:6379[6]&gt; BGSAVE    Background saving started6.SAVE：阻塞    执行SAVE时，数据量比较大时，需要几秒甚至更长的时间将数据保存到磁盘上，如果再SAVE过程中，写入请求会中断    的，可能会造成数据丢失，所以一般用BGSAVE.7.DBSIZE    显示当前库下的所有key数量    192.168.34.117:6379&gt; DBSIZE    (integer) 28.FLUSHDB    强制清空当前库中的所有key,慎重使用！9.FLUSHALL    强制清空当前redis服务器所有数据库中的所有key，即删除所有数据,慎重使用！10.CLIENT命令    127.0.0.1:6379[1]&gt; CLIENT LIST        #显示连进来的客户端    127.0.0.1:6379[1]&gt; CLIENT KILL        #关闭客户端+id或者ip+port11.redis的事务    1.事务操作是原子性的就是要么都执行要么都不执行，为了保证事务本身的特性，还可以撤销事务之前所做的操作；    2.redis也是支持事务的，虽然不支持撤销功能，但可以保证将多个命令打包成一个然后一次性的按顺序执行多个命令的机    制，并且在事务执行期间服务器不会中断事务而改变去执行其他客户端命令的请求，它会将事务中的所有命令执行完毕然后    才会处理其他命令请求；    3.redis通过MULTI,EXEC,WATCH等命令实现事务功能，但是仅仅是实现了将多个命令打包然后一次性的按顺序执行多个命令的机制；</code></pre><h3 id="Redis数据持久化"><a href="#Redis数据持久化" class="headerlink" title="Redis数据持久化"></a>Redis数据持久化</h3><pre><code>redis虽然是一个内存级别的缓存程序，即redis是使用内存进行数据的缓存的，但是其可以将内存的数据按照一定的策略保存到硬盘上，从而实现数据持久保存的目的，redis支持两种不同方式的数据持久化保存机制，分别是RDB和AOF.必须使用数据持久化吗？    但通常来说，仍然建议至少开启RDB方式的数据持久化，因为：        1.RDB方式的持久化几乎不损耗Redis本身的性能，在进行RDB持久化时，Redis主进            程唯一需要做的事情就是fork出一个子进程，所有持久化工作都由子进程完成        2.Redis无论因为什么原因crash掉之后，重启时能够自动恢复到上一次RDB快照中记            录的数据。这省去了手工从其他数据源（如DB）同步数据的过程，而且要比其他任何的数据恢复方式都要快        3.现在硬盘那么大，真的不缺那一点地方.Redis的持久化:    RDB：snapshotting, 二进制格式；按事先定制的策略，周期性地将数据从内存同步至磁盘；数据文件默认为dump.rdb；        客户端显式使用SAVE或BGSAVE命令来手动启动快照保存机制；            SAVE：同步，即在主线程中保存快照，此时会阻塞所有客户端请求；            BGSAVE：异步；backgroud        RDB是完全备份，所以可能会丢失数据；    AOF：Append Only File, fsync        记录每次写操作至指定的文件尾部实现的持久化；当redis重启时，可通过重新执行文件中的命令在内存中重建出数据库；            BGREWRITEAOF：AOF文件重写；                不会读取正在使用AOF文件，而是通过将内存中的数据以命令的方式保存至临时文件中，完成之后替换原来的AOF文件；RBD:基于时间的快照技术，在save 900 1，在900秒内有一个键内容发生更改就快照机制；在同时开启AOF和RBD时，因为AOF的级别比RBD高会使用AOF模式.AOF：类似于数据库的binlog，将文件拷贝走，放到另外一台redis的数据目录，自动恢复    AOF中记录的是每次在redis的操作，和mysql的bin-log类似;生产环境：    1.生产环境下，一般在Slave服务器上同时开启AOF和RDB，Master上只开启RBD.但是生产环境下是需要做集群来解决数据高可用的问题.    2.不建议同时开启RBD和AOF，会对I/O性能影响很高    3.如果一定要同时开启两种持久化方式，最好是把他们放在两个不同的后端存储系统上；    4.如果同时启用时，当出现故障时一定要用AOF恢复，因为它恢复的数据量更多；</code></pre><h4 id="RDB模式：snapshotting"><a href="#RDB模式：snapshotting" class="headerlink" title="RDB模式：snapshotting"></a>RDB模式：snapshotting</h4><pre><code>redis的RDB的快照机制是直接把redis放在内存中的数据所占用的内存空间直接原样不动的复刻一份放到磁盘上,它是一个二进制文件;    即把在内存中的数据和它的结构通通转为文件格式放到磁盘上,恢复时会从文件中读取，读取到内存中恢复为在内存空间中的空间结构和数据；RDB：基于时间的快照，默认只保留当前最新的一次快照(会把上一次的快照切换掉)，特点是执行速度比较快，缺点是可能会丢失从上次快照到当前快照未完成之间的数据(即在两次快照时间之间redis服务可能出现故障，数据会丢失);如果是AOF模式，则不会发生此问题.RDB实现的具体过程：    1.Redis从主进程先fork出一个子进程，使用写时复制(COW)机制，子进程将内存的数据保存为一个临时文件，比如    dump.rdb.temp，当数据保存完成之后再将上一次保存的RDB文件替换掉，然后关闭子进程，这样可以保存每一次做RDB快照    的时候保存的数据都是完整的，因为直接替换RDB文件的时候可能会出现突然断电等问题而导致RDB文件还没有保存完整就突    然关机停止保存而导致数据丢失的情况，可以手动将每次生成的RDB文件进程备份，这样可以最大化保存历史数据。    2.因为会单独开一个子进程负责做快照，所以不影响redis的读写请求.    3.Redis是先将数据写入到一个临时文件中，并且写成功了才会保存到打算要存的文件中，所以一般来讲只要备份下来rdb文件总是可用的；    4.当然也可以连到redis之后，执行SAVE或者BGSAVE命令启动快照保存机制，每隔多长时间执行一次手动RBD数据备份；    但是：        SAVE:            是在主线程保存快照，这就意味着在SAVE保存完成之前，此时会阻塞所有客户端请求，因为它是同步保存而且在主线程中实现；            都是完整(全量)的将内存中的数据写入到磁盘当中，而不是增量方式，如果内存中数据量比较大时，必然会影响性能；        BGSAVE:            异步方式实现，当我们启动BGSAVE以后，他将立即返回结果告诉已经启动了，然后自动在后台实现保存操作，所以客户端主进程是不会被阻塞的！所以一般是通过在脚本中使用BGSAVE命令执行手动RBD数据备份操作!!!RDB模式的优缺点：    优点：        1.RDB快照保存了某个时间点的数据，可以通过脚本执行bgsave(非阻塞)或者save(阻塞)命令自定义时间点备份，可以保留多个备份，当出现问题可以恢复到不同时间点的版本。        2.可以最大化o的性能，因为父进程在保存RDB 文件的时候唯一要做的是fork出一个子进程，然后的-操作都会有这个子进程操作，父进程无需任何的IO操作;        3.RDB在大量数据比如几个G的数据，恢复的速度比AOF的快；    因为RDB是直接将几个G的文件导入到内存中，AOF中记录的是几千上万行的操作命令，        在数据恢复时，需要逐行执行.    缺点：        1-不能实时的保存数据，会丢失自上一次执行RDB备份到当前的内存数据；        2-数据量非常大的时候，从父进程fork的时候需要一点时间，可能是毫秒或者秒；</code></pre><h3 id="生产环境下遇到的坑："><a href="#生产环境下遇到的坑：" class="headerlink" title="生产环境下遇到的坑："></a>生产环境下遇到的坑：</h3><pre><code>redis RDB持久化模式有坑,因为我们使用的服务器是机械硬盘，读写性能和SSD固态硬盘相差很大，服务器内存是128G，当时给redis分了最大内存是120G，每fork一次就出来一个新的进程，但是在此触发持久化的条件后又会fork一个进程出来，前一个还未写到硬盘中，后一个fork已经出现孙子辈的了，甚至重孙辈的，导致服务器资源耗尽，宕机。还有个redis强烈建议内网使用，程序调用也是内网，程序调用也是内网，程序调用也是内网。因为有一次被黑就是redis在公网上跑，还没有设置密码,导致将近20台服务器被黑。</code></pre><h4 id="AOF模式-append-only-file"><a href="#AOF模式-append-only-file" class="headerlink" title="AOF模式:append only file"></a>AOF模式:append only file</h4><pre><code>1.AOF日志的全称是Append Only File，从名字上我们就能看出来，它就是把redis的每个操作命令都以追加的方式写入的日志文件尾部；2.与一般数据库不同的是，AOF文件是可识别的纯文本，它的内容就是一个个的Redis标准命令3.类似于mysql的bin-log日志；AOF:按照用户或Web服务器的操作顺序依次将操作添加到指定的日志文件当中，特点是数据安全性相对较高，缺点是即使有些操作是重复的也会全部记录.AOF有二个显著缺陷：    1.用fsync来解决数据同步不及时的问题        1.因为linux内核写数据的时候，其实不是直接写磁盘的，而是先把写操作放到内存完成，然后同步到磁盘中的；        2.内核将内存中的数据同步到磁盘的时间是不确定的，因为在内核中有个脏页数据同步策略，写数据-&gt;内存-&gt;由内核        同步到内核内存-&gt;磁盘，由于同步时间的不确定，在断电之前的内核内存中需要同步的数据就丢失了,所以为了避免出        现这种问题就使用fsync;        3.在内核有一个库调用叫fsync(文件同步)，它的工作逻辑是当需要把数据祈请给内核中，内核不但要把数据保存到内核内存中，还要立即同步到磁盘文件中去；        4.而我们只需要调用了fsync，就不会按照内核自己的管理调用方式待会再同步到磁盘，而是立即同步到磁盘，确保了数据一定是保存在磁盘上了；        5.由于内核之所以会使用脏页数据同步策略，就是为了提高IO性能的，而我们却通过        fsync强行同步到磁盘中了，这样一来每秒钟同步的次数就相当多了，而机械硬盘1s也就100个I/O，像SSD能有500IO/s,而PCIE这样的硬盘能达到上万的IO，但价格是        相当昂贵的；    2.AOF的rewrite        1.在redis中一个key以counter来计数通过INCR使得数据增长，如果INCR了20w次，在AOF中也会记录20w行        INCR-counter，不但造成AOF文件过大而且恢复时也会很慢；        2.而这种情况无非就是将counter直接变成20w次，所以为了避免AOF文件过大，必要每隔一段时间对这个key重写一遍        N个合并成一个即可，这叫做AOF的rewrite;这样一来文件的体积就很小，恢复时重放也不会很慢了；AOF实现的具体过程:    AOF和RDB一样使用了写时复制机制，AOF默认为每秒钟fsync一次，即将执行的命令保存到AOF文件当中，这样即使redis    服务器发生故障的话顶多也就丢失1秒钟之内的数据，也可以设置不同的fsync策略，或者设置每次执行命令的时候执行    fsync，fsync会在后台执行线程，所以主线程可以继续处理用户的正常请求而不受到写入AOF文件的IO影响AOF的优点：    1.最安全，在启用appendfsync always时(fsync是同步内存中redis所有已经修改        的文件到存储设备)，任何已写入的数据都不会丢失，使用在启用appendfsync everysec也至多只会丢失1秒的数据。    2.AOF文件在发生断电等问题时也不会损坏，即使出现了某条日志只写入了一半的情况，        也可以使用redis-check-aof工具轻松修复。    3.AOF文件易读，可修改，在进行了某些错误的数据清除操作后，只要AOF文件没有        rewrite，就可以把AOF文件备份出来，把错误的命令删除，然后恢复数据。AOF模式缺点:    1.AOF文件通常比RDB文件更大    2.磁盘IO性能消耗比RDB高(fsync机制的原因)    3.数据恢复速度比RDB慢</code></pre><h3 id="redis一键安装脚本和启动脚本"><a href="#redis一键安装脚本和启动脚本" class="headerlink" title="redis一键安装脚本和启动脚本"></a>redis一键安装脚本和启动脚本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line">[root@redis-node ~]# cd /usr/local/src/</span><br><span class="line">[root@redis-node src]# ll redis-4.0.1.tar.gz</span><br><span class="line">-rw-rw-r-- 1 root root 1711660 Aug 27 16:19 redis-5.0.3.tar.gz</span><br><span class="line">[root@redis-node src]# cat redis_install.sh</span><br><span class="line">#!/usr/bin/env bash</span><br><span class="line"># It&apos;s Used to be install redis.</span><br><span class="line"># Created on 2018/03/06 .</span><br><span class="line"># author: lk.</span><br><span class="line"># Version: 1.0</span><br><span class="line">    </span><br><span class="line">function install_redis () &#123;</span><br><span class="line">###########################################################################</span><br><span class="line">        cd /usr/local/src</span><br><span class="line">        tar -zxvf /usr/local/src/redis-5.0.3.tar.gz</span><br><span class="line">        cd redis-5.0.3</span><br><span class="line">        make PREFIX=/usr/local/redis install</span><br><span class="line">        mkdir -p /usr/local/redis/&#123;etc,var&#125;</span><br><span class="line">        rsync -avz redis.conf  /usr/local/redis/etc/</span><br><span class="line">        sed -i &apos;s@pidfile.*@pidfile /var/run/redis-server.pid@&apos; /usr/local/redis/etc/redis.conf</span><br><span class="line">        sed -i &quot;s@logfile.*@logfile /usr/local/redis/var/redis.log@&quot; /usr/local/redis/etc/redis.conf</span><br><span class="line">        sed -i &quot;s@^dir.*@dir /usr/local/redis/var@&quot; /usr/local/redis/etc/redis.conf</span><br><span class="line">        sed -i &apos;s/daemonize no/daemonize yes/g&apos; /usr/local/redis/etc/redis.conf</span><br><span class="line">        sed -i &apos;s/^# bind 127.0.0.1/bind 0.0.0.0/g&apos; /usr/local/redis/etc/redis.conf</span><br><span class="line"> ##########################################################################</span><br><span class="line">&#125;</span><br><span class="line">install_redis</span><br><span class="line"></span><br><span class="line">赋予脚本执行权限,并进行安装</span><br><span class="line">[root@redis-node src]# chmod 755 /usr/local/src/redis_install.sh</span><br><span class="line">[root@redis-node src]# /bin/bash -x /usr/local/src/redis_install.sh</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">编写redis-server启动脚本</span><br><span class="line">[root@redis-node src]# cat /etc/init.d/redis-server</span><br><span class="line">#!/bin/bash</span><br><span class="line">#</span><br><span class="line"># redis - this script starts and stops the redis-server daemon</span><br><span class="line">#</span><br><span class="line"># chkconfig:   - 85 15</span><br><span class="line"># description:  Redis is a persistent key-value database</span><br><span class="line"># processname: redis-server</span><br><span class="line"># config:      /usr/local/redis/etc/redis.conf</span><br><span class="line"># config:      /etc/sysconfig/redis</span><br><span class="line"># pidfile:     /usr/local/redis/var/redis-server.pid</span><br><span class="line">   </span><br><span class="line"># Source function library.</span><br><span class="line">. /etc/rc.d/init.d/functions</span><br><span class="line">   </span><br><span class="line"># Source networking configuration.</span><br><span class="line">. /etc/sysconfig/network</span><br><span class="line">   </span><br><span class="line"># Check that networking is up.</span><br><span class="line">[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0</span><br><span class="line">   </span><br><span class="line">redis=&quot;/usr/local/redis/bin/redis-server&quot;</span><br><span class="line">prog=$(basename $redis)</span><br><span class="line">   </span><br><span class="line">REDIS_CONF_FILE=&quot;/usr/local/redis/etc/redis.conf&quot;</span><br><span class="line">   </span><br><span class="line">[ -f /etc/sysconfig/redis ] &amp;&amp; . /etc/sysconfig/redis</span><br><span class="line">   </span><br><span class="line">lockfile=/var/lock/subsys/redis-server</span><br><span class="line">   </span><br><span class="line">start() &#123;</span><br><span class="line">    [ -x $redis ] || exit 5</span><br><span class="line">    [ -f $REDIS_CONF_FILE ] || exit 6</span><br><span class="line">    echo -n $&quot;Starting $prog: &quot;</span><br><span class="line">    daemon $redis $REDIS_CONF_FILE</span><br><span class="line">    retval=$?</span><br><span class="line">    echo</span><br><span class="line">    [ $retval -eq 0 ] &amp;&amp; touch $lockfile</span><br><span class="line">    return $retval</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">stop() &#123;</span><br><span class="line">    echo -n $&quot;Stopping $prog: &quot;</span><br><span class="line">    killproc $prog</span><br><span class="line">    retval=$?</span><br><span class="line">    echo</span><br><span class="line">    [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile</span><br><span class="line">    return $retval</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">restart() &#123;</span><br><span class="line">    stop</span><br><span class="line">    start</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">reload() &#123;</span><br><span class="line">    echo -n $&quot;Reloading $prog: &quot;</span><br><span class="line">    killproc $redis -HUP</span><br><span class="line">    RETVAL=$?</span><br><span class="line">    echo</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">force_reload() &#123;</span><br><span class="line">    restart</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">rh_status() &#123;</span><br><span class="line">    status $prog</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">rh_status_q() &#123;</span><br><span class="line">    rh_status &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line">case &quot;$1&quot; in</span><br><span class="line">    start)</span><br><span class="line">        rh_status_q &amp;&amp; exit 0</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    stop)</span><br><span class="line">        rh_status_q || exit 0</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    restart)</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    reload)</span><br><span class="line">        rh_status_q || exit 7</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    force-reload)</span><br><span class="line">        force_reload</span><br><span class="line">        ;;</span><br><span class="line">    status)</span><br><span class="line">        rh_status</span><br><span class="line">        ;;</span><br><span class="line">    condrestart|try-restart)</span><br><span class="line">        rh_status_q || exit 0</span><br><span class="line">            ;;</span><br><span class="line">    *)</span><br><span class="line">        echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload&#125;&quot;</span><br><span class="line">        exit 2</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">赋予脚本执行权限,并启动redis-server</span><br><span class="line">[root@redis-node src]# /etc/init.d/redis-server start</span><br><span class="line">[root@redis-node src]# lsof -i:6379</span><br><span class="line">COMMAND     PID USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME</span><br><span class="line">redis-ser 24439 root    6u  IPv4 24642923      0t0  TCP dns02.kevin.cn:6379 (LISTEN)</span><br><span class="line"> </span><br><span class="line">温馨提示:</span><br><span class="line">需要将redis.conf文件中的bind改为本机ip.不能使用默认的127.0.0.1,否则远程连接该redis就会失败</span><br><span class="line">[root@redis-node src]# vim /usr/local/redis/etc/redis.conf</span><br><span class="line">.....</span><br><span class="line">bind 192.168.34.118</span><br><span class="line"> </span><br><span class="line">重启redis-server服务</span><br><span class="line">[root@redis-node src]# /etc/init.d/redis-server restart</span><br><span class="line">Stopping redis-server:                                     [  OK  ]</span><br><span class="line">Starting redis-server:                                     [  OK  ]</span><br><span class="line">[root@redis-node src]# lsof -i:6379</span><br><span class="line">COMMAND    PID USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME</span><br><span class="line">redis-ser 8184 root    6u  IPv4 24688720      0t0  TCP dns02.kevin.cn:6379 (LISTEN)</span><br><span class="line"> </span><br><span class="line">最好在tomcat两个节点上使用&quot;telnet 192.168.34.118 6379&quot;验证下redis是否能成功连接</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;缓存基础介绍&quot;&gt;&lt;a href=&quot;#缓存基础介绍&quot; class=&quot;headerlink&quot; title=&quot;缓存基础介绍&quot;&gt;&lt;/a&gt;缓存基础介绍&lt;/h3&gt;
    
    </summary>
    
      <category term="缓存" scheme="https://www.liukui.tech/categories/%E7%BC%93%E5%AD%98/"/>
    
      <category term="redis" scheme="https://www.liukui.tech/categories/%E7%BC%93%E5%AD%98/redis/"/>
    
    
      <category term="redis" scheme="https://www.liukui.tech/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>分布式存储系统数据分布方法</title>
    <link href="https://www.liukui.tech/2018/05/10/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E6%96%B9%E6%B3%95/"/>
    <id>https://www.liukui.tech/2018/05/10/分布式存储系统数据分布方法/</id>
    <published>2018-05-10T00:00:00.000Z</published>
    <updated>2019-04-03T14:57:29.012Z</updated>
    
    <content type="html"><![CDATA[<h3 id="分布式存储系统数据分布方法"><a href="#分布式存储系统数据分布方法" class="headerlink" title="分布式存储系统数据分布方法"></a>分布式存储系统数据分布方法</h3><a id="more"></a><pre><code>分布式存储系统中面临着的首要问题就是如何将大量的数据分布在不同的存储节点上，无论上层接口是KV存储、对象存储、块存储、亦或是列存储，在这个问题上大体是一致的；而分布式存储系统中做数据分布目标及可选的方案一般分为下面几种：假设目标数据是以key标识的数据块或对象，在一个包含多个存储节点的集群中，数据分布算法需要为每一个给定的key指定一个或多个对应的存储节点负责，数据分布算法有两个基本目标：1.均匀性(Uniformity) ：不同存储节点的负载应该均衡；2.稳定性(Consistency)：每次一个key通过数据分布算法得到的分布结果应该保持基本稳定，即使再有存储节点发生变化的情况下。    可以看出，这两个目标在一定程度上是相互矛盾的，当有存储节点增加或删除时，为了保持稳定应该尽量少的进行数据的移    动和重新分配，而这样又势必会带来负载不均。同样追求极致均匀也会导致较多的数据迁移。所以我们希望在这两个极端之间    找到一个点以获得合适的均匀性和稳定性。除了上述两个基本目标外，工程中还需要从以下几个方面考虑数据分布算法的优劣：3.性能可扩展性，这个主要考虑的是算法相对于存储节点规模的时间复杂度，为了整个系统的可扩展性，数据分布算法不应该在集群规模扩大后显著的增加运行时间。4.考虑节点异构，实际工程中，不同存储节点之间可能会有很大的性能或容量差异，好的数据分布算法应该能很好的应对这种异构，提供加权的数据均匀。5.隔离故障域，为了数据的高可用，数据分布算法应该为每个key找到一组存储节点，这些节点可能提供的是数据的镜像副本，也可能是类似擦除码的副本方式。数据分布算法应该尽量隔离这些副本的故障域，如不同机房、不同机架、不同交换机、不同机器。</code></pre><h3 id="算法实现："><a href="#算法实现：" class="headerlink" title="算法实现："></a>算法实现：</h3><pre><code>分析完分布算法的评价指标后，接下来介绍一些可能的方案演进，并分析他们的优劣。这里假设key的值足够分散；</code></pre><h4 id="1-Hash"><a href="#1-Hash" class="headerlink" title="1.Hash"></a>1.Hash</h4><pre><code>1.一个简单直观的想法是直接用Hash来计算，简单的以Key做哈希后对节点数取模。可以看出，在key足够分散的情况下，均匀性可以获得，但一旦有节点加入或退出，所有的原有节点都会受到影响，稳定性无从谈起；2.这和负载均衡的调度算法以及后端缓存服务器的调度情况很类似，单纯的hash取模法是无法保证稳定性的；3.hash原理：对对象(文件/IP地址)的名称做hash计算，对后端的节点数量进行取模，模是几就落到第几个节点上进行数据存储；</code></pre><h4 id="2-一致性Hash"><a href="#2-一致性Hash" class="headerlink" title="2.一致性Hash"></a>2.一致性Hash</h4><p>–Consistent hash<br><img src="/2018/05/10/分布式存储系统数据分布方法/Consistent hash.png" alt="Consistent hash"></p><pre><code>一致性Hash可以很好的解决稳定问题，可以将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到先遇到的一组存储节点存放。而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将数据从该节点接收或者给予。但这有带来均匀性的问题，即使可以将存储节点等距排列，也会在存储节点个数变化时带来数据的不均匀。而这种可能成倍数的不均匀在实际工程中是不可接受的;</code></pre><h4 id="3-带负载上限的一致性Hash"><a href="#3-带负载上限的一致性Hash" class="headerlink" title="3.带负载上限的一致性Hash"></a>3.带负载上限的一致性Hash</h4><p>–带负载上限的一致性Hash<br><img src="/2018/05/10/分布式存储系统数据分布方法/带负载上限的一致性Hash.png" alt="带负载上限的一致性Hash"></p><pre><code>1.一致性Hash有节点变化时不均匀的问题，Google在2017年提出了Consistent Hashing with Bounded Loads来控制这种不均匀的程度。简单的说，该算法给Hash环上的每个节点一个负载上限为1 + e倍的平均负载，这个e可以自定义，当key在Hash环上顺时针找到合适的节点后，会判断这个节点的负载是否已经到达上限，如果已达上限，则需要继续找之后的节点进行分配;2.如上图所示，假设每个桶当前上限是2，红色的小球按序号访问，当编号为6的红色小球到达时，发现顺时针首先遇到的B（3，4），C（1，5）都已经达到上限，因此最终放置在桶A。这个算法最吸引人的地方在于当有节点变化时，需要迁移的数据量是1/e^2相关，而与节点数或数据数均无关，也就是说当集群规模扩大时，数据迁移量并不会随着显著增加。另外，使用者可以通过调整e的值来控制均匀性和稳定性之间的权衡。无论是一致性Hash还是带负载限制的一致性Hash都无法解决节点异构的问题</code></pre><h4 id="4-带虚拟节点的一致性Hash"><a href="#4-带虚拟节点的一致性Hash" class="headerlink" title="4.带虚拟节点的一致性Hash"></a>4.带虚拟节点的一致性Hash</h4><p>–带虚拟节点的一致性Hash<br><img src="/2018/05/10/分布式存储系统数据分布方法/带虚拟节点的一致性Hash.png" alt="带虚拟节点的一致性Hash"></p><pre><code>1.为了解决负载不均匀和异构的问题，可以在一致性Hash的基础上引入虚拟节点，即hash环上的每个节点并不是实际的存储节点，而是一个虚拟节点。实际的存储节点根据其不同的权重，对应一个或多个虚拟节点，所有落到相应虚拟节点上的key都由该存储节点负责。如下图所示，存储节点A负责(1,3]，(4,8]，(10, 14]，存储节点B负责(14,1]，(8,10];2.这个算法的问题在于，一个实际存储节点的加入或退出，会影响多个虚拟节点的重新分配，进而影响很多节点参与到数据迁移中来；另外，实践中将一个虚拟节点重新分配给新的实际节点时需要将这部分数据遍历出来发送给新节点。我们需要一个跟合适的虚拟节点切分和分配方式，那就是分片</code></pre><h4 id="5-分片"><a href="#5-分片" class="headerlink" title="5.分片"></a>5.分片</h4><p><img src="/2018/05/10/分布式存储系统数据分布方法/分片.png" alt="分片"></p><p><img src="/2018/05/10/分布式存储系统数据分布方法/分片2.png" alt="分片2"></p><pre><code>1.分片将哈希环切割为相同大小的分片，然后将这些分片交给不同的节点负责。注意这里跟上面提到的虚拟节点有着很本质的区别，分片的划分和分片的分配被解耦，一个节点退出时，其所负责的分片并不需要顺时针合并给之后节点，而是可以更灵活的将整个分片作为一个整体交给任意节点，实践中，一个分片多作为最小的数据迁移和备份单位;2.而也正是由于上面提到的解耦，相当于将原先的key到节点的映射拆成两层，需要一个新的机制来进行分片到存储节点的映射，由于分片数相对key空间已经很小并且数量确定，可以更精确地初始设置，并引入中心目录服务来根据节点存活修改分片的映射关系，同时将这个映射信息通知给所有的存储节点和客户端 ;3.上图是我们的分布式KV存储Zeppelin中的分片方式，Key Space通过Hash到分片，分片极其副本又通过一层映射到最终的存储节点Node Server</code></pre><h4 id="6-CRUSH算法"><a href="#6-CRUSH算法" class="headerlink" title="6.CRUSH算法"></a>6.CRUSH算法</h4><p><img src="/2018/05/10/分布式存储系统数据分布方法/CRUSH算法.png" alt="CRUSH算法"></p><p><img src="/2018/05/10/分布式存储系统数据分布方法/CRUSH算法2.png" alt="CRUSH算法2"></p><pre><code>    CRUSH算法本质上也是一种分片的数据分布方式，其试图在以下几个方面进行优化：    1.分片映射信息量：避免中心目录服务和存储节点及客户端之间需要交互大量的分片映射信息，而改由存储节点或客户端自    己根据少量且稳定的集群节点拓扑和确定的规则自己计算分片映射。    2.完善的故障域划分：支持层级的故障域控制，将同一分片的不同副本按照配置划分到不同层级的故障域中。    客户端或存储节点利用key、存储节点的拓扑结构和分配算法，独立进行分片位置的计算，得到一组负责对应分片及副本的存    储位置。如下图所示是一次定位的过程，最终选择了一个row下的cab21，cab23，cab24三个机柜下的三个存储节点;    当节点变化时，由于节点拓扑的变化，会影响少量分片数据进行迁移，如下图新节点加入是引起的数据迁移，通过良好的分    配算法，可以得到很好的负载均衡和稳定性，CRUSH提供了Uniform、List、Tree、Straw四种分配算法常见的存储系统大多采用类似于分片的数据分布和定位方式：    * Dynamo及Cassandra采用分片的方式并通过Gossip在对等节点间同；    * Redis Cluster将key space划分为slots，同样利用Gossip通信；    * Zeppelin将数据分片为Partition，通过Meta集群提供中心目录服务；    * Bigtable将数据切割为Tablet，类似于可变的分片，Tablet Server可以进行分片的切割，最终分片信息记录在Chubby中；    * Ceph采用CRUSH方式，由中心集群Monitor维护并提供集群拓扑的变化</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;分布式存储系统数据分布方法&quot;&gt;&lt;a href=&quot;#分布式存储系统数据分布方法&quot; class=&quot;headerlink&quot; title=&quot;分布式存储系统数据分布方法&quot;&gt;&lt;/a&gt;分布式存储系统数据分布方法&lt;/h3&gt;
    
    </summary>
    
      <category term="存储" scheme="https://www.liukui.tech/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="https://www.liukui.tech/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现四层和七层负载均衡</title>
    <link href="https://www.liukui.tech/2018/03/26/nginx%E5%AE%9E%E7%8E%B0%E5%9B%9B%E5%B1%82%E5%92%8C%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>https://www.liukui.tech/2018/03/26/nginx实现四层和七层负载均衡/</id>
    <published>2018-03-26T00:00:00.000Z</published>
    <updated>2019-03-28T08:19:28.860Z</updated>
    
    <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <div id="hbe-security"> <div class="input-container"> <input type="password" class="form-control" id="pass" placeholder=" 输入密码,PC:Enter查看,Phone:输入法换行查看. " /> <label for="pass"> 输入密码,PC:Enter查看,Phone:输入法换行查看. </label> <div class="bottom-line"></div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      &lt;font size=3 color=&quot;#FF0000&quot;&gt;私密文章，需要输入密码.&lt;/font&gt;&lt;/br&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
</feed>
