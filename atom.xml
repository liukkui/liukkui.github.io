<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coool&#39;s Blog</title>
  
  <subtitle>As we watch our love grow.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.liukui.tech/"/>
  <updated>2019-01-03T01:29:23.920Z</updated>
  <id>https://www.liukui.tech/</id>
  
  <author>
    <name>空腹吃早餐</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>httpd脚本</title>
    <link href="https://www.liukui.tech/2018/12/30/httpd%E8%84%9A%E6%9C%AC/"/>
    <id>https://www.liukui.tech/2018/12/30/httpd脚本/</id>
    <published>2018-12-30T11:28:24.082Z</published>
    <updated>2019-01-03T01:29:23.920Z</updated>
    
    <content type="html"><![CDATA[<p>httpd服务<br><a id="more"></a></p><h3 id="httpd服务脚本"><a href="#httpd服务脚本" class="headerlink" title="httpd服务脚本"></a>httpd服务脚本</h3><pre><code>#!/bin/bash## httpd        Startup script for the Apache HTTP Server## chkconfig: - 85 15# description: The Apache HTTP Server is an efficient and extensible  \#              server implementing the current HTTP standards.# processname: httpd# config: /etc/httpd/conf/httpd.conf# config: /etc/sysconfig/httpd# pidfile: /var/run/httpd/httpd.pid#### BEGIN INIT INFO# Provides: httpd# Required-Start: $local_fs $remote_fs $network $named# Required-Stop: $local_fs $remote_fs $network# Should-Start: distcache# Short-Description: start and stop Apache HTTP Server# Description: The Apache HTTP Server is an extensible server #  implementing the current HTTP standards.### END INIT INFO# Source function library.. /etc/rc.d/init.d/functionsif [ -f /etc/sysconfig/httpd ]; then        . /etc/sysconfig/httpdfi# Start httpd in the C locale by default.HTTPD_LANG=${HTTPD_LANG-&quot;C&quot;}# This will prevent initlog from swallowing up a pass-phrase prompt if# mod_ssl needs a pass-phrase from the user.INITLOG_ARGS=&quot;&quot;# Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server# with the thread-based &quot;worker&quot; MPM; BE WARNED that some modules may not# work correctly with a thread-based MPM; notably PHP will refuse to start.# Path to the apachectl script, server binary, and short-form for messages.apachectl=/usr/sbin/apachectlhttpd=${HTTPD-/usr/sbin/httpd}prog=httpdpidfile=${PIDFILE-/var/run/httpd/httpd.pid}lockfile=${LOCKFILE-/var/lock/subsys/httpd}RETVAL=0STOP_TIMEOUT=${STOP_TIMEOUT-10}# The semantics of these two functions differ from the way apachectl does# things -- attempting to start while running is a failure, and shutdown# when not running is also a failure.  So we just do it the way init scripts# are expected to behave here.start() {        echo -n $&quot;Starting $prog: &quot;        LANG=$HTTPD_LANG daemon --pidfile=${pidfile} $httpd $OPTIONS        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; touch ${lockfile}        return $RETVAL}# When stopping httpd, a delay (of default 10 second) is required# before SIGKILLing the httpd parent; this gives enough time for the# httpd parent to SIGKILL any errant children.stop() {        status -p ${pidfile} $httpd &gt; /dev/null        if [[ $? = 0 ]]; then                echo -n $&quot;Stopping $prog: &quot;                killproc -p ${pidfile} -d ${STOP_TIMEOUT} $httpd        else                echo -n $&quot;Stopping $prog: &quot;                success        fi        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; rm -f ${lockfile} ${pidfile}}reload() {    echo -n $&quot;Reloading $prog: &quot;    if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then        RETVAL=6        echo $&quot;not reloading due to configuration syntax error&quot;        failure $&quot;not reloading $httpd due to configuration syntax error&quot;    else        # Force LSB behaviour from killproc        LSB=1 killproc -p ${pidfile} $httpd -HUP        RETVAL=$?        fi    fi    echo}# See how we were called.case &quot;$1&quot; in  start)        start        ;;  stop)        stop        ;;  status)        status -p ${pidfile} $httpd        RETVAL=$?        ;;  restart)        stop        start        ;;  condrestart|try-restart)        if status -p ${pidfile} $httpd &gt;&amp;/dev/null; then                stop                start        fi        ;;  force-reload|reload)        reload        ;;  graceful|help|configtest|fullstatus)        $apachectl $@        RETVAL=$?        ;;  *)        echo $&quot;Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|reload|status|fullstatus|graceful|help|configtest}&quot;        RETVAL=2esacexit $RETVAL  </code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;httpd服务&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>HTTP协议</title>
    <link href="https://www.liukui.tech/2018/12/18/HTTP%E5%8D%8F%E8%AE%AE/"/>
    <id>https://www.liukui.tech/2018/12/18/HTTP协议/</id>
    <published>2018-12-18T00:00:00.000Z</published>
    <updated>2018-12-31T08:08:23.394Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HTTP协议和APACHE原理"><a href="#HTTP协议和APACHE原理" class="headerlink" title="HTTP协议和APACHE原理"></a>HTTP协议和APACHE原理</h3><p>Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等<br>本文说的是HTTP SERVER<a href="http://www.apache.org/" target="_blank" rel="noopener">apache</a><br><a id="more"></a><br>HTTP2.4的官方文档<a href="http://httpd.apache.org/docs/2.4/" target="_blank" rel="noopener">http2.4文档：安装，模块，指令等说明</a><br>HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a><br><!--more--></p><h3 id="http协议-应用层协议-主流http-1-1版本"><a href="#http协议-应用层协议-主流http-1-1版本" class="headerlink" title="http协议:应用层协议,主流http/1.1版本"></a>http协议:应用层协议,主流http/1.1版本</h3><h4 id="http协议的版本区别"><a href="#http协议的版本区别" class="headerlink" title="http协议的版本区别"></a>http协议的版本区别</h4><p>http0.9、http1.0、http1.1和http2.0的版本区别</p><ul><li><p>http/0.9:</p><blockquote><p>只有一个GET命令，且只能回应<em>.html文件格式，像</em>.txt等都不支持</p></blockquote></li><li><p>http/1.0:效率太低</p><blockquote><p>1.支持cache, MIME(支持各种资源类型), method<br>2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低<br>3.引入了POST命令和HEAD命令，头部信息和<br>4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用</p></blockquote></li><li><p>http/1.1:主流使用版本</p><blockquote><p>1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭，<br>  对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性</p><pre><code>这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求</code></pre><p>2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率<br>3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)<br>4.缺点：<br>  同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象<br>5.解决队头堵塞的办法：<br>  为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等<br>6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度:</p><pre><code>不带状态怎么理解？http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点</code></pre></blockquote></li><li><p>http/2.0：解决 HTTP/1.1效率不高的问题</p><blockquote><p>1.头信息和数据体都是二进制，称为头信息帧和数据帧<br>2.和http1.1区别：请求不需要排队，提高效率<br>  复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）<br>3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度<br>4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息)</p></blockquote></li></ul><h3 id="HTTP工作机制"><a href="#HTTP工作机制" class="headerlink" title="HTTP工作机制"></a>HTTP工作机制</h3><ul><li>工作机制主要分为两步：请求和响应<blockquote><p>http请求：http request<br>http响应：http response<br>一次http事务：请求<-->响应</--></p></blockquote></li><li>Web资源：web resource<br>一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资<br>源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源<br>的集合<blockquote><p>静态页面/文件：无需服务端做出额外处理;</p><pre><code>服务器端是什么样传到客户端就是什么样，比如下面这些比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi只不过浏览器有时会解析出来以好看的页面展示给用户</code></pre><p>动态页面/文件：服务端执行程序，返回执行的结果</p><pre><code>服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果文件后缀：.php, .jsp ,.asp,.sh等将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户</code></pre></blockquote></li><li><p>提高HTTP连接性能</p><blockquote><p>并行连接：通过开多个TCP连接发起并发的HTTP请求<br>持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，<br>管道化连接：通过共享TCP连接发起并发的HTTP请求<br>复用的连接：交替传送请求和响应报文（实验阶段）</p></blockquote></li><li><p>HTTP协议的其他相关技术</p></li><li><p>1.URI：一般把URI认为是URL<br>URI: Uniform Resource Identifier 统一资源标识，分为URL和URN</p><blockquote><p>1.URN: Uniform Resource Naming，统一资源命名</p><pre><code>如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名</code></pre><p>2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置</p><pre><code>如输入一个网址，能具体体现出这个资源在互联网上的位置</code></pre><p>两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址</p></blockquote></li><li><p>URL的组成<br>scheme://user:password@host:port/path;params?query#frag</p><blockquote><p>scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等<br>user:用户，某些方案访问资源时需要的用户名<br>password:密码，用户对应的密码，中间用：分隔<br>Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析<br>port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080<br>/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔<br>params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对<br>query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能<br>frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔</p></blockquote></li><li><p>网站访问量</p><blockquote><p>1.IP(独立IP)：即Internet Protocol,指独立IP数。</p><pre><code>如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个</code></pre><p>2.PV(访问量)： 即Page View, </p><pre><code>页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量一般为了博客为了好看的访问量，都是统计PV量</code></pre><p>3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。</p><pre><code>网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1</code></pre></blockquote></li></ul><h3 id="Web服务请求处理步骤"><a href="#Web服务请求处理步骤" class="headerlink" title="Web服务请求处理步骤"></a>Web服务请求处理步骤</h3><p>很切合实际生活：比如<br>当我们打开一个浏览器，输入一个<a href="http://www.taobao.com，在互联网后台发生了什么？" target="_blank" rel="noopener">www.taobao.com，在互联网后台发生了什么？</a><br>这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图<br><img src="/2018/12/18/HTTP协议/web服务请求处理步骤.png" alt="web请求步骤"></p><p>当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程<br>每个过程都是一段需要原理详细描述的.</p><h4 id="一次完整的http请求处理过程"><a href="#一次完整的http请求处理过程" class="headerlink" title="一次完整的http请求处理过程"></a>一次完整的http请求处理过程</h4><pre><code>1.建立连接：接收或拒绝连接请求2.接收请求：接收客户端请求报文中对某资源的一次请求的过程Web访问响应模型（Web I/O）    单进程I/O模型：访问量不大        启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应        会造成请求排队现象，只适用于访问并发不大的情况    多进程I/O模型：        系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求        如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点        而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的    复用I/O结构：        开启多个进程进程，而一个进程又同时监控N个连接请求        只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗        实现方法：多线程模型和事件驱动        多线程模型：一个进程生成N个线程，每线程响应一个连接请求        事件驱动：一个进程处理N个请求    复用的多进程I/O模型：        启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求        充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的        nginx使用的复用多进程I/O模型</code></pre><font size="3" color="#FF0000"><br>    1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程<br>    2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应<br>    避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费<br>    同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题<br></font><p><img src="/2018/12/18/HTTP协议/web访问响应的四种模型.png" alt="web访问响应四种模型"><br>参考下面的HTTP的MPM三种工作模式<a href=""></a></p><pre><code>3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理    分析元数据：请求报文首部信息获得method    &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt;    HEADERS 格式 name:value    &lt;request body&gt;    通过method来响应用户请求，比如下载(get)，上传等信息    HTTP常用请求方式，Method        GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS4.访问资源：    服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源    在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件    web服务器资源路径映射方式：        (a) docroot        (b) alias        (c) 虚拟主机docroot        (d) 用户家目录docroot5.构建响应报文：    一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体   1）响应实体        描述了响应主体MIME类型的Content-Type首部        描述了响应主体长度的Content-Length   2）URL重定向        web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径   3）MIME类型   当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文    将构建完的响应报文发送给用户    将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户    用户再层层解封装获得index.html的内容7.记录日志    最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务    通过在/var/log/httpd/acess_log日志中记录http的响应记录数    方便分析日志统计该网站的IP，PV量等信息</code></pre><h3 id="Http协议"><a href="#Http协议" class="headerlink" title="Http协议"></a>Http协议</h3><pre><code>http协议    http/0.9, http/1.0, http/1.1, http/2.0http协议：stateless 无状态    服务器无法持续追踪访问者来源解决http协议无状态方法    cookie 客户端存放    session 服务端存放http事务：一次访问的过程    请求：request    响应：response</code></pre><h3 id="Session和Cookie的区别"><a href="#Session和Cookie的区别" class="headerlink" title="Session和Cookie的区别"></a>Session和Cookie的区别</h3><pre><code>前言:    HTTP是一种无状态的协议，为了分辨链接是谁发起的，就需要我们自己去解决这个问题。    不然有些情况下即使是同一个网站我们每打开一个页面也都要登录一下。而Session和    Cookie就是为解决这个问题而提出来的两个机制。应用场景:    1.日常登录一个网站，今天输入用户名密码登录了，第二天再打开很多情况下就直接打开      了。这个时候用到的一个机制就是cookie。    2.session的一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而      服务器端如何判别呢，所以也需要存储一些信息，这里就用到了session。Cookie的原理：    HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。    也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。    这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设    计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行    保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在    请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服    务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端    保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报    文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，    会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，    最后得到之前的状态信息。    通俗讲，Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时    候减少一些步骤。另外一个更准确的说法是：Cookies是服务器在本地机器上存储的小段文    本并随每一个请求发送至同一个服务器，是一种在客户端保持状态的方案。session的原理：    session就是一种保存上下文信息的机制，她是针对每一个用户的，session的内容在服    务器端，通过sessionId来区分不同的客户，session是以cookie或url重写为基础的，    默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie，我们成为session     cookie，以区分persistent coookies，注意session cookie是存储于浏览器内存中的    ，并不是写到硬盘上的；我们通常是看不见JSESSIONID的，但是当我们禁用浏览器的    cookie后，web服务器会采用url重写的方式传递sessionid，我们就可以在浏览器看到    sessionid=HJHADKSFHKAJSHFJ之类的字符串；session cookie针对某一次会话而言，会话结束session cookie也就消失了　session与cookie的区别：　　1.session保存在服务器，客户端不知道其中的信息；cookie保存在客户端，服务端可以        知道其中的信息　　2.session中保存的是对象，cookie中保存的是字符串　　3.session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个    地方都可以访问到；而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不道德session与cookie的联系：　　session是需要借助cookie才能正常工作的，如果客户端完全禁止cookie，session将失    效</code></pre><h3 id="Http应用层的报文头部-又分请求报文和响应报文两种"><a href="#Http应用层的报文头部-又分请求报文和响应报文两种" class="headerlink" title="Http应用层的报文头部:又分请求报文和响应报文两种"></a>Http应用层的报文头部:又分请求报文和响应报文两种</h3><p><img src="HTTP协议/http请求报文头部.png" alt="HTTP请求报文头部"></p><pre><code>开始行    方法：method        GET： 从服务器获取一个资源        HEAD： 只从服务器获取文档的响应首部        POST： 向服务器输入数据，通常会再由网关程序继续处理        PUT： 将请求的主体部分存储在服务器中，如上传文件        DELETE： 请求删除服务器上指定的文档        TRACE： 追踪请求到达服务器中间经过的代理服务器        OPTIONS：请求服务器返回对指定资源支持使用的请求方法    URL:路径首部行实体行</code></pre><p><img src="HTTP协议/http响应报文头部.png" alt="HTTP响应报文头部"></p><pre><code>开始行    版本：version        HTTP/&lt;major&gt;.&lt;minor&gt;1.1/2等等    状态码：        三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况    短语：        状态码所标记的状态的简要描述首部行实体行</code></pre><h3 id="Http常见的状态码和状态码分类"><a href="#Http常见的状态码和状态码分类" class="headerlink" title="Http常见的状态码和状态码分类"></a>Http常见的状态码和状态码分类</h3><pre><code>status(状态码)：    1xx：100-101 信息提示    2xx：200-206 成功    3xx：300-305 重定向    4xx：400-415 错误类信息，客户端错误    5xx：500-505 错误类信息，服务器端错误200： 成功，请求数据通过响应报文的entity-body部分发送;OK301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资      源现在所处的新位置；Moved Permanently302： 响应报文Location指明资源临时新位置 Moved Temporarily304： 如果之前访问一个网站，在本机上有缓存了，当再次访问时，就会出现304的状态码，      提示本地有不需要再去服务器上下载页面401： 需要输入账号和密码认证方能访问资源；Unauthorized403： 没有权限访问，请求被禁止了；Forbidden404： 服务器无法找到客户端请求的资源；要访问的文件不存在500： 服务器内部错误；Internal Server Error502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；Bad Gateway503： 服务不可用，临时服务器维护或过载，服务器无法处理请求      可能是服务器down机了，或者http服务关闭了504： 网关超时；转给后端服务器时，时间太长</code></pre><h3 id="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"><a href="#curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因" class="headerlink" title="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"></a>curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因</h3><pre><code>curl是基于URL语法在命令行方式下工作的文件传输工具1.它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。2.curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器，cookies，用户名/密码认证,下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling）3.还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等4.curl的强大在于能模拟各种浏览器自定义请求报文头部等信息，来访问某些控制严格的网站curl [options] [URL...]    -A/--user-agent &lt;string&gt; 冒充浏览器类型，实际上在请求报文修改了User-Agent        curl -A &apos;IE20&apos; http://192.168.34.103在http日志中可看到        一般用于测试访问网站或者爬虫功能要使用不同浏览器访问    -e/--referer &lt;URL&gt; 来源网址，防盗链相关        比如，伪装从百度跳转的192.168.34.103        curl -e &apos;www.baidu.com&apos; http://192.168.34.103    --cacert &lt;file&gt; CA证书 (SSL)    -k/--insecure 允许忽略证书进行 SSL 连接    --compressed 要求返回是压缩的格式    -H/--header &lt;line&gt;自定义首部信息访问网站    -i 显示页面内容，包括报文首部信息    -I/--head 只显示响应报文首部信息    -D/--dump-header &lt;file&gt; 将url的header信息存放在指定文件中，重定向    --basic 使用HTTP基本认证，401认证    -u/--user &lt;user[:password]&gt;设置服务器的用户和密码    -L 如果有3xx响应码，重新发请求到新位置        如果访问的网页被重定向到其他地方时，系统只会提示网页被重定向了，并不会跳转        -L就可以请求到新的页面上    -O 使用URL中默认的文件名保存文件到本地    -o &lt;file&gt; 将网络文件保存为指定的文件中    --limit-rate &lt;rate&gt; 设置传输速度    -0/--http1.0 数字0，使用HTTP 1.0    -v/--verbose 更详细    -C 选项可对文件使用断点续传功能    -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中    -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址    -X/--request &lt;command&gt; 向服务器发送指定请求方法    -U/--proxy-user &lt;user:password&gt; 代理服务器用户和密码    -T 选项可将指定的本地文件上传到FTP服务器上    --data/-d 方式指定使用POST方式传递数据    -b name=data 从服务器响应set-cookie得到值，返回给服务器elinks工具：    字符界面的浏览器，显示页面内容和源码等    elinks [OPTION]... [URL]...    -dump: 非交互式模式，将URL的内容输出至标准输出        比如有些网站是不允许复制的，通过-dump就可以把网站页面文字抓取到本地了        elinks -dump www.baidu.com        不过一般都是用js脚本限制了复制功能，在浏览器关闭js，或查看源码都可以    -source:打印源码</code></pre><h3 id="HTTP介绍"><a href="#HTTP介绍" class="headerlink" title="HTTP介绍"></a>HTTP介绍</h3><p>特性：<br>高度模块化：core + modules<br>DSO: Dynamic Shared Object 动态加/卸载<br>MPM：multi-processing module多路处理模块</p><h3 id="HTTP的三种工作模型：MPM工作模式"><a href="#HTTP的三种工作模型：MPM工作模式" class="headerlink" title="HTTP的三种工作模型：MPM工作模式"></a>HTTP的三种工作模型：MPM工作模式</h3><font size="3" color="#FF0000"><br>多用途的处理模块，三种模型分别是，默认使用prefork模型<br>因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型<br></font><ul><li>1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型<br>  一个主进程：生成和回收n个子进程，创建套接字，不响应请求<br>  多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个，消耗比较大内存资源</li><li>2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型<br>  一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性<br>  缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！</li><li>3.event：事件驱动模型（worker模型的优化,worker模型的变种）<br>  event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用<br>  一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n<br>  相比较worker的有点：<br>  有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力</li></ul><h3 id="进程工作的角色切换"><a href="#进程工作的角色切换" class="headerlink" title="进程工作的角色切换"></a>进程工作的角色切换</h3><p><img src="/2018/12/18/HTTP协议/进程角色切换原理.png" alt="进程间的角色切换"></p><h3 id="Httpd的功能特性"><a href="#Httpd的功能特性" class="headerlink" title="Httpd的功能特性"></a>Httpd的功能特性</h3><p>httpd的常见特性：</p><ul><li>虚拟主机：在一个物理服务器上搭建多个网站<br>  IP、Port、FQDN</li><li>CGI：Common Gateway Interface，通用网关接口<br>  通过CGI接口处理动态的程序处理</li><li>反向代理<br>  当有用户访问量大时，在前端有一个服务器充当调度器的角色<br>  通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息<br>  看不到后端真正提供服务的服务器群</li><li>负载均衡</li><li>路径别名</li><li>丰富的用户认证机制<br>  basic<br>  digest</li><li>支持第三方模块</li></ul><h3 id="Httpd2-4新特性和安装以及配置"><a href="#Httpd2-4新特性和安装以及配置" class="headerlink" title="Httpd2.4新特性和安装以及配置"></a>Httpd2.4新特性和安装以及配置</h3><pre><code>新特性    MPM支持运行为DSO机制；以模块形式按需加载        在centos7上的httpd2.4上只有一个二进制程序            /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可        但是在centos6上的httpd2.2版本：            每个MPM模式都有各自对应的二进制程序                /usr/sbin/httpd                /usr/sbin/httpd.event                /usr/sbin/httpd.worker            如果更改MPM的模式，是需要改对应的二进制程序的    event MPM生产环境可用    异步读写机制    支持每模块及每目录的单独日志级别定义    每请求相关的专用配置    增强版的表达式分析式    毫秒级持久连接时长定义：httpd2.2只能精确到秒级别        上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的        所以在http中是可以定义连接时长(时长和传输请求两种方式)的    基于FQDN的虚拟主机不需要NameVirutalHost指令        httpd2.2创建虚拟主机时还需要NameVirutalHost指令        httpd2.4就不需要了    新指令，AllowOverrideList    支持用户自定义变量    更低的内存消耗</code></pre><h3 id="Httpd2-4的具体安装和配置"><a href="#Httpd2-4的具体安装和配置" class="headerlink" title="Httpd2.4的具体安装和配置"></a>Httpd2.4的具体安装和配置</h3><p>Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了<br>还支持第三方的模块，按需加载模块<br>存放模块的路径：/etc/httpd/modules</p><pre><code>CentOS7程序环境安装：httpd-2.4    yum install httpd     yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档主要配置文件：    /usr/sbin/httpd     httpd的主程序文件    /usr/lib/systemd/system/httpd.service   httpd的启动单元文件    /etc/httpd/conf/httpd.conf              主要配置文件        配置文件里的路径都是以/etc/httpd/为参考点的    /etc/httpd/conf.d/*.conf    /etc/httpd/conf.modules.d/00-mpm.conf    mpm相关    /etc/httpd/conf.modules.d/00-proxy.conf  配置代理相关    /etc/httpd/conf.modules.d/00-systemd.conf     /etc/httpd/conf.modules.d/01-cgi.conf    CGI相关    /var/cache/httpd    httpd的缓存目录    /var/log/httpd      httpd的日志文件目录            access_log: 访问日志            error_log：错误日志    /etc/httpd/modules  httpd的模块存放路径，软件比较复杂    /usr/lib64/httpd/modules   也是httpd的模块存放路径        两个模块的路径实际上是软链接关系    /var/www/html       httpd存放网页的目录：默认index.html帮助文档包：在没有网络时查看帮助文档，建议安装    httpd-manual检查配置文件语法：    httpd –t    类似DNS的rndc语法检查功能    sudo：visudo功能    ansible:ansible -C|--check 执行前检查语法功能    cobbler 也有httpd的控制和启动命令    systemctl enable|disable httpd.service    systemctl {start|stop|restart|status|reload} httpd.service    备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作        有时reload是无效的，只能restart服务</code></pre><h3 id="Httpd2-4的常见配置"><a href="#Httpd2-4的常见配置" class="headerlink" title="Httpd2.4的常见配置"></a>Httpd2.4的常见配置</h3><ul><li><p>1.显示服务器版本信息HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a></p><p>  主要组成:</p><pre><code>Global Environment   全局配置Main server configuration   一个服务器上搭建一个网站叫主服务器virtual host   虚拟主机，一台主机上搭建多个网站</code></pre></li></ul><p>练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)<br>egrep -v ‘^ <em>#.</em>|^$’ /etc/httpd/conf/httpd.conf</p><font size="3" color="#FF0000"><br>常见配置一般都在/etc/httpd/conf/httpd.conf的文件中<br>没有的配置选项可以加在httpd.conf文件最后，也可以放在<br>/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf<br>下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加<br></font><ul><li>1.显示服务器版本信息<br>  访问<a href="http://192.168.34.103" target="_blank" rel="noopener">http://192.168.34.103</a><br>  打开f12调试模式，可以看到回应头的信息中带有apache的版本信息<br>  也可以通过curl -I <a href="http://192.168.34.103来显示头信息" target="_blank" rel="noopener">http://192.168.34.103来显示头信息</a><br>  可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全<br>  查看指令参考文档：修改ServerTokens选项<pre><code>建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全</code></pre></li><li><p>2.修改监听的IP和Port<br>  Listen [IP:]PORT<br>  (1) 省略IP表示为本机所有IP<br>  (2) Listen监听端口至少一个，可以有多个端口<br>  (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口</p><pre><code>test.conf添加listen端口：listen 172.18.132.151:6666 6666端口只能通过此IP才能访问</code></pre></li><li><p>3.持久连接：默认KeepAlive是开启的<br>  Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接<br>  断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级<br>  副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞<br>  折衷：使用较短的持久连接时间</p><pre><code>设置：    KeepAlive On|Off       设置持久连接开启或者关闭    KeepAliveTimeout 15    设置持久连接为15s测试：telnet WEB_SERVER_IP PORT    GET /index.html HTTP/1.1    Host: WEB_SERVER_IP  host可以随便填写，但是在虚拟主机中是有区别的</code></pre></li><li><p>4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event<br>  默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf  修改mpm的文件<br>  建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的<br>  查看静态编译的模块<br>  httpd -l<br>  查看当前系统中httpd的静态编译及动态装载的加载的模块<br>  httpd –M<br>  动态模块加载：不需重启即生效<br>  动态模块路径<br>   /usr/lib64/httpd/modules/</p><pre><code>切换使用的MPM模块    在/etc/httpd/conf.modules.d/00-mpm.conf中    选择要启用的MPM相关的LoadModule指令即可prefork的配置：    StartServers 8               MinSpareServers 5       保留5个空闲子进程处理新的请求    MaxSpareServers 20      允许的最大空闲进程数    ServerLimit 256         最多进程数,最大20000，并发量建议最多10000         MaxRequestsPerChild     4000 子进程最多能处理的请求数量。在处理    MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进    程占用的内存就会释放(为0时永远不释放）worker和prefork配置类似，只不过会有线程数量的限制</code></pre><p>从下面ps auxf的进程图可以看书httpd是使用的prefork模型，而且因为端口是80，开启需要特殊<br>权限，所以父进程是root,子进程是apache</p></li></ul><p><img src="/2018/12/18/HTTP协议/HTTPD的prefork模型.png" alt=""></p><ul><li><p>5.DSO： Dynamic Shared Object<br>  加载动态模块配置<br>  /etc/httpd/conf/httpd.conf<br>  Include conf.modules.d/*.conf<br>  配置指定实现模块加载格式：<br>  LoadModule &lt;mod_name&gt; &lt;mod_path&gt;<br>  模块文件路径可使用相对路径：<br>  相对于ServerRoot（默认/etc/httpd）</p></li><li><p>6.定义’Main’ server的文档页面路径：存放页面的主目录<br>  主目录是由DocumentRoot指令来设置的<br>  网页文件默认是存在/var/www/html/下的，此处可以自定义<br>  在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html”</p><pre><code>如果要自定义主目录，还需要设置该目录为允许访问在httpd2.2上是不需要设置权限访问的但是在httpd2.4上是需要设置该目录允许访问的修改格式如下：#DocumentRoot &quot;/var/www/html&quot;DocumentRoot &quot;/data/www&quot;&lt;directory /data/www&gt;    Require all granted&lt;/directory&gt; </code></pre></li><li><p>7.定义站点默认主页面<br>  访问192.168.34.103默认显示的是index.html的内容，<br>  这一项是由DirectoryIndex指令设置的</p><pre><code>在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件</code></pre><font color="#FF0000"><br>此处需要了解httpd的权限和访问报错的相关问题和默认主页面：<br>1.访问192.168.34.103跳出的页面默认是index.html页面，如果不存在，则去找conf.d/welcome.conf文件，即报错提示，如果两个都不存在，显示的是/var/www/html目录下的文件列表，因为在httpd.conf配置文件中，定义options indexes选项<br>2.默认页面和默认访问目录都是可以通过指令来指定的<br>3.如果没有index.html文件，没有welcome.conf文件，没有options indexes配置，访问时会报错You don’t have permission to access / on this server.的提示.<br>4.上面三条在下面第12条配置别名时，可以体现的很明显<br>5.所以如果自定义目录和用别名，有时是需要设置目录访问权限、设置目录对应的index.html文件或者跳转的html文件(如果该文件存在就不需要设置了)，设置options indexes选项<br></font></li><li><p>8.站点访问控制常见机制<br>  可基于两种机制指明对哪些资源进行何种访问控制<br>  访问控制机制有两种：1.客户端来源地址，2.用户账号<br>  而文件系统路径：可以是<br>  1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配<br>  示例：<br>  ‘<filesmatch "\.(gif|jpe?g|png)$"="">‘’   用的是扩展的正则表达式<br>  <files “?at.*”="">                     通配符<br>  &lt;Location /status&gt;</files></filesmatch></p>  <locationmatch "="" (extra|special)="" data"=""></locationmatch></li><li><p>9.<directory>中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制<br>   (1) Options：后跟1个或多个以空白字符分隔的选项列<br>  在选项前的+，- 表示增加或删除指定选项<br>  常见选项：<br>  Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制<br>  适用于下载网站和镜像网站，不适合电商网站<br>  FollowSymLinks：允许访问符号链接文件所指向的源文件,<br>  None：全部禁用<br>  All： 全部允许</directory></p><pre><code>Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站    &lt;directory &quot;/data/www&quot;&gt;    options Indexes                                              Require all granted    &lt;/directory&gt;FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件    &lt;directory &quot;/data/www&quot;&gt;    options Indexes  FollowSymLinks           Require all granted    &lt;/directory&gt;</code></pre><font size="4" color="#FF0000"><br>实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.conf文件，welcome.conf文件就是页面上经常看到的测试123页面，把welcome.conf文件改名或删除，就会显示主目录下的所有列表文件了.<br></font><p>  (2) AllowOverride<br>  allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可<br>  只对<directory>语句有效;<br>  allowoverride权限时卸载httpd的*.conf配置文件中的<br>  AllowOverride All: .htaccess中所有指令都有效<br>  AllowOverride None： .htaccess 文件无效<br>  AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它</directory></p><pre><code>配置allowoverride示例：/etc/httpd/conf.d/test.conf中添加访问控制的目录    &lt;directory /data/www&gt;    allowoverride all  --&gt;这条必须写，代表.htaccess文件中的options生效    Require all granted    &lt;/directory&gt;在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中    options indexes FollowSymLinks</code></pre><p>  (3) 基于IP的访问控制:<br>  无明确授权的目录，默认拒绝<br>  允许所有主机访问：Require all granted<br>  拒绝所有主机访问：Require all denied<br>  控制特定的IP访问：<br>  Require ip IPADDR：授权指定来源的IP访问<br>  Require not ip IPADDR：拒绝特定的IP访问<br>  控制特定的主机访问：<br>  Require host HOSTNAME：授权特定主机访问<br>  Require not host HOSTNAME：拒绝<br>  HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机</p><pre><code>基于IP的访问控制示例：如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表除了/data/www/ceshi文件夹    &lt;directory /data/www&gt;    options indexes                                                      &lt;RequireAll&gt;    Require all granted    Require not ip 192.168.34.107    &lt;/RequireAll&gt;    &lt;/directory&gt;2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问&lt;directory /data/www&gt;options indexesRequire all granted&lt;/directory&gt;&lt;directory /data/www/ceshi&gt;&lt;RequireAny&gt;Require all deniedRequire ip 192.168.34.107&lt;/RequireAny&gt;                                                 &lt;/directory&gt;</code></pre></li><li><p>10.日志设定：日志默认/var/log/httpd/下<br><a href="http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats" target="_blank" rel="noopener">format官方说明文档</a><br>  日志类型：访问日志(access_log)和错误日志(error_log)<br>  日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式</p><pre><code>在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined   --&gt;由Logformat指令定义完起一个combined名CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式ErrorLog &quot;logs/error_log&quot;</code></pre><p>  可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径</p><pre><code>日志中的格式各个项说明%h 客户端IP地址%l 远程用户,启用mod_ident才有效，通常为减号“-”%u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-”%t 服务器收到请求时的时间%r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本%&gt;s 响应状态码%b 响应报文的大小，单位是字节；不包括响应报文http首部%{Referer}i     请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页    是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源，所以网站一般要加防盗链，防止资源被盗和占用服务器资源%{User-Agent}i 指客户端的浏览器版本</code></pre></li><li><p>11.设定默认字符集<br>  一般不需要设置：基本上使用的是utf-8;<br>  AddDefaultCharset UTF-8 此为默认值</p><pre><code>如果需要修改字符集，在test.conf或者httpd.conf下添加AddDefaultCharset gb2312 即可</code></pre></li><li><p>12.定义路径别名<br>作用：默认访问的文件夹是设置的DocumentRoot文件夹，如果不是在默认文件夹下，而需求要实现把其他路径下的目录共享出来，这就用到了定义路径别名的功能</p><p>  把一个URL起一个别名不指向真正的目录<br>  在httpd2.4里目录如果没有开启允许时，默认是不允许访问的</p><pre><code>例如：访问 /var/www/html/111,111这个目录可有可无，只是充当别名    实际上访问的是/data/www/ceshi目录         directoryindex ceshi.html        alias /111 /data/www/ceshi        &lt;directory /data/www/ceshi&gt;        options indexes        Require all granted        &lt;/directory&gt;         </code></pre></li></ul><font color="#FF0000"><br>注意：<br>1.111只是一个别名，在/var/www/html下不需要创建；但是如果/var/www/html下有111的文件夹，如果设置别名后，则访问的是/data/www/ceshi目录，原目录下的111文件夹就失效了。<br>2.在这里和上文第7条设置权限时有联系的，httpd2.4设置路径别名的时候，真正的路径也是需要在test.conf下设置权限的(/data/www/ceshi目录)<br>3.如果/data/www/ceshi/下没有index.html会报权限不允许的错误，所以要设置默认主页面directoryindex，当然可以设置options indexes选项<br></font><ul><li><p>13.基于虚拟账户的登录访问控制：提示401状态码<br>  认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码<br>  认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源<br>  两种认证方式：<br>  basic：用的多，缺点是明文，后面可以用https进行加密<br>  digest：兼容性差，用的少<br>  用户的账号和密码:非linux用户密码<br>  虚拟账号：多种存储方式，只用于httpd服务的，类似vsftp，samba服务的虚拟用户<br>  存储：账号可放在文本文件，SQL数据库，ldap目录存储，nis等</p><pre><code>因为basic使用的多，下文以basic认证配置示例1.提供账号和密码存储（文本文件），如创建一个tom虚拟账户管理httpd    htpasswd --&gt;可以指定加密算法        -c 自动创建文件，仅应该在文件不存在时使用        -p 明文密码        -d CRYPT格式加密，默认        -m md5格式加密        -s sha格式加密        -D 删除指定用户    htpasswd -c httpdpass tom :设定密码即可;目录可指定，后面改配置文件即可    htpasswd -s httpdpass jerry 再添加jerry用户，就不需要-c选项了    htpasswd -D httpdpass jerry 从文件中删除jerry用户    修改httpdpass权限，加固安全 chmod 600 httpdpass     或者也可以创建组文件httpdgroup，通过组来管理,组文件组和成员列表    testgroup: tom jerry2. 在test.conf或者httpd.conf下定义安全域    &lt;directory /var/www/html/ksdir&gt;    AuthType Basic          ---&gt;使用的认证方式    AuthName &quot;Login&quot;        ----&gt;登录提示信息    AuthUserFile &quot;/etc/httpd/conf/httpdpass&quot;  --&gt;加密账户文件    AuthGroupFile &quot;/etc/httpd/conf/httpdgroup&quot; --&gt;组账户    Require user tom        ---&gt;允许用户访问的列表    Require group testgroup  ---&gt;允许访问的组    &lt;/directory&gt;    但是：因为httpd线程是以apache运行的，而httpdpass是600权限，所以默认tom登录是没有权限的，让apache对httpdpass有读权限：    setfacl -m u:apache:r httpdpass 即可</code></pre></li><li><p>14.实现用户家目录的http共享;并实现账户机密访问<br>  实现基础：基于模块mod_userdir.so实现<br>  httpd -M |grep user 可以看出user加密的模块是已经加载的，直接改配置文件即可<br>  在/etc/httpd/conf.d/userdir.conf文件中定义了家目录共享的格式，只需要启用就行了</p><pre><code>实现步骤：1. vim /etc/httpd/conf.d/userdir.conf    &lt;IfModule mod_userdir.c&gt;     UserDir enabled      ---&gt;启用即可；默认不启用    UserDir public_html  ---&gt;创建一个public_html文件    &lt;/IfModule&gt;2.在test家目录下，创建public_html文件夹和public_html文件    su test    mkdir public_html/    echo 23333 &gt; /public_html/public_html3.因为httpd线程是apache身份登录的，所以要允许apache访问test用户的家目录    setfacl -m u:apache:x /home/test4.设置test家目录访问权限及用户加密    &lt;directory /home/test/public_html&gt;        authtype basic    authname &quot;test home&quot;    authuserfile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;调用之前创建的虚拟账户文件即可    Require user haha    &lt;/directory&gt;5.http访问test家目录方式,即可用加密账户登录    192.168.34.103/~test</code></pre></li><li><p>15.ServerSignature On|Off|EMail<br>  作用：当用户访问的页面不存在的情况下服务器会产生错误文档，而当ServerSignature选项是打开的情况下，错误文档会将服务器的名字，apahce的版本信息，显示在页面上，某种程度上会对web服务器产生不安全因素，所以一般建议关闭</p><pre><code>在配置文件添加一行：ServerSignature off 即可</code></pre></li><li><p>16.status页面<br>  作用：显示apache的工作状态，有助于判断apache是否正常工作<br>  status页面功能是由下面这个模块实现的：httpd<br>  LoadModule status_module modules/mod_status.so</p><pre><code>实现步骤：在配置文件添加&lt;Location &quot;/status&quot;&gt; SetHandler server-status&lt;/Location&gt;ExtendedStatus ON   #显示扩展信息</code></pre><p>  记录的信息包括：启动时间，线程数，等待连接数，cpu，进程，MPM等信息<br>  在实际生产中，由于apache服务器很多，就可以通过curl 192.168.34.103/status来抓取页面，分析apache某个指标是不是正常的；</p><pre><code>比如编写简单一个脚本：    curl 192.168.34.103/status |grep &quot;Apache Status&quot; || systemctl start httpd</code></pre></li><li><p><font size="5" color="#FF0000">17.实现http的虚拟主机</font><br>  作用：一个物理服务器上实现多台虚拟主机，至于为什么会用到虚拟主机，有可能是因为要上线的同一网站的有多个域名，却只有一个公网IP地址，也有可能是主机不多啊..，所以虚拟主机的价值就体现出来了…</p><p>  实现虚拟主机有三种方式</p><pre><code>基于ip：为每个虚拟主机准备至少一个ip地址，一个主机可以配多个内网IP地址基于port：为每个虚拟主机使用至少一个独立的port；80,8081,8082等等基于FQDN：为每个虚拟主机使用至少一个FQDN</code></pre><p>  当然这三种方式，基于IP和port的对于用户来说不太现实，一般都是通过输入域名方式来实现虚拟主机搭建.</p><pre><code>1.基于IP的虚拟主机搭建：但是这种方式用的比较少先准备三个网站目录，和在本机上添加三个IP地址    &lt;virtualhost 192.168.34.103&gt;    DocumentRoot &quot;/data/asite&quot;    &lt;directory /data/asite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_a.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.200&gt;    DocumentRoot &quot;/data/bsite&quot;    &lt;directory /data/bsite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_b.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.210&gt;    DocumentRoot &quot;/data/csite&quot;    &lt;directory /data/csite&gt;    Require all granted    &lt;/directory&gt;重启服务即可通过curl 192.168.34.103      curl 192.168.34.200    curl 192.168.34.210即可获取到各自的index.html文件内容，对应的日志也都生成了</code></pre><p>  2.基于port的虚拟主机搭建，监听三个port即可;使用的不多</p><pre><code>listen 8081listen 8082listen 8083&lt;virtualhost *:8081&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8082&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8083&gt;                                                                                                      servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;</code></pre><p>  通过本机IP+port获得不同网站的信息</p><pre><code>curl 192.168.34.103:8081curl 192.168.34.103:8082curl 192.168.34.103:8083</code></pre><p>  3.基于FQDN的虚拟主机搭建：用的最多<br>  前提：这里就不搭建DNS服务器了，使用本机的hosts文件进行域名解析</p><pre><code>&lt;virtualhost *:80&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;                                                                                                     servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_c.log combined&lt;/virtualhost&gt;</code></pre><p>  测试：curl <a href="http://www.a.com" target="_blank" rel="noopener">www.a.com</a></p><pre><code>curl www.b.cncurl www.c.net</code></pre><p>  就可获得各自的主页面信息<br>从这telnet就可以理解出，如果在互联网通过域名访问时(同一IP)，返回的结果是不同网站的信息<br>  [root@node7-1 ~]#telnet 192.168.34.103 80</p><pre><code>Trying 192.168.34.103...Connected to 192.168.34.103.Escape character is &apos;^]&apos;.GET /index.html HTTP/1.1HOST: www.a.com</code></pre></li></ul><font size="4" color="#FF0000"><br>当访问192.168.34.103时 HOST：即网站的域名，返回的结果就是其对应的页面信息<br>在互联网上，一般是先在本地服务器上通过第三种方式搭建多个网站，然后再通过服务商的智能DNS解析，可以通过访问不同的域名，解析到IP地址，服务器根据输入的HOST：域名判断访问的是哪个网站，进而返回对应网站站点的信息，对于主机较少或者IP有限的环境中，使用http虚拟主机还是很方便的。<br></font>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;a href=&quot;#HTTP协议和APACHE原理&quot; class=&quot;headerlink&quot; title=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;/a&gt;HTTP协议和APACHE原理&lt;/h3&gt;&lt;p&gt;Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等&lt;br&gt;本文说的是HTTP SERVER&lt;a href=&quot;http://www.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;apache&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="HTTP协议" scheme="https://www.liukui.tech/categories/HTTP%E5%8D%8F%E8%AE%AE/"/>
    
    
      <category term="apache,web服务" scheme="https://www.liukui.tech/tags/apache-web%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>编译安装LAMP</title>
    <link href="https://www.liukui.tech/2018/12/10/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85LAMP/"/>
    <id>https://www.liukui.tech/2018/12/10/编译安装LAMP/</id>
    <published>2018-12-10T00:00:00.000Z</published>
    <updated>2018-12-31T11:57:40.667Z</updated>
    
    <content type="html"><![CDATA[<p>LAMP<br><a id="more"></a></p><p><img src="/2018/12/10/编译安装LAMP/LAMP架构.png" alt=""></p><h3 id="Centos7上编译安装LAMP"><a href="#Centos7上编译安装LAMP" class="headerlink" title="Centos7上编译安装LAMP"></a>Centos7上编译安装LAMP</h3><pre><code>    备注：本文编译PHP是基于fastCGI方式，php-fpm编译准备：    在192.168.34.105上实现，准备安装包都放在/data/src下        apr-1.6.5.tar.bz2        apr-util-1.6.1.tar.bz2        httpd-2.4.37.tar.bz2        php-7.1.18.tar.bz2        wordpress-5.0-zh_CN.zip        mariadb-10.2.19-linux-x86_64.tar.gz    准备开发包组：        yum install &apos;develoment tools&apos; -y    1.编译安装httpd和apr        准备依赖包和解压安装包        yum install pcre-devel openssl-devel expat-devel apr-util-devel -y        tar xvf apr-1.6.5.tar.bz2        tar xvf apr-util-1.6.1.tar.bz2         tar xvf httpd-2.4.37.tar.bz2        cp -r apr-1.6.5 httpd-2.4.37/srclib/apr        cp -r apr-util-1.6.1 httpd-2.4.37/srclib/apr-util        a.编译            cd httpd-2.4.37            ./configure \            --prefix=/data/httpd24 \            --enable-so \            --enable-ssl \            --enable-cgi \            --enable-rewrite \            --with-zlib \            --with-pcre \            --with-included-apr \            --enable-modules=most \            --enable-mpms-shared=all \            --with-mpm=prefork            make &amp;&amp; make install        b.准备环境变量            用自带的服务控制脚本：/app/httpd24/bin/apachectl就需要设置环境变量了            echo &apos;PATH=/mysql/httpd24/bin:$PATH&apos; &gt; /etc/profile.d/httpd24.sh            . /etc/profile.d/httpd24.sh        c.修改配置文件，为了安全以apache用户运行，并监听在本地            useradd -r -s /sbin/nologin apache            vim /data/httpd24/conf/httpd.conf                User apache                Group apache                ServerName localhost:80    2.二进制安装mariadb-10.2.19        a.准备用户和mysql数据库目录                useradd -r -s /sbin/nologin -d /data/mysql mysql                mkdir /data/mysql                chown mysql.mysql mysql/        b.解压二进制安装包：            tar xvf mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local/            cd /usr/local            ln -s mariadb-10.2.19-linux-x86_64/ mysql            chown -R root.mysql /usr/local/mysql/        c.创建数据库文件:(通过自带脚本工具)            cd /usr/local/mysql/            scripts/mysql_install_db --datadir=/mysql/data --user=mysql        d.准备配置文件(不修改/etc/my.cnf)拷贝解压完的文件            mkdir /etc/mysql/            cp support-files/my-huge.cnf /etc/mysql/my.cnf                                路径优先级高于/etc/my.cnf                根据性能来拷贝配置文件            [mysqld]中添加三个选项：/etc/mysql/my.cnf            datadir = /mysql/data            innodb_file_per_table = on            skip_name_resolve = on 禁止主机名解析，建议使用        e.准备服务脚本，并启动服务            cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld            chkconfig --add mysqld            service mysqld start        f.准备PATH路径            echo &apos;PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh            . /etc/profile.d/mysql.sh            systemctl start mysqld        为wordpress准备数据库和账号密码            mysql -e &apos;create database wordpress&apos;            mysql -e &quot;grant all on *.* to php1@&apos;192.168.34.%&apos; identified by &apos;php123&apos;&quot;    3.FastCGI方式编译安装php-7.1.18        tar xf php-7.1.18.tar.bz2        安装依赖包            yum install libxml2-devel bzip2-devel libmcrypt-devel -y         a.编译，指定安装数据路劲和配置文件路径                   cd php-7.1.18            ./configure --prefix=/data/php \            --enable-mysqlnd \            --with-mysqli=mysqlnd \            --with-openssl \            --with-pdo-mysql=mysqlnd \            --enable-mbstring \            --with-freetype-dir \            --with-jpeg-dir \            --with-png-dir \            --with-zlib \            --with-libxml-dir=/usr \            --enable-xml \            --enable-sockets \            --enable-fpm \            --with-config-file-path=/etc \            --with-config-file-scan-dir=/etc/php.d \            --enable-maintainer-zts \            --disable-fileinfo            make &amp;&amp; make install        b.准备php配置文件            cd php-7.1.18            cp php.ini-production /etc/php.ini                可以修改当前时区和按照生产环境修改并发连接数等信息        c.准备php的conf文件            cd /data/php            cp php-fpm.conf.default php-fpm.conf            cp php-fpm.d/www.conf.default php-fpm.d/www.conf            修改监听地址和允许连接地址，因为是在一台编译的，监听地址不用改了                vim php-fpm.d/www.conf                    listen = 127.0.0.1:9000                    ;listen.allowed_clients = 127.0.0.1        d.准备服务脚本:            cp /data/src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm            chmod +x /etc/init.d/php-fpm            chkconfig --add php-fpm            chkconfig php-fpm on    4.修改httpd文件，支持php和启用代理        编辑apache配置文件httpd.conf，以使apache支持php,并启用代理        vim /data/httpd24/conf/httpd.conf            1.取消下面两行的注释                LoadModule proxy_module modules/mod_proxy.so                LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so            2.定位至DirectoryIndex index.html                修改为DirectoryIndex index.php index.html            3.最后添加4行        AddType application/x-httpd-php .php        AddType application/x-httpd-php-source .phps        ProxyRequests Off        ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1             重启apache服务，apachectl restart    5.准备wordpress,把wordpress文件全部移动到httpd24/htdocs下        cd /data/src        unzip wordpress-5.0-zh_CN.zip        cd wordpress        mv * /data/httpd24/htdocs        为wordpress准备配置文件和数据库连接            cd /data/httpd24/htdocs            mv wp-config-sample.php wp-config.php            vim wp-config.php                define(&apos;DB_NAME&apos;, &apos;wordpress&apos;);                define(&apos;DB_USER&apos;, &apos;php&apos;);                define(&apos;DB_PASSWORD&apos;, &apos;php123&apos;);                define(&apos;DB_HOST&apos;, &apos;192.168.34.105&apos;);    到此所以的编译安装和准备工作都做完了，把mysql,php-fpm,httpd启动即可            apachectl start            systemctl start php-fpm            systemctl start mysqld        http://192.168.34.105 配置wordpress即可</code></pre><p><font size="4" color="#23238E"><br>然后把这套系统搬到自己的云服务上就可以轻松的实现了,本文是基于LAMP架构实现的<br>不过推荐使用LNMP架构，毕竟Nginx的强大可不是吹出来的..<br></font> </p><p><font size="4" color="#FF0000">安装完成后，开启了一个新的世界，就可以开心的玩耍了,helloworld！</font><br><img src="/2018/12/10/编译安装LAMP/haha.png"><br><img src="/2018/12/10/编译安装LAMP/wordpress.png" width="80%" height="80%"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LAMP&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="lamp,博客搭建" scheme="https://www.liukui.tech/categories/lamp-%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="博客搭建，wordpress" scheme="https://www.liukui.tech/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%8Cwordpress/"/>
    
  </entry>
  
  <entry>
    <title>Docker网络</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%BD%91%E7%BB%9C/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker网络/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-06T01:01:49.594Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Network"><a href="#Docker-Network" class="headerlink" title="Docker Network"></a>Docker Network</h3><a id="more"></a><p><img src="/2018/10/18/Docker网络/docker的四种网络.png" alt="docker的四种网络"></p><pre><code>KVM上虚拟桥接式网络类型：        隔离桥：只能与连接到同一个桥上的主机通信，IP地址还需要在同一网段        仅主机桥：可以和连接的桥地址进行通信        路由桥：            1.打开宿主机核心转发功能            2.虚拟机的网关都指向这个桥的地址            就可以与宿主机通信，不能与外网通信        NAT桥：在路由桥的基础上，在宿主机上做SNAT规则，即可访问外网地址    Docker提供的四种网络：    桥网络：bridge，默认就是docker0桥，docker0是SNAT桥            查看网络定义：docker network inspect bridge            大多数的容器还是使用bridge网络            而且这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器    共享桥：        每一个容器都是靠在内核级虚拟资源分配的独立的6种名称空间来支撑的        这6种名称空间是IPC,Net,Mount,UPS,PID,USER        虽然每个容器都有各自独立的名称空间，但是确可以共享，于是就有了这种方式        共享桥的原理：                共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈            而mount user PID还是隔离的，文件系统也是隔离的        这样做的效果就可以构建出一个模型            httpd---&gt;fpm127.0.0.1:9000---&gt;mysql127.0.0.1:3306            那么对于fpm和mysql来说只监听在本地端口上，保证了安全性    host宿主机网络：        既然多个容器可以使用同一个容器的网络名称空间，而且宿主机在内核中也有自己的        网络名称空间，那么容器也理所当然的可以使用宿主机的网络名称空间        容器使用宿主机的网络和DNAT方式有关系        作用：可以做日志收集主机，host一般在特殊环境下使用    none网络：封闭式网络        当容器不需要网络服务时，不创建网卡，只有本地lo网卡除了bridge桥之外，其他三种网络都是docker所独有的</code></pre><h3 id="Docker网络的相关命令"><a href="#Docker网络的相关命令" class="headerlink" title="Docker网络的相关命令"></a>Docker网络的相关命令</h3><pre><code>docker run 命令中涉及网络的相关命令    --network 启动容器时，指定使用的网络        [bridge|host|none|container:name]    --hostname 启动容器时，指定容器的主机名    --add-host list 启动容器时，指定内部的hosts解析文件        如：docker run --add-host c1:192.168.10.1 busybox:latest            cat /etc/hosts可以看到添加的解析    --dns 启动容器时，指定DNS地址        如：docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest            cat /etc/resolve可以看到指定的DNS地址    --ip string 启动容器时，指定容器的iPv4地址    -p|--publish         因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则docker network:    ls：显示docker内部的全部网络    connect: 让容器连接到某个网络上    disconnect: 把容器从某个网络断开    create: 创建自定义网络，和KVM创建网络类似    inspect:查看某个网络是怎么定义的    prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令    rm: 删除docker内部的网络</code></pre><h3 id="Docker-network的端口暴露"><a href="#Docker-network的端口暴露" class="headerlink" title="Docker network的端口暴露"></a>Docker network的端口暴露</h3><pre><code>docker run --network [bridge|host|none] -p|--publish     作为一个容器，是要提供web服务的，而docker默认的桥是bridge，而且是个SNAT桥    容器只能访问外网，而不能被外网所访问，那么就失去了web服务器对外提供服务的初衷    而docker提供了一个-p选项来自动生成DNAT规则，来避免每次都手写DNAT规则带来的麻烦-p选项的用法和使用格式：    •-p &lt;containerPort&gt;        将指定的容器端口映射至主机所有地址的一个动态端口    •-p &lt;hostPort&gt;:&lt;containerPort&gt;        将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt;    •-p &lt;ip&gt;::&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口    •-p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt;    “动态端口”指随机端口，具体的映射结果可使用docker port命令查看    不过一般还是要使用第四种方式指定宿主机的端口    指定了映射的端口后，可以使用命令查看映射关系：        docker container port [name]示例：1.docker run --name c1 -it --rm --network bridge -p 80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:327682.docker run --name c1 -it --rm --network bridge -p 80:80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:803.docker run --name c1 -it --rm --network bridge -p 192.168.34.103::80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:327684.docker run --name c1 -it --rm --network bridge -p 192.168.34.103:80:80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:80</code></pre><h3 id="Docker的自定义网络"><a href="#Docker的自定义网络" class="headerlink" title="Docker的自定义网络"></a>Docker的自定义网络</h3><pre><code>docker network create     connect:相当于创建一对网卡，一半在桥上，一半在容器中    而且默认创建的网络都是SNAT桥    选项：    -d|--driver string 创建时，要指定桥的类型        默认是bridge，当然还有 host macvlan null overlay四种类型    --gateway strings 默认是定义的子网的第一个IP地址    --subnet strings 子网地址    --ip-range strings 地址分配的IP地址范围修改默认的bridge，docker0桥的子网    自定义docker0桥的网络属性信息：也就是镜像加速的文件    vim /etc/docker/daemon.json文件    {        &quot;bip&quot;: &quot;192.168.1.5/24&quot;,        &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;,        &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,        &quot;mtu&quot;: 1500,        &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,        &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,        &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]    }     核心选项为bip，即bridge 桥接口的IP地址    ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。示例：    1.创建一个mybr2的网络，并指定子网地址        docker network create --subnet 10.0.0.0/8 mybr2    2.创建容器c1指定加入到mybr2网络中        docker run --name c1 -it --rm --network mybr2  busybox:latest    3.给容器c1再加入一个bridge网络中        docker network connect bridge c1        此时c1就有了两个网络地址    4.删除容器c1的网卡        docker network disconnect mybr2 c1</code></pre><h3 id="Docker指定容器启动的网路类型"><a href="#Docker指定容器启动的网路类型" class="headerlink" title="Docker指定容器启动的网路类型"></a>Docker指定容器启动的网路类型</h3><pre><code>1.启动为none类型的网络    docker run --name c1 -it --rm --network none busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/none网络.png" alt="none网络"></p><pre><code>2.启动为bridge类型的网络:docker默认的网络模型    docker run --name c2 -it --rm --network bridge busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/bridge网络.png" alt="bridge网络"></p><pre><code>3.启动为joined类型的网络    启动的c3共享的是c2的Net,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的</code></pre><p><img src="/2018/10/18/Docker网络/共享桥网络.png" alt="共享桥网络"></p><p>因为共享桥只是共享了Net网络，UTS主机名，IPC，<br>此时IP地址和hostname都是一样，就可以通过127.0.0.1进行通信了<br>而mount(文件系统)，user,PID还是隔离的，所以在1上创建一个文件，2上是看不到的<br>这就是共享桥的工作机制</p><pre><code>4.启动为host宿主机类型的网络    docker run --name c4 -it --rm --network host busybox:latest    可以看出hostname,Net都是和宿主机是一样的    此时在容器内部启动httpd服务，其他主机是可以通过宿主机提供服务的</code></pre><p><img src="/2018/10/18/Docker网络/host网络.png" alt="host网络"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Network&quot;&gt;&lt;a href=&quot;#Docker-Network&quot; class=&quot;headerlink&quot; title=&quot;Docker Network&quot;&gt;&lt;/a&gt;Docker Network&lt;/h3&gt;
    
    </summary>
    
      <category term="Docker" scheme="https://www.liukui.tech/categories/Docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker镜像</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E9%95%9C%E5%83%8F/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker镜像/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-06T01:23:12.660Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Images"><a href="#Docker-Images" class="headerlink" title="Docker Images"></a>Docker Images</h3><a id="more"></a><font size="3" color="#FF0000"><br>docker image是docker贡献给容器极具创造性的使用方式！<br>分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！<br></font><p><img src="/2018/10/18/Docker镜像/docker读写机制.png" alt="docker-image和读写机制"></p><pre><code>1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器    a.docker镜像就像KVM镜像一样，包含了启动容器/虚拟机所依赖的所有文件，文件系统        包括程序文件，库文件，配置文件,数据目录等等    b.dokcer采用分层构建机制，最底层为bootfs，其上是rootfs        bootfs：在创建的容器中是看不到的，只是用于系统引导的文件系统，包括                bootloader和kernel，因为在创建启动容器时，其实是用到内核的，                只不过只是启动引导容器启动的，当容器启动完成后会被卸载以节约内存资源;                而且把对应的对容器的管理委托给宿主机的内核，所以容器镜像的内核只                是启动时有用，而且看不到，所以bootfs叫引导文件系统        rootfs:位于bootfs之上，表现为docker容器的根文件系统;                1.在传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只                    读&quot;模式，完整性自检完成后将其重新挂载为读写模式；也就是fstab                    的最后两项，只有通过自检次序时，才会把根文件系统重新以&quot;读写&quot;方式挂载.                2.但是在docker中，rootfs由内核挂载为&quot;只读&quot;模式，就算容器启动完成                    ，rootfs也不会以读写方式重新挂载！也就是说docker容器的用户空                    间和根文件系统一直都是只读的！                3.docker是通过&quot;联合挂载&quot;技术额外挂载一个“可写”层；docker image layer2.Docker Images Layer    如上图    a.完整的docker镜像包括bootfs,rootfs    b.而rootfs又包括Base Image+自定义的镜像层+可写层writable        除了writable是可写层，其他都是只读层    c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加        一个可写层，这个可写层writable是属于容器的    d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的</code></pre><h4 id="容器的读写原理："><a href="#容器的读写原理：" class="headerlink" title="容器的读写原理："></a>容器的读写原理：</h4><p>如上图示： </p><ul><li>1.对于docker来说有一个专门存放镜像的路径叫Graph Driver，而这个文件系统必须是特殊<br>  格式的(aufs或者overlay2),在linux系统内默认是/var/lib/docker/image/overlay2；<br>  overlay2目录就是构建在宿主机(xfs或ext4)的/var/lib/docker/image/目录的二级文件系统</li></ul><ul><li>2.前面说镜像数据文件都放在bootfs和rootfs上的，可写层writbale是创建时创建的<br>  那么在可写层上是如何看到底层的数据目录？又是怎么把数据增删改到容器内的？<br>  默认xfs和ext4是不支持COW机制的</li></ul><blockquote><p>如何看到镜像目录的？</p></blockquote><pre><code>a.在创建容器时，是把镜像内的多层镜像通过联合挂载方式作为可写层的底层，也就是这个容器内部的可访问文件系统接    口b.所谓联合挂载，是通过把镜像内的多层一层一层叠加上去的，而这个叠加方式的原理是：    第一层上有数据时，而第二层没相同数据，在第二层是可以看到第一层数据的;如果第二层有第一层相同数据，    则会覆盖第一层上的相同数据，在第二层上看到的是第一层和第二层总的文件，以此类推，在可写层上就可以看到    镜像内的数据目录了，</code></pre><blockquote><p>如何修改和写文件？</p></blockquote><pre><code>a.对于修改文件，因为文件是放在只读层的，只能是通过COW写时复制机制，先把文件从只读层复制到可写层上再进行修改    然后保存在可写层,当然是首次修改，第二次再修改因为在可写层有文件了，在可写层修改即可，而只读层的该文件    版本仍然存在，只不过是被读写层中该文件的副本所隐藏了.b.对于写文件，新创建的文件是保存在可写层的，所以最终用户看到的是只读层和可写层的全    部数据文件，这就是镜像的工作逻辑</code></pre><blockquote><p>通过上面的分析可以得出：</p></blockquote><pre><code>1.这就是为什么基于同一镜像创建的两个容器，用户在不同的容器上看到的相同的数据都是只读层的，不同的数据是可写    层上各自独有的，因为可写层是独占的，只读层是共享的2.这就是为什么镜像背后必须要求特殊文件系统的原因：因为ext4和xfs默认是不支持联合挂载和写时复制机制的3.因为可写层是可以自定义修改的，把可写层保存为镜像，然后再和原始镜像进行叠加成一个自定义的镜像，    就可以作为基础镜像使用了，不过一般不这么做，而是通过dockerfile自定义镜像</code></pre><h3 id="docker-imge相关命令"><a href="#docker-imge相关命令" class="headerlink" title="docker imge相关命令"></a>docker imge相关命令</h3><pre><code>docker image 相关命令    docker imges:镜像的管理命令    ls： 查看本地所有的镜像列表    build:    import:    inspect: 查看下载/创建的镜像详细信息            可以查看下载的某个镜像的具体信息                    如：CMD:镜像启动默认运行的命令                        Volume:                        network:            下文中构建docker file时这些都可以自定义    load:    prune:    pull：从远程仓库拉取镜像到本地    push: 把本地镜像推到远程的Registry    rm:  docker image rm = docker rmi 删除镜像    tag: 给镜像打标签    save:2.将当前容器可写层保存为镜像并上传docker hub上    docker container commit [options] container [repository:[tag]]         选项：            -a:指定作者            -c:镜像内部默认运行的命名            -p|--pause:因为制作镜像时，容器还在运行，可能制作出的镜像和当前容器不                一致，可以在制作时，暂停容器，保持数据一致    比如：        1.在docker hub上注册用户，并创建镜像仓库            创建的仓库：myimg        2.把centos1容器做成镜像仓库下的myimg：v0.1版本            docker container commit -p -a &quot;liu &lt;liu@163.com&gt;&quot; -c &quot;CMD [&apos;/bin/httpd -f&apos;]&quot; centos1 liukkui/myimg:v0.1            然后新容器就可以基于这个镜像启动了        3.上传docker hub            docker login 登录到docker hub                输入账号密码，正常登录后        4.push镜像            docker image push liukkui/myimg:v0.1            正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Images&quot;&gt;&lt;a href=&quot;#Docker-Images&quot; class=&quot;headerlink&quot; title=&quot;Docker Images&quot;&gt;&lt;/a&gt;Docker Images&lt;/h3&gt;
    
    </summary>
    
      <category term="Docker" scheme="https://www.liukui.tech/categories/Docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>iptables之FORWARD和NAT</title>
    <link href="https://www.liukui.tech/2018/10/10/iptables%E4%B9%8BFORWARD%E5%92%8CNAT/"/>
    <id>https://www.liukui.tech/2018/10/10/iptables之FORWARD和NAT/</id>
    <published>2018-10-10T00:00:00.000Z</published>
    <updated>2018-12-29T09:57:45.701Z</updated>
    
    <content type="html"><![CDATA[<p>iptables/netfilter网络防火墙：<br>        在FORWARD链上定义规则，注意以下几个问题：<br>            (1) 请求-响应均经由FORWARD链，要注意规则的方向性；<br>            (2) 如果可以启用conntrack机制，建议将双方向的状态为ESTABLISHED的报文直接放行；<br><a id="more"></a></p><h3 id="网络防火墙原理及示例"><a href="#网络防火墙原理及示例" class="headerlink" title="网络防火墙原理及示例"></a>网络防火墙原理及示例</h3><p>本地通信：两个主机在没有网关或者路由下进行通信，所有的本地通信是通过MAC地址进行通信的<br>        name–&gt;IP–&gt;MAC地址基于广播机制<br>        如果有交换机，交换机会查找MAC地址表(是通过源地址学习得到的),<br>        将数据报文直接发送到连接到交换机的目标主机上<br>网络通信：其实就是多个本地通信实现的，由多个路由器进行中继转发最后到达目标主机的<br>    而把linux服务器扮演成路由器的角色，则这台linux服务器充当是网关，就需要打开核心转发功能</p><h3 id="FORWARD链"><a href="#FORWARD链" class="headerlink" title="FORWARD链"></a>FORWARD链</h3><p>右边是生产环境<br>左边是研发测试环境：</p><p>隧道VPN</p><p>实验模拟：<br>    sysctl -w net.ipv4.ip_forward=1<br>    A:<br>    route add -net 192.168.10.10/24 gw 192.168.34.103<br>    B:<br>    route add -net 192.168.34.0/24 gw 192.168.10.10<br>    情景一：客户端确定服务端不确定；源地址确定，目标地址不确定<br>    情景二：服务端确定，客户端不确定；源地址不确定，目标地址确定</p><p>对于情景一的情况：<br>    客户端确定,服务端不确定；即源地址确定，目标地址不确定<br>示例1:<br>    1.先在FORWARD链上默认为拒绝<br>    如控制客户端只能访问httpd和ping操作，就可以在FORWARD链上添加如下规则<br>    tcp:80端口限制:<br>    iptables -A FORWARD 1 -s 192.168.34.0/24 -p tcp –dport 80 -j ACCEPT<br>    iptables -I FORWARD 2 -d 192.168.34.0/24 -p tcp –sport 80 -j ACCEPT<br>    icmp的ping限制：<br>    iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -j ACCEPT<br>    iptables -I FORWARD 4 -d 192.168.34.0/24 -p icmp –icmp-type 0 -j ACCEPT<br>    默认拒绝策略：<br>        iptables -I FORWARD 5 -j REJECT<br>    2.因为之前介绍过state的状态追踪功能：<br>    就可以简化成这样的规则：<br>    iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT<br>    iptables -A FORWARD 2 -s 192.168.34.0/24 -p tcp –dport 80 -j ACCEPT<br>    iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -j ACCEPT<br>    iptables -I FORWARD 4 -j REJECT<br>    3.情景一因为都是内网的服务器，是不能接收外网的请求的<br>    所以对于ping和tcp只允许从内网出去的，外网是不能进来的，规则如下<br>    iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT<br>    iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp –dport 80 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 4 -j REJECT</p><p>示例2：控制访问ping,httpd：80,vsftp：21,dns：53<br>    规则如下：<br>    iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT<br>    iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp -m multiport –dport 80,21,53 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 3 -s 192.168.34.0/24 -p udp –dport 53 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 4 -s 192.168.34.0/24 -p icmp –icmp-type 8 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 5 -s 192.168.34.0/24 -p tcp -m state –state RELATED -j ACCEPT<br>    iptables -I FORWARD 6 -j REJECT<br>在这里需要指定-s 源，不然外网向内网主动发送报文请求也是可以到达内网的！</p><font size="3" color="#FF0000"><br>结论：<br>    1.所以说有时服务器ping不通不代表服务不能访问，而且通过内网ping外网时，在外网服务器<br>    进行抓包时，可以看出源地址是内网IP,非网关IP，目标地址是外网IP地址<br>[root@centos7 data]# tcpdump -i ens33 -nn icmp<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytes<br>21:10:24.541810 IP 192.168.34.107 &gt; 192.168.10.10: ICMP echo request, id 1764, seq 3, length 64<br>21:10:24.541877 IP 192.168.10.10 &gt; 192.168.34.107: ICMP echo reply, id 1764, seq 3, length 64<br>    2.用linux防火墙做网关网络防火墙，有一个问题，内网的机器是保护了，但是这台linux服务<br>        是没有防护的，所以还需要在这台网络防火墙上在INPUT和OUTPUT链上加上规则，来防护<br>        这台linux网关网络防火墙！所以当用一台linux服务器做网络防火墙时，INPUT,OUTPUT<br>        FORWARD链是都需要设置规则的！<br></font><p>对于情景二的情况：<br>右边的图则控制：源地址不确定，目标地址确定<br>示例3：控制允许互联网的主机访问ping,httpd：80,vsftp：21,dns：53<br>    所以规则应该如下：<br>    iptables -I FORWARD 1 -p tcp -m state –state ESTABLISHED -j ACCEPT<br>    iptables -I FORWARD 2 -d 192.168.10.0/24 -p tcp -m multiport –dports 80,53,21 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 3 -d 192.168.10.0/24 -p udp –dport 53 -j ACCEPT<br>    iptables -I FORWARD 4 -d 192.168.10.0/24 -p icmp –icmp-type 8 -m state –state ESTABLISHED  -j ACCEPT<br>    iptables -I FORWARD 5 -d 192.168.10.0/24 -m state –state RELATED -j ACCEPT<br>    iptables -I 6 FORWARD -j REJECT</p><h3 id="NAT："><a href="#NAT：" class="headerlink" title="NAT："></a>NAT：</h3><font size="3" color="#FF0000"><br>    当然NAT规则还是建立在FORWARD的基础上做地址转换，不能转发做NAT也没意义，所以放行和控制限制还是需要在FORWARD链上去做的<br></font><pre><code>NAT: network address translation，地址转换NAT技术的产生核心原因：隐藏本不需要公开的主机    1.请求报文的源地址地址转换是人为在NAT上加规则实现的    2.响应报文中的目标地址转换，是基于连接追踪功能实现的，不需要人为干预比如内网的机器要访问互联网，就必然留下IP地址或者端口信息，则有些攻击木马通过真正的    地址来扫描这些内网机器，如果有漏洞，则可能就会被攻击，所以NAT的技术的出现，就    会隐藏我们内网机器访问互联网时的真正IP地址和端口。实现隐藏的原理：    1.将数据报文中的源地址IP，修改为具有很强防护能力的IP地址，比如网关等,这样的话，互联网上的主机看到的源地址就会是网关的地址，即使被攻击也是攻击网关，而网关一般是具有很高的防护能力的，所以就达到了隐藏源地址的目的.    2.一般来说请求报文经过防火墙时，会拆掉以太网帧首部，看到目标地址不是自己时，会转发出去，但是对于NAT的情况，防火墙会修改数据报文的IP首部的源地址或者目标地址，然后重新封装数据报文，再到达目标主机，这样就会达到保护源主机和目标主机被攻击的风险，在这个过程中，请求报文由手动修改的，响应报文是由NAT连接追踪功能实现的。NAT的方式：SNAT,DNAT,FullNAT,PortNATNAT规则可加的链：    支持PREROUTING INPUT OUTPUT POSTROUTING,但是一般只在PREROUTING和    POSTROUTING上做NAT规则，INPUT和OUTPUT只有在特殊情况下才做NAT。</code></pre><p>那么在netfilter上是如何实现的？<br>    SNAT的实现<br>        数据报文经过防火墙时，如上图示，只有当数据报文进入防火墙时，才知道目标地址不是<br>        自己，还是需要转发，所以不适合在PREROUTING链上做地址转发，如果目标地址不是当前<br>        主机，就要经由FORWARD链进行转发，而FORWARD链本身确不支持地址转换功能，所以只<br>        有在离开本机再一次进行路由选择，路由完之后才扔给网卡发送队列中，所以只能在POSTROUTING链上加地址转换规则<br>    DNAT的实现</p><h3 id="SNAT：POSTROUTING源地址转换"><a href="#SNAT：POSTROUTING源地址转换" class="headerlink" title="SNAT：POSTROUTING源地址转换"></a>SNAT：POSTROUTING源地址转换</h3><p><img src="/2018/10/10/iptables之FORWARD和NAT/" alt="SNAT原理"></p><pre><code>原理：    请求报文发生了源地址修改：人为介入修改    响应报文经过防火墙的NAT规则时，同连接追踪机制自动修改目标地址    所以源地址转换适合隐藏服务端作用：    1.隐藏内网主机的IP地址，防止被攻击    2.SNAT可以解决IPV4端口不够用的问题：        IPV4的地址短缺的问题使得SNAT技术更加流行，因为私网地址使用一个公网地址，        所以通过SNAT地址转换，报文通过公网IP出去的时候，都会把源地址(私网地址)转        换成公网地址，才能与公网通信，响应报文回来的时候是发给公网IP的，则通过连接        追踪功能返回给原来的私网地址。SNAT实验：    192.168.34.0/24网段SNAT到192.168.10.11上，且只限制80和ping操作能进行    规则如下：    NAT的POSTROUTING链规则：        iptables -t nat -I POSTROUTING 1 -s 192.168.34.0/24 ! -d 192.168.34.0/24 -j SNAT --to-source 192.168.10.11    注意：这里的source是一个固定的地址，如果这个地址是变动的呢？        那么可能下次这条规则就不生效了！--&gt;    控制和放行还是需要在FORWARD链上做规则的        iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT        iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT        iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET        iptables -I  FORWARD 4 -j REJECT如上图：通过在192.168.10.10上抓icmp包和http日志也可以看出，确实是做了SNAT地址转换的    [root@node7-3 data]#tcpdump -i ens33 -nn icmp    14:56:14.315375 IP 192.168.10.11 &gt; 192.168.10.10: ICMP echo request, id 1373, seq 1, length 64    14:56:14.315473 IP 192.168.10.10 &gt; 192.168.10.11: ICMP echo reply, id 1373, seq 1, length 64    [root@node7-3 data]#tail /var/log/httpd/access_log     192.168.10.11 - - [29/Dec/2018:15:20:45 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot;</code></pre><h3 id="DNAT：PREROUTING和OUTPUT目标地址转换"><a href="#DNAT：PREROUTING和OUTPUT目标地址转换" class="headerlink" title="DNAT：PREROUTING和OUTPUT目标地址转换"></a>DNAT：PREROUTING和OUTPUT目标地址转换</h3><p><img src="/2018/10/10/iptables之FORWARD和NAT/" alt="DNAT原理"></p><pre><code>原理:    请求报文的目标地址需要修改成真正的IP地址    响应报文经过防火墙的NAT规则，通过连接追踪机制，自动修改目标地址作用：    1.隐藏提供服务的服务器的真实IP地址，防止被服务被劫持，如DNS劫持，http服务等    2.DNAT也通过PortNAT方式可以解决IPV4地址不够用的问题DNAT实验：    访问192.168.10.10的http服务时，只需要访问防火墙NAT服务器的地址即可    即把192.168.10.10DNAT到192.168.34.103上，这里只做简单的DNAT不做portnat    规则如下：    NAT的POSTROUTING链规则：        ptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10    控制和放行还是需要在FORWARD链上做规则的        iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT        iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT        iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET        iptables -I  FORWARD 4 -j REJECT验证：在192.168.34.107上获取192.168.10.10的页面信息：curl 192.168.10.10    因为DNAT是隐藏192.168.10.10的真实地址的，在互联网上只会暴露防火墙的192.168.34.103地址是提供http服务的，真正的地址得以保护，所以这里curl 192.168.34.103即可    [root@node7-2 data]#curl 192.168.34.103    haha    192.168.10.10    而在192.168.10.10查看http日志    [root@node7-3 data]#tail /var/log/httpd/access_log     192.168.34.107 - - [29/Dec/2018:17:24:20 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot;    192.168.34.107 - - [29/Dec/2018:17:26:42 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot;从实验也可以看出DNAT的规则生效了，达到了隐藏真正提供服务的192.168.10.10地址    从而保证了服务器被攻击的风险</code></pre><h3 id="PortNAT-端口映射"><a href="#PortNAT-端口映射" class="headerlink" title="PortNAT:端口映射"></a>PortNAT:端口映射</h3><p><img src="/2018/10/10/iptables之FORWARD和NAT/" alt="PortNAT原理"><br>端口映射在docker容器中的实现方式更加方便，直接加-p选项即可,而且源端口和目标端口可以指定</p><pre><code>进程与进程的通信，实际上就是端口号之间的通信1.对于SNAT来说，因为访问是互联网的随机端口，所以都转换即可2.而对于DNAT的情况来说：    a.很多情况下，并不是说只要访问防火墙F的地址，都通过DNAT转换成主机A的IPA，    而是当访问主机A的某个服务特定端口时，才进行地址转换    b.而访问F的端口和要转换的IPA的端口不一定需要一样        即IPF：port1--&gt;IPA:port2，port1和port2可以不一样3.DNAT也可以解决IPV4地址不够用的情况：如下图那么就可以说地址转换可以发生在网络层，而且借助端口映射也可以发生在传输层首部(端口)DNAT端口映射实验：如上图访问192.168.10.10：8080的http服务时，只需要访问防火墙NAT服务器的地址即可    即把192.168.10.10:8080DNAT到192.168.34.103:80上,在上面的DAT基础上做修改即可    规则如下：    NAT的POSTROUTING链规则：        ptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10:8080    控制和放行还是需要在FORWARD链上做规则的        iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT        iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT        iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET        iptables -I  FORWARD 4 -j REJECT验证：curl 192.168.34.103:80查看是否能获取到192.168.10.10：8080的页面    [root@node7-2 data]#curl 192.168.34.103    haha    192.168.10.10    [root@node7-2 data]#curl 192.168.10.10:8080    haha    192.168.10.10    [root@node7-3 data]#tail /var/log/httpd/access_log     192.168.34.107 - - [29/Dec/2018:17:27:01 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot;从实验也可以看出DNAT的端口映射规则生效了，映射的端口不一样也可以访问到页面</code></pre><font size="3" color="#FF0000"><br>    1.这里只模拟同一台服务器上的一个服务的DNAT端口映射情景<br>    2.对于同一台服务上的多个服务DNAT端口映射也是同样道理，加上对应的PORTNAT规则即可<br>    3.对于多台服务器上的多个服务DNAT端口映射同样是这样的，只需要在NAT服务器上添加多个地址，然后将对应地址进行多台服务器的服务映射即可<br></font><h3 id="FullNAT：源地址和目标地址都修改"><a href="#FullNAT：源地址和目标地址都修改" class="headerlink" title="FullNAT：源地址和目标地址都修改"></a>FullNAT：源地址和目标地址都修改</h3><pre><code>既是网关又是NATfullnat能实现网关和主机不在同一个网段FullNAT的存在是为了弥补SNAT和DNAT模式下，主机和NAT服务器必须在同一个网段的缺点    SNAT和DNAT都受限于NAT服务器和客户端都在一个网段    1.在SNAT中，主机的网关都是需要指向NAT服务器的，不然如果在主机和防火墙之间存在路由器的话，那么出去的请求报文就不一定经由NAT服务器了，也就达不到地址转换的目的    2.在DNAT中，如果提供服务器的主机和防火墙NAT服务器之间有路由器，那么响应的报文    也不一定经由NAT服务器，也达不到转换目标地址的目的。    3.所以FullNAT的存在就弥补了SNAT和DNAT的缺点FullNAT的地址转换原理：    如下图示FullNAT实验：    FullNAT的实验原理和SNAT,DNAT,PORTNAT实验方式一样，这里就不做演示了</code></pre><p><img src="/2018/10/10/iptables之FORWARD和NAT/" alt="FullNAT原理"></p><h3 id="MASQUERADE"><a href="#MASQUERADE" class="headerlink" title="MASQUERADE"></a>MASQUERADE</h3><pre><code>只能作用在POSTROUTING链上，对SNAT的缺点弥补外网地址是动态的就用MASQUERADE,如果是静态的就用SNAT；因为MASQUERADE会消耗更多的系统资源，能用SNAT就用SNAT，特殊场景才使用MASQUERADE</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;iptables/netfilter网络防火墙：&lt;br&gt;        在FORWARD链上定义规则，注意以下几个问题：&lt;br&gt;            (1) 请求-响应均经由FORWARD链，要注意规则的方向性；&lt;br&gt;            (2) 如果可以启用conntrack机制，建议将双方向的状态为ESTABLISHED的报文直接放行；&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="iptables" scheme="https://www.liukui.tech/categories/iptables/"/>
    
    
      <category term="iptables防火墙" scheme="https://www.liukui.tech/tags/iptables%E9%98%B2%E7%81%AB%E5%A2%99/"/>
    
  </entry>
  
  <entry>
    <title>iptables</title>
    <link href="https://www.liukui.tech/2018/10/06/iptables/"/>
    <id>https://www.liukui.tech/2018/10/06/iptables/</id>
    <published>2018-10-06T00:00:00.000Z</published>
    <updated>2018-12-25T13:30:05.134Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/10/06/iptables/doubi.jpg" alt=""></p><p>iptables的处理逻辑和命令</p><ul><li><p>对于防火墙而言，原理和设置规则尤其重要，了解原理意味着清楚防火墙是如何在数据报文的必经之路上进行规则限制即iptables的处理逻辑；</p></li><li><p>规则意味着iptables是如何通过命令和各种选项进行规则编写的</p></li></ul><p>对于防火墙而言，原理和设置规则尤其重要，原理意味着怎么对数据报文的走向进行规则限制，规则</p><a id="more"></a><h3 id="Linux防火墙"><a href="#Linux防火墙" class="headerlink" title="Linux防火墙"></a>Linux防火墙</h3><p>防火墙的概念<br>iptables的基本认识<br>iptables的组成:iptables的处理逻辑<br>iptables的基本语法<br>iptables之forward的概念<br>iptables之地址转换法则<br>SNAT源地址转换的具体实现<br>DNAT目标地址转换的具体实现</p><p>不理解的地方：5个表的优先级和规则的优先级<br>什么是显示扩展和隐式扩展</p><p>iptables的处理逻辑和命令</p><ul><li><p>对于防火墙而言，原理和设置规则尤其重要，了解原理意味着清楚防火墙是如何在数据报文的必经之路上进行规则限制即iptables的处理逻辑；</p></li><li><p>规则意味着iptables是如何通过命令和各种选项进行规则编写的</p></li></ul><h3 id="安全技术："><a href="#安全技术：" class="headerlink" title="安全技术："></a>安全技术：</h3><pre><code>防火墙：    防范非授权网络访问；隔离功能，工作在网络或主机边缘，对进出网络或主机的数据包基    于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一组功能的组件，    基本上的实现都是默认情况下关闭所有的通过型访问，只开放允许访问的策略入侵检测机制和管理系统：    当病毒或者网络攻击绕过防火墙进入系统后的入侵检测机制，告知管理员采取手段提供有针对性的指导措施和安全决策依据。杀毒软件：病毒入侵后的防御软件入侵防御系统：    入侵检测系统检测到网络攻击或者病毒时，通过入侵防御系统进行准确的分析判断，    在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般采用在线部署方式</code></pre><h3 id="防火墙作用："><a href="#防火墙作用：" class="headerlink" title="防火墙作用："></a>防火墙作用：</h3><pre><code>作用：数据报文发到服务器的以太网卡的二种访问行为1.linux中，数据报文从服务器的以太网卡经过内核空间走一遭，不与用户空间交互，再从网卡出去，穿墙而过2.或者数据报文达到网卡，到达内核空间，进而与本地用户空间的进程进行通讯，大多数网络通讯发生的目标所在，如httpd的访问，vsftp通讯，ssh通讯究竟数据报文会以哪种方式怎么选择，会根据主机内部的路由表来选择，内核从网卡拿到请求报文，对linux而言tcp/ip协议栈是在内核中意味着报文的处理是在内核中处理的，也就是说防火墙必须工作在内核中，防火墙必须在内核中完成tcp/ip报文所流进的位置，用规则取检查，才能真正工作起来；根据内核的网络协议栈处理逻辑，会先拆除IP层的封装，获取到目标IP，如果是则拆除ip地址的首部封装，获取传输层封装(传输层的tcp的源端口，目标端口，几个标记位等信息；)这里所说端口是指进程地址，防火墙通常是在这个地方做限制的，只有通过防火墙设置的规则，才能进而与用户空间的应用程序进行数据报文的传输.</code></pre><p>这里就要说到网络间的主机通信过程了：<br>如：主机A–&gt;R1路由—&gt;R2路由—&gt;R3路由–&gt;主机B的过程：<br>怎么知道报文是从哪到哪的？<br>在整个网络中，主机A发往主机B的数据报文是一般是经过很多路由转发才到达主机B的<br>而主机A上只会标记出报文的源IP:sipA，目标IP：dipB<br>因为要经过很多路由，所以主机A到达下一个路由设备的时候会在报文的最外层加一层以太网帧首部<br>标记出源MAC(主机A)和目标MAC(R1路由Mac)，将数据报文送到R1，R1会拆除外层的以太网帧头部<br>信息，R1看到目标IP不是自己，则会选择将数据报文继续转发R2，此时数据报文则又被封装源MAC(R1的MAC)和目标MAC(R2的MAC),到达R2，R2则继续拆封以太网帧头部，发现目标IP不是自己，则继续封装以太网帧首部转发出去，最终到达主机B，主机B拆封以太网帧首部，看到目标IP是自己，则继续拆分传输层TCP首部，应用层等进行数据的交换<br>这就是为什么数据报文会从主机A成功发送到主机B上去，在数据报文传输的过程中，IP首部的信息不会变，而MAC层首部会连续换很多次！</p><p>真正通信的不是主机而是主机内的进程，数据报文中还会标识出是从主机A的哪个地址，发往主机B<br>的哪个地址，这里的地址就是端口，而端口(2^16-1=65535,0是)则是动态分配的，<br>当原主机上的端口在进行通信的时候，会临时向内核申请端口：叫端口注册，这个端口叫源端口，<br>而目标端口则是如httpd80;ssh22端口，这些服务的端口是固定的，必须有一端的端口是固定的，<br>否则无法进行通讯，当主机B真正收到数据报文时，拆分IP首部后，则会看到传输层信息，看到端口<br>信息，主机B根据那个服务在内核注册的端口信息，将数据报文交给注册端口的这个服务，即交给用户空间的这个服务对应的进程，比如http继续看到httpd的首部，这个过程是在不是在内核空间处理<br>的，而是在用户空间的进程上处理的</p><p>所以这里就会发现在linux内，tcp的五层模型的前四层物理层 数据链路层 网络层 传输层这些<br>都是内核空间处理的，叫传输子网，因为都是在内核中完成的，使用的都是是公共资源模块，为了避免程序员造轮子，把公共资源模块做成了库*.so文件<br>只有应用层是在用户空间处理的，由客户端的浏览器等封装的，叫资源子网的组成部分</p><p>而数据报文达到内核中拆分IP头信息后看到目标IP不是自己，因为主机一般不会作为路由器来使用的，所以数据报文则会被丢弃，但是主机都有核心转发功能，如果核心转发功能是开启的forward,<br>则会查本机的路由表，将数据报文转发能到达目标主机的下一个设备，则数据报文在本机的内核中<br>绕一圈被转发出去</p><h3 id="主机防火墙和网络防火墙"><a href="#主机防火墙和网络防火墙" class="headerlink" title="主机防火墙和网络防火墙"></a>主机防火墙和网络防火墙</h3><pre><code>所以防火墙的防火功能则是数据报文的必经之路上放上所谓的墙，其实就是iptables很多规则，只有墙上事先设置的白名单规则，数据报文才允许经过，其他的报文则都被丢弃。前面说的是单台主机上的防火墙：主机防火墙然而在一个大的局域网内，通常会有一个大的网络防火墙，因为局域网内的数据报文都是经由网络防火墙的,负责整个网络的防护机制</code></pre><h3 id="硬件防火墙和软件防火墙"><a href="#硬件防火墙和软件防火墙" class="headerlink" title="硬件防火墙和软件防火墙"></a>硬件防火墙和软件防火墙</h3><pre><code>硬件防火墙：实现逻辑：专业的硬件级防护设备 非通用CPU    一般电脑上的CPU可以处理很多软件，而    使用的专业CPU，只负责管理防火这类的功能    通用CPU：可以完成诸多的功能软件防火墙：    通过特殊的防火软件来实现而单纯的硬件防火墙一般是达不到防火目的的，纯软件却可以达到防火目的，一般都是软硬件一起来实现防火目的的</code></pre><p>网络防火墙:检测TCP协议的下4层的协议报文(传输层极其以下的层数)<br>应用层防火墙：只是适用于某种服务和协议</p><h3 id="linux上的防火墙实现"><a href="#linux上的防火墙实现" class="headerlink" title="linux上的防火墙实现"></a>linux上的防火墙实现</h3><pre><code>linux的防火墙是模仿OpenBSD实现的防火墙    1.传软件实现    2.内核级实现的，只负责TCP协议的下4层的协议报文(传输层极其以下的层数)中工作和防护    也就是在前文所说的传输子网上进行工作和防护的</code></pre><p>内核级的防火机制：<br>在数据报文经过的路径上仔细选择5个钩子：hook，因为是必经之地，所以每个通过的报文都会<br>被hook勾住，然而这里只设置了hook，而没有设置规则，这些规则是由主机的管理员来设置的<br>只有满足设置的规则的数据报文才允许通过<br>当然这个hook不单单是防火功能，有时把经过的数据报文勾起来，修改它的目标地址源地址<br>信息，这个功能叫地址转换，NAT<br>所以对linux而言，防火墙的功能不单单是防火这一个功能，还包括地址转换，报文修改和<br>连接追踪的关闭等几项功能</p><h3 id="Netfilter框架的组成和负责的功能"><a href="#Netfilter框架的组成和负责的功能" class="headerlink" title="Netfilter框架的组成和负责的功能"></a>Netfilter框架的组成和负责的功能</h3><p>Netfilter只是内核级的framework<br>通过系统调用实现：syscall:iptables<br>由5个钩子基本实现了linux的防火墙<br>而这5个hook统称netfilter,只是内核中的一个框架framework，hook只是勾住数据报文，规则<br>则由用户管理员添加，只需要在5个hook的位置上添加相应规则即可</p><p>前3个hook是防火功能<br>    input+output+forward<br>        访问本机内部的应用<br>后2个hook:是实现地址转换，报文修改和连接追踪的关闭<br>    prerouting:在进入本机网卡接收队列前的瞬间：路由前<br>    postrouting:由本机发出或者forward转发的离开本机网卡接收队列的瞬间：路由后<br>    而prerouting是不能做过滤的</p><p>三种报文流向：<br>流入的报文：<br>    prerouting–&gt;路由–&gt;input–&gt;进入用户空间进程<br>流出的报文：这里说的流出报文是指由本机主动发出的请求报文<br>    用户空间进程 –&gt;output–&gt;postrouting<br>转发的报文：<br>    prerouting–&gt;forward–&gt;postrouting</p><p>而数据报文是有来有往的，有请求报文就应该有响应报文，所以整个通信的过程报文流向应该是<br>    先流入报文：请求报文<br>        prerouting–&gt;路由–&gt;input–&gt;进入用户空间进程<br>    再出去：响应报文<br>        用户空间进程 –&gt;output–&gt;postrouting<br>转发报文：请求<br>    prerouting–&gt;forward–&gt;postrouting<br>转发报文的：响应<br>    也是prerouting–&gt;forward–&gt;postrouting<br>这里要搞清楚，因为客户端和服务端是相对的，进来的都是prerouting出去的都是postrouting</p><p>而请求和响应的数据报文，因为方向不同，数据报文内封装的源IP+端口和目标IP+端口是相反的<br>客户端和服务端则是相对的，转发报文也是类似的，也是有来有往的<br>而为了服务器资源来说，如果要阻止报文，控制的是请求报文而非响应报文</p><h3 id="什么是iptables？"><a href="#什么是iptables？" class="headerlink" title="什么是iptables？"></a>什么是iptables？</h3><h3 id="实现规则的工具iptables和firewalld"><a href="#实现规则的工具iptables和firewalld" class="headerlink" title="实现规则的工具iptables和firewalld"></a>实现规则的工具iptables和firewalld</h3><p>因为Netfilter只是框架，规则由用户来设置，而Netfilter是内核中的，用户是无法直接与内核<br>进行交流的，所以linux创建了一个在用户空间的工具iptables,iptables是一个规则编辑器，<br>能调用内核级的Netfilter的系统调用接口，把写的规则送到内核上的hook上，并立即生效，而<br>内核的数据是保存在内存中的，关机则会丢失定义好的规则，要想规则永久生效，就需要保存在<br>系统reboot时自动加载的文件中，或者由启动的软件间接调用这个规则文件(iptables-server).</p><p>而ipfirewall–&gt;ipchains–&gt;iptables–&gt;nfstables</p><p>iptables是工作在网络层，可以通过隐式扩展工作在传输层，通过显示扩展的string工作在应用层<br>但是不能识别应用层http协议，ftp协议的请求方法，可以识别报文中的字串</p><h3 id="iptables的组成"><a href="#iptables的组成" class="headerlink" title="iptables的组成"></a>iptables的组成</h3><p>iptables由五个表和五个链以及一些规则组成</p><pre><code>五个表table：filter、nat、mangle、raw、securityfilter表：过滤规则表，根据预定义的规则过滤符合条件的数据包nat表：network address translation 地址转换规则表mangle：修改数据标记位规则表raw：关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度security：用于强制访问控制（MAC）网络规则，由Linux安全模块（如SELinux）实现优先级由高到低的顺序为:security --&gt;raw--&gt;mangle--&gt;nat--&gt;filter</code></pre><p>如果把规则放在input和output上称为主机防火墙，只防护当前主机内部的进程是如何访问的</p><h3 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h3><p>netfilter内核级的框架，内核framework，过滤器<br>syacall：iptables工具，管理规则：</p><p>centos7上：默认安装firewall<br>    系统内自带的前端工具firewall;默认启用，建议关闭或卸载即可<br>        firewalld:系统守护进程，firewall-cmd<br>    在真正的防火墙管理时，建议用iptables来管理的<br>        iptables：<br>    保存iptabels规则的命令包<br>        iptables-services 需要自己手动安装<br>        用iptables-save restore管理加载事先设定好的防火墙规则即可</p><h3 id="Netfilter表和链对应关系"><a href="#Netfilter表和链对应关系" class="headerlink" title="Netfilter表和链对应关系"></a>Netfilter表和链对应关系</h3><p><img src="/2018/10/06/iptables/" alt="Netfilter表的优先次序"></p><p>报文流向：</p><pre><code>* 流入报文路径：到本机内部* 流出报文路径：由本机发出* 转发报文路径：转发</code></pre><p>tables <--> chains链:在通过iptables引用是是需要大写的</--></p><pre><code>* filter: INPUT,FORWARD,OUTPUT只有3个链* nat: PREROUTING,INPUT,OUTPUT,POSTROUTING 4个链* mangle: PREROUTING,INPUT,FORWARD,OUTPUT,POSTROUTING* raw: PREROUTING,OUTPUT</code></pre><p>就算filter和nat上都在同一个input链上，因为不属于一个table的，规则是各自生效的<br>那么input上同时有filter和nat表的规则时，则是有优先级的</p><p>为了实验，要先关闭firewalld设置开机不启动<br>systemctl stop firewalld<br>systemctl disabled firewalld<br>systemctl is-enabled firewalld</p><p>规则顺序很重要<br>因为有些规则具有一票否则权比如drop，一旦报文匹配到drop规则，后面的规则都不看<br>因为有些规则具有一票否则权比如accept，一旦报文匹配到drop规则，即使后面有drop也无效<br>从这两条来说<br>把检查条件苛刻的规则放前面<br>规则调用的模块化管理：自定义链，由主链取调用才会生效，删除或更改时方便管理</p><h3 id="iptables的命令使用格式"><a href="#iptables的命令使用格式" class="headerlink" title="iptables的命令使用格式"></a>iptables的命令使用格式</h3><p>获取帮助：<br>                    CentOS 7：man iptables-extensions<br>                    CentOS 6：man iptables</p><p>规则的编写格式：<br>iptables [-t table] COMMAND chain [rulesnum][-m matchname [per-match-options]] [-j targetname [per-target-options]]<br>表–&gt;命令–&gt;chain–&gt;对链</p><pre><code>-t table：    默认为filter；其它可用的有raw, mangle, nat；子命令COMMAND:        管理链：            -P：policy，策略，定义链的默认策略； 一般有两种选择，ACCEPT和DROP；            -N：new，新建一条自定义的规则链；被内建链上的规则调用才能生效；[-j  chain_name]；            -X：drop，删除自定义的、空的、或者引用计数为0的空链；            -F：flush，清空指定的链；            -E：重命名引用计数和为0的自定义链；            -F：flush, 清空整条链            -Z：zero，计数器置零；改为零                 iptables的每条规则和每个链都有专用的两个计数器：                 每一个规则所匹配到的报文数量个数：pkts                 和体积计数器之和：bytes        管理规则：增删改、插入            -A：append，追加，在指定链的尾部追加一条规则；            -I：insert，插入，在指定的位置（省略位置时表示链首）插入一条规则；            -D：delelte，删除，删除指定的规则；            -R：replace，替换，将指定的规则替换为新规则；不能仅修改规则中的部分，而是整条规则完全替换；        查看：链上查看规则的动作，属于action的一种            -L：list，列出表中的链上的规则；                -n：numeric，以数值格式显示；                -v：verbose，显示详细格式信息；                     -vv, -vvv                -x：exactly，计数器的精确结果；                --line-numbers：显示链中的规则行号；        重置规则计数器：            -Z：zero，置0；        计数器：            规则，以及默认策略有专用的计数器；            记录被当前规则所匹配到的：                (1) 报文个数；                (2) 字节总数；chain：    (1) 内建链；INPUT OUTPUT FORWARD PREROUTING POSTROUTING    (2) 自定义链；匹配条件：matchname    多重条件：逻辑关系为“与”；    检查报文：        TCP或UDP首部：源端口、目标端口、标记为ACK           FSM: 有限状态机:TIME_WAIT,监听状态等        IP首部: SIP，DIP        MAC首部：MAC地址 将防火墙规则保存下来    iptables-save &gt; /tmp/iptables-rules.v0.1    iptables-restore &lt; /tmp/iptables-rules.v0.1开机自动加载iptables规则    yum install iptables-services -y    规则的保存和永久生效：    将iptables保存在文件    iptables-save    iptables-restore     iptables-server的service脚本    保存在/etc/sysconfig/iptables中，开启启动自动加载    firewalld,firewalld-cmd是不能调用iptables定义的规则，用iptables-server    必须先安装，不能并行    匹配条件又分为：通用匹配和扩展匹配    通用匹配条件：        5种检查方式：源 目标 协议 流入 流出         [!] -s, --sip,--source-ip报文源地址            其值可以是单个IP，或者连续IP，可以是网络地址，不能是离散的地址        [!] -d, --destination address[/mask][,...]：检查报文中的目标IP地址是否符合此处指定的地址或范围；        [!] -i, --in-interface name：数据报文从哪个网卡接口进入；            PREROUTING，INPUT, FORWARD            因为-i是数据报文流入的选项；            所以-i选项只能上面这三个链有关,用在前半部分相关的链上        [!] -o, --out-interface name：数据报文从哪个网卡接口出去；             FORWARD, OUTPUT POSTROUTING            同理因为-o是数据报文流出的选项；            所以-o选项只能上面这三个链有关,用在后半部分相关的链上        [!] -p, --protocol protocol：四层协议                tcp|udp|icmp|sctp    这也是为什么iptables叫网络防火墙的原因，正常的工作只能工作在网络层，    检查网络层属性，但是-i -o和网络层属性没关系，和网络层下面的协议有关    正常情况下，网络防火墙是用来检查网络层首部来获得相关信息的    扩展匹配条件：又分为隐式扩展和显示扩展        /lib/modules/$(uname -r)/net/netfilter/下xt开头的就是扩展模块            默认没有载入到内核中，只有当用时才加载的，就叫隐式扩展        netfilter为了做深入的条件检查，通过特定的模块来实现检查功能        隐式扩展：不用-m选项指出matchname即可使用此match的专用选项进行匹配；            -p tcp：隐含了-m tcp；                [!] --source-port,--sport port[:port]                    匹配报文中传输层的源端口；                    可以使用单个端口或者连续端口，但是不能使用离散端口                [!] --destination-port,--dport port[:port]、                    匹配报文中传输层的目标端口；                    可以使用单个端口或者连续端口，但是不能使用离散端口                    端口也只有2^16-1=65535个端口                [!] --tcp-flags mask comp                    SYN，ACK，FIN，RST，URG，PSH；                        mask：要检查的标志位列表，以逗号分隔；                    comp：必须为1的标志位列表，余下的出现在mask列表中的标志位则必须为0；                                            --tcp-flags  SYN,ACK,FIN,RST SYN                        如果只定义SYN则代表tcp握手的第一次，一般只检查第一次                        如果定义的是SYN，ACK代表tcp握手的第二次                        如果是ACK，则代表tcp的正常通信过程                [!] --syn：因为检查tcp握手的第一次比较常用                    所以系统内就设置这个选项代表下面这个选项                    相当于--tcp-flags  SYN,ACK,FIN,RST  SYN             -p udp：隐含了-m udp：                [!] --source-port,--sport port[:port]：匹配报文中传输层的源端口；                [!] --destination-port,--dport port[:port]：匹配报文中传输层的目标端口；            -p icmp：隐含了-m icmp:互联控制消息协议                 [!] --icmp-type {type[/code]|typename}                    icmp是有状态的                    8：echo-request                    0：echo-reply        显式扩展：必须使用-m选项指出matchname，有的match可能存在专用的选项；                显示扩展能帮我们更灵活的设置控制规则            获取帮助：                CentOS 7：man iptables-extensions                CentOS 6：man iptables            1、multiport扩展                以离散或连续的方式定义多端口匹配条件；                离散最多为15个，以冒号隔开的算一个，所以连续的端口用冒号隔开                 [!] --source-ports,--sports port[,port|,port:port]...：指定多个源端口；                 [!] --destination-ports,--dports port[,port|,port:port]...：指定多个目标端口；                 [!] --ports port[,port|,port:port]...：指定多个端口；            2、iprange扩展：连续的地址集                以连续的ip地址范围指明连续的多地址匹配条件；                [!] --src-range from[-to]：源IP地址；                [!] --dst-range from[-to]：目标IP地址；            3、set扩展：定义离散地址集                如果要开放的地址既不是连续的，也不是网络地址就需要使用set了                set依赖于ipset命令行工具；需要用ipset先定义一个地址集，                再用set调用地址集即可；需要先安装ipset安装包                yum install ipset ，重启iptables服务                set存在类型，常用的有两个：                    hash:net 网络地址的集合：两个网段剧哦多个网段                    hash:ip  IP地址的集合：离散地址集                使用方式：                    先创建集合：ipset create NAME TYPE( hash:ip/hash:net)                    向集合添加元素：ipset add NAME ELEMENT                set再调用                    --match-set  NAME src                    --match-set  NAME dst            4、string扩展：字串匹配，                借助string扩展，iptables把触角伸到了应用层                对报文中的应用层数据做字符串匹配检测；                [!] --string pattern：要检测字符串模式；                [!] --hex-string pattern：要检测的字符串模式，16进制编码；                --algo {bm|kmp} 2组比较算法            5、time扩展                根据报文到达的时间与指定的时间范围进行匹配度检测；                --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：起始日期时间；                --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：结束日期时间；                --timestart hh:mm[:ss]                --timestop  hh:mm[:ss]                [!] --monthdays day[,day...]                [!] --weekdays day[,day...]                --kerneltz：使用内核中配置的时区                ~]# iptables -I INPUT -d 172.16.100.67 -p tcp --dport 23 -m time --timestart 09:00:00 --timestop 18:00:00 --weekdays Tue,Thu,Sat -j ACCEPT            6、connlimit扩展                根据每客户端IP做并发连接数匹配；                --connlimit-upto n：连接数数量小于等于n，此时应该允许；                --connlimit-above n：连接数数量大于n，此时应该拒绝；                ~]# iptables -A INPUT -d 172.16.100.67 -p tcp --dport 23 -m connlimit --connlimit-upto 2 -j ACCEPT            7、limit扩展                基于收发报文的速率进行匹配；                --limit rate[/second|/minute|/hour|/day]：平均速率                --limit-burst number：峰值速率            8、state扩展                状态检测；连接追踪机制（conntrack）；                 INVALID：无法识别的状态；                  ESTABLISHED：已建立的连接；                 NEW：新连接；                  RELATED：相关联的连接；                 UNTRACKED：未追踪的连接；                nf_conntrack内核模块；记忆是由内核空间的conntrack模块实现的                    追踪到的连接：/proc/net/nf_conntrack文件中；                    能追踪的最大连接数量定义在：/proc/sys/net/nf_conntrack_max                        此值可自行定义，建议必要时调整到足够大；                    不同的协议的连接追踪的时长：                        /proc/sys/net/netfilter/                [!] --state STATE                如何开放被模式的ftp服务：                     (1) 装载追踪ftp协议的模块；                        # modprobe nf_conntrack_ftp                    (2) 放行命令连接                        ~] # iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT                        ~] # iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state NEW -j ACCEPT                    (3) 放行数据连接                        ~] iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state RELATED -j ACCEPT        处理动作（目标）            -j targetname [per-target-options]             targetname：            简单：                ACCEPT：接受；                DROP：丢弃；                    被请求的服务器数据报文丢弃了，请求端需要等待时间会消耗服务端和客户端资源            扩展：                REJECT：--reject-with:icmp-port-unreachable默认                    拒绝；适用内网，直接弹回报文请求                RETURN:当被调用的自定义链上没有规则则自动返回主链继续匹配;                REDIRECT：端口重定向                SNAT：源地址转换                DNAT：目标地址转换                MASQURADE:地址伪装                LOG：日志                自定义链：可以先定义自定义链，再通过主链调用，                当自定义链被引用时，需要先删除引用，再清空自定义链，然后再删除</code></pre><p>每个表对应控制的链，各不相同，记住对应关系<br>网络层<br>tcp协议的头部信息 2btye 2^16-1（0表示通用）<br>2个半连接*2<br>这里因为有两个半连接，请求和回应报文，<br>所以防火墙要设置input接收请求和output回应报文，<br>开启接收请求关闭回应报文，对方也是无法接收到回应报文的</p><h3 id="生产环境下如何设置防火墙？："><a href="#生产环境下如何设置防火墙？：" class="headerlink" title="生产环境下如何设置防火墙？："></a>生产环境下如何设置防火墙？：</h3><pre><code>1.因为生产环境下，被管理的主机不在本地或者在其他省份，我们是通过ssh远程连接管理的!2.防火墙规则一般是要设置白名单的，而默认策略是需要设置为DROP或者REJECT，这时，如果    不先把SSH或者VNC先设置白名单，我们就无法管理了！那就是给自己找麻烦了3.所以要先为SSH服务设置白名单，再设置默认策略为DROP或者REJECT！！！4.默认策略可以用-P设置，也可以用自定义策略；自定义策略的好处5.防火墙的检查机制,是按照顺序从上往下一个个匹配，如果最上面的一旦匹配即使下面有更    严格的条件，也会不生效，所以我们应该把检查严格的条件放到检查宽松的上面    比如：string检查规则(具体看示例)等</code></pre><h3 id="iptables的使用规范"><a href="#iptables的使用规范" class="headerlink" title="iptables的使用规范"></a>iptables的使用规范</h3><pre><code>iptables -F 即清空filter表的所有链，因为默认是filter表iptables -F INPUT，清空filter表上的INPUT链的所有规则定义防火墙要设置白名单极端清空下所有链都是drop的如果主机有多个网卡，当网关来用的时，forward链就是用来当网络防火墙来用的    规则优化：    (1) 注意规则的优先顺序，检查严格的放到前面，    (1) 可安全放行所有入站及出站，且状态为ESTABLISHED的连接；    (2) 服务于同一类功能的规则，匹配条件严格的放前面，宽松放后面；    (3) 服务于不同类功能的规则，匹配报文可能性较大扩前面，较小放后面；    (4) 设置默认策略；        (a) 最后一条规则设定；        (b) 默认策略设定；</code></pre><h5 id="隐式扩展示例："><a href="#隐式扩展示例：" class="headerlink" title="隐式扩展示例："></a>隐式扩展示例：</h5><pre><code>隐式扩展示例1：SSH服务    因为是ssh连接的，如果要设置默认策略为DROP，就一定要先开启SSH服务的请求和回应    iptables -A INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 22 -j ACCEPT    再设置默认INPUT链策略为DROP：两种写法：下文会表示自定义链的写法好处    iptables -P INPUT -j REJECT 设置默认策略是拒绝    或者用自定义写法：    iptables -t filter -A INPUT -j REJECT，定义流入的默认策略iptables -A OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 22 -j ACCEPTiptables -t filter -A OUTPUT -j REJECT(代替默认策略的写法)设置自定义白名单的好处：    必要时，所有规则都可以通过自己明确给定的规则来定义    可以写一个脚本把自定义规则写进去，执行后就可以不受控于默认策略因为管理的主机不在本地，如果再修改iptables规则时，把ssh也拒绝了，那么就有很大问题可以把规则写在一个脚本里，在任务计划里创建一个清空防火墙规则的命令即使脚本里的规则把自己拒绝了，可以等任务计划执行后，就可以登进去了，易于控制隐式扩展示例2：http服务    在会前基础上开放80端口的访问    iptables -I INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 80 -j ACCEPT    iptables -I OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 80 -j ACCEPT隐式扩展示例3：lo网卡    将127.0.0.1设置不受控    在之前的基础上ping 127.0.0.1是受控的    之前的iptables -t filter -P INPUT DROP，是将0.0.0.0到0.0.0.0都拒绝了    本地127.0.0.1也被拒绝了，所以稍微修改为非lo网卡受控，lo网卡即不受控了        iptables -R INPUT 3 ! -i lo -j REJECT        iptables -R OUTPUT 3 ! -o lo -j REJECT隐式扩展示例4：-p icmp的隐式扩展；ping请求如何设置当前主机可以ping其他主机，加在最后一条的前面    在之前的基础上此时主机主动ping其他主机也是受控的    icmp是有类型的,见下图，8 echo-request;  0 echo reply    iptables -I OUTPUT 3 -p icmp --icmp-type 8 -j ACCEPT    iptables -I INPUT 3 -p icmp --icmp-type 0 -j ACCEPT隐式扩展示例5：DNS -p udp    如何设置开放本机可以通过DNS解析域名    从本机出去，到达互联的DNS服务器，再接收回应的报文    iptables -I OUTPUT -p udp --dport 53 -j ACCEPT 出去的报文    iptables -I INPUT -p udp --sport 53 -j ACCEPT 回来的报文</code></pre><h5 id="自定义链的使用示例-N-E-X-F"><a href="#自定义链的使用示例-N-E-X-F" class="headerlink" title="自定义链的使用示例(-N -E -X -F)"></a>自定义链的使用示例(-N -E -X -F)</h5><p>以在自定义链中加入samba服务为例</p><pre><code>-N：新建一条自定义的规则链只不过在自定义链上是由计数器的iptables -N new_rules 新建自定义链iptables -E new_rules cifs_rules 改自定义链，必须要0引用的，0 references自定义规则链的创建、调用、删除；以在自定义链中加入samba服务;然后主链在调用自定义链为例    先设置入栈的规则        iptables -A cifs_rules -p tcp --dport 139 -j ACCEPT            iptables -A cifs_rules -p tcp --dport 445 -j ACCEPT        iptables -A cifs_rules -p udp --dport 137:138 -j ACCEPT        iptables -A cifs_rules -j RETURN    还要加一条RETURN规则表示，当cifs_rules规则被主链调用时，如果自定义链上的规则    没有被匹配到，则return到主链上继续匹配主链上的后续规则.在INPUT链去调用自定义链cifs_rules        iptables -I INPUT 5 -s 192.168.34.0/24 -j cifs_rules删除自定义链：需要先删除引用        iptables -D INPUT 5        iptables -F cifs_rules        iptables -X cifs_rules</code></pre><h5 id="显示扩展示例"><a href="#显示扩展示例" class="headerlink" title="显示扩展示例"></a>显示扩展示例</h5><p>必须使用-m选项指出matchname，有的match可能存在专用的选项</p><pre><code>显示扩展示例1：multiport扩展 --多端口匹配将21 22 80 139 445一起开启允许访问：iptables -I INPUT -p tcp -m multiport --dports 21:22,80,139,445 -j ACCEPTiptables -I OUTPUT -p tcp -m multiport --sports 21,22,80,139,445 -j ACCEPT显示扩展示例2： ip-range:必须是连续的范围允许ping的主机为192.168.34.100-192.168.34.106段的IP地址：iptables -I INPUT 3 -p icmp --icmp-type 8 -m iprange --src-range 192.168.34.100-192.168.34.106 -j ACCEPTiptables -I OUTPUT 3 -p icmp --icmp-type 0 -m iprange --dst-range 192.168.34.100-192.168.34.106 -j ACCEPT显示扩展示例3：set扩展    ipset先定义地址集:        ipset create allowpinghosts hash:ip  --先定义IP地址集        ipset add allowpinghosts 192.168.34.107 --向地址集添加IP地址    set再调用地址集：    iptables -I INPUT 4 -p icmp --icmp-type 8 -m set --match-set allowpinghosts src -j ACCEPT    iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m set --match-set allowpinghosts dst -j ACCEPT显示扩展示例4：string扩展：字串匹配    比如：控制httpd服务的报文带有sex字串的都拒绝进入和访问    事先构建一个带有sex字串的html文件，然后设置规则    （因为这个规则比较严格，所以记得要放到允许访问httpd规则的前面！）    iptables -I INPUT -p tcp --dport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT    iptables -I OUTPUT -p tcp --sport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT显示扩展示例5：time扩展</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/10/06/iptables/doubi.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;iptables的处理逻辑和命令&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对于防火墙而言，原理和设置规则尤其重要，了解原理意味着清楚防火墙是如何在数据报文的必经之路上进行规则限制即iptables的处理逻辑；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;规则意味着iptables是如何通过命令和各种选项进行规则编写的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于防火墙而言，原理和设置规则尤其重要，原理意味着怎么对数据报文的走向进行规则限制，规则&lt;/p&gt;
    
    </summary>
    
      <category term="iptables" scheme="https://www.liukui.tech/categories/iptables/"/>
    
    
      <category term="iptables防火墙" scheme="https://www.liukui.tech/tags/iptables%E9%98%B2%E7%81%AB%E5%A2%99/"/>
    
  </entry>
  
  <entry>
    <title>Docker</title>
    <link href="https://www.liukui.tech/2018/06/18/Docker/"/>
    <id>https://www.liukui.tech/2018/06/18/Docker/</id>
    <published>2018-06-18T00:00:00.000Z</published>
    <updated>2019-01-05T02:54:53.887Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p><code>什么是容器</code>：<a href="https://www.redhat.com/zh/topics/containers/whats-a-linux-container" target="_blank" rel="noopener">容器技术</a></p><h5 id="Docker-Image"><a href="#Docker-Image" class="headerlink" title="Docker Image"></a>Docker Image</h5><p><img src="/2018/06/18/Docker/" alt="docker image原理和文件系统机制"></p><font size="3" color="#FF0000"><br>docker image是docker贡献给容器极具创造性的使用方式！<br>分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！<br></font><ul><li>1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器<br>  采用分成构建机制，最底层为bootfs,其之为rootfs<blockquote><p>1.bootfs：用于系统引导的文件系统，包括bootloader和kernel，容器启动完成后会被卸载以节约内存资源；</p></blockquote></li></ul><pre><code>docker image 相关命令    docker imges:镜像的管理命令    ls： 查看本地所有的镜像列表    build:    import:    inspect: 查看下载/创建的镜像详细信息            可以查看下载的某个镜像的具体信息                    如：CMD:镜像启动默认运行的命令                        Volume:                        network:            下文中构建docker file时这些都可以自定义    load:    prune:    pull：从远程仓库拉取镜像到本地    push: 把本地镜像推到远程的Registry    rm:  docker image rm = docker rmi 删除镜像    tag: 给镜像打标签    save:如何构建docker镜像？    制作镜像的原理：bootfs,rootfs只读，最上层是可写成    镜像仓库    在docker hub上创建仓库并上传：docker pushcontainer：    repository:tags        tags的默认是lasted，不过lasted是原始版，最好不要用</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Docker&quot;&gt;&lt;a href=&quot;#Docker&quot; class=&quot;headerlink&quot; title=&quot;Docker&quot;&gt;&lt;/a&gt;Docker&lt;/h3&gt;&lt;p&gt;&lt;code&gt;什么是容器&lt;/code&gt;：&lt;a href=&quot;https://www.redhat.com/zh/
      
    
    </summary>
    
      <category term="Docker" scheme="https://www.liukui.tech/categories/Docker/"/>
    
    
      <category term="Docker" scheme="https://www.liukui.tech/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>ansible</title>
    <link href="https://www.liukui.tech/2018/03/06/ansible/"/>
    <id>https://www.liukui.tech/2018/03/06/ansible/</id>
    <published>2018-03-05T16:00:00.000Z</published>
    <updated>2018-12-17T07:14:16.667Z</updated>
    
    <content type="html"><![CDATA[<h1 id="运维自动化管理工具之Ansible"><a href="#运维自动化管理工具之Ansible" class="headerlink" title="运维自动化管理工具之Ansible"></a>运维自动化管理工具之Ansible</h1><p><img src="/2018/03/06/ansible/ansible.png" alt=""><br><a id="more"></a></p><h3 id="内容：1-软件发布环境机制优势对比-和-2-ansible的应用"><a href="#内容：1-软件发布环境机制优势对比-和-2-ansible的应用" class="headerlink" title="内容：1.软件发布环境机制优势对比  和   2.ansible的应用"></a>内容：1.软件发布环境机制优势对比  和   2.ansible的应用</h3><p><font color="#FF0000">ansible的相关的文档</font><br>ansible的中文权威指南：<a href="http://ansible.com.cn/" target="_blank" rel="noopener">ansible中文指南</a><br>Github上的ansible-galaxy示例：<a href="http://galaxy.ansible.com" target="_blank" rel="noopener">ansible-galaxy</a></p><p>其他相关运维管理工具使用方法：<br>pssh的使用方法参照链接文章：<a href="https://www.jianshu.com/p/d15b6b8f17a5" target="_blank" rel="noopener">pssh</a><br>saltstack介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">saltstack</a><br>puppet介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">puppet</a></p><pre><code>当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric常用自动化运维工具    PSSH：适用于主机数量很少的环境(基础ssh的key验证)    Ansible:python,Agentless,中小型应用环境(自带代理功能)    Saltstack:python，一般需部署agent，执行效率更高    Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境    Fabric：python，agentless    Chef: ruby,国内应用少    Cfengine    func</code></pre><h3 id="发布更新环境"><a href="#发布更新环境" class="headerlink" title="发布更新环境"></a>发布更新环境</h3><h4 id="灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机"><a href="#灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机" class="headerlink" title="灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)"></a>灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)</h4><pre><code>比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器    而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径     如：     软件路径为:/data/app     正在用的软件版本V1.0：/data/app1.0     更新的软件版本V2.0：/data/app2.0    则需要把删除原来的软链接：/data/app1.0---&gt;/data/app    创建新的软链接：/data/app2.0---&gt;/data/app10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线发布步骤：    1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。    2.从负载均衡列表中移除掉「金丝雀」服务器。    3.升级「金丝雀」应用（排掉原有流量并进行部署）。    4.对应用进行自动化测试。    5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。    6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。A/B Testing    A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。优势与不足：    优势：用户体验影响小，灰度发布过程出现问题只影响少量用户    不足：发布自动化程度不够，发布期间可引发服务中断预发布验证：    新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器灰度发布：    可以基于主机，用户或者业务，又细分为地区，VIP和普通用户</code></pre><h4 id="蓝绿发布：核心：主备两套环境"><a href="#蓝绿发布：核心：主备两套环境" class="headerlink" title="蓝绿发布：核心：主备两套环境"></a>蓝绿发布：核心：主备两套环境</h4><pre><code>定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同     时也升级到新版本主：绿色环境-活动环境：负责对外提供服务，版本：v1.0备：绿色环境-非活动环境：版本：v2.0工作机制：    先把备环境升级v1.0---&gt;v2.0版本，然后上线    把主环境的v1.0版本下线，已经升级的备环境进行替换特点：    蓝绿部署无需停机，并且风险较小.注意事项：    1.需要提前考虑数据库与应用部署同步迁移/回滚的问题    2.蓝绿部署需要有基础设施支持    3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境      和绿色环境有被摧毁的风险.优势与不足：    优势：升级切换和回退速度非常快    不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响</code></pre><h4 id="滚动发布：在灰度发布的基础上进行进一步优化"><a href="#滚动发布：在灰度发布的基础上进行进一步优化" class="headerlink" title="滚动发布：在灰度发布的基础上进行进一步优化"></a>滚动发布：在灰度发布的基础上进行进一步优化</h4><pre><code>定义：    一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式.特点：    1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数.  可以部分部署，例如每次只取出集群的20%进行升级。    2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出优势和不足:    优势：用户体验影响小，体验较平滑    不足：发布和回退时间比较缓慢。         发布工具比较复杂，LB需要平滑的流量摘除和拉入能力滚动发布目前成熟型技术组织所采用的主流发布方式</code></pre><h1 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h1><p><img src="/2018/03/06/ansible/ansible架构.png" alt="ansible架构"></p><h4 id="ansible特性：-最多管理500台主机，更多效率会降低"><a href="#ansible特性：-最多管理500台主机，更多效率会降低" class="headerlink" title="ansible特性：-最多管理500台主机，更多效率会降低"></a>ansible特性：-最多管理500台主机，更多效率会降低</h4><pre><code>1.模块化：调用特定的模块，完成特定任务   -类似linux中的小命令2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块3.支持自定义模块4.基于Python语言实现5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务)6.安全，基于OpenSSH7.支持playbook编排任务   -类似于脚本功能，多个脚本的集合成为Roles8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况9.无需代理不依赖PKI（无需ssl）10.可使用任何编程语言写模块11.YAML格式，编排任务，支持丰富的数据结构12.较强大的多层解决方案</code></pre><h3 id="Ansible的学习过程："><a href="#Ansible的学习过程：" class="headerlink" title="Ansible的学习过程："></a>Ansible的学习过程：</h3><pre><code>1.ansible基本命令使用2.ansible常用模块详解，介绍ansible单个命令的使用3.YAML语法介绍4.ansible playbook基础：剧本初体验，类似于写脚本5.playbook中的变量：tags，handlers使用6.plsybook模板：templates7.playbook的条件判断：when8.playbook的字典：with_items9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合</code></pre><p>会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。</p><h3 id="ansible命令执行过程"><a href="#ansible命令执行过程" class="headerlink" title="ansible命令执行过程"></a>ansible命令执行过程</h3><pre><code>ansible命令执行过程1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg2. 加载自己对应的模块文件，如command3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件4. 给文件+x执行5. 执行并返回结果6. 删除临时py文件，sleep 0退出执行状态：(颜色定义在/etc/ansible/ansible.cfg中)    绿色：执行成功并且不需要做改变的操作    黄色：执行成功并且对目标主机做变更    红色：执行失败</code></pre><h3 id="CMDB作用介绍"><a href="#CMDB作用介绍" class="headerlink" title="CMDB作用介绍:"></a>CMDB作用介绍:</h3><pre><code>CMDB:Configuration Management Database 配置管理数据库        将服务器的配置，网络配置写到数据库里CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管理等流程提供准确的配置信息.</code></pre><p>了解更多CMDB可参照文章：<a href="">CMDB</a></p><h2 id="1-ansible基本命令使用"><a href="#1-ansible基本命令使用" class="headerlink" title="1.ansible基本命令使用"></a>1.ansible基本命令使用</h2><h3 id="ansible软件安装：多种安装方法"><a href="#ansible软件安装：多种安装方法" class="headerlink" title="ansible软件安装：多种安装方法"></a>ansible软件安装：多种安装方法</h3><pre><code>1.基于epel源安装：    yum install ansible,非服务，只是一个管理工具2.编译安装：3.Github方式安装：可以同步安装4.pip安装：pip是安装Python包的管理器，类似yum</code></pre><h4 id="ansible的重要-amp-主要文件"><a href="#ansible的重要-amp-主要文件" class="headerlink" title="ansible的重要&amp;主要文件"></a>ansible的重要&amp;主要文件</h4><pre><code>配置文件：    /etc/ansible/ansible.cfg  配置ansible的工作特性    /etc/ansible/hosts  主机清单    /etc/ansible/roles  存放的角色目录程序文件：    /usr/bin/ansible   ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想    /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助    /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台    /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务    /usr/bin/ansible-vault 文件加密工具    /usr/bin/ansible-console 基于Console界面与用户交互的执行工具常用命令：    ansible all --list 查看ansible管理的主机群    ansible all -m &quot;模块名&quot; -a &apos;执行的命令&apos;   用什么模块执行什么命令        all也可以换成定义的--list中组的名字    ansible-playbook -C &apos;*.yml&apos; 对所有主机执行剧本    ansible-plsybook -C -t &apos;标签&apos; &apos;*.yml&apos; 对所有主机执行哪个标签的剧本</code></pre><h4 id="ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法"><a href="#ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法" class="headerlink" title="ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)"></a>ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)</h4><pre><code>支持不分组，分组，等方式    如：        192.168.34.100        [webservers]        192.168.34.101        192.168.34.102        [dbservers]        192.168.34.[1:6]7 (17,27..67)        db[01:100].cenntos.com</code></pre><h4 id="ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）"><a href="#ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）" class="headerlink" title="ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）"></a>ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）</h4><pre><code>配置文件只提供默认值，但可以通过playbook的设置进行覆盖配置文件可以放在/etc/ansible/ansible.cfg中也可以放到一个工作目录下命名为.ansible.cfg[defaults]inventory = /etc/ansible/hosts - 主机列表配置文件library = /usr/share/my_modules/ - 库文件存放目录remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录forks = 5 - 默认并发数sudo_user = root - 默认sudo 用户ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码ask_pass = Trueremote_port = 22host_key_checking = False  -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错[color] 定义ansible命令的执行结果颜色的</code></pre><h3 id="配置文件说明和建议修改的项："><a href="#配置文件说明和建议修改的项：" class="headerlink" title="配置文件说明和建议修改的项："></a>配置文件说明和建议修改的项：</h3><pre><code>local_tmp和remote_tmp：    本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地    家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除.host_key_checking = False -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错module_name = command   -默认使用的命令模块，可以修改成shell    module_name = shell</code></pre><h2 id="2-ansible常用模块详解，介绍ansible单个命令的使用"><a href="#2-ansible常用模块详解，介绍ansible单个命令的使用" class="headerlink" title="2.ansible常用模块详解，介绍ansible单个命令的使用"></a>2.ansible常用模块详解，介绍ansible单个命令的使用</h2><h3 id="ansible模块的使用查询方法"><a href="#ansible模块的使用查询方法" class="headerlink" title="ansible模块的使用查询方法"></a>ansible模块的使用查询方法</h3><pre><code>ansible-doc: 显示模块帮助ansible-doc [options] [module...]    -a 显示所有模块的文档    -l, --list 列出可用模块    -s, --snippet显示指定模块的playbook片段示例：    ansible-doc –l 列出所有功能模块    ansible-doc ping 查看ansible中的ping用法    ansible-doc -s shell 查看shell模块的使用方法</code></pre><h3 id="ansible的常用基本选项"><a href="#ansible的常用基本选项" class="headerlink" title="ansible的常用基本选项"></a>ansible的常用基本选项</h3><pre><code>ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible    端能基于密钥认证的方式联系各被管理节点ansible语法：    ansible &lt;host-pattern&gt; [-m module_name] [-a args]    --version 显示版本    -m module 指定模块，默认为command，主要使用选项    -v 详细过程 –vv -vvv更详细    --list-hosts 显示主机列表，可简写 --list    -k, --ask-pass 提示输入ssh连接密码，默认Key验证    -K, --ask-become-pass 提示输入sudo时的口令    -C, --check 检查，并不执行    -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s    -u, --user=REMOTE_USER 执行远程执行的用户    -b, --become 代替旧版的sudo 切换</code></pre><h3 id="ansible的主机清单表示方法-Host-pattern"><a href="#ansible的主机清单表示方法-Host-pattern" class="headerlink" title="ansible的主机清单表示方法:Host-pattern"></a>ansible的主机清单表示方法:Host-pattern</h3><pre><code>1.All ：表示所有Inventory中的所有主机    如：ansible all -m ping        ansible all --list-hosts列出所有主机清单        ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP2.* :通配符    如：ansible &quot;*&quot; = ansible all        ansible 192.168.34.* 表示34网段的所有IP3.或的关系    如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作        ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作4.与的关系(且)    如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机5.非，取反    如：ansible &apos;websrvs:!dbsrvs&apos;        在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号6.正则表达式    如：ansible &quot;~(web|db).*\.centos\.com&quot; </code></pre><h2 id="ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块"><a href="#ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块" class="headerlink" title="ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)"></a>ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)</h2><h5 id="ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项"><a href="#ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项" class="headerlink" title="ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项"></a>ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项</h5><pre><code>1.Command：在远程主机执行命令，默认模块，可忽略-m选项    可以在ansible.cfg中修改默认模块项    支持：chdir(切换目录)    command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现使用示例：    ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh    ansible all -a &apos;useradd test&apos; 所有主机上创建test用户2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项    支持功能：支持$ &lt; &gt; | ; &amp; 等            chdir 执行前，先切换到该文件夹示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos;        显示appsrvs组的主机名    ansible all -m shell -a &apos;chdir=/data rm -rf *&apos;    先切换到/data目录下，再执行删除命令3.Script: 批量运行脚本    可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理    功能：creates:远程主机的文件存在，则不运行        removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令示例：ansible all -m script -a &quot;/data/test.sh&quot;    ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot;        因为fstab文件存在，则不执行rm -rf /data/*命令    ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot;        因为fstab文件存在，则执行rm -rf /data/*命令4.Copy:从服务器复制文件到目标主机    src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos;    根据自己写的字符串生成文件5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取    src，dest(抓取到本机目录)示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;        将远程主机fstab2文件抓取到本机/data下    如果抓取的是目录，先打包再抓取    打包：ansible all -a &apos;tar cf /root/data.tar /data&apos;     抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;6.File：设置文件属性，创建/删除文件    src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos;     创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos;     删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos;7.Hostname：管理主机名     可以通过后面的变量来实现    a.先在hosts后定义hostname变量名        [centos6]        192.168.34.106 hostname=mini6-2        192.168.34.101 hostname=node6-1         [centos7]        192.168.34.107 hostname=mini7-1    b.再通过hostname模块批量修改        ansible all -m hostname -a &apos;name={{hostname}}&apos;8.Cron：计划任务    支持：minute，hour，day，month，weekday示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate        172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务     ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名     ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名9.Yum：管理包    支持：name,state=(started stopped reloaded restarted),absent    更新缓存：update_cache=yes，示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包      ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包10.Service：管理服务(同一systemctl&amp;service)    name，state(stopped,started,reloaded,restarted) enable(设置开启启动)示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务     ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务     ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务     ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动11.User：管理用户    name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录)示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos;    创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录12.Group：管理组    支持：group,name,gid,system,state=(absent)示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组    ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 </code></pre><h2 id="ansible系列的一些模块-用的不多"><a href="#ansible系列的一些模块-用的不多" class="headerlink" title="ansible系列的一些模块(用的不多)"></a>ansible系列的一些模块(用的不多)</h2><pre><code>简单介绍与了解：ansible-galaxy 互联网上的角色分享ansible-pull      推送命令至远程，效率无限提升，对运维要求较高  Ansible-vault管理yaml文件    功能：管理加密解密yml文件        ansible-vault [create|decrypt|edit|encrypt|rekey|view]        ansible-vault encrypt hello.yml 加密        ansible-vault decrypt hello.yml 解密        ansible-vault view hello.yml 查看        ansible-vault edit hello.yml 编辑加密文件        ansible-vault rekey hello.yml 修改口令        ansible-vault create new.yml 创建新文件Ansible-console</code></pre><h2 id="ansible重要知识之playbook-上面的各种模块的组合"><a href="#ansible重要知识之playbook-上面的各种模块的组合" class="headerlink" title="ansible重要知识之playbook(上面的各种模块的组合)"></a>ansible重要知识之playbook(上面的各种模块的组合)</h2><p><img src="/2018/03/06/ansible/" alt="playbook原理"></p><h3 id="YAML语言（编写playbook的专门语言）"><a href="#YAML语言（编写playbook的专门语言）" class="headerlink" title="YAML语言（编写playbook的专门语言）"></a>YAML语言（编写playbook的专门语言）</h3><pre><code>YAML语法：     在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三    个点号( ... )用来表示档案结尾    次行开始正常写Playbook的内容，一般建议写明该Playbook的功能    使用#号注释代码    缩进必须是统一的，不能空格和tab混用    缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过    缩进结合换行来实现的    YAML文件内容是区别大小写的，k/v的值均需大小写敏感    k/v的值可同行写也可换行写。同行使用:分隔    v可是个字符串，也可是另一个列表    一个完整的代码块功能需最少元素需包括 name: task    一个name只能包括一个task    YAML文件扩展名通常为yml或yaml    List：列表，其所有元素均使用“-”打头    Dictionary：字典，通常由多个key与value构成</code></pre><h2 id="Playbook中的核心元素"><a href="#Playbook中的核心元素" class="headerlink" title="Playbook中的核心元素:"></a>Playbook中的核心元素:</h2><pre><code>1.Hosts 执行的远程主机列表2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远    程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使    用sudo_user指定sudo时切换的用户3.Tasks 任务集4.Varniables 内置变量或自定义变量在playbook中调用5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断8.handlers和notify  </code></pre><h2 id="运行playbook"><a href="#运行playbook" class="headerlink" title="运行playbook"></a>运行playbook</h2><pre><code>运行playbook的方式ansible-playbook &lt;filename.yml&gt; ... [options]常见选项    -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测    --list-hosts 列出运行任务的主机    --limit 主机列表 只针对主机列表中的主机执行    -v 显示过程 -vv -vvv 更详细 备注：    执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误    ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行</code></pre><h3 id="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"><a href="#执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。" class="headerlink" title="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"></a>执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。</h3><h2 id="示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验"><a href="#示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验" class="headerlink" title="示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验"></a>示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验</h2><h4 id="将centos7的httpd-conf复制到centos7主机，6上的配置文件不同"><a href="#将centos7的httpd-conf复制到centos7主机，6上的配置文件不同" class="headerlink" title="将centos7的httpd.conf复制到centos7主机，6上的配置文件不同"></a>将centos7的httpd.conf复制到centos7主机，6上的配置文件不同</h4><pre><code>示例1：写一个安装启动httpd的playbook:install_httpd.yml        包括创建用户，安装httpd包，开启服务，并设置开机启动- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd    - name: copy config      copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf    - name: install package      yum: name=httpd    - name: service      service: name=httpd state=started enabled=yes备注：    执行完通过以下命令判断每个任务都否都执行成功了    1.ansible all -a &apos;getent passwd httpd&apos;    2.ansible all -a &apos;rpm -q httpd&apos;    3..ansible all -a &apos;ss -ntlp|grep 80&apos;示例2：写一个删除上面的playbook:remove_httpd.yml        包括：删除用户，卸载httpd包- hosts: all  remote_user: root  tasks:    - name: del user      user: name=httpd state=absent remove=yes    - name: remove package      yum: name=httpd state=absent备注：    如果只删除特定主机的httpd，而不是全部，需要加--limit选项    ansible-playbook --limit 192.168.34.105 remove_httpd.yml        只限制在192.168.34.105的主机执行</code></pre><h4 id="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"><a href="#上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。" class="headerlink" title="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"></a>上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。</h4><h3 id="handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。"><a href="#handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。" class="headerlink" title="handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。"></a>handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。</h3><pre><code>Handlers:    是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生        变化时，才会采取一定的操作Notify:    此action可用于在每个play的最后被触发，这样可避免多次有改变发生    时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。    在notify中列出的操作称为handler，也即notify中调用handler中定义的操作</code></pre><h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><pre><code>示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200）- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted 备注：停止并删除用户和安装包    ansible all -a &apos;service memcached stop&apos;    ansible all -a &apos;ss -ntl&apos;    ansible all -a &apos;rpm -q memcached&apos;    ansible all -a &apos;getent passwd memcached&apos;</code></pre><h3 id="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"><a href="#可以多个notify对应一个handlers，也可以多个motify对应多个handlers" class="headerlink" title="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"></a>可以多个notify对应一个handlers，也可以多个motify对应多个handlers</h3><pre><code>示例4：多个notify对应一个handlers- hosts: websrvs  remote_user: root  tasks:    - name: Install httpd      yum: name=httpd state=present    - name: Install configure file      copy: src=files/httpd.conf dest=/etc/httpd/conf/      notify: restart httpd  第一个notify    - name: ensure apache is running      service: name=httpd state=started enabled=yes      notify: restart httpd  第二个notify  handlers:      - name: restart httpd   对应一个handlers      service: name=httpd status=restarted</code></pre><h3 id="示例5：多个notify对应多个handlers"><a href="#示例5：多个notify对应多个handlers" class="headerlink" title="示例5：多个notify对应多个handlers"></a>示例5：多个notify对应多个handlers</h3><pre><code>- hosts: websrvs  remote_user: root  tasks:    - name: config      copy: src=/root/config.txt dest=/etc/nginx/nginx.conf      notify:        - Restart Nginx        - Check Nginx Process  多个notify的写法  handlers:    - name: Restart Nginx     对应写多个handlers      service: name=nginx state=restarted enabled=yes    - name: Check Nginx process      shell: killall -0 nginx &gt; /tmp/nginx.log</code></pre><h3 id="tags的用法：作用：挑选某一段的task来执行"><a href="#tags的用法：作用：挑选某一段的task来执行" class="headerlink" title="tags的用法：作用：挑选某一段的task来执行"></a>tags的用法：作用：挑选某一段的task来执行</h3><pre><code>将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行然后执行：ansible-plsybook -t ceshi install_memcached.yml        只会触发拷贝文件和handlers的动作---#test yaml file- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致      tags: ceshi   对拷贝动作加一个标签    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted</code></pre><h2 id="Playbook中变量使用-可以多出定义，但是存在优先级"><a href="#Playbook中变量使用-可以多出定义，但是存在优先级" class="headerlink" title="Playbook中变量使用:可以多出定义，但是存在优先级"></a>Playbook中变量使用:可以多出定义，但是存在优先级</h2><h4 id="优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量"><a href="#优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量" class="headerlink" title="优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量"></a>优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量</h4><pre><code>变量名：仅能由字母、数字和下划线组成，且只能以字母开头变量来源：1 ansible setup facts 远程主机的所有变量都可直接调用    setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的        代码块，然后用代码块当变量    比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的          ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量3 通过命令行指定变量，优先级最高    可以对单个变量赋值：ansible-playbook –e varname=value     也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot;4 在playbook中定义    vars:         - var1: value1         - var2: value25 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件            很适合在roles中进行单独定义6 在role中定义（下文中有介绍）</code></pre><h3 id="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令"><a href="#从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令" class="headerlink" title="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令"></a>从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令</h3><p>#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作<br>        ansible_fqdn 主机名的变量<br>        ansible_hostname 主机名<br>        ansible_distribution_major_version: “6” 版本名变量<br>        ansible_processor_vcpus 虚拟cpu个数变量<br>        ansible_memtotal_mb 内存的变量<br>    示例：<br>    ansible all -m setup -a “filter=ansible_memtotal_mb”<br>        用此命令来查看系统内变量的值</p><h4 id="调用不同变量来源的示例：得出变量的优先级顺序"><a href="#调用不同变量来源的示例：得出变量的优先级顺序" class="headerlink" title="调用不同变量来源的示例：得出变量的优先级顺序"></a>调用不同变量来源的示例：得出变量的优先级顺序</h4><pre><code>示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml- hosts: all  remote_user: root  tasks:    - name: touch file      file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量    /etc/ansible/hosts：中定义的变量：        [websrvs]        192.168.34.105 port1=80        192.168.34.106 port1=90   -普通变量        [websrvs:vars]   -公共组变量        mark=&quot;-&quot;        [appsrvs]        192.168.34.101 port1=100        [appsrvs:vars]        mark=&quot;=&quot;    vars.yml中书写格式：        - hosts: all          remote_user: root          tasks:            - name: touch file              file: name=/data/app{{mark}}{{ port1 }}.log state=touch最后生成的文件为：            app=100.log，app-80.logapp-90.log示例3：在示例1的基础上，再通过命令行中定义变量:    在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果：    ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml    可以看出，最后新建的文件名为hahaha.log示例4：在playbook中定义变量    - hosts: all      remote_user: root      vars:        - port1: 200        - mark: +++      tasks:        - name: touch file          file: name=/data/app{{mark}}{{ port1 }}.log state=touch    生成的文件：        app+++200.log示例5：先写在var.yml中定义变量，    1.先准备cat vars.yml:文件内容格式        var1: httpd        var2: nginx    2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义        - hosts: web          remote_user: root          vars_files:            - vars.yml         tasks:           - name: create httpd log             file: name=/app/{{ var1 }}.log state=touch           - name: create nginx log             file: name=/app/{{ var2 }}.log state=touch</code></pre><h2 id="模板templates，作用："><a href="#模板templates，作用：" class="headerlink" title="模板templates，作用："></a>模板templates，作用：</h2><pre><code>文本文件，嵌套有脚本（使用模板编程语言编写）Jinja2语言，使用字面量，有下面形式字符串：使用单引号或双引号数字：整数，浮点数列表：[item1, item2, ...]元组：(item1, item2, ...)字典：{key1:value1, key2:value2, ...}布尔型：true/false算术运算：+, -, *, /, //, %, **比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;=逻辑运算：and, or, not流表达式：For If When</code></pre><h3 id="templates功能：根据模块文件动态生成对应的配置文件"><a href="#templates功能：根据模块文件动态生成对应的配置文件" class="headerlink" title="templates功能：根据模块文件动态生成对应的配置文件"></a>templates功能：根据模块文件动态生成对应的配置文件</h3><p>   templates文件必须存放于templates目录下，且命名为 .j2 结尾</p><pre><code>yaml/yml 文件需和templates目录平级，目录结构如下：./├── temnginx.yml└── templates   └── nginx.conf.j2</code></pre><h4 id="示例1：通过templates模板nginx"><a href="#示例1：通过templates模板nginx" class="headerlink" title="示例1：通过templates模板nginx"></a>示例1：通过templates模板nginx</h4><pre><code>1.先生成nginx.conf.j2模板cp /etc/nginx/nginx.conf templates/nginx.conf.j22.创建playbook- hosts: all  remote_user: root  tasks:    - name: inastll nginx      yum: name=nginx    - name: template      template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf                                       notify: service    - name: start service      service: name=nginx state=started  handlers:    - name: service      service: name=nginx state=restarted</code></pre><h3 id="when配合templates实现根据不同版本执行不同的功能"><a href="#when配合templates实现根据不同版本执行不同的功能" class="headerlink" title="when配合templates实现根据不同版本执行不同的功能"></a>when配合templates实现根据不同版本执行不同的功能</h3><pre><code>条件测试:    如果需要根据变量、facts或此前任务的执行结果来做为某task执行与    否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法    格式when语句    在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法示例：tasks:     - name: &quot;shutdown RedHat flavored systems&quot;     command: /sbin/shutdown -h now     when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值</code></pre><h4 id="示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when"><a href="#示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when" class="headerlink" title="示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when"></a>示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when</h4><pre><code>步骤：涉及到多个notify对应一个handlers,定义端口变量1.hosts文件配置：修改了4台主机httpd的端口    [centos6]    192.168.34.105 http_port=86    192.168.34.106 http_port=87    192.168.34.101 http_port=88    [centos7]    192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件    httpd_6.conf.j2      httpd_7.conf.j23.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的    Listen {{http_port}} 调用hosts列表中的端口变量4.plsybook如下：---- hosts: all  remote_user: root  tasks:    - name: install httpd      yum: name=httpd    - name: templates 6      template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf      notify: restart service      when: ansible_distribution_major_version == &quot;6&quot;    - name: templates 7      template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf                                when: ansible_distribution_major_version == &quot;7&quot;      notify: restart service    - name: service      service: name=httpd state=started  handlers:    - name: restart service      service: name=httpd state=restarted</code></pre><h2 id="迭代：with-items，类似于shell中的for循环"><a href="#迭代：with-items，类似于shell中的for循环" class="headerlink" title="迭代：with_items，类似于shell中的for循环"></a>迭代：with_items，类似于shell中的for循环</h2><pre><code>迭代：当有需要重复性执行的任务时，可以使用迭代机制对迭代项的引用，固定变量名为”item“要在task中使用with_items给定要迭代的元素列表列表格式：    字符串    字典   字典构成一个键值对{key:vavul},如示例3</code></pre><h4 id="迭代的示例："><a href="#迭代的示例：" class="headerlink" title="迭代的示例："></a>迭代的示例：</h4><pre><code>示例1：比如创建user1.user2.user3个用户    - hosts: all      remote_user: root      tasks:        - name: touch users          user: name={{item}}          with_items:            - haha1            - haha2            - haha3示例2：拷贝3个文件，file1 file2 file3    - hosts: all     remote_user: root    tasks:      - name: copy files        copy: src=/data/playbook/{{item}} dest=/data/        with_items:          - file1          - file2          - file3</code></pre><h2 id="迭代嵌套子变量-涉及到多个键值对的表达方式"><a href="#迭代嵌套子变量-涉及到多个键值对的表达方式" class="headerlink" title="迭代嵌套子变量:涉及到多个键值对的表达方式"></a>迭代嵌套子变量:涉及到多个键值对的表达方式</h2><pre><code>示例3：创建3个组，再创建3个用户，指定加入一一对应的组    - hosts: all      remote_user: root      tasks:        - name: creat groups          group: name={{item}}          with_items:            - group1            - group2            - group3        - name: creat users          user: name={{item.name}} group={{item.group}}          with_items:            - { name: &apos;haha1&apos;, group: &apos;group1&apos; }            - { name: &apos;haha2&apos;, group: &apos;group2&apos; }            - { name: &apos;haha3&apos;, group: &apos;group3&apos; }备注：注意创建用户时，键值对的表达和使用方法    上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3;</code></pre><h3 id="Playbook中template结合for循环生成具有重复性的代码段"><a href="#Playbook中template结合for循环生成具有重复性的代码段" class="headerlink" title="Playbook中template结合for循环生成具有重复性的代码段"></a>Playbook中template结合for循环生成具有重复性的代码段</h3><pre><code>语法:for的写法：    {% for vhost in nginx_vhosts %}        server {        listen {{ vhost.listen | default('80 default_server') }}### Playbook中template结合for循环生成具有重复性的代码段         if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用                        如果没定义，则不执行接下来的代码：示例2        {% if vhost.server_name is defined %}                server_name {{ vhost.server_name }};        {% endif %}        {% if vhost.root is defined %}                root {{ vhost.root }};        {% endif %}### for和if的示例，帮助理解其要执行语句的含义        示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成    先创建for.j2文件：                {% for i in ports %}                server{                        listen {{i.listen}}                        name {{i.name}}                        root {{i.root}}                }                {% endfor %}        创建playbook:再其中调用for.j2文件            - hosts: all              remote_user: root              vars:                ports:                  - web1:                    listen: 81                    name: www.baidu.com                    root: /data/web1                  - web2:                    listen: 82                    name: www.baidu1.com                    root: /data/web2              tasks:                - name: test for                  template: src=for.j2 dest=/data/for1.conf    效果为：        server{            listen 81            name www.baidu.com            root /data/web1        }        server{            listen 82            name www.baidu1.com            root /data/web2        }示例2：template配合if的涵义：    在示例1中的playbook中，把name注释掉，即不定义name的值            - web1:                    listen: 81                   # name: www.baidu.com                    root: /data/web1    然后playbook:再调用for.j2文件        {% for i in ports %}            server{                    listen {{i.listen}}            {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用                    name {{i.name}}            {% endif %}                    root {{i.root}}            }            {% endfor %}    结果：则web1没有name的值，即可以理解if的用法        server{            listen 81            root /data/web1  少了web1的name的值        }        server{            listen 82            name www.baidu1.com            root /data/web2        }</code></pre><h3 id="Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？"><a href="#Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？" class="headerlink" title="Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？"></a>Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？</h3><h2 id="ansible重要内容之Roles；playbook的集合和拆分"><a href="#ansible重要内容之Roles；playbook的集合和拆分" class="headerlink" title="ansible重要内容之Roles；playbook的集合和拆分"></a>ansible重要内容之Roles；playbook的集合和拆分</h2><pre><code> ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles    能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需    要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、    文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一    种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程    等场景中复杂场景：建议使用roles，代码复用度高变更指定主机或主机组如命名不规范维护和传承成本大某些功能需多个Playbook，通过Includes即可实现</code></pre><h3 id="roles的意义和适用场景："><a href="#roles的意义和适用场景：" class="headerlink" title="roles的意义和适用场景："></a>roles的意义和适用场景：</h3><pre><code>角色(roles)：角色集合    适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把    同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了，    当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。        如系统内会存在如下的各类服务，可以先编排好角色        roles/        ├── httpd/        ├── memcached/        ├── mysql/        └── nginx/</code></pre><h3 id="roles的目录结构（一般分成以下目录进行存放一类的文件）"><a href="#roles的目录结构（一般分成以下目录进行存放一类的文件）" class="headerlink" title="roles的目录结构（一般分成以下目录进行存放一类的文件）"></a>roles的目录结构（一般分成以下目录进行存放一类的文件）</h3><pre><code>Roles各目录作用：/roles/project/ :项目名称,有以下子目录    如创建http，memcached，nginx等目录files/ ：存放由copy或script模块等调用的文件    保存需要拷贝的配置文件templates/：template模块查找所需要模板文件的目录    保存通过template的jinja2模板调用的配置文件tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；        其它的文件需要在此文件中通过include进行包含handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此           文件中通过include进行包含vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要       在此文件中通过include进行包含，可以单独定义变量的目录meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，其它文件需在此文件中通过include进行包含            tasks目录下，组合任务顺序的文件default/：设定默认变量时使用此目录中的main.yml文件</code></pre><h3 id="roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色"><a href="#roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色" class="headerlink" title="roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色."></a>roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.</h3><pre><code>- hosts: all  remote_user: root  roles:    - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]}       - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}    - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}</code></pre><h3 id="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"><a href="#playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量" class="headerlink" title="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"></a>playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量</h3><pre><code>方法一：把需要调用的角色写在一个playbook里    - hosts: all      remote_user: root      roles:        - role: httpd        - role: memcached        - role: nginx    弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活方法二；可以把变量在角色中定义    传递变量给角色    - hosts:      remote_user:      roles:        - mysql        - { role: nginx, username: nginx }          键role用于指定角色名称          后续的k/v用于传递变量给角色          调用角色方法3：还可基于条件测试实现角色调用方法三：还可基于条件测试实现角色调用    roles:      - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ }</code></pre><h2 id="roles示例："><a href="#roles示例：" class="headerlink" title="roles示例："></a>roles示例：</h2><h3 id="以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml"><a href="#以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml" class="headerlink" title="以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml"></a>以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml</h3><h4 id="roles的目录结构下的httpd-amp-nginxmemcached"><a href="#roles的目录结构下的httpd-amp-nginxmemcached" class="headerlink" title="roles的目录结构下的httpd&amp;nginxmemcached"></a>roles的目录结构下的httpd&amp;nginxmemcached</h4><pre><code>roles├── httpd│   ├── files│   │   ├── index_6.html│   │   └── index_7.html│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── copyhtml_6.yml│   │   ├── copyhtml_7.yml│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig_6.yml│   │   ├── tempconfig_7.yml│   │   └── user.yml│   ├── templates│   │   ├── httpd_6.conf.j2│   │   └── httpd_7.conf.j2│   └── vars├── memcached│   ├── files│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig.yml│   │   └── user.yml│   ├── templates│   │   └── memcached.j2│   └── vars└── nginx    ├── files    │   ├── index_6.html    │   └── index_7.html    ├── handlers    │   └── main.yml    ├── tasks    │   ├── copyhtml_6.yml    │   ├── copyhtml_7.yml    │   ├── group.yml    │   ├── main.yml    │   ├── package.yml    │   ├── service.yml    │   ├── tempconfig.yml    │   └── user.yml    ├── templates    │   └── nginx.conf.j2    └── vars       └── main.yml</code></pre><h3 id="调用角色的playbook-roles-yml"><a href="#调用角色的playbook-roles-yml" class="headerlink" title="调用角色的playbook:roles.yml"></a>调用角色的playbook:roles.yml</h3><h5 id="可以通过加变量和标签和条件测试调用更灵活的调用各种角色"><a href="#可以通过加变量和标签和条件测试调用更灵活的调用各种角色" class="headerlink" title="可以通过加变量和标签和条件测试调用更灵活的调用各种角色)"></a>可以通过加变量和标签和条件测试调用更灵活的调用各种角色)</h5><pre><code>    vim /data/roles.yml            - hosts: all            remote_user: root          roles:        - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“}        - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}        - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}比如：     1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法     2.ansible-playbook -t httpd roles.yml 只选择安装httpd     3.ansible-playbook -t nginx roles.yml 只选择安装nginx     4.ansible-playbook -t web roles.yml 安装httpd和memcached     5.ansible-playbook -t web1 roles.yml 只选择安装nginx</code></pre><h3 id="下图为每个role的各个文件内容："><a href="#下图为每个role的各个文件内容：" class="headerlink" title="下图为每个role的各个文件内容："></a>下图为每个role的各个文件内容：</h3><p>图一：参照roles的httpd的目录各个文件内容</p><p><img src="/2018/03/06/ansible/roles.png" alt="roles_memcached"></p><p>图二：参照roles的nginx的目录各个文件内容</p><pre><code>涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有    跨角色调用配置文件写法：   - name: copy index6  copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html</code></pre><p><img src="/2018/03/06/ansible/roles_nginx.png" alt="roles_nginx"><br>图三：参照roles的memcached的目录各个文件内容<br><img src="/2018/03/06/ansible/roles_memcached.png" alt="roles_memcached"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;a href=&quot;#运维自动化管理工具之Ansible&quot; class=&quot;headerlink&quot; title=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;/a&gt;运维自动化管理工具之Ansible&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2018/03/06/ansible/ansible.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="自动化运维" scheme="https://www.liukui.tech/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="ansible,运维技术" scheme="https://www.liukui.tech/tags/ansible-%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>httpd</title>
    <link href="https://www.liukui.tech/2017/10/18/httpd/"/>
    <id>https://www.liukui.tech/2017/10/18/httpd/</id>
    <published>2017-10-18T00:00:00.000Z</published>
    <updated>2018-12-20T11:13:47.622Z</updated>
    
    <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <div id="hbe-security"> <div class="input-container"> <input type="password" class="form-control" id="pass" placeholder=" 输入密码,PC:Enter查看,Phone:输入法换行查看. " /> <label for="pass"> 输入密码,PC:Enter查看,Phone:输入法换行查看. </label> <div class="bottom-line"></div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      &lt;font size=3 color=&quot;#FF0000&quot;&gt;私密文章，需要输入密码.&lt;/font&gt;&lt;/br&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>文本三剑客之awk</title>
    <link href="https://www.liukui.tech/2017/10/18/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk/"/>
    <id>https://www.liukui.tech/2017/10/18/文本三剑客之awk/</id>
    <published>2017-10-17T16:00:00.000Z</published>
    <updated>2018-12-19T01:39:56.244Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文本处理三剑客之awk"><a href="#文本处理三剑客之awk" class="headerlink" title="文本处理三剑客之awk"></a>文本处理三剑客之awk</h1><p><img src="/2017/10/18/文本三剑客之awk/awk.png" alt=""><br><a id="more"></a></p><p>Awk的用户使用指南<a href="http://www.gnu.org/software/gawk/manual/gawk.html" target="_blank" rel="noopener">awk用户指南</a></p><p>相关链接文章：<br>正则表达式： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">正则表达式</a><br>grep文本编辑： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">grep用法</a><br>sed文本编辑： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">sed用法</a></p><h3 id="总结对比一下这三个剑客的特长之处"><a href="#总结对比一下这三个剑客的特长之处" class="headerlink" title="总结对比一下这三个剑客的特长之处"></a>总结对比一下这三个剑客的特长之处</h3><p>grep、sed、awk被称为linux中的三剑客</p><p>grep更适合单纯的查找或匹配文件.<br>sed更适合编辑皮匹配到的文本<br>awk更适合格式化文本，对文本进行比较复杂格式处理</p><p>文本三剑客都是默认逐行处理，自带循环<br>sed 可以对文本进行修改，而grep&amp;awk 只是对文本进行过滤,不进行内容修改</p><p>awk中的-F后面的分隔符,要用单引号’’,双引号””会产生弱引用,比如特殊符号’\\‘ ‘\\$’<br>关于awk中的单引号和双引号的问题参照：<a href="https://blog.csdn.net/swinfans/article/details/82991077" target="_blank" rel="noopener">awk中的输入分隔符单引号&amp;双引号</a></p><p>学习awk的一个重要知识点</p><pre><code>先举两个例子：awk &apos;/^UUID/&apos; /etc/fstab = awk &apos;/^UUID/{print $0}&apos; /etc/fstab 其实是隐藏了{print $0}的写法数组中的例子awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6实际上是隐藏了{print $0}</code></pre><h3 id="学习中遇到的混淆的问题："><a href="#学习中遇到的混淆的问题：" class="headerlink" title="学习中遇到的混淆的问题："></a>学习中遇到的混淆的问题：</h3><pre><code>&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印而后面的数组里的是加了双括号{}，即用的patter的空模式，即文本中的每一行都处理</code></pre><hr><hr><h2 id="Awk"><a href="#Awk" class="headerlink" title="Awk"></a>Awk</h2><p>基本用法和功能以及各个功能示例：<br>awk介绍<br>awk基本用法<br>awk变量<br>awk格式化-printf<br>awk操作符<br>awk条件判断<br>awk循环<br>awk数组<br>awk函数<br>调用系统命令</p><hr><hr><h3 id="awk介绍："><a href="#awk介绍：" class="headerlink" title="awk介绍："></a>awk介绍：</h3><pre><code>whatis awk？awk：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出，输出成报表格式linux上默认使用 GNU awk(gawk)[root@centos7 data]which awk/usr/bin/awk[root@centos7 data]ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Sep 19 11:45 /usr/bin/awk -&gt; gawkwhich awk=/usr/bin/awk 是gawk的软链接 </code></pre><hr><hr><h3 id="awk基本用法"><a href="#awk基本用法" class="headerlink" title="awk基本用法"></a>awk基本用法</h3><pre><code>awk [options] &apos;program&apos; var=value file…awk [options] -f programfile var=value file…awk [options] &apos;BEGIN{action;… }pattern{action;… }END{action;… }&apos; file ...awk 程序可由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块，共3部分组成program 通常是被放在单引号中 选项：    -F “分隔符” 指明输入时用到的字段分隔符    -v var=value 变量赋值基本格式：awk [options] &apos;program&apos; file…         Program：pattern{action statements;..}也就是说awk用法：awk [options] &apos;pattern{action statements;..}&apos; file…    pattern和action    • pattern部分决定动作语句何时触发及触发事件    BEGIN,END    • action statements对数据进行处理，放在{}内指明print, printf分割符、域和记录    • awk执行时，由分隔符分隔的字段（域）标记$1,$2...$n称为域标识。$0    为所有域，注意：此时和shell中变量$符含义不同    • 文件的每一行称为记录    • 省略action，则默认执行 print $0 的操作print格式：print item1, item2, ...    要点：    (1) 逗号分隔符    (2) 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式    (3) 如省略item，相当于print $0</code></pre><h3 id="用法解析及示例："><a href="#用法解析及示例：" class="headerlink" title="用法解析及示例："></a>用法解析及示例：</h3><pre><code>$0=代表处理的整行的内容$1,$2,$3..代表每一列，也就域BEGIN，END是为生成一个报表的头和尾准备的，用法通常为：BEGIN：为生成报告模式 添加表头;END:为生成的报告 进行信息汇总awk &apos;BEGIN{print xxx}{print xxx}END{print xxx}&apos;注意：BEGIN{print *xxx}处理文本前，打印一遍xxx的内容当成表头     END{print xxx},处理文本后，打印一遍xxx的内容作为表尾</code></pre><h2 id="BEGIN-amp-END"><a href="#BEGIN-amp-END" class="headerlink" title="BEGIN&amp;END"></a>BEGIN&amp;END</h2><pre><code>BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。END：让用户在最后一条输入记录被读取之后发生的动作。</code></pre><h2 id="分隔符："><a href="#分隔符：" class="headerlink" title="分隔符："></a>分隔符：</h2><pre><code>awk默认使用空白符作为字段或列的分隔符；多个空白符被认为是一个，空白符包括空格，tab键/t，回车\n也可以自定义-F&quot;分隔符&quot;自定义分隔符</code></pre><h3 id="print-amp-printf的区别："><a href="#print-amp-printf的区别：" class="headerlink" title="print&amp;printf的区别："></a>print&amp;printf的区别：</h3><pre><code>print命令只是单纯的把特定的内容进行打印，默认换行printf命令可以把内容以灵活的格式进行显示,如左对齐,右对齐</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre><code>1.awk支持标准输入输出，后面可以不跟文件[root@centos7 ~]#awk &apos;{print $0}&apos;aaaaaaaaabcabcabcabc2.打印/etc/passwd：对比几个输出结果awk &apos;{print $0}&apos; /etc/passwd 把passwd文件全部打印出来awk &apos;{print &quot;abc&quot;}&apos; /etc/passwd   读入的是passwd文件所有行，打印的是abcawk -v abc=1 &apos;{print abc}&apos; /etc/passwd  读入的是passwd文件所有行，打印的都是1awk &apos;{print &quot;abc&quot;$0}&apos; /etc/passwd 把passwd文件所有行前都加一个abc,进行输出所以在awk中不加双引号，abc被识别为变量，如果要引用变量，需要-v先定义值如果只是想输出abc字符串，需要加双引号3.awk{}中支持数字运算awk &apos;{print 1+2}&apos; /etc/passwd 打印多行1+2=3的值awk &apos;{print &quot;1+2&quot;}&apos; /etc/passwd 加双引号会把1+2当成字符串，输出多行1+24.取分区利用率df,df |awk &apos;{print $1,$5}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos;5.以输入重定向方式，打印 passwd 文件的第1列，即获取当前系统中存在的所有用户和UIDawk -F: &apos;{print $1,$3}&apos; &lt; /etc/passwdcat /etc/passwd | awk -F: &apos;{print $1,$3}&apos;awk -F: &apos;{print $1：$3}&apos;  /etc/passwd  两列输出时，指定以：进行隔开，默认为空格隔开awk -F: &apos;{print $1、$3}&apos;  /etc/passwd  两列输出时，指定以：进行隔开，默认为空格隔开cat /etc/passwd | awk -F: &apos;{print $1&quot;\n&quot; $3}&apos; 两列输出时,进行换行cat /etc/passwd | awk -F: &apos;{print $1&quot;\t&quot; $3}&apos; 两列输出时,以tab键隔开备注：多行输出时，可以在双引号之间加自定义的分隔符格式：awk -F: &apos;{print $1&quot;=======&quot;$3}&apos;  /etc/passwd </code></pre><hr><hr><h2 id="Awk中的变量："><a href="#Awk中的变量：" class="headerlink" title="Awk中的变量："></a>Awk中的变量：</h2><h3 id="变量分为：内置变量和自定义变量"><a href="#变量分为：内置变量和自定义变量" class="headerlink" title="变量分为：内置变量和自定义变量"></a>变量分为：内置变量和自定义变量</h3><pre><code>awk中的内置变量除了$0,$1,$2等，还有以下几种；如果要使用这些变量需要加-v 选项先进行定义FS：输入字段分隔符，默认为空白字符  =filed separator=域或列的分隔符等于-F的选项，-F是选项，而FS是变量，实际作用是相等的与-F的区别在于：可以下次调用FS变量awk -v FS=&apos;:&apos; &apos;{print $1,$3}&apos; /etc/passwd  = awk -F:&apos;{print $1,$3}&apos; /etc/passwdawk -v FS=&apos;:&apos; &apos;{print $1,FS$3}&apos; /etc/passwd  两列输出时以：做分隔符，调用变量FSawk -v FS=&apos;:&apos; &apos;{print $1,FS FS$3}&apos; /etc/passwd  两列输出时以：：做分隔符，调用2次变量FS 以空格隔开可以先定义shell中的变量fs=:,awk再进行调用fs=:;awk -v FS=$fs &apos;{print $1,FS,$3}&apos; /etc/passwd  fs=:;awk –F$fs &apos;{print $1,$3,$7}&apos; /etc/passwdOFS：输出字段分隔符，默认为空白字符 =output filed separator定义输出分隔符，不指定默认空空格做分隔符awk -v FS=: -v OFS=+++ &apos;{print $1,$3,$7}&apos; /etc/passwdfs=+++;awk -v FS=: -v OFS=$fs &apos;{print $1,$3}&apos; /etc/passwd  调用shell变量做输出分隔符RS：输入记录分隔符，指定输入时的换行符,自定义行的分隔符 =record记录默认一行叫记录，行是以\n回车作为切割符的，RS可以自定义不用回车作为分隔符    awk -v RS=&apos; &apos; ‘{print }’ /etc/passwd    awk -v RS=&apos;:&apos; &apos;{print NR,$0}&apos;/etc/passwd     [root@centos7 ~]cat f1    aa;xxx:bb;bzzzz:cc    dd:eex;zccc:xxxx    [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print $0}&apos;    aa;xxx    bb;bzzzz    cc    dd    eex;zccc    xxxx    以RS=：冒号自定义行的分隔符，输出结果如上    [root@centos7 ~]#cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; &apos;{print $1}&apos;    aa    bb    cc    dd    eex    xxxx    自定义FS&amp;RS，输出结果如上ORS：输出记录分隔符，输出时用指定符号代替换行符 awk -v RS=&apos; &apos; -v ORS=&apos;###&apos;‘{print }’ /etc/passwd[root@centos7 ~]cat f1aa;xxx:bb;bzzzz:ccdd:eex;zccc:xxxx[root@centos7 ~]cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; -v ORS&quot;===&quot; &apos;{print $1}&apos;aa==bb==ccdd==eex==xxxx==自定义FS,RS,ORS结果很明显接下来是一个比较重要的变量NF：字段数量,也就是域或列的总数量awk -F: &apos;{print NF}&apos; /etc/passwd 以冒号做分隔符，显示每行的列的总数量awk -F: &apos;{print $NF}&apos; /etc/passwd 显示以冒号做分隔符，每一行的最后一个字段即bash类型awk -F：&apos;{print $(NF-1)}&apos; /etc/passwd 显示以冒号做分隔符，每一行的倒数第二个字段统计光盘中所有安装包适用的cpu架构类型root@centos7 mnt]#ls /mnt/Packages/*.rpm | awk -F&quot;.&quot; &apos;{print $(NF-1)}&apos;|sort|uniq -c   1371 noarch   2600 x86_64NR：记录号，可以显示行数，如果有多个文件会合并后再统计总行awk &apos;{print NR,$0}&apos; /etc/fstab 在每一行前加一个行号awk BEGIN&apos;{print NR}&apos; /etc/fstab 输出结果为0  awk还没开始处理行，所以记录为0awk END&apos;{print NR}&apos; /etc/fstab  输出结果为12 可以看出END是统计,awk处理的行数1.通过加行号，可以很明显看出以冒号作为行的分隔符，每一行的都有什么；可以看出cc dd是一行的[root@centos7 ~]cat f1aa;xxx:bb;bzzzz:ccdd:eex;zccc:xxxx[root@centos7 ~]cat f1| awk  -v RS=&quot;:&quot; &apos;{print NR$0}&apos;1aa;xxx2bb;bzzzz3ccdd4eex;zccc5xxxx2.备注：如果awk跟两个文件，awk会把两文件合并成一个文件，统计总行数，都取第一个字段的信息如果需要分开显示统计，则用FNR[root@centos7 ~]awk -F: &apos;{print NR,$1}&apos; /etc/passwd /etc/group1 root2 bin3 daemon4 admFNR：各文件分别计数,记录号1.FNR:多个文件，每个分别统计显示第一个字段并列出来awk &apos;{print FNR}&apos; /etc/fstab /etc/inittab[root@centos7 ~]awk -F: &apos;{print FNR,$1}&apos; /etc/passwd /etc/group1 root2 bin3 daemon48 quagga49 httpd1 root2 binFILENAME：当前文件名1.统计时，加上变量可以显示文件名awk &apos;{print FILENAME}&apos; /etc/fstab[root@centos7 ~]awk -F: &apos;{print FILENAME,FNR,$1}&apos; /etc/passwd /etc/passwd 1 root/etc/passwd 2 bin/etc/passwd 3 daemonARGC：命令行参数的个数awk &apos;{print ARGC}&apos; /etc/fstab /etc/inittab 结果为3awk &apos;BEGIN {print ARGC}&apos; /etc/fstab /etc/inittab 结果为3ARGC统计参数：awk单独算一个参数，后面的每个文件算一个参数,通过下面的数组可以体现出来ARGV：数组，保存的是命令行所给定的各参数1.显示awk的每个参数分别是哪个[root@centos7 ~]awk &apos;{print ARGV[0]}&apos; /etc/fstab /etc/inittabawk[root@centos7 ~]awk &apos;{print ARGV[1]}&apos; /etc/fstab /etc/inittab/etc/fstab</code></pre><h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><pre><code>1.统计当前网络连接情况的ip地址是 ss -ntss -nt | awk &apos;{print $5}&apos;2.取/var/log/httpd/access_log的时间如下：root@centos7 ~]cat /var/log/httpd/access_log192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; 分两步取：cat /var/log/httpd/access_log | awk &apos;{print $4}&apos;|awk -F&quot;[&quot; &apos;{print $2}&apos;一步取：cat /var/log/httpd/access_log | awk -F &quot;[\[ ]&quot; &apos;{print $5}&apos;原理分析：[\[ ]代表（转义）\[和空格都算是分隔符，正则表达式的写法,或的关系，而以空格分隔符，时间段为$4,那为什么是$5?在空格的标准里，[算$4,所以时间段为$53.取出磁盘分区利用率 -这次只取出利用率两步取出：df | awk -F% &apos;{print $1}&apos;|awk &apos;{print $5}&apos;一步取出：df | awk -F&quot;[[:space:]]+|%&quot; &apos;{print $5}&apos; awk用的是扩展的正则表达式面试题：3-1,取出fstab中挂载的目录[root@centos7 ~]cat /etc/fstab # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=9612633f-e7f1-4b28-8813-403d209d7abc /                       xfs     defaults        0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot                   xfs     defaults        0 0UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data                   xfs     defaults        0 0UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap                    swap    defaults        0 0[root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos;bootdataswap或者[root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos;bootdataswap4.面试题：将文件f3中的第一个点前的字符串取出再写进去[root@centos7 ~]cat f31 test.sina.com.cn2 music.sina.com.cn3 sports.sina.com.cn4.news.sina.com.cn[root@centos7 ~]cat f3 | awk -F&quot;[ .]&quot; &apos;{print $2}&apos; &gt;&gt; f3[root@centos7 ~]cat f31 test.sina.com.cn2 music.sina.com.cn3 sports.sina.com.cn4.news.sina.com.cntestmusicsportsnews4-1,扩展前面-F&quot;[ .]&quot;既然是表达或的意思，那么是否可以这么写-F&quot;[ ]|.&quot;？？？答案：不可以！原因：因为此处用的是正则表达式，在正则表达式中点(.)代表任意单个字符，会把空格后的字母当成分隔符！所以是不可以的，那么如何写？如果不是点而是%呢？%是可以的，因为在正则表达式中%就是代表%，但是$,或其他在正则表达式中有特殊含义的不可以作为分隔符，如果一定要做分隔符，需要反斜线转义如下：此处用3个反斜线转义[root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\.&quot; &apos;{print $2}&apos;testmusicsportsnews那如果文本中的第一个点是$呢？此处是4个反斜线进行转义[root@centos7 ~]cat f21 test$sina.com.cn2 music$sina.com.cn3 sports$sina.com.cn4 news$sina.com.cn[root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\\$&quot; &apos;{print $2}&apos;testmusicsportsnews[root@centos7 ~]cat f2 | awk -F&quot;[ $]&quot; &apos;{print $2}&apos;testmusicsportsnews当用一个空格和具有特殊含义的符号时，最好是写在中括号[]里的</code></pre><h3 id="AWK中自定义变量"><a href="#AWK中自定义变量" class="headerlink" title="AWK中自定义变量"></a>AWK中自定义变量</h3><pre><code>自定义变量(区分字符大小写)(1) -v var=value(2) 在program中直接定义(2-1)program可以放到一个文本里,awk -f 直接调用即可</code></pre><h5 id="示例：-1"><a href="#示例：-1" class="headerlink" title="示例："></a>示例：</h5><pre><code>自定义变量可以-v var定义，也可以放到program即{}里，变量要先定义，后使用awk -F:  &apos;{name=&quot;magedu&quot;;print $1,name}&apos; /etc/passwdawk -F: -v name=&quot;magedu&quot; &apos;{print $1,name}&apos; /etc/passwd例如cat awk.txt{print $1,$2,$6}awk -F： -f awk.txt /etc/passwd =awk -F: &apos;{print $1,$2,$6}&apos; /etc/passwd</code></pre><hr><hr><h3 id="Awk中的格式化"><a href="#Awk中的格式化" class="headerlink" title="Awk中的格式化"></a>Awk中的格式化</h3><p>在介绍printf前，先对其进行总结：<br>1.使用printf动作输出的文本不会换行，如果需要换行，可以在对应的格式替换符后加入”\n”进行转义<br>2.使用printf动作时，指定的格式和被格式化的文本之间，需要用”逗号”隔开。<br>3.使用printf动作时，格式中的格式替换符比喻与被格式化的文本一一对应</p><h4 id="printf命令-类似于shell里的printf"><a href="#printf命令-类似于shell里的printf" class="headerlink" title="printf命令-类似于shell里的printf"></a>printf命令-类似于shell里的printf</h4><pre><code>printf命令可以把内容以灵活的格式进行显示，如左对齐,右对齐格式化输出：printf &quot;FORMAT&quot;, item1, item2, ...(1) 必须指定FORMAT(2) 不会自动换行，需要显式给出换行控制符，\n(3) FORMAT中需要分别为后面每个item指定格式符格式符：与item一一对应%c：显示字符的ASCII码%d, %i：显示十进制整数   -用的比较多%e, %E：显示科学计数法数值%f：显示为浮点数%g, %G：以科学计数法或浮点形式显示数值%s：显示字符串  -用的比较多%u：无符号整数 -用的比较多%%：显示%自身修饰符#[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f+ 左对齐（默认右对齐） %-15s* 显示数值的正负符号 %+d</code></pre><h4 id="printf示例："><a href="#printf示例：" class="headerlink" title="printf示例："></a>printf示例：</h4><pre><code>1.设置对齐格式以及字符数[root@centos7 ~]awk -F: &apos;{printf &quot;%-20s %-5d\n&quot;,$1,$3}&apos; /etc/passwdroot                 0    bin                  1       pulse                171  gdm                  42   gnome-initial-setup  990  $1为字符串，所以设置左对齐为20s个字符，$3为数字所以设置左对齐为5d个字符printf默认不换行，所以需要加一个换行符  2.打印一个完整的报表格式root@centos7 ~]awk -F: &apos;BEGIN{print &quot;username   |uid\n--------&quot;}{printf &quot;%-10s |%-5d\n&quot;,$1,$3}END{print &quot;-------------&quot;}&apos; /etc/passwdusername             |uid-----------------------root                 |0    bin                  |1    daemon               |2 memcached            |987  ceshi                |1009 quagga               |92   httpd                |80   -------------------------awk生成报表格式大概就是这个样子，所以awk称为报表生成器3.[root@centos7 ~]awk -F: &apos;{printf &quot;Username: %s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwdUsername: root,UID:0Username: bin,UID:1Username: daemon,UID:2Username: adm,UID:34.[root@centos7 ~]awk -F: &apos;{printf &quot;Username: %-15s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwdUsername: root           ,UID:0Username: bin            ,UID:1Username: daemon         ,UID:2</code></pre><hr><hr><h3 id="awk操作符"><a href="#awk操作符" class="headerlink" title="awk操作符"></a>awk操作符</h3><pre><code>a.算术操作符：x+y, x-y, x*y, x/y, x^y, x%y- x：转换为负数+x：将字符串转换为数值字符串操作符：没有符号的操作符，字符串连接赋值操作符：=, +=, -=, *=, /=, %=, ^=，++, --,b.比较操作符：==, !=, &gt;, &gt;=, &lt;, &lt;=模式匹配符： ~：左边是否和右边匹配包含 !~：是否不匹配c.逻辑操作符：与&amp;&amp;，或||，非!d.条件表达式（三目表达式） selector?if-true-expression:if-false-expression 表达式；if-ture-xx:else-xxx eg:x&gt;y?var=x;var=y</code></pre><h3 id="操作符用法示例："><a href="#操作符用法示例：" class="headerlink" title="操作符用法示例："></a>操作符用法示例：</h3><pre><code>1.下面两语句有何不同• awk &apos;BEGIN{i=0;print ++i,i}&apos; 结果 1 1• awk &apos;BEGIN{i=0;print i++,i}&apos; 结果 0 1实际上AWK的语法是采用VC语言风格的2.示例：awk中~&amp;!~是否包含的用法：[root@centos7 ~]awk -F: &apos;$0 ~ /root/{print $1}&apos; /etc/passwdrootoperator意思是如果过滤的行中有包含root字符串的，则打印出这行的用户名用到下文提到的patter模式，在这里是匹配是否包含root字符串[root@centos7 ~]awk -F: &apos;$0 ~ &quot;/root&quot;{print $1}&apos; /etc/passwdrootoperator区别上面的这个写法，在这里是包含/root字符串的行[root@centos7 ~]awk -F: &apos;$0 !~ /root/{print $1}&apos; /etc/passwdbindaemonadm和上面的命令刚好相反，如果行不包含字符串root，则打印该行用户名[root@centos7 ~]awk -F: &apos;$3==0&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash意思：判断UID是否等于0，是则打印该行，判断是否为管理员[root@centos7 ~]awk &apos;$0~&quot;^root&quot;&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash意思：判断该行是不是以root开头的行，是则打印3.awk中的与&amp;&amp;，或|| 非!的使用示例：示例：• awk –F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000 {print $1}&apos; /etc/passwd如果0&lt;=UID&lt;=1000，则打印出该用户• awk -F: &apos;$3==0 || $3&gt;=1000 {print $1,$3}&apos; /etc/passwd打印出UID等于0和UID&gt;=1000的用户名和他的UID• awk -F: &apos;!($3==0) {print $1}&apos; /etc/passwd -要加括号打印出UID不等于0的用户名• awk -F: &apos;!($3&gt;=500) {print $3}&apos; /etc/passwd如果UID&lt;=500,时，打印出该用户的UID4.AWK中的条件判断表达式即三目表达式相当于把shell中的if;then,else,fi的放到awk中• 示例：[root@centos7 ~]awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwdsys root 0sys bin 1sys tcpdump 72common test 1000common nginx 1008判断用户是否为系统用户，是则打印并在开头加common,不是也打印在开头加sys</code></pre><hr><hr><h3 id="awk中的PATTERN和action"><a href="#awk中的PATTERN和action" class="headerlink" title="awk中的PATTERN和action"></a>awk中的PATTERN和action</h3><p>模式匹配和处理动作=sed的地址定界+修饰符<br>功能：和sed中的pattern一样起到过滤的功能，=sed的地址定界</p><h5 id="PATTERN-根据pattern条件，过滤匹配的行，再做处理"><a href="#PATTERN-根据pattern条件，过滤匹配的行，再做处理" class="headerlink" title="PATTERN:根据pattern条件，过滤匹配的行，再做处理"></a>PATTERN:根据pattern条件，过滤匹配的行，再做处理</h5><pre><code>(1)如果未指定：空模式，匹配每一行(2) /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来awk &apos;/^UUID/{print $1}&apos; /etc/fstabawk &apos;!/^UUID/{print $1}&apos; /etc/fstabawk的匹配模式支持的是扩展的正则表达式注意：不支持直接给出数字格式，但是可以变向的打印输出，详见下面的示例(3) relational expression: 关系表达式，结果为“真”才会被处理真：结果为非0值，非空字符串假：结果为空字符串或0值都是假字符串为空或者0为假(4) line ranges：行范围startline,endline：/pat1/,/pat2/ 不支持直接给出数字格式awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/{print $1}&apos; /etc/passwdawk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20){print NR,$1}&apos; /etc/passwdNR表示行(5) BEGIN/END模式BEGIN{}: 仅在开始处理文件中的文本之前执行一次END{}：仅在文本处理完成之后执行一次</code></pre><p>模式：指定一个行的范围。该语法不能包括BEGIN和END模式。<br>BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。<br>END：让用户在最后一条输入记录被读取之后发生的动作。</p><h5 id="patter用法示例："><a href="#patter用法示例：" class="headerlink" title="patter用法示例："></a>patter用法示例：</h5><pre><code>先写一个特殊的用法1.当在awk命令中使用正则模式时，使用到的正则用法属于&quot;扩展的正则表达式&quot;2.当使用{x,y}这种次数匹配正则表达式，需要配合--posix或者--re-interval选项备注：这是网上找到一个示例，文中提到{x,y}必须加这个选项，然而不加选项也是可以过滤的awk是是支持posix字符集的[root@centos7 ~]cat f3 seexsexseeexseeeeex[root@centos7 ~]cat f3 | awk &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3 | awk -posix &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3 | awk --re-interval  &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3|grep  -E &quot;se{2,3}x&quot;seexseeex[root@centos7 ~]cat f3|sed -nr &apos;/se{2,3}x/p&apos;seexseeex1.取系统磁盘分区空间利用率df,/dev/sd开头的分区(上文中虽然取出来了，但是没过滤)[root@centos7 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &apos;/^\/dev\/sd/{print $1,$5}&apos;/dev/sda2 8/dev/sda3 1/dev/sda1 172.取当前连接主机的IP地址(上文中虽然取出来了，但是没过滤)[root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $6}&apos;192.168.34.1192.168.34.105或者用NF的表达方式[root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;192.168.34.1192.168.34.1053.取登录当前系统失败（lastb）用户的IP[root@centos7 ~]#lastbroot     ssh:notty    192.168.34.105   Sun Nov 11 17:25 - 17:25  (00:00)    root23   ssh:notty    192.168.34.1     Mon Nov  5 15:43 - 15:43  (00:00)    btmp begins Fri Nov  2 09:58:52 2018[root@centos7 ~]#lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c3 192.168.34.11 192.168.34.101因为最后一行有btmp这样的字样，只能通过包含的功能来过滤掉最后一行如果要取失败连接次数大于3的扔到防火墙，可以先取出来root@centos7 ~]lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c| awk &apos;$1 &gt;=3{print $2}&apos;192.168.34.14.patter中为关系表达式的示例空字符串或0值都是假，其他为真awk &apos;0{print $0}&apos; /etc/passwd -0为假，结果为空awk &apos;&quot;&quot;{print $0}&apos; /etc/passwd -空也为假，结果为空awk &apos;1{print $0}&apos; /etc/passwd -1为真awk &apos;&quot; &quot;{print $0}&apos; /etc/passwd -空白符也为真awk -v abc=&quot; &quot; &apos;abc{print $0}&apos; /etc/passwd -abc为空白,不是空字符串,也为真awk -v abc=&quot; &quot; &apos;! abc{print $0}&apos; /etc/passwd -abc为空白,为真,对真取反，结果为假5.awk中patter的地址定界root@centos7 ~]#awk -F: &apos;/^root/,/^adm/{print $0}&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologin打印以root开头的行到以adm开头的行之间的所有行等于 sed -nr &apos;/^root/,/^adm/p&apos; /etc/passwd6.如何打印从多少行到多少行之间的行？？[root@centos7 ~]#awk -F: &apos;NR&gt;=10 &amp;&amp; NR&lt;=12 {print NR,$0}&apos; /etc/passwd10 operator:x:11:0:operator:/root:/sbin/nologin11 games:x:12:100:games:/usr/games:/sbin/nologin12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin通过变量NR变向的打印出行7.取出/etc/fstab配置文件中以UUID开头的行[root@centos7 ~]#cat /etc/fstab | awk &apos;/^UUID/{print $0}&apos;UUID=9612633f-e7f1-4b28-8813-403d209d7abc /    xfs  defaults 0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot   xfs defaults  0 0效果等于  grep &quot;^UUID&quot; /etc/fstab效果等于  sed -n &apos;/^UUID/p&apos; /etc/fstab8.awk &apos;!0&apos; /etc/passwd =awk &apos;!0{print $0}&apos; /etc/passwd 省略了{print $0}的写法结果为真，即打印全部行root@centos7 ~]#awk -F: &apos;i=1;j=1{print i,j}&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash1 1bin:x:1:1:bin:/bin:/sbin/nologin1 1？？？[root@centos7 ~]#awk -F: &apos;$NF ~ /bash$/{print $1,$NF}&apos; /etc/passwdroot /bin/bashtest /bin/bash判断用户shell是否为/bin/bash，是则打印用户名和shell类型，此处用变量NF来实现效果等于 awk -F: &apos;$NF==&quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd效果等于 awk -F: &apos;$7 == &quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd效果等于 awk -F: &apos;$0 ~ /bash$/{print $1,$NF}&apos; /etc/passwd9.打印奇数行和偶数行[root@centos7 ~]#seq 6 | awk &apos;i=!i&apos;  打印奇数行135原理：i初始值为空，为假，取反时，则打印第一行，此时i=1i=1时，为真，取反为假，所以第二行不打印，然后i=0依次类推所以只打印奇数行[root@centos7 ~]#seq 6 | awk &apos;!(i=!i)&apos; 打印偶数行246效果等于 seq 10 |awk -v i=1 &apos;i=!i&apos;原理：同上，只要先定义i=1，为真，第一行就不打印了或者用sed打印奇数行和偶数行(用sed步进的方式) seq 6 | sed -n &apos;1~2p&apos; 打印奇数行 seq 6 | sed -n &apos;2~2p&apos; 打印偶数行</code></pre><hr><hr><h3 id="awk-action"><a href="#awk-action" class="headerlink" title="awk action"></a>awk action</h3><h4 id="action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能"><a href="#action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能" class="headerlink" title="action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能"></a>action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能</h4><pre><code>• (1) Expressions:算术，比较表达式等• (2) Control statements：if, while等• (3) Compound statements：组合语句• (4) input statements• (5) output statements：print等</code></pre><h4 id="下面专门研究awk的控制语句包含if-while-do-for-break-continue-数组，exit等控制语句"><a href="#下面专门研究awk的控制语句包含if-while-do-for-break-continue-数组，exit等控制语句" class="headerlink" title="下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句"></a>下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句</h4><h5 id="awk中if-else控制语句的语法及用法"><a href="#awk中if-else控制语句的语法及用法" class="headerlink" title="awk中if-else控制语句的语法及用法"></a>awk中if-else控制语句的语法及用法</h5><pre><code>语法：双分支ifif(condition){statement;…}(多条语句用;隔开)[else statement]多分支ifif(condition1){statement1}else if(condition2){statement2}else{statement3}使用场景：对awk取得的整行或某个字段做条件判断</code></pre><h6 id="if-else示例："><a href="#if-else示例：" class="headerlink" title="if-else示例："></a>if-else示例：</h6><pre><code>如判断考试分数，写法如下[root@centos7 ~]awk -v score==80 &apos;BEGIN{if(score &lt;60){print &quot;no pass&quot;}else if(score &lt;=80){print &quot;soso&quot;}else {print good}}&apos;sosoawk -F: &apos;{if($3&gt;=1000)print $1,$3}&apos; /etc/passwd判断UID是否大于1000，是则打印用户名和UIDawk -F: &apos;{if($NF==&quot;/bin/bash&quot;) print $1}&apos; /etc/passwd判断用户shell是否为/bin/bash,是则打印用户名awk &apos;{if(NF&gt;5) print $0}&apos; /etc/fstab判断域或列个数是否大于5，是则打印该行awk -F: &apos;{if($3&gt;=1000) {printf &quot;Common user: %s\n&quot;,$1} else {printf &quot;root orSysuser: %s\n&quot;,$1}}&apos; /etc/passwd等于上文中的 awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd例如：随机生成1000个数字，用awk取出最大值和最小值(可以用shell写法)    1.生成1000个数字        for i in {1..1000};do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot;             &gt;&gt; f1.txt;else echo -e &quot;,$RANDOM\c&quot; &gt;&gt; f1.txt ;fi;done    2.用awk取出最大值和最小值        awk -F&apos;,&apos; &apos;{i=2;max=$1,while(i&lt;=NF){if($i &gt; max){max=$i}else         if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; f1.txt验证用awk是否取出的值为正确的：    方法一：用tr验证        tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | head -n1        tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | tail -n1    方法二：用shell脚本验证    #!/bin/bash    for i in {1..1000};do</code></pre><h4 id="awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，"><a href="#awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，" class="headerlink" title="awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，"></a>awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，</h4><h4 id="这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理"><a href="#这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理" class="headerlink" title="这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理"></a>这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理</h4><h4 id="awk中while循环控制语句的语法及用法"><a href="#awk中while循环控制语句的语法及用法" class="headerlink" title="awk中while循环控制语句的语法及用法"></a>awk中while循环控制语句的语法及用法</h4><pre><code>语法：while(condition){statement;…}条件“真”，进入循环；条件“假”，退出循环使用场景：对一行内的多个字段逐一类似处理时使用对数组中的各元素逐一处理时使用此时涉及到系统自带的一个函数length(函数在下面会有介绍)示例：1.统计每一行第一个字段的长度root@centos7 ~]awk -F: &apos;{print length($1),$1}&apos; /etc/passwd4 root3 bin6 daemon3 adm2.统计/etc/passwd第一行的每个字段的长度[root@centos7 ~]awk -F: &apos;NR==1{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/passwdroot 4x 10 10 1root 4/root 5/bin/bash 93.统计grub2.cfg文件中linux16那行的每个字段的长度[root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/grub2.cfglinux16 7/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46ro 2crashkernel=auto 16rhgb 4quiet 5LANG=en_US.UTF-8 16linux16 7/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46ro 2crashkernel=auto 16rhgb 4quiet 54.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用while循环root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){if(length($i)&gt;=10){print $i,length($i)};i++}}&apos; /etc/grub2.cfg/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16LANG=en_US.UTF-8 16/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 165.面试题用awk取出文本f5的最大值和最小值，需要先生成1000个随机数存到f5中如何做？1.不用awk，可以通过脚本实现最大值和最小值2.用awk如何来做？？先生成1000个随机数[root@centos7 ~]for i in `seq 1000`;do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f5;else echo -e &quot;,$aRANDOM\c&quot; &gt;&gt; f5 ;fi;done生成了1000随机数，如何取最大值最小值？[root@centos7 ~]awk -F&quot;,&quot; &apos;{i=2;max=$1;min=$1;while(i&lt;=NF){if($i &gt; max){max=$i}else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; &lt; f5max=32643 min=60</code></pre><h3 id="awk中do-while循环控制语句"><a href="#awk中do-while循环控制语句" class="headerlink" title="awk中do-while循环控制语句"></a>awk中do-while循环控制语句</h3><pre><code>语法：do {statement;…}while(condition)意义：无论真假，至少执行一次循环体</code></pre><h5 id="do-while使用示例："><a href="#do-while使用示例：" class="headerlink" title="do-while使用示例："></a>do-while使用示例：</h5><pre><code>求1-100正整数的和[root@centos7 ~]awk &apos;BEGIN{ total=0;i=0;do{ total+=i;i++;}while(i&lt;=100);print total}&apos;5050</code></pre><h3 id="awk中for循环控制语句"><a href="#awk中for循环控制语句" class="headerlink" title="awk中for循环控制语句"></a>awk中for循环控制语句</h3><pre><code>语法：for(expr1;expr2;expr3) {statement;…}常见用法：for(variable assignment;condition;iteration process){for-body}特殊用法：能够遍历数组中的元素语法：for(var in array) {for-body}</code></pre><h6 id="for循环使用示例："><a href="#for循环使用示例：" class="headerlink" title="for循环使用示例："></a>for循环使用示例：</h6><pre><code>1.求1-100正整数的和：[root@centos7 ~]awk &apos;BEGIN{for(i=1;i&lt;=100;i++)sum+=i;print sum}&apos;50502.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用for循环[root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{for(i=1;i&lt;=NF;i++){if(length($i)&gt;=10){print $i,length($i)}}}&apos; /etc/grub2.cfg/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16LANG=en_US.UTF-8 16/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16</code></pre><h3 id="awk中的switch控制语句"><a href="#awk中的switch控制语句" class="headerlink" title="awk中的switch控制语句"></a>awk中的switch控制语句</h3><pre><code>类似于shell中的case语句语法：switch(expression) {case VALUE1 or /REGEXP/: statement1; caseVALUE2 or /REGEXP2/: statement2; ...; default: statementn}</code></pre><h3 id="awk中的continue-break，next控制语句"><a href="#awk中的continue-break，next控制语句" class="headerlink" title="awk中的continue,break，next控制语句"></a>awk中的continue,break，next控制语句</h3><p>break和continue<br>next:<br>提前结束对本行处理而直接进入下一行处理（awk自身循环）</p><h5 id="continue的示例"><a href="#continue的示例" class="headerlink" title="continue的示例"></a>continue的示例</h5><pre><code>求1000以内偶数的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==0)continue;sum+=i}print sum}&apos;2500求1000以内奇数的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==1)continue;sum+=i}print sum}&apos;2550求1000以内除了66的所有数字的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i==66)continue;sum+=i}print sum}&apos;4984</code></pre><h5 id="break的示例："><a href="#break的示例：" class="headerlink" title="break的示例："></a>break的示例：</h5><pre><code>求1000数字中，当大于100时，跳出循环，即求100以内的和[root@centos7 ~]#awk &apos;BEGIN{sum=0;for(i=1;i&lt;=1000;i++){if(i&gt;100)break;sum+=i}print sum}&apos;5050</code></pre><h5 id="next的示例："><a href="#next的示例：" class="headerlink" title="next的示例："></a>next的示例：</h5><pre><code>因为提前结束对本行处理而直接进入下一行处理（因为awk本身就是循环行的功能），所以示例打印/etc/passwd下的奇数行[root@centos7 ~]awk -F: &apos;{if(NR%2==0)next;print NR,$0}&apos; /etc/passwd1 root:x:0:0:root:/root:/bin/bash3 daemon:x:2:2:daemon:/sbin:/sbin/nologin5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin11 games:x:12:100:games:/usr/games:/sbin/nologin13 nobody:x:99:99:Nobody:/:/sbin/nologin还可以这样写：awk -F: &apos;NR%2==1{print NR,$0}&apos; /etc/passwd</code></pre><hr><hr><h3 id="awk数组-一个非常使用的功能"><a href="#awk数组-一个非常使用的功能" class="headerlink" title="awk数组-一个非常使用的功能"></a>awk数组-一个非常使用的功能</h3><h6 id="awk的数组全都是关联数组"><a href="#awk的数组全都是关联数组" class="headerlink" title="awk的数组全都是关联数组"></a>awk的数组全都是关联数组</h6><pre><code>关联数组：array[index-expression]index-expression:• (1) 可使用任意字符串；字符串要使用双引号括起来• (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”• (3) 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历</code></pre><h4 id="数组的去重的效果示例："><a href="#数组的去重的效果示例：" class="headerlink" title="数组的去重的效果示例："></a>数组的去重的效果示例：</h4><pre><code>awk &apos;!arr[$0]++&apos; dupfileawk &apos;{!arr[$0]++;print $0, arr[$0]}&apos; dupfileecho abc abc ccc bcd ddd ddd abc abc &gt;&gt; f1.txt</code></pre><h4 id="awk关联数组的遍历："><a href="#awk关联数组的遍历：" class="headerlink" title="awk关联数组的遍历："></a>awk关联数组的遍历：</h4><pre><code>若要遍历数组中的每个元素，要使用for循环:因为关联数组下标是无序性for(var in array) {for-body}注意：var会遍历array的每个索引</code></pre><h4 id="数组的使用示例："><a href="#数组的使用示例：" class="headerlink" title="数组的使用示例："></a>数组的使用示例：</h4><pre><code>示例1.定义awk数组[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]}&apos;zhang可以用for循环把每一个数组的值都表示出来[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;];for(i in title){print i,title[i]}}&apos;zhangcoo liuceo zhangcto wang但输出时数组元素时，是无序的，这就是关联数组的特性示例2.awk数组中的重要功能    [root@centos7 ~]cat f6    abc    abc    ddd    ccc    aaa    ccc    ccc    [root@centos7 ~]awk &apos;!line[$0]++&apos; f6    abc    ddd    ccc    aaa问题：为什么执行结果是这个？？原因：awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6实际上是隐藏了{print $0}，这个隐藏功能在awk很重要！！！，但是要和后面patter中的空模式区别开&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印而后面的数组里的是加了双括号{}，{line[$0]++}即用的patter的空模式，即文本中的每一行都处理这两个写法是不一样的，别混淆了分析：基于这个考虑进行分析 &apos;!line[$0]++&apos; = &apos;!line[$0]++{print $0}&apos;当读取文本f6的第一行时=abc!line[&quot;abc&quot;]++，因为abc没有值，line[&quot;abc&quot;]=0为假，取反！line[&quot;abc&quot;]后为真所以把第一行的abc打印了一次，打印第一行结束后line[&quot;abc&quot;]=1当读取文本f6的第二行时=abc!line[&quot;abc&quot;]++，在之前基础上line[&quot;abc&quot;]=1为假，取反！line[&quot;abc&quot;]=0后为假所以把第二行的abc不打印，结束后line[&quot;abc&quot;]=2以此类推，发现后续出现abc都不会打印，但是line[&quot;abc&quot;]都会在之前的基础上+1，即达到去重并统计的目的而处理第三行!line[&quot;ddd&quot;]++时，和上述abc一样，第一次出现则打印，后续也不会打印所以，命令执行结果为去重的效果从这个命令执行结果也可以明显看到上述的分析结果可以看出abc的值是递增的，也就是abc出现的次数[root@centos7 ~]awk &apos;{!line[$0]++;print $0, line[$0]}&apos; f6abc 1abc 2ddd 1ccc 1aaa 1ccc 2</code></pre><hr><h3 id="awk数组中的重要功能之for循环遍历数组，很具有实用性"><a href="#awk数组中的重要功能之for循环遍历数组，很具有实用性" class="headerlink" title="awk数组中的重要功能之for循环遍历数组，很具有实用性"></a>awk数组中的重要功能之for循环遍历数组，很具有实用性</h3><h6 id="在后面的统计服务的一些日志文件很有作用"><a href="#在后面的统计服务的一些日志文件很有作用" class="headerlink" title="在后面的统计服务的一些日志文件很有作用"></a>在后面的统计服务的一些日志文件很有作用</h6><pre><code>如果要理解遍历awk数组，需要深刻理解上述的示例2:awk &apos;!line[$0]++&apos; f6是怎么实现的但还是有些和数组里的，遍历$2,把$2不同的值，当成数组的下标有些区别的</code></pre><h3 id="若要遍历数组中的每个元素，要使用for循环"><a href="#若要遍历数组中的每个元素，要使用for循环" class="headerlink" title="若要遍历数组中的每个元素，要使用for循环"></a>若要遍历数组中的每个元素，要使用for循环</h3><pre><code>for(var in array) {for-body}注意：var会遍历array的每个索引</code></pre><h6 id="为什么要通过特殊写法去遍历awk中的数组？"><a href="#为什么要通过特殊写法去遍历awk中的数组？" class="headerlink" title="为什么要通过特殊写法去遍历awk中的数组？"></a>为什么要通过特殊写法去遍历awk中的数组？</h6><pre><code>如果是普通数组，用循环0,1,2,3做个循环即可；而awk的数组都是关联数组，[]中括号里的下标都不固定所以要通过 for(var in array(数组名称)) {for-body}这样的特殊写法，var的值会从array数组元素取其下标，相当于每次循环var的值是等于array数组的下标的注意：当我们直接引用一个数组中不存在的元素时，awk会自动创建这个元素，并且为其赋值为&quot;空字符串&quot;</code></pre><h4 id="for循环遍历数组使用示例："><a href="#for循环遍历数组使用示例：" class="headerlink" title="for循环遍历数组使用示例："></a>for循环遍历数组使用示例：</h4><pre><code>示例1：[root@centos7 ~]awk &apos;BEGIN{print test[&quot;ip&quot;];test[&quot;ip&quot;]++;print test[&quot;ip&quot;]}&apos;1第一次输出为空，第二次自动加1示例2：1.[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;for(i in title){print title[i]}}&apos;liuzhangwang分析：for(i in title){print title[i]，i的值来自于title的下标，即i=ceo coo cto,而且是无序打印示例3：[root@centos7 ~]netstat -tanActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN     tcp        0      0 192.168.122.1:53        0.0.0.0:*               ESTABLISTEN     tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN     tcp        0     52 192.168.34.103:22       192.168.34.1:8816       ESTABLISHEDtcp        0      0 192.168.34.103:22       192.168.34.105:49746    ESTABLISHEDtcp6       0      0 :::111                  :::*                    LISTEN     tcp6       0      0 :::22                   :::*                    LISTEN     tcp6       0      0 ::1:631                 :::*                    LISTEN     tcp6       0      0 ::1:25                  :::*                    LISTEN     [root@centos7 ~]netstat -tan | awk &apos;/^tcp/{state[$NF]++}END{for(i in state) { print i,state[i]}}&apos;LISTEN 8ESTABLISHED 3分析：state[$NF]++以空白做分隔符，统计同一类型的状态有多少个for(i in state) { print i,state[i]} 即统计了出现状态的多少种以及出现的次数不明白的可以看上文中的示例2：awk数组中的重要功能当然，看懂这个命令，需要知道两个知识点1.空模式，即全文反复提到的{state[$NF]++}={state[$NF]++}{print $0}2.END模式，END的模式是在前面动作结束之后，最后执行依次END模式中的命令，所以先不用考虑空模式下面再一次对空模式中的处理过程，做详细的描述空模式中，我们创建了一个state数组，并将状态值(LISTEN、ESTABLISHED)作为引用下标，所以执行到第一行时，我们引用的是state[&quot;LISTEN&quot;],很明显，这个元素并不存在，所以，当第一行被空模式的动作处理完毕后state[&quot;LISTEN&quot;]的值已经被赋值为1了。这时，空模式中的动作继续处理下一行，而下一行的$NF=ESTABLISTEN；state[&quot;ESTABLISTEN&quot;]所以，state[&quot;ESTABLISTEN&quot;]第一次参与运算过程与上一个原理相同直到再次遇到相同的状态时，使用同样一个IP地址作为下标的元素将会再次被自加直到处理完所有的行，开始执行END模式中的动作。而END模式中，我们打印出state数组中的所有元素的下标，以及元素对应的值。此刻，state数组中的下标即为各种状态，元素的值即为对应状态出现的次数，最终，我们统计出每个状态出现的次数。3.统计/var/log/httpd/access_log，每个IP链接的次数root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; &quot;Mozil&quot;192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;192.168.34.103 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;[root@centos7 ~]awk &apos;{ip[$1]++}END{for(i in ip){print i,ip[i]}}&apos; /var/log/httpd/access_log192.168.34.101 9192.168.34.103 13::1 4192.168.34.1 88效果等于：[root@centos7 ~]awk &apos;{print $1}&apos; /var/log/httpd/access_log |sort|uniq -c4 ::188 192.168.34.19 192.168.34.10113 192.168.34.1034.统计ss -nt ip链接次数[root@centos7 ~]ss -ntState      Recv-Q Send-Q                 Local Address:Port                                Peer Address:Port              ESTAB      0      52                    192.168.34.103:22                                  192.168.34.1:8816               ESTAB      0      0                     192.168.34.103:22                                192.168.34.105:49746              [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{ip[$(NF-2)]++}END{for(i in ip){print i,ip[i]}}&apos;192.168.34.105 1192.168.34.1 1效果等于：[root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;|sort|uniq -c1 192.168.34.11 192.168.34.1055.统计/etc/fstab文件系统类型分别有多少个[root@centos7 ~]cat /etc/fstab # /etc/fstab# Created by anaconda on Wed Sep 19 11:44:48 2018UUID=9612633f-e7f1-4b28-8813-403d209d7abc /                       xfs     defaults        0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot                   xfs     defaults        0 0UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data                   xfs     defaults        0 0UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap                    swap    defaults        0 0[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos;swap 1xfs 36.求下表中的男生和女生的平均成绩[root@centos7 ~]cat f9name sex scorea     m   90b     f   80c     f   99d     m   88e     m   80如何利用awk的数组功能来求？思路先求男的和和女的和？利用两个数组？[root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3}END{for(i in sum){print i,sum[i]}}&apos; -求男女分的和m 258f 179[root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3;num[$2]++}END{for(i in sum){print i,sum[i]/num[i]}}&apos;m 86f 89.57.统计下面每个名字出现的次数[root@centos7 ~]cat f1Allen PhillipsGreen LeeWilliam Aiden Janmes LeeAngel JackJack ThomasLucas KevinTyler LeeWilliam Allen[root@centos7 ~]cat f1 | awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,cuont[j]}}&apos;Tyler Angel Lucas William Thomas Green Jack Phillips Kevin </code></pre><hr><hr><h3 id="awk函数"><a href="#awk函数" class="headerlink" title="awk函数"></a>awk函数</h3><h6 id="awk也包括内置函数和自定义函数"><a href="#awk也包括内置函数和自定义函数" class="headerlink" title="awk也包括内置函数和自定义函数"></a>awk也包括内置函数和自定义函数</h6><h6 id="内置函数包括-rand-length，sub-gsub-split，system"><a href="#内置函数包括-rand-length，sub-gsub-split，system" class="headerlink" title="内置函数包括 rand,length，sub,gsub,split，system"></a>内置函数包括 rand,length，sub,gsub,split，system</h6><pre><code>数值处理：rand(i)：返回0和1之间一个随机数awk &apos;BEGIN{srand(); for (i=1;i&lt;=10;i++)print int(rand()*100) }&apos;字符串处理：• length([s])：返回指定字符串的长度• sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为secho &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,“-&quot;,$1)&apos;• gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表示的内容echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos;• split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所表示的数组中，第一个索引值为1,第二个索引值为2,…netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}&apos;END{for (i in count) {print i,count[i]}</code></pre><h4 id="awk内置函数之sub、gsub、split实现搜索替换切割的用法"><a href="#awk内置函数之sub、gsub、split实现搜索替换切割的用法" class="headerlink" title="awk内置函数之sub、gsub、split实现搜索替换切割的用法"></a>awk内置函数之sub、gsub、split实现搜索替换切割的用法</h4><pre><code>示例1：sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为sgsub(r,s,[t])表示全局替换sub(r,s,[t])不是贪婪模式，默认值替换搜索出来的第一个[root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,&quot;-&quot;,$1)&apos;2008-08:08 08:08:08只替换$1root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$1)&apos;2008-08-08 08:08:08全局替换$0[root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos;2008-08-08 08-08-08示例2：统计字符串中每个字母出现的次数abcdaabbccdd[root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 3b 3c 3d 3在文章最后会用另外一种写法进行过滤(文章最后会以以空位分隔符的特殊写法来表示)</code></pre><h5 id="awk内置函数split的切割功能"><a href="#awk内置函数split的切割功能" class="headerlink" title="awk内置函数split的切割功能"></a>awk内置函数split的切割功能</h5><pre><code>示例1:    统计链接本机的IP和端口号    [root@centos7 ~]#netstat -tn    Active Internet connections (w/o servers)    Proto Recv-Q Send-Q Local Address           Foreign Address         State          tcp        0     52 192.168.34.103:22       192.168.34.1:8816       ESTABLISHED    tcp        0      0 192.168.34.103:22       192.168.34.105:49746    ESTABLISHED    [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}END{for (i in count) {print i,count[i]}}&apos;    192.168.34.105 1    192.168.34.1 1    [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[2]]++}END{for (i in count) {print i,count[i]}}&apos;    8816 1    49746 1    分析：    split($5,ip,&quot;:&quot;)将192.168.34.1:8816进行切割，数组ip的下标1放IP地址，下标2放端口号    count[ip[1]]++ 把ip下标为1也就是IP地址，把出现的IP个数，又给count当下标，就统计每个IP出现的次数    count[ip[2]]++ 把ip下标为2也就是端口号，把出现的端口号个数，又给count当下标，就统计每个端口号出现的次数</code></pre><h3 id="awk中的自定义函数格式："><a href="#awk中的自定义函数格式：" class="headerlink" title="awk中的自定义函数格式："></a>awk中的自定义函数格式：</h3><pre><code>awk自定义函数是用正规开发语言的函数格式function name ( parameter, parameter, ... ) { statements return expression}</code></pre><h5 id="awk自定义函数的用法："><a href="#awk自定义函数的用法：" class="headerlink" title="awk自定义函数的用法："></a>awk自定义函数的用法：</h5><pre><code>cat fun.awk,把函数写到文件中function max(x,y) {x&gt;y?var=x:var=yreturn var}BEGIN{print max(i,j)}awk -v i=10 -v j=20 -f fun.awk 调用函数即可，和shell中的函数类似</code></pre><h4 id="awk中很实用的内置函数system命令"><a href="#awk中很实用的内置函数system命令" class="headerlink" title="awk中很实用的内置函数system命令"></a>awk中很实用的内置函数system命令</h4><h6 id="system函数作用：在awk可以反过来调用linux里的命令"><a href="#system函数作用：在awk可以反过来调用linux里的命令" class="headerlink" title="system函数作用：在awk可以反过来调用linux里的命令"></a>system函数作用：在awk可以反过来调用linux里的命令</h6><pre><code>示例：    空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用    空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来示例1:显示/boot/grub2下的文件列表；调用命令时要加双引号[root@centos7 ~]#awk &apos;BEGIN{system(&quot;ls /boot/grub2&quot;)}&apos;device.map  fonts  grub.cfg  grubenv  i386-pc  locale或者这么写，先定义变量等于路径，再调用变量[root@centos7 ~]#awk &apos;BEGIN{dir=&quot;/boot/grub2&quot;;system(&quot;ls &quot;dir)}&apos;device.map  fonts  grub.cfg  grubenv  i386-pc  locale调用hostname命令，显示主机名[root@centos7 ~]#awk &apos;BEGIN{system(&quot;hostname&quot;)}&apos;centos7.localdomain示例2：之前处理过lastb中登录失败的IP，如果失败登录次数大于3次，扔到防火墙里，当时是先取出IP放到文件里，然后iptables再禁用；现在可以在awk中先取出IP,然后通过system(&quot;iptables &quot; IP)就可以直接扔到防火墙中具体实现？</code></pre><h3 id="awk脚本"><a href="#awk脚本" class="headerlink" title="awk脚本"></a>awk脚本</h3><pre><code>将awk程序写成脚本，直接调用或执行awk脚本使用示例：1.先写文本再调用cat f1.awk{if($3&gt;=1000)print $1,$3} awk -F: -f f1.awk /etc/passwd2.也可以写成脚本形式先写再调用[root@centos7 ~]vim f2.awk#!/bin/awk -f{if($3 &gt;=1000)print $1,$3} [root@centos7 ~]./f2.awk -F: /etc/passwdnfsnobody 65534test 1000gentoo 1007nginx 1008ceshi 1009</code></pre><h4 id="向awk脚本传递参数"><a href="#向awk脚本传递参数" class="headerlink" title="向awk脚本传递参数"></a>向awk脚本传递参数</h4><pre><code>格式：awkfile var=value var2=value2... Inputfile注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变量都需要一个-v参数</code></pre><h6 id="awk脚本传参使用示例："><a href="#awk脚本传参使用示例：" class="headerlink" title="awk脚本传参使用示例："></a>awk脚本传参使用示例：</h6><pre><code>cat test.awk #!/bin/awk –f {if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3}chmod +x test.awktest.awk -F: min=100 max=200 /etc/passwd</code></pre><h4 id="工作中遇到的常用awk文本解决案例："><a href="#工作中遇到的常用awk文本解决案例：" class="headerlink" title="工作中遇到的常用awk文本解决案例："></a>工作中遇到的常用awk文本解决案例：</h4><h5 id="Linux-Web服务器网站故障分析常用的命令"><a href="#Linux-Web服务器网站故障分析常用的命令" class="headerlink" title="Linux Web服务器网站故障分析常用的命令"></a>Linux Web服务器网站故障分析常用的命令</h5><pre><code>系统连接状态篇：1.查看TCP连接状态netstat -nat |awk &apos;{print $6}&apos;|sort|uniq -c|sort -rn每出现一被/^tcp/模式匹配到的行，数组S[$NF]就加1，NF为当前匹配到的行的最后一个字段，此处用其值做为数组S的元素索引；netstat -n | awk &apos;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}&apos; 或netstat -n | awk &apos;/^tcp/ {++state[$NF]}; END {for(key in state) print key,&quot;\t&quot;,state[key]}&apos;netstat -n | awk &apos;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,&quot;t&quot;,arr[k]}&apos;netstat -n |awk &apos;/^tcp/ {print $NF}&apos;|sort|uniq -c|sort -rnnetstat -ant | awk &apos;{print $NF}&apos; | grep -v &apos;[a-z]&apos; | sort | uniq -c    2.查找请求数请20个IP（常用于查找攻来源）：方法一：netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20方法二：netstat -ant |awk &apos;/:80/{split($5,ip,&quot;:&quot;);++A[ip[1]]}END{for(i in A) print A[i],i}&apos; |sort -rn|head -n203.用tcpdump嗅探80端口的访问看看谁最高tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; ‘{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}’ | sort | uniq -c | sort -nr |head -204.查找较多time_wait连接netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n205.找查较多的SYN连接netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more6.根据端口列进程netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1</code></pre><h5 id="网站日志分析篇1（Apache）："><a href="#网站日志分析篇1（Apache）：" class="headerlink" title="网站日志分析篇1（Apache）："></a>网站日志分析篇1（Apache）：</h5><pre><code>1.获得访问前10位的ip地址cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’2.访问次数最多的文件或页面,取前20cat access.log|awk ‘{print $11}’|sort|uniq -c|sort -nr|head -203.列出传输最大的几个exe文件（分析下载站的时候常用）cat access.log |awk ‘($7~/.exe/){print $10 &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -204.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数cat access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -1005.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面cat access.log |awk ‘($7~/.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -1006.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -1007.列出传输时间超过 30 秒的文件cat access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -208.统计网站流量（G)cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’9.统计404的连接awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort10. 统计http statuscat access.log |awk &apos;{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}&apos;cat access.log |awk &apos;{print $9}&apos;|sort|uniq -c|sort -rn10.蜘蛛分析，查看是哪些蜘蛛在抓取内容。/usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E &apos;bot|crawler|slurp|spider&apos;</code></pre><h5 id="网站日分析2-Squid篇）按域统计流量"><a href="#网站日分析2-Squid篇）按域统计流量" class="headerlink" title="网站日分析2(Squid篇）按域统计流量"></a>网站日分析2(Squid篇）按域统计流量</h5><pre><code>cat squid_access.log.tar.gz| awk &apos;{print $10,$7}&apos; |awk &apos;BEGIN{FS=&quot;[ /]&quot;}{trfc[$4]+=$1}END{for(domain in trfc){printf &quot;%st%dn&quot;,domain,trfc[domain]}}&apos;</code></pre><h5 id="安全篇：-ssh-lastb"><a href="#安全篇：-ssh-lastb" class="headerlink" title="安全篇：(ssh lastb)"></a>安全篇：(ssh lastb)</h5><pre><code>ssh日志中失败登录的IP，取出来 /var/log/secureawk &apos;/Failed PASSWORD/{IP[$(NF-3)]++}END{for(i in IP){print i,IP[i]}&apos; /var/log/secure1、文件ip_list.txt如下格式，请提取”.magedu.com”前面的主机名部分并写入到回到该文件中1 blog.magedu.com2 www.magedu.com…999 study.magedu.com2、统计/etc/fstab文件中每个文件系统类型出现的次数[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{print $3}&apos;|sort|uniq -c |sort -nr      3 xfs      1 swap[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos;swap 1xfs 33、统计/etc/fstab文件中每个单词出现的次数root@centos7 ~]cat /etc/fstab |awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,count[j]}}&apos;man 14、提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字[root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|awk &apos;gsub(/[^0-9]/,&quot;&quot;,$0)&apos;05973[root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|tr -dc &quot;[0-9]&quot;059735、有一文件记录了1-100000之间随机的整数共5000个，存储的格式100,50,35,89…请取出其中最大和最小的整数6、解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT[root@centos7 ~]awk &apos;{access[$1]++}END{for(i in access){if(access[i]&gt;=1){print i,access[i]}}}&apos; /var/log/httpd/access_log 192.168.34.101 9192.168.34.103 13只过滤出IP，监控任务可以写到计划任务里，或者用内置函数system[&quot;iptables&quot;]调用？7、将以下文件内容中FQDN取出并根据其进行计数从高到低排序http://mail.magedu.com/index.htmlhttp://www.magedu.com/test.htmlhttp://study.magedu.com/index.htmlhttp://blog.magedu.com/index.htmlhttp://www.magedu.com/images/logo.jpghttp://blog.magedu.com/20080102.html[root@centos7 ~]#cat f5|sed -nr &apos;s@.*//([^/]+)/.*@\1@p&apos;|sort|uniq -c|sort -nr      2 www.magedu.com      2 blog.magedu.com      1 study.magedu.com      1 mail.magedu.com[root@centos7 ~]#cat f5|awk -F&quot;/&quot; &apos;{print $3}&apos;|sort|uniq -c|sort -nr      2 www.magedu.com      2 blog.magedu.com      1 study.magedu.com      1 mail.magedu.com8、将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出同一inode中，beginnumber的最小值和endnumber的最大值inode|beginnumber|endnumber|counts|106|3363120000|3363129999|10000|106|3368560000|3368579999|20000|310|3337000000|3337000100|101|310|3342950000|3342959999|10000|310|3362120960|3362120961|2|311|3313460102|3313469999|9898|311|3313470000|3313499999|30000|311|3362120962|3362120963|2|输出的结果格式为：310|3337000000|3362120961|10103|311|3313460102|3362120963|39900|106|3363120000|3368579999|30000|awk -F&apos;|&apos; &apos;NR==1{print;next}{a[$1]?(a[$1]&gt;$2?a[$1]=$2:0):(a[$1]=$2);b[$1]?(b[$1]&lt;$3?b[$1]=$3:0):(b[$1]=$3);c[$1]+=$4}END{l=asorti(a,d);for(i=1;i&lt;=l;i++)print d[i] FS a[d[i]] FS b[d[i]] FS c[d[i]] FS}&apos; file[解析]  第一行直接打印。从第2行开始以$1为下标，建立3个数组，比较出$2的最小值，$3的最大值，然后把$4进行累加，最后进行排序后依次取出各项值。  这其中运用了三目运算的嵌套，跟我们 if(){if(){}}else{} 的使用是一个道理，不要认为复杂，如果觉得模糊不清，仔细读懂流程控制。9.统计字符串中每个字母出现的次数abcdaabbccdd[root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 3b 3c 3d 3下面的写法在双引号前一定要加一个空格才能匹配出来或者用单引号，但是也需要在前面几个空格[root@centos7 mnt]#echo abcdaabbccdd|awk -F &quot;&quot; &apos;{for(i=1;i&lt;=NF;i++)x[$i]++}END{for(i in x){print i,x[i]}}&apos; a 3                                 此处一定有个空格b 3c 3d 3或者用单引号，但是也需要在前面几个空格[root@mini7-1 ~]#echo abcdaabbccdd |awk -F &apos;&apos; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 2b 3c 3d 2root@centos7 mnt]#echo abcdaabbccdd | grep -o &quot;[a-z]&quot;|sort|uniq -c      3 a      3 b      3 c      3 d10.面试题：取出/etc/fstab中的挂载目录    [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos;    boot    data    swap    [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos;    boot    data    swap</code></pre><h3 id="AWK中的输入分隔符"><a href="#AWK中的输入分隔符" class="headerlink" title="AWK中的输入分隔符"></a>AWK中的输入分隔符</h3><h6 id="我们可以使用两次awk-F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。"><a href="#我们可以使用两次awk-F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。" class="headerlink" title="我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。"></a>我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。</h6><pre><code>要一次指定多个分隔符，需要将分隔符用中括号[]包裹起来，如果多个分隔符中有至少一个特殊字符，那么还需要在中括号外加上双引号或者单引号，并且使用两个或两个以上的\将其进行转义$、^、(、)、[、]、?、.、|示例1：        [root@node7-1 data]cat b.txt         ssh:user1@192.168.1.10        ssh:user2@192.168.1.11        ssh:user3@192.168.1.12    1.取user和IP        [root@node7-1 data]awk -F [:@] &apos;{print $2,$3}&apos; b.txt         user1 192.168.1.10        user2 192.168.1.11        user3 192.168.1.12    2.上面b.txt中的：和@换成^和|，又该怎么取？        [root@node7-1 data]awk -F &apos;[\\^\\|]&apos; &apos;{print $2,$3}&apos; b.txt         user1 192.168.1.10        user2 192.168.1.11        user3 192.168.1.12示例2：    示例1：        george[walker]bush        william[jefferson]clinton    如果要打印出由分隔符[和]分隔的三段数据，即可以分别使用两个或两个以上的\对[和]进行转义，如下所示    方法一：        awk -F &apos;[\\[\\]]&apos; &apos;{ print $1,$2,$3}&apos; name.txt        george walker bush        william jefferson clinton    方法二：        awk -F &apos;[][]&apos; &apos;{ print $1,$2,$3}&apos; name.txt        george walker bush        william jefferson clinton11.取出文本中的姓名和FQDN，awk的方法参照文章最上面的链接文章    [root@node7-1 data]cat a.txt     xiaoming\t20\thttp://sougou.com    xiaohua\t25\thttp://www.baidu.com    xiaodong\t30\thttp://www.jidong.com方法一：用awk取，以\t做分隔符，但是在表示方法上比较特殊    root@node7-1 data]awk -F&apos;\\\\t&apos; &apos;{print $1,$3}&apos; a.txt     xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com分析：    第一个给第二个转义，第三个给第四个转义，传给awk对就是\\t，awk再将\\解释成\t方法二：用awk和sed取    [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )t(.*)@\1\2@&apos;    xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com12.扩展11题的内容把t换成$,又该如何取？    [root@node7-1 data]cat a.txt     xiaoming\$20\$http://sougou.com    xiaohua\$25\$http://www.baidu.com    xiaodong\$30\$http://www.jidong.com方法一：还是只用awk来取    [root@node7-1 data]awk -F&apos;\\\\\\$&apos; &apos;{print $1,$3}&apos; a.txt     xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com    分析：        1.\\$是转义$的        2.前四个\\\\是转义\的方法二：awk和sed取    [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )\$(.*)@\1\2@&apos;    xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com分析：先用awk用\做分隔符来取，再用sed取，sed中的$需要转义</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;文本处理三剑客之awk&quot;&gt;&lt;a href=&quot;#文本处理三剑客之awk&quot; class=&quot;headerlink&quot; title=&quot;文本处理三剑客之awk&quot;&gt;&lt;/a&gt;文本处理三剑客之awk&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2017/10/18/文本三剑客之awk/awk.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本处理工具" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>旧事-大好河山</title>
    <link href="https://www.liukui.tech/2017/10/01/%E6%97%A7%E4%BA%8B-%E5%A4%A7%E5%A5%BD%E6%B2%B3%E5%B1%B1/"/>
    <id>https://www.liukui.tech/2017/10/01/旧事-大好河山/</id>
    <published>2017-10-01T00:00:00.000Z</published>
    <updated>2018-12-17T02:59:31.538Z</updated>
    
    <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <div id="hbe-security"> <div class="input-container"> <input type="password" class="form-control" id="pass" placeholder=" 输入密码,PC:Enter查看,Phone:输入法换行查看. " /> <label for="pass"> 输入密码,PC:Enter查看,Phone:输入法换行查看. </label> <div class="bottom-line"></div> </div> </div> <div id="encrypt-blog" style="display:none"> U2FsdGVkX1+pnyLetSP0eBABLJcuqZSBQQlvcbog3QGX7cNO4cllwHcCyFFG2hZ9qg9Wkj92PoBwmRLHRxHFE3+p6hfK1R81/yAdk4+PbdavlczAcbWuJxvwSuOvegR+8+ZSziVXZnDsXPUPLqCXzFe88WrpD3p/vz25NniEZLWK//opghUypUz2VUbGmj+GQYyDiObsavAv41qWE5B4LeMHUOH52xx0/LDoJTJpLKyt8tkCnOe7gs4yjGE/Gz81oZ/HdgozOC8NhBoC7PxALE86KPYTJPoUg90bpOrBkWaRtAtDFYAvKCeVseuvC4ma5+PtfaHS5Eb8i0FprGRxTL70gd782UdZqEkzSawYaQ/UoyVUcnutDUMF4KxVwYvT </div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      &lt;font size=3 color=&quot;#FF0000&quot;&gt;私密文章，需要输入密码.&lt;/font&gt;&lt;/br&gt;
    
    </summary>
    
      <category term="旧事，杂记" scheme="https://www.liukui.tech/categories/%E6%97%A7%E4%BA%8B%EF%BC%8C%E6%9D%82%E8%AE%B0/"/>
    
    
      <category term="旧事，杂记" scheme="https://www.liukui.tech/tags/%E6%97%A7%E4%BA%8B%EF%BC%8C%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>DHCP和PXE</title>
    <link href="https://www.liukui.tech/2017/07/06/DHCP%E5%92%8CPXE/"/>
    <id>https://www.liukui.tech/2017/07/06/DHCP和PXE/</id>
    <published>2017-07-06T00:00:00.000Z</published>
    <updated>2018-12-31T07:59:44.718Z</updated>
    
    <content type="html"><![CDATA[<p>PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobbler<br>cobbler实现系统自动化安装<a href="https://www.liukui.tech/2017/05/06/Cobbler/">cobbler自动化系统安装</a><br><a id="more"></a></p><h3 id="DHCP服务-amp-PXE自动化安装系统"><a href="#DHCP服务-amp-PXE自动化安装系统" class="headerlink" title="DHCP服务&amp;PXE自动化安装系统"></a>DHCP服务&amp;PXE自动化安装系统</h3><h3 id="DHCP服务-著名的Inter系统协会组织：研发的DHCP和DNS技术"><a href="#DHCP服务-著名的Inter系统协会组织：研发的DHCP和DNS技术" class="headerlink" title="DHCP服务:(著名的Inter系统协会组织：研发的DHCP和DNS技术)"></a>DHCP服务:(著名的Inter系统协会组织：研发的DHCP和DNS技术)</h3><p>DHCP官方文档：<a href="http://www.isc.org/downloads/DHCP/" target="_blank" rel="noopener">DHCP文档</a><br>BIND官网文档：<a href="https://www.isc.org/downloads/BIND/" target="_blank" rel="noopener">BIND文档</a><br>DNS搭建的相关文档:<a href="https://www.jianshu.com/p/50c8105fae32" target="_blank" rel="noopener">DNS原理解析&amp;搭建</a></p><p>PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobbler<br>cobbler实现系统自动化安装<a href="">cobbler自动化系统安装</a></p><p>全文只有二个实验：搭建DHCP和在centos7实现基于PXE安装centos7和centos6(centos6上原理类似)</p><h3 id="搭建DHCP服务器：基于UDP协议-dhcp服务器端口：67、dhcp客户端端口：68"><a href="#搭建DHCP服务器：基于UDP协议-dhcp服务器端口：67、dhcp客户端端口：68" class="headerlink" title="搭建DHCP服务器：基于UDP协议(dhcp服务器端口：67、dhcp客户端端口：68)"></a>搭建DHCP服务器：基于UDP协议(dhcp服务器端口：67、dhcp客户端端口：68)</h3><pre><code>DHCP: （Dynamic Host Configuration Protocol）    动态主机配置协议    局域网协议，UDP协议(67端口)主要用途：    用于内部网络和网络服务供应商自动分配IP地址给用户    用于内部网络管理员作为对所有电脑作集中管理的手段使用场景    自动化安装系统    解决IPV4资源不足问题</code></pre><h3 id="DHCP申请网络地址是通过四个过程实现的：四个数据报文"><a href="#DHCP申请网络地址是通过四个过程实现的：四个数据报文" class="headerlink" title="DHCP申请网络地址是通过四个过程实现的：四个数据报文"></a>DHCP申请网络地址是通过四个过程实现的：四个数据报文</h3><pre><code>DHCP共有八种报文    1.DHCP DISCOVER：客户端到服务器    2.DHCP OFFER ：服务器到客户端    3.DHCP REQUEST：客户端到服务器    4.DHCP ACK ：服务器到客户端    DHCP NAK：服务器到客户端,通知用户无法分配合适的IP    地址        DHCP DECLINE ：客户端到服务器，指示地址已被使用        DHCP RELEASE：客户端到服务器，放弃网络地址和取消    剩余的租约时间        DHCP INFORM：客户端到服务器, 客户端如果需要从DHCP        服务器端获取更为详细的配置信息，则发送Inform报文向        服务器进行请求，极少用到    同网段多DHCP服务        DHCP服务必须基于本地        先到先得的原则    跨网段        RFC 1542 Compliant Routers        dhcrelay: 中继    相关协议        Arp        rarp</code></pre><h3 id="DHCP服务器的实现方式：搭建DHCP服务器"><a href="#DHCP服务器的实现方式：搭建DHCP服务器" class="headerlink" title="DHCP服务器的实现方式：搭建DHCP服务器"></a>DHCP服务器的实现方式：搭建DHCP服务器</h3><pre><code>Linux DHCP协议的实现程序：dhcp, dnsmasq（dhcp,dns）    1.实现DHCP的软件有两个：dnsmasp,这个软件是安装系统是默认的一个        可以同时提供dns和dhcp两种服务，不是很专业        如：ss -ntl 看到的默认就有dnsmasp服务        LISTEN     0      5                  192.168.122.1:53          users:((&quot;dnsmasq&quot;,pid=1506,fd=6))    2.DHCP更专业：下面主要介绍</code></pre><h3 id="实验：DHCP服务的搭建"><a href="#实验：DHCP服务的搭建" class="headerlink" title="实验：DHCP服务的搭建"></a>实验：DHCP服务的搭建</h3><pre><code>实验前提：    1.把vmware虚拟机的主机都设置成仅主机模式，要不然会影响所在的        工作中的DHCP服务器，其他人可能会获取到实验配置的DHCP服务        获取到一个不能上网的IP地址    2.编辑vmware的虚拟网络编辑器，将仅主机的DHCP服务关闭，这样当前        就只有自己配置的DHCP服务器了Dhcp Server相关配置文件：    /etc/dhcp/dhcpd.conf  ---&gt;主要配置文件    /usr/lib/systemd/system/dhcpd.service  ---&gt;服务名    /usr/sbin/dhcpd        ---&gt;dhcp的主程序    /etc/dhcp/dhcpd.conf --&gt; /etc/rc.d/init.d/dhcpd    /etc/dhcp/dhcpd6.conf--&gt; /etc/rc.d/init.d/dhcpd6    /var/lib/dhcpd/dhcpd.leases   ---&gt;租出去的地址信息库文件    /usr/sbin/dhcrelay    /etc/rc.d/init.d/dhcrelay    dhcp server:67/udp    dhcp client: 68/udp    dhcpv6 client:546/udpDhcp client    dhclient    自动获取的IP信息： /var/lib/dhclient</code></pre><h3 id="dhcp-conf配置文件内容设置："><a href="#dhcp-conf配置文件内容设置：" class="headerlink" title="dhcp.conf配置文件内容设置："></a>dhcp.conf配置文件内容设置：</h3><pre><code>安装DHCP完,默认是启动不了的，因为配置文件dhcpd.conf是空的1.先通过模板生成新的配置文件    cp /usr/share/doc/dhcp*/dhcpd.conf.example /etc/dhcp/dhcpd.conf2.模板里的网段地址不对，需要修改，网段和IP范围    question：那么如何修改dhcd.conf配置文件？    answer：根据上面的模板文件中的信息自改自定义的一些值    该文件中定义了：        1.默认续租时间和最长租期        2.DHCP默认分配的网段和分配的IP地址范围        3.DHCP服务提供的默认网关地址和DNS地址3.前两项设置其他主机只是通过DHCP自动获取地址的需求，如果通过dhcp实现系统的    自动化安装，就不仅仅获取到地址，还需要从DHCP获取能启动计算机的文件，即    dhcp的配置文件中要有配置的地址：类似于grub的文件    其它配置选项：        filename: 指明引导文件名称        next-server：提供引导文件的服务器IP地址    示例：        filename &quot;pxelinux.0&quot;;        next-server 192.168.100.100;             网络中下载文件的主机地址，带有tftp功能    备注：如果网卡有pxe的功能即自带tftp的功能所以具有完整的功能的dhcp配置文件dhcp.conf内容类似；    default-lease-time 600;    max-lease-time 7200;    subnet 192.168.34.0 netmask 255.255.255.0 {        range 192.168.34.20 192.168.34.100;         option routers 192.168.34.1;        option domain-name-servers 6.6.6.6;        ext-server 192.168.34.103;        filename &quot;pxelinux.0&quot;;  PXE安装相关的配置      } 上面是主要配置内容，在dhcpd.conf中还可以把指定的mac地址与IP绑定    host passacaglia {        hardware ethernet 00:0c:29:af:45:f7;        fixed-address 192.168.34.80    }</code></pre><h3 id="安装tftp服务-UDP协议：69端口"><a href="#安装tftp服务-UDP协议：69端口" class="headerlink" title="安装tftp服务:(UDP协议：69端口)"></a>安装tftp服务:(UDP协议：69端口)</h3><pre><code>    yum install tftp-server -y    [root@node7-1 tftpboot]#rpm -ql tftp-server    /etc/xinetd.d/tftp                       /usr/lib/systemd/system/tftp.service    /usr/lib/systemd/system/tftp.socket    /usr/sbin/in.tftpd    /var/lib/tftpboot   存放下载上传的路径:系统所需要的文件centos7和centos6上安装tftp是由区别的    centos7上需要安装tftp-server服务--&gt;UDP69端口        yum install tftp-server        systemctl start tftp    在centos6上安装和telnet是一个道理，都依赖于xinetd        chkconfig tftp on--&gt; /etc/xinetd.d/tftp配置文件        service restart xinted</code></pre><h3 id="PXE介绍"><a href="#PXE介绍" class="headerlink" title="PXE介绍"></a>PXE介绍</h3><pre><code>PXE：    Preboot Excution Environment 预启动执行环境    Intel公司研发    基于Client/Server的网络模式，支持远程主机通过网络从远端服务器下载        映像，并由此支持通过网络启动操作系统    PXE可以引导和安装Windows,linux等多种操作系统</code></pre><h3 id="实验：在centos7实现基于PXE安装centos7和centos6"><a href="#实验：在centos7实现基于PXE安装centos7和centos6" class="headerlink" title="实验：在centos7实现基于PXE安装centos7和centos6"></a>实验：在centos7实现基于PXE安装centos7和centos6</h3><pre><code>自动化安装步骤：1.安装前准备：关闭防火墙和SELINUX，DHCP服务器静态IP2.安装软件包    httpd tftp-server dhcp syslinux system-config-kickstart    httpd:实现yum源    tftp-server：实现网络下载的文件    syslinux: 准备pxelinux.0文件         备注：centos6上是安装syslinux-nonlinux    system-config-kickstart制作kickstart软件，建议自己制作3.配置文件共享服务：    准备centos7&amp;centos6的yum源        systemctl enable httpd        systemctl start httpd        mkdir -pv /var/www/html/centos/{6,7}/os/x86_64        mount /dev/sr0 /var/www/html/centos/7/os/x86_64        mount /dev/sr1 /var/www/html/centos/6/os/x86_644.准备kickstart文件    拷贝已经安装机器上的anaconda文件，按照自定义稍微修改，放到http目录下    注意：644权限    cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg    cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg    ks应答文件的内容可以用system-config-kickstart或者anaconda修改就行了    最好是通过system-config-kickstart做一个应答文件，通过界面更深刻理解        每一项代表的意义    大概内容如下：(最后附件的有详细的ks文件内容)        url --url=http://192.168.34.7/centos/7/os/x86_64/        text        firewall --disabled        selinux --disabled        clearpart --all --initlabel        zerombr        reboot        %packages        @core        %end5.配置tftp服务    systemctl enable tftp.socket    systemctl start tftp.socket 6.配置DHCP服务    cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcpd/dhcpd.conf    vim /etc/dhcp/dhcpd.conf        option domain-name &quot;example.com&quot;;        default-lease-time 600;        max-lease-time 7200;        subnet 192.168.34.0 netmask 255.255.255.0 {            range 192.168.34.20 192.168.34.100;             option routers 192.168.34.1;            option domain-name-servers 6.6.6.6;            next-server 192.168.34.103;            filename &quot;pxelinux.0&quot;;           }    systemctl enable dhcpd    systemctl start dhcpd7.准备PXE相关文件    放pxelinux.0的专用目录，启动菜单        mkdir /var/lib/tftpboot/pxelinux.cfg/    分别存放6和7的vmliuz和initrd.img文件            mkdir linux{6,7}    拷贝6和7安装必要文件        cp /var/www/html/centos/6/os/x86_64/isolinux/{vmlinuz,initrd.img}             /var/lib/tftpboot/linux6/        cp /var/www/html/centos/7/os/x86_64/isolinux/{vmlinuz,initrd.img}             /var/lib/tftpboot/linux7/    cp /usr/share/syslinux/{pxelinux.0,menu.c32} /var/lib/tftpboot/    将光盘里的启动菜单拷贝到并改名为default        cp /var/www/html/centos/7/os/x86_64/isolinux.cfg /var/lib/tftpboot/            pxelinux.cfg/default 拷贝完所有文件,文件列表如下：    /var/lib/tftpboot/    .    ├── linux6    │   ├── initrd.img    │   └── vmlinuz    ├── linux7    │   ├── initrd.img    │   └── vmlinuz    ├── menu.c32    ├── pxelinux.0    └── pxelinux.cfg        └── default8.准备启动菜单菜单项可以自定义多个，如只有mini7和mini6的，还有必须要有本地硬盘启动的菜单项    但是要在文件内把各个的linuz和initrd路径vim /var/lib/tftpboot/pxelinux.cfg/defaultdefault menu.c32timeout 100menu title PXE Install CentOSlabel mini7  menu label ^Auto Install Mini CentOS 7  kernel linux7/vmlinuz  append initrd=linux7/initrd.img ks=http://192.168.34.7/ksdir/ks7-mini.cfglabel mini6  menu label ^Auto Install Mini CentOS 6  kernel linux6/vmlinuz  append initrd=linux6/initrd.img ks=http://192.168.34.7/ksdir/ks6-mini.cfglabel local  menu default  menu label Boot from ^local drive  localboot 0xffff.  9.准备完所有的文件和软件后，启动所有的服务，就可以测试PXE安装了。</code></pre><h3 id="附带centos7和centos6的ks应答文件模板：建议通过ystem-config-kickstart做一个应答文件，通过界面更深刻理解每一项代表的意义，当然也可以修改anaconda-ks-cfg文件"><a href="#附带centos7和centos6的ks应答文件模板：建议通过ystem-config-kickstart做一个应答文件，通过界面更深刻理解每一项代表的意义，当然也可以修改anaconda-ks-cfg文件" class="headerlink" title="附带centos7和centos6的ks应答文件模板：建议通过ystem-config-kickstart做一个应答文件，通过界面更深刻理解每一项代表的意义，当然也可以修改anaconda-ks.cfg文件"></a>附带centos7和centos6的ks应答文件模板：建议通过ystem-config-kickstart做一个应答文件，通过界面更深刻理解每一项代表的意义，当然也可以修改anaconda-ks.cfg文件</h3><h3 id="ks6-mini-cfg"><a href="#ks6-mini-cfg" class="headerlink" title="ks6-mini.cfg"></a>ks6-mini.cfg</h3><pre><code>installurl --url=http://192.168.34.103/centos/6/os/x86_64/    #httpd的yum源路径lang en_US.UTF-8keyboard ustext      #纯文本安装reboot    #安装完重启network --onboot yes --device eth0 --bootproto dhcp --noipv6rootpw  --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQktJjA57WrZO0firewall --service=ssh      关闭防火墙authconfig --enableshadow --passalgo=sha512selinux --enforcing         关闭selinuxtimezone Asia/Shanghai      时区信息bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; # The following is the partition information you requested# Note that any partitions you deleted are not expressed# here so unless you clear all partitions first, this is# not guaranteed to workclearpart --all        清空分区信息zerombr                清空mbr#自定义的分区信息part /boot --fstype=ext4 --size=1024part / --fstype=ext4 --size=50000part /data --fstype=ext4 --size=30000part swap --size=2048#自定义的分区信息%packages@core%end   只安装最基本的核心包，后面也可以加上安装后脚本</code></pre><h3 id="ks7-mini-cfg：类似centos6的只是稍微的区别"><a href="#ks7-mini-cfg：类似centos6的只是稍微的区别" class="headerlink" title="ks7-mini.cfg：类似centos6的只是稍微的区别"></a>ks7-mini.cfg：类似centos6的只是稍微的区别</h3><pre><code>auth --enableshadow --passalgo=sha512url --url=http://192.168.34.103/centos/7/os/x86_64/textfirstboot --enable                                                                                                  ignoredisk --only-use=sdakeyboard --vckeymap=us --xlayouts=&apos;us&apos;lang en_US.UTF-8network  --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --activatenetwork  --hostname=centos7.localdomainrootpw --iscrypted $6$j2QVLmDO2xasQEW0$xEvr1jyj1mHs0HBtCc7jD73r6u4NrQCxwVoAu.SMXhwm8GiKBHq5ETZ2zFxP4rFsNavYbG0u6Gq13Igxrn1Ry.firewall --disabledselinux --disabledservices --enabled=&quot;chronyd&quot;timezone Asia/Shanghai --isUtcuser --name=test --password=$6$Awcwirg.mougtUlL$Yr1a9e2Vfs2k/Nizdn/ZeiunlsU.rJAmI1vhp1iafeccRt48h3PVIlnVwGvKPPt4dVuma/W32jzYIsn1XCrva. --iscrypted --gecos=&quot;test&quot;bootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sdaclearpart --all --initlabelzerombrrebootpart / --fstype=&quot;xfs&quot; --ondisk=sda --size=51200part /boot --fstype=&quot;xfs&quot; --ondisk=sda --size=1024part swap --fstype=&quot;swap&quot; --ondisk=sda --size=4096part /data --fstype=&quot;xfs&quot; --ondisk=sda --size=30720%packages@core%end</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobbler&lt;br&gt;cobbler实现系统自动化安装&lt;a href=&quot;https://www.liukui.tech/2017/05/06/Cobbler/&quot;&gt;cobbler自动化系统安装&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="系统安装" scheme="https://www.liukui.tech/categories/%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="运维，linux，windows" scheme="https://www.liukui.tech/tags/%E8%BF%90%E7%BB%B4%EF%BC%8Clinux%EF%BC%8Cwindows/"/>
    
  </entry>
  
  <entry>
    <title>Cobbler</title>
    <link href="https://www.liukui.tech/2017/05/06/Cobbler/"/>
    <id>https://www.liukui.tech/2017/05/06/Cobbler/</id>
    <published>2017-05-06T00:00:00.000Z</published>
    <updated>2018-12-16T10:01:07.099Z</updated>
    
    <content type="html"><![CDATA[<p><strong>在服务器很多的情况下，用U盘或者光盘安装时，就显得有点吃力了，虽然可以用PXE进行安装，但是PXE不支持UEFI<br>所以现在更多使用Cobbler来实现自动化部署.</strong></p><a id="more"></a><h3 id="Cobbler工作原理"><a href="#Cobbler工作原理" class="headerlink" title="Cobbler工作原理"></a>Cobbler工作原理</h3><p><img src="/2017/05/06/Cobbler/cobbler工作原理.png" alt=""></p><h3 id="系统自动安装之-cobbler"><a href="#系统自动安装之-cobbler" class="headerlink" title="系统自动安装之-cobbler"></a>系统自动安装之-cobbler</h3><p>之前写过PXE自动化安装的文档，但是PXE只支持BIOS，不支持UEFI:<a href="">PXE系统自动化部署</a><br>Cobbler可以同时支持BIOS和UEFI两种：基于PXE技术为基础的整合</p><p>BIOS+MBR：分区最多支持2T的<br>UEFI+GPT：分区可以支持大于2T的分区<br>    在之前的工作中，需要建立大于2T的分区时，PXE安装就不合适了</p><h3 id="cobbler-具有图形化管理界面的工具"><a href="#cobbler-具有图形化管理界面的工具" class="headerlink" title="cobbler:具有图形化管理界面的工具"></a>cobbler:具有图形化管理界面的工具</h3><pre><code>cobbler是什么？    实际上是把PXE技术用python代码做了封装，形成了相对完整的自动化安装，    但是实现PXE的原有的httpd，DHCP，tftp服务还是需要提前安装的。Cobbler:快速网络安装linux操作系统的服务，支持众多的Linux发行版：Red Hat、    Fedora、CentOS、Debian、Ubuntu和SuSE，也可以支持网络安装windowsPXE的二次封装，将多种安装参数封装到一个菜单Python编写提供了CLI和Web的管理形式</code></pre><h3 id="安装cobbler：EPEL源"><a href="#安装cobbler：EPEL源" class="headerlink" title="安装cobbler：EPEL源"></a>安装cobbler：EPEL源</h3><pre><code>安装包    cobbler 基于EPEL源    cobbler 服务集成        前面说过因为是基于PXE的,安装cobbler因为有依赖性，会自动安装下面的服务        PXE        DHCP        rsync        Httpd        DNS        Kickstart        syslinux         tftp-server         IPMI 电源管理启动cobbler:依赖于httpd，要想启动cobbler,必须先启动httpd    systemctl start httpd tftp dhcp    systemctl start cobblerd然后再检查cobbler环境    cobbler check</code></pre><h3 id="cobbler的相关配置文件"><a href="#cobbler的相关配置文件" class="headerlink" title="cobbler的相关配置文件"></a>cobbler的相关配置文件</h3><pre><code>安装：yum install cobbler dhcp配置文件目录 /etc/cobbler    /etc/cobbler/settings : cobbler 主配置文件(下文会对该文件修改4行)    /etc/cobbler/iso/: iso模板配置文件    /etc/cobbler/pxe: pxe模板文件    /etc/cobbler/power: 电源配置文件    /etc/cobbler/user.conf: web服务授权配置文件    /etc/cobbler/users.digest: web访问的用户名密码配置文件    /etc/cobbler/dhcp.template : dhcp服务器的的配置末班    /etc/cobbler/dnsmasq.template : dns服务器的配置模板    /etc/cobbler/tftpd.template : tftp服务的配置模板    /etc/cobbler/modules.conf : 模块的配置文件数据目录    /var/lib/cobbler/config/: 用于存放distros，system，profiles 等信息配置文件    /var/lib/cobbler/triggers/: 用于存放用户定义的cobbler命令    /var/lib/cobbler/kickstart/: 默认存放kickstart文件    /var/lib/cobbler/loaders/: 存放各种引导程序镜像目录    /var/www/cobbler/ks_mirror/: 导入的发行版系统的所有数据    /var/www/cobbler/images/ : 导入发行版的kernel和initrd镜像用于远程网络启动    /var/www/cobbler/repo_mirror/: yum 仓库存储目录日志目录    /var/log/cobbler/installing: 客户端安装日志    /var/log/cobbler/cobbler.log : cobbler日志</code></pre><h3 id="cobbler命令介绍"><a href="#cobbler命令介绍" class="headerlink" title="cobbler命令介绍"></a>cobbler命令介绍</h3><pre><code>cobbler commands介绍cobbler check 核对当前设置是否有问题cobbler list 列出所有的cobbler元素cobbler report 列出元素的详细信息cobbler sync 同步配置到数据目录,更改配置最好都要执行下cobbler reposync 同步yum仓库cobbler distro 查看导入的发行版系统信息cobbler system 查看添加的系统信息cobbler profile 查看配置信息</code></pre><h3 id="cobbler重要的参数-及下面需要修改的4行内容"><a href="#cobbler重要的参数-及下面需要修改的4行内容" class="headerlink" title="cobbler重要的参数:及下面需要修改的4行内容"></a>cobbler重要的参数:及下面需要修改的4行内容</h3><pre><code>/etc/cobbler/settings中重要的参数设置    default_password_crypted: &quot;$1$gEc7ilpP$pg5iSOj/mlxTxEslhRvyp/&quot;    server: 192.168.34.17    next_server: 192.168.34.17          server：&lt;cobbler服务器的 IP 地址&gt;    manage_dhcp: 1    manage_tftpd：1    pxe_just_once：1</code></pre><h3 id="cobbler环境检查：先启动cobbler服务再检查"><a href="#cobbler环境检查：先启动cobbler服务再检查" class="headerlink" title="cobbler环境检查：先启动cobbler服务再检查"></a>cobbler环境检查：先启动cobbler服务再检查</h3><pre><code>1.先启动cobbler服务，再用cobbler check 进行检查执行Cobbler check命令会报如下异常1 : The ‘server’ field in /etc/cobbler/settings must be set to something     other than localhost, or kickstarting features will not work. This    should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the ‘next_server’ field in /etc/cobbler/    settings must be set to something other than 127.0.0.1, and should    match the IP of the boot server on the PXE network.3 : some network boot-loaders are missing from /var/lib/cobbler/loaders,     you may run ‘cobbler get-loaders’ to download them, or, if you    only want to handle x86/x86_64 netbooting, you may ensure that you have installed a recent version of the syslinux package installed and    can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32,    elilo.efi, and yaboot. The ‘cobbler get-loaders’ command is the easiest way to resolve these requirements.4 : change ‘disable’ to ‘no’ in /etc/xinetd.d/rsync5 : comment ‘dists’ on /etc/debmirror.conf for proper debian support6 : comment ‘arches’ on /etc/debmirror.conf for proper debian support7 : The default password used by the sample templates for newly installed     machines (default_password_crypted in /etc/cobbler/settings)    is still set to ‘cobbler’ and should be changed, try: “openssl passwd -1 -salt ‘random-phrase-here’ ‘your-password-here’” to generate new    one8 : fencing tools were not found, and are required to use the (optional)     power management features. install cman or fence-agents to use them</code></pre><h3 id="Cobbler的8项报错解决方法"><a href="#Cobbler的8项报错解决方法" class="headerlink" title="Cobbler的8项报错解决方法"></a>Cobbler的8项报错解决方法</h3><pre><code>错误信息都是在/etc/cobbler/settings文件改了4行，在下文体现执行Cobbler check报错解决方式    第一个错误解决方法：    1.修改/etc/cobbler/settings文件中的server参数的值为提供cobbler服务的主机相        应的IP地址或主机名：384行，然后重新启动cobbler            server: 192.168.34.107    2.修改/etc/cobbler/settings文件中的next_server参数的值为提供PXE服务的主机        相应的IP地址:272行，指定的tftp的服务器地址            next_server: 192.168.34.107    3.执行cobbler get-loaders和cobbler sync；        如果当前节点可以访问互联网，执行&quot;cobbler get-loaders&quot;命令即可；         cobbler会自动通过互联网把最小化的系统启动文件下载下来放到        /var/lib/cobbler/loaders/下，再通过&quot;cobbler sync&quot;命令同步到/var/lib/tftpboot/下    4.cobbler认为是在centos6上，tftp服务是依赖于xinetd的，提示启动xinetd,在        这里，由于是在cnetos7上安装的，这项可以忽略    5.执行“chkconfig rsync on”命令即可        4,5,6项如果是在centos7上安装的cobbler是不需要修改也可以启动的    7.第7项是说安装的操作系统密码cobbler事先已经帮忙设置好了，但是不安全，需要自己        去修改一个自定义的密码(通过openssl passwd -1)生成：101行            default_password_crypted：修改成自己设置的密码备注：在这个提示里，还有一项建议修改，之前用PXE的时候，搭建的DHCP服务，dhcpd.conf    文件时通过模板生成的，但是在cobbler中，可以通过colbber来生成，但是需要改    /etc/cobbler/settings一项配置：242行        manage_dhcp: 0 改成 manage_dhcp: 1    再通过cobbler自带的dhcp模板：/etc/cobbler/dhcp.template，生成dhcpd.conf    只需要把这个模板改一下就行了，而不用想PXE那样通过模板生成dhcpd.conf文件    把dhcp.template里的网段地址改一下        subnet 192.168.34.0 netmask 255.255.255.0 {             option subnet-mask         255.255.255.0;             range dynamic-bootp        192.168.34.20 192.168.34.100;    再通过cobbler sync重新生成/etc/dhcp/dhcpd.conf,并且会开启DHCP服务</code></pre><h3 id="上面的报错全部解决之后，且httpd-tftp，dhcp-cobbler都启动之后，实际上就已经具备了雏形了"><a href="#上面的报错全部解决之后，且httpd-tftp，dhcp-cobbler都启动之后，实际上就已经具备了雏形了" class="headerlink" title="上面的报错全部解决之后，且httpd,tftp，dhcp,cobbler都启动之后，实际上就已经具备了雏形了"></a>上面的报错全部解决之后，且httpd,tftp，dhcp,cobbler都启动之后，实际上就已经具备了雏形了</h3><h3 id="var-lib-tftpboot的目录结构-上面的第三步完成后就生成下面的所有文件了"><a href="#var-lib-tftpboot的目录结构-上面的第三步完成后就生成下面的所有文件了" class="headerlink" title="/var/lib/tftpboot的目录结构:上面的第三步完成后就生成下面的所有文件了"></a>/var/lib/tftpboot的目录结构:上面的第三步完成后就生成下面的所有文件了</h3><pre><code>[root@mini7-1 tftpboot]#tree /var/lib/tftpboot    /var/lib/tftpboot    ├── boot    │   └── grub    │       └── menu.lst    ├── etc    ├── grub    │   ├── efidefault    │   ├── grub-x86_64.efi    │   ├── grub-x86.efi    │   └── images -&gt; ../images    ├── images    ├── images2    ├── memdisk    ├── menu.c32    ├── ppc    ├── pxelinux.0    ├── pxelinux.cfg    │   └── default    ├── s390x    │   └── profile_list    └── yaboot</code></pre><h3 id="接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘-centos6-amp-centos7"><a href="#接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘-centos6-amp-centos7" class="headerlink" title="接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘(centos6&amp;centos7)"></a>接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘(centos6&amp;centos7)</h3><pre><code>cobbler命令的选项：cobbler &lt;distro|profile|system|repo|image|mgmtclass|package|file&gt; ...         [add|edit|copy|getks*|list|remove|rename|report] [options|--help]cobbler &lt;aclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink&gt; [options|--help]这里用import选项将6和7的光盘导入cobbler的主机上    mount /dev/sr0 /mnt/   ---&gt;挂载centos7光盘    mount /dev/sr1 /media  ---&gt;挂载centos6光盘    cobbler import --path=/mnt/ --name=Centos-7.5-x86_64 --arch=x86_64    cobbler import --path=/media/ --name=Centos-6.10-x86_64 --arch=x86_64cobbler会把光盘拷贝到/var/www/cobbler/下分开存放，目录结构如下[root@mini7-1 cobbler]#tree -d /var/www/cobbler/var/www/cobbler├── images│   ├── Centos-6.10-x86_64│   └── Centos-7.5-x86_64├── ks_mirror│   ├── Centos-6.10-x86_64│   │   ├── EFI│   │   │   └── BOOT│   │   ├── images│   │   │   └── pxeboot│   │   ├── isolinux│   │   ├── Packages│   │   └── repodata│   ├── Centos-7.5-x86_64│   │   ├── EFI│   │   │   └── BOOT│   │   │       └── fonts│   │   ├── images│   │   │   └── pxeboot│   │   ├── isolinux│   │   ├── LiveOS│   │   ├── Packages│   │   └── repodata│   └── config├── links│   ├── Centos-6.10-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-6.10-x86_64│   └── Centos-7.5-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-7.5-x86_64├── localmirror├── misc├── pub├── rendered├── repo_mirror└── svc拷贝完，cobbler sync再同步一次然后cobbler会把/var/lib/tftpboot/pxelinux.cfg/default文件自动更新，生成新的菜单DEFAULT menuPROMPT 0MENU TITLE Cobbler | http://cobbler.github.io/TIMEOUT 200TOTALTIMEOUT 6000ONTIMEOUT localLABEL local        MENU LABEL (local)        MENU DEFAULT        LOCALBOOT -1LABEL Centos-6.10-x86_64        kernel /images/Centos-6.10-x86_64/vmlinuz        MENU LABEL Centos-6.10-x86_64        append initrd=/images/Centos-6.10-x86_64/initrd.img ksdevice=bootif lang=  kssendmac text  ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-6.10-x86_64        ipappend 2LABEL Centos-7.5-x86_64        kernel /images/Centos-7.5-x86_64/vmlinuz        MENU LABEL Centos-7.5-x86_64        append initrd=/images/Centos-7.5-x86_64/initrd.img ksdevice=bootif lang=  kssendmac text  ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-7.5-x86_64        ipappend 2MENU end</code></pre><p> 此时，就可以用cobbler实现自动化安装了，但是不能自定义ks应答文件安装，下面会讲解如何自定义cobbler的应答文件</p><h3 id="Cobbler中自定义应答文件"><a href="#Cobbler中自定义应答文件" class="headerlink" title="Cobbler中自定义应答文件"></a>Cobbler中自定义应答文件</h3><p>之前在PXE安装时，是自定义的kickstart应答文件，在cobbler中如何实现？</p><pre><code>1.在cobbler中，应答文件是放在/var/lib/cobbler/kickstarts/中2.把之前制作的ks6-mini.cfg，ks7-mini.cfg拷贝到此目录，但是拷贝完，但cobbler是无    法识别这些应答文件是对应的那个发行版本的，所以要绑定3.将自定义的应答文件和安装版本进行绑定4.这两个应答文件有一项需要修改    即url --url=这一项，要改成cobbler的yum源路径，$tree这里只显示ks6-mini.cfg的详细信息    install    url --url=http://192.168.34.103/centos/6/os/x86_64/  (PXE下的源路径)        #httpd的yum源路径，要改成$tree        或者改成具体的地址：即光盘拷贝到cobbler的具体路径        http://192.168.34.107/cobbler/ks_mirror/Centos-6.10-x86_64/    lang en_US.UTF-8    keyboard us    text      #纯文本安装    reboot    #安装完重启    network --onboot yes --device eth0 --bootproto dhcp --noipv6    rootpw  --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt    JjA57WrZO0    firewall --service=ssh      关闭防火墙    authconfig --enableshadow --passalgo=sha512    selinux --enforcing         关闭selinux    timezone Asia/Shanghai      时区信息    bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot;     # The following is the partition information you requested    # Note that any partitions you deleted are not expressed    # here so unless you clear all partitions first, this is    # not guaranteed to work    clearpart --all        清空分区信息    zerombr                清空mbr    #自定义的分区信息    part /boot --fstype=ext4 --size=1024    part / --fstype=ext4 --size=50000    part /data --fstype=ext4 --size=30000    part swap --size=2048    #自定义的分区信息    %packages    @core    %end   只安装最基本的核心包，后面也可以加上安装后脚本</code></pre><h3 id="将KS和OS关联，生成启动新的菜单"><a href="#将KS和OS关联，生成启动新的菜单" class="headerlink" title="将KS和OS关联，生成启动新的菜单"></a>将KS和OS关联，生成启动新的菜单</h3><p>自定义的应答文件的绑定、删除、重命名、显示菜单栏对应的ks应答文件信息</p><pre><code>在cobberl中    distro中记录的是cobbler中安装的发型版本对应的原文件的    [root@mini7-1 kickstarts]#cobbler distro list       Centos-6.10-x86_64       Centos-7.5-x86_64在cobberl中    profile是对应的各个发型版本的安装方法，就是安装启动界面的选择菜单栏，有多少个        就对应多少个菜单栏：如下图只有两个    [root@mini7-1 kickstarts]#cobbler profile list       Centos-6.10-x86_64       Centos-7.5-x86_64将自定义的应答文件和安装版本进行绑定：cobbler profile命令绑定将ks6-mini.cfg和centos6进行绑定    cobbler profile add --name=centos-6.10-x86_64_mini --distro=Centos-6.10-x86_64      --kickstart=/var/lib/cobbler/kickstarts/ks6-mini.cfgcobbler profile add --name=centos-7.5-x86_64_mini     --distro=Centos-7.5-x86_64     --kickstart=/var/lib/cobbler/kickstarts/ks7-mini.cfg也可以删除应答文件：    cobbler profile remove --name=Centos-6.10-x86_64    cobbler profile remove --name=Centos-7.5-x86_64也可以修改带单名    cobbler profile rename --name=Centos-7.5-x86_64             --newname=centos-7.5-x86_64_desktop查看菜单项对应的具体是哪个应答文件信息    cobbler profile report --name=centos-7.5-x86_64_mini/var/lib/tftpboot/pxelinux.cfg/default会自动生成新的菜单项，从cobbler profile list,也可以看出来[root@mini7-1 tftpboot]#cobbler profile list   Centos-6.10-x86_64   Centos-7.5-x86_64   centos-6.10-x86_64_mini   centos-7.5-x86_64_mini</code></pre><h3 id="cobbler的web管理实现"><a href="#cobbler的web管理实现" class="headerlink" title="cobbler的web管理实现"></a>cobbler的web管理实现</h3><p>此外cobbler是带有web管理界面的，不过需要安装web界面的包<br>    yum install cobbler-web -y</p><pre><code>配置文件：    [root@mini7-1 kickstarts]#rpm -qf cobbler-web    /etc/httpd/conf.d/cobbler_web.conf    cobbler-web是经过http协议的，所以 安装完，需要重启httpd服务    然后看到对应的是443端口启动了</code></pre><p>登录界面是，因为cobbler-web是https加密的<br>/etc/cobbler/modules.conf 验证方法;<br>/etc/cobbler/users.digest 记录的用户<br>增加用户</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;在服务器很多的情况下，用U盘或者光盘安装时，就显得有点吃力了，虽然可以用PXE进行安装，但是PXE不支持UEFI&lt;br&gt;所以现在更多使用Cobbler来实现自动化部署.&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="系统安装" scheme="https://www.liukui.tech/categories/%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="运维，linux，windows" scheme="https://www.liukui.tech/tags/%E8%BF%90%E7%BB%B4%EF%BC%8Clinux%EF%BC%8Cwindows/"/>
    
  </entry>
  
</feed>
