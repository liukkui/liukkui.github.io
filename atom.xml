<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coool&#39;s Blog</title>
  
  <subtitle>As we watch our love grow.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.liukui.tech/"/>
  <updated>2019-01-07T11:23:00.341Z</updated>
  <id>https://www.liukui.tech/</id>
  
  <author>
    <name>空腹吃早餐</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>httpd脚本</title>
    <link href="https://www.liukui.tech/2018/12/30/httpd%E8%84%9A%E6%9C%AC/"/>
    <id>https://www.liukui.tech/2018/12/30/httpd脚本/</id>
    <published>2018-12-30T11:28:24.082Z</published>
    <updated>2019-01-07T11:23:00.341Z</updated>
    
    <content type="html"><![CDATA[<p>httpd服务<br><a id="more"></a></p><h3 id="httpd服务脚本"><a href="#httpd服务脚本" class="headerlink" title="httpd服务脚本"></a>httpd服务脚本</h3><pre><code>#!/bin/bash## httpd        Startup script for the Apache HTTP Server## chkconfig: - 85 15# description: The Apache HTTP Server is an efficient and extensible  \#              server implementing the current HTTP standards.# processname: httpd# config: /etc/httpd/conf/httpd.conf# config: /etc/sysconfig/httpd# pidfile: /var/run/httpd/httpd.pid#### BEGIN INIT INFO# Provides: httpd# Required-Start: $local_fs $remote_fs $network $named# Required-Stop: $local_fs $remote_fs $network# Should-Start: distcache# Short-Description: start and stop Apache HTTP Server# Description: The Apache HTTP Server is an extensible server #  implementing the current HTTP standards.### END INIT INFO# Source function library.. /etc/rc.d/init.d/functionsif [ -f /etc/sysconfig/httpd ]; then        . /etc/sysconfig/httpdfi# Start httpd in the C locale by default.HTTPD_LANG=${HTTPD_LANG-&quot;C&quot;}# This will prevent initlog from swallowing up a pass-phrase prompt if# mod_ssl needs a pass-phrase from the user.INITLOG_ARGS=&quot;&quot;# Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server# with the thread-based &quot;worker&quot; MPM; BE WARNED that some modules may not# work correctly with a thread-based MPM; notably PHP will refuse to start.# Path to the apachectl script, server binary, and short-form for messages.apachectl=/usr/sbin/apachectlhttpd=${HTTPD-/usr/sbin/httpd}prog=httpdpidfile=${PIDFILE-/var/run/httpd/httpd.pid}lockfile=${LOCKFILE-/var/lock/subsys/httpd}RETVAL=0STOP_TIMEOUT=${STOP_TIMEOUT-10}# The semantics of these two functions differ from the way apachectl does# things -- attempting to start while running is a failure, and shutdown# when not running is also a failure.  So we just do it the way init scripts# are expected to behave here.start() {        echo -n $&quot;Starting $prog: &quot;        LANG=$HTTPD_LANG daemon --pidfile=${pidfile} $httpd $OPTIONS        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; touch ${lockfile}        return $RETVAL}# When stopping httpd, a delay (of default 10 second) is required# before SIGKILLing the httpd parent; this gives enough time for the# httpd parent to SIGKILL any errant children.stop() {        status -p ${pidfile} $httpd &gt; /dev/null        if [[ $? = 0 ]]; then                echo -n $&quot;Stopping $prog: &quot;                killproc -p ${pidfile} -d ${STOP_TIMEOUT} $httpd        else                echo -n $&quot;Stopping $prog: &quot;                success        fi        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; rm -f ${lockfile} ${pidfile}}reload() {    echo -n $&quot;Reloading $prog: &quot;    if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then        RETVAL=6        echo $&quot;not reloading due to configuration syntax error&quot;        failure $&quot;not reloading $httpd due to configuration syntax error&quot;    else        # Force LSB behaviour from killproc        LSB=1 killproc -p ${pidfile} $httpd -HUP        RETVAL=$?        fi    fi    echo}# See how we were called.case &quot;$1&quot; in  start)        start        ;;  stop)        stop        ;;  status)        status -p ${pidfile} $httpd        RETVAL=$?        ;;  restart)        stop        start        ;;  condrestart|try-restart)        if status -p ${pidfile} $httpd &gt;&amp;/dev/null; then                stop                start        fi        ;;  force-reload|reload)        reload        ;;  graceful|help|configtest|fullstatus)        $apachectl $@        RETVAL=$?        ;;  *)        echo $&quot;Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|reload|status|fullstatus|graceful|help|configtest}&quot;        RETVAL=2esacexit $RETVAL  </code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;httpd服务&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>HTTP协议</title>
    <link href="https://www.liukui.tech/2018/12/18/HTTP%E5%8D%8F%E8%AE%AE/"/>
    <id>https://www.liukui.tech/2018/12/18/HTTP协议/</id>
    <published>2018-12-18T00:00:00.000Z</published>
    <updated>2019-01-22T11:55:18.830Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HTTP协议和APACHE原理"><a href="#HTTP协议和APACHE原理" class="headerlink" title="HTTP协议和APACHE原理"></a>HTTP协议和APACHE原理</h3><p>Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等<br>本文说的是HTTP SERVER<a href="http://www.apache.org/" target="_blank" rel="noopener">apache</a><br><a id="more"></a><br>HTTP2.4的官方文档<a href="http://httpd.apache.org/docs/2.4/" target="_blank" rel="noopener">http2.4文档：安装，模块，指令等说明</a><br>HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a><br><!--more--></p><h3 id="http协议-应用层协议-主流http-1-1版本"><a href="#http协议-应用层协议-主流http-1-1版本" class="headerlink" title="http协议:应用层协议,主流http/1.1版本"></a>http协议:应用层协议,主流http/1.1版本</h3><h4 id="http协议的版本区别"><a href="#http协议的版本区别" class="headerlink" title="http协议的版本区别"></a>http协议的版本区别</h4><p>http0.9、http1.0、http1.1和http2.0的版本区别</p><ul><li><p>http/0.9:</p><blockquote><p>只有一个GET命令，且只能回应<em>.html文件格式，像</em>.txt等都不支持</p></blockquote></li><li><p>http/1.0:效率太低</p><blockquote><p>1.支持cache, MIME(支持各种资源类型), method<br>2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低<br>3.引入了POST命令和HEAD命令，头部信息和<br>4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用</p></blockquote></li><li><p>http/1.1:主流使用版本</p><blockquote><p>1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭，<br>  对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性</p><pre><code>这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求</code></pre><p>2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率<br>3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)<br>4.缺点：<br>  同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象<br>5.解决队头堵塞的办法：<br>  为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等<br>6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度:</p><pre><code>不带状态怎么理解？http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点</code></pre></blockquote></li><li><p>http/2.0：解决 HTTP/1.1效率不高的问题</p><blockquote><p>1.头信息和数据体都是二进制，称为头信息帧和数据帧<br>2.和http1.1区别：请求不需要排队，提高效率<br>  复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）<br>3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度<br>4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息)</p></blockquote></li></ul><h3 id="HTTP工作机制"><a href="#HTTP工作机制" class="headerlink" title="HTTP工作机制"></a>HTTP工作机制</h3><ul><li>工作机制主要分为两步：请求和响应<blockquote><p>http请求：http request<br>http响应：http response<br>一次http事务：请求<-->响应</--></p></blockquote></li><li>Web资源：web resource<br>一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资<br>源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源<br>的集合<blockquote><p>静态页面/文件：无需服务端做出额外处理;</p><pre><code>服务器端是什么样传到客户端就是什么样，比如下面这些比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi只不过浏览器有时会解析出来以好看的页面展示给用户</code></pre><p>动态页面/文件：服务端执行程序，返回执行的结果</p><pre><code>服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果文件后缀：.php, .jsp ,.asp,.sh等将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户</code></pre></blockquote></li><li><p>提高HTTP连接性能</p><blockquote><p>并行连接：通过开多个TCP连接发起并发的HTTP请求<br>持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，<br>管道化连接：通过共享TCP连接发起并发的HTTP请求<br>复用的连接：交替传送请求和响应报文（实验阶段）</p></blockquote></li><li><p>HTTP协议的其他相关技术</p></li><li><p>1.URI：一般把URI认为是URL<br>URI: Uniform Resource Identifier 统一资源标识，分为URL和URN</p><blockquote><p>1.URN: Uniform Resource Naming，统一资源命名</p><pre><code>如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名</code></pre><p>2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置</p><pre><code>如输入一个网址，能具体体现出这个资源在互联网上的位置</code></pre><p>两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址</p></blockquote></li><li><p>URL的组成<br>scheme://user:password@host:port/path;params?query#frag</p><blockquote><p>scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等<br>user:用户，某些方案访问资源时需要的用户名<br>password:密码，用户对应的密码，中间用：分隔<br>Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析<br>port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080<br>/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔<br>params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对<br>query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能<br>frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔</p></blockquote></li><li><p>网站访问量</p><blockquote><p>1.IP(独立IP)：即Internet Protocol,指独立IP数。</p><pre><code>如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个</code></pre><p>2.PV(访问量)： 即Page View, </p><pre><code>页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量一般为了博客为了好看的访问量，都是统计PV量</code></pre><p>3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。</p><pre><code>网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1</code></pre></blockquote></li></ul><h3 id="Web服务请求处理步骤"><a href="#Web服务请求处理步骤" class="headerlink" title="Web服务请求处理步骤"></a>Web服务请求处理步骤</h3><p>很切合实际生活：比如<br>当我们打开一个浏览器，输入一个<a href="http://www.taobao.com，在互联网后台发生了什么？" target="_blank" rel="noopener">www.taobao.com，在互联网后台发生了什么？</a><br>这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图<br><img src="/2018/12/18/HTTP协议/web服务请求处理步骤.png" alt="web请求步骤"></p><p>当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程<br>每个过程都是一段需要原理详细描述的.</p><h4 id="一次完整的http请求处理过程"><a href="#一次完整的http请求处理过程" class="headerlink" title="一次完整的http请求处理过程"></a>一次完整的http请求处理过程</h4><pre><code>1.建立连接：接收或拒绝连接请求2.接收请求：接收客户端请求报文中对某资源的一次请求的过程Web访问响应模型（Web I/O）    单进程I/O模型：访问量不大        启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应        会造成请求排队现象，只适用于访问并发不大的情况    多进程I/O模型：        系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求        如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点        而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的    复用I/O结构：        开启多个进程进程，而一个进程又同时监控N个连接请求        只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗        实现方法：多线程模型和事件驱动        多线程模型：一个进程生成N个线程，每线程响应一个连接请求        事件驱动：一个进程处理N个请求    复用的多进程I/O模型：        启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求        充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的        nginx使用的复用多进程I/O模型</code></pre><font size="3" color="#FF0000"><br>    1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程<br>    2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应<br>    避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费<br>    同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题<br></font><p><img src="/2018/12/18/HTTP协议/web访问响应的四种模型.png" alt="web访问响应四种模型"><br>参考下面的HTTP的MPM三种工作模式<a href=""></a></p><pre><code>3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理    分析元数据：请求报文首部信息获得method    &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt;    HEADERS 格式 name:value    &lt;request body&gt;    通过method来响应用户请求，比如下载(get)，上传等信息    HTTP常用请求方式，Method        GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS4.访问资源：    服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源    在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件    web服务器资源路径映射方式：        (a) docroot        (b) alias        (c) 虚拟主机docroot        (d) 用户家目录docroot5.构建响应报文：    一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体   1）响应实体        描述了响应主体MIME类型的Content-Type首部        描述了响应主体长度的Content-Length   2）URL重定向        web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径   3）MIME类型   当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文    将构建完的响应报文发送给用户    将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户    用户再层层解封装获得index.html的内容7.记录日志    最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务    通过在/var/log/httpd/acess_log日志中记录http的响应记录数    方便分析日志统计该网站的IP，PV量等信息</code></pre><h3 id="Http协议"><a href="#Http协议" class="headerlink" title="Http协议"></a>Http协议</h3><pre><code>http协议    http/0.9, http/1.0, http/1.1, http/2.0http协议：stateless 无状态    服务器无法持续追踪访问者来源解决http协议无状态方法    cookie 客户端存放    session 服务端存放http事务：一次访问的过程    请求：request    响应：response</code></pre><h3 id="Session和Cookie的区别"><a href="#Session和Cookie的区别" class="headerlink" title="Session和Cookie的区别"></a>Session和Cookie的区别</h3><pre><code>前言:    HTTP是一种无状态的协议，为了分辨链接是谁发起的，就需要我们自己去解决这个问题。    不然有些情况下即使是同一个网站我们每打开一个页面也都要登录一下。而Session和    Cookie就是为解决这个问题而提出来的两个机制。应用场景:    1.日常登录一个网站，今天输入用户名密码登录了，第二天再打开很多情况下就直接打开      了。这个时候用到的一个机制就是cookie。    2.session的一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而      服务器端如何判别呢，所以也需要存储一些信息，这里就用到了session。Cookie的原理：    HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。    也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。    这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设    计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行    保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在    请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服    务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端    保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报    文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，    会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，    最后得到之前的状态信息。    通俗讲，Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时    候减少一些步骤。另外一个更准确的说法是：Cookies是服务器在本地机器上存储的小段文    本并随每一个请求发送至同一个服务器，是一种在客户端保持状态的方案。session的原理：    session就是一种保存上下文信息的机制，她是针对每一个用户的，session的内容在服    务器端，通过sessionId来区分不同的客户，session是以cookie或url重写为基础的，    默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie，我们成为session     cookie，以区分persistent coookies，注意session cookie是存储于浏览器内存中的    ，并不是写到硬盘上的；我们通常是看不见JSESSIONID的，但是当我们禁用浏览器的    cookie后，web服务器会采用url重写的方式传递sessionid，我们就可以在浏览器看到    sessionid=HJHADKSFHKAJSHFJ之类的字符串；session cookie针对某一次会话而言，会话结束session cookie也就消失了　session与cookie的区别：　　1.session保存在服务器，客户端不知道其中的信息；cookie保存在客户端，服务端可以        知道其中的信息　　2.session中保存的是对象，cookie中保存的是字符串　　3.session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个    地方都可以访问到；而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不道德session与cookie的联系：　　session是需要借助cookie才能正常工作的，如果客户端完全禁止cookie，session将失    效</code></pre><h3 id="Http应用层的报文头部-又分请求报文和响应报文两种"><a href="#Http应用层的报文头部-又分请求报文和响应报文两种" class="headerlink" title="Http应用层的报文头部:又分请求报文和响应报文两种"></a>Http应用层的报文头部:又分请求报文和响应报文两种</h3><p>-HTTP请求报文头部<br><img src="/2018/12/18/HTTP协议/请求报文头部.png" alt="HTTP请求报文头部"></p><pre><code>开始行    方法：method        GET： 从服务器获取一个资源        HEAD： 只从服务器获取文档的响应首部        POST： 向服务器输入数据，通常会再由网关程序继续处理        PUT： 将请求的主体部分存储在服务器中，如上传文件        DELETE： 请求删除服务器上指定的文档        TRACE： 追踪请求到达服务器中间经过的代理服务器        OPTIONS：请求服务器返回对指定资源支持使用的请求方法    URL:路径首部行实体行</code></pre><p>-HTTP响应报文头部<br><img src="/2018/12/18/HTTP协议/响应报文头部.png" alt="HTTP响应报文头部"></p><pre><code>开始行    版本：version        HTTP/&lt;major&gt;.&lt;minor&gt;1.1/2等等    状态码：        三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况    短语：        状态码所标记的状态的简要描述首部行实体行</code></pre><h3 id="Http常见的状态码和状态码分类"><a href="#Http常见的状态码和状态码分类" class="headerlink" title="Http常见的状态码和状态码分类"></a>Http常见的状态码和状态码分类</h3><pre><code>status(状态码)：    1xx：100-101 信息提示    2xx：200-206 成功    3xx：300-305 重定向    4xx：400-415 错误类信息，客户端错误    5xx：500-505 错误类信息，服务器端错误200： 成功，请求数据通过响应报文的entity-body部分发送;OK301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资      源现在所处的新位置；Moved Permanently302： 响应报文Location指明资源临时新位置 Moved Temporarily304： 如果之前访问一个网站，在本机上有缓存了，当再次访问时，就会出现304的状态码，      提示本地有不需要再去服务器上下载页面401： 需要输入账号和密码认证方能访问资源；Unauthorized403： 没有权限访问，请求被禁止了；Forbidden404： 服务器无法找到客户端请求的资源；要访问的文件不存在500： 服务器内部错误；Internal Server Error502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；Bad Gateway503： 服务不可用，临时服务器维护或过载，服务器无法处理请求      可能是服务器down机了，或者http服务关闭了504： 网关超时；转给后端服务器时，时间太长</code></pre><h3 id="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"><a href="#curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因" class="headerlink" title="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"></a>curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因</h3><pre><code>curl是基于URL语法在命令行方式下工作的文件传输工具1.它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。2.curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器，cookies，用户名/密码认证,下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling）3.还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等4.curl的强大在于能模拟各种浏览器自定义请求报文头部等信息，来访问某些控制严格的网站curl [options] [URL...]    -A/--user-agent &lt;string&gt; 冒充浏览器类型，实际上在请求报文修改了User-Agent        curl -A &apos;IE20&apos; http://192.168.34.103在http日志中可看到        一般用于测试访问网站或者爬虫功能要使用不同浏览器访问    -e/--referer &lt;URL&gt; 来源网址，防盗链相关        比如，伪装从百度跳转的192.168.34.103        curl -e &apos;www.baidu.com&apos; http://192.168.34.103    --cacert &lt;file&gt; CA证书 (SSL)    -k/--insecure 允许忽略证书进行 SSL 连接    --compressed 要求返回是压缩的格式    -H/--header &lt;line&gt;自定义首部信息访问网站    -i 显示页面内容，包括报文首部信息    -I/--head 只显示响应报文首部信息    -D/--dump-header &lt;file&gt; 将url的header信息存放在指定文件中，重定向    --basic 使用HTTP基本认证，401认证    -u/--user &lt;user[:password]&gt;设置服务器的用户和密码    -L 如果有3xx响应码，重新发请求到新位置        如果访问的网页被重定向到其他地方时，系统只会提示网页被重定向了，并不会跳转        -L就可以请求到新的页面上    -O 使用URL中默认的文件名保存文件到本地    -o &lt;file&gt; 将网络文件保存为指定的文件中    --limit-rate &lt;rate&gt; 设置传输速度    -0/--http1.0 数字0，使用HTTP 1.0    -v/--verbose 更详细    -C 选项可对文件使用断点续传功能    -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中    -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址    -X/--request &lt;command&gt; 向服务器发送指定请求方法    -U/--proxy-user &lt;user:password&gt; 代理服务器用户和密码    -T 选项可将指定的本地文件上传到FTP服务器上    --data/-d 方式指定使用POST方式传递数据    -b name=data 从服务器响应set-cookie得到值，返回给服务器elinks工具：    字符界面的浏览器，显示页面内容和源码等    elinks [OPTION]... [URL]...    -dump: 非交互式模式，将URL的内容输出至标准输出        比如有些网站是不允许复制的，通过-dump就可以把网站页面文字抓取到本地了        elinks -dump www.baidu.com        不过一般都是用js脚本限制了复制功能，在浏览器关闭js，或查看源码都可以    -source:打印源码</code></pre><h3 id="HTTP介绍"><a href="#HTTP介绍" class="headerlink" title="HTTP介绍"></a>HTTP介绍</h3><p>特性：<br>高度模块化：core + modules<br>DSO: Dynamic Shared Object 动态加/卸载<br>MPM：multi-processing module多路处理模块</p><h3 id="HTTP的三种工作模型：MPM工作模式"><a href="#HTTP的三种工作模型：MPM工作模式" class="headerlink" title="HTTP的三种工作模型：MPM工作模式"></a>HTTP的三种工作模型：MPM工作模式</h3><font size="3" color="#FF0000"><br>多用途的处理模块，三种模型分别是，默认使用prefork模型<br>因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型<br></font><h3 id="1-prefork：多进程I-O模型，每个进程响应一个请求，默认模型"><a href="#1-prefork：多进程I-O模型，每个进程响应一个请求，默认模型" class="headerlink" title="1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型"></a>1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型</h3><pre><code>一个主进程：生成和回收n个子进程，创建套接字，不响应请求多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个，消耗比较大内存资源受限于并发访问控制的内部系统调用机制：        select()；内生使用限制最多只能使用1024个描述符，所以最多也就1024个进程        epoll();Prefork MPM: 预派生模式，有一个主控制进程，然后生成多个子进程，使用select模型，最大并发1024，每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定，可以设置最大和最小进程数，是最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景。优点：稳定缺点：慢，占用资源，不适用于高并发场景配置文件原内容：&lt;IfModule mpm_prefork_module&gt;    StartServers           5 #定义apache服务在启动时启动的子进程数量    MinSpareServers         5 #定义最小空闲进程数，空闲进程就是没有处理用户请求的进程数    MaxSpareServers        10 #定义最大空闲进程数    MaxRequestWorkers      250 #定义在prefork模式下的最大并发连接数，表示了apache的最大并发处理能力，超过的连接请求将被排队等候处理。    MaxConnectionsPerChild   0  #进程生命周期内，处理的最大请求数目。达到该数目后，进程将死掉。如果设置    为0，表示没有限制。该参数的意义在于，避免了可能存在的内存泄露带来的系统问题。&lt;/IfModule&gt;如果确定合适的MaxRequestWorkers呢？首先，通过top命令查看apache进程占用的资源，主要看%CPU和%MEM这两个指标，例如，每个进程的CPU占用率不超过1%，每个进程的内存占用率不超过2%，考虑内存限制，比较合适的apache进程数量为50个，然后，逐步测试最大值。通过观测得来的CPU和内存的指标有一定的误差，一般可以适当调节这个数值，例如调到1.5或者2倍，再通过峰值场景下的机器是否卡顿来判断是继续上调还是下调。</code></pre><p><img src="/2018/12/18/HTTP协议/Prefork.png" alt="Prefork"></p><h3 id="2-worker：复用的多进程I-O模型-多进程多线程，IIS使用此模型"><a href="#2-worker：复用的多进程I-O模型-多进程多线程，IIS使用此模型" class="headerlink" title="2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型"></a>2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型</h3><pre><code>一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！woker MPM：是一种多进程和多线程混合的模型，有一个控制进程，启动多个子进程，每个子进程里面包含固定的线程，使用线程程来处理请求，当线程不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求，由于其使用了线程处理请求，因此可以承受更高的并发。优点：相比prefork 占用的内存较少，可以同时处理更多的请求缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生）配置文件原内容详解：&lt;IfModule mpm_worker_module&gt;    StartServers         3   # #定义apache服务在启动时启动的子进程数量，默认是3个     MinSpareThreads      75   # 整个控制进程保持最小数的空闲线程数    MaxSpareThreads      250  # 整个控制进程保持最大数的空闲线程数    #ThreadLimit        64   # 每个子进程可以启动的线程数量上限值，默认没有设置    ThreadsPerChild      25   # 每个子进程启动的线程默认数量，开启启动两个子进程每个子进程25个 线程，就是apache 启动后开启25个线程。    MaxRequestWorkers    400   # 所有子进程加起来的线程数量最大值，数量等于最大启动的进程数*ThreadsPerChild(每个进程的线程数)    MaxConnectionsPerChild   0  # 每个子进程被请求多少次服务后被kill掉重新生成一个新的子进程，为了解决内存回收方面的问题，0为不设置&lt;/IfModule&gt;</code></pre><p><img src="/2018/12/18/HTTP协议/Worker.png" alt="Worker"></p><h3 id="3-event：事件驱动模型（worker模型的优化-worker模型的变种）"><a href="#3-event：事件驱动模型（worker模型的优化-worker模型的变种）" class="headerlink" title="3.event：事件驱动模型（worker模型的优化,worker模型的变种）"></a>3.event：事件驱动模型（worker模型的优化,worker模型的变种）</h3><pre><code>event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用每一个cpu核心生成一个进程；一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n            注意这里的m*n和work的m*n是不同的机制相比较worker的有点：有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力event MPM：Apache中最新的模式，属于事件驱动模型(epoll)，每个进程响应多个请求，在现在版本里的已经是稳定可用的模式。它和worker模式很像，最大的区别在于，它解决了keep-alive场景下，长期被占用的线程的资源浪费问题（某些线程因为被keep-alive，空挂在哪里等待，中间几乎没有请求过来，甚至等到超时）。event MPM中，会有一个专门的线程来管理这些keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放。这样增强了高并发场景下的请求处理能力。event只在有数据发送的时候才开始建立连接，连接请求才会触发工作线程，即使用了TCP的一个选项，叫做延迟接受连接TCP_DEFER_ACCEPT，加了这个选项后，若客户端只进行TCP连接，不发送请求，则不会触发Accept操作，也就不会触发工作线程去干活，进行了简单的防攻击（TCP连接）,可以使用Telnet进行测试验证：主机192.168.10.130为客户端机器，192.168.10.131为apache服务器机器使用event模式：     在192.168.10.130上telnet 192.168.10.131 80，然后在192.168.10.130客户端机器上使用netstat查看，发现连接已经建立，处于ESTABLISHED状态，然后再到apache服务器192.168.10.131使用netstat查看，发现是处于SYN_RECV状态。优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放 缺点：没有线程安全控制配置文件内容：&lt;IfModule mpm_event_module&gt;    StartServers           3  #apache服务启动的子进程数，默认3个    MinSpareThreads         75  #控制进程保持最小的空闲线程数    MaxSpareThreads        250  #控制进程保持的最大空闲线程数    ThreadsPerChild         25  #每个子进程启动的线程数    MaxRequestWorkers       400  #并发最大请求数，也就是所有子进程加起来的线程数量，woker模式下的    400就是并发400，但是由于是异步处理请求的，因此这里的400比woker模型下的并发处理速度要快很多，因为event省略了工作线程的会话保持。    MaxConnectionsPerChild    0  #每个子进程请求多少次以后被kill掉重新生成一个新的子进程。&lt;/IfModule&gt;</code></pre><p><img src="/2018/12/18/HTTP协议/event.png" alt="event"></p><pre><code>注意：    event模型的强大的I/O机制    httpd从设计上就默认支持prefork    而nginx从设计上就支持event事件驱动模型</code></pre><h3 id="进程工作的角色切换"><a href="#进程工作的角色切换" class="headerlink" title="进程工作的角色切换"></a>进程工作的角色切换</h3><p><img src="/2018/12/18/HTTP协议/进程角色切换原理.png" alt="进程间的角色切换"></p><h3 id="Httpd的功能特性"><a href="#Httpd的功能特性" class="headerlink" title="Httpd的功能特性"></a>Httpd的功能特性</h3><p>httpd的常见特性：</p><ul><li>虚拟主机：在一个物理服务器上搭建多个网站<br>  IP、Port、FQDN</li><li>CGI：Common Gateway Interface，通用网关接口<br>  通过CGI接口处理动态的程序处理</li><li>反向代理<br>  当有用户访问量大时，在前端有一个服务器充当调度器的角色<br>  通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息<br>  看不到后端真正提供服务的服务器群</li><li>负载均衡</li><li>路径别名</li><li>丰富的用户认证机制<br>  basic<br>  digest</li><li>支持第三方模块</li></ul><h3 id="Httpd2-4新特性和安装以及配置"><a href="#Httpd2-4新特性和安装以及配置" class="headerlink" title="Httpd2.4新特性和安装以及配置"></a>Httpd2.4新特性和安装以及配置</h3><pre><code>新特性    MPM支持运行为DSO机制；以模块形式按需加载        在centos7上的httpd2.4上只有一个二进制程序            /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可        但是在centos6上的httpd2.2版本：            每个MPM模式都有各自对应的二进制程序                /usr/sbin/httpd                /usr/sbin/httpd.event                /usr/sbin/httpd.worker            如果更改MPM的模式，是需要改对应的二进制程序的    event MPM生产环境可用    异步读写机制    支持每模块及每目录的单独日志级别定义    每请求相关的专用配置    增强版的表达式分析式    毫秒级持久连接时长定义：httpd2.2只能精确到秒级别        上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的        所以在http中是可以定义连接时长(时长和传输请求两种方式)的    基于FQDN的虚拟主机不需要NameVirutalHost指令        httpd2.2创建虚拟主机时还需要NameVirutalHost指令        httpd2.4就不需要了    新指令，AllowOverrideList    支持用户自定义变量    更低的内存消耗</code></pre><h3 id="Httpd2-4的具体安装和配置"><a href="#Httpd2-4的具体安装和配置" class="headerlink" title="Httpd2.4的具体安装和配置"></a>Httpd2.4的具体安装和配置</h3><p>Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了<br>还支持第三方的模块，按需加载模块<br>存放模块的路径：/etc/httpd/modules</p><pre><code>CentOS7程序环境安装：httpd-2.4    yum install httpd     yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档主要配置文件：    /usr/sbin/httpd     httpd的主程序文件    /usr/lib/systemd/system/httpd.service   httpd的启动单元文件    /etc/httpd/conf/httpd.conf              主要配置文件        配置文件里的路径都是以/etc/httpd/为参考点的    /etc/httpd/conf.d/*.conf    /etc/httpd/conf.modules.d/00-mpm.conf    mpm相关    /etc/httpd/conf.modules.d/00-proxy.conf  配置代理相关    /etc/httpd/conf.modules.d/00-systemd.conf     /etc/httpd/conf.modules.d/01-cgi.conf    CGI相关    /var/cache/httpd    httpd的缓存目录    /var/log/httpd      httpd的日志文件目录            access_log: 访问日志            error_log：错误日志    /etc/httpd/modules  httpd的模块存放路径，软件比较复杂    /usr/lib64/httpd/modules   也是httpd的模块存放路径        两个模块的路径实际上是软链接关系    /var/www/html       httpd存放网页的目录：默认index.html帮助文档包：在没有网络时查看帮助文档，建议安装    httpd-manual检查配置文件语法：    httpd –t    类似DNS的rndc语法检查功能    sudo：visudo功能    ansible:ansible -C|--check 执行前检查语法功能    cobbler 也有httpd的控制和启动命令    systemctl enable|disable httpd.service    systemctl {start|stop|restart|status|reload} httpd.service    备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作        有时reload是无效的，只能restart服务</code></pre><h3 id="Httpd2-4的常见配置"><a href="#Httpd2-4的常见配置" class="headerlink" title="Httpd2.4的常见配置"></a>Httpd2.4的常见配置</h3><ul><li><p>1.显示服务器版本信息HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a></p><p>  主要组成:</p><pre><code>Global Environment   全局配置Main server configuration   一个服务器上搭建一个网站叫主服务器virtual host   虚拟主机，一台主机上搭建多个网站</code></pre></li></ul><p>练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)<br>egrep -v ‘^ <em>#.</em>|^$’ /etc/httpd/conf/httpd.conf</p><font size="3" color="#FF0000"><br>常见配置一般都在/etc/httpd/conf/httpd.conf的文件中<br>没有的配置选项可以加在httpd.conf文件最后，也可以放在<br>/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf<br>下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加<br></font><ul><li>1.显示服务器版本信息<br>  访问<a href="http://192.168.34.103" target="_blank" rel="noopener">http://192.168.34.103</a><br>  打开f12调试模式，可以看到回应头的信息中带有apache的版本信息<br>  也可以通过curl -I <a href="http://192.168.34.103来显示头信息" target="_blank" rel="noopener">http://192.168.34.103来显示头信息</a><br>  可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全<br>  查看指令参考文档：修改ServerTokens选项<pre><code>建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全</code></pre></li><li><p>2.修改监听的IP和Port<br>  Listen [IP:]PORT<br>  (1) 省略IP表示为本机所有IP<br>  (2) Listen监听端口至少一个，可以有多个端口<br>  (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口</p><pre><code>test.conf添加listen端口：listen 172.18.132.151:6666 6666端口只能通过此IP才能访问</code></pre></li><li><p>3.持久连接：默认KeepAlive是开启的<br>  Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接<br>  断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级<br>  副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞<br>  折衷：使用较短的持久连接时间</p><pre><code>设置：    KeepAlive On|Off       设置持久连接开启或者关闭    KeepAliveTimeout 15    设置持久连接为15s测试：telnet WEB_SERVER_IP PORT    GET /index.html HTTP/1.1    Host: WEB_SERVER_IP  host可以随便填写，但是在虚拟主机中是有区别的</code></pre></li><li><p>4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event<br>  默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf  修改mpm的文件<br>  建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的<br>  查看静态编译的模块<br>  httpd -l<br>  查看当前系统中httpd的静态编译及动态装载的加载的模块<br>  httpd –M<br>  动态模块加载：不需重启即生效<br>  动态模块路径<br>   /usr/lib64/httpd/modules/</p><pre><code>切换使用的MPM模块    在/etc/httpd/conf.modules.d/00-mpm.conf中    选择要启用的MPM相关的LoadModule指令即可prefork的配置：    StartServers 8               MinSpareServers 5       保留5个空闲子进程处理新的请求    MaxSpareServers 20      允许的最大空闲进程数    ServerLimit 256         最多进程数,最大20000，并发量建议最多10000         MaxRequestsPerChild     4000 子进程最多能处理的请求数量。在处理    MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进    程占用的内存就会释放(为0时永远不释放）worker和prefork配置类似，只不过会有线程数量的限制</code></pre><p>从下面ps auxf的进程图可以看书httpd是使用的prefork模型，而且因为端口是80，开启需要特殊<br>权限，所以父进程是root,子进程是apache</p></li></ul><p><img src="/2018/12/18/HTTP协议/HTTPD的prefork模型.png" alt=""></p><ul><li><p>5.DSO： Dynamic Shared Object<br>  加载动态模块配置<br>  /etc/httpd/conf/httpd.conf<br>  Include conf.modules.d/*.conf<br>  配置指定实现模块加载格式：<br>  LoadModule &lt;mod_name&gt; &lt;mod_path&gt;<br>  模块文件路径可使用相对路径：<br>  相对于ServerRoot（默认/etc/httpd）</p></li><li><p>6.定义’Main’ server的文档页面路径：存放页面的主目录<br>  主目录是由DocumentRoot指令来设置的<br>  网页文件默认是存在/var/www/html/下的，此处可以自定义<br>  在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html”</p><pre><code>如果要自定义主目录，还需要设置该目录为允许访问在httpd2.2上是不需要设置权限访问的但是在httpd2.4上是需要设置该目录允许访问的修改格式如下：#DocumentRoot &quot;/var/www/html&quot;DocumentRoot &quot;/data/www&quot;&lt;directory /data/www&gt;    Require all granted&lt;/directory&gt; </code></pre></li><li><p>7.定义站点默认主页面<br>  访问192.168.34.103默认显示的是index.html的内容，<br>  这一项是由DirectoryIndex指令设置的</p><pre><code>在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件</code></pre><font color="#FF0000"><br>此处需要了解httpd的权限和访问报错的相关问题和默认主页面：<br>1.访问192.168.34.103跳出的页面默认是index.html页面，如果不存在，则去找conf.d/welcome.conf文件，即报错提示，如果两个都不存在，显示的是/var/www/html目录下的文件列表，因为在httpd.conf配置文件中，定义options indexes选项<br>2.默认页面和默认访问目录都是可以通过指令来指定的<br>3.如果没有index.html文件，没有welcome.conf文件，没有options indexes配置，访问时会报错You don’t have permission to access / on this server.的提示.<br>4.上面三条在下面第12条配置别名时，可以体现的很明显<br>5.所以如果自定义目录和用别名，有时是需要设置目录访问权限、设置目录对应的index.html文件或者跳转的html文件(如果该文件存在就不需要设置了)，设置options indexes选项<br></font></li><li><p>8.站点访问控制常见机制<br>  可基于两种机制指明对哪些资源进行何种访问控制<br>  访问控制机制有两种：1.客户端来源地址，2.用户账号<br>  而文件系统路径：可以是<br>  1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配<br>  示例：<br>  ‘<filesmatch "\.(gif|jpe?g|png)$"="">‘’   用的是扩展的正则表达式<br>  <files “?at.*”="">                     通配符<br>  &lt;Location /status&gt;</files></filesmatch></p>  <locationmatch "="" (extra|special)="" data"=""></locationmatch></li><li><p>9.<directory>中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制<br>   (1) Options：后跟1个或多个以空白字符分隔的选项列<br>  在选项前的+，- 表示增加或删除指定选项<br>  常见选项：<br>  Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制<br>  适用于下载网站和镜像网站，不适合电商网站<br>  FollowSymLinks：允许访问符号链接文件所指向的源文件,<br>  None：全部禁用<br>  All： 全部允许</directory></p><pre><code>Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站    &lt;directory &quot;/data/www&quot;&gt;    options Indexes                                              Require all granted    &lt;/directory&gt;FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件    &lt;directory &quot;/data/www&quot;&gt;    options Indexes  FollowSymLinks           Require all granted    &lt;/directory&gt;</code></pre><font size="4" color="#FF0000"><br>实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.conf文件，welcome.conf文件就是页面上经常看到的测试123页面，把welcome.conf文件改名或删除，就会显示主目录下的所有列表文件了.<br></font><p>  (2) AllowOverride<br>  allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可<br>  只对<directory>语句有效;<br>  allowoverride权限时卸载httpd的*.conf配置文件中的<br>  AllowOverride All: .htaccess中所有指令都有效<br>  AllowOverride None： .htaccess 文件无效<br>  AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它</directory></p><pre><code>配置allowoverride示例：/etc/httpd/conf.d/test.conf中添加访问控制的目录    &lt;directory /data/www&gt;    allowoverride all  --&gt;这条必须写，代表.htaccess文件中的options生效    Require all granted    &lt;/directory&gt;在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中    options indexes FollowSymLinks</code></pre><p>  (3) 基于IP的访问控制:<br>  无明确授权的目录，默认拒绝<br>  允许所有主机访问：Require all granted<br>  拒绝所有主机访问：Require all denied<br>  控制特定的IP访问：<br>  Require ip IPADDR：授权指定来源的IP访问<br>  Require not ip IPADDR：拒绝特定的IP访问<br>  控制特定的主机访问：<br>  Require host HOSTNAME：授权特定主机访问<br>  Require not host HOSTNAME：拒绝<br>  HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机</p><pre><code>基于IP的访问控制示例：如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表除了/data/www/ceshi文件夹    &lt;directory /data/www&gt;    options indexes                                                      &lt;RequireAll&gt;    Require all granted    Require not ip 192.168.34.107    &lt;/RequireAll&gt;    &lt;/directory&gt;2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问&lt;directory /data/www&gt;options indexesRequire all granted&lt;/directory&gt;&lt;directory /data/www/ceshi&gt;&lt;RequireAny&gt;Require all deniedRequire ip 192.168.34.107&lt;/RequireAny&gt;                                                 &lt;/directory&gt;</code></pre></li><li><p>10.日志设定：日志默认/var/log/httpd/下<br><a href="http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats" target="_blank" rel="noopener">format官方说明文档</a><br>  日志类型：访问日志(access_log)和错误日志(error_log)<br>  日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式</p><pre><code>在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined   --&gt;由Logformat指令定义完起一个combined名CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式ErrorLog &quot;logs/error_log&quot;</code></pre><p>  可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径</p><pre><code>日志中的格式各个项说明%h 客户端IP地址%l 远程用户,启用mod_ident才有效，通常为减号“-”%u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-”%t 服务器收到请求时的时间%r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本%&gt;s 响应状态码%b 响应报文的大小，单位是字节；不包括响应报文http首部%{Referer}i     请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页    是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源，所以网站一般要加防盗链，防止资源被盗和占用服务器资源%{User-Agent}i 指客户端的浏览器版本</code></pre></li><li><p>11.设定默认字符集<br>  一般不需要设置：基本上使用的是utf-8;<br>  AddDefaultCharset UTF-8 此为默认值</p><pre><code>如果需要修改字符集，在test.conf或者httpd.conf下添加AddDefaultCharset gb2312 即可</code></pre></li><li><p>12.定义路径别名<br>作用：默认访问的文件夹是设置的DocumentRoot文件夹，如果不是在默认文件夹下，而需求要实现把其他路径下的目录共享出来，这就用到了定义路径别名的功能</p><p>  把一个URL起一个别名不指向真正的目录<br>  在httpd2.4里目录如果没有开启允许时，默认是不允许访问的</p><pre><code>例如：访问 /var/www/html/111,111这个目录可有可无，只是充当别名    实际上访问的是/data/www/ceshi目录         directoryindex ceshi.html        alias /111 /data/www/ceshi        &lt;directory /data/www/ceshi&gt;        options indexes        Require all granted        &lt;/directory&gt;         </code></pre></li></ul><font color="#FF0000"><br>注意：<br>1.111只是一个别名，在/var/www/html下不需要创建；但是如果/var/www/html下有111的文件夹，如果设置别名后，则访问的是/data/www/ceshi目录，原目录下的111文件夹就失效了。<br>2.在这里和上文第7条设置权限时有联系的，httpd2.4设置路径别名的时候，真正的路径也是需要在test.conf下设置权限的(/data/www/ceshi目录)<br>3.如果/data/www/ceshi/下没有index.html会报权限不允许的错误，所以要设置默认主页面directoryindex，当然可以设置options indexes选项<br></font><ul><li><p>13.基于虚拟账户的登录访问控制：提示401状态码<br>  认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码<br>  认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源<br>  两种认证方式：<br>  basic：用的多，缺点是明文，后面可以用https进行加密<br>  digest：兼容性差，用的少<br>  用户的账号和密码:非linux用户密码<br>  虚拟账号：多种存储方式，只用于httpd服务的，类似vsftp，samba服务的虚拟用户<br>  存储：账号可放在文本文件，SQL数据库，ldap目录存储，nis等</p><pre><code>因为basic使用的多，下文以basic认证配置示例1.提供账号和密码存储（文本文件），如创建一个tom虚拟账户管理httpd    htpasswd --&gt;可以指定加密算法        -c 自动创建文件，仅应该在文件不存在时使用        -p 明文密码        -d CRYPT格式加密，默认        -m md5格式加密        -s sha格式加密        -D 删除指定用户    htpasswd -c httpdpass tom :设定密码即可;目录可指定，后面改配置文件即可    htpasswd -s httpdpass jerry 再添加jerry用户，就不需要-c选项了    htpasswd -D httpdpass jerry 从文件中删除jerry用户    修改httpdpass权限，加固安全 chmod 600 httpdpass     或者也可以创建组文件httpdgroup，通过组来管理,组文件组和成员列表    testgroup: tom jerry2. 在test.conf或者httpd.conf下定义安全域    &lt;directory /var/www/html/ksdir&gt;    AuthType Basic          ---&gt;使用的认证方式    AuthName &quot;Login&quot;        ----&gt;登录提示信息    AuthUserFile &quot;/etc/httpd/conf/httpdpass&quot;  --&gt;加密账户文件    AuthGroupFile &quot;/etc/httpd/conf/httpdgroup&quot; --&gt;组账户    Require user tom        ---&gt;允许用户访问的列表    Require group testgroup  ---&gt;允许访问的组    &lt;/directory&gt;    但是：因为httpd线程是以apache运行的，而httpdpass是600权限，所以默认tom登录是没有权限的，让apache对httpdpass有读权限：    setfacl -m u:apache:r httpdpass 即可</code></pre></li><li><p>14.实现用户家目录的http共享;并实现账户机密访问<br>  实现基础：基于模块mod_userdir.so实现<br>  httpd -M |grep user 可以看出user加密的模块是已经加载的，直接改配置文件即可<br>  在/etc/httpd/conf.d/userdir.conf文件中定义了家目录共享的格式，只需要启用就行了</p><pre><code>实现步骤：1. vim /etc/httpd/conf.d/userdir.conf    &lt;IfModule mod_userdir.c&gt;     UserDir enabled      ---&gt;启用即可；默认不启用    UserDir public_html  ---&gt;创建一个public_html文件    &lt;/IfModule&gt;2.在test家目录下，创建public_html文件夹和public_html文件    su test    mkdir public_html/    echo 23333 &gt; /public_html/public_html3.因为httpd线程是apache身份登录的，所以要允许apache访问test用户的家目录    setfacl -m u:apache:x /home/test4.设置test家目录访问权限及用户加密    &lt;directory /home/test/public_html&gt;        authtype basic    authname &quot;test home&quot;    authuserfile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;调用之前创建的虚拟账户文件即可    Require user haha    &lt;/directory&gt;5.http访问test家目录方式,即可用加密账户登录    192.168.34.103/~test</code></pre></li><li><p>15.ServerSignature On|Off|EMail<br>  作用：当用户访问的页面不存在的情况下服务器会产生错误文档，而当ServerSignature选项是打开的情况下，错误文档会将服务器的名字，apahce的版本信息，显示在页面上，某种程度上会对web服务器产生不安全因素，所以一般建议关闭</p><pre><code>在配置文件添加一行：ServerSignature off 即可</code></pre></li><li><p>16.status页面<br>  作用：显示apache的工作状态，有助于判断apache是否正常工作<br>  status页面功能是由下面这个模块实现的：httpd<br>  LoadModule status_module modules/mod_status.so</p><pre><code>实现步骤：在配置文件添加&lt;Location &quot;/status&quot;&gt; SetHandler server-status&lt;/Location&gt;ExtendedStatus ON   #显示扩展信息</code></pre><p>  记录的信息包括：启动时间，线程数，等待连接数，cpu，进程，MPM等信息<br>  在实际生产中，由于apache服务器很多，就可以通过curl 192.168.34.103/status来抓取页面，分析apache某个指标是不是正常的；</p><pre><code>比如编写简单一个脚本：    curl 192.168.34.103/status |grep &quot;Apache Status&quot; || systemctl start httpd</code></pre></li><li><p><font size="5" color="#FF0000">17.实现http的虚拟主机</font><br>  作用：一个物理服务器上实现多台虚拟主机，至于为什么会用到虚拟主机，有可能是因为要上线的同一网站的有多个域名，却只有一个公网IP地址，也有可能是主机不多啊..，所以虚拟主机的价值就体现出来了…</p><p>  实现虚拟主机有三种方式</p><pre><code>基于ip：为每个虚拟主机准备至少一个ip地址，一个主机可以配多个内网IP地址基于port：为每个虚拟主机使用至少一个独立的port；80,8081,8082等等基于FQDN：为每个虚拟主机使用至少一个FQDN</code></pre><p>  当然这三种方式，基于IP和port的对于用户来说不太现实，一般都是通过输入域名方式来实现虚拟主机搭建.</p><pre><code>1.基于IP的虚拟主机搭建：但是这种方式用的比较少先准备三个网站目录，和在本机上添加三个IP地址    &lt;virtualhost 192.168.34.103&gt;    DocumentRoot &quot;/data/asite&quot;    &lt;directory /data/asite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_a.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.200&gt;    DocumentRoot &quot;/data/bsite&quot;    &lt;directory /data/bsite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_b.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.210&gt;    DocumentRoot &quot;/data/csite&quot;    &lt;directory /data/csite&gt;    Require all granted    &lt;/directory&gt;重启服务即可通过curl 192.168.34.103      curl 192.168.34.200    curl 192.168.34.210即可获取到各自的index.html文件内容，对应的日志也都生成了</code></pre><p>  2.基于port的虚拟主机搭建，监听三个port即可;使用的不多</p><pre><code>listen 8081listen 8082listen 8083&lt;virtualhost *:8081&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8082&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8083&gt;                                                                                                      servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;</code></pre><p>  通过本机IP+port获得不同网站的信息</p><pre><code>curl 192.168.34.103:8081curl 192.168.34.103:8082curl 192.168.34.103:8083</code></pre><p>  3.基于FQDN的虚拟主机搭建：用的最多<br>  前提：这里就不搭建DNS服务器了，使用本机的hosts文件进行域名解析</p><pre><code>&lt;virtualhost *:80&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;                                                                                                     servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_c.log combined&lt;/virtualhost&gt;</code></pre><p>  测试：curl <a href="http://www.a.com" target="_blank" rel="noopener">www.a.com</a></p><pre><code>curl www.b.cncurl www.c.net</code></pre><p>  就可获得各自的主页面信息<br>从这telnet就可以理解出，如果在互联网通过域名访问时(同一IP)，返回的结果是不同网站的信息<br>  [root@node7-1 ~]#telnet 192.168.34.103 80</p><pre><code>Trying 192.168.34.103...Connected to 192.168.34.103.Escape character is &apos;^]&apos;.GET /index.html HTTP/1.1HOST: www.a.com</code></pre></li></ul><font size="4" color="#FF0000"><br>当访问192.168.34.103时 HOST：即网站的域名，返回的结果就是其对应的页面信息<br>在互联网上，一般是先在本地服务器上通过第三种方式搭建多个网站，然后再通过服务商的智能DNS解析，可以通过访问不同的域名，解析到IP地址，服务器根据输入的HOST：域名判断访问的是哪个网站，进而返回对应网站站点的信息，对于主机较少或者IP有限的环境中，使用http虚拟主机还是很方便的。<br></font>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;a href=&quot;#HTTP协议和APACHE原理&quot; class=&quot;headerlink&quot; title=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;/a&gt;HTTP协议和APACHE原理&lt;/h3&gt;&lt;p&gt;Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等&lt;br&gt;本文说的是HTTP SERVER&lt;a href=&quot;http://www.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;apache&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="http" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/http/"/>
    
    
      <category term="Web服务" scheme="https://www.liukui.tech/tags/Web%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>编译安装LAMP</title>
    <link href="https://www.liukui.tech/2018/12/10/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85LAMP/"/>
    <id>https://www.liukui.tech/2018/12/10/编译安装LAMP/</id>
    <published>2018-12-10T00:00:00.000Z</published>
    <updated>2019-01-22T08:46:48.428Z</updated>
    
    <content type="html"><![CDATA[<p>LAMP<br><a id="more"></a></p><p><img src="/2018/12/10/编译安装LAMP/LAMP架构.png" alt=""></p><h3 id="Centos7上编译安装LAMP"><a href="#Centos7上编译安装LAMP" class="headerlink" title="Centos7上编译安装LAMP"></a>Centos7上编译安装LAMP</h3><pre><code>    备注：本文编译PHP是基于fastCGI方式，php-fpm编译准备：    在192.168.34.105上实现，准备安装包都放在/data/src下        apr-1.6.5.tar.bz2        apr-util-1.6.1.tar.bz2        httpd-2.4.37.tar.bz2        php-7.1.18.tar.bz2        wordpress-5.0-zh_CN.zip        mariadb-10.2.19-linux-x86_64.tar.gz    准备开发包组：        yum install &apos;develoment tools&apos; -y    1.编译安装httpd和apr        准备依赖包和解压安装包        yum install pcre-devel openssl-devel expat-devel apr-util-devel -y        tar xvf apr-1.6.5.tar.bz2        tar xvf apr-util-1.6.1.tar.bz2         tar xvf httpd-2.4.37.tar.bz2        cp -r apr-1.6.5 httpd-2.4.37/srclib/apr        cp -r apr-util-1.6.1 httpd-2.4.37/srclib/apr-util        a.编译            cd httpd-2.4.37            ./configure \            --prefix=/data/httpd24 \            --enable-so \            --enable-ssl \            --enable-cgi \            --enable-rewrite \            --with-zlib \            --with-pcre \            --with-included-apr \            --enable-modules=most \            --enable-mpms-shared=all \            --with-mpm=prefork            make &amp;&amp; make install        b.准备环境变量            用自带的服务控制脚本：/app/httpd24/bin/apachectl就需要设置环境变量了            echo &apos;PATH=/mysql/httpd24/bin:$PATH&apos; &gt; /etc/profile.d/httpd24.sh            . /etc/profile.d/httpd24.sh        c.修改配置文件，为了安全以apache用户运行，并监听在本地            useradd -r -s /sbin/nologin apache            vim /data/httpd24/conf/httpd.conf                User apache                Group apache                ServerName localhost:80    2.二进制安装mariadb-10.2.19        a.准备用户和mysql数据库目录                useradd -r -s /sbin/nologin -d /data/mysql mysql                mkdir /data/mysql                chown mysql.mysql mysql/        b.解压二进制安装包：            tar xvf mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local/            cd /usr/local            ln -s mariadb-10.2.19-linux-x86_64/ mysql            chown -R root.mysql /usr/local/mysql/        c.创建数据库文件:(通过自带脚本工具)            cd /usr/local/mysql/            scripts/mysql_install_db --datadir=/mysql/data --user=mysql        d.准备配置文件(不修改/etc/my.cnf)拷贝解压完的文件            mkdir /etc/mysql/            cp support-files/my-huge.cnf /etc/mysql/my.cnf                                路径优先级高于/etc/my.cnf                根据性能来拷贝配置文件            [mysqld]中添加三个选项：/etc/mysql/my.cnf            datadir = /mysql/data            innodb_file_per_table = on            skip_name_resolve = on 禁止主机名解析，建议使用        e.准备服务脚本，并启动服务            cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld            chkconfig --add mysqld            service mysqld start        f.准备PATH路径            echo &apos;PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh            . /etc/profile.d/mysql.sh            systemctl start mysqld        为wordpress准备数据库和账号密码            mysql -e &apos;create database wordpress&apos;            mysql -e &quot;grant all on *.* to php1@&apos;192.168.34.%&apos; identified by &apos;php123&apos;&quot;    3.FastCGI方式编译安装php-7.1.18        tar xf php-7.1.18.tar.bz2        安装依赖包            yum install libxml2-devel bzip2-devel libmcrypt-devel -y         a.编译，指定安装数据路劲和配置文件路径                   cd php-7.1.18            ./configure --prefix=/data/php \            --enable-mysqlnd \            --with-mysqli=mysqlnd \            --with-openssl \            --with-pdo-mysql=mysqlnd \            --enable-mbstring \            --with-freetype-dir \            --with-jpeg-dir \            --with-png-dir \            --with-zlib \            --with-libxml-dir=/usr \            --enable-xml \            --enable-sockets \            --enable-fpm \            --with-config-file-path=/etc \            --with-config-file-scan-dir=/etc/php.d \            --enable-maintainer-zts \            --disable-fileinfo            make &amp;&amp; make install        b.准备php配置文件            cd php-7.1.18            cp php.ini-production /etc/php.ini                可以修改当前时区和按照生产环境修改并发连接数等信息        c.创建nginx用户            useradd -s /sbin/nologin nginx        d.准备php的conf文件            cd /data/php            cp php-fpm.conf.default php-fpm.conf            cp php-fpm.d/www.conf.default php-fpm.d/www.conf            修改监听地址和允许连接地址，因为是在一台编译的，监听地址不用改了                vim php-fpm.d/www.conf                    listen = 127.0.0.1:9000                    ;listen.allowed_clients = 127.0.0.1                    user = nginx                    group = nginx        e.准备服务脚本:            cp /data/src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm            chmod +x /etc/init.d/php-fpm            chkconfig --add php-fpm            chkconfig php-fpm on    4.修改httpd文件，支持php和启用代理        编辑apache配置文件httpd.conf，以使apache支持php,并启用代理        vim /data/httpd24/conf/httpd.conf            1.取消下面两行的注释                LoadModule proxy_module modules/mod_proxy.so                LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so            2.定位至DirectoryIndex index.html                修改为DirectoryIndex index.php index.html            3.最后添加4行        AddType application/x-httpd-php .php        AddType application/x-httpd-php-source .phps        ProxyRequests Off        ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1             重启apache服务，apachectl restart    5.准备wordpress,把wordpress文件全部移动到httpd24/htdocs下        cd /data/src        unzip wordpress-5.0-zh_CN.zip        cd wordpress        mv * /data/httpd24/htdocs        为wordpress准备配置文件和数据库连接            cd /data/httpd24/htdocs            mv wp-config-sample.php wp-config.php            vim wp-config.php                define(&apos;DB_NAME&apos;, &apos;wordpress&apos;);                define(&apos;DB_USER&apos;, &apos;php&apos;);                define(&apos;DB_PASSWORD&apos;, &apos;php123&apos;);                define(&apos;DB_HOST&apos;, &apos;192.168.34.105&apos;);        修改/data/httpd24/htdocs的所有者和所属组            cd /data/httpd24            chown -R nginx.nginx htdocs/    到此所以的编译安装和准备工作都做完了，把mysql,php-fpm,httpd启动即可            apachectl start            systemctl start php-fpm            systemctl start mysqld        http://192.168.34.105 配置wordpress即可    备注：        创建的文章和账户是放在wordpress数据库中的;        图片是放在/data/httpd24/htdocs/wp-content/uploads下的</code></pre><p><font size="4" color="#23238E"><br>然后把这套系统搬到自己的云服务上就可以轻松的实现了,本文是基于LAMP架构实现的<br>不过推荐使用LNMP架构，毕竟Nginx的强大可不是吹出来的..<br></font> </p><p><font size="4" color="#FF0000">安装完成后，开启了一个新的世界，就可以开心的玩耍了,helloworld！</font><br><img src="/2018/12/10/编译安装LAMP/haha.png"><br><img src="/2018/12/10/编译安装LAMP/wordpress.png" width="80%" height="80%"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LAMP&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="个人博客搭建" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="web" scheme="https://www.liukui.tech/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>Docker的资源限制</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%9A%84%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker的资源限制/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-26T13:44:29.460Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker资源限制"><a href="#Docker资源限制" class="headerlink" title="Docker资源限制"></a>Docker资源限制</h3><a id="more"></a><pre><code>docker容器得以实现的三个组件：    Namespace:内核中的名称空间是实现容器技术非常重要的组件    CGroups：实现容器的资源配额        1.如果没有资源配额的限定，比如恶意代码会占用宿主机上的很多资源，会造成其他容器无法运行的情况，        默认是宿主机上的所有资源.        2.cgroup允许将宿主机上的所有技术资源(CPU,内存等)做资源分割,以指定方式进行分配，而CPU和内存又分别支持两种不同的配额方式        3.CPU属于可压缩型资源，如果程序运行的cpu不够，只需要等待cpu资源即可，不会造成容器崩溃。        4.内存属于不可压缩型资源，如果一个进程依赖于3g内存来运行，宿主机只分配给它1g，则会造成OOM，这个进程就会因为内存耗尽而被终止.内存的限制方式：    -m|--memory= 限制容器的最大内存使用量，进程并不是一启动就占用最大内存的，而是            运行一段时间慢慢增长的，所以要分配给进程运行的最大内存.    --memory-swap * 当前容器所允许使用的交换分区大小(生产环境是禁止启用交换内存            的，因为性能会急剧下降.)    --memory-swappiness 使用交换分区的倾向性：因为使用交换分区会极大影响性能，        只有到万不得已才使用交换分区，数值越小,越会较晚使用交换分区，所以一般这个        值建议调小，默认是0-100    --memory-reservation 为系统保留多的内存空间，保证系统的正常运行    --kernel-memory  为内核保留多少内存空间    --oom-kill-disable  一旦某个容器发生OOM是否立刻kill这个容器，建议设置，因为        会造成整个宿主机的崩溃，也可以事先设定好内核和系统的内存空间，然后手动处理            发生OOM的容器，以便分析发生OOM的原因.    注意：        1.在容器内使用free命令可以看到的swap空间并不具有其所展现的空间指示意义.        2.-m|--memory=和 --memory-swap *一般是结合起来生效的CPU的限制方式：    主流的分两种：共享式和CPU绑定式    --cpu-shares 共享方式是基于权重分配的，而且是根据容器的数量和CPU的权重动态            分配调整的.如果只有一个容器在运行，那么这个容器也会尽可能的占用宿主机的CPU资源，这种分配方式依然会有可能造成系统崩溃.    --cpus &lt;value&gt; 定义容器最多跑满宿主机的几个核心数，例如宿主机有8核，限制容器        最多跑满2个核心数，而且这个2核可以跑在8个核心上加起来是2个核心数，也可以是        在2个核心上跑满.真正限制了容器使用的最大核心数.        docker的1.13版以后都使用这个选项来定义.    --cpuset-cpus         定义容器只能跑在宿主机核心的几号核心上，例如只允许跑在1号和3号核心上，那么        这个容器最多也就只能跑满这两个核心,也叫CPU绑定.</code></pre><p>所以在创建启动容器一定要做资源限制，即使不清楚容器中某个程序要占用多大的资源时，也应该设置只允许占用宿主机一半的资源.</p><h3 id="资源限制压测"><a href="#资源限制压测" class="headerlink" title="资源限制压测"></a>资源限制压测</h3><pre><code>在docker hub上的lorel/docker-stress-ng镜像    -c N 启动几个进程对CPU进行压测    -vm N 启动几个进程对内存做压测示例：通过该镜像进行压测    限制只能跑在cpu的0号和3号上，最多只能跑满2个核心数    限制最多占用512m的内存大小docker run --name stress --cpus 2 --cpuset-cpus 0,3 -m 512m --rm lorel/docker-stress-ng -c 2 -vm 2</code></pre><p>-docker stats命令查看结果<br><img src="/2018/10/18/Docker的资源限制/docker-stats.png" alt="docker status"></p><p>-top命令显示宿主机资源(安装1显示全部的CPU核心数信息)<br><img src="/2018/10/18/Docker的资源限制/top命令.png" alt="top命令"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker资源限制&quot;&gt;&lt;a href=&quot;#Docker资源限制&quot; class=&quot;headerlink&quot; title=&quot;Docker资源限制&quot;&gt;&lt;/a&gt;Docker资源限制&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker仓库管理工具Harbor</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7Harbor/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker仓库管理工具Harbor/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-27T03:25:41.692Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker仓库管理工具Harbor"><a href="#Docker仓库管理工具Harbor" class="headerlink" title="Docker仓库管理工具Harbor"></a>Docker仓库管理工具Harbor</h3><a id="more"></a><p><img src="/2018/10/18/Docker仓库管理工具Harbor/harbor架构.png" alt="harbor架构"></p><p><a href="https://goharbor.io/" target="_blank" rel="noopener">HARBOR</a><br><a href="https://github.com/goharbor/harbor" target="_blank" rel="noopener">github上的harbor</a></p><pre><code>harbor官方功能介绍：    1.基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可        以对多个镜像仓库在同一命名空间（project）里有不同的权限。    2.镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡，        高可用，混合云和多云的场景。    3.图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，        管理项目和命名空间.    4.Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。    5.AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。    6.审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。依赖环境和使用介绍：    1.harbor是基于distribution二次开发的企业级私有仓库，云原生registry，多租户机制，允许用户创建自己的名称空间    2.因为harbor内置了mysql,nginx等服务才能构建一个harbor,所以依赖于docker-compose进行容器编排和依赖于至少docker-17.03.0版本    3.harbor为了安全，也需要以https运行，需要在harbor服务器提供证书，而且也需要为        其他客户端提供证书，为harbor验证使用，当然可以关闭https功能    4.因为需要实时下载镜像，提供了离线安装和在线安装，也可以安装到vSphere平台(OVA方式)虚拟设备。</code></pre><h3 id="离线版安装和配置："><a href="#离线版安装和配置：" class="headerlink" title="离线版安装和配置："></a>离线版安装和配置：</h3><p><a href="https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.1.tgz" target="_blank" rel="noopener">harbor离线安装包下载</a><br><a href="https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md" target="_blank" rel="noopener">离线版安装部署文档</a></p><pre><code>1.先安装docker-compose，docker-ce    yum install docker-compose docker-ce -y2.tar xf harbor-offline-installer-v1.4.0.tgz -C /usr/local/3.cd /usr/local/harbor并修改主配置文件harbor.cfg    [root@mysql_2 harbor]# grep &quot;^[a-Z]&quot; harbor.cfg         hostname = mysql_2      #设置主机名/IP        ui_url_protocol = http      #访问协议，支持http和https        max_job_workers = 10        #最大进程连接数    #####设置使用https协议的证书和路径#####        customize_crt = on          #是否使用自定义证书        ssl_cert = /data/cert/server.crt        ssl_cert_key = /data/cert/server.key        secretkey_path = /data        log_rotate_count = 50       #本地最多保存50次日志滚动        log_rotate_size = 200M      #当日志达到200M时滚动一次        http_proxy =                #是否使用代理        https_proxy =        no_proxy = 127.0.0.1,localhost,core,registry    ####设置用户上下载镜像时，是否启用发邮件功能#########        email_identity =         email_server = smtp.mydomain.com        email_server_port = 25        email_username = sample_admin@mydomain.com        email_password = abc        email_from = admin &lt;sample_admin@mydomain.com&gt;        email_ssl = false        email_insecure = false    ####使用互联网上的邮箱##############        harbor_admin_password = Harbor12345    #harbor默认的管理员密码        auth_mode = db_auth                    #默认使用的数据库类型        db_host = mysql         #设置连接mysql的端口和用户密码        db_password = root123        db_port = 3306        db_user = root         #这里还支持 ldap 以及 本地文件存储方式。    #####修改数据库类型和用户和密码#########4.运行install.sh    因为是离线安装包，会从tar文件中装入所需的镜像文件并启动，启动时会检查    docker-ce和docker-compose的版本开始加载镜像(mysql,redis,nginx等等)    [root@mysql_2 harbor]# ./install.sh     [Step 0]: checking installation environment ...    Note: docker version: 18.09.0    Note: docker-compose version: 1.18.0    [Step 1]: loading Harbor images ...</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/harbor安装过程.png" alt="创建并启动的所有容器"><br><img src="/2018/10/18/Docker仓库管理工具Harbor/和harbor相关的所有容器.png" alt="创建并启动的所有容器2"></p><pre><code>5.启用的容器可能会使用宿主机的名称空间6.通过docker-compose管理harbor    cd /usr/local/harbor/    docker-compose stop    docker-compose start</code></pre><p>登录web管理界面：<a href="http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码" target="_blank" rel="noopener">http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码</a><br><img src="/2018/10/18/Docker仓库管理工具Harbor/登录页面.png" alt="登录页面"></p><pre><code>7.创建用户和测试仓库：    创建lk用户，测试登录    创建test仓库用于测试上传镜像 直接创建test仓库即可</code></pre><h3 id="内网服务器登录harbor"><a href="#内网服务器登录harbor" class="headerlink" title="内网服务器登录harbor"></a>内网服务器登录harbor</h3><p>-登录报错<br>–Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。<br>如果配置文件中启用了https，而且也有证书等信息，就不会有这个报错<br><img src="/2018/10/18/Docker仓库管理工具Harbor/登录报错.png" alt="docker login报错"></p><pre><code>解决方法：    1.在所有的内网需要上传下载镜像的服务器上都创建daemon.json文件        vim /etc/docker/daemon.json        {           &quot;insecure-registries&quot;:[&quot;192.168.100.17&quot;]           ###该选项表示从不安全的仓库下载或上传镜像        }    2.还要注意：        如果[&quot;192.168.100.17&quot;]中使用的主机名，那么需要在本地hosts文件或者局域网DNS        服务器上进行主机名解析    3.也可以修改vim /usr/lib/systemd/system/docker.service文件        vim /usr/lib/systemd/system/docker.service             ExecStart=/usr/bin/dockerd  --insecure-registry 192.168.100.17        重启docker            systemctl daemon-reload            systemctl restart docker    4.docker login 192.168.100.17|主机名 #登录私有harbor仓库      docker logout 192.168.100.17|主机名 #退出私有harbor仓库</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/成功登录.png" alt="成功登录"></p><pre><code>4.制作镜像并测试上传    制作镜像：docker tag httpd:v0.1 192.168.100.17/test/httpd:v1                将之前制作好的镜像改标签再上传上去            docker image build . -t 192.168.100.17/test/httpd:v2.0                也可以通过dockerfile重新制作一个再上传    上传到test仓库中: docker push 192.168.100.17/test/httpd:v1</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/上传.png" alt="上传镜像"><br><img src="/2018/10/18/Docker仓库管理工具Harbor/上传镜像.png" alt="上传镜像"></p><pre><code>5.测试拉取镜像    在页面上点击复按钮，在命令行中就可以拉取镜像了</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/拉取镜像.png" alt="拉取镜像"></p><h3 id="如何修改配置："><a href="#如何修改配置：" class="headerlink" title="如何修改配置："></a>如何修改配置：</h3><pre><code>[root@linux-host1 harbor]# /usr/local/harbor[root@linux-host1 harbor]# docker-compose   stop #先停止服务[root@linux-host1 harbor]# vim harbor.cfg  #编辑配置[root@linux-host1 harbor]# docker-compose start #重新启动服务</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker仓库管理工具Harbor&quot;&gt;&lt;a href=&quot;#Docker仓库管理工具Harbor&quot; class=&quot;headerlink&quot; title=&quot;Docker仓库管理工具Harbor&quot;&gt;&lt;/a&gt;Docker仓库管理工具Harbor&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker镜像</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E9%95%9C%E5%83%8F/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker镜像/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-02-15T05:54:46.540Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Images"><a href="#Docker-Images" class="headerlink" title="Docker Images"></a>Docker Images</h3><a id="more"></a><font size="3" color="#FF0000"><br>1.docker image是docker贡献给容器极具创造性的使用方式！<br>2.分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！<br>3.容器编排技术：<br>—Docker通过镜像机制极富创造性的解决了应用程序打包的根本性难题，它推动了容器技术的快速普及和生产落地<br>—容器本身仅提供托管运行应用的底层逻辑，而容器编排(Orchestration)才是真正产生价值的位置所在；<br></font><p>-docker-image和读写机制<br><img src="/2018/10/18/Docker镜像/docker读写机制.png" alt="docker-image和读写机制"></p><pre><code>1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器    a.docker镜像就像KVM镜像一样，包含了启动容器/虚拟机所依赖的所有文件，文件系统        包括程序文件，库文件，配置文件,数据目录等等    b.dokcer采用分层构建机制，最底层为bootfs，其上是rootfs        bootfs：在创建的容器中是看不到的，只是用于系统引导的文件系统，包括                bootloader和kernel，因为在创建启动容器时，其实是用到内核的，                只不过只是启动引导容器启动的，当容器启动完成后会被卸载以节约内存资源;                而且把对应的对容器的管理委托给宿主机的内核，所以容器镜像的内核只                是启动时有用，而且看不到，所以bootfs叫引导文件系统        rootfs:位于bootfs之上，表现为docker容器的根文件系统;                1.在传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只                    读&quot;模式，完整性自检完成后将其重新挂载为读写模式；也就是fstab                    的最后两项，只有通过自检次序时，才会把根文件系统重新以&quot;读写&quot;方式挂载.                2.但是在docker中，rootfs由内核挂载为&quot;只读&quot;模式，就算容器启动完成                    ，rootfs也不会以读写方式重新挂载！也就是说docker容器的用户空                    间和根文件系统一直都是只读的！                3.docker是通过&quot;联合挂载&quot;技术额外挂载一个“可写”层；docker image layer2.Docker Images Layer    如上图    a.完整的docker镜像包括bootfs,rootfs    b.而rootfs又包括Base Image+自定义的镜像层+可写层writable        除了writable是可写层，其他都是只读层    c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加        一个可写层，这个可写层writable是属于容器的    d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的</code></pre><h4 id="容器的读写原理："><a href="#容器的读写原理：" class="headerlink" title="容器的读写原理："></a>容器的读写原理：</h4><p>如上图示： </p><ul><li>1.对于docker来说有一个专门存放镜像的路径叫Graph Driver，而这个文件系统必须是特殊<br>  格式的(aufs或者overlay2),在linux系统内默认是/var/lib/docker/image/overlay2；<br>  overlay2目录就是构建在宿主机(xfs或ext4)的/var/lib/docker/image/目录的二级文件系统</li></ul><ul><li>2.前面说镜像数据文件都放在bootfs和rootfs上的，可写层writbale是创建时创建的<br>  那么在可写层上是如何看到底层的数据目录？又是怎么把数据增删改到容器内的？<br>  默认xfs和ext4是不支持COW机制的</li></ul><blockquote><p>如何看到镜像目录的？</p></blockquote><pre><code>a.在创建容器时，是把镜像内的多层镜像通过联合挂载方式作为可写层的底层，也就是这个容器内部的可访问文件系统接    口b.所谓联合挂载，是通过把镜像内的多层一层一层叠加上去的，而这个叠加方式的原理是：    第一层上有数据时，而第二层没相同数据，在第二层是可以看到第一层数据的;如果第二层有第一层相同数据，    则会覆盖第一层上的相同数据，在第二层上看到的是第一层和第二层总的文件，以此类推，在可写层上就可以看到    镜像内的数据目录了，</code></pre><blockquote><p>如何修改和写文件？</p></blockquote><pre><code>a.对于修改文件，因为文件是放在只读层的，只能是通过COW写时复制机制，先把文件从只读层复制到可写层上再进行修改    然后保存在可写层,当然是首次修改，第二次再修改因为在可写层有文件了，在可写层修改即可，而只读层的该文件    版本仍然存在，只不过是被读写层中该文件的副本所隐藏了.b.对于写文件，新创建的文件是保存在可写层的，所以最终用户看到的是只读层和可写层的全    部数据文件，这就是镜像的工作逻辑</code></pre><blockquote><p>通过上面的分析可以得出：</p></blockquote><pre><code>1.这就是为什么基于同一镜像创建的两个容器，用户在不同的容器上看到的相同的数据都是只读层的，不同的数据是可写    层上各自独有的，因为可写层是独占的，只读层是共享的2.这就是为什么镜像背后必须要求特殊文件系统的原因：因为ext4和xfs默认是不支持联合挂载和写时复制机制的3.因为可写层是可以自定义修改的，把可写层保存为镜像，然后再和原始镜像进行叠加成一个自定义的镜像，    就可以作为基础镜像使用了，不过一般不这么做，而是通过dockerfile自定义镜像</code></pre><h3 id="docker-imge相关命令"><a href="#docker-imge相关命令" class="headerlink" title="docker imge相关命令"></a>docker imge相关命令</h3><pre><code>docker image 相关命令    docker imges:镜像的管理命令    ls： 查看本地所有的镜像列表    build:    import:    inspect: 查看下载/创建的镜像详细信息            可以查看下载的某个镜像的具体信息                    如：CMD:镜像启动默认运行的命令                        Volume:                        network:            下文中构建docker file时这些都可以自定义    load:    prune:    pull：从远程仓库拉取镜像到本地    push: 把本地镜像推到远程的Registry    rm:  docker image rm = docker rmi 删除镜像    tag: 给镜像打标签    save:2.将当前容器可写层保存为镜像并上传docker hub上    docker container commit [options] container [repository:[tag]]         选项：            -a:指定作者            -c:镜像内部默认运行的命名            -p|--pause:因为制作镜像时，容器还在运行，可能制作出的镜像和当前容器不                一致，可以在制作时，暂停容器，保持数据一致    比如：        1.在docker hub上注册用户，并创建镜像仓库            创建的仓库：myimg        2.把centos1容器做成镜像仓库下的myimg：v0.1版本            docker container commit -p -a &quot;liu &lt;liu@163.com&gt;&quot; -c &quot;CMD [&apos;/bin/httpd -f&apos;]&quot; centos1 liukkui/myimg:v0.1            然后新容器就可以基于这个镜像启动了        3.上传docker hub            docker login 登录到docker hub                输入账号密码，正常登录后        4.push镜像            docker image push liukkui/myimg:v0.1            正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Images&quot;&gt;&lt;a href=&quot;#Docker-Images&quot; class=&quot;headerlink&quot; title=&quot;Docker Images&quot;&gt;&lt;/a&gt;Docker Images&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile</title>
    <link href="https://www.liukui.tech/2018/10/18/Dockerfile/"/>
    <id>https://www.liukui.tech/2018/10/18/Dockerfile/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-22T08:38:18.043Z</updated>
    
    <content type="html"><![CDATA[<h3 id="DockerFile：构建镜像"><a href="#DockerFile：构建镜像" class="headerlink" title="DockerFile：构建镜像"></a>DockerFile：构建镜像</h3><a id="more"></a><pre><code>前面说过：    1.镜像是分层的，当基于这个镜像创建一个容器时，docker是通过联合挂载机制把镜像层    进行叠加作为容器的只读层，而后又在这个镜像栈上构建了一个可写层作为这个容器的工    作目录.    2.所有的底层数据在第一次发生修改操作时，是通过CoW写时复制机制，把数据复制到读    写层进行修改并保存在读写层，覆盖底层的原始文件；写入新数据时，则直接保存在读写    层，而在读写层看到的数据就是全部的镜像层数据(镜像栈)    3.而Graph Driver则又在构建在本地文件系统之上的二级文件系统(aufs,overlay2)    4.基于Graph Driver这种特有的图形驱动程序，就可以把分成构建的镜像堆积在存储    空间当中，紧邻的镜像是有依赖关系的    5.docker commit可以把当前的读写层及其底层依赖的镜像关系打包成一个镜像层存储    在Graph Driver当中，并且指向底层依赖的镜像层，形成一个新的镜像层，如果基于    同一个镜像commit多个可写层，这些新的镜像层都是指向之前的底层镜像的，这也是    docker镜像不是很大的原因。    6.所以在制作镜像时，完全不必基于某个基础镜像显示启动一个新容器，然后在上面创建    修改可写层并打包成镜像；commit只是一种方式，也可以使用dokcerfile    7.如果再本地将软件源码编译/二进制编译到容器也是可以的</code></pre><h3 id="dockerfile基本要求"><a href="#dockerfile基本要求" class="headerlink" title="dockerfile基本要求"></a>dockerfile基本要求</h3><pre><code>1.dockerfile的工作逻辑：    制作镜像无非就是基于某个基础镜像创建一个可写层修改后再commit成一层新的镜像    这个过程可以由docker自身完成，只需要在dockerfile配置文件中写清楚，基于哪个基础镜像，    按需修改(通过各种指令生成)，而docker build可以读取dockerfile文件，隐    式的执行这些指令集生成一个新的镜像层保存在Graph Driver中2.工作目录    构建docker镜像时，必须有一个工作目录docker,这个目录下只存在dockerfile和在    dockerfile中定义要复制的文件，是起始目录3.dockerfile format：语法    dockerfile就是一个纯文本文件;        注释行        dockerfile instruction args:指令要纯大写        第一条指令必须是FROM：基础镜像名称        docker build是按顺序读取执行dockerfile中的指令集的4.dockerfile中的每一条指令都会生成一个新的镜像层    如果指令比较多，生成的镜像层就比较多，就会造成第一次的CoW从底层读取数据时很慢    但是镜像层比较多又容易被分享和易控，较少又会比较繁琐    所以一般是把做同一个件事的多个操作通过\换行符，用一条指令完成(见下文)5.镜像内唯一要运行的程序一定必须要运行在前台</code></pre><h3 id="dockerfile中的环境变量"><a href="#dockerfile中的环境变量" class="headerlink" title="dockerfile中的环境变量"></a>dockerfile中的环境变量</h3><pre><code>1.docker为了满足同一镜像在不同环境下的使用场景引入了环境变量的方式    某个容器基于镜像启动时，通过传递环境变量参数，来生成容器内的不同的配置文件    docker container run --name CONTAINER_NAME -e VAR -it IMAGE_NAME COMMAND    这样一来，就可以用基于同一基础镜像，传递不同的环境变量作为参数值，创建适应    于不同环境的容器2.entrypoint.sh脚本    但是传统的代码不支持传环境变量作为参数，而在docker中又需要传参，这时就有了衔接    层也就是shell脚本，这个脚本作为容器第一个要运行的程序然后运行完退出，再退出去    之前读取用户传的环境变量，将环境变量的值写到程序的配置文件中；    而且很多镜像通过docker image inspect mysql:8.0 |grep entrypoint过滤是可以    看到有这个脚本的3.环境变量的两类用法：    a.在构建dockerfile中使用    b.以dockerfile构建的镜像为基础镜像，启动容器时使用    而dockerfile中的指令的生命周期是有两个阶段的        build：基于基础镜像构建镜像的阶段        run: 启动容器的阶段        dockerfile中的一些指令或者环境变量在不同阶段使用发挥的价值是不一样的4.环境变量的设定和引用    设置：ENV statement    两种引用方式：    1.${variable:-word}         如果变量variable为空或不存在时，就使用word值        如果设置了variable，就使用该变量值    2.${variable:+word}         如果变量有值，就使用word值，如有没值就是空值</code></pre><h3 id="dockerignore-file"><a href="#dockerignore-file" class="headerlink" title=".dockerignore file"></a>.dockerignore file</h3><pre><code>1.dockerignore是工作目录中专门记录需要忽略的文件列表2.而且docker build会自动忽略.dockerignore自身和记录在其中的所有文件</code></pre><h3 id="Dockerfile基本语法"><a href="#Dockerfile基本语法" class="headerlink" title="Dockerfile基本语法"></a>Dockerfile基本语法</h3><pre><code>FROM：    FROM必须是文件的第一指令    FROM &lt;repository&gt;[:&lt;tag&gt;  镜像的标签    或者&lt;resository&gt;@&lt;digest&gt; 镜像的ID号校验码        推荐使用digest因为校验码是安全的，而且最好不要使用lastedLABLE:    authtor&apos;s infomation;提供该镜像的标签信息    语法： maintainer &quot;liu &lt;liu@163.com&gt;&quot;COPY:    从宿主机复制文件至创建的新镜像    COPY &lt;src&gt;... &lt;dest&gt;    COPY [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]         &lt;src&gt;：要复制的源文件或目录，支持使用通配符        &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则，COPY指定则以WORKDIR为其起始路径；        注意：在路径中有空白字符时，通常使用第二种格式    注意：    1. src：必须为build上下文中的路径，可使用相对路径    2.如果src是目录，其内部的文件或子目录会自动被递归复制，但src自身不会被复制            等于cp -r /src/* /dest/    3. src有多个，或者src使用通配符，则dest必须是一个目录，且必须以/结尾    4. 如果dest事先不存在，它将会被自动创建ADD:    类似于COPY，但是额外支持tar文件和URL路径    ADD &lt;src&gt;... &lt;dest&gt;    ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]    1. 如src为URL时且dest不以/结尾，ADD会自动将指定的文件下载并创建为dest，        如dest以/结尾，则会下载指定的文件并保存为dest/FILENAME        即一个是下载并改名，一个是下载到这个文件目录下    2. 如src是一个本地的tar文件，则会被自动展开为一个目录，但通过URL获取到的文件        则不会自动展开，即在本地的就展开，互联网的就不展开    3. 如src有多个，或使用通配符，则dest必须是目录且以/结尾，如dest不以/结尾，        则被视为一个普通文件，src的内容将被直接追加写入到dest文件中WORKDIR：    1.用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录    2.WORKDIR指令可出现多次，表示下个指令可以以此目录为父目录，路径可以表示为相对    路径，也可以写成绝对路径    3.WORKDIR的有效范围当前workdir向下，下一个workdir之前的范围    4.另外，WORKDIR也可调用由ENV定义的环境变量的值，如果下次修改环境变量的值，响应生成信息的镜像层    5.而且如果设定了WORKDIR，容器启动时，默认就进入到workdir路径了VOLUME：    用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷    注意：        1.在dockerfile中定义的卷，启动容器时，是被docker管理的卷与宿主机的某个            路径建立关联关系        2.如果需要定义的卷与宿主机特定的目录建立关联关系，还需要在run container时            指定-v选项        3.如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此            前的所有文件复制到新挂载的卷中EXPOSE:都是动态端口暴露    用于为容器打开指定要监听的端口以实现与外部通信    EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...]       &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议    注意：        1.即使在dockerfile中定义了暴露的端口，启动为容器时，端口也不会暴露的            因为是有安全风险的；        但可以用run container时加 -P选项强行暴露端口，但这是个动态端口暴露        用起来极其鸡肋！ENV：    build阶段使用的：        用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令        如ENV、ADD、COPY等）所调用，调用格式为$variable_name或${variable_name}    两种语法：    1.ENV &lt;key&gt; &lt;value&gt;         &lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只        能设置一个变量；    2.ENV &lt;key&gt;=&lt;value&gt; ...        可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果        &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另外，反斜线也可用于续行；    定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能    缺点：如果想修改ENV定义的值，只能修改dockerfile中的值，比价麻烦，此时    就可以使用ARG来代替ENVARG：    arg是在build阶段进行传值，替换dockerfile中的值        ARG &lt;name&gt; [=&lt;default&gt;] 可以设置默认值    当build创建镜像时没有传值，则使用在dockerfile中设置的默认值    既可以弥补ENV的缺点也可以和RUN，CMD的ENV传环境变量区别开    如：在build时更改home的值    docker image build --build-arg home=&quot;/webdata/&quot; /data/dockerfile/ -t myimg:v0.4</code></pre><h4 id="RUN-CMD-ENTRYPOINT的区别"><a href="#RUN-CMD-ENTRYPOINT的区别" class="headerlink" title="RUN,CMD,ENTRYPOINT的区别"></a>RUN,CMD,ENTRYPOINT的区别</h4><p><img src="/2018/10/18/Dockerfile/三者区别.png" alt="三者的区别"></p><p>区别：</p><pre><code>RUN：    用于指定docker build过程中运行的程序，可以是任何命令                (这就意味着RUN的命令必须是使用的基础镜像支持的命令)    1.是指在docker build过程中通过运行RUN定义的shell命令，以达到在镜像中安装软件等操作    2.RUN可以设定多次，而且每一个都会在build的时执行    语法：        RUN &lt;command&gt;            通常运行的是一个shell命令，且以&quot;/bin/sh -c&quot;运行，且/bin/sh是PID为1的进程，command是作为shell的子进程存在        RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;]            此种格式指定的命令不会以&quot;/bin/sh -c&quot;，因此无法支持shell的诸多特性，如要依赖于shell特性，可替换成如下格式：            RUN [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;]CMD：    1.当把镜像运行容器时，需要指定默认运行的程序，这在dockerfile中需要用CMD命令来        指定，ENTRYPOINT也可以    2.默认运行的程序必须运行在前台    3.由于CMD设定的是容器启动默认运行的程序，所以必须只有一个，如果有多个，        则最后一个CMD生效    语法：        CMD &lt;command&gt; 或        CMD [“&lt;executable&gt;”, “&lt;param1&gt;”, “&lt;param2&gt;”] 或        CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]        前两种语法格式的意义同RUN        第三种则用于为ENTRYPOINT指令提供默认参数    systemctl start httpd启动是运行在systemd的前台上，所以启动就会退出ENTRYPOINT：    1.CMD和ENTRYPOINT都表示镜像启动为容器时，容器默认运行的程序，而且CMD和ENTRYPOINT有多个，也都是最后一个生效    2.如果CMD和ENTRYPOINT同时存在，CMD和ENTRYPONIT需要组合起来，则CMD指定的内容    都作为ENTRYPOINT所指定内容的参数    语法：        ENTRYPOINT &lt;command&gt;或者        ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;]    docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到    ENTRYPOINT命令最后做为其参数使用    Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效</code></pre><p>示例：<br>    docker run –name c1 -P -d myimg:v0.1 以后台运行容器</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;DockerFile：构建镜像&quot;&gt;&lt;a href=&quot;#DockerFile：构建镜像&quot; class=&quot;headerlink&quot; title=&quot;DockerFile：构建镜像&quot;&gt;&lt;/a&gt;DockerFile：构建镜像&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker网络</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%BD%91%E7%BB%9C/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker网络/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-02-15T08:21:33.861Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Network"><a href="#Docker-Network" class="headerlink" title="Docker Network"></a>Docker Network</h3><a id="more"></a><p><img src="/2018/10/18/Docker网络/docker的四种网络.png" alt="docker的四种网络"></p><pre><code>KVM上虚拟桥接式网络类型：        隔离桥：只能与连接到同一个桥上的主机通信，IP地址还需要在同一网段        仅主机桥：可以和连接的桥地址进行通信        路由桥：            1.打开宿主机核心转发功能            2.虚拟机的网关都指向这个桥的地址            就可以与宿主机通信，不能与外网通信        NAT桥：在路由桥的基础上，在宿主机上做SNAT规则，即可访问外网地址    Docker提供的四种网络：    桥网络：桥接网络            bridge，默认就是docker0桥，docker0是SNAT桥            查看网络定义：docker network inspect bridge            大多数的容器还是使用bridge网络            而且这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器    共享桥：联盟式网络         每一个容器都是靠在内核级虚拟资源分配的独立的6种名称空间来支撑的        这6种名称空间是IPC,Net,Mount,UTS,PID,USER        虽然每个容器都有各自独立的名称空间，但是确可以共享，于是就有了这种方式        共享桥的原理：                共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈            而mount user PID还是隔离的，文件系统也是隔离的        这样做的效果就可以构建出一个模型            httpd---&gt;fpm127.0.0.1:9000---&gt;mysql127.0.0.1:3306            那么对于fpm和mysql来说只监听在本地端口上，保证了安全性    host宿主机网络：共享宿主机网络        既然多个容器可以使用同一个容器的网络名称空间，而且宿主机在内核中也有自己的        网络名称空间，那么容器也理所当然的可以使用宿主机的网络名称空间        容器使用宿主机的网络和DNAT方式有关系        作用：可以做日志收集主机，host一般在特殊环境下使用    none网络：封闭式网络        当容器不需要网络服务时，不创建网卡，只有本地lo网卡除了bridge桥之外，其他三种网络都是docker所独有的</code></pre><h3 id="Docker网络的相关命令"><a href="#Docker网络的相关命令" class="headerlink" title="Docker网络的相关命令"></a>Docker网络的相关命令</h3><pre><code>docker run 命令中涉及网络的相关命令    --network 启动容器时，指定使用的网络        [bridge|host|none|container:name]    --hostname 启动容器时，指定容器的主机名    --add-host list 启动容器时，指定内部的hosts解析文件        如：docker run --add-host c1:192.168.10.1 busybox:latest            cat /etc/hosts可以看到添加的解析    --dns 启动容器时，指定DNS地址        如：docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest            cat /etc/resolve可以看到指定的DNS地址    --ip string 启动容器时，指定容器的iPv4地址    -p|--publish         因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则docker network:    ls：显示docker内部的全部网络    connect: 让容器连接到某个网络上    disconnect: 把容器从某个网络断开    create: 创建自定义网络，和KVM创建网络类似    inspect:查看某个网络是怎么定义的    prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令    rm: 删除docker内部的网络</code></pre><h3 id="Docker-network的端口暴露"><a href="#Docker-network的端口暴露" class="headerlink" title="Docker network的端口暴露"></a>Docker network的端口暴露</h3><pre><code>docker run --network [bridge|host|none] -p|--publish     作为一个容器，是要提供web服务的，而docker默认的桥是bridge，而且是个SNAT桥    容器只能访问外网，而不能被外网所访问，那么就失去了web服务器对外提供服务的初衷    而docker提供了一个-p选项来自动生成DNAT规则，来避免每次都手写DNAT规则带来的麻烦-p选项的用法和使用格式：    •-p &lt;containerPort&gt;        将指定的容器端口映射至主机所有地址的一个动态端口    •-p &lt;hostPort&gt;:&lt;containerPort&gt;        将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt;    •-p &lt;ip&gt;::&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口    •-p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt;    “动态端口”指随机端口，具体的映射结果可使用docker port命令查看    不过一般还是要使用第四种方式指定宿主机的端口    指定了映射的端口后，可以使用命令查看映射关系：        docker container port [name]示例：1.docker run --name c1 -it --rm --network bridge -p 80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:327682.docker run --name c1 -it --rm --network bridge -p 80:80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:803.docker run --name c1 -it --rm --network bridge -p 192.168.34.103::80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:327684.docker run --name c1 -it --rm --network bridge -p 192.168.34.103:80:80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:80</code></pre><h3 id="Docker的自定义网络"><a href="#Docker的自定义网络" class="headerlink" title="Docker的自定义网络"></a>Docker的自定义网络</h3><pre><code>docker network create     connect:相当于创建一对网卡，一半在桥上，一半在容器中    而且默认创建的网络都是SNAT桥    选项：    -d|--driver string 创建时，要指定桥的类型        默认是bridge，当然还有 host macvlan null overlay四种类型    --gateway strings 默认是定义的子网的第一个IP地址    --subnet strings 子网地址    --ip-range strings 地址分配的IP地址范围修改默认的bridge，docker0桥的子网    自定义docker0桥的网络属性信息：也就是镜像加速的文件    vim /etc/docker/daemon.json文件    {        &quot;bip&quot;: &quot;192.168.1.5/24&quot;,        &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;,        &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,        &quot;mtu&quot;: 1500,        &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,        &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,        &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]    }     核心选项为bip，即bridge 桥接口的IP地址    ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。示例：    1.创建一个mybr2的网络，并指定子网地址        docker network create --subnet 10.0.0.0/8 mybr2    2.创建容器c1指定加入到mybr2网络中        docker run --name c1 -it --rm --network mybr2  busybox:latest    3.给容器c1再加入一个bridge网络中        docker network connect bridge c1        此时c1就有了两个网络地址    4.删除容器c1的网卡        docker network disconnect mybr2 c1</code></pre><h3 id="Docker指定容器启动的网路类型"><a href="#Docker指定容器启动的网路类型" class="headerlink" title="Docker指定容器启动的网路类型"></a>Docker指定容器启动的网路类型</h3><pre><code>1.启动为none类型的网络    docker run --name c1 -it --rm --network none busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/none网络.png" alt="none网络"></p><pre><code>2.启动为bridge类型的网络:docker默认的网络模型    docker run --name c2 -it --rm --network bridge busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/bridge网络.png" alt="bridge网络"></p><pre><code>3.启动为joined类型的网络    启动的c3共享的是c2的Net,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的</code></pre><p><img src="/2018/10/18/Docker网络/共享桥网络.png" alt="共享桥网络"></p><p>因为共享桥只是共享了Net网络，UTS主机名，IPC，<br>此时IP地址和hostname都是一样，就可以通过127.0.0.1进行通信了<br>而mount(文件系统)，user,PID还是隔离的，所以在1上创建一个文件，2上是看不到的<br>这就是共享桥的工作机制</p><pre><code>4.启动为host宿主机类型的网络    docker run --name c4 -it --rm --network host busybox:latest    可以看出hostname,Net都是和宿主机是一样的    此时在容器内部启动httpd服务，其他主机是可以通过宿主机提供服务的</code></pre><p><img src="/2018/10/18/Docker网络/host网络.png" alt="host网络"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Network&quot;&gt;&lt;a href=&quot;#Docker-Network&quot; class=&quot;headerlink&quot; title=&quot;Docker Network&quot;&gt;&lt;/a&gt;Docker Network&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>docker存储卷</title>
    <link href="https://www.liukui.tech/2018/10/18/docker%E5%AD%98%E5%82%A8%E5%8D%B7/"/>
    <id>https://www.liukui.tech/2018/10/18/docker存储卷/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-07T11:44:05.627Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Data-Volume：docker存储卷"><a href="#Docker-Data-Volume：docker存储卷" class="headerlink" title="Docker Data Volume：docker存储卷"></a>Docker Data Volume：docker存储卷</h3><a id="more"></a><pre><code>存储卷是什么：    存储卷是容器上一个或者多个“目录”，并将此“目录”与宿主机上的某目录建立关联关系，    存储卷在容器初始化之时会被创建，由baseimage提供的卷中的数据数据会在此时完成复制为什么需要用到存储卷:    docker启动一个容器是基于镜像的只读层，并在其上添加一个读写层，而镜像是由多个只读层叠加而来。如果运行中    的容器修改了现有一个已存在的文件，那该文件将会从只读层复制到读写层，而该文件的只读版本仍然存在，只是    被读写层中该文件的副本所隐藏而已，而此时关闭该容器，该容器所修改的文件的将会丢失且不能被其它容器共享、复用，因而需要一个存储卷。如何实现容器内的路径与容器外的存储建立关联关系？    实际应用场景：        1.通常在可写层上只保存临时数据，有效数据保存在和宿主机关联的目录下，这样就        剥离了程序和产生的数据间紧密的耦合关系，即程序在容器的名称空间上，数据在        宿主机或存储上，数据就独立于容器的生命周期之外        2.当容器down后，再启动一个新容器，指定数据路径为宿主机或存储上的路径，则        又恢复了数据，这就叫做Docker的存储卷存储卷存在的问题：    存在的问题        •存储于联合文件系统中，不易于宿主机访问；        •容器间数据共享不便        •删除容器其数据会丢失    解决方案：“卷(volume)”        •“卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机            上的某目录“绑定(关联)”        •Volume于容器初始化之时即会创建，由base image提供的卷中的数据会于此期间            完成复制        •Volume的初衷是独立于容器的生命周期实现数据持久化，因此删除容器之时既不会        删除卷，也不会对哪怕未被引用的卷做垃圾回收操作；存储卷的type:    1. Bind mount volume        绑定挂载卷，永久生效        容器内目录和宿主机中的目录都是由用户自己指定的，    2. Docker-managed volume：        称为docker自己指定的卷        容器中的卷是用户自己指定的，而宿主机上的目录是由docker-daemon进程自行        决定与宿主机的哪个目录建立        关联关系的存储卷，只能用于临时挂载。存储卷的相关命令:    docker run         -v 运行时，指定存储卷        --volumes-from list 复制其他容器的卷，达到共享卷的目的        --sorkdir string    docker volume         ls：列出当前已和宿主建立关联关系的存储卷        create：        inspect name:查看一个卷的详细信息        prune        rm: 因为docker container inspect c1看到的容器内的详细信息是JSON格式的    所以就可以通过过滤特殊字段显示查询的信息    docker container inspect CONTAINER_NAME -f {{.JSON_VALUE}}     Docker-managed volume        • ~]# docker run -it -name c1 –v /data busybox        • ~]# docker inspect -f {{.Mounts}} c1        • 查看c1容器的卷、卷标识符及挂载的主机目录            和docker container inspect c1的过滤效果一样    Bind-mount Volume        • ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name c1 busybox        • ~]# docker inspect -f {{.Mounts}} c1如图以过滤IP地址为例，其他信息类似</code></pre><p><img src="/2018/10/18/docker存储卷/JSON格式的过滤.png" alt="JSON格式过滤"></p><pre><code>示例1.Docker-managed volume    临时创建挂载一个mydata卷        docker run --name c1 -it  --rm -v /mydata busybox:latest        并通过docker container inspect c1 探测        mydata被docker指定与宿主机的哪个目录建立了关联关系</code></pre><p><img src="/2018/10/18/docker存储卷/docker管理的卷.png" alt="docker管理的卷"></p><font size="3" color="#FF0000"><br>从上图看mydata是被docker-manager指定与该容器目录下的_data建立了关系<br>注意：<br>创建容器的时候加–rm选项时，停止容器后，宿主机上的卷也会被删除的<br>不加–rm选项，停止容器，并rm容器，宿主机上的卷是不会被删除的<br>缺点是对应的宿主机上的目录难查找<br></font><pre><code>示例2.Bind mount volume    现在宿主机上创建卷的目录 mkdir /data/volume/c1docker run --name c1 -it  --rm -v /data/volumes/c1:/mydata busybox:latest     并通过docker container inspect c1 </code></pre><p><img src="/2018/10/18/docker存储卷/bind卷.png" alt="bind卷"></p><font size="3" color="#FF0000"><br>可以看出宿主机的/data/volumes/c1与容器内的/mydata是建立的bind类型的卷<br>即使容器被删除，数据还在存在的<br>而且如果/data/volume/c1是在NFS网络文件系统上的话，即使宿主机down了，数据也是无损的<br></font><pre><code>示例3：多容器之间的数据共享1.先创建容器c1docker run --name c1 -it  --rm -v /data/volumes/c1:/mydata busybox:latest 2.创建容器c2时，共享容器c1的卷    docker run --name c2 -it  --rm --volumes-from c1 busybox:latest    此时c1和c2上看到的mydata卷看的数据都是一样的，达到共享卷的目的示例4.用docker实现类似于k8s上的pod组件机制    要求：        1.c1上挂载多个NFS存储上的卷和bridge桥        2.c3和c4使用c1的网络名称空间和c1上的卷    实现：    c1:        docker run --name c1 -v /data/volumes/c1:/mydata -v /data/volume2:/mydata2 busybox:latest     c3.    docker run --name c3 -it --rm --network container:c1 --volumes-from c1  busybox:latest    c4.    docker run --name c4 -it --rm --network container:c1 --volumes-from c1  busybox:latest</code></pre><p><img src="/2018/10/18/docker存储卷/实现docker的pod组件模型.png" alt="实现docker的pod组件模型"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Data-Volume：docker存储卷&quot;&gt;&lt;a href=&quot;#Docker-Data-Volume：docker存储卷&quot; class=&quot;headerlink&quot; title=&quot;Docker Data Volume：docker存储卷&quot;&gt;&lt;/a&gt;Docker Data Volume：docker存储卷&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>iptables之FORWARD和NAT</title>
    <link href="https://www.liukui.tech/2018/10/10/iptables%E4%B9%8BFORWARD%E5%92%8CNAT/"/>
    <id>https://www.liukui.tech/2018/10/10/iptables之FORWARD和NAT/</id>
    <published>2018-10-10T00:00:00.000Z</published>
    <updated>2019-01-07T11:23:00.386Z</updated>
    
    <content type="html"><![CDATA[<p>iptables/netfilter网络防火墙：<br>        在FORWARD链上定义规则，注意以下几个问题：<br>            (1) 请求-响应均经由FORWARD链，要注意规则的方向性；<br>            (2) 如果可以启用conntrack机制，建议将双方向的状态为ESTABLISHED的报文直接放行；<br><a id="more"></a></p><h3 id="网络防火墙原理及示例"><a href="#网络防火墙原理及示例" class="headerlink" title="网络防火墙原理及示例"></a>网络防火墙原理及示例</h3><p>本地通信：两个主机在没有网关或者路由下进行通信，所有的本地通信是通过MAC地址进行通信的<br>        name–&gt;IP–&gt;MAC地址基于广播机制<br>        如果有交换机，交换机会查找MAC地址表(是通过源地址学习得到的),<br>        将数据报文直接发送到连接到交换机的目标主机上<br>网络通信：其实就是多个本地通信实现的，由多个路由器进行中继转发最后到达目标主机的<br>    而把linux服务器扮演成路由器的角色，则这台linux服务器充当是网关，就需要打开核心转发功能</p><h3 id="FORWARD链"><a href="#FORWARD链" class="headerlink" title="FORWARD链"></a>FORWARD链</h3><p>右边是生产环境<br>左边是研发测试环境：</p><p>隧道VPN</p><p>实验模拟：<br>    sysctl -w net.ipv4.ip_forward=1<br>    A:<br>    route add -net 192.168.10.10/24 gw 192.168.34.103<br>    B:<br>    route add -net 192.168.34.0/24 gw 192.168.10.10<br>    情景一：客户端确定服务端不确定；源地址确定，目标地址不确定<br>    情景二：服务端确定，客户端不确定；源地址不确定，目标地址确定</p><p>对于情景一的情况：<br>    客户端确定,服务端不确定；即源地址确定，目标地址不确定<br>示例1:<br>    1.先在FORWARD链上默认为拒绝<br>    如控制客户端只能访问httpd和ping操作，就可以在FORWARD链上添加如下规则<br>    tcp:80端口限制:<br>    iptables -A FORWARD 1 -s 192.168.34.0/24 -p tcp –dport 80 -j ACCEPT<br>    iptables -I FORWARD 2 -d 192.168.34.0/24 -p tcp –sport 80 -j ACCEPT<br>    icmp的ping限制：<br>    iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -j ACCEPT<br>    iptables -I FORWARD 4 -d 192.168.34.0/24 -p icmp –icmp-type 0 -j ACCEPT<br>    默认拒绝策略：<br>        iptables -I FORWARD 5 -j REJECT<br>    2.因为之前介绍过state的状态追踪功能：<br>    就可以简化成这样的规则：<br>    iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT<br>    iptables -A FORWARD 2 -s 192.168.34.0/24 -p tcp –dport 80 -j ACCEPT<br>    iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -j ACCEPT<br>    iptables -I FORWARD 4 -j REJECT<br>    3.情景一因为都是内网的服务器，是不能接收外网的请求的<br>    所以对于ping和tcp只允许从内网出去的，外网是不能进来的，规则如下<br>    iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT<br>    iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp –dport 80 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 4 -j REJECT</p><p>示例2：控制访问ping,httpd：80,vsftp：21,dns：53<br>    规则如下：<br>    iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT<br>    iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp -m multiport –dport 80,21,53 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 3 -s 192.168.34.0/24 -p udp –dport 53 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 4 -s 192.168.34.0/24 -p icmp –icmp-type 8 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 5 -s 192.168.34.0/24 -p tcp -m state –state RELATED -j ACCEPT<br>    iptables -I FORWARD 6 -j REJECT<br>在这里需要指定-s 源，不然外网向内网主动发送报文请求也是可以到达内网的！</p><font size="3" color="#FF0000"><br>结论：<br>    1.所以说有时服务器ping不通不代表服务不能访问，而且通过内网ping外网时，在外网服务器<br>    进行抓包时，可以看出源地址是内网IP,非网关IP，目标地址是外网IP地址<br>[root@centos7 data]# tcpdump -i ens33 -nn icmp<br>tcpdump: verbose output suppressed, use -v or -vv for full protocol decode<br>listening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytes<br>21:10:24.541810 IP 192.168.34.107 &gt; 192.168.10.10: ICMP echo request, id 1764, seq 3, length 64<br>21:10:24.541877 IP 192.168.10.10 &gt; 192.168.34.107: ICMP echo reply, id 1764, seq 3, length 64<br>    2.用linux防火墙做网关网络防火墙，有一个问题，内网的机器是保护了，但是这台linux服务<br>        是没有防护的，所以还需要在这台网络防火墙上在INPUT和OUTPUT链上加上规则，来防护<br>        这台linux网关网络防火墙！所以当用一台linux服务器做网络防火墙时，INPUT,OUTPUT<br>        FORWARD链是都需要设置规则的！<br></font><p>对于情景二的情况：<br>右边的图则控制：源地址不确定，目标地址确定<br>示例3：控制允许互联网的主机访问ping,httpd：80,vsftp：21,dns：53<br>    所以规则应该如下：<br>    iptables -I FORWARD 1 -p tcp -m state –state ESTABLISHED -j ACCEPT<br>    iptables -I FORWARD 2 -d 192.168.10.0/24 -p tcp -m multiport –dports 80,53,21 -m state –state NEW -j ACCEPT<br>    iptables -I FORWARD 3 -d 192.168.10.0/24 -p udp –dport 53 -j ACCEPT<br>    iptables -I FORWARD 4 -d 192.168.10.0/24 -p icmp –icmp-type 8 -m state –state ESTABLISHED  -j ACCEPT<br>    iptables -I FORWARD 5 -d 192.168.10.0/24 -m state –state RELATED -j ACCEPT<br>    iptables -I 6 FORWARD -j REJECT</p><h3 id="NAT："><a href="#NAT：" class="headerlink" title="NAT："></a>NAT：</h3><font size="3" color="#FF0000"><br>    当然NAT规则还是建立在FORWARD的基础上做地址转换，不能转发做NAT也没意义，所以放行和控制限制还是需要在FORWARD链上去做的<br></font><pre><code>NAT: network address translation，地址转换NAT技术的产生核心原因：隐藏本不需要公开的主机    1.请求报文的源地址地址转换是人为在NAT上加规则实现的    2.响应报文中的目标地址转换，是基于连接追踪功能实现的，不需要人为干预比如内网的机器要访问互联网，就必然留下IP地址或者端口信息，则有些攻击木马通过真正的    地址来扫描这些内网机器，如果有漏洞，则可能就会被攻击，所以NAT的技术的出现，就    会隐藏我们内网机器访问互联网时的真正IP地址和端口。实现隐藏的原理：    1.将数据报文中的源地址IP，修改为具有很强防护能力的IP地址，比如网关等,这样的话，互联网上的主机看到的源地址就会是网关的地址，即使被攻击也是攻击网关，而网关一般是具有很高的防护能力的，所以就达到了隐藏源地址的目的.    2.一般来说请求报文经过防火墙时，会拆掉以太网帧首部，看到目标地址不是自己时，会转发出去，但是对于NAT的情况，防火墙会修改数据报文的IP首部的源地址或者目标地址，然后重新封装数据报文，再到达目标主机，这样就会达到保护源主机和目标主机被攻击的风险，在这个过程中，请求报文由手动修改的，响应报文是由NAT连接追踪功能实现的。NAT的方式：SNAT,DNAT,FullNAT,PortNATNAT规则可加的链：    支持PREROUTING INPUT OUTPUT POSTROUTING,但是一般只在PREROUTING和    POSTROUTING上做NAT规则，INPUT和OUTPUT只有在特殊情况下才做NAT。</code></pre><p>那么在netfilter上是如何实现的？<br>    SNAT的实现<br>        数据报文经过防火墙时，如上图示，只有当数据报文进入防火墙时，才知道目标地址不是<br>        自己，还是需要转发，所以不适合在PREROUTING链上做地址转发，如果目标地址不是当前<br>        主机，就要经由FORWARD链进行转发，而FORWARD链本身确不支持地址转换功能，所以只<br>        有在离开本机再一次进行路由选择，路由完之后才扔给网卡发送队列中，所以只能在POSTROUTING链上加地址转换规则<br>    DNAT的实现</p><h3 id="SNAT：POSTROUTING源地址转换"><a href="#SNAT：POSTROUTING源地址转换" class="headerlink" title="SNAT：POSTROUTING源地址转换"></a>SNAT：POSTROUTING源地址转换</h3><p><img src="/2018/10/10/iptables之FORWARD和NAT/" alt="SNAT原理"></p><pre><code>原理：    请求报文发生了源地址修改：人为介入修改    响应报文经过防火墙的NAT规则时，同连接追踪机制自动修改目标地址    所以源地址转换适合隐藏服务端作用：    1.隐藏内网主机的IP地址，防止被攻击    2.SNAT可以解决IPV4端口不够用的问题：        IPV4的地址短缺的问题使得SNAT技术更加流行，因为私网地址使用一个公网地址，        所以通过SNAT地址转换，报文通过公网IP出去的时候，都会把源地址(私网地址)转        换成公网地址，才能与公网通信，响应报文回来的时候是发给公网IP的，则通过连接        追踪功能返回给原来的私网地址。SNAT实验：    192.168.34.0/24网段SNAT到192.168.10.11上，且只限制80和ping操作能进行    规则如下：    NAT的POSTROUTING链规则：        iptables -t nat -I POSTROUTING 1 -s 192.168.34.0/24 ! -d 192.168.34.0/24 -j SNAT --to-source 192.168.10.11    注意：这里的source是一个固定的地址，如果这个地址是变动的呢？        那么可能下次这条规则就不生效了！--&gt;    控制和放行还是需要在FORWARD链上做规则的        iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT        iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT        iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET        iptables -I  FORWARD 4 -j REJECT如上图：通过在192.168.10.10上抓icmp包和http日志也可以看出，确实是做了SNAT地址转换的    [root@node7-3 data]#tcpdump -i ens33 -nn icmp    14:56:14.315375 IP 192.168.10.11 &gt; 192.168.10.10: ICMP echo request, id 1373, seq 1, length 64    14:56:14.315473 IP 192.168.10.10 &gt; 192.168.10.11: ICMP echo reply, id 1373, seq 1, length 64    [root@node7-3 data]#tail /var/log/httpd/access_log     192.168.10.11 - - [29/Dec/2018:15:20:45 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot;</code></pre><h3 id="DNAT：PREROUTING和OUTPUT目标地址转换"><a href="#DNAT：PREROUTING和OUTPUT目标地址转换" class="headerlink" title="DNAT：PREROUTING和OUTPUT目标地址转换"></a>DNAT：PREROUTING和OUTPUT目标地址转换</h3><p><img src="/2018/10/10/iptables之FORWARD和NAT/" alt="DNAT原理"></p><pre><code>原理:    请求报文的目标地址需要修改成真正的IP地址    响应报文经过防火墙的NAT规则，通过连接追踪机制，自动修改目标地址作用：    1.隐藏提供服务的服务器的真实IP地址，防止被服务被劫持，如DNS劫持，http服务等    2.DNAT也通过PortNAT方式可以解决IPV4地址不够用的问题DNAT实验：    访问192.168.10.10的http服务时，只需要访问防火墙NAT服务器的地址即可    即把192.168.10.10DNAT到192.168.34.103上，这里只做简单的DNAT不做portnat    规则如下：    NAT的POSTROUTING链规则：        ptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10    控制和放行还是需要在FORWARD链上做规则的        iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT        iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT        iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET        iptables -I  FORWARD 4 -j REJECT验证：在192.168.34.107上获取192.168.10.10的页面信息：curl 192.168.10.10    因为DNAT是隐藏192.168.10.10的真实地址的，在互联网上只会暴露防火墙的192.168.34.103地址是提供http服务的，真正的地址得以保护，所以这里curl 192.168.34.103即可    [root@node7-2 data]#curl 192.168.34.103    haha    192.168.10.10    而在192.168.10.10查看http日志    [root@node7-3 data]#tail /var/log/httpd/access_log     192.168.34.107 - - [29/Dec/2018:17:24:20 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot;    192.168.34.107 - - [29/Dec/2018:17:26:42 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot;从实验也可以看出DNAT的规则生效了，达到了隐藏真正提供服务的192.168.10.10地址    从而保证了服务器被攻击的风险</code></pre><h3 id="PortNAT-端口映射"><a href="#PortNAT-端口映射" class="headerlink" title="PortNAT:端口映射"></a>PortNAT:端口映射</h3><p><img src="/2018/10/10/iptables之FORWARD和NAT/" alt="PortNAT原理"><br>端口映射在docker容器中的实现方式更加方便，直接加-p选项即可,而且源端口和目标端口可以指定</p><pre><code>进程与进程的通信，实际上就是端口号之间的通信1.对于SNAT来说，因为访问是互联网的随机端口，所以都转换即可2.而对于DNAT的情况来说：    a.很多情况下，并不是说只要访问防火墙F的地址，都通过DNAT转换成主机A的IPA，    而是当访问主机A的某个服务特定端口时，才进行地址转换    b.而访问F的端口和要转换的IPA的端口不一定需要一样        即IPF：port1--&gt;IPA:port2，port1和port2可以不一样3.DNAT也可以解决IPV4地址不够用的情况：如下图那么就可以说地址转换可以发生在网络层，而且借助端口映射也可以发生在传输层首部(端口)DNAT端口映射实验：如上图访问192.168.10.10：8080的http服务时，只需要访问防火墙NAT服务器的地址即可    即把192.168.10.10:8080DNAT到192.168.34.103:80上,在上面的DAT基础上做修改即可    规则如下：    NAT的POSTROUTING链规则：        ptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10:8080    控制和放行还是需要在FORWARD链上做规则的        iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT        iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT        iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET        iptables -I  FORWARD 4 -j REJECT验证：curl 192.168.34.103:80查看是否能获取到192.168.10.10：8080的页面    [root@node7-2 data]#curl 192.168.34.103    haha    192.168.10.10    [root@node7-2 data]#curl 192.168.10.10:8080    haha    192.168.10.10    [root@node7-3 data]#tail /var/log/httpd/access_log     192.168.34.107 - - [29/Dec/2018:17:27:01 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot;从实验也可以看出DNAT的端口映射规则生效了，映射的端口不一样也可以访问到页面</code></pre><font size="3" color="#FF0000"><br>    1.这里只模拟同一台服务器上的一个服务的DNAT端口映射情景<br>    2.对于同一台服务上的多个服务DNAT端口映射也是同样道理，加上对应的PORTNAT规则即可<br>    3.对于多台服务器上的多个服务DNAT端口映射同样是这样的，只需要在NAT服务器上添加多个地址，然后将对应地址进行多台服务器的服务映射即可<br></font><h3 id="FullNAT：源地址和目标地址都修改"><a href="#FullNAT：源地址和目标地址都修改" class="headerlink" title="FullNAT：源地址和目标地址都修改"></a>FullNAT：源地址和目标地址都修改</h3><pre><code>既是网关又是NATfullnat能实现网关和主机不在同一个网段FullNAT的存在是为了弥补SNAT和DNAT模式下，主机和NAT服务器必须在同一个网段的缺点    SNAT和DNAT都受限于NAT服务器和客户端都在一个网段    1.在SNAT中，主机的网关都是需要指向NAT服务器的，不然如果在主机和防火墙之间存在路由器的话，那么出去的请求报文就不一定经由NAT服务器了，也就达不到地址转换的目的    2.在DNAT中，如果提供服务器的主机和防火墙NAT服务器之间有路由器，那么响应的报文    也不一定经由NAT服务器，也达不到转换目标地址的目的。    3.所以FullNAT的存在就弥补了SNAT和DNAT的缺点FullNAT的地址转换原理：    如下图示FullNAT实验：    FullNAT的实验原理和SNAT,DNAT,PORTNAT实验方式一样，这里就不做演示了</code></pre><p><img src="/2018/10/10/iptables之FORWARD和NAT/" alt="FullNAT原理"></p><h3 id="MASQUERADE"><a href="#MASQUERADE" class="headerlink" title="MASQUERADE"></a>MASQUERADE</h3><pre><code>只能作用在POSTROUTING链上，对SNAT的缺点弥补外网地址是动态的就用MASQUERADE,如果是静态的就用SNAT；因为MASQUERADE会消耗更多的系统资源，能用SNAT就用SNAT，特殊场景才使用MASQUERADE</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;iptables/netfilter网络防火墙：&lt;br&gt;        在FORWARD链上定义规则，注意以下几个问题：&lt;br&gt;            (1) 请求-响应均经由FORWARD链，要注意规则的方向性；&lt;br&gt;            (2) 如果可以启用conntrack机制，建议将双方向的状态为ESTABLISHED的报文直接放行；&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="iptables" scheme="https://www.liukui.tech/categories/iptables/"/>
    
    
      <category term="iptables防火墙" scheme="https://www.liukui.tech/tags/iptables%E9%98%B2%E7%81%AB%E5%A2%99/"/>
    
  </entry>
  
  <entry>
    <title>iptables</title>
    <link href="https://www.liukui.tech/2018/10/06/iptables/"/>
    <id>https://www.liukui.tech/2018/10/06/iptables/</id>
    <published>2018-10-06T00:00:00.000Z</published>
    <updated>2019-01-07T11:23:00.404Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2018/10/06/iptables/doubi.jpg" alt=""></p><p>iptables的处理逻辑和命令</p><ul><li><p>对于防火墙而言，原理和设置规则尤其重要，了解原理意味着清楚防火墙是如何在数据报文的必经之路上进行规则限制即iptables的处理逻辑；</p></li><li><p>规则意味着iptables是如何通过命令和各种选项进行规则编写的</p></li></ul><p>对于防火墙而言，原理和设置规则尤其重要，原理意味着怎么对数据报文的走向进行规则限制，规则</p><a id="more"></a><h3 id="Linux防火墙"><a href="#Linux防火墙" class="headerlink" title="Linux防火墙"></a>Linux防火墙</h3><p>防火墙的概念<br>iptables的基本认识<br>iptables的组成:iptables的处理逻辑<br>iptables的基本语法<br>iptables之forward的概念<br>iptables之地址转换法则<br>SNAT源地址转换的具体实现<br>DNAT目标地址转换的具体实现</p><p>不理解的地方：5个表的优先级和规则的优先级<br>什么是显示扩展和隐式扩展</p><p>iptables的处理逻辑和命令</p><ul><li><p>对于防火墙而言，原理和设置规则尤其重要，了解原理意味着清楚防火墙是如何在数据报文的必经之路上进行规则限制即iptables的处理逻辑；</p></li><li><p>规则意味着iptables是如何通过命令和各种选项进行规则编写的</p></li></ul><h3 id="安全技术："><a href="#安全技术：" class="headerlink" title="安全技术："></a>安全技术：</h3><pre><code>防火墙：    防范非授权网络访问；隔离功能，工作在网络或主机边缘，对进出网络或主机的数据包基    于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一组功能的组件，    基本上的实现都是默认情况下关闭所有的通过型访问，只开放允许访问的策略入侵检测机制和管理系统：    当病毒或者网络攻击绕过防火墙进入系统后的入侵检测机制，告知管理员采取手段提供有针对性的指导措施和安全决策依据。杀毒软件：病毒入侵后的防御软件入侵防御系统：    入侵检测系统检测到网络攻击或者病毒时，通过入侵防御系统进行准确的分析判断，    在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般采用在线部署方式</code></pre><h3 id="防火墙作用："><a href="#防火墙作用：" class="headerlink" title="防火墙作用："></a>防火墙作用：</h3><pre><code>作用：数据报文发到服务器的以太网卡的二种访问行为1.linux中，数据报文从服务器的以太网卡经过内核空间走一遭，不与用户空间交互，再从网卡出去，穿墙而过2.或者数据报文达到网卡，到达内核空间，进而与本地用户空间的进程进行通讯，大多数网络通讯发生的目标所在，如httpd的访问，vsftp通讯，ssh通讯究竟数据报文会以哪种方式怎么选择，会根据主机内部的路由表来选择，内核从网卡拿到请求报文，对linux而言tcp/ip协议栈是在内核中意味着报文的处理是在内核中处理的，也就是说防火墙必须工作在内核中，防火墙必须在内核中完成tcp/ip报文所流进的位置，用规则取检查，才能真正工作起来；根据内核的网络协议栈处理逻辑，会先拆除IP层的封装，获取到目标IP，如果是则拆除ip地址的首部封装，获取传输层封装(传输层的tcp的源端口，目标端口，几个标记位等信息；)这里所说端口是指进程地址，防火墙通常是在这个地方做限制的，只有通过防火墙设置的规则，才能进而与用户空间的应用程序进行数据报文的传输.</code></pre><p>这里就要说到网络间的主机通信过程了：<br>如：主机A–&gt;R1路由—&gt;R2路由—&gt;R3路由–&gt;主机B的过程：<br>怎么知道报文是从哪到哪的？<br>在整个网络中，主机A发往主机B的数据报文是一般是经过很多路由转发才到达主机B的<br>而主机A上只会标记出报文的源IP:sipA，目标IP：dipB<br>因为要经过很多路由，所以主机A到达下一个路由设备的时候会在报文的最外层加一层以太网帧首部<br>标记出源MAC(主机A)和目标MAC(R1路由Mac)，将数据报文送到R1，R1会拆除外层的以太网帧头部<br>信息，R1看到目标IP不是自己，则会选择将数据报文继续转发R2，此时数据报文则又被封装源MAC(R1的MAC)和目标MAC(R2的MAC),到达R2，R2则继续拆封以太网帧头部，发现目标IP不是自己，则继续封装以太网帧首部转发出去，最终到达主机B，主机B拆封以太网帧首部，看到目标IP是自己，则继续拆分传输层TCP首部，应用层等进行数据的交换<br>这就是为什么数据报文会从主机A成功发送到主机B上去，在数据报文传输的过程中，IP首部的信息不会变，而MAC层首部会连续换很多次！</p><p>真正通信的不是主机而是主机内的进程，数据报文中还会标识出是从主机A的哪个地址，发往主机B<br>的哪个地址，这里的地址就是端口，而端口(2^16-1=65535,0是)则是动态分配的，<br>当原主机上的端口在进行通信的时候，会临时向内核申请端口：叫端口注册，这个端口叫源端口，<br>而目标端口则是如httpd80;ssh22端口，这些服务的端口是固定的，必须有一端的端口是固定的，<br>否则无法进行通讯，当主机B真正收到数据报文时，拆分IP首部后，则会看到传输层信息，看到端口<br>信息，主机B根据那个服务在内核注册的端口信息，将数据报文交给注册端口的这个服务，即交给用户空间的这个服务对应的进程，比如http继续看到httpd的首部，这个过程是在不是在内核空间处理<br>的，而是在用户空间的进程上处理的</p><p>所以这里就会发现在linux内，tcp的五层模型的前四层物理层 数据链路层 网络层 传输层这些<br>都是内核空间处理的，叫传输子网，因为都是在内核中完成的，使用的都是是公共资源模块，为了避免程序员造轮子，把公共资源模块做成了库*.so文件<br>只有应用层是在用户空间处理的，由客户端的浏览器等封装的，叫资源子网的组成部分</p><p>而数据报文达到内核中拆分IP头信息后看到目标IP不是自己，因为主机一般不会作为路由器来使用的，所以数据报文则会被丢弃，但是主机都有核心转发功能，如果核心转发功能是开启的forward,<br>则会查本机的路由表，将数据报文转发能到达目标主机的下一个设备，则数据报文在本机的内核中<br>绕一圈被转发出去</p><h3 id="主机防火墙和网络防火墙"><a href="#主机防火墙和网络防火墙" class="headerlink" title="主机防火墙和网络防火墙"></a>主机防火墙和网络防火墙</h3><pre><code>所以防火墙的防火功能则是数据报文的必经之路上放上所谓的墙，其实就是iptables很多规则，只有墙上事先设置的白名单规则，数据报文才允许经过，其他的报文则都被丢弃。前面说的是单台主机上的防火墙：主机防火墙然而在一个大的局域网内，通常会有一个大的网络防火墙，因为局域网内的数据报文都是经由网络防火墙的,负责整个网络的防护机制</code></pre><h3 id="硬件防火墙和软件防火墙"><a href="#硬件防火墙和软件防火墙" class="headerlink" title="硬件防火墙和软件防火墙"></a>硬件防火墙和软件防火墙</h3><pre><code>硬件防火墙：实现逻辑：专业的硬件级防护设备 非通用CPU    一般电脑上的CPU可以处理很多软件，而    使用的专业CPU，只负责管理防火这类的功能    通用CPU：可以完成诸多的功能软件防火墙：    通过特殊的防火软件来实现而单纯的硬件防火墙一般是达不到防火目的的，纯软件却可以达到防火目的，一般都是软硬件一起来实现防火目的的</code></pre><p>网络防火墙:检测TCP协议的下4层的协议报文(传输层极其以下的层数)<br>应用层防火墙：只是适用于某种服务和协议</p><h3 id="linux上的防火墙实现"><a href="#linux上的防火墙实现" class="headerlink" title="linux上的防火墙实现"></a>linux上的防火墙实现</h3><pre><code>linux的防火墙是模仿OpenBSD实现的防火墙    1.传软件实现    2.内核级实现的，只负责TCP协议的下4层的协议报文(传输层极其以下的层数)中工作和防护    也就是在前文所说的传输子网上进行工作和防护的</code></pre><p>内核级的防火机制：<br>在数据报文经过的路径上仔细选择5个钩子：hook，因为是必经之地，所以每个通过的报文都会<br>被hook勾住，然而这里只设置了hook，而没有设置规则，这些规则是由主机的管理员来设置的<br>只有满足设置的规则的数据报文才允许通过<br>当然这个hook不单单是防火功能，有时把经过的数据报文勾起来，修改它的目标地址源地址<br>信息，这个功能叫地址转换，NAT<br>所以对linux而言，防火墙的功能不单单是防火这一个功能，还包括地址转换，报文修改和<br>连接追踪的关闭等几项功能</p><h3 id="Netfilter框架的组成和负责的功能"><a href="#Netfilter框架的组成和负责的功能" class="headerlink" title="Netfilter框架的组成和负责的功能"></a>Netfilter框架的组成和负责的功能</h3><p>Netfilter只是内核级的framework<br>通过系统调用实现：syscall:iptables<br>由5个钩子基本实现了linux的防火墙<br>而这5个hook统称netfilter,只是内核中的一个框架framework，hook只是勾住数据报文，规则<br>则由用户管理员添加，只需要在5个hook的位置上添加相应规则即可</p><p>前3个hook是防火功能<br>    input+output+forward<br>        访问本机内部的应用<br>后2个hook:是实现地址转换，报文修改和连接追踪的关闭<br>    prerouting:在进入本机网卡接收队列前的瞬间：路由前<br>    postrouting:由本机发出或者forward转发的离开本机网卡接收队列的瞬间：路由后<br>    而prerouting是不能做过滤的</p><p>三种报文流向：<br>流入的报文：<br>    prerouting–&gt;路由–&gt;input–&gt;进入用户空间进程<br>流出的报文：这里说的流出报文是指由本机主动发出的请求报文<br>    用户空间进程 –&gt;output–&gt;postrouting<br>转发的报文：<br>    prerouting–&gt;forward–&gt;postrouting</p><p>而数据报文是有来有往的，有请求报文就应该有响应报文，所以整个通信的过程报文流向应该是<br>    先流入报文：请求报文<br>        prerouting–&gt;路由–&gt;input–&gt;进入用户空间进程<br>    再出去：响应报文<br>        用户空间进程 –&gt;output–&gt;postrouting<br>转发报文：请求<br>    prerouting–&gt;forward–&gt;postrouting<br>转发报文的：响应<br>    也是prerouting–&gt;forward–&gt;postrouting<br>这里要搞清楚，因为客户端和服务端是相对的，进来的都是prerouting出去的都是postrouting</p><p>而请求和响应的数据报文，因为方向不同，数据报文内封装的源IP+端口和目标IP+端口是相反的<br>客户端和服务端则是相对的，转发报文也是类似的，也是有来有往的<br>而为了服务器资源来说，如果要阻止报文，控制的是请求报文而非响应报文</p><h3 id="什么是iptables？"><a href="#什么是iptables？" class="headerlink" title="什么是iptables？"></a>什么是iptables？</h3><h3 id="实现规则的工具iptables和firewalld"><a href="#实现规则的工具iptables和firewalld" class="headerlink" title="实现规则的工具iptables和firewalld"></a>实现规则的工具iptables和firewalld</h3><p>因为Netfilter只是框架，规则由用户来设置，而Netfilter是内核中的，用户是无法直接与内核<br>进行交流的，所以linux创建了一个在用户空间的工具iptables,iptables是一个规则编辑器，<br>能调用内核级的Netfilter的系统调用接口，把写的规则送到内核上的hook上，并立即生效，而<br>内核的数据是保存在内存中的，关机则会丢失定义好的规则，要想规则永久生效，就需要保存在<br>系统reboot时自动加载的文件中，或者由启动的软件间接调用这个规则文件(iptables-server).</p><p>而ipfirewall–&gt;ipchains–&gt;iptables–&gt;nfstables</p><p>iptables是工作在网络层，可以通过隐式扩展工作在传输层，通过显示扩展的string工作在应用层<br>但是不能识别应用层http协议，ftp协议的请求方法，可以识别报文中的字串</p><h3 id="iptables的组成"><a href="#iptables的组成" class="headerlink" title="iptables的组成"></a>iptables的组成</h3><p>iptables由五个表和五个链以及一些规则组成</p><pre><code>五个表table：filter、nat、mangle、raw、securityfilter表：过滤规则表，根据预定义的规则过滤符合条件的数据包nat表：network address translation 地址转换规则表mangle：修改数据标记位规则表raw：关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度security：用于强制访问控制（MAC）网络规则，由Linux安全模块（如SELinux）实现优先级由高到低的顺序为:security --&gt;raw--&gt;mangle--&gt;nat--&gt;filter</code></pre><p>如果把规则放在input和output上称为主机防火墙，只防护当前主机内部的进程是如何访问的</p><h3 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h3><p>netfilter内核级的框架，内核framework，过滤器<br>syacall：iptables工具，管理规则：</p><p>centos7上：默认安装firewall<br>    系统内自带的前端工具firewall;默认启用，建议关闭或卸载即可<br>        firewalld:系统守护进程，firewall-cmd<br>    在真正的防火墙管理时，建议用iptables来管理的<br>        iptables：<br>    保存iptabels规则的命令包<br>        iptables-services 需要自己手动安装<br>        用iptables-save restore管理加载事先设定好的防火墙规则即可</p><h3 id="Netfilter表和链对应关系"><a href="#Netfilter表和链对应关系" class="headerlink" title="Netfilter表和链对应关系"></a>Netfilter表和链对应关系</h3><p><img src="/2018/10/06/iptables/" alt="Netfilter表的优先次序"></p><p>报文流向：</p><pre><code>* 流入报文路径：到本机内部* 流出报文路径：由本机发出* 转发报文路径：转发</code></pre><p>tables <--> chains链:在通过iptables引用是是需要大写的</--></p><pre><code>* filter: INPUT,FORWARD,OUTPUT只有3个链* nat: PREROUTING,INPUT,OUTPUT,POSTROUTING 4个链* mangle: PREROUTING,INPUT,FORWARD,OUTPUT,POSTROUTING* raw: PREROUTING,OUTPUT</code></pre><p>就算filter和nat上都在同一个input链上，因为不属于一个table的，规则是各自生效的<br>那么input上同时有filter和nat表的规则时，则是有优先级的</p><p>为了实验，要先关闭firewalld设置开机不启动<br>systemctl stop firewalld<br>systemctl disabled firewalld<br>systemctl is-enabled firewalld</p><p>规则顺序很重要<br>因为有些规则具有一票否则权比如drop，一旦报文匹配到drop规则，后面的规则都不看<br>因为有些规则具有一票否则权比如accept，一旦报文匹配到drop规则，即使后面有drop也无效<br>从这两条来说<br>把检查条件苛刻的规则放前面<br>规则调用的模块化管理：自定义链，由主链取调用才会生效，删除或更改时方便管理</p><h3 id="iptables的命令使用格式"><a href="#iptables的命令使用格式" class="headerlink" title="iptables的命令使用格式"></a>iptables的命令使用格式</h3><p>获取帮助：<br>                    CentOS 7：man iptables-extensions<br>                    CentOS 6：man iptables</p><p>规则的编写格式：<br>iptables [-t table] COMMAND chain [rulesnum][-m matchname [per-match-options]] [-j targetname [per-target-options]]<br>表–&gt;命令–&gt;chain–&gt;对链</p><pre><code>-t table：    默认为filter；其它可用的有raw, mangle, nat；子命令COMMAND:        管理链：            -P：policy，策略，定义链的默认策略； 一般有两种选择，ACCEPT和DROP；            -N：new，新建一条自定义的规则链；被内建链上的规则调用才能生效；[-j  chain_name]；            -X：drop，删除自定义的、空的、或者引用计数为0的空链；            -F：flush，清空指定的链；            -E：重命名引用计数和为0的自定义链；            -F：flush, 清空整条链            -Z：zero，计数器置零；改为零                 iptables的每条规则和每个链都有专用的两个计数器：                 每一个规则所匹配到的报文数量个数：pkts                 和体积计数器之和：bytes        管理规则：增删改、插入            -A：append，追加，在指定链的尾部追加一条规则；            -I：insert，插入，在指定的位置（省略位置时表示链首）插入一条规则；            -D：delelte，删除，删除指定的规则；            -R：replace，替换，将指定的规则替换为新规则；不能仅修改规则中的部分，而是整条规则完全替换；        查看：链上查看规则的动作，属于action的一种            -L：list，列出表中的链上的规则；                -n：numeric，以数值格式显示；                -v：verbose，显示详细格式信息；                     -vv, -vvv                -x：exactly，计数器的精确结果；                --line-numbers：显示链中的规则行号；        重置规则计数器：            -Z：zero，置0；        计数器：            规则，以及默认策略有专用的计数器；            记录被当前规则所匹配到的：                (1) 报文个数；                (2) 字节总数；chain：    (1) 内建链；INPUT OUTPUT FORWARD PREROUTING POSTROUTING    (2) 自定义链；匹配条件：matchname    多重条件：逻辑关系为“与”；    检查报文：        TCP或UDP首部：源端口、目标端口、标记为ACK           FSM: 有限状态机:TIME_WAIT,监听状态等        IP首部: SIP，DIP        MAC首部：MAC地址 将防火墙规则保存下来    iptables-save &gt; /tmp/iptables-rules.v0.1    iptables-restore &lt; /tmp/iptables-rules.v0.1开机自动加载iptables规则    yum install iptables-services -y    规则的保存和永久生效：    将iptables保存在文件    iptables-save    iptables-restore     iptables-server的service脚本    保存在/etc/sysconfig/iptables中，开启启动自动加载    firewalld,firewalld-cmd是不能调用iptables定义的规则，用iptables-server    必须先安装，不能并行    匹配条件又分为：通用匹配和扩展匹配    通用匹配条件：        5种检查方式：源 目标 协议 流入 流出         [!] -s, --sip,--source-ip报文源地址            其值可以是单个IP，或者连续IP，可以是网络地址，不能是离散的地址        [!] -d, --destination address[/mask][,...]：检查报文中的目标IP地址是否符合此处指定的地址或范围；        [!] -i, --in-interface name：数据报文从哪个网卡接口进入；            PREROUTING，INPUT, FORWARD            因为-i是数据报文流入的选项；            所以-i选项只能上面这三个链有关,用在前半部分相关的链上        [!] -o, --out-interface name：数据报文从哪个网卡接口出去；             FORWARD, OUTPUT POSTROUTING            同理因为-o是数据报文流出的选项；            所以-o选项只能上面这三个链有关,用在后半部分相关的链上        [!] -p, --protocol protocol：四层协议                tcp|udp|icmp|sctp    这也是为什么iptables叫网络防火墙的原因，正常的工作只能工作在网络层，    检查网络层属性，但是-i -o和网络层属性没关系，和网络层下面的协议有关    正常情况下，网络防火墙是用来检查网络层首部来获得相关信息的    扩展匹配条件：又分为隐式扩展和显示扩展        /lib/modules/$(uname -r)/net/netfilter/下xt开头的就是扩展模块            默认没有载入到内核中，只有当用时才加载的，就叫隐式扩展        netfilter为了做深入的条件检查，通过特定的模块来实现检查功能        隐式扩展：不用-m选项指出matchname即可使用此match的专用选项进行匹配；            -p tcp：隐含了-m tcp；                [!] --source-port,--sport port[:port]                    匹配报文中传输层的源端口；                    可以使用单个端口或者连续端口，但是不能使用离散端口                [!] --destination-port,--dport port[:port]、                    匹配报文中传输层的目标端口；                    可以使用单个端口或者连续端口，但是不能使用离散端口                    端口也只有2^16-1=65535个端口                [!] --tcp-flags mask comp                    SYN，ACK，FIN，RST，URG，PSH；                        mask：要检查的标志位列表，以逗号分隔；                    comp：必须为1的标志位列表，余下的出现在mask列表中的标志位则必须为0；                                            --tcp-flags  SYN,ACK,FIN,RST SYN                        如果只定义SYN则代表tcp握手的第一次，一般只检查第一次                        如果定义的是SYN，ACK代表tcp握手的第二次                        如果是ACK，则代表tcp的正常通信过程                [!] --syn：因为检查tcp握手的第一次比较常用                    所以系统内就设置这个选项代表下面这个选项                    相当于--tcp-flags  SYN,ACK,FIN,RST  SYN             -p udp：隐含了-m udp：                [!] --source-port,--sport port[:port]：匹配报文中传输层的源端口；                [!] --destination-port,--dport port[:port]：匹配报文中传输层的目标端口；            -p icmp：隐含了-m icmp:互联控制消息协议                 [!] --icmp-type {type[/code]|typename}                    icmp是有状态的                    8：echo-request                    0：echo-reply        显式扩展：必须使用-m选项指出matchname，有的match可能存在专用的选项；                显示扩展能帮我们更灵活的设置控制规则            获取帮助：                CentOS 7：man iptables-extensions                CentOS 6：man iptables            1、multiport扩展                以离散或连续的方式定义多端口匹配条件；                离散最多为15个，以冒号隔开的算一个，所以连续的端口用冒号隔开                 [!] --source-ports,--sports port[,port|,port:port]...：指定多个源端口；                 [!] --destination-ports,--dports port[,port|,port:port]...：指定多个目标端口；                 [!] --ports port[,port|,port:port]...：指定多个端口；            2、iprange扩展：连续的地址集                以连续的ip地址范围指明连续的多地址匹配条件；                [!] --src-range from[-to]：源IP地址；                [!] --dst-range from[-to]：目标IP地址；            3、set扩展：定义离散地址集                如果要开放的地址既不是连续的，也不是网络地址就需要使用set了                set依赖于ipset命令行工具；需要用ipset先定义一个地址集，                再用set调用地址集即可；需要先安装ipset安装包                yum install ipset ，重启iptables服务                set存在类型，常用的有两个：                    hash:net 网络地址的集合：两个网段剧哦多个网段                    hash:ip  IP地址的集合：离散地址集                使用方式：                    先创建集合：ipset create NAME TYPE( hash:ip/hash:net)                    向集合添加元素：ipset add NAME ELEMENT                set再调用                    --match-set  NAME src                    --match-set  NAME dst            4、string扩展：字串匹配，                借助string扩展，iptables把触角伸到了应用层                对报文中的应用层数据做字符串匹配检测；                [!] --string pattern：要检测字符串模式；                [!] --hex-string pattern：要检测的字符串模式，16进制编码；                --algo {bm|kmp} 2组比较算法            5、time扩展                根据报文到达的时间与指定的时间范围进行匹配度检测；                --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：起始日期时间；                --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：结束日期时间；                --timestart hh:mm[:ss]                --timestop  hh:mm[:ss]                [!] --monthdays day[,day...]                [!] --weekdays day[,day...]                --kerneltz：使用内核中配置的时区                ~]# iptables -I INPUT -d 172.16.100.67 -p tcp --dport 23 -m time --timestart 09:00:00 --timestop 18:00:00 --weekdays Tue,Thu,Sat -j ACCEPT            6、connlimit扩展                根据每客户端IP做并发连接数匹配；                --connlimit-upto n：连接数数量小于等于n，此时应该允许；                --connlimit-above n：连接数数量大于n，此时应该拒绝；                ~]# iptables -A INPUT -d 172.16.100.67 -p tcp --dport 23 -m connlimit --connlimit-upto 2 -j ACCEPT            7、limit扩展                基于收发报文的速率进行匹配；                --limit rate[/second|/minute|/hour|/day]：平均速率                --limit-burst number：峰值速率            8、state扩展                状态检测；连接追踪机制（conntrack）；                 INVALID：无法识别的状态；                  ESTABLISHED：已建立的连接；                 NEW：新连接；                  RELATED：相关联的连接；                 UNTRACKED：未追踪的连接；                nf_conntrack内核模块；记忆是由内核空间的conntrack模块实现的                    追踪到的连接：/proc/net/nf_conntrack文件中；                    能追踪的最大连接数量定义在：/proc/sys/net/nf_conntrack_max                        此值可自行定义，建议必要时调整到足够大；                    不同的协议的连接追踪的时长：                        /proc/sys/net/netfilter/                [!] --state STATE                如何开放被模式的ftp服务：                     (1) 装载追踪ftp协议的模块；                        # modprobe nf_conntrack_ftp                    (2) 放行命令连接                        ~] # iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT                        ~] # iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state NEW -j ACCEPT                    (3) 放行数据连接                        ~] iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state RELATED -j ACCEPT        处理动作（目标）            -j targetname [per-target-options]             targetname：            简单：                ACCEPT：接受；                DROP：丢弃；                    被请求的服务器数据报文丢弃了，请求端需要等待时间会消耗服务端和客户端资源            扩展：                REJECT：--reject-with:icmp-port-unreachable默认                    拒绝；适用内网，直接弹回报文请求                RETURN:当被调用的自定义链上没有规则则自动返回主链继续匹配;                REDIRECT：端口重定向                SNAT：源地址转换                DNAT：目标地址转换                MASQURADE:地址伪装                LOG：日志                自定义链：可以先定义自定义链，再通过主链调用，                当自定义链被引用时，需要先删除引用，再清空自定义链，然后再删除</code></pre><p>每个表对应控制的链，各不相同，记住对应关系<br>网络层<br>tcp协议的头部信息 2btye 2^16-1（0表示通用）<br>2个半连接*2<br>这里因为有两个半连接，请求和回应报文，<br>所以防火墙要设置input接收请求和output回应报文，<br>开启接收请求关闭回应报文，对方也是无法接收到回应报文的</p><h3 id="生产环境下如何设置防火墙？："><a href="#生产环境下如何设置防火墙？：" class="headerlink" title="生产环境下如何设置防火墙？："></a>生产环境下如何设置防火墙？：</h3><pre><code>1.因为生产环境下，被管理的主机不在本地或者在其他省份，我们是通过ssh远程连接管理的!2.防火墙规则一般是要设置白名单的，而默认策略是需要设置为DROP或者REJECT，这时，如果    不先把SSH或者VNC先设置白名单，我们就无法管理了！那就是给自己找麻烦了3.所以要先为SSH服务设置白名单，再设置默认策略为DROP或者REJECT！！！4.默认策略可以用-P设置，也可以用自定义策略；自定义策略的好处5.防火墙的检查机制,是按照顺序从上往下一个个匹配，如果最上面的一旦匹配即使下面有更    严格的条件，也会不生效，所以我们应该把检查严格的条件放到检查宽松的上面    比如：string检查规则(具体看示例)等</code></pre><h3 id="iptables的使用规范"><a href="#iptables的使用规范" class="headerlink" title="iptables的使用规范"></a>iptables的使用规范</h3><pre><code>iptables -F 即清空filter表的所有链，因为默认是filter表iptables -F INPUT，清空filter表上的INPUT链的所有规则定义防火墙要设置白名单极端清空下所有链都是drop的如果主机有多个网卡，当网关来用的时，forward链就是用来当网络防火墙来用的    规则优化：    (1) 注意规则的优先顺序，检查严格的放到前面，    (1) 可安全放行所有入站及出站，且状态为ESTABLISHED的连接；    (2) 服务于同一类功能的规则，匹配条件严格的放前面，宽松放后面；    (3) 服务于不同类功能的规则，匹配报文可能性较大扩前面，较小放后面；    (4) 设置默认策略；        (a) 最后一条规则设定；        (b) 默认策略设定；</code></pre><h5 id="隐式扩展示例："><a href="#隐式扩展示例：" class="headerlink" title="隐式扩展示例："></a>隐式扩展示例：</h5><pre><code>隐式扩展示例1：SSH服务    因为是ssh连接的，如果要设置默认策略为DROP，就一定要先开启SSH服务的请求和回应    iptables -A INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 22 -j ACCEPT    再设置默认INPUT链策略为DROP：两种写法：下文会表示自定义链的写法好处    iptables -P INPUT -j REJECT 设置默认策略是拒绝    或者用自定义写法：    iptables -t filter -A INPUT -j REJECT，定义流入的默认策略iptables -A OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 22 -j ACCEPTiptables -t filter -A OUTPUT -j REJECT(代替默认策略的写法)设置自定义白名单的好处：    必要时，所有规则都可以通过自己明确给定的规则来定义    可以写一个脚本把自定义规则写进去，执行后就可以不受控于默认策略因为管理的主机不在本地，如果再修改iptables规则时，把ssh也拒绝了，那么就有很大问题可以把规则写在一个脚本里，在任务计划里创建一个清空防火墙规则的命令即使脚本里的规则把自己拒绝了，可以等任务计划执行后，就可以登进去了，易于控制隐式扩展示例2：http服务    在会前基础上开放80端口的访问    iptables -I INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 80 -j ACCEPT    iptables -I OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 80 -j ACCEPT隐式扩展示例3：lo网卡    将127.0.0.1设置不受控    在之前的基础上ping 127.0.0.1是受控的    之前的iptables -t filter -P INPUT DROP，是将0.0.0.0到0.0.0.0都拒绝了    本地127.0.0.1也被拒绝了，所以稍微修改为非lo网卡受控，lo网卡即不受控了        iptables -R INPUT 3 ! -i lo -j REJECT        iptables -R OUTPUT 3 ! -o lo -j REJECT隐式扩展示例4：-p icmp的隐式扩展；ping请求如何设置当前主机可以ping其他主机，加在最后一条的前面    在之前的基础上此时主机主动ping其他主机也是受控的    icmp是有类型的,见下图，8 echo-request;  0 echo reply    iptables -I OUTPUT 3 -p icmp --icmp-type 8 -j ACCEPT    iptables -I INPUT 3 -p icmp --icmp-type 0 -j ACCEPT隐式扩展示例5：DNS -p udp    如何设置开放本机可以通过DNS解析域名    从本机出去，到达互联的DNS服务器，再接收回应的报文    iptables -I OUTPUT -p udp --dport 53 -j ACCEPT 出去的报文    iptables -I INPUT -p udp --sport 53 -j ACCEPT 回来的报文</code></pre><h5 id="自定义链的使用示例-N-E-X-F"><a href="#自定义链的使用示例-N-E-X-F" class="headerlink" title="自定义链的使用示例(-N -E -X -F)"></a>自定义链的使用示例(-N -E -X -F)</h5><p>以在自定义链中加入samba服务为例</p><pre><code>-N：新建一条自定义的规则链只不过在自定义链上是由计数器的iptables -N new_rules 新建自定义链iptables -E new_rules cifs_rules 改自定义链，必须要0引用的，0 references自定义规则链的创建、调用、删除；以在自定义链中加入samba服务;然后主链在调用自定义链为例    先设置入栈的规则        iptables -A cifs_rules -p tcp --dport 139 -j ACCEPT            iptables -A cifs_rules -p tcp --dport 445 -j ACCEPT        iptables -A cifs_rules -p udp --dport 137:138 -j ACCEPT        iptables -A cifs_rules -j RETURN    还要加一条RETURN规则表示，当cifs_rules规则被主链调用时，如果自定义链上的规则    没有被匹配到，则return到主链上继续匹配主链上的后续规则.在INPUT链去调用自定义链cifs_rules        iptables -I INPUT 5 -s 192.168.34.0/24 -j cifs_rules删除自定义链：需要先删除引用        iptables -D INPUT 5        iptables -F cifs_rules        iptables -X cifs_rules</code></pre><h5 id="显示扩展示例"><a href="#显示扩展示例" class="headerlink" title="显示扩展示例"></a>显示扩展示例</h5><p>必须使用-m选项指出matchname，有的match可能存在专用的选项</p><pre><code>显示扩展示例1：multiport扩展 --多端口匹配将21 22 80 139 445一起开启允许访问：iptables -I INPUT -p tcp -m multiport --dports 21:22,80,139,445 -j ACCEPTiptables -I OUTPUT -p tcp -m multiport --sports 21,22,80,139,445 -j ACCEPT显示扩展示例2： ip-range:必须是连续的范围允许ping的主机为192.168.34.100-192.168.34.106段的IP地址：iptables -I INPUT 3 -p icmp --icmp-type 8 -m iprange --src-range 192.168.34.100-192.168.34.106 -j ACCEPTiptables -I OUTPUT 3 -p icmp --icmp-type 0 -m iprange --dst-range 192.168.34.100-192.168.34.106 -j ACCEPT显示扩展示例3：set扩展    ipset先定义地址集:        ipset create allowpinghosts hash:ip  --先定义IP地址集        ipset add allowpinghosts 192.168.34.107 --向地址集添加IP地址    set再调用地址集：    iptables -I INPUT 4 -p icmp --icmp-type 8 -m set --match-set allowpinghosts src -j ACCEPT    iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m set --match-set allowpinghosts dst -j ACCEPT显示扩展示例4：string扩展：字串匹配    比如：控制httpd服务的报文带有sex字串的都拒绝进入和访问    事先构建一个带有sex字串的html文件，然后设置规则    （因为这个规则比较严格，所以记得要放到允许访问httpd规则的前面！）    iptables -I INPUT -p tcp --dport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT    iptables -I OUTPUT -p tcp --sport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT显示扩展示例5：time扩展</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2018/10/06/iptables/doubi.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;iptables的处理逻辑和命令&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;对于防火墙而言，原理和设置规则尤其重要，了解原理意味着清楚防火墙是如何在数据报文的必经之路上进行规则限制即iptables的处理逻辑；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;规则意味着iptables是如何通过命令和各种选项进行规则编写的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于防火墙而言，原理和设置规则尤其重要，原理意味着怎么对数据报文的走向进行规则限制，规则&lt;/p&gt;
    
    </summary>
    
      <category term="iptables" scheme="https://www.liukui.tech/categories/iptables/"/>
    
    
      <category term="iptables防火墙" scheme="https://www.liukui.tech/tags/iptables%E9%98%B2%E7%81%AB%E5%A2%99/"/>
    
  </entry>
  
  <entry>
    <title>k8s-volumes</title>
    <link href="https://www.liukui.tech/2018/08/10/k8s-volumes/"/>
    <id>https://www.liukui.tech/2018/08/10/k8s-volumes/</id>
    <published>2018-08-10T00:00:00.000Z</published>
    <updated>2019-02-24T06:09:09.343Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Kubernetes-Volumes"><a href="#Kubernetes-Volumes" class="headerlink" title="Kubernetes Volumes"></a>Kubernetes Volumes</h3><a id="more"></a><p><img src="/2018/08/10/k8s-volumes/k8s支持的存储卷类型.png" alt="k8s支持的存储卷类型"></p><pre><code>k8s上的volumes和docker中的volumes都是为了保存数据，但还是有区别的：    1.docker上因为是在单机上运行容器的，删除容器只要加载本地之前挂载的卷就可以了。    2.在k8s集群上，如果删除一个Pod,则这个pod的卷数据会保存在之前的这个node节点上了，而scheduler的调度是随机的，        有可能不会运行在之前的node上，那么之前保存的数据是无意义，不能利用的.    3.k8s是分布式集群，如果所有节点都挂载网络文件系统，那么数据就可以跨节点使用了.数据冗余实现方式：    1.存储设备做镜像，主备模式    2.分布式存储        不会对存储节点设备做冗余，而是在软件数据管理级别上对每个数据对象做冗余；        根据调度规则和冗余级别在当前集群的多个节点上都存放一份数据        还支持向外扩展如何挂载：    1.pod中是有个基础容器pause的,同一个pod中是共享pause容器的UTS(主机名),Network(网络名称空间),IPC(进程间通信，网络协议栈).    2.因为在节点上的pod是共享节点内核的，驱动也是在内核，所以节点本身需要先识别适配外部的各种存储系统.    3.节点是可以挂载多种外部存储系统的，所以pause挂载存储时，需要指明挂载的是哪种文件系统类型的存储并有相应的存储插件驱动.    4.同一Pod中的其他容器要想使用pause中的volumes,需要先通过volumes定义pause中定义卷，pod再通过volumeMounts复制并挂载pause定义的卷.CSI:    Container Storage interface，通过容器存储接口自定义存储卷    k8s中内置的存储卷类型        kubectl explain pod.spec.volumes定义存储卷    详见：kubectl explain pod.spec.volumes #如何定义挂载卷    要用存储卷需要现在pod.spec字段定义挂载卷类型和目录等信息挂载存储：    详见：        kubectl explain pod.spec.containers.volumeMounts #定义如何挂载卷        是使用挂载卷，需要在pod.spec.containers中挂载上去才能用spec中的详细定义说明：    spec:      volumes:          #先定义pause中的挂载卷      - name                    #必须定义存储卷名称,以便挂载时引用    下面根据存储类型不同定义方式也不同，按需修改        hostPath/nfs            #必须指定存储类型        - path                  #定义宿主机或者网络存储的路径          type                  #指定的目录/文件不存在时，应该怎么创建            DirectoryOrCreate   #不存在则创建            Directory           #目录必须事先存在            File                #文件可以挂载，但是必须事先存在            FileOrCreate        #文件不存在则自动创建            Socket              #必须是套接字文件，必须事先存在            CharDevice          #字符设备文件，必须事先存在            BlockDevice         #块设备文件，必须事先存在      containers:      - name:        image:        volumeMounts:   #复制并挂载pause中定义的卷        - name:                 #引用volumes中定义的1个或多个卷的卷名          mountPath             #挂载在容器的哪个路径(应用程序的文件路径)          readOnly：true|false  #挂载的路径是否只读，默认是读写权限          mountPropagation      #</code></pre><h3 id="本地存储：hostPath和local"><a href="#本地存储：hostPath和local" class="headerlink" title="本地存储：hostPath和local"></a>本地存储：hostPath和local</h3><pre><code>示例1：hostPath类型            #节点级的目录    vim myapp-hostpath-volumes.yaml         apiVersion: v1        kind: Pod        metadata:          name: myapp          namespace: volumes-test        spec:          containers:          - name: myapp            image: ikubernetes/myapp:v1            volumeMounts:            - name: website              mountPath: /usr/share/nginx/html              readOnly: true          volumes:          - name: website            hostPath:              path: /volumes/myapp              type: DirectoryOrCreate示例2：local类型    k8s1.10版本之后的类型，且是节点级的设备或者节点级目录</code></pre><h3 id="临时存储：emptyDir"><a href="#临时存储：emptyDir" class="headerlink" title="临时存储：emptyDir"></a>临时存储：emptyDir</h3><pre><code>临时存储作用：    1.为容器提供缓存存储空间        1.支持在节点的内存中切分一部分空间作为缓存来用    2.为没有持久存储必要的同一Pod中的两个容器共享数据    3.临时存储随着Pod的删除自动删除用法：    kubectl explain pod.spec.volumes.emptyDir        medium      #默认是disk磁盘，还可以是Memory内存        sizeLimit   #当medium是memory时，则必须进行限制简单示例：    volumes:    - name: ceshi#      emptyDir: {}  #如果medium和sizelimit都不定义，则为磁盘的任意空间      emptyDir:        medium: Memeory  #使用内存当空间        sizeLimit: 200Mi #使用内存空间为200M</code></pre><h3 id="网络存储：NFS"><a href="#网络存储：NFS" class="headerlink" title="网络存储：NFS"></a>网络存储：NFS</h3><pre><code>用法：    kubectl explain pods.spec.volumes.nfs        path：                #nfs的共享目录：如/vols/v1        readOnly：true|false  #是否只读，默认读写        server:               #nfs服务IP或者主机名缺点：    1.需要事先知道nfs服务器的地址    2.nfs导出的存储空间目录示例：    先准备nfs的共享目录:在10.10.0.29上测试    vim /etc/exports        /vols/v1 10.10.0.0/8(rw,no_root_squash)[root@master01 manifsets]# vim redis-nfs-volumes.yaml apiVersion: v1kind: Podmetadata:  name: redis  namespace: volumes-testspec:  nodeName: node03  containers:  - name: redis    image: redis:alpine    ports:    - name: redis      containerPort: 6379    volumeMounts:    - name: redisdata      mountPath: /data      readOnly: false  volumes:  - name: redisdata    nfs:      path: /vols/v1     #nfs导出的共享目录      server: 10.10.0.29 #nfs服务器的地址</code></pre><h3 id="持久卷申请存储：PV-amp-PVC"><a href="#持久卷申请存储：PV-amp-PVC" class="headerlink" title="持久卷申请存储：PV&amp;PVC"></a>持久卷申请存储：PV&amp;PVC</h3><pre><code>为了使用存储方便，为volumeMounts和后端存储设备加加了两个中间层在spec.volumes和存储间加了一个persistentVolume中间层把存储系统的所提供的存储能力抽象成k8s上的标准资源：persistentVolume持久存储卷persistentVolume：    1.PV和存储系统之间不是一一对应关系，而是与对应后端存储系统上可被单独访问的逻辑单元；    2.一个PV对应nfs的一个导出目录、ceph的一个image、云存储的一个云盘;    3.把后端存储的一个个逻辑单元映射为k8s上的一个个PV;    4.PV是集群级别的资源，不属于任何名称空间;PV的lifecycle:    provisioning: #PV的动态供给    bingding      #PV被绑定    using         #PV被使用    reclaiming    #PV被回收PV的供给方式：    动态供给：        1.存储系统上需要事先有逻辑存储单元，根据PVC的空间需求，在底层存储上选择适合空间需求的存储单元动态得创建为PV.        2.底层存储的逻辑单元不存在，只有存储空间            1.PVC向SC请求调用存储系统的API存储接口，临时创建需求空间大小的逻辑存储单元.            2.然后在SC内部把此存储单元创建为PV，与PVC进行binding.        3.动态供给是创建SC，而不是PV    静态供给：        存储系统上事先有存储，手动创建PV，再手动创建PVC与之绑定.PV的回收策略：reclaim    Pod删除时，PVC也可以删除，则引用的PV就处于回收状态，PV删除有二种策略        Delete:   #PVC删除时连带PV一起删除        Retain    #PV和PV上的数据都保留    备注：        1.如果是retain的，PV上仍然会有数据，但是不能被其他PVC所绑定了        2.可以手动删除PV，并手动删除存储上逻辑单元下的数据persistentVolumeClaim    1.PV属于集群级别资源，Pod属于名称空间级别资源，如果pod想使用PV就需要把PV注册到名称空间中;    2.Pod是通过PVC请求占用PV，来使用PV的，一旦名称空间A占用PV1，其他名称空间就不能再用PV1了;    3.PVC占用PV称为binding;为被PVC占用的PV称为avaiable(可用的PV);    4.Pod通过volumes.persistentVolumeClaim使用PVC，进而间接使用PVC所占用的PV的.    5.PVC是属于某个名称空间，可以由管理员手动创建的.PVC和存储系统的多路访问模型：    1.单路读写： RW0:ReadWriteOnce      iscsi    2.多路读写: RWX:ReadWriteMany    3.多路只读: ROX:ReadOnlyMany    作用：        PV是与后端存储的逻辑单元做映射的，存储系统是否支持多路读写应该体现在PV的定义上，才能避免PVC关联PV是否能多路读写出现存储故障.PV和PVC的删除保护：    当PVC和PV被Pod使用时，在k8s的1.10版本之后，即使PVC和PV被删除，此时也不会真的被删除，只有Pod被删除时，    PVC和PV才会被允许删除，这就是PVC和PV的删除保护.定义PV：    pv.spec和pod.spec.volumes是一样的，这样在创建pod时就不要再定义volumes了直接在containers.volumeMounts进行复制挂载就行了.    kubectl explain persistentVolume.spec    spec:      accessModes               #定义存储系统的访问模型的字符串列表            RW0/RWZ/ROX      capacity:                 #定义存储容量        storage   #单位是Ki Mi Gi等等      volumeMode:               #存储设备的访问接口(文件系统接口和块设备接口)            Fileystem|block      persistentVolumeReclaimPolicy  #定义PV的回收策略            Delete|Retain      storageClassName:           #定义使用哪种存储类      mountOptions:          #自定义挂载选项,下面这两项是默认的        - hard        - nfsvers=4.1      nfs/ceph:                  #定义PV关联的存储类型        下面选项根据不同存储系统定义不同的属性值        server:                   path:        定义PVC：    kubectl explain pvc.spec        accessModes          #访问权限必须要要绑定的PV权限的子集        volumeMode           #存储设备的访问接口(文件系统接口和块设备接口)        resources            #资源请求            requests:               #资源需求                storage:   #具体的需求存储空间大小            limit                  #资源上限        storageClassName     #存储类(PVC和PV必须在同一存储类中)        selector             #通过标签选择器去选PV                不定义选择器，则从所有PV中选择合适的PV        volumeName           #        dataSource           #</code></pre><h3 id="存储类SC：StorageClass"><a href="#存储类SC：StorageClass" class="headerlink" title="存储类SC：StorageClass"></a>存储类SC：StorageClass</h3><p><img src="/2018/08/10/k8s-volumes/SC.png" alt="SC"></p><pre><code>SC:Storageclass是k8s上的标准资源    SC是实现PVC动态创建存储单元PV的基础        1.SC上定义了如何连接外部存储API管理接口的方式        2.PVC只能向同一个SC中的PV请求绑定，不能跨SC.定义SC：    详见：kubectl explain sc        apiVersion        kind        metadata        parameters     #对接外部存储时的参数        reclaimPolicy  #在此SC中的PV回收策略        provisioner    #指明后端存储设备-----必须项        volumeBindingMode #后端存储支持的访问模型(RWX,ROX,RWO)        allowVolumeExpansion   #后端存储系统是否支持空间拉伸官方示例：    glusterfs类型的SC          apiVersion: storage.k8s.io/v1        kind: StorageClass        metadata:          name: slow        provisioner: kubernetes.io/glusterfs        parameters:          resturl: &quot;http://127.0.0.1:8081&quot;          clusterid: &quot;630372ccdc720a92c681fb928f27b53f&quot;          restauthenabled: &quot;true&quot;          restuser: &quot;admin&quot;          secretNamespace: &quot;default&quot;          secretName: &quot;heketi-secret&quot;          gidMin: &quot;40000&quot;          gidMax: &quot;50000&quot;          volumetype: &quot;replicate:3&quot;    ceph-rbd类型的SC:        kind: StorageClass        apiVersion: storage.k8s.io/v1        metadata:          name: fast        provisioner: kubernetes.io/rbd        parameters:          monitors: 10.16.153.105:6789          adminId: kube          adminSecretName: ceph-secret          adminSecretNamespace: kube-system          pool: kube          userId: kube          userSecretName: ceph-secret-user          userSecretNamespace: default          fsType: ext4          imageFormat: &quot;2&quot;          imageFeatures: &quot;layering&quot;</code></pre><h3 id="示例-创建静态供给PV和PVC"><a href="#示例-创建静态供给PV和PVC" class="headerlink" title="示例-创建静态供给PV和PVC"></a>示例-创建静态供给PV和PVC</h3><pre><code>以nfs为例定义一个PV：    [root@master01 manifsets]# vim pv-test.yaml    apiVersion: v1    kind: PersistentVolume    metadata:      name: pv-nfs-v1      labels:        storagefs: nfs    spec:    #  accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;]      accessModes:      - ReadWriteMany      - ReadWriteOnce      - ReadOnlyMany      capacity:        storage: 1Gi                #定义PV能提供多大存储空间      volumeMode: Filesystem      persistentVolumeReclaimPolicy: Retain     #定义PV回收策略      nfs:        path: /vols/v2        server: 10.10.0.29创建PVC：    apiVersion: v1    kind: PersistentVolumeClaim    metadata:      name: redis-pvc            #定义PVC的名称，以便Pod中引用      namespace: volumes-test    spec:      selector:   #定义关联到哪个PV，不指定则根据需求空间找相近空间大小的PV        matchLabels:          storagefs: nfs2      accessModes:      - ReadWriteMany      volumeMode: Filesystem      resources:        requests:          storage: 500Mi          #根据PV的存储空间定义PVC有多少空间创建Pod挂载PVC    apiVersion: v1    kind: Pod    metadata:      name: redis      namespace: volumes-test    spec:      nodeName: node03      containers:      - name: redis        image: redis:alpine        ports:        - name: redis          containerPort: 6379        volumeMounts:              #容器复制挂载volumes        - name: redisdata          mountPath: /data          readOnly: false      volumes:      - name: redisdata        persistentVolumeClaim:          claimName: redis-pvc           #挂载PVC测试：    [root@master01 ~]# kubectl get pv    NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                      STORAGECLASS   REASON   AGE    pv-nfs-v1   1Gi        RWO,ROX,RWX    Retain           Available                                                      8m14s    pv-nfs-v2   2Gi        RWO,ROX,RWX    Retain           Released    volumes-test/redis-pvc-1                           8m14s    pv-nfs-v3   3Gi        RWO,ROX,RWX    Retain           Bound       volumes-test/redis-pvc                             8m14s    [root@master01 ~]# kubectl get pvc -n volumes-test    NAME        STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE    redis-pvc   Bound    pv-nfs-v3   3Gi        RWO,ROX,RWX                   5m55s</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Kubernetes-Volumes&quot;&gt;&lt;a href=&quot;#Kubernetes-Volumes&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes Volumes&quot;&gt;&lt;/a&gt;Kubernetes Volumes&lt;/h3&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.liukui.tech/categories/kubernetes/"/>
    
    
      <category term="k8s" scheme="https://www.liukui.tech/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现四层和七层负载均衡</title>
    <link href="https://www.liukui.tech/2018/03/26/nginx%E5%AE%9E%E7%8E%B0%E5%9B%9B%E5%B1%82%E5%92%8C%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>https://www.liukui.tech/2018/03/26/nginx实现四层和七层负载均衡/</id>
    <published>2018-03-26T00:00:00.000Z</published>
    <updated>2019-01-22T12:20:21.612Z</updated>
    
    <content type="html"><![CDATA[<h3 id="nginx实现七层负载均衡"><a href="#nginx实现七层负载均衡" class="headerlink" title="nginx实现七层负载均衡"></a>nginx实现七层负载均衡</h3><a id="more"></a><p><img src="/2018/03/26/nginx实现四层和七层负载均衡/nginx七层代理.png" alt="nginx实现七层调度的动静分离架构和调度算法分析"></p><pre><code>1.先通过upstream模块将多个后端服务器定义成server服务器组，再使用proxy_pass向后端    代理到这个server组2.upstream模块实现模块级的负载均衡算法调度3.upstream模块可以实现对后端服务器集群的健康状态监测，当有服务器down机了自动从这个    组中剔除，服务器恢复正常也会重新加入到这个组中，还支持所有服务器down机，然后由    一台sorry server提供服务4.session保持的三种方式：    session sticky:        1.基于客户端IP做hash将seesion保存在一台服务器上，如果是SNAT网络则IP是            一样的，seesion的颗粒度过于粗糙.        2.cookie机制即使是在通过SNAT网络中，不同的浏览器客户端也会被识别为不同            客户端，seesion的颗粒度精细的多.nginx可以识别应用层的cookie信息，            完全可以基于cookie信息做会话绑定的.但是只有nginx商业版支持.    seesion replication:        在同一集群中，session是共享的，但是对内存的消耗比较大        把自己的seesion复制给集群的其他主机    session server:        把用户访问的seesion保存单独的一台服务器，但是session的冗余实现比较麻烦        和cookie</code></pre><h3 id="ngx-http-upstream-module模块"><a href="#ngx-http-upstream-module模块" class="headerlink" title="ngx_http_upstream_module模块"></a>ngx_http_upstream_module模块</h3><pre><code>作用于server之外的http上下文1.upstream name {...}    定义后端服务器组；引入一个新的上下文；只能用于http{}上下文中；    默认调度算法是round robin，也就是加权轮询wrr；默认权重是12.server address [parameters];    定义服务器地址和相关的参数；        地址格式：            IP[:PORT]            HOSTNAME[:PORT]            unix:/PATH/TO/SOME_SOCK_FILE                server的修饰参数：            weight=number                权重，默认为1；            max_fails=number                失败尝试连接的最大次数；默认是1次            fail_timeout=time                设置服务器为不可用状态的超时时长；                失败的默认健康状态检测超时时长，默认10s    备注：max_fails和fail_timeout的乘机算一个周期，比如下面这个例子            backup                把服务器标记为“备用”状态；用于say sorry服务器            down                手动标记其为不可用；手动下线服务器，用于发布更新服务支持的算法：                3.least_conn;        1.短连接最好使用轮询wrr，长连接最好使用wlc;        2.如果不启用保持连接，即使改成least conn,效果也不是很明显.        3.最少连接调度算法，当server拥有不同的权重时其为wlc，当所有后端主机连接数            相同时，则使用wrr，适用于长连接    4.ip_hash;静态hash算法        对源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server；         1.ip_hash是对源地址进行hash，然后对后端服务器的权重之和取模，模是多少，            就把对应的结果映射到第几台服务器上，如果有服务器down了，那么权重            之和也会变，那么原来的hash结果大概率不能命中，所以ip_hash的调度算法存在很大的缺陷.        2.如果采用ip_hash算法，一旦后端有一台缓存服务器down了，由于是取模法，会造            成后台缓存服务器集群全部不能命中，并发请求数10W时，会把请求压力全部集            中到后端服务器上，造成系统崩溃        3.所以生产环境下一般不用ip_hash，而是采用一致性hash算法.    5.hash key [consistent];        consistent,虚拟主机的一致性hash算法；        此处可以对任意的key进行hash,所选取的key的值不同，hash的结果可以实现不同的            请求调度功能.而且此处的key可以是文本，变量或者二者的组合    例如：        hash $remote_addr consistent = ip_hash             即还是对源地址进行hash，但是效果确实一致性hash        hash $request_uri consistent             后端服务器是缓存服务器时，对静态内容的请求资源request_uri进行hash，            极有可能在缓存中命中,从而缓解了并加大了服务器的并发访问数.        hash $cookie_name consistent             对cookie的hash，首先服务端需要给客户端端强行插入cookie,就需要用到            sticky_cookie_insert,而这个功能只有在nginx plus版本中才能够使用    6.keepalive connections;    可使用长连接的连接数量；每worker与后端服务保持的最大空闲长连接数量；    为每个worker进程保留的空闲的长连接数量，可节约nginx端口，并减少连接管理的消耗    长连接的作用：    connections意思代理服务器与后端服务器之前先建立一定数量的始终不断开的长连接数量，当有用户请求时，这些长连接相当于一个一直处于连接状态管道，即一个连接上可以    发N个请求，既可以提升响应速度又可以减少代理服务器的套接字占用，避免了重复建立、断开、再建立的消耗资源的步骤,属于一种优化方式.示例：    upstream staticwebservs {        #   ip_hash;        #   hash $remote_addr consistent;            hash $request_uri consistent;            server 172.17.0.2 weight=2 fail_timeout=2 max_fails=2;            server 172.17.0.3 fail_timeout=2 max_fails=2;             keepalive 32；    }    server {    listen 8083;    location / {            proxy_pass http://staticwebservs/;    }这样就可以检测后端服务器集群健康状态的时长，在4s内检测到服务器有问题，就标记为down而且建立不断开的长连接总结：    1.对静态资源的请求，因为是短连接，要用weight round robin,加权轮询算法:wrr    2.对动态资源的请求，因为要有会话保持seesion sticky，所以要用ip_hash或者        hash $remote_addr consistent 算法，但是对IP hash的颗粒度较为粗糙，可以        对cookie进行hash,但是nginx社区版不支持.    3.如果网站有缓存层，要用hash $request_uri consistent一致性hash的绑定机制算        法,避免因为后端的一台缓存服务器down机，而影响全局的缓存层!</code></pre><h3 id="nginx实现四层负载均衡-调度-功能"><a href="#nginx实现四层负载均衡-调度-功能" class="headerlink" title="nginx实现四层负载均衡(调度)功能"></a>nginx实现四层负载均衡(调度)功能</h3><p><img src="/2018/03/26/nginx实现四层和七层负载均衡/" alt="nginx实现四层负载均衡原理"></p><pre><code>1.nginx实现四层调度，在nginx和后端服务器集群中建立一个四层的转发通道，对客户端发来    的请求报文不做任何解析，而是对客户端请求的地址和端口转发.2.如果后端有服务器集群，可以通过upstream模块实现不同算法的负载均衡调度效果.3.四层负载调度功能，作用于stream上下文，需要单独定义4.对数据存储等有状态的一类的应用一定不能做负载均衡，而是通过一种数据分发路由机制的    高级组件来完成，比如mysql的读写分离，mysql的分片框架等5.如上图示，因为只是实现四层调度，不存在什么动静分离资源，只是简单的四层调度功能</code></pre><h3 id="ngx-stream-core-module"><a href="#ngx-stream-core-module" class="headerlink" title="ngx_stream_core_module"></a>ngx_stream_core_module</h3><pre><code>The ngx_stream_core_module module is available since version 1.9.0. This module is not built by default, it should be enabled with the --with-stream configuration parameter.(1) listen address:port [ssl] [udp] [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];    监听的端口；        默认为tcp协议；        udp: 监听udp协议的端口；</code></pre><h3 id="ngx-stream-upstream-module"><a href="#ngx-stream-upstream-module" class="headerlink" title="ngx_stream_upstream_module"></a>ngx_stream_upstream_module</h3><pre><code>实现四层调度需要在upstream中定义，负载均衡调度的组    upstream name {...}，作用于stream上下文    server address [parmameters]        修饰符：            weight=number            max_conns=number            max_fails=number            fail_timeout=time            backup            down</code></pre><h3 id="ngx-stream-proxy-module"><a href="#ngx-stream-proxy-module" class="headerlink" title="ngx_stream_proxy_module"></a>ngx_stream_proxy_module</h3><pre><code>(1) proxy_pass address; (2) proxy_timeout timeout;    默认为10m;    (3) proxy_connect_timeout time;                设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s；示例：stream {    upstream sshsrvs {        server 192.168.10.130:22;        server 192.168.10.131:22;        hash $remote_addr consistent;    }    server {        listen 172.16.100.6:22202;        proxy_pass sshsrvs;         proxy_timeout 60s;        proxy_connect_timeout 10s;    }} </code></pre><h3 id="实现Nginx高并发的Linux入门级内核优化"><a href="#实现Nginx高并发的Linux入门级内核优化" class="headerlink" title="实现Nginx高并发的Linux入门级内核优化"></a>实现Nginx高并发的Linux入门级内核优化</h3><p>虽然nginx本身就支持高性能的并发访问，除了在配置文件级别的一些性能调优的必要参数之外<br>有时也需要在linux内核级进行简单的调优.</p><pre><code>优化说明：    优化是很复杂的一个问题，不是明显的设置缺点的话，不建议对nginx进行优化，因为不确定哪个是导致nginx明显短板的因素，有时也可以通过nginx的二级调度来实现高并发的    访问.    1.由于默认的Linux内核参数考虑的是最通用场景，这明显不符合用于支持高并发访问的        Web服务器的定义，所以需要修改Linux内核参数    2.Nginx可以拥有更高的性能,根据业务特点来进行调整，当Nginx作为静态web内容服务器、反向代理或者提供压缩服务器的服务器时，期内核参数的调整都是不同的，这里针对最通用的、使Nginx支持更多并发请求的TCP网络参数做简单的配置,修改/etc/sysctl.conf来更改内核参数    3.sysctl的用法：        sysctl命令：            默认配置文件：/etc/sysctl.conf            (1) 设置某参数            sysctl -w parameter=VALUE            (2) 通过读取配置文件设置参数            sysctl -p [/path/to/conf_file]            (3) 查看所有生效参数            sysctl -a        最好是写在/etc/sysctl.conf中，再通过sysctl -p /etc/sysctl.conf生效即可    比如：        进制本机被ping的设置            sysctl -w net.ipv4.icmp_echo_ignore_all=1fs.file-max = 999999：单个进程较大可以打开的文件描述符数量    ulimit -n 999999net.ipv4.tcp_tw_reuse = 1 (必调)    参数设置为1，表示允许将TIME_WAIT状态的socket重新用于新的TCP连接，因为在服务器端有大量的处于TCP中的TIME_WAIT状态的链接存在，能够复用这个socket对于繁忙的服务器来说意义重大.    echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse (sysctl)net.ipv4.tcp_keepalive_time = 600     当keepalive启动时，TCP发送keepalive消息的频度，默认为2小时，将其设置10分钟，可以更快的清理无效连接net.ipv4.tcp_fin_timeout = 30    当服务器主动关闭连接是，socket保持在FIN_WAIT2状态的较大时间net.ipv4.tcp_max_tw_buckets = 5000    默认是8000，建议调小    允许TIME_WAIT套接字数量的较大值，如果超过这个数字，TIME_WAIT套接字将立刻清除并打印警告信息，默认为8000，过多TIME_WAIT套接字会使web服务器变慢net.ipv4.ip_local_port_range = 1024 65000    TCP和UDP连接的本地端口取值范围net.ipv4.tcp_rmem = 1024 87380 12582912    TCP接收缓存的最小值、默认值、最大值net.ipv4.tcp_wmen = 1024 87380 12582912    TCP发送缓冲的最小值、默认值、最大值net.core.netdev_max_backlog = 8096    网卡接收队列最大值net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_sync_backlog = 8192    TCP三次握手建立阶段接收SYN请求队列的最大长度，默认为1024net.ipv4.tcp_tw_recyle = 1    启用timewait的快速回收</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;nginx实现七层负载均衡&quot;&gt;&lt;a href=&quot;#nginx实现七层负载均衡&quot; class=&quot;headerlink&quot; title=&quot;nginx实现七层负载均衡&quot;&gt;&lt;/a&gt;nginx实现七层负载均衡&lt;/h3&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>基于lnnmp搭建个人博客</title>
    <link href="https://www.liukui.tech/2018/03/22/%E5%9F%BA%E4%BA%8Elnnmp%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>https://www.liukui.tech/2018/03/22/基于lnnmp搭建个人博客/</id>
    <published>2018-03-22T00:00:00.000Z</published>
    <updated>2019-01-28T06:49:21.656Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基于openstack-docker搭建LNNMP"><a href="#基于openstack-docker搭建LNNMP" class="headerlink" title="基于openstack/docker搭建LNNMP"></a>基于openstack/docker搭建LNNMP</h3><a id="more"></a><p>-个人网站基本架构图<br><img src="/2018/03/22/基于lnnmp搭建个人博客/lnnmp架构图.png" alt="LNNMP架构图"></p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><pre><code>1.所有服务器时间要同步2.proxysql要和mysql所有服务器在同一个网段，不然会影响mysql的性能    nginx调度服务器：192.168.100.10    nginx+fpm-1服务器：192.168.100.3    nginx+fpm-2服务器：192.168.100.4    proxysql数据库读写分离：192.168.100.30    mysql_1服务器:192.168.100.9    mysql_2服务器:192.168.100.16    mysql_3服务器:192.168.100.17    NFS主：在mysql_2服务器上192.168.100.16    NFS备：在mysql_3服务器上192.168.100.17软件版本：     wordpress:         wordpress-5.0-zh_CN.zip (默认安装再升级)        wordpress-5.0.2-zh_CN.zip(用于测试升级版本)        依赖于php7.3版本之上和mysql5.6或者mariadb10.0版本之上    mysql:mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz(和一键安装脚本)    nginx:nginx-1.12.2.tar.gz    php-fpm:php-7.2.14.tar.gz    nfs: nfs-utils</code></pre><h3 id="1-搭建一主二从数据库"><a href="#1-搭建一主二从数据库" class="headerlink" title="1.搭建一主二从数据库"></a>1.搭建一主二从数据库</h3><pre><code>二进制安装mysql，此处用事先准备好的脚本进行安装(供参考)；</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql_1 ~]# vim mysql-install.sh   </span><br><span class="line">#!/bin/bash</span><br><span class="line">DIR=`pwd`</span><br><span class="line">NAME=&quot;mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz&quot;</span><br><span class="line">FULL_NAME=$&#123;DIR&#125;/$&#123;NAME&#125;</span><br><span class="line">DATA_DIR=&quot;/data/mysql&quot;</span><br><span class="line"></span><br><span class="line">yum install vim gcc gcc-c++ wget autoconf  net-tools lrzsz iotop lsof iotop bash-completion -y</span><br><span class="line">yum install curl policycoreutils openssh-server openssh-clients postfix -y</span><br><span class="line"></span><br><span class="line">if [ -f $&#123;FULL_NAME&#125; ];then</span><br><span class="line">    echo &quot;安装文件存在&quot;</span><br><span class="line">else</span><br><span class="line">    echo &quot;安装文件不存在&quot;</span><br><span class="line">    exit 3</span><br><span class="line">fi</span><br><span class="line">if [ -h /usr/local/mysql ];then</span><br><span class="line">    echo &quot;Mysql已经安装&quot;</span><br><span class="line">    exit 3</span><br><span class="line">else</span><br><span class="line">    tar xvf $&#123;FULL_NAME&#125;   -C /usr/local/src</span><br><span class="line">    ln -sv /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64  /usr/local/mysql</span><br><span class="line">    if id  mysql;then</span><br><span class="line">        echo &quot;mysql用户已经存在&quot;</span><br><span class="line">    fi</span><br><span class="line">        useradd  mysql  -s /sbin/nologin</span><br><span class="line">    if  id  mysql;then</span><br><span class="line">        chown  -R mysql.mysql  /usr/local/mysql/* -R</span><br><span class="line">        if [ ! -d  /data/mysql ];then</span><br><span class="line">            mkdir -pv /data/mysql &amp;&amp; chown -R mysql.mysql  /data   -R</span><br><span class="line">            /usr/local/mysql/scripts/mysql_install_db  --user=mysql --datadir=/data/mysql  --basedir=/usr/local/mysql/</span><br><span class="line">            cp  /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64/support-files/mysql.server /etc/init.d/mysqld</span><br><span class="line">            chmod a+x /etc/init.d/mysqld</span><br><span class="line">            cp $&#123;DIR&#125;/my.cnf   /etc/my.cnf</span><br><span class="line">            ln -sv /usr/local/mysql/bin/mysql  /usr/bin/mysql</span><br><span class="line">            chkconfig --add mysqld</span><br><span class="line">            service mysqld start</span><br><span class="line">        else</span><br><span class="line">            echo &quot;MySQL数据目录已经存在&quot;</span><br><span class="line">            exit 2</span><br><span class="line">        fi</span><br><span class="line">    fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><pre><code>主节点数据库：    1.启用二进制日志和跳过主机名称解析        server-id=1        log_bin=/data/mysql/master-log        skip_name_resolve = on    2.授权主从复制账号        grant replication slave on *.* to repluser@&apos;192.168.100.%&apos; identified by &apos;root123&apos;;    3.show master logs;        查看二进制日志位置，准备change master to信息    4.创建wordpress数据库        create database wordpress;    5.创建php连接mysql的用户和proxysql读写分离的用户         grant all on *.* to wordpress@&apos;192.168.100.%&apos; identified by &apos;wordpress123&apos;        此账号既作为php连接数据库的账号，又作为proxysql中读写分离的账户从节点数据库：    1.每个从节点都需要如下设置，设置只读，启用中继日志        server-id=2|3        read-only        relay_log=/data/mysql    2.设置change master to:        CHANGE MASTER TO          MASTER_HOST=&apos;192.168.100.9&apos;,          MASTER_USER=&apos;repluser&apos;,          MASTER_PASSWORD=&apos;root123&apos;,          MASTER_PORT=3306,          MASTER_LOG_FILE=&apos;master-log.000001&apos;,          MASTER_LOG_POS=4,          MASTER_CONNECT_RETRY=120;    3.start slave;启动MySQL主从    service mysqld start</code></pre><h3 id="安装配置proxysql读写分离器"><a href="#安装配置proxysql读写分离器" class="headerlink" title="安装配置proxysql读写分离器"></a>安装配置proxysql读写分离器</h3><pre><code>1.基于YUM仓库安装    vim /etc/yum.repos.d/proxysql.repo    [proxysql_repo]    name= ProxySQL YUM repository    baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever    gpgcheck=1    gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key2.安装启动    yum install proxysql &amp;&amp; systemctl start proxysql3.向ProxySQL中添加MySQL所有节点，以下操作不需要use main也可成功    MySQL &gt; select * from mysql_servers;    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.9&apos;,3306);    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.16&apos;,3306);    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)    values(10,&apos;192.168.100.17&apos;,3306);    MySQL &gt; load mysql servers to runtime;    MySQL &gt; save mysql servers to disk;4.配置监控账号：    a.在主节点上，创建监控账号        grant replication client on *.* to monitor@&apos;192.168.100.%&apos; identified by &apos;root123&apos;;        备注：replication client权限是负责监控的，和replication slave是不同的权限    b.Proxysql上配置监控        实际上是保存在global_variables表中，可以查看是否修改成功        MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;;        MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;;    c.使global_variables表生效        MySQL [mian]&gt; load mysql variables to runtime;        MySQL [mian]&gt; save mysql variables to disk;5.设置分组信息和读写规则    main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20    插入读写组的编号：        insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;);    生效和保存：        MySQL [monitor]&gt; load mysql servers to runtime;        MySQL [monitor]&gt; save mysql servers to disk;    再次查看        select hostgroup_id,hostname,port,status,weight from mysql_servers;6.创建用于测试读写分离的账号    主节点上创建访问用户：        用上面创建的wordpress账户即可    在ProxySQL配置，将用户wordpress添加到mysql_users表中：        insert into mysql_users(username,password,default_hostgroup)values(&apos;wordpress&apos;,&apos;wordpress123&apos;,10);    生效和保存：        MySQL [monitor]&gt; load mysql users to runtime;        MySQL [monitor]&gt; save mysql users to disk;7.配置路由规则，实现读写分离    与规则相关的表：mysql_qeury_rules    插入路由规则,实现读写分离的规则        insert into mysql_query_rules        (rule_id,active,match_digest,destination_hostgroup,apply)        VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1);    生效和保存到磁盘：        load mysql query rules to runtime;        save mysql query rules to disk;8.可以现在本机用wordpress测试是否可以实现读写分离    读：因为是读操作会在2和3上随机选择    mysql -wordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos;    写：事务是非select开头的，所以查询的都是1上    mysql -uwordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos;  </code></pre><h3 id="编译安装php"><a href="#编译安装php" class="headerlink" title="编译安装php"></a>编译安装php</h3><pre><code>1.准备环境依赖包：    yum -y install wget vim pcre pcre-devel openssl openssl-devel libicu-devel gcc gcc-c++     autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2     libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel ncurses ncurses-devel     curl curl-devel krb5-devel libidn libidn-devel openldap openldap-devel nss_ldap     jemalloc-devel cmake boost-devel bison automake libevent libevent-devel gd gd-devel     libtool* libmcrypt libmcrypt-devel mcrypt mhash libxslt libxslt-devel readline     readline-devel gmp gmp-devel libcurl libcurl-devel openjpeg-devel2.编译php:    ./configure  --prefix=/usr/local/php \    --with-config-file-path=/usr/local/php/etc \    --with-config-file-scan-dir=/usr/local/php/etc/conf.d \    --enable-fpm --with-fpm-user=www \    --with-fpm-group=www --with-pear \    --with-curl  --with-png-dir --with-freetype-dir \    --with-iconv   --with-mhash   --with-zlib --with-xmlrpc \    --with-xsl --with-openssl  --with-mysqli --with-pdo-mysql \    --disable-debug --enable-zip --enable-sockets \    --enable-soap   --enable-inline-optimization  --enable-xml \    --enable-ftp --enable-exif --enable-wddx \    --enable-bcmath --enable-calendar   --enable-shmop \    --enable-dba --enable-sysvsem --enable-sysvshm --enable-sysvmsg    make &amp;&amp; make install3.创建用户    useradd www4.准备配置文件    cd /usr/local/php/etc/    cp php-fpm.conf.default php-fpm.conf    cp php-fpm.d/www.conf.default php-fpm.d/www.conf    1.修改php-fpm.d/www.conf配置文件，使用dynamic动态模式，并设置最大，最少        空闲进程等信息    2.修改启动php的用户为www5.准备启动脚本    cp /root/ php-7.2.14/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm        chmod +x /etc/init.d/php-fpm        chkconfig --add php-fpm        chkconfig php-fpm on    也可以使用编译生成的        /usr/local/php/sbin/php-fpm直接启动</code></pre><h3 id="编译安装nginx实现web服务"><a href="#编译安装nginx实现web服务" class="headerlink" title="编译安装nginx实现web服务"></a>编译安装nginx实现web服务</h3><pre><code>因为在上文架构图中nginx既做web服务，又作为前端负载均衡服务器在这两台服务器上编译安装nginx,实现转发wordpress请求    nginx+fpm-1服务器：192.168.100.3    nginx+fpm-2服务器：192.168.100.41.解压并编译    tar xf nginx-1.12.2.tar.gz    cd nginx-1.12.2    ./configure \    --prefix=/usr/local/nginx  \    --with-pcre \    --with-http_stub_status_module \    --with-http_ssl_module    make &amp; make install2.修改配置文件将php资源请求调度到php-fpm    在server的上下文定义：因为nginx和php在同一台服务器，所以直接写127.0.0.1:9000    location / {    root   /data/nginx/wordpress;    index  index.php index.html index.htm;    }    location ~ \.php$ {        root          /data/nginx/wordpress;(可不写)        fastcgi_pass   127.0.0.1:9000;        fastcgi_index  index.php;        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;            include        fastcgi_params;    }    如果location中不写root，$document_root就要写/data/nginx/wordpress$fastcgi_script_name;3.启动服务    /usr/local/nginx/sbin/nginx </code></pre><h3 id="部署wordpress-5-0"><a href="#部署wordpress-5-0" class="headerlink" title="部署wordpress-5.0"></a>部署wordpress-5.0</h3><pre><code>在两台nginxweb服务器上安装同样的wordpress和配置1.创建存放wordpress目录    mkdir -pv /data/nginx/wordpress2.解压并将全部文件拷贝到/data/nginx/wordpress下    tar xf wordpress-5.0-zh_CN.zip    mv wordpress/* /data/nginx/wordpress/3.修改/data/nginx/wordpress的所有者和所属组    chown -R www.www /data/nginx/wordpress4.准备连接数据库的文件    cp wp-config-sample.php wp-config.php    vim wp-config.php        /** WordPress数据库的名称 */        define(&apos;DB_NAME&apos;, &apos;wordpress&apos;);        /** MySQL数据库用户名 */        define(&apos;DB_USER&apos;, &apos;wordpress&apos;);        /** MySQL数据库密码 */        define(&apos;DB_PASSWORD&apos;, &apos;wordpress123&apos;);        /** MySQL主机 */        define(&apos;DB_HOST&apos;, &apos;192.168.100.30:6033&apos;);    此处连接的mysql数据库主机是proxysql读写分离的IP和端口</code></pre><h3 id="通过NFS共享图片目录"><a href="#通过NFS共享图片目录" class="headerlink" title="通过NFS共享图片目录"></a>通过NFS共享图片目录</h3><pre><code>准备NFS主备后端存储：    1.这里nfs主备用mysql的两台从服务来实现        yum install nfs-utils -y        一定要安装nfs-utils，实际环境测试不安装utils，访问nfs的速度很慢        准备共享目录：            mkdir -pv /nfsdata/images        设置权限nfs共享目录权限            vim /etc/exports            /nfsdata/images *(rw,no_root_squash)    2.实现主备NFS的图片同步    rsync -avrlopg /nfsdata/images/* 192.168.100.17:/nfsdata/images/在nginx+pfp-fpm的两台服务器挂载nfs的共享目录    showmount -e 192.168.100.16    显示该主机上可以挂载的nfs目录1.挂载目录并设置开机自动挂载    因为wordpress的图片是保存在/data/nginx/wordpress/wp-content/uploads中的    所以要把该目录用nfs共享    1.vim /etc/fstab        192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads/ nfs defaults,_netdev 0 0        写在fstab文件中一定要加_netdev选项,刚开机没有IP地址时，即使挂载不上也可以启动    2.也可以写在/etc/rc.d/rc.local中，因为该文件是系统启动最后加载的文件，此时        已经获取到IP地址了，当然可以实现自动挂载,要设置执行权限        vim /etc/rc.d/rc.local        mount -t nfs 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads        chmod +x /etc/rc.d/rc.local3.备注：    NFS共享，为了避免IP地址的问题，最好要配置一个DNS服务器来主机名和IP地址    挂载的时候最好使用主机名取挂载，即使IP地址出问题了，也可以临时在DNS服务器上    修改主机名和IP地址的对应关系.</code></pre><h3 id="编译安装nginx实现负载均衡"><a href="#编译安装nginx实现负载均衡" class="headerlink" title="编译安装nginx实现负载均衡"></a>编译安装nginx实现负载均衡</h3><pre><code>nginx调度服务器：192.168.100.101.解压并编译    tar xf nginx-1.12.2.tar.gz    cd nginx-1.12.2    ./configure \    --prefix=/usr/local/nginx  \    --with-pcre \    --with-http_stub_status_module \    --with-http_ssl_module    make &amp; make install2.修改配置文件实现七层调度    在http上下文定义：vim /usr/local/nginx/conf/nginx.confupstream blogs {server 192.168.100.3:80 weight=1 max_fails=3 fail_timeout=100s;server 192.168.100.4:80 weight=1 max_fails=3 fail_timeout=100s;hash $remote_addr consistent; (做会话保持)}server {    listen 80;    server_name www.lkblog.net;    index index.html index.php;    location / {        proxy_pass http://blogs;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        add_header X-Via  $server_addr;        proxy_next_upstream http_502 http_504 error timeout invalid_header;    }}3.启动服务    /usr/local/nginx/sbin/nginx     /usr/local/nginx/sbin/nginx -t     /usr/local/nginx/sbin/nginx -s reload 配置完后重新加载</code></pre><h3 id="启动各服务，并测试读写"><a href="#启动各服务，并测试读写" class="headerlink" title="启动各服务，并测试读写"></a>启动各服务，并测试读写</h3><p>-<br><img src="/2018/03/22/基于lnnmp搭建个人博客/初次登录注册.png" alt="初次登录注册页面"><br>注册完后生成数据库各表<br><img src="/2018/03/22/基于lnnmp搭建个人博客/数据库表.png" alt="数据库"><br>-<br><img src="/2018/03/22/基于lnnmp搭建个人博客/上传图片测试.png" alt="上传图片测试"><br>上传图片测试，在nfs也是可以看到的，说明挂载是成功的</p><p>-浏览站点，因为是普通的http请求，用轮询的方式是没问题的<br><img src="/2018/03/22/基于lnnmp搭建个人博客/后台日志.png" alt="后台日志"></p><p>-对于登录页面，如果没有做会话保持是登不上去的，这也是为什么Nginx负载均衡器上做源地址hash的原因.<br><img src="/2018/03/22/基于lnnmp搭建个人博客/用户登录测试.png" alt="用户登录测试"></p><h3 id="升级wordpress版本"><a href="#升级wordpress版本" class="headerlink" title="升级wordpress版本"></a>升级wordpress版本</h3><pre><code>版本更新需要注意最好不要跨大版本进行更新，一般更新也是在大版本下进行小版本的更新以下以wordpress-5.0--&gt;wordpress-5.0.2步骤：    1.停止Nginx服务    2.备份元数据或删除    3.升级版本    4.启动服务简单的以脚本方式实现一台wordpress升级    vim updates.sh        ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx -s stop&quot;        ssh 192.168.100.4 &quot;rm -rf /data/nginx/wordpress/*&quot;        scp wordpress-5.0.2-zh_CN.zip 192.168.100.4:/data        ssh 192.168.100.4 &quot;unzip wordpress-5.0.2-zh_CN.zip -d /data/nginx/wordpress/&quot;        ssh 192.168.100.4 &quot;chown -R www.www /data/nginx/wordpress/&quot;        ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx&quot;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;基于openstack-docker搭建LNNMP&quot;&gt;&lt;a href=&quot;#基于openstack-docker搭建LNNMP&quot; class=&quot;headerlink&quot; title=&quot;基于openstack/docker搭建LNNMP&quot;&gt;&lt;/a&gt;基于openstack/docker搭建LNNMP&lt;/h3&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现反向代理功能</title>
    <link href="https://www.liukui.tech/2018/03/22/nginx%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%8A%9F%E8%83%BD/"/>
    <id>https://www.liukui.tech/2018/03/22/nginx实现反向代理功能/</id>
    <published>2018-03-22T00:00:00.000Z</published>
    <updated>2019-01-22T12:20:49.758Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Nginx实现反向代理服务器的配置"><a href="#Nginx实现反向代理服务器的配置" class="headerlink" title="Nginx实现反向代理服务器的配置"></a>Nginx实现反向代理服务器的配置</h3><a id="more"></a><p><img src="/2018/03/22/nginx实现反向代理功能/nginx代理原理.png" alt="nginx实现反向代理原理"></p><pre><code>nginx实现反代的工作原理：    1.代理服务器需要注册监听端口，用来接收用户请求，而监听端口是可以被复用的，且一个端口可以接收N路请求.    2.代理服务器本地没有资源，当请求报文送达时，由于代理服务本身就是个web服务器，所以能够充分理解请求报        文的MIME类型，URL等，差别只是本来是需要通过IO加载本地资源的，但是由于本地没有，则会向后端服务器        去取资源，但是此时请求报文已经被完完整整的拆开了，是不能把请求报文发往后端的    3.所以在nginx中是由一个模块扮演成类似客户端浏览器角色的，把自己模拟成客户端程序，封装一个新的http请求，    向后端服务器发起请求.    4.而后端服务器会把响应报文发送给代理服务器，代理服务器则又会拆掉网络层封装，传输成封装，应用层封装，        看到响应报文的body主体部分，把主体部分拿出来重新封装成一个响应报文发回给客户端》    5.只要是向后端请求必然会再占用一个端口    6.代理服务器要维持两路连接，而且是彼此隔离且独立的    7.那么向后端发送的请求报文要不要带客户端请求中所独有的私有的信息数据？        如果不传递，后端服务器是无法识别并相应的，必要时要把客户端的属性信息:请求        的url,用户认证信息等等重新封装到向后端发送的请求报文中，还是引用了客户端        发来的数据，而且代理服务器是可以修改请求报文的信息和响应报文中的信息    8.代理服务器可以操纵发往后端的请求和操纵响应给客户端的请求    9.这些也只有工作在应用层并且能识别应用层协议才可以实现的，如果再加一些访问控制        的功能，那么就可以做到四层防火墙做不到的访问控制能力，这也是代理服务器叫做        代理网关的原因，对于iptables和LVS是做不到的    10.面向客户端工作http/https协议，面向后端工作http,tcp,fastCGI,memcache，uwsgi(python的web框架)        等协议，那么这个能模拟客户端的模块就需要是多种专用模块1.nginx作为代理服务器来说，面向于客户端和服务端可以代理多种协议  代理服务器又叫代理网关，因为工作在应用层可以控制用户访问请求的资源，具有防护功能    面向客户端：        一般是http/https协议：通过http模块实现        mail:简单邮件传输协议等        stream:stream模块实现代理四层协议：tcp/udp            (nginx从1.9版本后可以实现四层负载均衡的)    代理后端服务器：        nginx内嵌了很多客户端模块来适配不同的后端协议：            http协议的服务器：ngx_http_proxy_modules模块            fpm服务器：ngx_http_fastcgi_module模块            memche服务器：</code></pre><h3 id="代理后端http协议的模块：专门代理后端是http协议的服务器集群-httpd和nginx"><a href="#代理后端http协议的模块：专门代理后端是http协议的服务器集群-httpd和nginx" class="headerlink" title="代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx)"></a>代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx)</h3><p><img src="/2018/03/22/nginx实现反向代理功能/" alt="nginx代理逻辑"></p><p>1.nginx作为代理服务器是，代理客户端和后端服务器，在数据报文是有两段的：<br>    1.客户端—&gt;代理服务器<br>    2.代理服务器作为客户端—&gt;后端的httpd/fpm/memche服务器<br>    而且代理服务器可以把客户端发来的数据报文进行修改重新封装发给后端服务器，<br>    后端服务器响应给代理服务器的报文也可以被代理服务器修改，再响应给客户端<br>    在设置中，可以通过不能功能体现出数据报文被如何修改的！</p><p>2.作为代理配置和nginx作为web服务器差不多，只不过要把root/alias缓存proxy_pass<br>    如果同时又root和proxy_pass，proxy_pass的优先级高</p><p>3.在location中将<em>.php或者</em>.jpg代理到不同的后端服务器上，可以实现资源请求的动静分离<br>    实现了在一台代理服务器上的资源路由.</p><h3 id="ngx-http-proxy-module模块："><a href="#ngx-http-proxy-module模块：" class="headerlink" title="ngx_http_proxy_module模块："></a>ngx_http_proxy_module模块：</h3><pre><code>1.proxy_pass URL     代理http协议的主要功能，是将客户端的请求代理至后端服务的路径上        Context: location, if in location, limit_except；        server {            ...            server_name HOSTNAME;            location / {                proxy http://hos[:port]; 优先级高于server的root                }            location /uri/ {                    proxy http://host/new_uri/;                }            location ~|~* /uri/ {                    proxy http://host;                }            ...        }          http://HOSTNAME/uri --&gt; http://host/uri     http://HOSTNAME/uri/ --&gt; http://host/new_uri/    http://HOSTNAME/uri/ --&gt; http://host/uri/；    路径映射，前后端的location和proxy_pass是映射关系,必要加/    如果location是正则表达式路径，proxy_pass的路径必须没有/和URI，因为是正则表达        式，无法判断路径</code></pre><p>-前后端路径映射<br><img src="/2018/03/22/nginx实现反向代理功能/前后端路径映射.png" alt="前后端路径映射"> </p><pre><code>2.proxy_set_header field value;    前面说过代理服务器可以修改客户端请求数据报文的信息发送给后端服务器，而对于后端    服务器来说看到的请求报文的源IP一直是代理服务器，但是可以通过修改参数是的后端    服务器看到的IP地址是真正的客户端地址而不是代理服务器！    设定发往后端主机的请求报文的请求首部的值；Context:http,server,location    设置代理服务器：        proxy_set_header X-Real-IP  $remote_addr;        或者        proxy_set_header X-Real-HOST  $host;将        或者        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    然后修改后端服务器的日志格式：        LogFormat &quot;%{X-Real-IP}i %l %u %t \&quot;%r\&quot; %&gt;s %b&quot;重启httpd服务即可    此时，后端服务器看到的IP就是客户端的IP了，所以可以设置任何真实的信息传递给后端服务器</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/proxy_set_header.png" alt="proxy_set_header"></p><h3 id="Nginx代理Web服务的Proxy缓存功能"><a href="#Nginx代理Web服务的Proxy缓存功能" class="headerlink" title="Nginx代理Web服务的Proxy缓存功能"></a>Nginx代理Web服务的Proxy缓存功能</h3><p>Nginx是一个高性能的web服务器，尤其在高并发和处理静态页面的时候有先天的优势；很大一部分得益于缓存的开启，缓存的实现逻辑</p><pre><code>* 此处是作用于http的上下文，因为每个代理模块都有缓存功能，但是不能混用* 要想使用proxy的缓存功能，必须先定义再引用* 定义缓存所以列表：对文件进行hash生成hash串，hash串是16进制数字，如果把hash串的前三位数字，按照数字放在对应的层级生成一个三级索引列表* 根据实际情况定义缓存层级，每多一次就是对磁盘IO的消耗，灵活定义缓存层级很有必要，比如一层以1个16进制数就是16个目录，2个16进制数就是2^8=256个目录，可以通过增加每次的级数，减小层数，对磁盘的IO消耗就降低了nginx的缓存功能： 不一定启用nginx缓存，可以使用varnish,或者CDN        只有真正需要启用时，才会启用nginx缓存    3.proxy_cache_path        nginx作为代理服务器是可以使用缓存功能的        定义缓存功能键也就是索引，是放在内存中的        定义可用于proxy功能的缓存；Context:http的上下文                   proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time];    4.proxy_cache ksys_zone的name | off;        指明要调用的缓存，或关闭缓存机制；Context:http, server, location    5.proxy_cache_key string;        虽然定义了缓存，还需要定义键，而这个键就是用户访问的地址;        1.为了避免后端有两台server_name有一模一样的URI,造成缓存索引出错，这里引入            了更多的差别数据，把整个访问路径都引入进来进行hash值缓存.        2.然而把整个url都引入进来，也会有问题，比如一个server有两个主机名，路径本            来就应该是相同的，如果引入了全路径则造成缓存不能命中了        3.所以如何定义这个&quot;键&quot;是根据不同场景使用的        默认值：proxy_cache_key $scheme$proxy_host$request_uri;                有时也可以定义为：$request_uri        所以根据不同使用场景proxy_cache_key的值需要修改    6.proxy_cache_valid [code ...] time;        通过定义不同的响应码来定义不同的缓存时长；(也可以统一为一个值)    7.proxy_cache_use_stale        当后端服务器有问题时，是否能够用过期的缓存资源响应客户端请求，默认是关闭的        proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...;    8.proxy_cache_methods GET | HEAD | POST ...;        设置客户端通过什么方法查询时，才调用缓存功能    9.proxy_hide_header field;        隐藏发送给客户端的响应报文的信息；f12中的header中看到的        默认nginx在响应报文中不传递后端服务器的首部字段Date, Server, X-Pad,         X-Accel-等，用于隐藏后端服务器特定的响应首部代理服务器请求后端服务器的几个超时时长：    10.proxy_connect_timeout time;        定义代理服务器后端服务器发请求的三次握手的连接时长        默认为60s，最长75s,不需要调    11.proxy_read_timeout time;        从后端接收响应报文的超时时长    12.proxy_send_timeout time;        连接建立后，向后端发送请求报文的超时时长示例：            先在http上下文中定义缓存；        proxy_cache_path /data/cache/nginx  levels=1:1:2；keys_zone webcache:10m max_size=2G;    再在server或者location中调用缓存和设置&quot;键&quot;以及过期时长；        location ~* \.(jpg|gif|jpeg)$ {           proxy_pass http://172.17.0.2;           proxy_cache webcache;           proxy_cache_key $request_uri;(这里根据不同场景定义)           proxy_cache_valid 200 302 301 1h;           proxy_cache_valid any 1m;           proxy_cache_methods GET HEAD;           proxy_cache_use_stale error timeout http_500 http_502 http_503;    这样就表示把缓存放在/data/cache/nginx中,最好是固态硬盘，磁盘IO越快，索引    查询的速度越快，定义了1:1:2三层路由索引，第一层16个目录，第二层16个子目录    第三次256个子目录</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/" alt="proxy_pass的缓存层级"></p><h3 id="ngx-http-headers-module模块：操纵响应报文首部"><a href="#ngx-http-headers-module模块：操纵响应报文首部" class="headerlink" title="ngx_http_headers_module模块：操纵响应报文首部"></a>ngx_http_headers_module模块：操纵响应报文首部</h3><pre><code>区别于proxy_set_header：    是代理服务器把客户端请求报文中的某些信息通过修改代理服务器请求报文首部的方式发送给后端服务器headers：    代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值；达到隐藏        某些信息不发给客户端。    1.add_header name value [always];        添加自定义首部；        add_header X-Via  $server_addr;        或者        add_header X-Accel $server_name;     发送给客户端的响应报文时，显示真正的后端服务器IP或者主机名    2.expires [modified] time;        expires epoch | max | off;        响应缓存的缓存时长        用于定义Expire或Cache-Control首部的值；</code></pre><h3 id="Nginx代理后端fastCGI协议"><a href="#Nginx代理后端fastCGI协议" class="headerlink" title="Nginx代理后端fastCGI协议"></a>Nginx代理后端fastCGI协议</h3><p><img src="/2018/03/22/nginx实现反向代理功能/LNMP的多种架构.png" alt="LA/NMP的几种架构"></p><pre><code>1.fpm其实就是一种类似于httpd的MPM模型中的prefork模型    启用一个fpm主进程，生成n个子进程，由子进程内部的php解释器负责处理并发的多路    请求，再将在本地运行完的php页面程序处理结果响应给请求的调用者2.fastcgi其实就是简装版的http协议，后端对应的php的fpm就是fastcgi协议的服务器后端    的解析fastcgi协议，而且还能够让fpm的子进程加载磁盘上的php程序文件在php解释器    中运行执行出结果3.Php并不支持编译成nginx的模块，那么Nginx只能调fastcgi模块与后端的fpm(php)服务器    进行通信，实现LNMP的架构4.真正与mysql等数据库通信的是php程序代码，即php到mysql的驱动模块，而不是php解释器5.如上图，因为fpm对进程的管理能力较弱，可以用nginx与全端调度器去连接，而且nginx可    以根据fastcgi处理请求的并发数，在nginx处限制向后端的请求连接数，nginx可以实现    中间件进行流量控制的效果.6.php管理自己子进程的方式有两种，static和dynamic动态和静态管理方式7.实现fpm的负载均衡调度，也是需要</code></pre><h3 id="ngx-http-fastcgi-module模块："><a href="#ngx-http-fastcgi-module模块：" class="headerlink" title="ngx_http_fastcgi_module模块："></a>ngx_http_fastcgi_module模块：</h3><pre><code>1.fastcgi_pass address;    address为fastcgi server的地址； location, if in location；    如：fastcgi_pass localhost:9000;    http://www.ilinux.io/admin/index.php --&gt; /admin/index.php (uri)        /data/application/admin/index.php2.fastcgi_index name;    fastcgi默认的主页资源; web的是index.html,php应该为index.php    如：fastcgi_index index.php3.fastcgi_param parameter value [if_not_empty];    1.由于动态站点在处理请求时，需要取得客户端在连接请求报文中的很多信息(IP,请求        方法,flag,param等)，所以nginx代理必须把保存在变量中与客户端连接状态的        数据，原样的传递给后端的fpm-server或fastcgi.    2.但是保存在nginx的变量名格式和fastcgi的变量名表示格式是不一样的，nginx的        是$+全小写的变量名，fpm是全大写的变量名    3.安装nginx默认就带有/etc/nginx/fastcgi_params,这个文件记录了需要向后端        fpm传递的所有变量.    4.除了传递变量，还需要将请求的uri与后端fpm服务器的路径建立映射关系，即定义        fpm上存放请求页面资源的真正路径.    配置示例：        比如先起一个fpm的容器：并且将动态资源保存在php容器的/data目录下        docker run --name php1 -d -v /data/php1:/data php:7-fpm-alpine    在nginx代理上如下设置：        location ~* \.php$ {            fastcgi_pass   172.17.0.4:9000;            fastcgi_index  index.php;            fastcgi_param  SCRIPT_FILENAME  /data$fastcgi_script_name;            include        fastcgi_params;        }</code></pre><h3 id="fpm的状态监控"><a href="#fpm的状态监控" class="headerlink" title="fpm的状态监控"></a>fpm的状态监控</h3><pre><code>4.php的状态监控    1.fpm的进程有static和dynamic两种管理方式，而且为了监控fpm是否正常工作，fpm的        配置文件中内嵌了/pm_status和/ping两个url来监控，status用来输出内嵌信息的        ，而默认是通过fastcgi协议显示的，不能直接看到状态信息，所以可以通过http协        议进行反代来检测fpm的工作状态.    2.可以通过显示监控状态的值，再通过ab,JMeter等工具进行压力测试，调整fpm的实际        场景下的并发访问量配置示例：通过/pm_status和/ping来获取fpm server状态信息；    location ~* ^/(status|ping)$ {            fastcgi_pass 172.17.0.2:9000;            fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;            include fastcgi_params;         }  测试： 如下图可以通过http://192.168.34.107:8082/status?xml&amp;full    或者html、json格式输出并显示出来，而且还可以通过接口调用加入到zabbix监控中</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/fpm状态监控.png" alt="fpm监控状态"> </p><h3 id="fastcgi的压力测试和缓存功能"><a href="#fastcgi的压力测试和缓存功能" class="headerlink" title="fastcgi的压力测试和缓存功能"></a>fastcgi的压力测试和缓存功能</h3><pre><code>a.fastcgi的动态资源缓存意义更大，因为php不用每次都执行代码了b.要使用缓存就需要先定义缓存；c.因为后端动态资源服务器是有用户认证和用户支付的资源的，为了信息安全对动态资源的缓    存一定不要缓存包含用户信息的资源定义缓存：和proxy的缓存是不能兼容的，需要单独定义(在server外,http的上下文定义)4.fastcgi_cache_path     path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number]     [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time]     [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time];    定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义；    levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE        leves=1:2:2    keys_zone=name:size        k/v映射的内存空间的名称及大小    inactive=time        非活动时长    max_size=size        磁盘上用于缓存数据的缓存空间上限调用缓存：        5.fastcgi_cache keys_zone的名称 | off;        调用指定的缓存空间来缓存数据；http, server, location        无定义默认使用的键，需要手动指定    6.fastcgi_cache_key string;        定义用作缓存项的key的字符串；              7.fastcgi_cache_methods GET | HEAD | POST ...;        为哪些请求方法使用缓存；               8.fastcgi_cache_min_uses number;        缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项；               9.fastcgi_cache_valid [code ...] time;        不同的响应码各自的缓存时长；    10.fastcgi_keep_conn on | off;        默认情况下，fastCGI响应一个请求后会立刻断开，如果是on状态会保持长连接fastcgi缓存定义示例：            http {        fastcgi_cache_path /data/cache/fcgi levels=1:2 keys_zone=fcgicache:10m max_size=2G;        server {            ...            location ~* \.php$ {            fastcgi_pass   172.17.0.4:9000;            fastcgi_index  index.php;            fastcgi_param  SCRIPT_FILENAME  /data$fastcgi_script_name;            include        fastcgi_params;            fastcgi_cache fcgicache;            fastcgi_cache_key $request_uri;            fastcgi_cache_valid 200 302 301 1h;            fastcgi_cache_valid any 1m;            fastcgi_cache_methods GET HEAD;        }缓存性能测试：                       ab -n 1000 -c 50 http://192.168.34.107:8082/index.php    在缓存前和缓存后通过模拟50路并发请求测试响应时间</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Nginx实现反向代理服务器的配置&quot;&gt;&lt;a href=&quot;#Nginx实现反向代理服务器的配置&quot; class=&quot;headerlink&quot; title=&quot;Nginx实现反向代理服务器的配置&quot;&gt;&lt;/a&gt;Nginx实现反向代理服务器的配置&lt;/h3&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现web服务配置</title>
    <link href="https://www.liukui.tech/2018/03/20/nginx%E5%AE%9E%E7%8E%B0web%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE/"/>
    <id>https://www.liukui.tech/2018/03/20/nginx实现web服务配置/</id>
    <published>2018-03-20T00:00:00.000Z</published>
    <updated>2019-01-26T06:28:48.699Z</updated>
    
    <content type="html"><![CDATA[<h3 id="nginx安装和配置文件"><a href="#nginx安装和配置文件" class="headerlink" title="nginx安装和配置文件"></a>nginx安装和配置文件</h3><p><a href="http://nginx.org/en/docs/" target="_blank" rel="noopener">Nginx下载安装和模块使用说明手册</a><br><a id="more"></a></p><pre><code>nginx安装：    源码编译,二进制安装，yum安装，要注意使用次版本为偶数的版本        nginx所说的高度模块化是指静态模块，如果编译安装了很多模块，启动时不管在配        置文件是否使用该模块，默认都是加载的，不过在Nginx的新版本中少量的动态模块        是可以按需加载的        而httpd是可以通过modprobe安装加载模块的配置文件的组成部分：    主配置文件：        /etc/nginx/nginx.conf 还包括 conf.d/*.conf和default.d/*.conf            对于同以功能的配置最好放到一个*.conf中，方便管理        /usr/lib/systemd/system/nginx.service   Unit file文件        /usr/sbin/nginx                         主程序文件        /usr/share/nginx/html/404.html        /usr/share/nginx/html/50x.html        /usr/share/nginx/html/index.html        页面文件            fastcgi， uwsgi，scgi等协议相关的配置文件            mime.types：支持的mime类型   启动和配置：    yum install nginx -y （编译时按需加载模块即可）    systemctl start nginx / nginx备注：    在生产环境下只要是修改nginx相关的配置文件,一定要nginx -t先进行测试    再nginx -s reload使配置文件生效配置：    主配置文件的配置指令：    指定生效的范围，三个上下文中        directive value [value2 ...];        注意：            (1) 指令必须以分号结尾；            (2) 支持使用配置变量；                内建变量：由Nginx模块引入，可直接引用；                自定义变量：由用户使用set命令定义；                    set variable_name value;                    引用变量：$variable_name主配置文件结构：        main block：主配置段，也即全局配置段；都是顶格写的        event {                ...            }：事件驱动相关的配置；        http {            server {}                root                proxy_pass            server {}            ...        }：http/https 协议相关的配置段；        mail {            ...        }        stream {            ...        }主配置段都不管是web服务、mail服务还是四层代理是都需要配置的，而且这三个功能一般是    不会一起使用的，至少http和mail功能是不一起使用的</code></pre><h3 id="Nginx的全局配置和优化必调参数项"><a href="#Nginx的全局配置和优化必调参数项" class="headerlink" title="Nginx的全局配置和优化必调参数项"></a>Nginx的全局配置和优化必调参数项</h3><pre><code>配置指令：    main配置段常见的配置指令：全局配置        分类：            正常运行必备的配置            优化性能相关的配置            用于调试及定位问题相关的配置            事件驱动相关的配置        正常运行必备的配置：    1、user，group,是默认运行nginx的用户和组，按需修改    2、pid /PATH/TO/PID_FILE;        指定存储nginx主进程进程号码的文件路径；    3、include file | mask;        指明包含进来的其它配置文件片断；    4、load_module file;        指明要装载的动态模块；性能优化相关的配置：    1、worker_processes number | auto;        worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数；        auto：当前主机物理CPU核心数；    2、worker_cpu_affinity cpumask ...;        worker_cpu_affinity auto [cpumask];        nginx进程的CPU亲缘性解释；        1.因为CPU有三级缓存，一级和二级是每个CPU所独有的，只有三级缓存是共享的；        2.将worker进程与cpu绑定，这个进程会在cpu本地缓存很多数据和状态信息        3.如果把这个进程调到其他cpu上，那么之前的缓存就失效了，从而影响了性能，而cpu的绑定则起到刚好的负载效果和性能        CPU MASK：            00000000：            0000 0001：0号CPU            0000 0010：1号CPU            0000 0100：2号CPU            0000 1000：3号CPU            ... ...            0000 0111：表示0和1号和2号CPU；    3、worker_priority number;        指定worker进程的nice值，设定worker进程优先级；[-20,19]                4、worker_rlimit_nofile number;        worker进程所能够打开的文件数量上限；        对于高并发的服务器来说至关重要，每一个连接都需要打开一个套接字，每一个套接        字的维持都需要一个文件描述符，默认情况下linux限制每个用户最多同时打开1024        个文件，所以并发数量很高时，并发数量受限于文件数量，因此对于高并发服务器来        说都需要修改ulimit数量(ulmit -a/-n number)事件驱动相关的配置:    events {        ...    }    1.worker_connections number;        事件驱动决定了单个worker进程所能够打开的最大并发连接数数量；        所以nginx最大并发连接上限=            [worker_processes] * [worker_connections]           在要求高并发的服务器上这两个是必调参数    2.use method;        指明并发连接请求的处理方法；            use epoll；是事件驱动模型得以运行的根本                       3.accept_mutex on | off;是否打开mutex互斥锁        处理新的连接请求的方法；            on意味着由各worker轮流处理新请求，默认为on            Off意味着每个新请求的到达都会通知所有的worker进程；会造成进程抢夺请求的情况调试、定位问题：    1、daemon on|off;            是否以守护进程方式运行Nignx；默认为on                2、master_process on|off;        是否以master/worker模型运行nginx；默认为on；        调试时，把只有主进程处理请求和以前台运行来查找错误原因              3、error_log file [level];        默认级别</code></pre><h3 id="Nginx实现web服务的全局配置和主要模块"><a href="#Nginx实现web服务的全局配置和主要模块" class="headerlink" title="Nginx实现web服务的全局配置和主要模块"></a>Nginx实现web服务的全局配置和主要模块</h3><pre><code>1.Nginx无论是作为web服务器或者是web服务器的代理服务器，所有配置都在http的上下文2.location和directory的区别    1.httpd和nginx作为web服务器都可以对用户访问的资源进行限制    2.&lt;Directory &quot;/var/www/html/images/&quot;&gt; 也可以写成        &lt;Location &quot;/images/&quot;&gt;</code></pre><h4 id="http协议的全局配置"><a href="#http协议的全局配置" class="headerlink" title="http协议的全局配置"></a>http协议的全局配置</h4><p>匹配检查顺序：server_name和Port–&gt;location–&gt;if in location–&gt;匹配路径(root和alias)</p><h4 id="ngx-http-core-module-Nginx的核心模块"><a href="#ngx-http-core-module-Nginx的核心模块" class="headerlink" title="ngx_http_core_module:Nginx的核心模块"></a>ngx_http_core_module:Nginx的核心模块</h4><p>Nginx不管作为什么功能，都要使用core核心模块</p><pre><code>http协议上下文的相关配置：    http {        ... ...  是http的全局配置，共享给多个server使用        server {            ...            listen            server_name            root/proxy_pass                 (root是作为web服务器的，proxy_pass是作为代理服务器使用的)            location [OPERATOR] /uri/ (类似于httpd的directory）                ...            }        }        server {            ...        }    }与套接字相关的配置：    1、server { ... }        配置一个虚拟主机；            server {            listen address[:PORT]|PORT;            server_name SERVER_NAME;            root /PATH/TO/DOCUMENT_ROOT;                                    }          server只能出现在http的上下文中，而且不能嵌套server    2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE          listen address[:port] [default_server] [ssl] [http2 | spdy]  [backlog=number] [rcvbuf=size] [sndbuf=size]        特殊设置：前两个尤为重要            default_server：设定为默认虚拟主机；                如httpd基于主机名配置的多个虚拟主机，访问时是由上而下匹配的            ssl：强制只能通过ssl连接提供服务；            backlog=number：后援队列长度；            rcvbuf=size：接收缓冲区大小；            sndbuf=size：发送缓冲区大小；(默认值足以满足需求)    3、server_name name ...;        必然要使用通配符来设置虚拟主机名和设置优先级        1.支持*通配任意长度的任意字符；server_name *.baidu.com  www.baidu.*        2.支持~起始的字符做正则表达式模式匹配；server_name ~^www\d+\.baidu\.com$   (\d匹配单个数字)        匹配机制优先级：            (1) 首先是字符串精确匹配;            (2) 左侧*通配符；            (3) 右侧*通配符；            (4) 正则表达式；            (并发访问多时，不建议使用正则表达式匹配主机名，对服务器性能有很大消耗)    4、tcp_nodelay on | off;        在keepalived模式下的连接是否启用TCP_NODELAY选项        当为off时，延迟发送，合并多个请求后再发送        默认On时，不延迟发送        可用于：http, server, location    5.tcp_nopush on|off;        在sendfile模式下，是否启用TCP_CORK选项；    5.sendfile on | off;        是否启用sendfile功能；和定义路径相关的配置：    6.root path;         设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径；        root可以作用在http, server, location, if in location上下文中，        如果多有多层级的root，则精确到最内层的root生效    7.location [ = | ^~ | ~ | ~* ] uri { ... }                    在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置；        用户请求server_name--&gt;server--&gt;Location--&gt;if in Location                    会根据正则表达式匹配的优先级匹配到一个最佳的路径    修饰符号： 修饰符匹配优先级：=, ^~, ~/~*，不带符号；        1.=：对URI做精确匹配；        2.^~：对URI的左半部分做匹配检查，不区分字符大小写；            左半部分是指scheme中不包含path和它之后的部分            如https://www.lk.tech/images/1.jpg的左半部分是https://www.lk.tech        3.~：对URI做正则表达式模式匹配，区分字符大小写；        4.~*：对URI做正则表达式模式匹配，不区分字符大小写；        5.不带符号：以URI为前缀的所有uri；通配性最高级location /                还可以在location中定义if这种三级路由选择        root /vhosts/www/htdocs/        http://www.lk.tech/index.html --&gt; /vhosts/www/htdocs/index.html         server {            root  /vhosts/www/htdocs/            location /admin/ {                root /webapps/app1/data/            }        }</code></pre><p>–官方示例<br><img src="/2018/03/20/nginx实现web服务配置/正则表达式优先级.png" alt="nginx的正则表达式优先级"></p><pre><code>    8.alias path;        定义路径别名，文档映射的另一种机制；仅能用于location上下文；        注意：location中使用root指令和alias指令的意义不同；            (a) root，给定的路径对应于location中的/uri/左侧的/；            (b) alias，给定的路径对应于location中的/uri/右侧的/；            如：                location /images/                 alias &quot;/data/www/&quot;;             alias定义的意思是即 /images/* = /data/www/*                location /images/ {                alias &quot;/data/www/&quot;;             root定义的意思就是访问 /data/www/images/*    9、设置默认主页：index file ...;        默认资源；http, server, location；    10、error_page code ... [=[response]] uri;       例如：error_page 404 /404.html;            location = /404.html {                root &quot;/www/error_pages&quot;;            }                           11、try_files file ... uri;        定义客户端请求的相关配置定义客户端请求的相关配置    12、keepalive_timeout timeout [header_timeout];        设定保持连接的超时时长，0表示禁止长连接；默认为75s；    13、keepalive_requests number;        在一次长连接上所允许请求的资源的最大数量，默认为100;     14、keepalive_disable none | browser ...;        对哪种浏览器禁用长连接；    15、send_timeout time;        向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长；    16、client_body_buffer_size size;        用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置；    17、client_body_temp_path path [level1 [level2 [level3]]];        设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量；            16进制的数字；            client_body_temp_path   /var/tmp/client_body  1 2 2                1：表示用一位16进制数字表示一级子目录；0-f                2：表示用2位16进程数字表示二级子目录：00-ff                2：表示用2位16进程数字表示三级子目录：00-ff对客户端进行限制的相关配置：    18、limit_rate rate;        限制响应给客户端的传输速率，单位是bytes/second，0表示无限制；    19、limit_except method ... { ... }        限制对指定的请求方法之外的其它方法的使用客户端；        limit_except GET {            allow 192.168.1.0/24;            deny  all;        } 文件操作优化的配置</code></pre><h4 id="访问控制和认证的两个模块"><a href="#访问控制和认证的两个模块" class="headerlink" title="访问控制和认证的两个模块"></a>访问控制和认证的两个模块</h4><pre><code>ngx_http_access_module模块：实现基于ip的访问控制功能，比httpd的控制更简单    1.allow address | CIDR | unix: | all;    2.deny address | CIDR | unix: | all;        http, server, location, limit_exceptngx_http_auth_basic_module模块    实现基于用户的访问控制，使用basic机制进行用户认证；    1.auth_basic string | off;    2.auth_basic_user_file file;    需要先生成账号密码，而且htpasswd命令由httpd-tools所提供；        htpasswd -c -m /data/.nginxpasswd tom        htpasswd -b -m /data/.nginxpasswd haha haha123        如：            location /admin/ {            auth_basic &quot;需要提供用户密码&quot;;(提示信息)            auth_basic_user_file /etc/nginx/.ngxpasswd;            }</code></pre><h4 id="ngx-http-stub-status-module模块：状态监控"><a href="#ngx-http-stub-status-module模块：状态监控" class="headerlink" title="ngx_http_stub_status_module模块：状态监控"></a>ngx_http_stub_status_module模块：状态监控</h4><pre><code>一般和监控系统一起用，可以在编译安装nginx时加上这个选项可以通过脚本函数监控这七个数值，纳入到zabbix中进行图形化监控为了不影响其他location，一般定义专用的location来监控nginx状态，放在server内即可用于输出nginx的基本状态信息；    Active connections: 291         当前的活动连接    server accepts handled requests  连接数，接收并处理的，，        16630948 16630948 31070465     Reading: 6 Writing: 179 Waiting: 106        中间三个是统计数据，其他四个是当前数据；        Active connections: 正在处理活动状态的连接数；        accepts：已经接受的客户端请求的总数；(tcp建立的连接数)        handled：已经处理完成的客户端请求的总数；(客户端发送，nginx处理过的)        requests：客户端发来的总的请求数；(建立tcp连接并发送的请求数)        Reading：处于读取客户端请求报文首部的连接的连接数；(接收报文)        Writing：处于向客户端发送响应报文过程中的连接数；(nginx发送报文)        Waiting：处于等待客户端发出请求的空闲连接数； (已经读取未发送的)        用于监控nginx的连接数脚本    1.stub_status;        配置示例：            location = /status {                stub_status;            }</code></pre><h4 id="ngx-http-log-module模块：日志分析展示"><a href="#ngx-http-log-module模块：日志分析展示" class="headerlink" title="ngx_http_log_module模块：日志分析展示"></a>ngx_http_log_module模块：日志分析展示</h4><p><a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#var_remote_addr" target="_blank" rel="noopener">nginx官方日志变量说明</a></p><pre><code>1.log_format name string ...;    string可以使用nginx核心模块及其它模块内嵌的变量；    日志格式：        $remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;              &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;              &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;        http_x_forward_for 表示被代理服务器的日志记录的访问的IP地址是代理服务器，为了在后端服务器上记录真实的客户端，需要启用这一项    实现：1.为nginx定义使用类似于httpd的combined格式的访问日志；         2.把combined的日志格式定义输出成json格式(KV键值对)2.access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];    access_log off;    访问日志文件路径，格式及相关的缓冲的配置；        buffer=size        flush=time 3.open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];    open_log_file_cache off;    缓存各日志文件相关的元数据信息；    max：缓存的最大文件描述符数量；    min_uses：在inactive指定的时长内访问次数低于min_uses就认为是无效的；    inactive：非活动时长；    valid：验正缓存中各缓存项是否为活动项的时间间隔；检查inactive的间隔</code></pre><h4 id="ngx-http-gzip-module：文本资源压缩传输节约带宽"><a href="#ngx-http-gzip-module：文本资源压缩传输节约带宽" class="headerlink" title="ngx_http_gzip_module：文本资源压缩传输节约带宽"></a>ngx_http_gzip_module：文本资源压缩传输节约带宽</h4><pre><code>在CPU等硬件资源不稀缺的情况下，带宽流量的稀缺使得资源压缩必须启用启用资源压缩功能，虽然可以大大减小了带宽的消耗，要注意适用的场景；    1.比如当前服务器CPU负载较大，压缩功能本身就会消耗更多的CPU资源，如果启用        对服务器的压力就会更大    2.应该只对文本内容进行压缩，视频、图片、流媒体等本身就已经是有压缩比的资源    3.实现逻辑：先使用压缩过滤器过滤出来有很好压缩比的资源(css,js,html)等文本        再定义压缩规则    1.gzip on | off;        需要先开启gzip压缩功能    2.gzip_comp_level level;        设置压缩比1~9,压缩比越大对CPU的消耗越大    3.gzip_disable regex ...;         过滤User_Agent浏览器类型，禁用较老的浏览器版本不启用压缩功能。    4.gzip_min_length length;        当响应报文大小达到某个值，才压缩，太小就不值得压缩了        比如：低于100k不压缩，高于这个值才进行资源压缩，单位:byte字节    5.gzip_buffers number size;        支持实现压缩功能时为其配置的缓冲区数量(number)及每个缓存区的大小(size)；        在服务器的内存资源充沛时，启用缓冲区可以更快的对资源进行压缩    6、gzip_proxied off | expired | no-cache | no-store | private |         no_last_modified | no_etag | auth | any ...;        nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的；            off：对代理的请求不启用            no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能；            any:任何内容不压缩    7.gzip_types mime-type ...;        压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能；        过滤需要压缩的类型，纯文本和html不需要，因为默认就对其压缩    示例：        gzip  on;        gzip_comp_level 6;        gzip_min_length 64;        gzip_proxied any;        gzip_types text/xml text/css  application/javascript; </code></pre><h4 id="ngx-http-ssl-module模块："><a href="#ngx-http-ssl-module模块：" class="headerlink" title="ngx_http_ssl_module模块："></a>ngx_http_ssl_module模块：</h4><pre><code>如上图，代理服务用nginx不采用LVS的一个原因就是LVS不支持SSL的代理，nginx可以实现    面对客户端使用https协议，面对后端服务器集群使用http协议，所以有时nginx反代也叫https的会话卸载器如果是四层调度，https访问必须是客户端与后端服务器之间建立；如果两段式连接，对内调度是明文的，把压力放在前端代理服务器上，本身前端调度器岁CPU资源消耗不是很大    1.ssl on | off;        Enables the HTTPS protocol for the given virtual server.      2.ssl_certificate file;        当前虚拟主机使用PEM格式的证书文件；    3.ssl_certificate_key file;        当前虚拟主机上与其证书匹配的私钥文件；    4.ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2];        支持ssl协议版本，默认为后三个；    5.ssl_session_cache off | none | [builtin[:size]] [shared:name:size];        nginx的ssl会话有两种：        1.builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有；        2.[shared:name:size]：在各worker之间使用一个共享的缓存；        ssl的session建立是很慢的,所以要启用ssl的缓存，而且还是shared类型的共享缓存方式    6、ssl_session_timeout time;        客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长；实现https加密：            生成私钥和证书：        openssl genrsa -out nginx.key 2048        openssl req -new -x509 -key nginx.key -out nginx.crt -days 3650 -subj &quot;/CN=www.lk.tech&quot;    配置https主体：        server {            listen 443 ssl;            server_name www.lk.tech;            root /data/lk;            ssl on;            ssl_certificate /etc/nginx/ssl/nginx.crt;            ssl_certificate_key /etc/nginx/ssl/nginx.key;            ssl_session_cache shared:sslcache:20m;            ssl_session_timeout 10m;        }                           </code></pre><h4 id="ngx-http-rewrite-module模块：实现URL重写"><a href="#ngx-http-rewrite-module模块：实现URL重写" class="headerlink" title="ngx_http_rewrite_module模块：实现URL重写"></a>ngx_http_rewrite_module模块：实现URL重写</h4><p><img src="/2018/03/20/nginx实现web服务配置/官网rewrite1.png" alt="rewrite官方示例1"><br><img src="/2018/03/20/nginx实现web服务配置/官网rewrite2.png" alt="rewrite官方示例2"></p><pre><code>什么是url重写？为什么要用到url重写？    1.客户端访问URL被重写到另外一个路径了    http://www.lk.tech/photos/1.jpg ---&gt; http://images.lk.tech/1.jpg    2.全站ssl加密时，将用户访问的http://请求全部被重写到https://的虚拟主机上    http://www.lk.tech/images/1.jpg---&gt;https://www.lk.tech/1.jpgrewirte的处理逻辑：    1.将用户请求的URL基于(regex)正则表达式的查找，而后完成替换即可(replacement)    2.如果出现server中两个location互相rewrite，则会出现死循环的现象，所以就引入        了last和break的两个机制    3.last表示接着检查其他rewrite，break表示匹配到当前的rewrite.就不检查其他的        rewrite了这样就避免了死循环。1.rewrite regex replacement [flag]    a.将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement        指定的新的URI；    b.rewrite重写的路径可以是相对路径也可以是绝对路径    注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制；    如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端    ；用的比较多的是301和302        301：permanent,永久重定向；        302：redirect,临时重定向；    [flag]：        last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环；         break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环；        redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；302        permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；301       2.return：类似于重定向的操作    return code [text];    return code URL;    return URL;    Stops processing and returns the specified code to a client. 3.rewrite_log on | off;    是否开启重写日志；可能出现安全风险，所以没有必要时不用开启4.if (condition) { ... }    引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令；    一般用于server, location；    condition：        比较操作符：            ==            !=            ~：模式匹配，区分字符大小写；            ~*：模式匹配，不区分字符大小写；            !~：模式不匹配，区分字符大小写；            !~*：模式不匹配，不区分字符大小写；        文件及目录存在性判断：            -e, !-e            -f, !-f            -d, !-d            -x, !-x            5.set $variable value;    用户自定义变量；示例：    location ~* ^/(photos|pictures) {    ##      rewrite ^/photos/(.*)$ /image/$1 last;    #       rewrite ^/photos/(.*)$ http://images.lk.tech:8081/$1;    #       rewrite ^/(photos|pictures)/(.*)$ http://images.lk.tech:8081/$2 permanent;                                       #       }</code></pre><p>-redirect和permanent的示例演示<br><img src="/2018/03/20/nginx实现web服务配置/rewrite规则.png" alt="rewrite机制"></p><h4 id="ngx-http-referer-module模块：网站防盗链"><a href="#ngx-http-referer-module模块：网站防盗链" class="headerlink" title="ngx_http_referer_module模块：网站防盗链"></a>ngx_http_referer_module模块：网站防盗链</h4><pre><code>检查客户端的请求数据报文首部，实际就是防盗链的过滤器，所以在日志中记录referer    referer来源：        1.        2.    1.valid_referers none | blocked | server_names | string ...;        定义referer首部的合法有效的值            none：请求报文首部没有referer首部；        blocked：请求报文的referer首部没有值；        server_names：参数，其可以有值作为主机名或主机名模式；            arbitrary_string：直接字符串，但可使用*作通配符；            regular expression：被指定的正则表达式模式匹配到的字符串；                要使用~打头，例如 ~.*\.lk.com；使用说明和示例：    先定义valid_referers的允许连接网站，再通过if判断如果不是在    valid_referers中定义的网站，就返回一张图片或者文字说明        valid_referers none block server_names *.lk.com lk.* ~\.lk\.;        if ($invalid_referer) {            return http://www.lk.tech/hello.html;        } </code></pre><p><img src="/2018/03/20/nginx实现web服务配置/referer防盗机制.png" alt="referer防盗机制"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;nginx安装和配置文件&quot;&gt;&lt;a href=&quot;#nginx安装和配置文件&quot; class=&quot;headerlink&quot; title=&quot;nginx安装和配置文件&quot;&gt;&lt;/a&gt;nginx安装和配置文件&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://nginx.org/en/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Nginx下载安装和模块使用说明手册&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>ansible</title>
    <link href="https://www.liukui.tech/2018/03/06/ansible/"/>
    <id>https://www.liukui.tech/2018/03/06/ansible/</id>
    <published>2018-03-05T16:00:00.000Z</published>
    <updated>2019-01-07T11:23:00.413Z</updated>
    
    <content type="html"><![CDATA[<h1 id="运维自动化管理工具之Ansible"><a href="#运维自动化管理工具之Ansible" class="headerlink" title="运维自动化管理工具之Ansible"></a>运维自动化管理工具之Ansible</h1><p><img src="/2018/03/06/ansible/ansible.png" alt=""><br><a id="more"></a></p><h3 id="内容：1-软件发布环境机制优势对比-和-2-ansible的应用"><a href="#内容：1-软件发布环境机制优势对比-和-2-ansible的应用" class="headerlink" title="内容：1.软件发布环境机制优势对比  和   2.ansible的应用"></a>内容：1.软件发布环境机制优势对比  和   2.ansible的应用</h3><p><font color="#FF0000">ansible的相关的文档</font><br>ansible的中文权威指南：<a href="http://ansible.com.cn/" target="_blank" rel="noopener">ansible中文指南</a><br>Github上的ansible-galaxy示例：<a href="http://galaxy.ansible.com" target="_blank" rel="noopener">ansible-galaxy</a></p><p>其他相关运维管理工具使用方法：<br>pssh的使用方法参照链接文章：<a href="https://www.jianshu.com/p/d15b6b8f17a5" target="_blank" rel="noopener">pssh</a><br>saltstack介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">saltstack</a><br>puppet介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">puppet</a></p><pre><code>当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric常用自动化运维工具    PSSH：适用于主机数量很少的环境(基础ssh的key验证)    Ansible:python,Agentless,中小型应用环境(自带代理功能)    Saltstack:python，一般需部署agent，执行效率更高    Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境    Fabric：python，agentless    Chef: ruby,国内应用少    Cfengine    func</code></pre><h3 id="发布更新环境"><a href="#发布更新环境" class="headerlink" title="发布更新环境"></a>发布更新环境</h3><h4 id="灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机"><a href="#灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机" class="headerlink" title="灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)"></a>灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)</h4><pre><code>比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器    而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径     如：     软件路径为:/data/app     正在用的软件版本V1.0：/data/app1.0     更新的软件版本V2.0：/data/app2.0    则需要把删除原来的软链接：/data/app1.0---&gt;/data/app    创建新的软链接：/data/app2.0---&gt;/data/app10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线发布步骤：    1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。    2.从负载均衡列表中移除掉「金丝雀」服务器。    3.升级「金丝雀」应用（排掉原有流量并进行部署）。    4.对应用进行自动化测试。    5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。    6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。A/B Testing    A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。优势与不足：    优势：用户体验影响小，灰度发布过程出现问题只影响少量用户    不足：发布自动化程度不够，发布期间可引发服务中断预发布验证：    新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器灰度发布：    可以基于主机，用户或者业务，又细分为地区，VIP和普通用户</code></pre><h4 id="蓝绿发布：核心：主备两套环境"><a href="#蓝绿发布：核心：主备两套环境" class="headerlink" title="蓝绿发布：核心：主备两套环境"></a>蓝绿发布：核心：主备两套环境</h4><pre><code>定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同     时也升级到新版本主：绿色环境-活动环境：负责对外提供服务，版本：v1.0备：绿色环境-非活动环境：版本：v2.0工作机制：    先把备环境升级v1.0---&gt;v2.0版本，然后上线    把主环境的v1.0版本下线，已经升级的备环境进行替换特点：    蓝绿部署无需停机，并且风险较小.注意事项：    1.需要提前考虑数据库与应用部署同步迁移/回滚的问题    2.蓝绿部署需要有基础设施支持    3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境      和绿色环境有被摧毁的风险.优势与不足：    优势：升级切换和回退速度非常快    不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响</code></pre><h4 id="滚动发布：在灰度发布的基础上进行进一步优化"><a href="#滚动发布：在灰度发布的基础上进行进一步优化" class="headerlink" title="滚动发布：在灰度发布的基础上进行进一步优化"></a>滚动发布：在灰度发布的基础上进行进一步优化</h4><pre><code>定义：    一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式.特点：    1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数.  可以部分部署，例如每次只取出集群的20%进行升级。    2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出优势和不足:    优势：用户体验影响小，体验较平滑    不足：发布和回退时间比较缓慢。         发布工具比较复杂，LB需要平滑的流量摘除和拉入能力滚动发布目前成熟型技术组织所采用的主流发布方式</code></pre><h1 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h1><p><img src="/2018/03/06/ansible/ansible架构.png" alt="ansible架构"></p><h4 id="ansible特性：-最多管理500台主机，更多效率会降低"><a href="#ansible特性：-最多管理500台主机，更多效率会降低" class="headerlink" title="ansible特性：-最多管理500台主机，更多效率会降低"></a>ansible特性：-最多管理500台主机，更多效率会降低</h4><pre><code>1.模块化：调用特定的模块，完成特定任务   -类似linux中的小命令2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块3.支持自定义模块4.基于Python语言实现5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务)6.安全，基于OpenSSH7.支持playbook编排任务   -类似于脚本功能，多个脚本的集合成为Roles8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况9.无需代理不依赖PKI（无需ssl）10.可使用任何编程语言写模块11.YAML格式，编排任务，支持丰富的数据结构12.较强大的多层解决方案</code></pre><h3 id="Ansible的学习过程："><a href="#Ansible的学习过程：" class="headerlink" title="Ansible的学习过程："></a>Ansible的学习过程：</h3><pre><code>1.ansible基本命令使用2.ansible常用模块详解，介绍ansible单个命令的使用3.YAML语法介绍4.ansible playbook基础：剧本初体验，类似于写脚本5.playbook中的变量：tags，handlers使用6.plsybook模板：templates7.playbook的条件判断：when8.playbook的字典：with_items9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合</code></pre><p>会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。</p><h3 id="ansible命令执行过程"><a href="#ansible命令执行过程" class="headerlink" title="ansible命令执行过程"></a>ansible命令执行过程</h3><pre><code>ansible命令执行过程1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg2. 加载自己对应的模块文件，如command3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件4. 给文件+x执行5. 执行并返回结果6. 删除临时py文件，sleep 0退出执行状态：(颜色定义在/etc/ansible/ansible.cfg中)    绿色：执行成功并且不需要做改变的操作    黄色：执行成功并且对目标主机做变更    红色：执行失败</code></pre><h3 id="CMDB作用介绍"><a href="#CMDB作用介绍" class="headerlink" title="CMDB作用介绍:"></a>CMDB作用介绍:</h3><pre><code>CMDB:Configuration Management Database 配置管理数据库        将服务器的配置，网络配置写到数据库里CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管理等流程提供准确的配置信息.</code></pre><p>了解更多CMDB可参照文章：<a href="">CMDB</a></p><h2 id="1-ansible基本命令使用"><a href="#1-ansible基本命令使用" class="headerlink" title="1.ansible基本命令使用"></a>1.ansible基本命令使用</h2><h3 id="ansible软件安装：多种安装方法"><a href="#ansible软件安装：多种安装方法" class="headerlink" title="ansible软件安装：多种安装方法"></a>ansible软件安装：多种安装方法</h3><pre><code>1.基于epel源安装：    yum install ansible,非服务，只是一个管理工具2.编译安装：3.Github方式安装：可以同步安装4.pip安装：pip是安装Python包的管理器，类似yum</code></pre><h4 id="ansible的重要-amp-主要文件"><a href="#ansible的重要-amp-主要文件" class="headerlink" title="ansible的重要&amp;主要文件"></a>ansible的重要&amp;主要文件</h4><pre><code>配置文件：    /etc/ansible/ansible.cfg  配置ansible的工作特性    /etc/ansible/hosts  主机清单    /etc/ansible/roles  存放的角色目录程序文件：    /usr/bin/ansible   ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想    /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助    /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台    /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务    /usr/bin/ansible-vault 文件加密工具    /usr/bin/ansible-console 基于Console界面与用户交互的执行工具常用命令：    ansible all --list 查看ansible管理的主机群    ansible all -m &quot;模块名&quot; -a &apos;执行的命令&apos;   用什么模块执行什么命令        all也可以换成定义的--list中组的名字    ansible-playbook -C &apos;*.yml&apos; 对所有主机执行剧本    ansible-plsybook -C -t &apos;标签&apos; &apos;*.yml&apos; 对所有主机执行哪个标签的剧本</code></pre><h4 id="ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法"><a href="#ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法" class="headerlink" title="ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)"></a>ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)</h4><pre><code>支持不分组，分组，等方式    如：        192.168.34.100        [webservers]        192.168.34.101        192.168.34.102        [dbservers]        192.168.34.[1:6]7 (17,27..67)        db[01:100].cenntos.com</code></pre><h4 id="ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）"><a href="#ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）" class="headerlink" title="ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）"></a>ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）</h4><pre><code>配置文件只提供默认值，但可以通过playbook的设置进行覆盖配置文件可以放在/etc/ansible/ansible.cfg中也可以放到一个工作目录下命名为.ansible.cfg[defaults]inventory = /etc/ansible/hosts - 主机列表配置文件library = /usr/share/my_modules/ - 库文件存放目录remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录forks = 5 - 默认并发数sudo_user = root - 默认sudo 用户ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码ask_pass = Trueremote_port = 22host_key_checking = False  -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错[color] 定义ansible命令的执行结果颜色的</code></pre><h3 id="配置文件说明和建议修改的项："><a href="#配置文件说明和建议修改的项：" class="headerlink" title="配置文件说明和建议修改的项："></a>配置文件说明和建议修改的项：</h3><pre><code>local_tmp和remote_tmp：    本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地    家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除.host_key_checking = False -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错module_name = command   -默认使用的命令模块，可以修改成shell    module_name = shell</code></pre><h2 id="2-ansible常用模块详解，介绍ansible单个命令的使用"><a href="#2-ansible常用模块详解，介绍ansible单个命令的使用" class="headerlink" title="2.ansible常用模块详解，介绍ansible单个命令的使用"></a>2.ansible常用模块详解，介绍ansible单个命令的使用</h2><h3 id="ansible模块的使用查询方法"><a href="#ansible模块的使用查询方法" class="headerlink" title="ansible模块的使用查询方法"></a>ansible模块的使用查询方法</h3><pre><code>ansible-doc: 显示模块帮助ansible-doc [options] [module...]    -a 显示所有模块的文档    -l, --list 列出可用模块    -s, --snippet显示指定模块的playbook片段示例：    ansible-doc –l 列出所有功能模块    ansible-doc ping 查看ansible中的ping用法    ansible-doc -s shell 查看shell模块的使用方法</code></pre><h3 id="ansible的常用基本选项"><a href="#ansible的常用基本选项" class="headerlink" title="ansible的常用基本选项"></a>ansible的常用基本选项</h3><pre><code>ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible    端能基于密钥认证的方式联系各被管理节点ansible语法：    ansible &lt;host-pattern&gt; [-m module_name] [-a args]    --version 显示版本    -m module 指定模块，默认为command，主要使用选项    -v 详细过程 –vv -vvv更详细    --list-hosts 显示主机列表，可简写 --list    -k, --ask-pass 提示输入ssh连接密码，默认Key验证    -K, --ask-become-pass 提示输入sudo时的口令    -C, --check 检查，并不执行    -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s    -u, --user=REMOTE_USER 执行远程执行的用户    -b, --become 代替旧版的sudo 切换</code></pre><h3 id="ansible的主机清单表示方法-Host-pattern"><a href="#ansible的主机清单表示方法-Host-pattern" class="headerlink" title="ansible的主机清单表示方法:Host-pattern"></a>ansible的主机清单表示方法:Host-pattern</h3><pre><code>1.All ：表示所有Inventory中的所有主机    如：ansible all -m ping        ansible all --list-hosts列出所有主机清单        ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP2.* :通配符    如：ansible &quot;*&quot; = ansible all        ansible 192.168.34.* 表示34网段的所有IP3.或的关系    如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作        ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作4.与的关系(且)    如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机5.非，取反    如：ansible &apos;websrvs:!dbsrvs&apos;        在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号6.正则表达式    如：ansible &quot;~(web|db).*\.centos\.com&quot; </code></pre><h2 id="ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块"><a href="#ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块" class="headerlink" title="ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)"></a>ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)</h2><h5 id="ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项"><a href="#ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项" class="headerlink" title="ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项"></a>ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项</h5><pre><code>1.Command：在远程主机执行命令，默认模块，可忽略-m选项    可以在ansible.cfg中修改默认模块项    支持：chdir(切换目录)    command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现使用示例：    ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh    ansible all -a &apos;useradd test&apos; 所有主机上创建test用户2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项    支持功能：支持$ &lt; &gt; | ; &amp; 等            chdir 执行前，先切换到该文件夹示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos;        显示appsrvs组的主机名    ansible all -m shell -a &apos;chdir=/data rm -rf *&apos;    先切换到/data目录下，再执行删除命令3.Script: 批量运行脚本    可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理    功能：creates:远程主机的文件存在，则不运行        removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令示例：ansible all -m script -a &quot;/data/test.sh&quot;    ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot;        因为fstab文件存在，则不执行rm -rf /data/*命令    ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot;        因为fstab文件存在，则执行rm -rf /data/*命令4.Copy:从服务器复制文件到目标主机    src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos;    根据自己写的字符串生成文件5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取    src，dest(抓取到本机目录)示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;        将远程主机fstab2文件抓取到本机/data下    如果抓取的是目录，先打包再抓取    打包：ansible all -a &apos;tar cf /root/data.tar /data&apos;     抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;6.File：设置文件属性，创建/删除文件    src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos;     创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos;     删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos;7.Hostname：管理主机名     可以通过后面的变量来实现    a.先在hosts后定义hostname变量名        [centos6]        192.168.34.106 hostname=mini6-2        192.168.34.101 hostname=node6-1         [centos7]        192.168.34.107 hostname=mini7-1    b.再通过hostname模块批量修改        ansible all -m hostname -a &apos;name={{hostname}}&apos;8.Cron：计划任务    支持：minute，hour，day，month，weekday示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate        172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务     ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名     ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名9.Yum：管理包    支持：name,state=(started stopped reloaded restarted),absent    更新缓存：update_cache=yes，示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包      ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包10.Service：管理服务(同一systemctl&amp;service)    name，state(stopped,started,reloaded,restarted) enable(设置开启启动)示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务     ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务     ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务     ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动11.User：管理用户    name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录)示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos;    创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录12.Group：管理组    支持：group,name,gid,system,state=(absent)示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组    ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 </code></pre><h2 id="ansible系列的一些模块-用的不多"><a href="#ansible系列的一些模块-用的不多" class="headerlink" title="ansible系列的一些模块(用的不多)"></a>ansible系列的一些模块(用的不多)</h2><pre><code>简单介绍与了解：ansible-galaxy 互联网上的角色分享ansible-pull      推送命令至远程，效率无限提升，对运维要求较高  Ansible-vault管理yaml文件    功能：管理加密解密yml文件        ansible-vault [create|decrypt|edit|encrypt|rekey|view]        ansible-vault encrypt hello.yml 加密        ansible-vault decrypt hello.yml 解密        ansible-vault view hello.yml 查看        ansible-vault edit hello.yml 编辑加密文件        ansible-vault rekey hello.yml 修改口令        ansible-vault create new.yml 创建新文件Ansible-console</code></pre><h2 id="ansible重要知识之playbook-上面的各种模块的组合"><a href="#ansible重要知识之playbook-上面的各种模块的组合" class="headerlink" title="ansible重要知识之playbook(上面的各种模块的组合)"></a>ansible重要知识之playbook(上面的各种模块的组合)</h2><p><img src="/2018/03/06/ansible/" alt="playbook原理"></p><h3 id="YAML语言（编写playbook的专门语言）"><a href="#YAML语言（编写playbook的专门语言）" class="headerlink" title="YAML语言（编写playbook的专门语言）"></a>YAML语言（编写playbook的专门语言）</h3><pre><code>YAML语法：     在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三    个点号( ... )用来表示档案结尾    次行开始正常写Playbook的内容，一般建议写明该Playbook的功能    使用#号注释代码    缩进必须是统一的，不能空格和tab混用    缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过    缩进结合换行来实现的    YAML文件内容是区别大小写的，k/v的值均需大小写敏感    k/v的值可同行写也可换行写。同行使用:分隔    v可是个字符串，也可是另一个列表    一个完整的代码块功能需最少元素需包括 name: task    一个name只能包括一个task    YAML文件扩展名通常为yml或yaml    List：列表，其所有元素均使用“-”打头    Dictionary：字典，通常由多个key与value构成</code></pre><h2 id="Playbook中的核心元素"><a href="#Playbook中的核心元素" class="headerlink" title="Playbook中的核心元素:"></a>Playbook中的核心元素:</h2><pre><code>1.Hosts 执行的远程主机列表2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远    程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使    用sudo_user指定sudo时切换的用户3.Tasks 任务集4.Varniables 内置变量或自定义变量在playbook中调用5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断8.handlers和notify  </code></pre><h2 id="运行playbook"><a href="#运行playbook" class="headerlink" title="运行playbook"></a>运行playbook</h2><pre><code>运行playbook的方式ansible-playbook &lt;filename.yml&gt; ... [options]常见选项    -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测    --list-hosts 列出运行任务的主机    --limit 主机列表 只针对主机列表中的主机执行    -v 显示过程 -vv -vvv 更详细 备注：    执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误    ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行</code></pre><h3 id="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"><a href="#执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。" class="headerlink" title="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"></a>执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。</h3><h2 id="示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验"><a href="#示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验" class="headerlink" title="示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验"></a>示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验</h2><h4 id="将centos7的httpd-conf复制到centos7主机，6上的配置文件不同"><a href="#将centos7的httpd-conf复制到centos7主机，6上的配置文件不同" class="headerlink" title="将centos7的httpd.conf复制到centos7主机，6上的配置文件不同"></a>将centos7的httpd.conf复制到centos7主机，6上的配置文件不同</h4><pre><code>示例1：写一个安装启动httpd的playbook:install_httpd.yml        包括创建用户，安装httpd包，开启服务，并设置开机启动- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd    - name: copy config      copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf    - name: install package      yum: name=httpd    - name: service      service: name=httpd state=started enabled=yes备注：    执行完通过以下命令判断每个任务都否都执行成功了    1.ansible all -a &apos;getent passwd httpd&apos;    2.ansible all -a &apos;rpm -q httpd&apos;    3..ansible all -a &apos;ss -ntlp|grep 80&apos;示例2：写一个删除上面的playbook:remove_httpd.yml        包括：删除用户，卸载httpd包- hosts: all  remote_user: root  tasks:    - name: del user      user: name=httpd state=absent remove=yes    - name: remove package      yum: name=httpd state=absent备注：    如果只删除特定主机的httpd，而不是全部，需要加--limit选项    ansible-playbook --limit 192.168.34.105 remove_httpd.yml        只限制在192.168.34.105的主机执行</code></pre><h4 id="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"><a href="#上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。" class="headerlink" title="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"></a>上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。</h4><h3 id="handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。"><a href="#handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。" class="headerlink" title="handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。"></a>handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。</h3><pre><code>Handlers:    是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生        变化时，才会采取一定的操作Notify:    此action可用于在每个play的最后被触发，这样可避免多次有改变发生    时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。    在notify中列出的操作称为handler，也即notify中调用handler中定义的操作</code></pre><h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><pre><code>示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200）- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted 备注：停止并删除用户和安装包    ansible all -a &apos;service memcached stop&apos;    ansible all -a &apos;ss -ntl&apos;    ansible all -a &apos;rpm -q memcached&apos;    ansible all -a &apos;getent passwd memcached&apos;</code></pre><h3 id="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"><a href="#可以多个notify对应一个handlers，也可以多个motify对应多个handlers" class="headerlink" title="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"></a>可以多个notify对应一个handlers，也可以多个motify对应多个handlers</h3><pre><code>示例4：多个notify对应一个handlers- hosts: websrvs  remote_user: root  tasks:    - name: Install httpd      yum: name=httpd state=present    - name: Install configure file      copy: src=files/httpd.conf dest=/etc/httpd/conf/      notify: restart httpd  第一个notify    - name: ensure apache is running      service: name=httpd state=started enabled=yes      notify: restart httpd  第二个notify  handlers:      - name: restart httpd   对应一个handlers      service: name=httpd status=restarted</code></pre><h3 id="示例5：多个notify对应多个handlers"><a href="#示例5：多个notify对应多个handlers" class="headerlink" title="示例5：多个notify对应多个handlers"></a>示例5：多个notify对应多个handlers</h3><pre><code>- hosts: websrvs  remote_user: root  tasks:    - name: config      copy: src=/root/config.txt dest=/etc/nginx/nginx.conf      notify:        - Restart Nginx        - Check Nginx Process  多个notify的写法  handlers:    - name: Restart Nginx     对应写多个handlers      service: name=nginx state=restarted enabled=yes    - name: Check Nginx process      shell: killall -0 nginx &gt; /tmp/nginx.log</code></pre><h3 id="tags的用法：作用：挑选某一段的task来执行"><a href="#tags的用法：作用：挑选某一段的task来执行" class="headerlink" title="tags的用法：作用：挑选某一段的task来执行"></a>tags的用法：作用：挑选某一段的task来执行</h3><pre><code>将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行然后执行：ansible-plsybook -t ceshi install_memcached.yml        只会触发拷贝文件和handlers的动作---#test yaml file- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致      tags: ceshi   对拷贝动作加一个标签    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted</code></pre><h2 id="Playbook中变量使用-可以多出定义，但是存在优先级"><a href="#Playbook中变量使用-可以多出定义，但是存在优先级" class="headerlink" title="Playbook中变量使用:可以多出定义，但是存在优先级"></a>Playbook中变量使用:可以多出定义，但是存在优先级</h2><h4 id="优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量"><a href="#优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量" class="headerlink" title="优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量"></a>优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量</h4><pre><code>变量名：仅能由字母、数字和下划线组成，且只能以字母开头变量来源：1 ansible setup facts 远程主机的所有变量都可直接调用    setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的        代码块，然后用代码块当变量    比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的          ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量3 通过命令行指定变量，优先级最高    可以对单个变量赋值：ansible-playbook –e varname=value     也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot;4 在playbook中定义    vars:         - var1: value1         - var2: value25 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件            很适合在roles中进行单独定义6 在role中定义（下文中有介绍）</code></pre><h3 id="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令"><a href="#从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令" class="headerlink" title="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令"></a>从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令</h3><p>#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作<br>        ansible_fqdn 主机名的变量<br>        ansible_hostname 主机名<br>        ansible_distribution_major_version: “6” 版本名变量<br>        ansible_processor_vcpus 虚拟cpu个数变量<br>        ansible_memtotal_mb 内存的变量<br>    示例：<br>    ansible all -m setup -a “filter=ansible_memtotal_mb”<br>        用此命令来查看系统内变量的值</p><h4 id="调用不同变量来源的示例：得出变量的优先级顺序"><a href="#调用不同变量来源的示例：得出变量的优先级顺序" class="headerlink" title="调用不同变量来源的示例：得出变量的优先级顺序"></a>调用不同变量来源的示例：得出变量的优先级顺序</h4><pre><code>示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml- hosts: all  remote_user: root  tasks:    - name: touch file      file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量    /etc/ansible/hosts：中定义的变量：        [websrvs]        192.168.34.105 port1=80        192.168.34.106 port1=90   -普通变量        [websrvs:vars]   -公共组变量        mark=&quot;-&quot;        [appsrvs]        192.168.34.101 port1=100        [appsrvs:vars]        mark=&quot;=&quot;    vars.yml中书写格式：        - hosts: all          remote_user: root          tasks:            - name: touch file              file: name=/data/app{{mark}}{{ port1 }}.log state=touch最后生成的文件为：            app=100.log，app-80.logapp-90.log示例3：在示例1的基础上，再通过命令行中定义变量:    在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果：    ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml    可以看出，最后新建的文件名为hahaha.log示例4：在playbook中定义变量    - hosts: all      remote_user: root      vars:        - port1: 200        - mark: +++      tasks:        - name: touch file          file: name=/data/app{{mark}}{{ port1 }}.log state=touch    生成的文件：        app+++200.log示例5：先写在var.yml中定义变量，    1.先准备cat vars.yml:文件内容格式        var1: httpd        var2: nginx    2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义        - hosts: web          remote_user: root          vars_files:            - vars.yml         tasks:           - name: create httpd log             file: name=/app/{{ var1 }}.log state=touch           - name: create nginx log             file: name=/app/{{ var2 }}.log state=touch</code></pre><h2 id="模板templates，作用："><a href="#模板templates，作用：" class="headerlink" title="模板templates，作用："></a>模板templates，作用：</h2><pre><code>文本文件，嵌套有脚本（使用模板编程语言编写）Jinja2语言，使用字面量，有下面形式字符串：使用单引号或双引号数字：整数，浮点数列表：[item1, item2, ...]元组：(item1, item2, ...)字典：{key1:value1, key2:value2, ...}布尔型：true/false算术运算：+, -, *, /, //, %, **比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;=逻辑运算：and, or, not流表达式：For If When</code></pre><h3 id="templates功能：根据模块文件动态生成对应的配置文件"><a href="#templates功能：根据模块文件动态生成对应的配置文件" class="headerlink" title="templates功能：根据模块文件动态生成对应的配置文件"></a>templates功能：根据模块文件动态生成对应的配置文件</h3><p>   templates文件必须存放于templates目录下，且命名为 .j2 结尾</p><pre><code>yaml/yml 文件需和templates目录平级，目录结构如下：./├── temnginx.yml└── templates   └── nginx.conf.j2</code></pre><h4 id="示例1：通过templates模板nginx"><a href="#示例1：通过templates模板nginx" class="headerlink" title="示例1：通过templates模板nginx"></a>示例1：通过templates模板nginx</h4><pre><code>1.先生成nginx.conf.j2模板cp /etc/nginx/nginx.conf templates/nginx.conf.j22.创建playbook- hosts: all  remote_user: root  tasks:    - name: inastll nginx      yum: name=nginx    - name: template      template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf                                       notify: service    - name: start service      service: name=nginx state=started  handlers:    - name: service      service: name=nginx state=restarted</code></pre><h3 id="when配合templates实现根据不同版本执行不同的功能"><a href="#when配合templates实现根据不同版本执行不同的功能" class="headerlink" title="when配合templates实现根据不同版本执行不同的功能"></a>when配合templates实现根据不同版本执行不同的功能</h3><pre><code>条件测试:    如果需要根据变量、facts或此前任务的执行结果来做为某task执行与    否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法    格式when语句    在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法示例：tasks:     - name: &quot;shutdown RedHat flavored systems&quot;     command: /sbin/shutdown -h now     when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值</code></pre><h4 id="示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when"><a href="#示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when" class="headerlink" title="示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when"></a>示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when</h4><pre><code>步骤：涉及到多个notify对应一个handlers,定义端口变量1.hosts文件配置：修改了4台主机httpd的端口    [centos6]    192.168.34.105 http_port=86    192.168.34.106 http_port=87    192.168.34.101 http_port=88    [centos7]    192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件    httpd_6.conf.j2      httpd_7.conf.j23.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的    Listen {{http_port}} 调用hosts列表中的端口变量4.plsybook如下：---- hosts: all  remote_user: root  tasks:    - name: install httpd      yum: name=httpd    - name: templates 6      template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf      notify: restart service      when: ansible_distribution_major_version == &quot;6&quot;    - name: templates 7      template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf                                when: ansible_distribution_major_version == &quot;7&quot;      notify: restart service    - name: service      service: name=httpd state=started  handlers:    - name: restart service      service: name=httpd state=restarted</code></pre><h2 id="迭代：with-items，类似于shell中的for循环"><a href="#迭代：with-items，类似于shell中的for循环" class="headerlink" title="迭代：with_items，类似于shell中的for循环"></a>迭代：with_items，类似于shell中的for循环</h2><pre><code>迭代：当有需要重复性执行的任务时，可以使用迭代机制对迭代项的引用，固定变量名为”item“要在task中使用with_items给定要迭代的元素列表列表格式：    字符串    字典   字典构成一个键值对{key:vavul},如示例3</code></pre><h4 id="迭代的示例："><a href="#迭代的示例：" class="headerlink" title="迭代的示例："></a>迭代的示例：</h4><pre><code>示例1：比如创建user1.user2.user3个用户    - hosts: all      remote_user: root      tasks:        - name: touch users          user: name={{item}}          with_items:            - haha1            - haha2            - haha3示例2：拷贝3个文件，file1 file2 file3    - hosts: all     remote_user: root    tasks:      - name: copy files        copy: src=/data/playbook/{{item}} dest=/data/        with_items:          - file1          - file2          - file3</code></pre><h2 id="迭代嵌套子变量-涉及到多个键值对的表达方式"><a href="#迭代嵌套子变量-涉及到多个键值对的表达方式" class="headerlink" title="迭代嵌套子变量:涉及到多个键值对的表达方式"></a>迭代嵌套子变量:涉及到多个键值对的表达方式</h2><pre><code>示例3：创建3个组，再创建3个用户，指定加入一一对应的组    - hosts: all      remote_user: root      tasks:        - name: creat groups          group: name={{item}}          with_items:            - group1            - group2            - group3        - name: creat users          user: name={{item.name}} group={{item.group}}          with_items:            - { name: &apos;haha1&apos;, group: &apos;group1&apos; }            - { name: &apos;haha2&apos;, group: &apos;group2&apos; }            - { name: &apos;haha3&apos;, group: &apos;group3&apos; }备注：注意创建用户时，键值对的表达和使用方法    上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3;</code></pre><h3 id="Playbook中template结合for循环生成具有重复性的代码段"><a href="#Playbook中template结合for循环生成具有重复性的代码段" class="headerlink" title="Playbook中template结合for循环生成具有重复性的代码段"></a>Playbook中template结合for循环生成具有重复性的代码段</h3><pre><code>语法:for的写法：    {% for vhost in nginx_vhosts %}        server {        listen {{ vhost.listen | default('80 default_server') }}### Playbook中template结合for循环生成具有重复性的代码段         if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用                        如果没定义，则不执行接下来的代码：示例2        {% if vhost.server_name is defined %}                server_name {{ vhost.server_name }};        {% endif %}        {% if vhost.root is defined %}                root {{ vhost.root }};        {% endif %}### for和if的示例，帮助理解其要执行语句的含义        示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成    先创建for.j2文件：                {% for i in ports %}                server{                        listen {{i.listen}}                        name {{i.name}}                        root {{i.root}}                }                {% endfor %}        创建playbook:再其中调用for.j2文件            - hosts: all              remote_user: root              vars:                ports:                  - web1:                    listen: 81                    name: www.baidu.com                    root: /data/web1                  - web2:                    listen: 82                    name: www.baidu1.com                    root: /data/web2              tasks:                - name: test for                  template: src=for.j2 dest=/data/for1.conf    效果为：        server{            listen 81            name www.baidu.com            root /data/web1        }        server{            listen 82            name www.baidu1.com            root /data/web2        }示例2：template配合if的涵义：    在示例1中的playbook中，把name注释掉，即不定义name的值            - web1:                    listen: 81                   # name: www.baidu.com                    root: /data/web1    然后playbook:再调用for.j2文件        {% for i in ports %}            server{                    listen {{i.listen}}            {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用                    name {{i.name}}            {% endif %}                    root {{i.root}}            }            {% endfor %}    结果：则web1没有name的值，即可以理解if的用法        server{            listen 81            root /data/web1  少了web1的name的值        }        server{            listen 82            name www.baidu1.com            root /data/web2        }</code></pre><h3 id="Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？"><a href="#Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？" class="headerlink" title="Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？"></a>Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？</h3><h2 id="ansible重要内容之Roles；playbook的集合和拆分"><a href="#ansible重要内容之Roles；playbook的集合和拆分" class="headerlink" title="ansible重要内容之Roles；playbook的集合和拆分"></a>ansible重要内容之Roles；playbook的集合和拆分</h2><pre><code> ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles    能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需    要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、    文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一    种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程    等场景中复杂场景：建议使用roles，代码复用度高变更指定主机或主机组如命名不规范维护和传承成本大某些功能需多个Playbook，通过Includes即可实现</code></pre><h3 id="roles的意义和适用场景："><a href="#roles的意义和适用场景：" class="headerlink" title="roles的意义和适用场景："></a>roles的意义和适用场景：</h3><pre><code>角色(roles)：角色集合    适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把    同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了，    当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。        如系统内会存在如下的各类服务，可以先编排好角色        roles/        ├── httpd/        ├── memcached/        ├── mysql/        └── nginx/</code></pre><h3 id="roles的目录结构（一般分成以下目录进行存放一类的文件）"><a href="#roles的目录结构（一般分成以下目录进行存放一类的文件）" class="headerlink" title="roles的目录结构（一般分成以下目录进行存放一类的文件）"></a>roles的目录结构（一般分成以下目录进行存放一类的文件）</h3><pre><code>Roles各目录作用：/roles/project/ :项目名称,有以下子目录    如创建http，memcached，nginx等目录files/ ：存放由copy或script模块等调用的文件    保存需要拷贝的配置文件templates/：template模块查找所需要模板文件的目录    保存通过template的jinja2模板调用的配置文件tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；        其它的文件需要在此文件中通过include进行包含handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此           文件中通过include进行包含vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要       在此文件中通过include进行包含，可以单独定义变量的目录meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，其它文件需在此文件中通过include进行包含            tasks目录下，组合任务顺序的文件default/：设定默认变量时使用此目录中的main.yml文件</code></pre><h3 id="roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色"><a href="#roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色" class="headerlink" title="roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色."></a>roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.</h3><pre><code>- hosts: all  remote_user: root  roles:    - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]}       - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}    - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}</code></pre><h3 id="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"><a href="#playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量" class="headerlink" title="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"></a>playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量</h3><pre><code>方法一：把需要调用的角色写在一个playbook里    - hosts: all      remote_user: root      roles:        - role: httpd        - role: memcached        - role: nginx    弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活方法二；可以把变量在角色中定义    传递变量给角色    - hosts:      remote_user:      roles:        - mysql        - { role: nginx, username: nginx }          键role用于指定角色名称          后续的k/v用于传递变量给角色          调用角色方法3：还可基于条件测试实现角色调用方法三：还可基于条件测试实现角色调用    roles:      - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ }</code></pre><h2 id="roles示例："><a href="#roles示例：" class="headerlink" title="roles示例："></a>roles示例：</h2><h3 id="以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml"><a href="#以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml" class="headerlink" title="以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml"></a>以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml</h3><h4 id="roles的目录结构下的httpd-amp-nginxmemcached"><a href="#roles的目录结构下的httpd-amp-nginxmemcached" class="headerlink" title="roles的目录结构下的httpd&amp;nginxmemcached"></a>roles的目录结构下的httpd&amp;nginxmemcached</h4><pre><code>roles├── httpd│   ├── files│   │   ├── index_6.html│   │   └── index_7.html│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── copyhtml_6.yml│   │   ├── copyhtml_7.yml│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig_6.yml│   │   ├── tempconfig_7.yml│   │   └── user.yml│   ├── templates│   │   ├── httpd_6.conf.j2│   │   └── httpd_7.conf.j2│   └── vars├── memcached│   ├── files│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig.yml│   │   └── user.yml│   ├── templates│   │   └── memcached.j2│   └── vars└── nginx    ├── files    │   ├── index_6.html    │   └── index_7.html    ├── handlers    │   └── main.yml    ├── tasks    │   ├── copyhtml_6.yml    │   ├── copyhtml_7.yml    │   ├── group.yml    │   ├── main.yml    │   ├── package.yml    │   ├── service.yml    │   ├── tempconfig.yml    │   └── user.yml    ├── templates    │   └── nginx.conf.j2    └── vars       └── main.yml</code></pre><h3 id="调用角色的playbook-roles-yml"><a href="#调用角色的playbook-roles-yml" class="headerlink" title="调用角色的playbook:roles.yml"></a>调用角色的playbook:roles.yml</h3><h5 id="可以通过加变量和标签和条件测试调用更灵活的调用各种角色"><a href="#可以通过加变量和标签和条件测试调用更灵活的调用各种角色" class="headerlink" title="可以通过加变量和标签和条件测试调用更灵活的调用各种角色)"></a>可以通过加变量和标签和条件测试调用更灵活的调用各种角色)</h5><pre><code>    vim /data/roles.yml            - hosts: all            remote_user: root          roles:        - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“}        - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}        - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}比如：     1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法     2.ansible-playbook -t httpd roles.yml 只选择安装httpd     3.ansible-playbook -t nginx roles.yml 只选择安装nginx     4.ansible-playbook -t web roles.yml 安装httpd和memcached     5.ansible-playbook -t web1 roles.yml 只选择安装nginx</code></pre><h3 id="下图为每个role的各个文件内容："><a href="#下图为每个role的各个文件内容：" class="headerlink" title="下图为每个role的各个文件内容："></a>下图为每个role的各个文件内容：</h3><p>图一：参照roles的httpd的目录各个文件内容</p><p><img src="/2018/03/06/ansible/roles.png" alt="roles_memcached"></p><p>图二：参照roles的nginx的目录各个文件内容</p><pre><code>涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有    跨角色调用配置文件写法：   - name: copy index6  copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html</code></pre><p><img src="/2018/03/06/ansible/roles_nginx.png" alt="roles_nginx"><br>图三：参照roles的memcached的目录各个文件内容<br><img src="/2018/03/06/ansible/roles_memcached.png" alt="roles_memcached"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;a href=&quot;#运维自动化管理工具之Ansible&quot; class=&quot;headerlink&quot; title=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;/a&gt;运维自动化管理工具之Ansible&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2018/03/06/ansible/ansible.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="自动化运维" scheme="https://www.liukui.tech/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="ansible,运维技术" scheme="https://www.liukui.tech/tags/ansible-%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>搭建内网yum源</title>
    <link href="https://www.liukui.tech/2017/10/18/%E6%90%AD%E5%BB%BA%E5%86%85%E7%BD%91yum%E6%BA%90/"/>
    <id>https://www.liukui.tech/2017/10/18/搭建内网yum源/</id>
    <published>2017-10-18T00:00:00.000Z</published>
    <updated>2018-09-01T00:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>创建文章的默认模板，可根据实际情况修改</p><p><blockquote class="blockquote-center">Till I reach the end, then I’ll start again<br>《Try Everything》<br></blockquote><br><!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --></p><p><blockquote class="blockquote-center">1</blockquote><br><a id="more"></a></p><p>// 插入音乐</p><p><audio id="audio" controls preload="none"><br>      <source id="mp3" src="http://other.web.ri01.sycdn.kuwo.cn/resource/n3/1/70/780373770.mp3"><br></audio><br>或者</p><div align="center"><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=30375690&auto=1&height=66"></iframe></div><p>// 表示图片在左边或者右边，中间(left，right，center)<br><img src="/2017/10/18/搭建内网yum源/文本三剑客之awk/111.gif" div="" align="right"></p><p>// markdown格式<br><del>测试，就是要测试一下啊啊啊啊a</del> 文本上带一条横线，表示错误</p><h1 id="This-is-an-H1"><a href="#This-is-an-H1" class="headerlink" title="This is an H1"></a>This is an H1</h1><ul><li>Red</li><li>Green</li><li>Blue<blockquote><p>This is a blockquote<br>inside a list item.</p></blockquote></li></ul><hr><p><a href="http://example.com/" target="_blank" rel="noopener">http://example.com/</a></p><h3 id="This-is-an-H2"><a href="#This-is-an-H2" class="headerlink" title="This is an H2"></a>This is an H2</h3><p>// 插入图片并设置大小两种方法</p><p><img src="/2017/10/18/搭建内网yum源/旧事-大好河山/纳木错.JPG" alt="Pulpit rock" width="800" height="800"><br><img src="/2017/10/18/搭建内网yum源/旧事-大好河山/纳木错.JPG" width="60%" height="60%"><br><img src="/2017/10/18/搭建内网yum源/旧事-大好河山/纳木错.JPG" alt=""></p><p>// 颜色选择</p><font size="3" color="#FF0000"> size定义字体大小，color定义颜色</font><br><font size="3" color="#70DB93"> size定义字体大小，color定义颜色</font><br><font size="3" color="#9F5F9F"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D9D919"> size定义字体大小，color定义颜色</font><br><font size="3" color="#FF7F00"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D98719"> size定义字体大小，color定义颜色</font><br><font size="3" color="#2ae0c8"> size定义字体大小，color定义颜色</font><br><font size="3" color="#fad8be"> size定义字体大小，color定义颜色</font><br><font size="3" color="#cbf5fb"> size定义字体大小，color定义颜色</font><br><font size="3" color="#acf6ef"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D9D919"> size定义字体大小，color定义颜色</font><br><font size="3" color="#70DB93"> size定义字体大小，color定义颜色</font><br><font size="3" color="#BC8F8F"> size定义字体大小，color定义颜色</font><br><font size="3" color="#DB70DB"> size定义字体大小，color定义颜色</font><br><font size="3" color="#CFB53B"> size定义字体大小，color定义颜色</font><br><font size="3" color="#FF2400"> size定义字体大小，color定义颜色</font><br><font size="3" color="#CD7F32"> size定义字体大小，color定义颜色</font><br><font size="3" color="#23238E"> size定义字体大小，color定义颜色</font>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;创建文章的默认模板，可根据实际情况修改&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;Till I reach the end, then I’ll start again&lt;br&gt;《Try Everything》&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;&lt;!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --&gt;&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;1&lt;/blockquote&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>TCP三次握手、四次断开与十一种状态</title>
    <link href="https://www.liukui.tech/2017/10/18/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E3%80%81%E5%9B%9B%E6%AC%A1%E6%96%AD%E5%BC%80%E4%B8%8E%E5%8D%81%E4%B8%80%E7%A7%8D%E7%8A%B6%E6%80%81/"/>
    <id>https://www.liukui.tech/2017/10/18/TCP三次握手、四次断开与十一种状态/</id>
    <published>2017-10-18T00:00:00.000Z</published>
    <updated>2019-02-24T06:14:12.595Z</updated>
    
    <content type="html"><![CDATA[<h3 id="TCP三次握手、四次断开与十一种状态"><a href="#TCP三次握手、四次断开与十一种状态" class="headerlink" title="TCP三次握手、四次断开与十一种状态"></a>TCP三次握手、四次断开与十一种状态</h3><a id="more"></a><p>OSI模型由下到上分别为物理层、数据链路层、网络层、传输层、会话层、表示层、应用层</p><pre><code>1：第七层：应用层的功能：为应用软件提供接口，使应用程序能够使用网络服务。常见的应用层协议：http(80)、ftp(20/21)、smtp(25)、pop3(110)、telnet(23)、dns(53)等2：第六层：表示层的功能：数据的编码和解码、数据的加密和解密、数据和压缩和解压缩，常见的标准有JPEG/ASCII等3：第五层：会话层的功能：建立、管理和终止表示层实体之间的会话连接，在设各或节点之间提供会话控制，它在系统之间协调通信过程,并提供3种不同的方式来组织它们之间的通信:单工、半双工和全双工4：第四层：传输层的功能：负责建立端到端的连接，保证报文在端到端之间的传输。提供可靠TCP及不可靠UDP的传输机制,服务点编址、分段与重组、连接控制、流量控制、差错控制。5：第三层：网络层的功能：定义逻辑地址,逻辑寻址，将数据分组从源传输到目的,路径选择、路由发现、维护路由表，功能是隔离广播域；隔离广播,路由选择；维护路由表,寻址及转发,流量管理并连接广域网6：第二层：数据链路层的功能：组帧、物理编址，将数据帧从链路上的一个节点传递到另一个节点，流量控制、差错控制、接入控制7：第一层：物理层的功能：在介质上传递比特流，定义接口和媒体的物理特性，定义比特的表示、数据传输速率、信号的传输模式（单工、半双工、全双工），定义网络物理拓扑（网状、星型、环型、总线型等）</code></pre><h3 id="TCP协议简介："><a href="#TCP协议简介：" class="headerlink" title="TCP协议简介："></a>TCP协议简介：</h3><p>TCP，全称Transfer Control Protocol，中文名为传输控制协议，它工作在OSI的传输层，提供面向连接的可靠传输服务，TCP的工作主要是建立连接，然后从应用层程序中接收数据并进行传输。TCP采用虚电路连接方式进行工作，在发送数据前它需要在发送方和接收方建立一个连接，数据在发送出去后，发送方会等待接收方给出一个确认性的应答，否则发送方将认为此数据丢失，并重新发送此数据。<br>TCP的报文头部结构：<br>-TCP的报文头部结构<br><img src="/2017/10/18/TCP三次握手、四次断开与十一种状态/TCP报文头部.png" alt="TCP的报文头部结构"></p><h3 id="TCP三次握手："><a href="#TCP三次握手：" class="headerlink" title="TCP三次握手："></a>TCP三次握手：</h3><pre><code>在建立连接的时候，所谓的客户端与服务端是相对应的，即要看是谁主动连接的谁，如果A主动连接B那么A就是客户端而B是服务端，如果返过来B主动连接A，那么B就是客户端而A就成了服务端。1:连接过程：第一次握手：客户端发送SYN标志位为1的请求到服务端，并随机生成一个seq 序列号x，其中seq是随机产生的数据包的序列号。第二次握手：服务器收到客户端请求并返回SYN=1，ACK=1，seq=y，ack=x+1，其中ACK=1表示是响应报文，seq=y是服务器随机产生的数据包序列号，ack=x+1是确认客户端序列号有效并返回给客户端确认。第三次握手：客户端收到服务器的确认ack=x+1有效的验证信息，即在自己发送的序列号基础之上加了1表示服务器收到并返回，表示第二次连接有效，然后客户端恢回复ACK=1，seq=x+1，ack=y+1，这是讲服务器发来+1后的序列号当做自己的seq序列号，确认号ack使用服务器的随机号y再加1即ack=y+1，这样客户端就完成了第三次的验证在讲数据包发给服务器，服务器收到后验证确认号是在自己的seq之上加了1，表示没有问题就开始传输数据。注：ACK :TCP协议规定，只有ACK=1时有效，也规定连接建立后所有发送的报文的ACK必须为1Seq:序号,4字节，范围为0^32—1^32,共4284967296，达到时重新开始计算在第三次的时候SYN等于0，因为SYN(SYNchronization) 只i在连接建立时用来同步序号,当SYN=1而ACK=0时,表明这是一个连接请求报文,对方若同意建立连接,则应在响应报文中使SYN=1和ACK=1. 因此, SYN置1就表示这是一个连接请求或连接接受报文，链路建立成功之后就将标志位置为0。SYN(synchronous建立联机)             ACK(acknowledgement 确认)PSH(push传送)                    FIN(finish结束)RST(reset重置)                   URG(urgent紧急)                      Sequence number(顺序号码)            Acknowledge number(确认号码)</code></pre><p>-TCP三次握手<br><img src="/2017/10/18/TCP三次握手、四次断开与十一种状态/TCP三次握手.jpg" alt="TCP三次握手"></p><h3 id="TCP的四次断开："><a href="#TCP的四次断开：" class="headerlink" title="TCP的四次断开："></a>TCP的四次断开：</h3><pre><code>TCP断开要四次是因为TCP传输数全双工的，即数据是在同一时间内两条数据链路双向互相传输的，因此每个方向都要单独关闭一次，断开需要客户端到服务端断开一次，而服务端到客户端也需要断开一次，这样的断开才是完整的断开，第一次断开：客户方发给服务器一个FIN为1的请求，FIN为1表示是一个断开连接的请求，即表示数据传输完毕请求断开，并发送seq序列号和Ack确认号。第二次断开：服务器收到客户端请求并返回ACK标志位为1，Ack为Seq+1等于201，并将对方的Ack作为自己的Seq序列号的确认数据包，biao 接收到请求同意断开。第三次断开：服务器发送ACK=1，FIN=1，Seq等于客户端第一次请求断开的Ack确认号+1，即Seq等于501的断开请求给客户端。第四次断开：客户端发送ACK=1，Ack在上一步Seq上+1等于502，并使用在第二次断开中服务器发送的Ack确号201作为本次的序列号发给服务器表示同意断开，服务器收到后验证序列号是第二次的，验证Ack是第三次+1的，确认没有问题后同意断开，然后将端口置为TIME_WAIT状态，等待2 MSL时间后置为关闭状态，被动方收到主动方的报文确认Ack确认号没有问题后将端口置为CLOSED，至此端口g。SYN(synchronous建立联机)             ACK(acknowledgement 确认)PSH(push传送)                    FIN(finish结束)RST(reset重置)                    URG(urgent紧急)                  Sequence number(顺序号码)            Acknowledge number(确认号码)四次断开的图形示意如下：</code></pre><p>-TCP四次挥手<br><img src="/2017/10/18/TCP三次握手、四次断开与十一种状态/TCP四次挥手.png" alt="TCP四次挥手"></p><h3 id="TCP端口的十一种连接状态："><a href="#TCP端口的十一种连接状态：" class="headerlink" title="TCP端口的十一种连接状态："></a>TCP端口的十一种连接状态：</h3><pre><code>TCP端口一共有十一种状态，CLOSE_WAIT表示是程序y关闭连接，而TIME_WAIT只占用一个socket连接，到时间之后会释放，因此大量的CLOSE_WAIT是比大量的TIME_WAIT影响更大，另外还有FIN_WAIT1和FIN_WAIT2，如果有FIN_WAIT2也表示服务有问题，以下是每个端口状态的含义：1：CLOSED：端口默认是关闭状态。2：LISTEN： 服务器程序开始监听一个端口，就是LISTEN状态。3：SYN_RCVD：三次握手的第二次握手后的端口状态，是收到了客户端发送的SYN_SENT数据包之后的状态，这个状态很短暂，正常在服务器上是很少看到的，除非服务器故意不发送最后一次握手数据包，服务器返回给客户端SYN确认之后就会将在自己的端口置为SYN_RCVD。4：SYN_SENT：SYN_SENT状态表示客户端已发送SYN=1的请求连接报文，发送之后客户端就会将自己的端口状态置为SYN_SENT。5：ESTABLISHED：表示已经连接成功，客户端收到服务器的确认报文会回复服务器，然后就将端口置为ESTABLISHED，服务器第三次收到客户端的Ack确认就会将端口置为ESTABLISHED并开始传输数据。6：FIN_WAIT_1：出现在主动关闭方，FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，当任意一方想主动关闭连接，向对方发送了FIN=1的断开连接请求报文，此时该SOCKET即 进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马 上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。7：FIN_WAIT_2：出现在主动关闭方，当被动方回应FIN_WAIT_1的ACK报文后，则进入到FIN_WAIT_2状态8：TIME_WAIT：出现在主动关闭方，表示收到了对方的FIN请求关闭报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。9：CLOSING： 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送FIN报文后，按理来说是应该先收到（或同时收到）对方的 ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什 么情况下会出现此种情况呢？其实细想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报 文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。10：CLOSE_WAIT： 表示在等待关闭端口，这种状态存在于被动关闭的一方。11：LAST_ACK： 是被动关闭方在主动关闭一方在发送FIN报文后，最后等待对方的ACK报文，当再次收到ACK报文后，也即可以进入到CLOSED可用状态了。12：区分主动断开和被动端口方的端口状态：主动端口方：SYN_SENT、FIN_WAIT1、FIN_WAIT2、CLOSING、TIME_WAIT 。被动断开方：LISTEN、SYN_RCVD、CLOSE_WAIT、LAST_ACK 。都具有的：CLOSED 、ESTABLISHED 。</code></pre><p>-TCP的11种状态<br><img src="/2017/10/18/TCP三次握手、四次断开与十一种状态/TCP的11种状态.png" alt="TCP的11种状态"></p><h3 id="关于优化："><a href="#关于优化：" class="headerlink" title="关于优化："></a>关于优化：</h3><pre><code>socket就是一个TCP连接，包括源地址、源端口、目标地址、目标端口和协议(TCP|UDP),0端口是保留不能使用的，因此服务器的最大端口使用数量为63353个，最大65536个端口是因为TCP报文头部有个端口长度为2^16次方等于65536，查看当前打开的端口范围# cat /proc/sys/net/ipv4/ip_local_port_range，单个IP地址能接受的最大并发为六万多，1万个TIME_WAIT大约使用1MB的内存CPU占用更小，因此资源使用很小可以忽略不计，但是会占用一个socket，可以通过在负载上配置多个公网IP地址以提高高并发的问题， [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_recycle  0  #用于快速回收处于TIME_WAIT状态的socket以便重新分，在负载服务器不能打开，会导致通过nat上网的后续用户无法打开网页，因为后面的访问用户时间戳小于前面的用户，会导致数据包被负载服务器丢弃，可以在内网使用，但是通常建议关闭。[root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_reuse 0  #kernel会复用处于TIME_WAIT状态的socket，即允许将TIME_WAIT状态得socket用于直接新的TCP连接，负载服务器建议打开[root@localhost ~]# cat /proc/sys/net/ipv4/tcp_timestamps 1 #记录数据包的时间戳，判断是新的数据包还是旧的，如果是旧的就丢弃，配合上面两个选项的时候一定要打开才生效。</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;TCP三次握手、四次断开与十一种状态&quot;&gt;&lt;a href=&quot;#TCP三次握手、四次断开与十一种状态&quot; class=&quot;headerlink&quot; title=&quot;TCP三次握手、四次断开与十一种状态&quot;&gt;&lt;/a&gt;TCP三次握手、四次断开与十一种状态&lt;/h3&gt;
    
    </summary>
    
      <category term="TCP协议" scheme="https://www.liukui.tech/categories/TCP%E5%8D%8F%E8%AE%AE/"/>
    
    
      <category term="网络基础" scheme="https://www.liukui.tech/tags/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Linux下双网卡绑定及Bridge</title>
    <link href="https://www.liukui.tech/2017/10/18/Linux%E4%B8%8B%E5%8F%8C%E7%BD%91%E5%8D%A1%E7%BB%91%E5%AE%9A%E5%8F%8ABridge/"/>
    <id>https://www.liukui.tech/2017/10/18/Linux下双网卡绑定及Bridge/</id>
    <published>2017-10-18T00:00:00.000Z</published>
    <updated>2019-01-22T13:39:43.978Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Linux的双网卡绑定及Bridge"><a href="#Linux的双网卡绑定及Bridge" class="headerlink" title="Linux的双网卡绑定及Bridge"></a>Linux的双网卡绑定及Bridge</h3><p>一：linux操作系统下双网卡绑定有七种模式。现在一般的企业都会使用双网卡接入，这样既能添加网络带宽，同时又能做相应的冗余，可以说是好处多多。而一般企业都会使用linux操作系统下自带的网卡绑定模式，当然现在网卡产商也会出一些针对windows操作系统网卡管理软件来做网卡绑定，一共有其中方式，其中比较长用的是0/1/6：<br>二：windows操作系统没有网卡绑定功能需要第三方支持：DELLr720一般都是博科的网卡，Inter网卡，随机光盘和网上<br>    有很多双网卡绑定的软件.</p><a id="more"></a><p>1：网卡绑定案例，先做绑定，然后再把绑定后的网卡配置成桥接：</p><p>1.1：第一组配置，将eth1和eth5绑定为bond0：</p><p>1.1.1：先创建bond0配置那文件步骤及内容如下：</p><pre><code>[root@linux-host1 ~]# cd /etc/sysconfig/network-scripts/[root@linux-host1 network-scripts]# cp ifcfg-eth0   ifcfg-bond0[root@linux-host1 network-scripts]# cat ifcfg-bond0 #内容如下：BOOTPROTO=staticNAME=bond0DEVICE=bond0ONBOOT=yesBONDING_MASTER=yesBONDING_OPTS=&quot;mode=1 miimon=100&quot; #指定绑定类型为1及链路状态监测间隔时间BRIDGE=br0 #桥接到br0</code></pre><p>1.1.2：配置br0：</p><pre><code>TYPE=BridgeBOOTPROTO=staticDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noNAME=br0DEVICE=br0ONBOOT=yesIPADDR=X.X.X.XNETMASK=255.255.255.0GATEWAY=X.X.X.X</code></pre><p>1.1.3：eth1配置：</p><pre><code>[root@linux-host1 network-scripts]# vim ifcfg-eth1BOOTPROTO=staticNAME=eth1DEVICE=eth1ONBOOT=yesNM_CONTROLLED=noMASTER=bond0USERCTL=noSLAVE=yes</code></pre><p>1.1.4：eth5的配置：</p><pre><code>[root@linux-host1 network-scripts]# cp ifcfg-eth1  ifcfg-eth5[root@linux-host1 network-scripts]# vim ifcfg-eth5BOOTPROTO=staticNAME=eth5DEVICE=eth5ONBOOT=yesNM_CONTROLLED=noMASTER=bond0USERCTL=noSLAVE=yes</code></pre><p>1.1.5：重启网络服务：</p><pre><code>[root@linux-host1 network-scripts]# systemctl  restart network</code></pre><p>1.1.6：验证网络是否正常：</p><pre><code>[root@linux-host1 network-scripts]# ping www.baidu.comPING www.a.shifen.com (61.135.169.125) 56(84) bytes of data.64 bytes from 61.135.169.125: icmp_seq=1 ttl=128 time=6.17 ms64 bytes from 61.135.169.125: icmp_seq=2 ttl=128 time=10.3 ms64 bytes from 61.135.169.125: icmp_seq=3 ttl=128 time=5.36 ms64 bytes from 61.135.169.125: icmp_seq=4 ttl=128 time=6.74 ms64 bytes from 61.135.169.125: icmp_seq=5 ttl=128 time=5.71 ms</code></pre><p>1.1.:6：可以验证当前是绑定在哪一块网卡上的：</p><pre><code>[root@linux-host1 ~]# cat /proc/net/bonding/bond0Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)Bonding Mode: fault-tolerance (active-backup)Primary Slave: NoneCurrently Active Slave: eth1 #备份链路网卡MII Status: upMII Polling Interval (ms): 100Up Delay (ms): 0Down Delay (ms): 0Slave Interface: eth1MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 18:66:da:f3:34:e5Slave queue ID: 0Slave Interface: eth5MII Status: upSpeed: 1000 MbpsDuplex: fullLink Failure Count: 0Permanent HW addr: 00:0a:f7:99:ba:d1Slave queue ID: 0</code></pre><p>1.2：第二组配置，将eth2和eth6绑定为bond1：</p><p>1.2.1：创建bond1配置文件：</p><pre><code>[root@linux-host1 network-scripts]# cp ifcfg-bond0  ifcfg-bond1[root@linux-host1 network-scripts]# vim ifcfg-bond1BOOTPROTO=staticNAME=bond1DEVICE=bond1TYPE=BondBONDING_MASTER=yesBOOTPROTO=staticNAME=bond1ONBOOT=yesBONDING_OPTS=&quot;mode=1 miimon=100&quot;BRIDGE=br1</code></pre><p>1.2.2：配置br1：</p><pre><code>TYPE=BridgeBOOTPROTO=staticDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noNAME=br1DEVICE=br1ONBOOT=yesIPADDR=X.X.X.XNETMASK=255.255.255.0GATEWAY=X.X.X.XDNS1=X.X.X.X</code></pre><p>1.2.3：eth2的配置：</p><pre><code>[root@linux-host1 network-scripts]# vim ifcfg-eth2BOOTPROTO=staticNAME=eth2DEVICE=eth2ONBOOT=yesNM_CONTROLLED=noMASTER=bond1USERCTL=noSLAVE=yes</code></pre><p>1.2.4：eth6的配置：</p><pre><code>[root@linux-host1 network-scripts]# vim ifcfg-eth6BOOTPROTO=staticNAME=eth6DEVICE=eth6ONBOOT=yesNM_CONTROLLED=noMASTER=bond1USERCTL=noSLAVE=yes</code></pre><p>1.2.5：重启网络服务：</p><pre><code>[root@linux-host1 network-scripts]# systemctl  restart network</code></pre><p>1.2.6：测试内网网络是否正常：</p><pre><code>[root@linux-host1 network-scripts]# ping 192.168.20.12PING 192.168.20.12 (192.168.20.12) 56(84) bytes of data.64 bytes from 192.168.20.12: icmp_seq=1 ttl=64 time=1.86 ms64 bytes from 192.168.20.12: icmp_seq=2 ttl=64 time=0.570 ms64 bytes from 192.168.20.12: icmp_seq=3 ttl=64 time=0.410 ms</code></pre><p>1.3：设置开机启动：</p><pre><code>[root@linux-host1 network-scripts]# vim /etc/rc.d/rc.localifenslave eth1 eth5ifenslave eth2 eth6[root@linux-host1 network-scripts]# chmod  a+x /etc/rc.d/rc.local </code></pre><p>1.4：重启系统后验证网络</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Linux的双网卡绑定及Bridge&quot;&gt;&lt;a href=&quot;#Linux的双网卡绑定及Bridge&quot; class=&quot;headerlink&quot; title=&quot;Linux的双网卡绑定及Bridge&quot;&gt;&lt;/a&gt;Linux的双网卡绑定及Bridge&lt;/h3&gt;&lt;p&gt;一：linux操作系统下双网卡绑定有七种模式。现在一般的企业都会使用双网卡接入，这样既能添加网络带宽，同时又能做相应的冗余，可以说是好处多多。而一般企业都会使用linux操作系统下自带的网卡绑定模式，当然现在网卡产商也会出一些针对windows操作系统网卡管理软件来做网卡绑定，一共有其中方式，其中比较长用的是0/1/6：&lt;br&gt;二：windows操作系统没有网卡绑定功能需要第三方支持：DELLr720一般都是博科的网卡，Inter网卡，随机光盘和网上&lt;br&gt;    有很多双网卡绑定的软件.&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="linux网络" scheme="https://www.liukui.tech/tags/linux%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
</feed>
