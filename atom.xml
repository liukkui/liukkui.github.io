<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coool&#39;s Blog</title>
  
  <subtitle>As we watch our love grow.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.liukui.tech/"/>
  <updated>2019-04-02T13:19:04.933Z</updated>
  <id>https://www.liukui.tech/</id>
  
  <author>
    <name>空腹吃早餐</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Ceph存储</title>
    <link href="https://www.liukui.tech/2019/01/18/Ceph%E5%AD%98%E5%82%A8/"/>
    <id>https://www.liukui.tech/2019/01/18/Ceph存储/</id>
    <published>2019-01-18T00:00:00.000Z</published>
    <updated>2019-04-02T13:19:04.933Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="存储" scheme="https://www.liukui.tech/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="https://www.liukui.tech/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Promethues监控</title>
    <link href="https://www.liukui.tech/2019/01/15/Promethues%E7%9B%91%E6%8E%A7/"/>
    <id>https://www.liukui.tech/2019/01/15/Promethues监控/</id>
    <published>2019-01-15T00:00:00.000Z</published>
    <updated>2019-03-13T10:26:37.922Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="promethues" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/promethues/"/>
    
    
      <category term="promethues" scheme="https://www.liukui.tech/tags/promethues/"/>
    
  </entry>
  
  <entry>
    <title>httpd脚本</title>
    <link href="https://www.liukui.tech/2018/12/30/httpd%E8%84%9A%E6%9C%AC/"/>
    <id>https://www.liukui.tech/2018/12/30/httpd脚本/</id>
    <published>2018-12-30T11:28:24.082Z</published>
    <updated>2019-01-07T11:23:00.341Z</updated>
    
    <content type="html"><![CDATA[<p>httpd服务<br><a id="more"></a></p><h3 id="httpd服务脚本"><a href="#httpd服务脚本" class="headerlink" title="httpd服务脚本"></a>httpd服务脚本</h3><pre><code>#!/bin/bash## httpd        Startup script for the Apache HTTP Server## chkconfig: - 85 15# description: The Apache HTTP Server is an efficient and extensible  \#              server implementing the current HTTP standards.# processname: httpd# config: /etc/httpd/conf/httpd.conf# config: /etc/sysconfig/httpd# pidfile: /var/run/httpd/httpd.pid#### BEGIN INIT INFO# Provides: httpd# Required-Start: $local_fs $remote_fs $network $named# Required-Stop: $local_fs $remote_fs $network# Should-Start: distcache# Short-Description: start and stop Apache HTTP Server# Description: The Apache HTTP Server is an extensible server #  implementing the current HTTP standards.### END INIT INFO# Source function library.. /etc/rc.d/init.d/functionsif [ -f /etc/sysconfig/httpd ]; then        . /etc/sysconfig/httpdfi# Start httpd in the C locale by default.HTTPD_LANG=${HTTPD_LANG-&quot;C&quot;}# This will prevent initlog from swallowing up a pass-phrase prompt if# mod_ssl needs a pass-phrase from the user.INITLOG_ARGS=&quot;&quot;# Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server# with the thread-based &quot;worker&quot; MPM; BE WARNED that some modules may not# work correctly with a thread-based MPM; notably PHP will refuse to start.# Path to the apachectl script, server binary, and short-form for messages.apachectl=/usr/sbin/apachectlhttpd=${HTTPD-/usr/sbin/httpd}prog=httpdpidfile=${PIDFILE-/var/run/httpd/httpd.pid}lockfile=${LOCKFILE-/var/lock/subsys/httpd}RETVAL=0STOP_TIMEOUT=${STOP_TIMEOUT-10}# The semantics of these two functions differ from the way apachectl does# things -- attempting to start while running is a failure, and shutdown# when not running is also a failure.  So we just do it the way init scripts# are expected to behave here.start() {        echo -n $&quot;Starting $prog: &quot;        LANG=$HTTPD_LANG daemon --pidfile=${pidfile} $httpd $OPTIONS        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; touch ${lockfile}        return $RETVAL}# When stopping httpd, a delay (of default 10 second) is required# before SIGKILLing the httpd parent; this gives enough time for the# httpd parent to SIGKILL any errant children.stop() {        status -p ${pidfile} $httpd &gt; /dev/null        if [[ $? = 0 ]]; then                echo -n $&quot;Stopping $prog: &quot;                killproc -p ${pidfile} -d ${STOP_TIMEOUT} $httpd        else                echo -n $&quot;Stopping $prog: &quot;                success        fi        RETVAL=$?        echo        [ $RETVAL = 0 ] &amp;&amp; rm -f ${lockfile} ${pidfile}}reload() {    echo -n $&quot;Reloading $prog: &quot;    if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then        RETVAL=6        echo $&quot;not reloading due to configuration syntax error&quot;        failure $&quot;not reloading $httpd due to configuration syntax error&quot;    else        # Force LSB behaviour from killproc        LSB=1 killproc -p ${pidfile} $httpd -HUP        RETVAL=$?        fi    fi    echo}# See how we were called.case &quot;$1&quot; in  start)        start        ;;  stop)        stop        ;;  status)        status -p ${pidfile} $httpd        RETVAL=$?        ;;  restart)        stop        start        ;;  condrestart|try-restart)        if status -p ${pidfile} $httpd &gt;&amp;/dev/null; then                stop                start        fi        ;;  force-reload|reload)        reload        ;;  graceful|help|configtest|fullstatus)        $apachectl $@        RETVAL=$?        ;;  *)        echo $&quot;Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|reload|status|fullstatus|graceful|help|configtest}&quot;        RETVAL=2esacexit $RETVAL  </code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;httpd服务&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>HTTP协议</title>
    <link href="https://www.liukui.tech/2018/12/18/HTTP%E5%8D%8F%E8%AE%AE/"/>
    <id>https://www.liukui.tech/2018/12/18/HTTP协议/</id>
    <published>2018-12-18T00:00:00.000Z</published>
    <updated>2019-01-22T11:55:18.830Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HTTP协议和APACHE原理"><a href="#HTTP协议和APACHE原理" class="headerlink" title="HTTP协议和APACHE原理"></a>HTTP协议和APACHE原理</h3><p>Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等<br>本文说的是HTTP SERVER<a href="http://www.apache.org/" target="_blank" rel="noopener">apache</a><br><a id="more"></a><br>HTTP2.4的官方文档<a href="http://httpd.apache.org/docs/2.4/" target="_blank" rel="noopener">http2.4文档：安装，模块，指令等说明</a><br>HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a><br><!--more--></p><h3 id="http协议-应用层协议-主流http-1-1版本"><a href="#http协议-应用层协议-主流http-1-1版本" class="headerlink" title="http协议:应用层协议,主流http/1.1版本"></a>http协议:应用层协议,主流http/1.1版本</h3><h4 id="http协议的版本区别"><a href="#http协议的版本区别" class="headerlink" title="http协议的版本区别"></a>http协议的版本区别</h4><p>http0.9、http1.0、http1.1和http2.0的版本区别</p><ul><li><p>http/0.9:</p><blockquote><p>只有一个GET命令，且只能回应<em>.html文件格式，像</em>.txt等都不支持</p></blockquote></li><li><p>http/1.0:效率太低</p><blockquote><p>1.支持cache, MIME(支持各种资源类型), method<br>2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低<br>3.引入了POST命令和HEAD命令，头部信息和<br>4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用</p></blockquote></li><li><p>http/1.1:主流使用版本</p><blockquote><p>1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭，<br>  对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性</p><pre><code>这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求</code></pre><p>2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率<br>3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)<br>4.缺点：<br>  同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象<br>5.解决队头堵塞的办法：<br>  为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等<br>6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度:</p><pre><code>不带状态怎么理解？http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点</code></pre></blockquote></li><li><p>http/2.0：解决 HTTP/1.1效率不高的问题</p><blockquote><p>1.头信息和数据体都是二进制，称为头信息帧和数据帧<br>2.和http1.1区别：请求不需要排队，提高效率<br>  复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）<br>3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度<br>4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息)</p></blockquote></li></ul><h3 id="HTTP工作机制"><a href="#HTTP工作机制" class="headerlink" title="HTTP工作机制"></a>HTTP工作机制</h3><ul><li>工作机制主要分为两步：请求和响应<blockquote><p>http请求：http request<br>http响应：http response<br>一次http事务：请求<-->响应</--></p></blockquote></li><li>Web资源：web resource<br>一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资<br>源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源<br>的集合<blockquote><p>静态页面/文件：无需服务端做出额外处理;</p><pre><code>服务器端是什么样传到客户端就是什么样，比如下面这些比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi只不过浏览器有时会解析出来以好看的页面展示给用户</code></pre><p>动态页面/文件：服务端执行程序，返回执行的结果</p><pre><code>服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果文件后缀：.php, .jsp ,.asp,.sh等将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户</code></pre></blockquote></li><li><p>提高HTTP连接性能</p><blockquote><p>并行连接：通过开多个TCP连接发起并发的HTTP请求<br>持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，<br>管道化连接：通过共享TCP连接发起并发的HTTP请求<br>复用的连接：交替传送请求和响应报文（实验阶段）</p></blockquote></li><li><p>HTTP协议的其他相关技术</p></li><li><p>1.URI：一般把URI认为是URL<br>URI: Uniform Resource Identifier 统一资源标识，分为URL和URN</p><blockquote><p>1.URN: Uniform Resource Naming，统一资源命名</p><pre><code>如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名</code></pre><p>2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置</p><pre><code>如输入一个网址，能具体体现出这个资源在互联网上的位置</code></pre><p>两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址</p></blockquote></li><li><p>URL的组成<br>scheme://user:password@host:port/path;params?query#frag</p><blockquote><p>scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等<br>user:用户，某些方案访问资源时需要的用户名<br>password:密码，用户对应的密码，中间用：分隔<br>Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析<br>port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080<br>/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔<br>params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对<br>query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能<br>frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔</p></blockquote></li><li><p>网站访问量</p><blockquote><p>1.IP(独立IP)：即Internet Protocol,指独立IP数。</p><pre><code>如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个</code></pre><p>2.PV(访问量)： 即Page View, </p><pre><code>页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量一般为了博客为了好看的访问量，都是统计PV量</code></pre><p>3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。</p><pre><code>网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1</code></pre></blockquote></li></ul><h3 id="Web服务请求处理步骤"><a href="#Web服务请求处理步骤" class="headerlink" title="Web服务请求处理步骤"></a>Web服务请求处理步骤</h3><p>很切合实际生活：比如<br>当我们打开一个浏览器，输入一个<a href="http://www.taobao.com，在互联网后台发生了什么？" target="_blank" rel="noopener">www.taobao.com，在互联网后台发生了什么？</a><br>这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图<br><img src="/2018/12/18/HTTP协议/web服务请求处理步骤.png" alt="web请求步骤"></p><p>当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程<br>每个过程都是一段需要原理详细描述的.</p><h4 id="一次完整的http请求处理过程"><a href="#一次完整的http请求处理过程" class="headerlink" title="一次完整的http请求处理过程"></a>一次完整的http请求处理过程</h4><pre><code>1.建立连接：接收或拒绝连接请求2.接收请求：接收客户端请求报文中对某资源的一次请求的过程Web访问响应模型（Web I/O）    单进程I/O模型：访问量不大        启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应        会造成请求排队现象，只适用于访问并发不大的情况    多进程I/O模型：        系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求        如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点        而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的    复用I/O结构：        开启多个进程进程，而一个进程又同时监控N个连接请求        只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗        实现方法：多线程模型和事件驱动        多线程模型：一个进程生成N个线程，每线程响应一个连接请求        事件驱动：一个进程处理N个请求    复用的多进程I/O模型：        启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求        充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的        nginx使用的复用多进程I/O模型</code></pre><font size="3" color="#FF0000"><br>    1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程<br>    2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应<br>    避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费<br>    同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题<br></font><p><img src="/2018/12/18/HTTP协议/web访问响应的四种模型.png" alt="web访问响应四种模型"><br>参考下面的HTTP的MPM三种工作模式<a href=""></a></p><pre><code>3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理    分析元数据：请求报文首部信息获得method    &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt;    HEADERS 格式 name:value    &lt;request body&gt;    通过method来响应用户请求，比如下载(get)，上传等信息    HTTP常用请求方式，Method        GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS4.访问资源：    服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源    在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件    web服务器资源路径映射方式：        (a) docroot        (b) alias        (c) 虚拟主机docroot        (d) 用户家目录docroot5.构建响应报文：    一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体   1）响应实体        描述了响应主体MIME类型的Content-Type首部        描述了响应主体长度的Content-Length   2）URL重定向        web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径   3）MIME类型   当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文    将构建完的响应报文发送给用户    将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户    用户再层层解封装获得index.html的内容7.记录日志    最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务    通过在/var/log/httpd/acess_log日志中记录http的响应记录数    方便分析日志统计该网站的IP，PV量等信息</code></pre><h3 id="Http协议"><a href="#Http协议" class="headerlink" title="Http协议"></a>Http协议</h3><pre><code>http协议    http/0.9, http/1.0, http/1.1, http/2.0http协议：stateless 无状态    服务器无法持续追踪访问者来源解决http协议无状态方法    cookie 客户端存放    session 服务端存放http事务：一次访问的过程    请求：request    响应：response</code></pre><h3 id="Session和Cookie的区别"><a href="#Session和Cookie的区别" class="headerlink" title="Session和Cookie的区别"></a>Session和Cookie的区别</h3><pre><code>前言:    HTTP是一种无状态的协议，为了分辨链接是谁发起的，就需要我们自己去解决这个问题。    不然有些情况下即使是同一个网站我们每打开一个页面也都要登录一下。而Session和    Cookie就是为解决这个问题而提出来的两个机制。应用场景:    1.日常登录一个网站，今天输入用户名密码登录了，第二天再打开很多情况下就直接打开      了。这个时候用到的一个机制就是cookie。    2.session的一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而      服务器端如何判别呢，所以也需要存储一些信息，这里就用到了session。Cookie的原理：    HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。    也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。    这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设    计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行    保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在    请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服    务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端    保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报    文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，    会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，    最后得到之前的状态信息。    通俗讲，Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时    候减少一些步骤。另外一个更准确的说法是：Cookies是服务器在本地机器上存储的小段文    本并随每一个请求发送至同一个服务器，是一种在客户端保持状态的方案。session的原理：    session就是一种保存上下文信息的机制，她是针对每一个用户的，session的内容在服    务器端，通过sessionId来区分不同的客户，session是以cookie或url重写为基础的，    默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie，我们成为session     cookie，以区分persistent coookies，注意session cookie是存储于浏览器内存中的    ，并不是写到硬盘上的；我们通常是看不见JSESSIONID的，但是当我们禁用浏览器的    cookie后，web服务器会采用url重写的方式传递sessionid，我们就可以在浏览器看到    sessionid=HJHADKSFHKAJSHFJ之类的字符串；session cookie针对某一次会话而言，会话结束session cookie也就消失了　session与cookie的区别：　　1.session保存在服务器，客户端不知道其中的信息；cookie保存在客户端，服务端可以        知道其中的信息　　2.session中保存的是对象，cookie中保存的是字符串　　3.session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个    地方都可以访问到；而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不道德session与cookie的联系：　　session是需要借助cookie才能正常工作的，如果客户端完全禁止cookie，session将失    效</code></pre><h3 id="Http应用层的报文头部-又分请求报文和响应报文两种"><a href="#Http应用层的报文头部-又分请求报文和响应报文两种" class="headerlink" title="Http应用层的报文头部:又分请求报文和响应报文两种"></a>Http应用层的报文头部:又分请求报文和响应报文两种</h3><p>-HTTP请求报文头部<br><img src="/2018/12/18/HTTP协议/请求报文头部.png" alt="HTTP请求报文头部"></p><pre><code>开始行    方法：method        GET： 从服务器获取一个资源        HEAD： 只从服务器获取文档的响应首部        POST： 向服务器输入数据，通常会再由网关程序继续处理        PUT： 将请求的主体部分存储在服务器中，如上传文件        DELETE： 请求删除服务器上指定的文档        TRACE： 追踪请求到达服务器中间经过的代理服务器        OPTIONS：请求服务器返回对指定资源支持使用的请求方法    URL:路径首部行实体行</code></pre><p>-HTTP响应报文头部<br><img src="/2018/12/18/HTTP协议/响应报文头部.png" alt="HTTP响应报文头部"></p><pre><code>开始行    版本：version        HTTP/&lt;major&gt;.&lt;minor&gt;1.1/2等等    状态码：        三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况    短语：        状态码所标记的状态的简要描述首部行实体行</code></pre><h3 id="Http常见的状态码和状态码分类"><a href="#Http常见的状态码和状态码分类" class="headerlink" title="Http常见的状态码和状态码分类"></a>Http常见的状态码和状态码分类</h3><pre><code>status(状态码)：    1xx：100-101 信息提示    2xx：200-206 成功    3xx：300-305 重定向    4xx：400-415 错误类信息，客户端错误    5xx：500-505 错误类信息，服务器端错误200： 成功，请求数据通过响应报文的entity-body部分发送;OK301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资      源现在所处的新位置；Moved Permanently302： 响应报文Location指明资源临时新位置 Moved Temporarily304： 如果之前访问一个网站，在本机上有缓存了，当再次访问时，就会出现304的状态码，      提示本地有不需要再去服务器上下载页面401： 需要输入账号和密码认证方能访问资源；Unauthorized403： 没有权限访问，请求被禁止了；Forbidden404： 服务器无法找到客户端请求的资源；要访问的文件不存在500： 服务器内部错误；Internal Server Error502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；Bad Gateway503： 服务不可用，临时服务器维护或过载，服务器无法处理请求      可能是服务器down机了，或者http服务关闭了504： 网关超时；转给后端服务器时，时间太长</code></pre><h3 id="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"><a href="#curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因" class="headerlink" title="curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因"></a>curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因</h3><pre><code>curl是基于URL语法在命令行方式下工作的文件传输工具1.它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。2.curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器，cookies，用户名/密码认证,下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling）3.还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等4.curl的强大在于能模拟各种浏览器自定义请求报文头部等信息，来访问某些控制严格的网站curl [options] [URL...]    -A/--user-agent &lt;string&gt; 冒充浏览器类型，实际上在请求报文修改了User-Agent        curl -A &apos;IE20&apos; http://192.168.34.103在http日志中可看到        一般用于测试访问网站或者爬虫功能要使用不同浏览器访问    -e/--referer &lt;URL&gt; 来源网址，防盗链相关        比如，伪装从百度跳转的192.168.34.103        curl -e &apos;www.baidu.com&apos; http://192.168.34.103    --cacert &lt;file&gt; CA证书 (SSL)    -k/--insecure 允许忽略证书进行 SSL 连接    --compressed 要求返回是压缩的格式    -H/--header &lt;line&gt;自定义首部信息访问网站    -i 显示页面内容，包括报文首部信息    -I/--head 只显示响应报文首部信息    -D/--dump-header &lt;file&gt; 将url的header信息存放在指定文件中，重定向    --basic 使用HTTP基本认证，401认证    -u/--user &lt;user[:password]&gt;设置服务器的用户和密码    -L 如果有3xx响应码，重新发请求到新位置        如果访问的网页被重定向到其他地方时，系统只会提示网页被重定向了，并不会跳转        -L就可以请求到新的页面上    -O 使用URL中默认的文件名保存文件到本地    -o &lt;file&gt; 将网络文件保存为指定的文件中    --limit-rate &lt;rate&gt; 设置传输速度    -0/--http1.0 数字0，使用HTTP 1.0    -v/--verbose 更详细    -C 选项可对文件使用断点续传功能    -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中    -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址    -X/--request &lt;command&gt; 向服务器发送指定请求方法    -U/--proxy-user &lt;user:password&gt; 代理服务器用户和密码    -T 选项可将指定的本地文件上传到FTP服务器上    --data/-d 方式指定使用POST方式传递数据    -b name=data 从服务器响应set-cookie得到值，返回给服务器elinks工具：    字符界面的浏览器，显示页面内容和源码等    elinks [OPTION]... [URL]...    -dump: 非交互式模式，将URL的内容输出至标准输出        比如有些网站是不允许复制的，通过-dump就可以把网站页面文字抓取到本地了        elinks -dump www.baidu.com        不过一般都是用js脚本限制了复制功能，在浏览器关闭js，或查看源码都可以    -source:打印源码</code></pre><h3 id="HTTP介绍"><a href="#HTTP介绍" class="headerlink" title="HTTP介绍"></a>HTTP介绍</h3><p>特性：<br>高度模块化：core + modules<br>DSO: Dynamic Shared Object 动态加/卸载<br>MPM：multi-processing module多路处理模块</p><h3 id="HTTP的三种工作模型：MPM工作模式"><a href="#HTTP的三种工作模型：MPM工作模式" class="headerlink" title="HTTP的三种工作模型：MPM工作模式"></a>HTTP的三种工作模型：MPM工作模式</h3><font size="3" color="#FF0000"><br>多用途的处理模块，三种模型分别是，默认使用prefork模型<br>因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型<br></font><h3 id="1-prefork：多进程I-O模型，每个进程响应一个请求，默认模型"><a href="#1-prefork：多进程I-O模型，每个进程响应一个请求，默认模型" class="headerlink" title="1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型"></a>1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型</h3><pre><code>一个主进程：生成和回收n个子进程，创建套接字，不响应请求多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个，消耗比较大内存资源受限于并发访问控制的内部系统调用机制：        select()；内生使用限制最多只能使用1024个描述符，所以最多也就1024个进程        epoll();Prefork MPM: 预派生模式，有一个主控制进程，然后生成多个子进程，使用select模型，最大并发1024，每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定，可以设置最大和最小进程数，是最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景。优点：稳定缺点：慢，占用资源，不适用于高并发场景配置文件原内容：&lt;IfModule mpm_prefork_module&gt;    StartServers           5 #定义apache服务在启动时启动的子进程数量    MinSpareServers         5 #定义最小空闲进程数，空闲进程就是没有处理用户请求的进程数    MaxSpareServers        10 #定义最大空闲进程数    MaxRequestWorkers      250 #定义在prefork模式下的最大并发连接数，表示了apache的最大并发处理能力，超过的连接请求将被排队等候处理。    MaxConnectionsPerChild   0  #进程生命周期内，处理的最大请求数目。达到该数目后，进程将死掉。如果设置    为0，表示没有限制。该参数的意义在于，避免了可能存在的内存泄露带来的系统问题。&lt;/IfModule&gt;如果确定合适的MaxRequestWorkers呢？首先，通过top命令查看apache进程占用的资源，主要看%CPU和%MEM这两个指标，例如，每个进程的CPU占用率不超过1%，每个进程的内存占用率不超过2%，考虑内存限制，比较合适的apache进程数量为50个，然后，逐步测试最大值。通过观测得来的CPU和内存的指标有一定的误差，一般可以适当调节这个数值，例如调到1.5或者2倍，再通过峰值场景下的机器是否卡顿来判断是继续上调还是下调。</code></pre><p><img src="/2018/12/18/HTTP协议/Prefork.png" alt="Prefork"></p><h3 id="2-worker：复用的多进程I-O模型-多进程多线程，IIS使用此模型"><a href="#2-worker：复用的多进程I-O模型-多进程多线程，IIS使用此模型" class="headerlink" title="2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型"></a>2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型</h3><pre><code>一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！woker MPM：是一种多进程和多线程混合的模型，有一个控制进程，启动多个子进程，每个子进程里面包含固定的线程，使用线程程来处理请求，当线程不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求，由于其使用了线程处理请求，因此可以承受更高的并发。优点：相比prefork 占用的内存较少，可以同时处理更多的请求缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生）配置文件原内容详解：&lt;IfModule mpm_worker_module&gt;    StartServers         3   # #定义apache服务在启动时启动的子进程数量，默认是3个     MinSpareThreads      75   # 整个控制进程保持最小数的空闲线程数    MaxSpareThreads      250  # 整个控制进程保持最大数的空闲线程数    #ThreadLimit        64   # 每个子进程可以启动的线程数量上限值，默认没有设置    ThreadsPerChild      25   # 每个子进程启动的线程默认数量，开启启动两个子进程每个子进程25个 线程，就是apache 启动后开启25个线程。    MaxRequestWorkers    400   # 所有子进程加起来的线程数量最大值，数量等于最大启动的进程数*ThreadsPerChild(每个进程的线程数)    MaxConnectionsPerChild   0  # 每个子进程被请求多少次服务后被kill掉重新生成一个新的子进程，为了解决内存回收方面的问题，0为不设置&lt;/IfModule&gt;</code></pre><p><img src="/2018/12/18/HTTP协议/Worker.png" alt="Worker"></p><h3 id="3-event：事件驱动模型（worker模型的优化-worker模型的变种）"><a href="#3-event：事件驱动模型（worker模型的优化-worker模型的变种）" class="headerlink" title="3.event：事件驱动模型（worker模型的优化,worker模型的变种）"></a>3.event：事件驱动模型（worker模型的优化,worker模型的变种）</h3><pre><code>event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用每一个cpu核心生成一个进程；一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n            注意这里的m*n和work的m*n是不同的机制相比较worker的有点：有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力event MPM：Apache中最新的模式，属于事件驱动模型(epoll)，每个进程响应多个请求，在现在版本里的已经是稳定可用的模式。它和worker模式很像，最大的区别在于，它解决了keep-alive场景下，长期被占用的线程的资源浪费问题（某些线程因为被keep-alive，空挂在哪里等待，中间几乎没有请求过来，甚至等到超时）。event MPM中，会有一个专门的线程来管理这些keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放。这样增强了高并发场景下的请求处理能力。event只在有数据发送的时候才开始建立连接，连接请求才会触发工作线程，即使用了TCP的一个选项，叫做延迟接受连接TCP_DEFER_ACCEPT，加了这个选项后，若客户端只进行TCP连接，不发送请求，则不会触发Accept操作，也就不会触发工作线程去干活，进行了简单的防攻击（TCP连接）,可以使用Telnet进行测试验证：主机192.168.10.130为客户端机器，192.168.10.131为apache服务器机器使用event模式：     在192.168.10.130上telnet 192.168.10.131 80，然后在192.168.10.130客户端机器上使用netstat查看，发现连接已经建立，处于ESTABLISHED状态，然后再到apache服务器192.168.10.131使用netstat查看，发现是处于SYN_RECV状态。优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放 缺点：没有线程安全控制配置文件内容：&lt;IfModule mpm_event_module&gt;    StartServers           3  #apache服务启动的子进程数，默认3个    MinSpareThreads         75  #控制进程保持最小的空闲线程数    MaxSpareThreads        250  #控制进程保持的最大空闲线程数    ThreadsPerChild         25  #每个子进程启动的线程数    MaxRequestWorkers       400  #并发最大请求数，也就是所有子进程加起来的线程数量，woker模式下的    400就是并发400，但是由于是异步处理请求的，因此这里的400比woker模型下的并发处理速度要快很多，因为event省略了工作线程的会话保持。    MaxConnectionsPerChild    0  #每个子进程请求多少次以后被kill掉重新生成一个新的子进程。&lt;/IfModule&gt;</code></pre><p><img src="/2018/12/18/HTTP协议/event.png" alt="event"></p><pre><code>注意：    event模型的强大的I/O机制    httpd从设计上就默认支持prefork    而nginx从设计上就支持event事件驱动模型</code></pre><h3 id="进程工作的角色切换"><a href="#进程工作的角色切换" class="headerlink" title="进程工作的角色切换"></a>进程工作的角色切换</h3><p><img src="/2018/12/18/HTTP协议/进程角色切换原理.png" alt="进程间的角色切换"></p><h3 id="Httpd的功能特性"><a href="#Httpd的功能特性" class="headerlink" title="Httpd的功能特性"></a>Httpd的功能特性</h3><p>httpd的常见特性：</p><ul><li>虚拟主机：在一个物理服务器上搭建多个网站<br>  IP、Port、FQDN</li><li>CGI：Common Gateway Interface，通用网关接口<br>  通过CGI接口处理动态的程序处理</li><li>反向代理<br>  当有用户访问量大时，在前端有一个服务器充当调度器的角色<br>  通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息<br>  看不到后端真正提供服务的服务器群</li><li>负载均衡</li><li>路径别名</li><li>丰富的用户认证机制<br>  basic<br>  digest</li><li>支持第三方模块</li></ul><h3 id="Httpd2-4新特性和安装以及配置"><a href="#Httpd2-4新特性和安装以及配置" class="headerlink" title="Httpd2.4新特性和安装以及配置"></a>Httpd2.4新特性和安装以及配置</h3><pre><code>新特性    MPM支持运行为DSO机制；以模块形式按需加载        在centos7上的httpd2.4上只有一个二进制程序            /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可        但是在centos6上的httpd2.2版本：            每个MPM模式都有各自对应的二进制程序                /usr/sbin/httpd                /usr/sbin/httpd.event                /usr/sbin/httpd.worker            如果更改MPM的模式，是需要改对应的二进制程序的    event MPM生产环境可用    异步读写机制    支持每模块及每目录的单独日志级别定义    每请求相关的专用配置    增强版的表达式分析式    毫秒级持久连接时长定义：httpd2.2只能精确到秒级别        上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的        所以在http中是可以定义连接时长(时长和传输请求两种方式)的    基于FQDN的虚拟主机不需要NameVirutalHost指令        httpd2.2创建虚拟主机时还需要NameVirutalHost指令        httpd2.4就不需要了    新指令，AllowOverrideList    支持用户自定义变量    更低的内存消耗</code></pre><h3 id="Httpd2-4的具体安装和配置"><a href="#Httpd2-4的具体安装和配置" class="headerlink" title="Httpd2.4的具体安装和配置"></a>Httpd2.4的具体安装和配置</h3><p>Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了<br>还支持第三方的模块，按需加载模块<br>存放模块的路径：/etc/httpd/modules</p><pre><code>CentOS7程序环境安装：httpd-2.4    yum install httpd     yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档主要配置文件：    /usr/sbin/httpd     httpd的主程序文件    /usr/lib/systemd/system/httpd.service   httpd的启动单元文件    /etc/httpd/conf/httpd.conf              主要配置文件        配置文件里的路径都是以/etc/httpd/为参考点的    /etc/httpd/conf.d/*.conf    /etc/httpd/conf.modules.d/00-mpm.conf    mpm相关    /etc/httpd/conf.modules.d/00-proxy.conf  配置代理相关    /etc/httpd/conf.modules.d/00-systemd.conf     /etc/httpd/conf.modules.d/01-cgi.conf    CGI相关    /var/cache/httpd    httpd的缓存目录    /var/log/httpd      httpd的日志文件目录            access_log: 访问日志            error_log：错误日志    /etc/httpd/modules  httpd的模块存放路径，软件比较复杂    /usr/lib64/httpd/modules   也是httpd的模块存放路径        两个模块的路径实际上是软链接关系    /var/www/html       httpd存放网页的目录：默认index.html帮助文档包：在没有网络时查看帮助文档，建议安装    httpd-manual检查配置文件语法：    httpd –t    类似DNS的rndc语法检查功能    sudo：visudo功能    ansible:ansible -C|--check 执行前检查语法功能    cobbler 也有httpd的控制和启动命令    systemctl enable|disable httpd.service    systemctl {start|stop|restart|status|reload} httpd.service    备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作        有时reload是无效的，只能restart服务</code></pre><h3 id="Httpd2-4的常见配置"><a href="#Httpd2-4的常见配置" class="headerlink" title="Httpd2.4的常见配置"></a>Httpd2.4的常见配置</h3><ul><li><p>1.显示服务器版本信息HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a></p><p>  主要组成:</p><pre><code>Global Environment   全局配置Main server configuration   一个服务器上搭建一个网站叫主服务器virtual host   虚拟主机，一台主机上搭建多个网站</code></pre></li></ul><p>练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)<br>egrep -v ‘^ <em>#.</em>|^$’ /etc/httpd/conf/httpd.conf</p><font size="3" color="#FF0000"><br>常见配置一般都在/etc/httpd/conf/httpd.conf的文件中<br>没有的配置选项可以加在httpd.conf文件最后，也可以放在<br>/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf<br>下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加<br></font><ul><li>1.显示服务器版本信息<br>  访问<a href="http://192.168.34.103" target="_blank" rel="noopener">http://192.168.34.103</a><br>  打开f12调试模式，可以看到回应头的信息中带有apache的版本信息<br>  也可以通过curl -I <a href="http://192.168.34.103来显示头信息" target="_blank" rel="noopener">http://192.168.34.103来显示头信息</a><br>  可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全<br>  查看指令参考文档：修改ServerTokens选项<pre><code>建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全</code></pre></li><li><p>2.修改监听的IP和Port<br>  Listen [IP:]PORT<br>  (1) 省略IP表示为本机所有IP<br>  (2) Listen监听端口至少一个，可以有多个端口<br>  (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口</p><pre><code>test.conf添加listen端口：listen 172.18.132.151:6666 6666端口只能通过此IP才能访问</code></pre></li><li><p>3.持久连接：默认KeepAlive是开启的<br>  Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接<br>  断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级<br>  副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞<br>  折衷：使用较短的持久连接时间</p><pre><code>设置：    KeepAlive On|Off       设置持久连接开启或者关闭    KeepAliveTimeout 15    设置持久连接为15s测试：telnet WEB_SERVER_IP PORT    GET /index.html HTTP/1.1    Host: WEB_SERVER_IP  host可以随便填写，但是在虚拟主机中是有区别的</code></pre></li><li><p>4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event<br>  默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf  修改mpm的文件<br>  建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的<br>  查看静态编译的模块<br>  httpd -l<br>  查看当前系统中httpd的静态编译及动态装载的加载的模块<br>  httpd –M<br>  动态模块加载：不需重启即生效<br>  动态模块路径<br>   /usr/lib64/httpd/modules/</p><pre><code>切换使用的MPM模块    在/etc/httpd/conf.modules.d/00-mpm.conf中    选择要启用的MPM相关的LoadModule指令即可prefork的配置：    StartServers 8               MinSpareServers 5       保留5个空闲子进程处理新的请求    MaxSpareServers 20      允许的最大空闲进程数    ServerLimit 256         最多进程数,最大20000，并发量建议最多10000         MaxRequestsPerChild     4000 子进程最多能处理的请求数量。在处理    MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进    程占用的内存就会释放(为0时永远不释放）worker和prefork配置类似，只不过会有线程数量的限制</code></pre><p>从下面ps auxf的进程图可以看书httpd是使用的prefork模型，而且因为端口是80，开启需要特殊<br>权限，所以父进程是root,子进程是apache</p></li></ul><p><img src="/2018/12/18/HTTP协议/HTTPD的prefork模型.png" alt=""></p><ul><li><p>5.DSO： Dynamic Shared Object<br>  加载动态模块配置<br>  /etc/httpd/conf/httpd.conf<br>  Include conf.modules.d/*.conf<br>  配置指定实现模块加载格式：<br>  LoadModule &lt;mod_name&gt; &lt;mod_path&gt;<br>  模块文件路径可使用相对路径：<br>  相对于ServerRoot（默认/etc/httpd）</p></li><li><p>6.定义’Main’ server的文档页面路径：存放页面的主目录<br>  主目录是由DocumentRoot指令来设置的<br>  网页文件默认是存在/var/www/html/下的，此处可以自定义<br>  在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html”</p><pre><code>如果要自定义主目录，还需要设置该目录为允许访问在httpd2.2上是不需要设置权限访问的但是在httpd2.4上是需要设置该目录允许访问的修改格式如下：#DocumentRoot &quot;/var/www/html&quot;DocumentRoot &quot;/data/www&quot;&lt;directory /data/www&gt;    Require all granted&lt;/directory&gt; </code></pre></li><li><p>7.定义站点默认主页面<br>  访问192.168.34.103默认显示的是index.html的内容，<br>  这一项是由DirectoryIndex指令设置的</p><pre><code>在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件</code></pre><font color="#FF0000"><br>此处需要了解httpd的权限和访问报错的相关问题和默认主页面：<br>1.访问192.168.34.103跳出的页面默认是index.html页面，如果不存在，则去找conf.d/welcome.conf文件，即报错提示，如果两个都不存在，显示的是/var/www/html目录下的文件列表，因为在httpd.conf配置文件中，定义options indexes选项<br>2.默认页面和默认访问目录都是可以通过指令来指定的<br>3.如果没有index.html文件，没有welcome.conf文件，没有options indexes配置，访问时会报错You don’t have permission to access / on this server.的提示.<br>4.上面三条在下面第12条配置别名时，可以体现的很明显<br>5.所以如果自定义目录和用别名，有时是需要设置目录访问权限、设置目录对应的index.html文件或者跳转的html文件(如果该文件存在就不需要设置了)，设置options indexes选项<br></font></li><li><p>8.站点访问控制常见机制<br>  可基于两种机制指明对哪些资源进行何种访问控制<br>  访问控制机制有两种：1.客户端来源地址，2.用户账号<br>  而文件系统路径：可以是<br>  1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配<br>  示例：<br>  ‘<filesmatch "\.(gif|jpe?g|png)$"="">‘’   用的是扩展的正则表达式<br>  <files “?at.*”="">                     通配符<br>  &lt;Location /status&gt;</files></filesmatch></p>  <locationmatch "="" (extra|special)="" data"=""></locationmatch></li><li><p>9.<directory>中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制<br>   (1) Options：后跟1个或多个以空白字符分隔的选项列<br>  在选项前的+，- 表示增加或删除指定选项<br>  常见选项：<br>  Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制<br>  适用于下载网站和镜像网站，不适合电商网站<br>  FollowSymLinks：允许访问符号链接文件所指向的源文件,<br>  None：全部禁用<br>  All： 全部允许</directory></p><pre><code>Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站    &lt;directory &quot;/data/www&quot;&gt;    options Indexes                                              Require all granted    &lt;/directory&gt;FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件    &lt;directory &quot;/data/www&quot;&gt;    options Indexes  FollowSymLinks           Require all granted    &lt;/directory&gt;</code></pre><font size="4" color="#FF0000"><br>实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.conf文件，welcome.conf文件就是页面上经常看到的测试123页面，把welcome.conf文件改名或删除，就会显示主目录下的所有列表文件了.<br></font><p>  (2) AllowOverride<br>  allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可<br>  只对<directory>语句有效;<br>  allowoverride权限时卸载httpd的*.conf配置文件中的<br>  AllowOverride All: .htaccess中所有指令都有效<br>  AllowOverride None： .htaccess 文件无效<br>  AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它</directory></p><pre><code>配置allowoverride示例：/etc/httpd/conf.d/test.conf中添加访问控制的目录    &lt;directory /data/www&gt;    allowoverride all  --&gt;这条必须写，代表.htaccess文件中的options生效    Require all granted    &lt;/directory&gt;在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中    options indexes FollowSymLinks</code></pre><p>  (3) 基于IP的访问控制:<br>  无明确授权的目录，默认拒绝<br>  允许所有主机访问：Require all granted<br>  拒绝所有主机访问：Require all denied<br>  控制特定的IP访问：<br>  Require ip IPADDR：授权指定来源的IP访问<br>  Require not ip IPADDR：拒绝特定的IP访问<br>  控制特定的主机访问：<br>  Require host HOSTNAME：授权特定主机访问<br>  Require not host HOSTNAME：拒绝<br>  HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机</p><pre><code>基于IP的访问控制示例：如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表除了/data/www/ceshi文件夹    &lt;directory /data/www&gt;    options indexes                                                      &lt;RequireAll&gt;    Require all granted    Require not ip 192.168.34.107    &lt;/RequireAll&gt;    &lt;/directory&gt;2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问&lt;directory /data/www&gt;options indexesRequire all granted&lt;/directory&gt;&lt;directory /data/www/ceshi&gt;&lt;RequireAny&gt;Require all deniedRequire ip 192.168.34.107&lt;/RequireAny&gt;                                                 &lt;/directory&gt;</code></pre></li><li><p>10.日志设定：日志默认/var/log/httpd/下<br><a href="http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats" target="_blank" rel="noopener">format官方说明文档</a><br>  日志类型：访问日志(access_log)和错误日志(error_log)<br>  日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式</p><pre><code>在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined   --&gt;由Logformat指令定义完起一个combined名CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式ErrorLog &quot;logs/error_log&quot;</code></pre><p>  可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径</p><pre><code>日志中的格式各个项说明%h 客户端IP地址%l 远程用户,启用mod_ident才有效，通常为减号“-”%u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-”%t 服务器收到请求时的时间%r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本%&gt;s 响应状态码%b 响应报文的大小，单位是字节；不包括响应报文http首部%{Referer}i     请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页    是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源，所以网站一般要加防盗链，防止资源被盗和占用服务器资源%{User-Agent}i 指客户端的浏览器版本</code></pre></li><li><p>11.设定默认字符集<br>  一般不需要设置：基本上使用的是utf-8;<br>  AddDefaultCharset UTF-8 此为默认值</p><pre><code>如果需要修改字符集，在test.conf或者httpd.conf下添加AddDefaultCharset gb2312 即可</code></pre></li><li><p>12.定义路径别名<br>作用：默认访问的文件夹是设置的DocumentRoot文件夹，如果不是在默认文件夹下，而需求要实现把其他路径下的目录共享出来，这就用到了定义路径别名的功能</p><p>  把一个URL起一个别名不指向真正的目录<br>  在httpd2.4里目录如果没有开启允许时，默认是不允许访问的</p><pre><code>例如：访问 /var/www/html/111,111这个目录可有可无，只是充当别名    实际上访问的是/data/www/ceshi目录         directoryindex ceshi.html        alias /111 /data/www/ceshi        &lt;directory /data/www/ceshi&gt;        options indexes        Require all granted        &lt;/directory&gt;         </code></pre></li></ul><font color="#FF0000"><br>注意：<br>1.111只是一个别名，在/var/www/html下不需要创建；但是如果/var/www/html下有111的文件夹，如果设置别名后，则访问的是/data/www/ceshi目录，原目录下的111文件夹就失效了。<br>2.在这里和上文第7条设置权限时有联系的，httpd2.4设置路径别名的时候，真正的路径也是需要在test.conf下设置权限的(/data/www/ceshi目录)<br>3.如果/data/www/ceshi/下没有index.html会报权限不允许的错误，所以要设置默认主页面directoryindex，当然可以设置options indexes选项<br></font><ul><li><p>13.基于虚拟账户的登录访问控制：提示401状态码<br>  认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码<br>  认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源<br>  两种认证方式：<br>  basic：用的多，缺点是明文，后面可以用https进行加密<br>  digest：兼容性差，用的少<br>  用户的账号和密码:非linux用户密码<br>  虚拟账号：多种存储方式，只用于httpd服务的，类似vsftp，samba服务的虚拟用户<br>  存储：账号可放在文本文件，SQL数据库，ldap目录存储，nis等</p><pre><code>因为basic使用的多，下文以basic认证配置示例1.提供账号和密码存储（文本文件），如创建一个tom虚拟账户管理httpd    htpasswd --&gt;可以指定加密算法        -c 自动创建文件，仅应该在文件不存在时使用        -p 明文密码        -d CRYPT格式加密，默认        -m md5格式加密        -s sha格式加密        -D 删除指定用户    htpasswd -c httpdpass tom :设定密码即可;目录可指定，后面改配置文件即可    htpasswd -s httpdpass jerry 再添加jerry用户，就不需要-c选项了    htpasswd -D httpdpass jerry 从文件中删除jerry用户    修改httpdpass权限，加固安全 chmod 600 httpdpass     或者也可以创建组文件httpdgroup，通过组来管理,组文件组和成员列表    testgroup: tom jerry2. 在test.conf或者httpd.conf下定义安全域    &lt;directory /var/www/html/ksdir&gt;    AuthType Basic          ---&gt;使用的认证方式    AuthName &quot;Login&quot;        ----&gt;登录提示信息    AuthUserFile &quot;/etc/httpd/conf/httpdpass&quot;  --&gt;加密账户文件    AuthGroupFile &quot;/etc/httpd/conf/httpdgroup&quot; --&gt;组账户    Require user tom        ---&gt;允许用户访问的列表    Require group testgroup  ---&gt;允许访问的组    &lt;/directory&gt;    但是：因为httpd线程是以apache运行的，而httpdpass是600权限，所以默认tom登录是没有权限的，让apache对httpdpass有读权限：    setfacl -m u:apache:r httpdpass 即可</code></pre></li><li><p>14.实现用户家目录的http共享;并实现账户机密访问<br>  实现基础：基于模块mod_userdir.so实现<br>  httpd -M |grep user 可以看出user加密的模块是已经加载的，直接改配置文件即可<br>  在/etc/httpd/conf.d/userdir.conf文件中定义了家目录共享的格式，只需要启用就行了</p><pre><code>实现步骤：1. vim /etc/httpd/conf.d/userdir.conf    &lt;IfModule mod_userdir.c&gt;     UserDir enabled      ---&gt;启用即可；默认不启用    UserDir public_html  ---&gt;创建一个public_html文件    &lt;/IfModule&gt;2.在test家目录下，创建public_html文件夹和public_html文件    su test    mkdir public_html/    echo 23333 &gt; /public_html/public_html3.因为httpd线程是apache身份登录的，所以要允许apache访问test用户的家目录    setfacl -m u:apache:x /home/test4.设置test家目录访问权限及用户加密    &lt;directory /home/test/public_html&gt;        authtype basic    authname &quot;test home&quot;    authuserfile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;调用之前创建的虚拟账户文件即可    Require user haha    &lt;/directory&gt;5.http访问test家目录方式,即可用加密账户登录    192.168.34.103/~test</code></pre></li><li><p>15.ServerSignature On|Off|EMail<br>  作用：当用户访问的页面不存在的情况下服务器会产生错误文档，而当ServerSignature选项是打开的情况下，错误文档会将服务器的名字，apahce的版本信息，显示在页面上，某种程度上会对web服务器产生不安全因素，所以一般建议关闭</p><pre><code>在配置文件添加一行：ServerSignature off 即可</code></pre></li><li><p>16.status页面<br>  作用：显示apache的工作状态，有助于判断apache是否正常工作<br>  status页面功能是由下面这个模块实现的：httpd<br>  LoadModule status_module modules/mod_status.so</p><pre><code>实现步骤：在配置文件添加&lt;Location &quot;/status&quot;&gt; SetHandler server-status&lt;/Location&gt;ExtendedStatus ON   #显示扩展信息</code></pre><p>  记录的信息包括：启动时间，线程数，等待连接数，cpu，进程，MPM等信息<br>  在实际生产中，由于apache服务器很多，就可以通过curl 192.168.34.103/status来抓取页面，分析apache某个指标是不是正常的；</p><pre><code>比如编写简单一个脚本：    curl 192.168.34.103/status |grep &quot;Apache Status&quot; || systemctl start httpd</code></pre></li><li><p><font size="5" color="#FF0000">17.实现http的虚拟主机</font><br>  作用：一个物理服务器上实现多台虚拟主机，至于为什么会用到虚拟主机，有可能是因为要上线的同一网站的有多个域名，却只有一个公网IP地址，也有可能是主机不多啊..，所以虚拟主机的价值就体现出来了…</p><p>  实现虚拟主机有三种方式</p><pre><code>基于ip：为每个虚拟主机准备至少一个ip地址，一个主机可以配多个内网IP地址基于port：为每个虚拟主机使用至少一个独立的port；80,8081,8082等等基于FQDN：为每个虚拟主机使用至少一个FQDN</code></pre><p>  当然这三种方式，基于IP和port的对于用户来说不太现实，一般都是通过输入域名方式来实现虚拟主机搭建.</p><pre><code>1.基于IP的虚拟主机搭建：但是这种方式用的比较少先准备三个网站目录，和在本机上添加三个IP地址    &lt;virtualhost 192.168.34.103&gt;    DocumentRoot &quot;/data/asite&quot;    &lt;directory /data/asite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_a.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.200&gt;    DocumentRoot &quot;/data/bsite&quot;    &lt;directory /data/bsite&gt;    Require all granted    &lt;/directory&gt;    customlog /var/log/httpd/access_b.log combined    &lt;/virtualhost&gt;    &lt;virtualhost 192.168.34.210&gt;    DocumentRoot &quot;/data/csite&quot;    &lt;directory /data/csite&gt;    Require all granted    &lt;/directory&gt;重启服务即可通过curl 192.168.34.103      curl 192.168.34.200    curl 192.168.34.210即可获取到各自的index.html文件内容，对应的日志也都生成了</code></pre><p>  2.基于port的虚拟主机搭建，监听三个port即可;使用的不多</p><pre><code>listen 8081listen 8082listen 8083&lt;virtualhost *:8081&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8082&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:8083&gt;                                                                                                      servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;</code></pre><p>  通过本机IP+port获得不同网站的信息</p><pre><code>curl 192.168.34.103:8081curl 192.168.34.103:8082curl 192.168.34.103:8083</code></pre><p>  3.基于FQDN的虚拟主机搭建：用的最多<br>  前提：这里就不搭建DNS服务器了，使用本机的hosts文件进行域名解析</p><pre><code>&lt;virtualhost *:80&gt;servername &quot;www.a.com&quot;DocumentRoot &quot;/data/asite&quot;&lt;directory /data/asite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_a.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;servername &quot;www.b.cn&quot;DocumentRoot &quot;/data/bsite&quot;&lt;directory /data/bsite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_b.log combined&lt;/virtualhost&gt;&lt;virtualhost *:80&gt;                                                                                                     servername &quot;www.c.net&quot;DocumentRoot &quot;/data/csite&quot;&lt;directory /data/csite&gt;Require all granted&lt;/directory&gt;customlog /var/log/httpd/access_c.log combined&lt;/virtualhost&gt;</code></pre><p>  测试：curl <a href="http://www.a.com" target="_blank" rel="noopener">www.a.com</a></p><pre><code>curl www.b.cncurl www.c.net</code></pre><p>  就可获得各自的主页面信息<br>从这telnet就可以理解出，如果在互联网通过域名访问时(同一IP)，返回的结果是不同网站的信息<br>  [root@node7-1 ~]#telnet 192.168.34.103 80</p><pre><code>Trying 192.168.34.103...Connected to 192.168.34.103.Escape character is &apos;^]&apos;.GET /index.html HTTP/1.1HOST: www.a.com</code></pre></li></ul><font size="4" color="#FF0000"><br>当访问192.168.34.103时 HOST：即网站的域名，返回的结果就是其对应的页面信息<br>在互联网上，一般是先在本地服务器上通过第三种方式搭建多个网站，然后再通过服务商的智能DNS解析，可以通过访问不同的域名，解析到IP地址，服务器根据输入的HOST：域名判断访问的是哪个网站，进而返回对应网站站点的信息，对于主机较少或者IP有限的环境中，使用http虚拟主机还是很方便的。<br></font>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;a href=&quot;#HTTP协议和APACHE原理&quot; class=&quot;headerlink&quot; title=&quot;HTTP协议和APACHE原理&quot;&gt;&lt;/a&gt;HTTP协议和APACHE原理&lt;/h3&gt;&lt;p&gt;Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等&lt;br&gt;本文说的是HTTP SERVER&lt;a href=&quot;http://www.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;apache&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="http" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/http/"/>
    
    
      <category term="Web服务" scheme="https://www.liukui.tech/tags/Web%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>编译安装LAMP</title>
    <link href="https://www.liukui.tech/2018/12/10/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85LAMP/"/>
    <id>https://www.liukui.tech/2018/12/10/编译安装LAMP/</id>
    <published>2018-12-10T00:00:00.000Z</published>
    <updated>2019-01-22T08:46:48.428Z</updated>
    
    <content type="html"><![CDATA[<p>LAMP<br><a id="more"></a></p><p><img src="/2018/12/10/编译安装LAMP/LAMP架构.png" alt=""></p><h3 id="Centos7上编译安装LAMP"><a href="#Centos7上编译安装LAMP" class="headerlink" title="Centos7上编译安装LAMP"></a>Centos7上编译安装LAMP</h3><pre><code>    备注：本文编译PHP是基于fastCGI方式，php-fpm编译准备：    在192.168.34.105上实现，准备安装包都放在/data/src下        apr-1.6.5.tar.bz2        apr-util-1.6.1.tar.bz2        httpd-2.4.37.tar.bz2        php-7.1.18.tar.bz2        wordpress-5.0-zh_CN.zip        mariadb-10.2.19-linux-x86_64.tar.gz    准备开发包组：        yum install &apos;develoment tools&apos; -y    1.编译安装httpd和apr        准备依赖包和解压安装包        yum install pcre-devel openssl-devel expat-devel apr-util-devel -y        tar xvf apr-1.6.5.tar.bz2        tar xvf apr-util-1.6.1.tar.bz2         tar xvf httpd-2.4.37.tar.bz2        cp -r apr-1.6.5 httpd-2.4.37/srclib/apr        cp -r apr-util-1.6.1 httpd-2.4.37/srclib/apr-util        a.编译            cd httpd-2.4.37            ./configure \            --prefix=/data/httpd24 \            --enable-so \            --enable-ssl \            --enable-cgi \            --enable-rewrite \            --with-zlib \            --with-pcre \            --with-included-apr \            --enable-modules=most \            --enable-mpms-shared=all \            --with-mpm=prefork            make &amp;&amp; make install        b.准备环境变量            用自带的服务控制脚本：/app/httpd24/bin/apachectl就需要设置环境变量了            echo &apos;PATH=/mysql/httpd24/bin:$PATH&apos; &gt; /etc/profile.d/httpd24.sh            . /etc/profile.d/httpd24.sh        c.修改配置文件，为了安全以apache用户运行，并监听在本地            useradd -r -s /sbin/nologin apache            vim /data/httpd24/conf/httpd.conf                User apache                Group apache                ServerName localhost:80    2.二进制安装mariadb-10.2.19        a.准备用户和mysql数据库目录                useradd -r -s /sbin/nologin -d /data/mysql mysql                mkdir /data/mysql                chown mysql.mysql mysql/        b.解压二进制安装包：            tar xvf mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local/            cd /usr/local            ln -s mariadb-10.2.19-linux-x86_64/ mysql            chown -R root.mysql /usr/local/mysql/        c.创建数据库文件:(通过自带脚本工具)            cd /usr/local/mysql/            scripts/mysql_install_db --datadir=/mysql/data --user=mysql        d.准备配置文件(不修改/etc/my.cnf)拷贝解压完的文件            mkdir /etc/mysql/            cp support-files/my-huge.cnf /etc/mysql/my.cnf                                路径优先级高于/etc/my.cnf                根据性能来拷贝配置文件            [mysqld]中添加三个选项：/etc/mysql/my.cnf            datadir = /mysql/data            innodb_file_per_table = on            skip_name_resolve = on 禁止主机名解析，建议使用        e.准备服务脚本，并启动服务            cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld            chkconfig --add mysqld            service mysqld start        f.准备PATH路径            echo &apos;PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh            . /etc/profile.d/mysql.sh            systemctl start mysqld        为wordpress准备数据库和账号密码            mysql -e &apos;create database wordpress&apos;            mysql -e &quot;grant all on *.* to php1@&apos;192.168.34.%&apos; identified by &apos;php123&apos;&quot;    3.FastCGI方式编译安装php-7.1.18        tar xf php-7.1.18.tar.bz2        安装依赖包            yum install libxml2-devel bzip2-devel libmcrypt-devel -y         a.编译，指定安装数据路劲和配置文件路径                   cd php-7.1.18            ./configure --prefix=/data/php \            --enable-mysqlnd \            --with-mysqli=mysqlnd \            --with-openssl \            --with-pdo-mysql=mysqlnd \            --enable-mbstring \            --with-freetype-dir \            --with-jpeg-dir \            --with-png-dir \            --with-zlib \            --with-libxml-dir=/usr \            --enable-xml \            --enable-sockets \            --enable-fpm \            --with-config-file-path=/etc \            --with-config-file-scan-dir=/etc/php.d \            --enable-maintainer-zts \            --disable-fileinfo            make &amp;&amp; make install        b.准备php配置文件            cd php-7.1.18            cp php.ini-production /etc/php.ini                可以修改当前时区和按照生产环境修改并发连接数等信息        c.创建nginx用户            useradd -s /sbin/nologin nginx        d.准备php的conf文件            cd /data/php            cp php-fpm.conf.default php-fpm.conf            cp php-fpm.d/www.conf.default php-fpm.d/www.conf            修改监听地址和允许连接地址，因为是在一台编译的，监听地址不用改了                vim php-fpm.d/www.conf                    listen = 127.0.0.1:9000                    ;listen.allowed_clients = 127.0.0.1                    user = nginx                    group = nginx        e.准备服务脚本:            cp /data/src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm            chmod +x /etc/init.d/php-fpm            chkconfig --add php-fpm            chkconfig php-fpm on    4.修改httpd文件，支持php和启用代理        编辑apache配置文件httpd.conf，以使apache支持php,并启用代理        vim /data/httpd24/conf/httpd.conf            1.取消下面两行的注释                LoadModule proxy_module modules/mod_proxy.so                LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so            2.定位至DirectoryIndex index.html                修改为DirectoryIndex index.php index.html            3.最后添加4行        AddType application/x-httpd-php .php        AddType application/x-httpd-php-source .phps        ProxyRequests Off        ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1             重启apache服务，apachectl restart    5.准备wordpress,把wordpress文件全部移动到httpd24/htdocs下        cd /data/src        unzip wordpress-5.0-zh_CN.zip        cd wordpress        mv * /data/httpd24/htdocs        为wordpress准备配置文件和数据库连接            cd /data/httpd24/htdocs            mv wp-config-sample.php wp-config.php            vim wp-config.php                define(&apos;DB_NAME&apos;, &apos;wordpress&apos;);                define(&apos;DB_USER&apos;, &apos;php&apos;);                define(&apos;DB_PASSWORD&apos;, &apos;php123&apos;);                define(&apos;DB_HOST&apos;, &apos;192.168.34.105&apos;);        修改/data/httpd24/htdocs的所有者和所属组            cd /data/httpd24            chown -R nginx.nginx htdocs/    到此所以的编译安装和准备工作都做完了，把mysql,php-fpm,httpd启动即可            apachectl start            systemctl start php-fpm            systemctl start mysqld        http://192.168.34.105 配置wordpress即可    备注：        创建的文章和账户是放在wordpress数据库中的;        图片是放在/data/httpd24/htdocs/wp-content/uploads下的</code></pre><p><font size="4" color="#23238E"><br>然后把这套系统搬到自己的云服务上就可以轻松的实现了,本文是基于LAMP架构实现的<br>不过推荐使用LNMP架构，毕竟Nginx的强大可不是吹出来的..<br></font> </p><p><font size="4" color="#FF0000">安装完成后，开启了一个新的世界，就可以开心的玩耍了,helloworld！</font><br><img src="/2018/12/10/编译安装LAMP/haha.png"><br><img src="/2018/12/10/编译安装LAMP/wordpress.png" width="80%" height="80%"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LAMP&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="个人博客搭建" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="web" scheme="https://www.liukui.tech/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>GlusterFS存储</title>
    <link href="https://www.liukui.tech/2018/12/06/GlusterFS%E5%AD%98%E5%82%A8/"/>
    <id>https://www.liukui.tech/2018/12/06/GlusterFS存储/</id>
    <published>2018-12-06T00:00:00.000Z</published>
    <updated>2019-04-02T13:19:38.907Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="存储" scheme="https://www.liukui.tech/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="https://www.liukui.tech/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>ceph存储基础</title>
    <link href="https://www.liukui.tech/2018/11/03/ceph%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80/"/>
    <id>https://www.liukui.tech/2018/11/03/ceph存储基础/</id>
    <published>2018-11-03T00:00:00.000Z</published>
    <updated>2019-04-03T14:50:18.436Z</updated>
    
    <content type="html"><![CDATA[<h3 id="存储基础"><a href="#存储基础" class="headerlink" title="存储基础"></a>存储基础</h3><a id="more"></a><pre><code>存储设备：1.DAS:IDE，SATA，SCSI，SAS，USB    #DAS直接附加存储是直接接到计算机的主板总线上去的；2.NAS: NFS，CIFS，    #1.NAS(Network Attacked Storage)网络附加存储，文件系统级别的存储；    #2.把一个文件系统挂载到本地的文件系统树上的某一个挂载点上就可以直接访问，因为    它是通过网络附加到当前主机文件系统之上的一个存储空间就称为网络附加存储；    #3.网络附加存储的特点都是文件系统接口(filesystem),本身就是一个做好的文件    系统，通过nfs/cifs接口基于内核级的nfs/cifs模块与远程主机进行通信，把它转    为像本地文件系统一样来使用；    #4.对于这种存储设备我们是没办法对它进行再一次的分区格式化等操作的3.SAN:SCSI    #1.SAN(Storage Area Network)称为存储区域局域网络    #2.与NAS不同的是SAN提供给客户端使用的接口是块(block)级别的，所以SAN大多数使用    的是SCSI协议；    SCSI协议：        SCSI协议也是分层的和tcp/ip协议很像也分数据链路，物理层，传输层，应用层的，不过SCSI只是用来传输数据的存取，SCSI的物理层早期也是使用并行的线缆传输SCSI信号来实现的，SCSI协议的分层设计意味着某一层是可以被替代的；    FC-SAN:        把SCSI的物理层替换成光纤和它对应的协议，就是FC-SAN的形成    ISCSI:        把SCSI的物理层替换成tcp/ip协议和它对应的底层设备(以太网),就是ISCSI    它们其实就是把SCSI协议底层的物理传输接口改换成了另外一种传输信道；    而且SCSI协议本身的传输距离有限，如果是通过以太网传输就大大增加了距离；    所以这种网络提供给客户端的存储接口就称为存储区域网络；大多数SSD使用如SATA、SAS或光纤通道等接口与计算机接口的总线连接。随着固态硬盘在大众市场上的流行，SATA已成为个人电脑中连接SSD的最典型方式；但是，SATA的设计主要是作为机械硬盘驱动器（HDD）的接口，并随着时间的推移越来越难满足速度日益提高的SSD。随着在大众市场的流行，许多固态硬盘的数据速率提升已经放缓。不同于机械硬盘，部分SSD已受到SATA最大吞吐量的限制。在NVMe出现之前，高端SSD只得以采用PCI Express总线制造，但需使用非标准规范的接口。若使用标准化的SSD接口，操作系统只需要一个驱动程序就能使用匹配规范的所有SSD。这也意味着每个SSD制造商不必用额外的资源来设计特定接口的驱动程序</code></pre><h3 id="HDFS分布式存储-文件系统接口"><a href="#HDFS分布式存储-文件系统接口" class="headerlink" title="HDFS分布式存储(文件系统接口)"></a>HDFS分布式存储(文件系统接口)</h3><p>–HDFS分布式存储<br><img src="/2018/11/03/ceph存储基础/HDFS分布式存储.png" alt="HDFS分布式存储"></p><pre><code>前提：    设计成分布式文件系统的根本目的就是为了能够做到按需扩展有状态应用：    如果一个服务的第二次访问请求和第一次请求是有关系的，就是有状态的应用分布式存储：    1.所以分布式存储也是一种有状态应用的一种，如果存储是分布和扩展到多个节点上，以mysql为例，数据第一次写到Storage-A节点,查的时候在分布式存储内部必须要有一个路由机制使得查询的时候还是到Storage-A节点查询，而不是Storage-B|C|D节点;    2.可能你会想把Storage-A节点的数据同步到B|C|D上，查询数据的时候不就路由到哪个节点都可以了？    如果是这样每个存储节点都会拥有全部一样的数据了，这样就不符合分布式存储的定义了；元数据、数据的实现？    元数据就是负责路由的，    以ext4文件系统为例：        inode信息是存储在元数据区的        元数据就是让我们找到所需文件的路由表，但是当我们使用分布式存储时，就不能使用这种传统的在一个分区上来组织数据和元数据了，而是把数据和元数据分开存放分布式存储方式：    1.元数据服务器：(NameNode)        分布式存储的元数据和数据不能像ext4那样，但是可以在存储集群中找一个固定的节点存放元数据    2.写数据：(DataNode)        当客户端想要存储2G的数据请求发给元数据节点后，元数据负责将这2G的数据做指定大小规模进行切块，每一块当做独立的文件进行路由和调度从而达到分散存储的目的，而且还可以并发调度存储到不同的节点充分利用多个节点的磁盘和网络I/O；    3.读数据：(DataNode)        用户读数据时只需要联系元数据服务器，根据在元数据中记录的某一文件切块大小、数量、每一块所在的节点以及块之间的偏移量然后元数据从各个节点上并行的加载这些数据块然后按照元数据中的逻辑由客户端将其组合起来得到完整的数据；NameNode的高可用：    1.如果只有一台元数据服务器就有单点故障，所以要实现NameNode的高可用；    2.但是文件系统的元数据是一类非常密集但是I/O量非常小的数据，所以为了实现请求元数据时的高效，一般是把它放到内存当中，但是当服务器down机时会丢失数据的，所以又需要一种机制持久同步存储到磁盘上；    3.但是当文件修改时，元数据也会被修改，因为无法判断哪个文件会被修改，所以就会造成大量的修改操作同步到磁盘上是随机的，大家都知道随机I/O操作会非常慢；    4.因此为了能够对这些非常密集的文件元数据的修改操作进行高效的同步到磁盘上，一般都不是直接去改那个元数据的，而是像mysql的binlog一样把每一次的操作请求记下来，而不是真正的去修改元数据，将来想要还原回来只需要把日志重放一遍就行了，这样就比较像redis的AOF顺序追加记录机制，这样就把随机I/O改成顺序I/O能够快速的进行同步    磁盘进行保存；    5.顺序I/O(AOF)的缺点就是只能通过重放记录在文件中的指令才能把数据还原回来，而不    是复制，所以恢复速度非常慢；    6.为了避免将元数据同步到磁盘上时恢复时比较慢，现在的方案都是持久放在第三方存储上，第三方存储集群使用zookeeper,这样一来NameNode1宕机了之后，NameNode2就可以快速的从zookeeper中恢复数据；    (这样的解决方案就很类似于把有状态的k8s-apiserver放到etcd集群中一样，不过        zookeepr主要作用于java编程领域，etcd作用于go编程领域)；DataNode的高可用：    由于数据文件是被切成很多块分散存储到多个datanode的，当其中任何一个DataNode宕机都会造成此文件的丢失；    数据存储区的两种高可用方案：    1.在DataNode的节点级做冗余，即每个DataNode都有一个从节点，这样代价有点大；    2.分片级的冗余：        1.可以对存在DataNode上的单个数据块做副本，将副本放到存储集群中的其他DataNode节点上，冗余级别取决于每个数据块的副本数量；        2.这样一来，就可以在NameNode中定义任意个数据块都必须有3个副本数量存在，主分片(primary shard)负责数据复制(replica shard)到事先选择好的其他节点上；把即使任何一个DataNode宕机了也不会影响数据文件的完整性；    3.机架的规划        DataNodeA DataNodeB DataNodeC一般是不在一个机柜的，避免因为一台断电数据        全部丢失；        机柜1：DataNodeA+DataNodeB        机柜2：DataNodeC            A--&gt;B-&gt;C #这样一来至少保证以一台数据的安全性，提高冗余级别；TFS(淘宝)&lt;--HDFS&lt;--GFS(谷歌文件系统)    特点：        这种分布式文件系统的特点是读写接口是受限的，可以随机的/顺序的读，但只能顺        序的写，不能随机的写!!!</code></pre><h3 id="块级别设备存储"><a href="#块级别设备存储" class="headerlink" title="块级别设备存储"></a>块级别设备存储</h3><p>–块设备接口逻辑<br><img src="/2018/11/03/ceph存储基础/块设备接口逻辑.png" alt="块设备接口逻辑"></p><pre><code>区别：    1.块级别的存储就是一个裸设备，提供给我们的就是一个没有被组织过的存储空间，而文件系统存储让我们只能以文件形式来存放数据；    2.但是要注意的是&quot;数据并不一定都是文件形式的，也可以是数据流形式的&quot;，只有把数据流组织起来放在一个特定的文件系统上时的一种表现形式；    3.所以文件系统只是数据的组织存放接口，所有数据流存进来以后都表现为我们看到的、所理解的&quot;一种文件&quot;；而文件系统接口一般是建立在块级别存储接口之上的，我们在一个块级别的存储空间上创建出文件系统来。就可以存放数据流了；    4.像HDFS这种分布式存储最常见的就是文件系统接口，因为在计算机发展中文件系统接口是最经典的接口，因为在计算机中大量的存储都是以文件形式存放的！虽然文件系统接口是最经典最常用的，但有些应用程序确实要求不应该使用文件系统接口，比如KVM,VMware虚拟机启动时使用的磁盘镜像文件，如果提供给它的是文件系统接口它还需要再将文件虚拟成磁盘进行挂载就会影响它的性能，如果是直接提供块设备作为磁盘，它启动时直接加载磁盘不是更好吗;</code></pre><h3 id="对象存储"><a href="#对象存储" class="headerlink" title="对象存储"></a>对象存储</h3><p>–对象存储的存储方式<br><img src="/2018/11/03/ceph存储基础/对象存储的存储方式.png" alt="对象存储的存储方式"></p><pre><code>如上图示：    和文件系统中把数据和元数据分开存放的不同在于：对象存储中每一个数据流都自带数据data和元数据metadata，每一个这样的数据流都被叫做一个对象；    1.这样一来只要找到这个对象就可以知道它的元数据信息不需要再访问元数据区了；    2.这样一来每一个数据对象内部都应该有自己的管理格式用来标记它的数据和元数据所在的位置    3.因此对象是直接放到磁盘之上的，而不是像文件系统那样分开存放；</code></pre><p>–对象的组织格式<br><img src="/2018/11/03/ceph存储基础/对象的组织格式.png" alt="对象的组织格式"></p><pre><code>每一个object是如何被存下来的？    如上图对象是自带数据data和元数据metadata被统一存储的    ID用于集群内部引用    元数据是K/V类型的</code></pre><p>–filestore和bluestore<br><img src="/2018/11/03/ceph存储基础/filestore和bluestore.png" alt="filestore和bluestore"></p><pre><code>FileStore存储方式：    1.将对象转换成文件进行存储，转换成的文件的元数据放在元数据区    2.原来对象自己的元数据都被放在levelDB中        #levelDB也是高性能的K/V类型数据库是直接放在xfs文件系统上    3.对象数据直接存在文件系统上    非标准的文件系统键入元数据BlueStore存储方式：    1.BlueStore=BlueFS+RocksDB        #因为此时OSD是一个裸设备，而RocksDB数据库必须运行在一个文件系统之上，所以在其下也必须有文件系统叫做BlueFS支撑RocksDB数据库运行；    2.此时对象本身就直接存放在OSD裸设备磁盘内，对象的元数据放在RocksDB内    3.而RocksDB为了实现它的安全性需要进行数据持久化保存，使用WAL的方式来写日志；    所以在BlueStore上存储的数据分为三类：        1.数据        2.元数据        3.元数据的元数据，就像redis的AOF文件一样    鉴于以上因素，BlueStore支持三种不同的存储设备，然后就有了这种方案        1.BlueFS和RocksDB放在固态硬盘上        2.对象数据放在机械硬盘上        3.RocksDB的持久化数据放在NVMe上</code></pre><h3 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a>Ceph</h3><p>–ceph微型架构<br><img src="/2018/11/03/ceph存储基础/ceph微型架构.png" alt="ceph微型架构"></p><pre><code>1.Ceph是什么？    Ceph也是分布式存储的一种解决方案，但是和HDFS还是有一点区别的：    1.Ceph是一个软件定义的存储SDS(software-defined storage),而且是一个开源的高    度可伸缩的平台；    2.Ceph是一个&quot;对象（object）&quot;式存储系统，它把每一个待管理的数据流（例如一个文件） 切分为一到多个&quot;固定大小&quot;的对象数据shard，并以其为&quot;原子单元&quot;完成数据存取；    默认的&quot;固定大小&quot;是4M，但可以自定义；    3.对象数据的底层存储服务是由多个主机（host）组成的存储集群，该集群也被称之为 RADOS（Reliable Automatic Distributed Object Store）存储集群，即可靠、    自动化、 分布式对象存储系统；    4.librados是RADOS存储集群的API（库接口），它支持C、C++、Java、Python、Ruby和PHP等编程 语言；    5.Ceph从设计上就是为了解决分布式存储所面临的元数据服务器很容易称为瓶颈的缺点；    备注：        要注意的是每一个固定大小的对象(每一个数据流)都自带数据data和元数据        metadata,这样每一个数据流都被叫做一个对象2.Ceph是如何解决元数据服务器瓶颈的问题的？    Ceph在存数据的时候，为了避免有一个元数据中心服务器成为整个系统的瓶颈所在，它也采用了计算方式来解决问题；    Ceph是没有文件元数据中心服务器的，因为它的所有数据访问都是通过CRUSH算法实时计算路由的，而且计算所需的资源量很小而且是无状态的可以按需无限制扩展；    Crush组件：        1.即当存储一个文件时它要对文件做hash计算，然后映射到对应的存储节点上去，查和读的时候也是做计算去查的，这是依靠Crush算法来实现的.        2.CRUSH算法就是ceph内部通过计算方式用来完成对象路由的一个非常重要的算法；</code></pre><h3 id="Ceph-Architecture：ceph架构"><a href="#Ceph-Architecture：ceph架构" class="headerlink" title="Ceph Architecture：ceph架构"></a>Ceph Architecture：ceph架构</h3><p>–ceph的架构<br><img src="/2018/11/03/ceph存储基础/ceph的架构.png" alt="ceph的架构"></p><pre><code>由于从根本上来讲，Ceph存储在底层是一个由多节点组成的RADOS存储集群，而这个存储集群服务是librados的API;    1.而服务是一个API就意味着是无法挂载的，如果想要存一个文件必须自己写一个对接这个api的程序才行；    2.所以为了让用户使用方便，Ceph在其存储接口api之上开发提供了三种抽象接口以便用户能够像传统意义上的存储功能一样使用Ceph.三个接口：    1.CephFS        1.就像NFS,CIFS一样是一个做好的文件系统，可以挂在到客户端        2.CephFS其实是不依赖于librados的，因为它自身就集成在rados cluster之上的        3.CephFS是最早出现的，也是最后(J版本)投入生产使用的；        4.Cephfs因为是文件系统接口可以直接在客户端进行挂载，而且还可以再次抽象成NFS/CIFS接口来使用；        5.CephFS是依靠ceph-mds服务对外提供服务的；    2.RBD        #将ceph提供的存储空间模拟成一个个独立的块设备使用，每一个块设备叫做一个image磁盘,可以对这个磁盘做分区/格式然后挂载使用；        1.RBD是使用最广泛的接口；        2.RBD是块接口的需要映射到内核才能被使用，所以要基于内核模块(librbd),由客户端主机基于librbd与RBD接口进行交互完之后，再由客户端主机对其进行分区格式化进行挂载使用；        3.如果是KVM的virt可以直接使用RBD块存储；        4.RBD是不需要守护进程的，而是使用内核模块librbd对外提供服务；    3.RadosGW        #更加抽象的、能够跨互联网使用的对象(object)存储        区别：            1.这个所谓的对象不是指ceph内部的对象，ceph内部的对象是固定大小的存储块，而且通常只在ceph集群中使用，它是基于rpc接口调用的；            2.而互联网上的OSS对象存储是基于restful接口提供的存储，每一个文件都是一个对象，而且文件大小各不相同；        RadosGW提供的是http/https协议的接口；        RadosGW是依靠ceph-radosgw对外提供服务的注意：    1.RBD/RadosGW都是为了与librados-api交互写的创建，而且CephFS/RBD/RadosGW都是RADOS的客户端，他们底层都以rados作为存储后台，他们只是这个存储后台的一种抽象层而已；    2.任何一个客户端要想接入rados cluster服务，就必须经过pool存储池来实现；    3.而且这三种客户端都有各自的专用存储池，且所需的存储池个数都不一样；</code></pre><h3 id="Ceph存储底层的工作逻辑基础"><a href="#Ceph存储底层的工作逻辑基础" class="headerlink" title="Ceph存储底层的工作逻辑基础"></a>Ceph存储底层的工作逻辑基础</h3><p>–ceph存储的组成和逻辑<br><img src="/2018/11/03/ceph存储基础/ceph存储的组成和逻辑.png" alt="ceph存储的组成和逻辑"></p><pre><code>RADOS的组成：    rados最为最底层，是应该由很多主机host组织成一个rados cluster存储集群Rados Cluster    1.rados-cluster是ceph的核心组件，它以对象化的方式把每一个文件切分成固定大小的对象，然后基于对象进行管理的；    2.每一个对象都必须经过CRUSH算法实时计算后映射到集群中的某个osd上；Host:    1.每个主机上都应该运行一些守护进行来确保每个host能够提供存储空间；    2.Host主机本地的存储空间是以什么形式供给的？    FileStore:        我们都知道ceph是对象存储，每个对象存储自带数据和元数据的，而在早期的ceph上每个host中都是由已经格式化成xfs系统的磁盘组成，如果把对象存进来，那么又回到了将数据和元数据分开存放的形式，它一定会降低存储性能的,这就是FileStore：文件管理引擎；    BlueStore:        在后来的ceph的Host内部是直接使用磁盘来存储对象了，而这个磁盘内部有自己的裸设备管理逻辑，这种形式叫做BlueStore，BlueStore是Ceph的新存储引擎，是社区版的默认配置；因此RADOS才是把多个节点组织为一个集群，并利用对方的存储空间整合成一个更大的存储空间，从而提供分布式的存储服务的一个非常重要的底层存储机制；OSD:    1.每一个主机host上有多个OSD(Object Storage Device),每一个OSD可以认为是一个    磁盘(FileStore意味着它是一个目录，BlueStore意味着它是一个磁盘)；    2.OSD叫做对象存储设备，每一个磁盘叫做一个OSD；MON：集群元数据监视器    在RADOS cluster中除了Host之外，还有一类节点叫做Mon    1.mon是集群元数据节点，而在前面说过ceph为了实现没有性能瓶颈是没有元数据服务器的，这里的所说的元数据节点是指它是用来管理整个集群的元数据；    2.mon有整个集群的运行图：host节点的数量和状态、每个host上的osd数量和健康状态，每个PG的健康状态等等；    3.所以mon需要做高可用，而且mon的高可用是内部直接使用Paxos协议来实现数据冗余，任何一个节点都有完整的副本，为了使各节点上的数据冗余是强一致的，所以使用Paxos分布式协作协议实现；    (类似etcd使用Raft协议实现高可用一样)；    [Monitor and Paxos参考文章](https://www.jianshu.com/p/53dd30054c0f)Mgr:    因为mon对集群元数据采集是实时的查询的，这种实时查询的代价是很高的，因为在Ceph的新版本(从L版开始)中引用了一个新组件mgr；    1.mgr:manager专门维护查询的操作，根据内部的逻辑将查询操作缓存下来然后再响应给客户端；Pool:存储池    类似于k8s中的namspace思想一样，将Rados cluster所提供的存储空间切成多个pool    原因：        这里说一下存储在ceph中的所有对象都是在一个平面当中的，因为ceph中没有文件系统，没有目录，是没有分层管理的概念的，这样一来所有对象都放一起了，代来的麻烦就是管理、分类、迁移就难！    1.基于以上的原因，rados把它的存储空间切成了类似于分区大小的磁盘方便管理；    2.每一个分区叫做一个存储池pool,每个pool的大小是取决于底层rados-cluster所提供的存储空间的；    3.存储池pool必须先创建才能使用,对象只需要向这个pool请求存储就行了；    4.pool存储池的类型：        所谓存储池类型就是如何做数据冗余的:前面说过数据冗余有节点级冗余和分片级冗余；        1.而pool的存储池类型就是分片级冗余，不过这里不叫主分片/副本分片；        2.pool是以PG为单位来管理的，所以它叫做主PG和副本PG；    5.ceph还支持纠正删码池存储池        纠删码池也会选择足量的osd来，不过多个osd不是用来存副本的，而是每一个osd存一部分，另外一份存的是校验码，必要时可以通过校验码计算出来完整数据，这样做的好处就是存储空间的利用率高了；PG：归置组    1.每一个pool的空间如果太大了，当把1亿个对象(4M大小)存进pool之后，以对象为颗粒    度进行副本管理太过于精细，代价高且维护起来太麻烦；所以还可以进一步的切分成多个PG；    2.PG就是将对象映射到OSD之间的一个虚拟中间层，是不能被创建的;    3.放到一个PG内的所有对象是被统一管理的，而且是放到同一个OSD上的；以PG为颗粒度的管理就变得简单多了；    4.pool--&gt;PG        将放在pool中的对象名字做一致性hash计算，hash的结果映射到hash环上，而这个hash环上遍布着PG，再通过顺时针找到最近的PG，然后将对象归置到这个PG上；        这只是CRUSH算法的第一步实现；    5.PG--&gt;OSD        1.这是CRUSH算法的第二步实现：需要把PG根据pool的类型和冗余副本数量找到足量的osd来动态映射；        2.而PG的主、副本是由CURSH算法来区分的；那么外部文件是如何存储到rados cluster中OSD上的？    客户端接入(CephFS/RBD/RadosGW)-&gt;切分固定大小的存储对象-&gt;pool-&gt;PG-&gt;osd    究竟要放到哪个OSD上，这中间是依靠cursh来完成的；总结：    从上面的基础概念可以概括出Ceph存储的基本组件包括：    1.OSDs    2.Monitors        #一般是3~5~7个监视器    3.Managers        #2个以上的管理器    4.MdSs        #如果要用到CephFS文件系统的话，还需要有MDSs文件系统元数据服务器，而且为了实现元数据安全MDS是要做高可用的；        #从严格意义上来说，MDS只能算是构建在RADOS存储集群之上的文件存取接口，它同RBD/RadosGW属于同一级别，而非Ceph必要组件，使用CephFS接口时才是需要的；</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;存储基础&quot;&gt;&lt;a href=&quot;#存储基础&quot; class=&quot;headerlink&quot; title=&quot;存储基础&quot;&gt;&lt;/a&gt;存储基础&lt;/h3&gt;
    
    </summary>
    
      <category term="存储" scheme="https://www.liukui.tech/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="https://www.liukui.tech/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>docker存储卷</title>
    <link href="https://www.liukui.tech/2018/10/18/docker%E5%AD%98%E5%82%A8%E5%8D%B7/"/>
    <id>https://www.liukui.tech/2018/10/18/docker存储卷/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-07T11:44:05.627Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Data-Volume：docker存储卷"><a href="#Docker-Data-Volume：docker存储卷" class="headerlink" title="Docker Data Volume：docker存储卷"></a>Docker Data Volume：docker存储卷</h3><a id="more"></a><pre><code>存储卷是什么：    存储卷是容器上一个或者多个“目录”，并将此“目录”与宿主机上的某目录建立关联关系，    存储卷在容器初始化之时会被创建，由baseimage提供的卷中的数据数据会在此时完成复制为什么需要用到存储卷:    docker启动一个容器是基于镜像的只读层，并在其上添加一个读写层，而镜像是由多个只读层叠加而来。如果运行中    的容器修改了现有一个已存在的文件，那该文件将会从只读层复制到读写层，而该文件的只读版本仍然存在，只是    被读写层中该文件的副本所隐藏而已，而此时关闭该容器，该容器所修改的文件的将会丢失且不能被其它容器共享、复用，因而需要一个存储卷。如何实现容器内的路径与容器外的存储建立关联关系？    实际应用场景：        1.通常在可写层上只保存临时数据，有效数据保存在和宿主机关联的目录下，这样就        剥离了程序和产生的数据间紧密的耦合关系，即程序在容器的名称空间上，数据在        宿主机或存储上，数据就独立于容器的生命周期之外        2.当容器down后，再启动一个新容器，指定数据路径为宿主机或存储上的路径，则        又恢复了数据，这就叫做Docker的存储卷存储卷存在的问题：    存在的问题        •存储于联合文件系统中，不易于宿主机访问；        •容器间数据共享不便        •删除容器其数据会丢失    解决方案：“卷(volume)”        •“卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机            上的某目录“绑定(关联)”        •Volume于容器初始化之时即会创建，由base image提供的卷中的数据会于此期间            完成复制        •Volume的初衷是独立于容器的生命周期实现数据持久化，因此删除容器之时既不会        删除卷，也不会对哪怕未被引用的卷做垃圾回收操作；存储卷的type:    1. Bind mount volume        绑定挂载卷，永久生效        容器内目录和宿主机中的目录都是由用户自己指定的，    2. Docker-managed volume：        称为docker自己指定的卷        容器中的卷是用户自己指定的，而宿主机上的目录是由docker-daemon进程自行        决定与宿主机的哪个目录建立        关联关系的存储卷，只能用于临时挂载。存储卷的相关命令:    docker run         -v 运行时，指定存储卷        --volumes-from list 复制其他容器的卷，达到共享卷的目的        --sorkdir string    docker volume         ls：列出当前已和宿主建立关联关系的存储卷        create：        inspect name:查看一个卷的详细信息        prune        rm: 因为docker container inspect c1看到的容器内的详细信息是JSON格式的    所以就可以通过过滤特殊字段显示查询的信息    docker container inspect CONTAINER_NAME -f {{.JSON_VALUE}}     Docker-managed volume        • ~]# docker run -it -name c1 –v /data busybox        • ~]# docker inspect -f {{.Mounts}} c1        • 查看c1容器的卷、卷标识符及挂载的主机目录            和docker container inspect c1的过滤效果一样    Bind-mount Volume        • ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name c1 busybox        • ~]# docker inspect -f {{.Mounts}} c1如图以过滤IP地址为例，其他信息类似</code></pre><p><img src="/2018/10/18/docker存储卷/JSON格式的过滤.png" alt="JSON格式过滤"></p><pre><code>示例1.Docker-managed volume    临时创建挂载一个mydata卷        docker run --name c1 -it  --rm -v /mydata busybox:latest        并通过docker container inspect c1 探测        mydata被docker指定与宿主机的哪个目录建立了关联关系</code></pre><p><img src="/2018/10/18/docker存储卷/docker管理的卷.png" alt="docker管理的卷"></p><font size="3" color="#FF0000"><br>从上图看mydata是被docker-manager指定与该容器目录下的_data建立了关系<br>注意：<br>创建容器的时候加–rm选项时，停止容器后，宿主机上的卷也会被删除的<br>不加–rm选项，停止容器，并rm容器，宿主机上的卷是不会被删除的<br>缺点是对应的宿主机上的目录难查找<br></font><pre><code>示例2.Bind mount volume    现在宿主机上创建卷的目录 mkdir /data/volume/c1docker run --name c1 -it  --rm -v /data/volumes/c1:/mydata busybox:latest     并通过docker container inspect c1 </code></pre><p><img src="/2018/10/18/docker存储卷/bind卷.png" alt="bind卷"></p><font size="3" color="#FF0000"><br>可以看出宿主机的/data/volumes/c1与容器内的/mydata是建立的bind类型的卷<br>即使容器被删除，数据还在存在的<br>而且如果/data/volume/c1是在NFS网络文件系统上的话，即使宿主机down了，数据也是无损的<br></font><pre><code>示例3：多容器之间的数据共享1.先创建容器c1docker run --name c1 -it  --rm -v /data/volumes/c1:/mydata busybox:latest 2.创建容器c2时，共享容器c1的卷    docker run --name c2 -it  --rm --volumes-from c1 busybox:latest    此时c1和c2上看到的mydata卷看的数据都是一样的，达到共享卷的目的示例4.用docker实现类似于k8s上的pod组件机制    要求：        1.c1上挂载多个NFS存储上的卷和bridge桥        2.c3和c4使用c1的网络名称空间和c1上的卷    实现：    c1:        docker run --name c1 -v /data/volumes/c1:/mydata -v /data/volume2:/mydata2 busybox:latest     c3.    docker run --name c3 -it --rm --network container:c1 --volumes-from c1  busybox:latest    c4.    docker run --name c4 -it --rm --network container:c1 --volumes-from c1  busybox:latest</code></pre><p><img src="/2018/10/18/docker存储卷/实现docker的pod组件模型.png" alt="实现docker的pod组件模型"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Data-Volume：docker存储卷&quot;&gt;&lt;a href=&quot;#Docker-Data-Volume：docker存储卷&quot; class=&quot;headerlink&quot; title=&quot;Docker Data Volume：docker存储卷&quot;&gt;&lt;/a&gt;Docker Data Volume：docker存储卷&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker的资源限制</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%9A%84%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker的资源限制/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-26T13:44:29.460Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker资源限制"><a href="#Docker资源限制" class="headerlink" title="Docker资源限制"></a>Docker资源限制</h3><a id="more"></a><pre><code>docker容器得以实现的三个组件：    Namespace:内核中的名称空间是实现容器技术非常重要的组件    CGroups：实现容器的资源配额        1.如果没有资源配额的限定，比如恶意代码会占用宿主机上的很多资源，会造成其他容器无法运行的情况，        默认是宿主机上的所有资源.        2.cgroup允许将宿主机上的所有技术资源(CPU,内存等)做资源分割,以指定方式进行分配，而CPU和内存又分别支持两种不同的配额方式        3.CPU属于可压缩型资源，如果程序运行的cpu不够，只需要等待cpu资源即可，不会造成容器崩溃。        4.内存属于不可压缩型资源，如果一个进程依赖于3g内存来运行，宿主机只分配给它1g，则会造成OOM，这个进程就会因为内存耗尽而被终止.内存的限制方式：    -m|--memory= 限制容器的最大内存使用量，进程并不是一启动就占用最大内存的，而是            运行一段时间慢慢增长的，所以要分配给进程运行的最大内存.    --memory-swap * 当前容器所允许使用的交换分区大小(生产环境是禁止启用交换内存            的，因为性能会急剧下降.)    --memory-swappiness 使用交换分区的倾向性：因为使用交换分区会极大影响性能，        只有到万不得已才使用交换分区，数值越小,越会较晚使用交换分区，所以一般这个        值建议调小，默认是0-100    --memory-reservation 为系统保留多的内存空间，保证系统的正常运行    --kernel-memory  为内核保留多少内存空间    --oom-kill-disable  一旦某个容器发生OOM是否立刻kill这个容器，建议设置，因为        会造成整个宿主机的崩溃，也可以事先设定好内核和系统的内存空间，然后手动处理            发生OOM的容器，以便分析发生OOM的原因.    注意：        1.在容器内使用free命令可以看到的swap空间并不具有其所展现的空间指示意义.        2.-m|--memory=和 --memory-swap *一般是结合起来生效的CPU的限制方式：    主流的分两种：共享式和CPU绑定式    --cpu-shares 共享方式是基于权重分配的，而且是根据容器的数量和CPU的权重动态            分配调整的.如果只有一个容器在运行，那么这个容器也会尽可能的占用宿主机的CPU资源，这种分配方式依然会有可能造成系统崩溃.    --cpus &lt;value&gt; 定义容器最多跑满宿主机的几个核心数，例如宿主机有8核，限制容器        最多跑满2个核心数，而且这个2核可以跑在8个核心上加起来是2个核心数，也可以是        在2个核心上跑满.真正限制了容器使用的最大核心数.        docker的1.13版以后都使用这个选项来定义.    --cpuset-cpus         定义容器只能跑在宿主机核心的几号核心上，例如只允许跑在1号和3号核心上，那么        这个容器最多也就只能跑满这两个核心,也叫CPU绑定.</code></pre><p>所以在创建启动容器一定要做资源限制，即使不清楚容器中某个程序要占用多大的资源时，也应该设置只允许占用宿主机一半的资源.</p><h3 id="资源限制压测"><a href="#资源限制压测" class="headerlink" title="资源限制压测"></a>资源限制压测</h3><pre><code>在docker hub上的lorel/docker-stress-ng镜像    -c N 启动几个进程对CPU进行压测    -vm N 启动几个进程对内存做压测示例：通过该镜像进行压测    限制只能跑在cpu的0号和3号上，最多只能跑满2个核心数    限制最多占用512m的内存大小docker run --name stress --cpus 2 --cpuset-cpus 0,3 -m 512m --rm lorel/docker-stress-ng -c 2 -vm 2</code></pre><p>-docker stats命令查看结果<br><img src="/2018/10/18/Docker的资源限制/docker-stats.png" alt="docker status"></p><p>-top命令显示宿主机资源(安装1显示全部的CPU核心数信息)<br><img src="/2018/10/18/Docker的资源限制/top命令.png" alt="top命令"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker资源限制&quot;&gt;&lt;a href=&quot;#Docker资源限制&quot; class=&quot;headerlink&quot; title=&quot;Docker资源限制&quot;&gt;&lt;/a&gt;Docker资源限制&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker仓库管理工具Harbor</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7Harbor/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker仓库管理工具Harbor/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-27T03:25:41.692Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker仓库管理工具Harbor"><a href="#Docker仓库管理工具Harbor" class="headerlink" title="Docker仓库管理工具Harbor"></a>Docker仓库管理工具Harbor</h3><a id="more"></a><p><img src="/2018/10/18/Docker仓库管理工具Harbor/harbor架构.png" alt="harbor架构"></p><p><a href="https://goharbor.io/" target="_blank" rel="noopener">HARBOR</a><br><a href="https://github.com/goharbor/harbor" target="_blank" rel="noopener">github上的harbor</a></p><pre><code>harbor官方功能介绍：    1.基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可        以对多个镜像仓库在同一命名空间（project）里有不同的权限。    2.镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡，        高可用，混合云和多云的场景。    3.图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，        管理项目和命名空间.    4.Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。    5.AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。    6.审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。依赖环境和使用介绍：    1.harbor是基于distribution二次开发的企业级私有仓库，云原生registry，多租户机制，允许用户创建自己的名称空间    2.因为harbor内置了mysql,nginx等服务才能构建一个harbor,所以依赖于docker-compose进行容器编排和依赖于至少docker-17.03.0版本    3.harbor为了安全，也需要以https运行，需要在harbor服务器提供证书，而且也需要为        其他客户端提供证书，为harbor验证使用，当然可以关闭https功能    4.因为需要实时下载镜像，提供了离线安装和在线安装，也可以安装到vSphere平台(OVA方式)虚拟设备。</code></pre><h3 id="离线版安装和配置："><a href="#离线版安装和配置：" class="headerlink" title="离线版安装和配置："></a>离线版安装和配置：</h3><p><a href="https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-online-installer-v1.7.1.tgz" target="_blank" rel="noopener">harbor离线安装包下载</a><br><a href="https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md" target="_blank" rel="noopener">离线版安装部署文档</a></p><pre><code>1.先安装docker-compose，docker-ce    yum install docker-compose docker-ce -y2.tar xf harbor-offline-installer-v1.4.0.tgz -C /usr/local/3.cd /usr/local/harbor并修改主配置文件harbor.cfg    [root@mysql_2 harbor]# grep &quot;^[a-Z]&quot; harbor.cfg         hostname = mysql_2      #设置主机名/IP        ui_url_protocol = http      #访问协议，支持http和https        max_job_workers = 10        #最大进程连接数    #####设置使用https协议的证书和路径#####        customize_crt = on          #是否使用自定义证书        ssl_cert = /data/cert/server.crt        ssl_cert_key = /data/cert/server.key        secretkey_path = /data        log_rotate_count = 50       #本地最多保存50次日志滚动        log_rotate_size = 200M      #当日志达到200M时滚动一次        http_proxy =                #是否使用代理        https_proxy =        no_proxy = 127.0.0.1,localhost,core,registry    ####设置用户上下载镜像时，是否启用发邮件功能#########        email_identity =         email_server = smtp.mydomain.com        email_server_port = 25        email_username = sample_admin@mydomain.com        email_password = abc        email_from = admin &lt;sample_admin@mydomain.com&gt;        email_ssl = false        email_insecure = false    ####使用互联网上的邮箱##############        harbor_admin_password = Harbor12345    #harbor默认的管理员密码        auth_mode = db_auth                    #默认使用的数据库类型        db_host = mysql         #设置连接mysql的端口和用户密码        db_password = root123        db_port = 3306        db_user = root         #这里还支持 ldap 以及 本地文件存储方式。    #####修改数据库类型和用户和密码#########4.运行install.sh    因为是离线安装包，会从tar文件中装入所需的镜像文件并启动，启动时会检查    docker-ce和docker-compose的版本开始加载镜像(mysql,redis,nginx等等)    [root@mysql_2 harbor]# ./install.sh     [Step 0]: checking installation environment ...    Note: docker version: 18.09.0    Note: docker-compose version: 1.18.0    [Step 1]: loading Harbor images ...</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/harbor安装过程.png" alt="创建并启动的所有容器"><br><img src="/2018/10/18/Docker仓库管理工具Harbor/和harbor相关的所有容器.png" alt="创建并启动的所有容器2"></p><pre><code>5.启用的容器可能会使用宿主机的名称空间6.通过docker-compose管理harbor    cd /usr/local/harbor/    docker-compose stop    docker-compose start</code></pre><p>登录web管理界面：<a href="http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码" target="_blank" rel="noopener">http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码</a><br><img src="/2018/10/18/Docker仓库管理工具Harbor/登录页面.png" alt="登录页面"></p><pre><code>7.创建用户和测试仓库：    创建lk用户，测试登录    创建test仓库用于测试上传镜像 直接创建test仓库即可</code></pre><h3 id="内网服务器登录harbor"><a href="#内网服务器登录harbor" class="headerlink" title="内网服务器登录harbor"></a>内网服务器登录harbor</h3><p>-登录报错<br>–Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。<br>如果配置文件中启用了https，而且也有证书等信息，就不会有这个报错<br><img src="/2018/10/18/Docker仓库管理工具Harbor/登录报错.png" alt="docker login报错"></p><pre><code>解决方法：    1.在所有的内网需要上传下载镜像的服务器上都创建daemon.json文件        vim /etc/docker/daemon.json        {           &quot;insecure-registries&quot;:[&quot;192.168.100.17&quot;]           ###该选项表示从不安全的仓库下载或上传镜像        }    2.还要注意：        如果[&quot;192.168.100.17&quot;]中使用的主机名，那么需要在本地hosts文件或者局域网DNS        服务器上进行主机名解析    3.也可以修改vim /usr/lib/systemd/system/docker.service文件        vim /usr/lib/systemd/system/docker.service             ExecStart=/usr/bin/dockerd  --insecure-registry 192.168.100.17        重启docker            systemctl daemon-reload            systemctl restart docker    4.docker login 192.168.100.17|主机名 #登录私有harbor仓库      docker logout 192.168.100.17|主机名 #退出私有harbor仓库</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/成功登录.png" alt="成功登录"></p><pre><code>4.制作镜像并测试上传    制作镜像：docker tag httpd:v0.1 192.168.100.17/test/httpd:v1                将之前制作好的镜像改标签再上传上去            docker image build . -t 192.168.100.17/test/httpd:v2.0                也可以通过dockerfile重新制作一个再上传    上传到test仓库中: docker push 192.168.100.17/test/httpd:v1</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/上传.png" alt="上传镜像"><br><img src="/2018/10/18/Docker仓库管理工具Harbor/上传镜像.png" alt="上传镜像"></p><pre><code>5.测试拉取镜像    在页面上点击复按钮，在命令行中就可以拉取镜像了</code></pre><p>-<br><img src="/2018/10/18/Docker仓库管理工具Harbor/拉取镜像.png" alt="拉取镜像"></p><h3 id="如何修改配置："><a href="#如何修改配置：" class="headerlink" title="如何修改配置："></a>如何修改配置：</h3><pre><code>[root@linux-host1 harbor]# /usr/local/harbor[root@linux-host1 harbor]# docker-compose   stop #先停止服务[root@linux-host1 harbor]# vim harbor.cfg  #编辑配置[root@linux-host1 harbor]# docker-compose start #重新启动服务</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker仓库管理工具Harbor&quot;&gt;&lt;a href=&quot;#Docker仓库管理工具Harbor&quot; class=&quot;headerlink&quot; title=&quot;Docker仓库管理工具Harbor&quot;&gt;&lt;/a&gt;Docker仓库管理工具Harbor&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile</title>
    <link href="https://www.liukui.tech/2018/10/18/Dockerfile/"/>
    <id>https://www.liukui.tech/2018/10/18/Dockerfile/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-01-22T08:38:18.043Z</updated>
    
    <content type="html"><![CDATA[<h3 id="DockerFile：构建镜像"><a href="#DockerFile：构建镜像" class="headerlink" title="DockerFile：构建镜像"></a>DockerFile：构建镜像</h3><a id="more"></a><pre><code>前面说过：    1.镜像是分层的，当基于这个镜像创建一个容器时，docker是通过联合挂载机制把镜像层    进行叠加作为容器的只读层，而后又在这个镜像栈上构建了一个可写层作为这个容器的工    作目录.    2.所有的底层数据在第一次发生修改操作时，是通过CoW写时复制机制，把数据复制到读    写层进行修改并保存在读写层，覆盖底层的原始文件；写入新数据时，则直接保存在读写    层，而在读写层看到的数据就是全部的镜像层数据(镜像栈)    3.而Graph Driver则又在构建在本地文件系统之上的二级文件系统(aufs,overlay2)    4.基于Graph Driver这种特有的图形驱动程序，就可以把分成构建的镜像堆积在存储    空间当中，紧邻的镜像是有依赖关系的    5.docker commit可以把当前的读写层及其底层依赖的镜像关系打包成一个镜像层存储    在Graph Driver当中，并且指向底层依赖的镜像层，形成一个新的镜像层，如果基于    同一个镜像commit多个可写层，这些新的镜像层都是指向之前的底层镜像的，这也是    docker镜像不是很大的原因。    6.所以在制作镜像时，完全不必基于某个基础镜像显示启动一个新容器，然后在上面创建    修改可写层并打包成镜像；commit只是一种方式，也可以使用dokcerfile    7.如果再本地将软件源码编译/二进制编译到容器也是可以的</code></pre><h3 id="dockerfile基本要求"><a href="#dockerfile基本要求" class="headerlink" title="dockerfile基本要求"></a>dockerfile基本要求</h3><pre><code>1.dockerfile的工作逻辑：    制作镜像无非就是基于某个基础镜像创建一个可写层修改后再commit成一层新的镜像    这个过程可以由docker自身完成，只需要在dockerfile配置文件中写清楚，基于哪个基础镜像，    按需修改(通过各种指令生成)，而docker build可以读取dockerfile文件，隐    式的执行这些指令集生成一个新的镜像层保存在Graph Driver中2.工作目录    构建docker镜像时，必须有一个工作目录docker,这个目录下只存在dockerfile和在    dockerfile中定义要复制的文件，是起始目录3.dockerfile format：语法    dockerfile就是一个纯文本文件;        注释行        dockerfile instruction args:指令要纯大写        第一条指令必须是FROM：基础镜像名称        docker build是按顺序读取执行dockerfile中的指令集的4.dockerfile中的每一条指令都会生成一个新的镜像层    如果指令比较多，生成的镜像层就比较多，就会造成第一次的CoW从底层读取数据时很慢    但是镜像层比较多又容易被分享和易控，较少又会比较繁琐    所以一般是把做同一个件事的多个操作通过\换行符，用一条指令完成(见下文)5.镜像内唯一要运行的程序一定必须要运行在前台</code></pre><h3 id="dockerfile中的环境变量"><a href="#dockerfile中的环境变量" class="headerlink" title="dockerfile中的环境变量"></a>dockerfile中的环境变量</h3><pre><code>1.docker为了满足同一镜像在不同环境下的使用场景引入了环境变量的方式    某个容器基于镜像启动时，通过传递环境变量参数，来生成容器内的不同的配置文件    docker container run --name CONTAINER_NAME -e VAR -it IMAGE_NAME COMMAND    这样一来，就可以用基于同一基础镜像，传递不同的环境变量作为参数值，创建适应    于不同环境的容器2.entrypoint.sh脚本    但是传统的代码不支持传环境变量作为参数，而在docker中又需要传参，这时就有了衔接    层也就是shell脚本，这个脚本作为容器第一个要运行的程序然后运行完退出，再退出去    之前读取用户传的环境变量，将环境变量的值写到程序的配置文件中；    而且很多镜像通过docker image inspect mysql:8.0 |grep entrypoint过滤是可以    看到有这个脚本的3.环境变量的两类用法：    a.在构建dockerfile中使用    b.以dockerfile构建的镜像为基础镜像，启动容器时使用    而dockerfile中的指令的生命周期是有两个阶段的        build：基于基础镜像构建镜像的阶段        run: 启动容器的阶段        dockerfile中的一些指令或者环境变量在不同阶段使用发挥的价值是不一样的4.环境变量的设定和引用    设置：ENV statement    两种引用方式：    1.${variable:-word}         如果变量variable为空或不存在时，就使用word值        如果设置了variable，就使用该变量值    2.${variable:+word}         如果变量有值，就使用word值，如有没值就是空值</code></pre><h3 id="dockerignore-file"><a href="#dockerignore-file" class="headerlink" title=".dockerignore file"></a>.dockerignore file</h3><pre><code>1.dockerignore是工作目录中专门记录需要忽略的文件列表2.而且docker build会自动忽略.dockerignore自身和记录在其中的所有文件</code></pre><h3 id="Dockerfile基本语法"><a href="#Dockerfile基本语法" class="headerlink" title="Dockerfile基本语法"></a>Dockerfile基本语法</h3><pre><code>FROM：    FROM必须是文件的第一指令    FROM &lt;repository&gt;[:&lt;tag&gt;  镜像的标签    或者&lt;resository&gt;@&lt;digest&gt; 镜像的ID号校验码        推荐使用digest因为校验码是安全的，而且最好不要使用lastedLABLE:    authtor&apos;s infomation;提供该镜像的标签信息    语法： maintainer &quot;liu &lt;liu@163.com&gt;&quot;COPY:    从宿主机复制文件至创建的新镜像    COPY &lt;src&gt;... &lt;dest&gt;    COPY [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]         &lt;src&gt;：要复制的源文件或目录，支持使用通配符        &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则，COPY指定则以WORKDIR为其起始路径；        注意：在路径中有空白字符时，通常使用第二种格式    注意：    1. src：必须为build上下文中的路径，可使用相对路径    2.如果src是目录，其内部的文件或子目录会自动被递归复制，但src自身不会被复制            等于cp -r /src/* /dest/    3. src有多个，或者src使用通配符，则dest必须是一个目录，且必须以/结尾    4. 如果dest事先不存在，它将会被自动创建ADD:    类似于COPY，但是额外支持tar文件和URL路径    ADD &lt;src&gt;... &lt;dest&gt;    ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;]    1. 如src为URL时且dest不以/结尾，ADD会自动将指定的文件下载并创建为dest，        如dest以/结尾，则会下载指定的文件并保存为dest/FILENAME        即一个是下载并改名，一个是下载到这个文件目录下    2. 如src是一个本地的tar文件，则会被自动展开为一个目录，但通过URL获取到的文件        则不会自动展开，即在本地的就展开，互联网的就不展开    3. 如src有多个，或使用通配符，则dest必须是目录且以/结尾，如dest不以/结尾，        则被视为一个普通文件，src的内容将被直接追加写入到dest文件中WORKDIR：    1.用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录    2.WORKDIR指令可出现多次，表示下个指令可以以此目录为父目录，路径可以表示为相对    路径，也可以写成绝对路径    3.WORKDIR的有效范围当前workdir向下，下一个workdir之前的范围    4.另外，WORKDIR也可调用由ENV定义的环境变量的值，如果下次修改环境变量的值，响应生成信息的镜像层    5.而且如果设定了WORKDIR，容器启动时，默认就进入到workdir路径了VOLUME：    用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷    注意：        1.在dockerfile中定义的卷，启动容器时，是被docker管理的卷与宿主机的某个            路径建立关联关系        2.如果需要定义的卷与宿主机特定的目录建立关联关系，还需要在run container时            指定-v选项        3.如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此            前的所有文件复制到新挂载的卷中EXPOSE:都是动态端口暴露    用于为容器打开指定要监听的端口以实现与外部通信    EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...]       &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议    注意：        1.即使在dockerfile中定义了暴露的端口，启动为容器时，端口也不会暴露的            因为是有安全风险的；        但可以用run container时加 -P选项强行暴露端口，但这是个动态端口暴露        用起来极其鸡肋！ENV：    build阶段使用的：        用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令        如ENV、ADD、COPY等）所调用，调用格式为$variable_name或${variable_name}    两种语法：    1.ENV &lt;key&gt; &lt;value&gt;         &lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只        能设置一个变量；    2.ENV &lt;key&gt;=&lt;value&gt; ...        可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果        &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另外，反斜线也可用于续行；    定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能    缺点：如果想修改ENV定义的值，只能修改dockerfile中的值，比价麻烦，此时    就可以使用ARG来代替ENVARG：    arg是在build阶段进行传值，替换dockerfile中的值        ARG &lt;name&gt; [=&lt;default&gt;] 可以设置默认值    当build创建镜像时没有传值，则使用在dockerfile中设置的默认值    既可以弥补ENV的缺点也可以和RUN，CMD的ENV传环境变量区别开    如：在build时更改home的值    docker image build --build-arg home=&quot;/webdata/&quot; /data/dockerfile/ -t myimg:v0.4</code></pre><h4 id="RUN-CMD-ENTRYPOINT的区别"><a href="#RUN-CMD-ENTRYPOINT的区别" class="headerlink" title="RUN,CMD,ENTRYPOINT的区别"></a>RUN,CMD,ENTRYPOINT的区别</h4><p><img src="/2018/10/18/Dockerfile/三者区别.png" alt="三者的区别"></p><p>区别：</p><pre><code>RUN：    用于指定docker build过程中运行的程序，可以是任何命令                (这就意味着RUN的命令必须是使用的基础镜像支持的命令)    1.是指在docker build过程中通过运行RUN定义的shell命令，以达到在镜像中安装软件等操作    2.RUN可以设定多次，而且每一个都会在build的时执行    语法：        RUN &lt;command&gt;            通常运行的是一个shell命令，且以&quot;/bin/sh -c&quot;运行，且/bin/sh是PID为1的进程，command是作为shell的子进程存在        RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;]            此种格式指定的命令不会以&quot;/bin/sh -c&quot;，因此无法支持shell的诸多特性，如要依赖于shell特性，可替换成如下格式：            RUN [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;]CMD：    1.当把镜像运行容器时，需要指定默认运行的程序，这在dockerfile中需要用CMD命令来        指定，ENTRYPOINT也可以    2.默认运行的程序必须运行在前台    3.由于CMD设定的是容器启动默认运行的程序，所以必须只有一个，如果有多个，        则最后一个CMD生效    语法：        CMD &lt;command&gt; 或        CMD [“&lt;executable&gt;”, “&lt;param1&gt;”, “&lt;param2&gt;”] 或        CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]        前两种语法格式的意义同RUN        第三种则用于为ENTRYPOINT指令提供默认参数    systemctl start httpd启动是运行在systemd的前台上，所以启动就会退出ENTRYPOINT：    1.CMD和ENTRYPOINT都表示镜像启动为容器时，容器默认运行的程序，而且CMD和ENTRYPOINT有多个，也都是最后一个生效    2.如果CMD和ENTRYPOINT同时存在，CMD和ENTRYPONIT需要组合起来，则CMD指定的内容    都作为ENTRYPOINT所指定内容的参数    语法：        ENTRYPOINT &lt;command&gt;或者        ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;]    docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到    ENTRYPOINT命令最后做为其参数使用    Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效</code></pre><p>示例：<br>    docker run –name c1 -P -d myimg:v0.1 以后台运行容器</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;DockerFile：构建镜像&quot;&gt;&lt;a href=&quot;#DockerFile：构建镜像&quot; class=&quot;headerlink&quot; title=&quot;DockerFile：构建镜像&quot;&gt;&lt;/a&gt;DockerFile：构建镜像&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker网络</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E7%BD%91%E7%BB%9C/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker网络/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-02-15T08:21:33.861Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Network"><a href="#Docker-Network" class="headerlink" title="Docker Network"></a>Docker Network</h3><a id="more"></a><p><img src="/2018/10/18/Docker网络/docker的四种网络.png" alt="docker的四种网络"></p><pre><code>KVM上虚拟桥接式网络类型：        隔离桥：只能与连接到同一个桥上的主机通信，IP地址还需要在同一网段        仅主机桥：可以和连接的桥地址进行通信        路由桥：            1.打开宿主机核心转发功能            2.虚拟机的网关都指向这个桥的地址            就可以与宿主机通信，不能与外网通信        NAT桥：在路由桥的基础上，在宿主机上做SNAT规则，即可访问外网地址    Docker提供的四种网络：    桥网络：桥接网络            bridge，默认就是docker0桥，docker0是SNAT桥            查看网络定义：docker network inspect bridge            大多数的容器还是使用bridge网络            而且这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器    共享桥：联盟式网络         每一个容器都是靠在内核级虚拟资源分配的独立的6种名称空间来支撑的        这6种名称空间是IPC,Net,Mount,UTS,PID,USER        虽然每个容器都有各自独立的名称空间，但是确可以共享，于是就有了这种方式        共享桥的原理：                共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈            而mount user PID还是隔离的，文件系统也是隔离的        这样做的效果就可以构建出一个模型            httpd---&gt;fpm127.0.0.1:9000---&gt;mysql127.0.0.1:3306            那么对于fpm和mysql来说只监听在本地端口上，保证了安全性    host宿主机网络：共享宿主机网络        既然多个容器可以使用同一个容器的网络名称空间，而且宿主机在内核中也有自己的        网络名称空间，那么容器也理所当然的可以使用宿主机的网络名称空间        容器使用宿主机的网络和DNAT方式有关系        作用：可以做日志收集主机，host一般在特殊环境下使用    none网络：封闭式网络        当容器不需要网络服务时，不创建网卡，只有本地lo网卡除了bridge桥之外，其他三种网络都是docker所独有的</code></pre><h3 id="Docker网络的相关命令"><a href="#Docker网络的相关命令" class="headerlink" title="Docker网络的相关命令"></a>Docker网络的相关命令</h3><pre><code>docker run 命令中涉及网络的相关命令    --network 启动容器时，指定使用的网络        [bridge|host|none|container:name]    --hostname 启动容器时，指定容器的主机名    --add-host list 启动容器时，指定内部的hosts解析文件        如：docker run --add-host c1:192.168.10.1 busybox:latest            cat /etc/hosts可以看到添加的解析    --dns 启动容器时，指定DNS地址        如：docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest            cat /etc/resolve可以看到指定的DNS地址    --ip string 启动容器时，指定容器的iPv4地址    -p|--publish         因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则docker network:    ls：显示docker内部的全部网络    connect: 让容器连接到某个网络上    disconnect: 把容器从某个网络断开    create: 创建自定义网络，和KVM创建网络类似    inspect:查看某个网络是怎么定义的    prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令    rm: 删除docker内部的网络</code></pre><h3 id="Docker-network的端口暴露"><a href="#Docker-network的端口暴露" class="headerlink" title="Docker network的端口暴露"></a>Docker network的端口暴露</h3><pre><code>docker run --network [bridge|host|none] -p|--publish     作为一个容器，是要提供web服务的，而docker默认的桥是bridge，而且是个SNAT桥    容器只能访问外网，而不能被外网所访问，那么就失去了web服务器对外提供服务的初衷    而docker提供了一个-p选项来自动生成DNAT规则，来避免每次都手写DNAT规则带来的麻烦-p选项的用法和使用格式：    •-p &lt;containerPort&gt;        将指定的容器端口映射至主机所有地址的一个动态端口    •-p &lt;hostPort&gt;:&lt;containerPort&gt;        将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt;    •-p &lt;ip&gt;::&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口    •-p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt;        将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt;    “动态端口”指随机端口，具体的映射结果可使用docker port命令查看    不过一般还是要使用第四种方式指定宿主机的端口    指定了映射的端口后，可以使用命令查看映射关系：        docker container port [name]示例：1.docker run --name c1 -it --rm --network bridge -p 80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:327682.docker run --name c1 -it --rm --network bridge -p 80:80  busybox:latest    使用docker port tiny 查看映射的端口        [root@node7-1 ~]#docker container port c1        80/tcp -&gt; 0.0.0.0:803.docker run --name c1 -it --rm --network bridge -p 192.168.34.103::80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:327684.docker run --name c1 -it --rm --network bridge -p 192.168.34.103:80:80  busybox:latest    使用docker port tiny 查看映射的端口    [root@node7-1 ~]#docker container port c1    80/tcp -&gt; 192.168.34.103:80</code></pre><h3 id="Docker的自定义网络"><a href="#Docker的自定义网络" class="headerlink" title="Docker的自定义网络"></a>Docker的自定义网络</h3><pre><code>docker network create     connect:相当于创建一对网卡，一半在桥上，一半在容器中    而且默认创建的网络都是SNAT桥    选项：    -d|--driver string 创建时，要指定桥的类型        默认是bridge，当然还有 host macvlan null overlay四种类型    --gateway strings 默认是定义的子网的第一个IP地址    --subnet strings 子网地址    --ip-range strings 地址分配的IP地址范围修改默认的bridge，docker0桥的子网    自定义docker0桥的网络属性信息：也就是镜像加速的文件    vim /etc/docker/daemon.json文件    {        &quot;bip&quot;: &quot;192.168.1.5/24&quot;,        &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;,        &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,        &quot;mtu&quot;: 1500,        &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,        &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,        &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]    }     核心选项为bip，即bridge 桥接口的IP地址    ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。示例：    1.创建一个mybr2的网络，并指定子网地址        docker network create --subnet 10.0.0.0/8 mybr2    2.创建容器c1指定加入到mybr2网络中        docker run --name c1 -it --rm --network mybr2  busybox:latest    3.给容器c1再加入一个bridge网络中        docker network connect bridge c1        此时c1就有了两个网络地址    4.删除容器c1的网卡        docker network disconnect mybr2 c1</code></pre><h3 id="Docker指定容器启动的网路类型"><a href="#Docker指定容器启动的网路类型" class="headerlink" title="Docker指定容器启动的网路类型"></a>Docker指定容器启动的网路类型</h3><pre><code>1.启动为none类型的网络    docker run --name c1 -it --rm --network none busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/none网络.png" alt="none网络"></p><pre><code>2.启动为bridge类型的网络:docker默认的网络模型    docker run --name c2 -it --rm --network bridge busybox:latest</code></pre><p><img src="/2018/10/18/Docker网络/bridge网络.png" alt="bridge网络"></p><pre><code>3.启动为joined类型的网络    启动的c3共享的是c2的Net,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的</code></pre><p><img src="/2018/10/18/Docker网络/共享桥网络.png" alt="共享桥网络"></p><p>因为共享桥只是共享了Net网络，UTS主机名，IPC，<br>此时IP地址和hostname都是一样，就可以通过127.0.0.1进行通信了<br>而mount(文件系统)，user,PID还是隔离的，所以在1上创建一个文件，2上是看不到的<br>这就是共享桥的工作机制</p><pre><code>4.启动为host宿主机类型的网络    docker run --name c4 -it --rm --network host busybox:latest    可以看出hostname,Net都是和宿主机是一样的    此时在容器内部启动httpd服务，其他主机是可以通过宿主机提供服务的</code></pre><p><img src="/2018/10/18/Docker网络/host网络.png" alt="host网络"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Network&quot;&gt;&lt;a href=&quot;#Docker-Network&quot; class=&quot;headerlink&quot; title=&quot;Docker Network&quot;&gt;&lt;/a&gt;Docker Network&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker镜像</title>
    <link href="https://www.liukui.tech/2018/10/18/Docker%E9%95%9C%E5%83%8F/"/>
    <id>https://www.liukui.tech/2018/10/18/Docker镜像/</id>
    <published>2018-10-18T00:00:00.000Z</published>
    <updated>2019-02-15T05:54:46.540Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Docker-Images"><a href="#Docker-Images" class="headerlink" title="Docker Images"></a>Docker Images</h3><a id="more"></a><font size="3" color="#FF0000"><br>1.docker image是docker贡献给容器极具创造性的使用方式！<br>2.分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！<br>3.容器编排技术：<br>—Docker通过镜像机制极富创造性的解决了应用程序打包的根本性难题，它推动了容器技术的快速普及和生产落地<br>—容器本身仅提供托管运行应用的底层逻辑，而容器编排(Orchestration)才是真正产生价值的位置所在；<br></font><p>-docker-image和读写机制<br><img src="/2018/10/18/Docker镜像/docker读写机制.png" alt="docker-image和读写机制"></p><pre><code>1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器    a.docker镜像就像KVM镜像一样，包含了启动容器/虚拟机所依赖的所有文件，文件系统        包括程序文件，库文件，配置文件,数据目录等等    b.dokcer采用分层构建机制，最底层为bootfs，其上是rootfs        bootfs：在创建的容器中是看不到的，只是用于系统引导的文件系统，包括                bootloader和kernel，因为在创建启动容器时，其实是用到内核的，                只不过只是启动引导容器启动的，当容器启动完成后会被卸载以节约内存资源;                而且把对应的对容器的管理委托给宿主机的内核，所以容器镜像的内核只                是启动时有用，而且看不到，所以bootfs叫引导文件系统        rootfs:位于bootfs之上，表现为docker容器的根文件系统;                1.在传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只                    读&quot;模式，完整性自检完成后将其重新挂载为读写模式；也就是fstab                    的最后两项，只有通过自检次序时，才会把根文件系统重新以&quot;读写&quot;方式挂载.                2.但是在docker中，rootfs由内核挂载为&quot;只读&quot;模式，就算容器启动完成                    ，rootfs也不会以读写方式重新挂载！也就是说docker容器的用户空                    间和根文件系统一直都是只读的！                3.docker是通过&quot;联合挂载&quot;技术额外挂载一个“可写”层；docker image layer2.Docker Images Layer    如上图    a.完整的docker镜像包括bootfs,rootfs    b.而rootfs又包括Base Image+自定义的镜像层+可写层writable        除了writable是可写层，其他都是只读层    c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加        一个可写层，这个可写层writable是属于容器的    d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的</code></pre><h4 id="容器的读写原理："><a href="#容器的读写原理：" class="headerlink" title="容器的读写原理："></a>容器的读写原理：</h4><p>如上图示： </p><ul><li>1.对于docker来说有一个专门存放镜像的路径叫Graph Driver，而这个文件系统必须是特殊<br>  格式的(aufs或者overlay2),在linux系统内默认是/var/lib/docker/image/overlay2；<br>  overlay2目录就是构建在宿主机(xfs或ext4)的/var/lib/docker/image/目录的二级文件系统</li></ul><ul><li>2.前面说镜像数据文件都放在bootfs和rootfs上的，可写层writbale是创建时创建的<br>  那么在可写层上是如何看到底层的数据目录？又是怎么把数据增删改到容器内的？<br>  默认xfs和ext4是不支持COW机制的</li></ul><blockquote><p>如何看到镜像目录的？</p></blockquote><pre><code>a.在创建容器时，是把镜像内的多层镜像通过联合挂载方式作为可写层的底层，也就是这个容器内部的可访问文件系统接    口b.所谓联合挂载，是通过把镜像内的多层一层一层叠加上去的，而这个叠加方式的原理是：    第一层上有数据时，而第二层没相同数据，在第二层是可以看到第一层数据的;如果第二层有第一层相同数据，    则会覆盖第一层上的相同数据，在第二层上看到的是第一层和第二层总的文件，以此类推，在可写层上就可以看到    镜像内的数据目录了，</code></pre><blockquote><p>如何修改和写文件？</p></blockquote><pre><code>a.对于修改文件，因为文件是放在只读层的，只能是通过COW写时复制机制，先把文件从只读层复制到可写层上再进行修改    然后保存在可写层,当然是首次修改，第二次再修改因为在可写层有文件了，在可写层修改即可，而只读层的该文件    版本仍然存在，只不过是被读写层中该文件的副本所隐藏了.b.对于写文件，新创建的文件是保存在可写层的，所以最终用户看到的是只读层和可写层的全    部数据文件，这就是镜像的工作逻辑</code></pre><blockquote><p>通过上面的分析可以得出：</p></blockquote><pre><code>1.这就是为什么基于同一镜像创建的两个容器，用户在不同的容器上看到的相同的数据都是只读层的，不同的数据是可写    层上各自独有的，因为可写层是独占的，只读层是共享的2.这就是为什么镜像背后必须要求特殊文件系统的原因：因为ext4和xfs默认是不支持联合挂载和写时复制机制的3.因为可写层是可以自定义修改的，把可写层保存为镜像，然后再和原始镜像进行叠加成一个自定义的镜像，    就可以作为基础镜像使用了，不过一般不这么做，而是通过dockerfile自定义镜像</code></pre><h3 id="docker-imge相关命令"><a href="#docker-imge相关命令" class="headerlink" title="docker imge相关命令"></a>docker imge相关命令</h3><pre><code>docker image 相关命令    docker imges:镜像的管理命令    ls： 查看本地所有的镜像列表    build:    import:    inspect: 查看下载/创建的镜像详细信息            可以查看下载的某个镜像的具体信息                    如：CMD:镜像启动默认运行的命令                        Volume:                        network:            下文中构建docker file时这些都可以自定义    load:    prune:    pull：从远程仓库拉取镜像到本地    push: 把本地镜像推到远程的Registry    rm:  docker image rm = docker rmi 删除镜像    tag: 给镜像打标签    save:2.将当前容器可写层保存为镜像并上传docker hub上    docker container commit [options] container [repository:[tag]]         选项：            -a:指定作者            -c:镜像内部默认运行的命名            -p|--pause:因为制作镜像时，容器还在运行，可能制作出的镜像和当前容器不                一致，可以在制作时，暂停容器，保持数据一致    比如：        1.在docker hub上注册用户，并创建镜像仓库            创建的仓库：myimg        2.把centos1容器做成镜像仓库下的myimg：v0.1版本            docker container commit -p -a &quot;liu &lt;liu@163.com&gt;&quot; -c &quot;CMD [&apos;/bin/httpd -f&apos;]&quot; centos1 liukkui/myimg:v0.1            然后新容器就可以基于这个镜像启动了        3.上传docker hub            docker login 登录到docker hub                输入账号密码，正常登录后        4.push镜像            docker image push liukkui/myimg:v0.1            正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Docker-Images&quot;&gt;&lt;a href=&quot;#Docker-Images&quot; class=&quot;headerlink&quot; title=&quot;Docker Images&quot;&gt;&lt;/a&gt;Docker Images&lt;/h3&gt;
    
    </summary>
    
      <category term="虚拟化" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
      <category term="docker" scheme="https://www.liukui.tech/categories/%E8%99%9A%E6%8B%9F%E5%8C%96/docker/"/>
    
    
      <category term="容器" scheme="https://www.liukui.tech/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>k8s-volumes</title>
    <link href="https://www.liukui.tech/2018/08/10/k8s-volumes/"/>
    <id>https://www.liukui.tech/2018/08/10/k8s-volumes/</id>
    <published>2018-08-10T00:00:00.000Z</published>
    <updated>2019-02-28T12:34:40.561Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Kubernetes-Volumes"><a href="#Kubernetes-Volumes" class="headerlink" title="Kubernetes Volumes"></a>Kubernetes Volumes</h3><a id="more"></a><p><img src="/2018/08/10/k8s-volumes/k8s支持的存储卷类型.png" alt="k8s支持的存储卷类型"></p><pre><code>k8s上的volumes和docker中的volumes都是为了保存数据，但还是有区别的：    1.docker上因为是在单机上运行容器的，删除容器只要加载本地之前挂载的卷就可以了。    2.在k8s集群上，如果删除一个Pod,则这个pod的卷数据会保存在之前的这个node节点上了，而scheduler的调度是随机的，        有可能不会运行在之前的node上，那么之前保存的数据是无意义，不能利用的.    3.k8s是分布式集群，如果所有节点都挂载网络文件系统，那么数据就可以跨节点使用了.数据冗余实现方式：    1.存储设备做镜像，主备模式    2.分布式存储        不会对存储节点设备做冗余，而是在软件数据管理级别上对每个数据对象做冗余；        根据调度规则和冗余级别在当前集群的多个节点上都存放一份数据        还支持向外扩展如何挂载：    1.pod中是有个基础容器pause的,同一个pod中是共享pause容器的UTS(主机名),Network(网络名称空间),IPC(进程间通信，网络协议栈).    2.因为在节点上的pod是共享节点内核的，驱动也是在内核，所以节点本身需要先识别适配外部的各种存储系统.    3.节点是可以挂载多种外部存储系统的，所以pause挂载存储时，需要指明挂载的是哪种文件系统类型的存储并有相应的存储插件驱动.    4.同一Pod中的其他容器要想使用pause中的volumes,需要先通过volumes定义pause中定义卷，pod再通过volumeMounts复制并挂载pause定义的卷.CSI:    Container Storage interface，通过容器存储接口自定义存储卷    k8s中内置的存储卷类型        kubectl explain pod.spec.volumes定义存储卷    详见：kubectl explain pod.spec.volumes #如何定义挂载卷    要用存储卷需要现在pod.spec字段定义挂载卷类型和目录等信息挂载存储：    详见：        kubectl explain pod.spec.containers.volumeMounts #定义如何挂载卷        是使用挂载卷，需要在pod.spec.containers中挂载上去才能用spec中的详细定义说明：    spec:      volumes:          #先定义pause中的挂载卷      - name                    #必须定义存储卷名称,以便挂载时引用    下面根据存储类型不同定义方式也不同，按需修改        hostPath/nfs            #必须指定存储类型        - path                  #定义宿主机或者网络存储的路径          type                  #指定的目录/文件不存在时，应该怎么创建            DirectoryOrCreate   #不存在则创建            Directory           #目录必须事先存在            File                #文件可以挂载，但是必须事先存在            FileOrCreate        #文件不存在则自动创建            Socket              #必须是套接字文件，必须事先存在            CharDevice          #字符设备文件，必须事先存在            BlockDevice         #块设备文件，必须事先存在      containers:      - name:        image:        volumeMounts:   #复制并挂载pause中定义的卷        - name:                 #引用volumes中定义的1个或多个卷的卷名          mountPath             #挂载在容器的哪个路径(应用程序的文件路径)          readOnly：true|false  #挂载的路径是否只读，默认是读写权限          mountPropagation      #</code></pre><h3 id="本地存储：hostPath和local"><a href="#本地存储：hostPath和local" class="headerlink" title="本地存储：hostPath和local"></a>本地存储：hostPath和local</h3><pre><code>示例1：hostPath类型            #节点级的目录    vim myapp-hostpath-volumes.yaml         apiVersion: v1        kind: Pod        metadata:          name: myapp          namespace: volumes-test        spec:          containers:          - name: myapp            image: ikubernetes/myapp:v1            volumeMounts:            - name: website              mountPath: /usr/share/nginx/html              readOnly: true          volumes:          - name: website            hostPath:              path: /volumes/myapp              type: DirectoryOrCreate示例2：local类型    k8s1.10版本之后的类型，且是节点级的设备或者节点级目录</code></pre><h3 id="临时存储：emptyDir"><a href="#临时存储：emptyDir" class="headerlink" title="临时存储：emptyDir"></a>临时存储：emptyDir</h3><pre><code>临时存储作用：    1.为容器提供缓存存储空间        1.支持在节点的内存中切分一部分空间作为缓存来用    2.为没有持久存储必要的同一Pod中的两个容器共享数据    3.临时存储随着Pod的删除自动删除用法：    kubectl explain pod.spec.volumes.emptyDir        medium      #默认是disk磁盘，还可以是Memory内存        sizeLimit   #当medium是memory时，则必须进行限制简单示例：    volumes:    - name: ceshi#      emptyDir: {}  #如果medium和sizelimit都不定义，则为磁盘的任意空间      emptyDir:        medium: Memeory  #使用内存当空间        sizeLimit: 200Mi #使用内存空间为200M</code></pre><h3 id="网络存储：NFS"><a href="#网络存储：NFS" class="headerlink" title="网络存储：NFS"></a>网络存储：NFS</h3><pre><code>用法：    kubectl explain pods.spec.volumes.nfs        path：                #nfs的共享目录：如/vols/v1        readOnly：true|false  #是否只读，默认读写        server:               #nfs服务IP或者主机名缺点：    1.需要事先知道nfs服务器的地址    2.nfs导出的存储空间目录示例：    先准备nfs的共享目录:在10.10.0.29上测试    vim /etc/exports        /vols/v1 10.10.0.0/8(rw,no_root_squash)[root@master01 manifsets]# vim redis-nfs-volumes.yaml apiVersion: v1kind: Podmetadata:  name: redis  namespace: volumes-testspec:  nodeName: node03  containers:  - name: redis    image: redis:alpine    ports:    - name: redis      containerPort: 6379    volumeMounts:    - name: redisdata      mountPath: /data      readOnly: false  volumes:  - name: redisdata    nfs:      path: /vols/v1     #nfs导出的共享目录      server: 10.10.0.29 #nfs服务器的地址</code></pre><h3 id="持久卷申请存储：PV-amp-PVC"><a href="#持久卷申请存储：PV-amp-PVC" class="headerlink" title="持久卷申请存储：PV&amp;PVC"></a>持久卷申请存储：PV&amp;PVC</h3><pre><code>为了使用存储方便，为volumeMounts和后端存储设备加加了两个中间层在spec.volumes和存储间加了一个persistentVolume中间层把存储系统的所提供的存储能力抽象成k8s上的标准资源：persistentVolume持久存储卷persistentVolume：    1.PV和存储系统之间不是一一对应关系，而是与对应后端存储系统上可被单独访问的逻辑单元；    2.一个PV对应nfs的一个导出目录、ceph的一个image、云存储的一个云盘;    3.把后端存储的一个个逻辑单元映射为k8s上的一个个PV;    4.PV是集群级别的资源，不属于任何名称空间;PV的lifecycle:    provisioning: #PV的动态供给    bingding      #PV被绑定    using         #PV被使用    reclaiming    #PV被回收PV的供给方式：    动态供给：        1.存储系统上需要事先有逻辑存储单元，根据PVC的空间需求，在底层存储上选择适合空间需求的存储单元动态得创建为PV.        2.底层存储的逻辑单元不存在，只有存储空间            1.PVC向SC请求调用存储系统的API存储接口，临时创建需求空间大小的逻辑存储单元.            2.然后在SC内部把此存储单元创建为PV，与PVC进行binding.        3.动态供给是创建SC，而不是PV    静态供给：        存储系统上事先有存储，手动创建PV，再手动创建PVC与之绑定.PV的回收策略：reclaim    Pod删除时，PVC也可以删除，则引用的PV就处于回收状态，PV删除有二种策略        Delete:   #PVC删除时连带PV一起删除        Retain    #PV和PV上的数据都保留    备注：        1.如果是retain的，PV上仍然会有数据，但是不能被其他PVC所绑定了        2.可以手动删除PV，并手动删除存储上逻辑单元下的数据persistentVolumeClaim    1.PV属于集群级别资源，Pod属于名称空间级别资源，如果pod想使用PV就需要把PV注册到名称空间中;    2.Pod是通过PVC请求占用PV，来使用PV的，一旦名称空间A占用PV1，其他名称空间就不能再用PV1了;    3.PVC占用PV称为binding;为被PVC占用的PV称为avaiable(可用的PV);    4.Pod通过volumes.persistentVolumeClaim使用PVC，进而间接使用PVC所占用的PV的.    5.PVC是属于某个名称空间，可以由管理员手动创建的.PVC和存储系统的多路访问模型：    1.单路读写： RW0:ReadWriteOnce      iscsi    2.多路读写: RWX:ReadWriteMany    3.多路只读: ROX:ReadOnlyMany    作用：        PV是与后端存储的逻辑单元做映射的，存储系统是否支持多路读写应该体现在PV的定义上，才能避免PVC关联PV是否能多路读写出现存储故障.PV和PVC的删除保护：    当PVC和PV被Pod使用时，在k8s的1.10版本之后，即使PVC和PV被删除，此时也不会真的被删除，只有Pod被删除时，    PVC和PV才会被允许删除，这就是PVC和PV的删除保护.定义PV：    pv.spec和pod.spec.volumes是一样的，这样在创建pod时就不要再定义volumes了直接在containers.volumeMounts进行复制挂载就行了.    kubectl explain persistentVolume.spec    spec:      accessModes               #定义存储系统的访问模型的字符串列表            RW0/RWZ/ROX      capacity:                 #定义存储容量        storage   #单位是Ki Mi Gi等等      volumeMode:               #存储设备的访问接口(文件系统接口和块设备接口)            Fileystem|block      persistentVolumeReclaimPolicy  #定义PV的回收策略            Delete|Retain      storageClassName:           #定义使用哪种存储类      mountOptions:          #自定义挂载选项,下面这两项是默认的        - hard        - nfsvers=4.1      nfs/ceph:                  #定义PV关联的存储类型        下面选项根据不同存储系统定义不同的属性值        server:                   path:        定义PVC：    kubectl explain pvc.spec        accessModes          #访问权限必须要要绑定的PV权限的子集        volumeMode           #存储设备的访问接口(文件系统接口和块设备接口)        resources            #资源请求            requests:               #资源需求                storage:   #具体的需求存储空间大小            limit                  #资源上限        storageClassName     #存储类(PVC和PV必须在同一存储类中)        selector             #通过标签选择器去选PV                不定义选择器，则从所有PV中选择合适的PV        volumeName           #        dataSource           #</code></pre><h3 id="存储类SC：StorageClass"><a href="#存储类SC：StorageClass" class="headerlink" title="存储类SC：StorageClass"></a>存储类SC：StorageClass</h3><p><img src="/2018/08/10/k8s-volumes/SC.png" alt="SC"></p><pre><code>SC:Storageclass是k8s上的标准资源    SC是实现PVC动态创建存储单元PV的基础        1.SC上定义了如何连接外部存储API管理接口的方式        2.PVC只能向同一个SC中的PV请求绑定，不能跨SC.定义SC：    详见：kubectl explain sc        apiVersion        kind        metadata        parameters     #对接外部存储时的参数        reclaimPolicy  #在此SC中的PV回收策略        provisioner    #指明后端存储设备-----必须项        volumeBindingMode #后端存储支持的访问模型(RWX,ROX,RWO)        allowVolumeExpansion   #后端存储系统是否支持空间拉伸官方示例：    glusterfs类型的SC          apiVersion: storage.k8s.io/v1        kind: StorageClass        metadata:          name: slow        provisioner: kubernetes.io/glusterfs        parameters:          resturl: &quot;http://127.0.0.1:8081&quot;          clusterid: &quot;630372ccdc720a92c681fb928f27b53f&quot;          restauthenabled: &quot;true&quot;          restuser: &quot;admin&quot;          secretNamespace: &quot;default&quot;          secretName: &quot;heketi-secret&quot;          gidMin: &quot;40000&quot;          gidMax: &quot;50000&quot;          volumetype: &quot;replicate:3&quot;    ceph-rbd类型的SC:        kind: StorageClass        apiVersion: storage.k8s.io/v1        metadata:          name: fast        provisioner: kubernetes.io/rbd        parameters:          monitors: 10.16.153.105:6789          adminId: kube          adminSecretName: ceph-secret          adminSecretNamespace: kube-system          pool: kube          userId: kube          userSecretName: ceph-secret-user          userSecretNamespace: default          fsType: ext4          imageFormat: &quot;2&quot;          imageFeatures: &quot;layering&quot;</code></pre><h3 id="示例-创建静态供给PV和PVC"><a href="#示例-创建静态供给PV和PVC" class="headerlink" title="示例-创建静态供给PV和PVC"></a>示例-创建静态供给PV和PVC</h3><pre><code>以nfs为例定义一个PV：    [root@master01 manifsets]# vim pv-test.yaml    apiVersion: v1    kind: PersistentVolume    metadata:      name: pv-nfs-v1      labels:        storagefs: nfs    spec:    #  accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;]      accessModes:      - ReadWriteMany      - ReadWriteOnce      - ReadOnlyMany      capacity:        storage: 1Gi                #定义PV能提供多大存储空间      volumeMode: Filesystem      persistentVolumeReclaimPolicy: Retain     #定义PV回收策略      nfs:        path: /vols/v2        server: 10.10.0.29创建PVC：    apiVersion: v1    kind: PersistentVolumeClaim    metadata:      name: redis-pvc            #定义PVC的名称，以便Pod中引用      namespace: volumes-test    spec:      selector:   #定义关联到哪个PV，不指定则根据需求空间找相近空间大小的PV        matchLabels:          storagefs: nfs2      accessModes:      - ReadWriteMany      volumeMode: Filesystem      resources:        requests:          storage: 500Mi          #根据PV的存储空间定义PVC有多少空间创建Pod挂载PVC    apiVersion: v1    kind: Pod    metadata:      name: redis      namespace: volumes-test    spec:      nodeName: node03      containers:      - name: redis        image: redis:alpine        ports:        - name: redis          containerPort: 6379        volumeMounts:              #容器复制挂载volumes        - name: redisdata          mountPath: /data          readOnly: false      volumes:      - name: redisdata        persistentVolumeClaim:          claimName: redis-pvc           #挂载PVC测试：    [root@master01 ~]# kubectl get pv    NAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                      STORAGECLASS   REASON   AGE    pv-nfs-v1   1Gi        RWO,ROX,RWX    Retain           Available                                                      8m14s    pv-nfs-v2   2Gi        RWO,ROX,RWX    Retain           Released    volumes-test/redis-pvc-1                           8m14s    pv-nfs-v3   3Gi        RWO,ROX,RWX    Retain           Bound       volumes-test/redis-pvc                             8m14s    [root@master01 ~]# kubectl get pvc -n volumes-test    NAME        STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE    redis-pvc   Bound    pv-nfs-v3   3Gi        RWO,ROX,RWX                   5m55s</code></pre><h3 id="特殊存储：ConfigMap和Secret"><a href="#特殊存储：ConfigMap和Secret" class="headerlink" title="特殊存储：ConfigMap和Secret"></a>特殊存储：ConfigMap和Secret</h3><p>都是为pod中的容器提供配置变更，扮演了k8s系统上一组控制器控制的pod的配置中心</p><pre><code>docker中的应用程序根据不同的环境配置不同的配置文件是依靠两种方式：    1.应用程序镜像是云原生或者支持通过enterpoint脚本可以传递环境变量来适应不同的场景使用.        缺点是：要修改传的值需要删除容器重新创建    2.先配置好不同的配置文件，通过挂载卷将文件传递到容器中.        缺点是：在本地映射的路径下修改了配置文件，容器是不会自动加载新的配置文件的.        k8s上面临相同的问题，为了解决修改配置文件或参数值能够使Pod自动重载配置信息，就将配置文件做成了k8s上的configMap资源.ConfigMap和Secret    1.Pod中的容器提供配置信息    2.配置中心：配置发生变更，测试完成后，通知方式(灰度)    区别：        configMap用来保存非敏感数据，Secret用来保存敏感数据的configMap和Secret是如何将配置传递至Pod中的？    先定义configMap和secret类型的资源，而这种资源时K/V键值对存在的        1.如果是环境变量，则定义这两种资源时，指定key和value        2.如果是配置文件，则文件名为Key,文件内容为值value创建pod时，只需要引用此资源的Key即可：    1.把configmap和secret资源的key映射给pod容器中的环境变量或者文件名    2.给环境变量传key的名称，通过k/v替换，获得v的值，如果想变更配置，只需要修改pod外部configmap中的value的值即可    ，pod会在一段时间内自动传递新的value值，进行配置更新.</code></pre><h3 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h3><pre><code>注意：    1.命令行创建configmap比资源清单更简单，但是配置清单更易维护.    2.通过资源清单配置的configMap中嵌套的是K/V数值还比较简单如果嵌套的是文件内容    的话，配置格式还是有些麻烦的.创建ConfigMap的两种方式    1.基于命令行的    kubectl create configmap -h        --from-literal  #手动指定K/V值，定义多个K/V值需要有多个--from-literal        --from-file     #从文件中读取创建    2.配置清单(比命令行麻烦，但是更易维护)        kubectl explain configmap            data:       #只有data字段，而没有spec字段两种引用configMap的方式: pod和configMap必须在同一名称空间    1.基于环境变量方式引用configMap (用于传递环境变量)    [root@master01 ~]#pod.spec.containers.env        env       #直接手动给变量        - name         #镜像中所能接收的变量名          value        #手动给值(一般用valuefrom)          valuefrom    #从其他位置引用值            configMapKeyRef     #引用一个configMap的键key                name                 #configMap的名称                key                  #configMap中的一个键名                optional        #被引用的configMap资源存在就可以，不存在则报错                    true|false  #默认是必须存在            secretKeyRef        #引用一个Secret的键key,用于敏感数据传输        envfrom   #从其他地方加载环境变量    缺点：        1.如果修改configmap中的环境变量的值，pod是不会更新环境变量的，除非删除重建pod，新的环境变量才会生效.    2.基于存储卷方式引用configMap (用于传递文件)        是把configmap资源当成存储卷来用的        kubectl explain pods.spec.volumes.configMap        volumes:        - name           #定义存储卷名称以便挂载时使用          configMap:            name         #configMap资源的名称            items        #要引用configmap中的那些键映射为本地的文件            - key          #configmap中的键名              mode         #映射的文件权限时多少，没定义则使用外部的defaultMode              path      #映射到pod中叫什么文件名(可以和key一样，也可以随意更改)                    必须是相对路径，而且是相对于挂载点而言            defaultMode  #映射到本地的文件权限为多少                        默认是0644读写权限，可以自己指定            optional     #引用的configMap资源或者引用的键不存在是否报错注意：    1.相对于环境变量方式引用configmap，存储卷方式的pod会根据configmap内容的变化而更新自己pod中的配置信息.    2.如果一个deploy控制的多个pod，并定义挂载了configMap类型的存储，如果修改configMap文件中的内容，这些pod一般会在一分钟之内都更新到最新configmap中新的值.    3.在deploy控制的后端pod众多的情况下，需要借助互联网上的配置中心组件实现pod的滚动更新或者金丝雀更新.    4.后端pod较少的情况下，可以用ansible或者puppet进行灰度更新.</code></pre><h4 id="创建并引用ConfigMap示例"><a href="#创建并引用ConfigMap示例" class="headerlink" title="创建并引用ConfigMap示例"></a>创建并引用ConfigMap示例</h4><pre><code>1.基于命令行的--from-literal创建    kubectl create configmap filebeat-cfg -n config-ns --from-literal=redis_host=&quot;filebeat.defalut.svc.cluster.local&quot; --from-literal=log_level=&quot;Info&quot;    创建名为filebeat-cfg的cm,并设定两个key和他的值2.基于命令行的--from-file创建    kubectl create cm nginx-cfg --from-file=nginx-./server1.conf --from-file=server-zhihui.conf=./nginx-server2.conf -n config-ns引用示例：    1.基于环境变量引用configMap        此处手动创建一个Pod，用来演示使用env属性值引用configMap：filebeat-cfg        apiVersion: v1        kind: Pod        metadata:          name: filebeat          namespace: config-ns    #pod和configMap必须在同一名称空间        spec:          containers:          - name: filebeat            image: ikubernetes/filebeat:5.6.5-alpine            env:            - name: REDIS_HOST              valueFrom:                configMapKeyRef:                  name: filebeat-cfg                  key: redis_host            - name: LOG_LEVEL              valueFrom:                configMapKeyRef:                  name: filebeat-cfg                  key: log_level    2.基于存储卷方式引用configMap        此处手动创建一个Pod，用来演示挂载configMap类型的存储        apiVersion: v1        kind: Pod        metadata:          name: nginx          namespace: config-ns    #pod和configMap必须在同一名称空间        spec:          containers:          - name: nginx            image: ikubernetes/myapp:v1            volumeMounts:            - name: config              mountPath: /etc/nginx/conf.d     #挂载的目录          volumes:          - name: config            configMap:              name: nginx-cfg                          items:              - key: nginx-server1.conf          #本地文件名                path: server1.conf      #映射到pod中的文件名              - key: server-zhihui.conf          #本地文件名                path: server2.conf      #映射到pod中的文件名测试：    通过手动修改configmap的值，查看pod中的文件是否也会发生改变    kubectl edit cm/nginx-cfg -n config-ns    测试看出基于存储卷方式引用configMap的pod的文件内容也会自动更新.</code></pre><h3 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h3><pre><code>1.Secret和configMap在功能上是一样的，只不过Secret是保存敏感数据的.2.Secret的数据是通过base64编码处理过的，不是真正意义上的加密，可以通过base64进行解码.3.Secret资源一般是通过命令行创建，而不是配置清单，因为如果通过配置清单配置时，需要手动将敏感数据(密码)进行base64编码，是很麻烦的，而命令行创建，会自动把敏感数据进行base64编码后保存到secret中.Secret的三种类型：    详见：kubectl create secret -h    1.docker-registry         私有镜像仓库需要登录才能够访问，docker-registry就是将账号密码进行加密认证，以便kubelet可以认证到镜像仓库服务器上.        认证方式有两种：            1.kubectl explain pod.spec.imagePullSecrets                name:可以定义多个列表用于认证                缺点：如果想使用不同的账户时，是不易修改Secret的            2.kubectl explain pod.spec.serviceAccountName                服务账号：可以使用pod之外的系统认证方式                即使修改账号只需要修改serviceAccountName就可以了.    2.generic        非证书的私有敏感信息都用generic类型,通用型    3.tls          #tls是专用于把ssl的tls中的x509格式的证书和私钥打包到一个secret中        而且不管原来的*.key和*.crt都被转成名为tls.key和tls.crt创建secret-generic资源:    1.命令行创建，类似于configmap        kubectl create secret [secret类型] secret名称 --from-literal=        --from-file=[key=]source    2.资源清单创建，要注意将密码进行base64编码后填到data资源中的key:value中        kubectl explain secret创建secret-tls资源:    1.命令行创建：        kubectl create secret tls NAME --cert=path/to/cert/file --key=path/to/key/file -n namespace        #需要先创建证书和私钥，再在创建secret-tls时引用即可.创建docker-registry资源:    1.命令行创建：        kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL          # 创建docker-registry类型的资源时，要指定连接的私有docker仓库的IP/域名，用户名，密码，注册时使用的账号引用secret的方式    1.通过env环境变量引用        kubectl explain pod.spec.containers.env            env:            - name                  #Pod镜像中的存在的变量名              valueFrom:                secretKeyRef:       #表示从secret类型资源引用键                  name:           #引用的Secret资源的名称                  key             #secret资源中的键名                  optional:   #secret资源或者引用的key不存在时报错                    true|false    2.通过存储卷引用Secret资源        kubectl explain pod.spec.volumes.secret        volumes:        - name:              #定义存储卷名称以便挂载时使用          secret:            secretName        #引用的secret资源名称              items:           #引用的多个键对象              - key            #引用的secret资源中的键名                mode:    #文件权限，私密数据建议600权限，不指定则使用外部默认的                path:    #映射到pod中叫什么文件名(可以和key一样，也可以随意更改)          defaultMode      #引用资源的默认权限，0644          optional注意：    1.tls类型的证书和私钥一般要用存储卷方式进行引用，不然value的值太长的.示例：    1.generic类型的secret引用示例        apiVersion: v1        kind: Pod        metadata:          name: mysql          namespace: config-ns        spec:          containers:          - name: mysql            image: mysql:5.6            env:            - name: MYSQL_ROOT_PASSWORD              valueFrom:                secretKeyRef:                  name: mysql-root-password                  key: passwd                  optional: true    2.tls类型secret引用示例        apiVersion: v1            kind: Pod            metadata:              name: nginx              namespace: config-ns            spec:              containers:              - name: nginx                image: nginx:1.14-alpine                volumeMounts:            - name: tls              mountPath: /etc/nginx/ssl          volumes:          - name: tls            secret:            - secretName: nginx-tls              items:              - key: nginx.crt              #原来的证书名                path: nginx-server.crt #映射到pod中的证书名              - key: nginx.key              #原来的私钥名                path: nginx-server.key  #映射到pod中的私钥名                    mode: 0600</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Kubernetes-Volumes&quot;&gt;&lt;a href=&quot;#Kubernetes-Volumes&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes Volumes&quot;&gt;&lt;/a&gt;Kubernetes Volumes&lt;/h3&gt;
    
    </summary>
    
      <category term="kubernetes" scheme="https://www.liukui.tech/categories/kubernetes/"/>
    
    
      <category term="k8s" scheme="https://www.liukui.tech/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>分布式存储系统数据分布方法</title>
    <link href="https://www.liukui.tech/2018/05/10/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E6%96%B9%E6%B3%95/"/>
    <id>https://www.liukui.tech/2018/05/10/分布式存储系统数据分布方法/</id>
    <published>2018-05-10T00:00:00.000Z</published>
    <updated>2019-04-03T14:57:29.012Z</updated>
    
    <content type="html"><![CDATA[<h3 id="分布式存储系统数据分布方法"><a href="#分布式存储系统数据分布方法" class="headerlink" title="分布式存储系统数据分布方法"></a>分布式存储系统数据分布方法</h3><a id="more"></a><pre><code>分布式存储系统中面临着的首要问题就是如何将大量的数据分布在不同的存储节点上，无论上层接口是KV存储、对象存储、块存储、亦或是列存储，在这个问题上大体是一致的；而分布式存储系统中做数据分布目标及可选的方案一般分为下面几种：假设目标数据是以key标识的数据块或对象，在一个包含多个存储节点的集群中，数据分布算法需要为每一个给定的key指定一个或多个对应的存储节点负责，数据分布算法有两个基本目标：1.均匀性(Uniformity) ：不同存储节点的负载应该均衡；2.稳定性(Consistency)：每次一个key通过数据分布算法得到的分布结果应该保持基本稳定，即使再有存储节点发生变化的情况下。    可以看出，这两个目标在一定程度上是相互矛盾的，当有存储节点增加或删除时，为了保持稳定应该尽量少的进行数据的移    动和重新分配，而这样又势必会带来负载不均。同样追求极致均匀也会导致较多的数据迁移。所以我们希望在这两个极端之间    找到一个点以获得合适的均匀性和稳定性。除了上述两个基本目标外，工程中还需要从以下几个方面考虑数据分布算法的优劣：3.性能可扩展性，这个主要考虑的是算法相对于存储节点规模的时间复杂度，为了整个系统的可扩展性，数据分布算法不应该在集群规模扩大后显著的增加运行时间。4.考虑节点异构，实际工程中，不同存储节点之间可能会有很大的性能或容量差异，好的数据分布算法应该能很好的应对这种异构，提供加权的数据均匀。5.隔离故障域，为了数据的高可用，数据分布算法应该为每个key找到一组存储节点，这些节点可能提供的是数据的镜像副本，也可能是类似擦除码的副本方式。数据分布算法应该尽量隔离这些副本的故障域，如不同机房、不同机架、不同交换机、不同机器。</code></pre><h3 id="算法实现："><a href="#算法实现：" class="headerlink" title="算法实现："></a>算法实现：</h3><pre><code>分析完分布算法的评价指标后，接下来介绍一些可能的方案演进，并分析他们的优劣。这里假设key的值足够分散；</code></pre><h4 id="1-Hash"><a href="#1-Hash" class="headerlink" title="1.Hash"></a>1.Hash</h4><pre><code>1.一个简单直观的想法是直接用Hash来计算，简单的以Key做哈希后对节点数取模。可以看出，在key足够分散的情况下，均匀性可以获得，但一旦有节点加入或退出，所有的原有节点都会受到影响，稳定性无从谈起；2.这和负载均衡的调度算法以及后端缓存服务器的调度情况很类似，单纯的hash取模法是无法保证稳定性的；3.hash原理：对对象(文件/IP地址)的名称做hash计算，对后端的节点数量进行取模，模是几就落到第几个节点上进行数据存储；</code></pre><h4 id="2-一致性Hash"><a href="#2-一致性Hash" class="headerlink" title="2.一致性Hash"></a>2.一致性Hash</h4><p>–Consistent hash<br><img src="/2018/05/10/分布式存储系统数据分布方法/Consistent hash.png" alt="Consistent hash"></p><pre><code>一致性Hash可以很好的解决稳定问题，可以将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到先遇到的一组存储节点存放。而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将数据从该节点接收或者给予。但这有带来均匀性的问题，即使可以将存储节点等距排列，也会在存储节点个数变化时带来数据的不均匀。而这种可能成倍数的不均匀在实际工程中是不可接受的;</code></pre><h4 id="3-带负载上限的一致性Hash"><a href="#3-带负载上限的一致性Hash" class="headerlink" title="3.带负载上限的一致性Hash"></a>3.带负载上限的一致性Hash</h4><p>–带负载上限的一致性Hash<br><img src="/2018/05/10/分布式存储系统数据分布方法/带负载上限的一致性Hash.png" alt="带负载上限的一致性Hash"></p><pre><code>1.一致性Hash有节点变化时不均匀的问题，Google在2017年提出了Consistent Hashing with Bounded Loads来控制这种不均匀的程度。简单的说，该算法给Hash环上的每个节点一个负载上限为1 + e倍的平均负载，这个e可以自定义，当key在Hash环上顺时针找到合适的节点后，会判断这个节点的负载是否已经到达上限，如果已达上限，则需要继续找之后的节点进行分配;2.如上图所示，假设每个桶当前上限是2，红色的小球按序号访问，当编号为6的红色小球到达时，发现顺时针首先遇到的B（3，4），C（1，5）都已经达到上限，因此最终放置在桶A。这个算法最吸引人的地方在于当有节点变化时，需要迁移的数据量是1/e^2相关，而与节点数或数据数均无关，也就是说当集群规模扩大时，数据迁移量并不会随着显著增加。另外，使用者可以通过调整e的值来控制均匀性和稳定性之间的权衡。无论是一致性Hash还是带负载限制的一致性Hash都无法解决节点异构的问题</code></pre><h4 id="4-带虚拟节点的一致性Hash"><a href="#4-带虚拟节点的一致性Hash" class="headerlink" title="4.带虚拟节点的一致性Hash"></a>4.带虚拟节点的一致性Hash</h4><p>–带虚拟节点的一致性Hash<br><img src="/2018/05/10/分布式存储系统数据分布方法/带虚拟节点的一致性Hash.png" alt="带虚拟节点的一致性Hash"></p><pre><code>1.为了解决负载不均匀和异构的问题，可以在一致性Hash的基础上引入虚拟节点，即hash环上的每个节点并不是实际的存储节点，而是一个虚拟节点。实际的存储节点根据其不同的权重，对应一个或多个虚拟节点，所有落到相应虚拟节点上的key都由该存储节点负责。如下图所示，存储节点A负责(1,3]，(4,8]，(10, 14]，存储节点B负责(14,1]，(8,10];2.这个算法的问题在于，一个实际存储节点的加入或退出，会影响多个虚拟节点的重新分配，进而影响很多节点参与到数据迁移中来；另外，实践中将一个虚拟节点重新分配给新的实际节点时需要将这部分数据遍历出来发送给新节点。我们需要一个跟合适的虚拟节点切分和分配方式，那就是分片</code></pre><h4 id="5-分片"><a href="#5-分片" class="headerlink" title="5.分片"></a>5.分片</h4><p><img src="/2018/05/10/分布式存储系统数据分布方法/分片.png" alt="分片"></p><p><img src="/2018/05/10/分布式存储系统数据分布方法/分片2.png" alt="分片2"></p><pre><code>1.分片将哈希环切割为相同大小的分片，然后将这些分片交给不同的节点负责。注意这里跟上面提到的虚拟节点有着很本质的区别，分片的划分和分片的分配被解耦，一个节点退出时，其所负责的分片并不需要顺时针合并给之后节点，而是可以更灵活的将整个分片作为一个整体交给任意节点，实践中，一个分片多作为最小的数据迁移和备份单位;2.而也正是由于上面提到的解耦，相当于将原先的key到节点的映射拆成两层，需要一个新的机制来进行分片到存储节点的映射，由于分片数相对key空间已经很小并且数量确定，可以更精确地初始设置，并引入中心目录服务来根据节点存活修改分片的映射关系，同时将这个映射信息通知给所有的存储节点和客户端 ;3.上图是我们的分布式KV存储Zeppelin中的分片方式，Key Space通过Hash到分片，分片极其副本又通过一层映射到最终的存储节点Node Server</code></pre><h4 id="6-CRUSH算法"><a href="#6-CRUSH算法" class="headerlink" title="6.CRUSH算法"></a>6.CRUSH算法</h4><p><img src="/2018/05/10/分布式存储系统数据分布方法/CRUSH算法.png" alt="CRUSH算法"></p><p><img src="/2018/05/10/分布式存储系统数据分布方法/CRUSH算法2.png" alt="CRUSH算法2"></p><pre><code>    CRUSH算法本质上也是一种分片的数据分布方式，其试图在以下几个方面进行优化：    1.分片映射信息量：避免中心目录服务和存储节点及客户端之间需要交互大量的分片映射信息，而改由存储节点或客户端自    己根据少量且稳定的集群节点拓扑和确定的规则自己计算分片映射。    2.完善的故障域划分：支持层级的故障域控制，将同一分片的不同副本按照配置划分到不同层级的故障域中。    客户端或存储节点利用key、存储节点的拓扑结构和分配算法，独立进行分片位置的计算，得到一组负责对应分片及副本的存    储位置。如下图所示是一次定位的过程，最终选择了一个row下的cab21，cab23，cab24三个机柜下的三个存储节点;    当节点变化时，由于节点拓扑的变化，会影响少量分片数据进行迁移，如下图新节点加入是引起的数据迁移，通过良好的分    配算法，可以得到很好的负载均衡和稳定性，CRUSH提供了Uniform、List、Tree、Straw四种分配算法常见的存储系统大多采用类似于分片的数据分布和定位方式：    * Dynamo及Cassandra采用分片的方式并通过Gossip在对等节点间同；    * Redis Cluster将key space划分为slots，同样利用Gossip通信；    * Zeppelin将数据分片为Partition，通过Meta集群提供中心目录服务；    * Bigtable将数据切割为Tablet，类似于可变的分片，Tablet Server可以进行分片的切割，最终分片信息记录在Chubby中；    * Ceph采用CRUSH方式，由中心集群Monitor维护并提供集群拓扑的变化</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;分布式存储系统数据分布方法&quot;&gt;&lt;a href=&quot;#分布式存储系统数据分布方法&quot; class=&quot;headerlink&quot; title=&quot;分布式存储系统数据分布方法&quot;&gt;&lt;/a&gt;分布式存储系统数据分布方法&lt;/h3&gt;
    
    </summary>
    
      <category term="存储" scheme="https://www.liukui.tech/categories/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="存储" scheme="https://www.liukui.tech/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现四层和七层负载均衡</title>
    <link href="https://www.liukui.tech/2018/03/26/nginx%E5%AE%9E%E7%8E%B0%E5%9B%9B%E5%B1%82%E5%92%8C%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>https://www.liukui.tech/2018/03/26/nginx实现四层和七层负载均衡/</id>
    <published>2018-03-26T00:00:00.000Z</published>
    <updated>2019-03-28T08:19:28.860Z</updated>
    
    <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <div id="hbe-security"> <div class="input-container"> <input type="password" class="form-control" id="pass" placeholder=" 输入密码,PC:Enter查看,Phone:输入法换行查看. " /> <label for="pass"> 输入密码,PC:Enter查看,Phone:输入法换行查看. </label> <div class="bottom-line"></div> </div> </div> <div id="encrypt-blog" style="display:none"> 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 </div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      &lt;font size=3 color=&quot;#FF0000&quot;&gt;私密文章，需要输入密码.&lt;/font&gt;&lt;/br&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>进程管理与计划任务</title>
    <link href="https://www.liukui.tech/2018/03/22/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E4%B8%8E%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/"/>
    <id>https://www.liukui.tech/2018/03/22/进程管理与计划任务/</id>
    <published>2018-03-22T00:00:00.000Z</published>
    <updated>2019-04-02T12:34:02.774Z</updated>
    
    <content type="html"><![CDATA[<h3 id="进程管理与计划任务"><a href="#进程管理与计划任务" class="headerlink" title="进程管理与计划任务"></a>进程管理与计划任务</h3><a id="more"></a><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><pre><code>运行程序的一个副本</code></pre><h3 id="进程优先级"><a href="#进程优先级" class="headerlink" title="进程优先级"></a>进程优先级</h3><pre><code>系统优先级：数字越小，优先级越高    0-139（Centos4,5)    0-98，99(Centos6)实时优先级：99-0 值越大优先级最高nice优先级    -20-19，对应系统优先级100-139或99</code></pre><h3 id="Big-O：时间复杂度，用时和规模的关系"><a href="#Big-O：时间复杂度，用时和规模的关系" class="headerlink" title="Big O：时间复杂度，用时和规模的关系"></a>Big O：时间复杂度，用时和规模的关系</h3><pre><code>O(1)，O(logn), O(n)线性, O(n^2)抛物线, O(2^n)</code></pre><h3 id="进程内存："><a href="#进程内存：" class="headerlink" title="进程内存："></a>进程内存：</h3><pre><code>Page Frame，页框，存储页面数据，最小页框大小4kLRU：Least Recently Used 近期最少使用算法，释放内存物理地址空间和线性地址空间    如内存中有长期不使用的数据，则被调出内存空间，当内存中有一数据被调用，则把其从内存的空间中移到首位，与当前内存空间的首位数据，调换位置，并将其它数据依次后推MMU：Memory Management Unit 负责转换线性和物理地址TLB：Translation Lookaside Buffer </code></pre><h3 id="IPC，进程间通信"><a href="#IPC，进程间通信" class="headerlink" title="IPC，进程间通信"></a>IPC，进程间通信</h3><pre><code>同一主机：    signal，信号    shm，共享内存    semaphore，信号量不同主机：    socket，IP和端口号    PRC，远程过程调用    MQ，消息队列</code></pre><h3 id="进程的状态"><a href="#进程的状态" class="headerlink" title="进程的状态"></a>进程的状态</h3><pre><code>进程类型：    守护进程，deamon，与终端无关，系统启动时启动    前台进程，跟终端相关，通过终端启动进程状态：    运行态，running    就绪态，ready    睡眠态，sleep        可中断睡眠，interruptable        不可中断睡眠，uninterruptable    停止态，stopped    僵死态，zombie</code></pre><h3 id="进程的分类"><a href="#进程的分类" class="headerlink" title="进程的分类"></a>进程的分类</h3><pre><code>CPU-Bond：CPU密集型IO-Bond：IO密集型</code></pre><h4 id="pstree-进程间的树形结构"><a href="#pstree-进程间的树形结构" class="headerlink" title="pstree 进程间的树形结构"></a>pstree 进程间的树形结构</h4><pre><code>-p，显示详细的树形结构</code></pre><p><img src="/2018/03/22/进程管理与计划任务/1.jpg" alt=""></p><h4 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h4><pre><code>Linux各进程的信息保存在/proc/PIDps [option]    [option]    ps a，与终端相关所有进程</code></pre><p><img src="/2018/03/22/进程管理与计划任务/2.jpg" alt=""></p><pre><code>ps x，与终端无关的进程</code></pre><p><img src="/2018/03/22/进程管理与计划任务/3.jpg" alt=""></p><pre><code>ps u，与用户相关的进程</code></pre><p><img src="/2018/03/22/进程管理与计划任务/4.jpg" alt=""></p><pre><code>ps f，显示进程树形结构</code></pre><p><img src="/2018/03/22/进程管理与计划任务/6.jpg" alt=""></p><pre><code>ps o，显示指定的指定字段pid，%cpu，%mem，...常用于ax选项一起使用    L，显示可指定所有字段</code></pre><p><img src="/2018/03/22/进程管理与计划任务/7.jpg" alt=""></p><pre><code>ps -C，只显示cmdlist中的进程</code></pre><p><img src="/2018/03/22/进程管理与计划任务/9.jpg" alt=""></p><pre><code>ps -e，显示所有进程，常用于f选项一起使用</code></pre><p><img src="/2018/03/22/进程管理与计划任务/8.jpg" alt=""></p><pre><code>ps -u，显示有效用户ps -U，显示真正用户ps -g，显示有效组名称ps -G，显示真正组名称</code></pre><p><img src="/2018/03/22/进程管理与计划任务/5.jpg" alt=""></p><pre><code>user，当前运行该进程所有者PID，当前运行进程调度父进程CPU，当前进程的cpu负载mem，当前进程的mem负载VSZ，虚拟内存集RSS，常驻内存集TTY，当前进程所关联的终端stat，当前进程的运行的状态START，当前进程启动的时间TIME，当前进程所用占用cpu的时间片COMMAND，当前进程运行的命令示例    ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%men | head，当前系统men使用最多的进程    ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head ，当前系统cpu使用最多的进程</code></pre><h4 id="taskset-绑定进程至指定的CPU"><a href="#taskset-绑定进程至指定的CPU" class="headerlink" title="taskset 绑定进程至指定的CPU"></a>taskset 绑定进程至指定的CPU</h4><pre><code>taskset -cp CPUID PID</code></pre><h4 id="renice-调整进程优先级"><a href="#renice-调整进程优先级" class="headerlink" title="renice 调整进程优先级"></a>renice 调整进程优先级</h4><h4 id="pgrep"><a href="#pgrep" class="headerlink" title="pgrep"></a>pgrep</h4><pre><code>-u，显示有效用户-U，显示真正用户-t termimal 显示与终端相关的进程-l，显示进程名</code></pre><h4 id="pidof-显示进程的进程编号"><a href="#pidof-显示进程的进程编号" class="headerlink" title="pidof 显示进程的进程编号"></a>pidof 显示进程的进程编号</h4><p><img src="/2018/03/22/进程管理与计划任务/10.jpg" alt=""></p><h4 id="uptime-显示系统启动的时间"><a href="#uptime-显示系统启动的时间" class="headerlink" title="uptime 显示系统启动的时间"></a>uptime 显示系统启动的时间</h4><p><img src="/2018/03/22/进程管理与计划任务/11.jpg" alt=""></p><h4 id="top-动态监测系统"><a href="#top-动态监测系统" class="headerlink" title="top 动态监测系统"></a>top 动态监测系统</h4><p><img src="/2018/03/22/进程管理与计划任务/12.jpg" alt=""></p><pre><code>    -p，显示指定的pid    -u，显示指定用户的pid    -n，最多显示几次就退出top -p pids -u|User -n max -o field</code></pre><h4 id="free"><a href="#free" class="headerlink" title="free"></a>free</h4><pre><code>free -h，已易读的方式显示</code></pre><p><img src="/2018/03/22/进程管理与计划任务/13.jpg" alt=""></p><h4 id="vmstat-虚拟内存状态"><a href="#vmstat-虚拟内存状态" class="headerlink" title="vmstat 虚拟内存状态"></a>vmstat 虚拟内存状态</h4><p><img src="/2018/03/22/进程管理与计划任务/14.jpg" alt=""></p><pre><code>si，从swap写入数据到内存so，从内存写出数据到swap</code></pre><h4 id="iostat-显示io的负载情况，在sysstat"><a href="#iostat-显示io的负载情况，在sysstat" class="headerlink" title="iostat 显示io的负载情况，在sysstat"></a>iostat 显示io的负载情况，在sysstat</h4><p><img src="/2018/03/22/进程管理与计划任务/18.jpg" alt=""></p><h4 id="pmap-显示进程的内存占用情况"><a href="#pmap-显示进程的内存占用情况" class="headerlink" title="pmap 显示进程的内存占用情况"></a>pmap 显示进程的内存占用情况</h4><p><img src="/2018/03/22/进程管理与计划任务/15.jpg" alt=""></p><h4 id="dstat-显示系统的占用，替代vmstat，iostat"><a href="#dstat-显示系统的占用，替代vmstat，iostat" class="headerlink" title="dstat 显示系统的占用，替代vmstat，iostat"></a>dstat 显示系统的占用，替代vmstat，iostat</h4><h4 id="iotop-显示进程的io占用的情况"><a href="#iotop-显示进程的io占用的情况" class="headerlink" title="iotop 显示进程的io占用的情况"></a>iotop 显示进程的io占用的情况</h4><pre><code>iotop -p pid 指定pid</code></pre><p><img src="/2018/03/22/进程管理与计划任务/16.jpg" alt=""></p><pre><code>iotop -u user 指定的用户</code></pre><p><img src="/2018/03/22/进程管理与计划任务/17.jpg" alt="">   </p><pre><code>iotop -n NUM 指定显示多少次后退出</code></pre><h4 id="lsof-查看进程打开的文件"><a href="#lsof-查看进程打开的文件" class="headerlink" title="lsof 查看进程打开的文件"></a>lsof 查看进程打开的文件</h4><pre><code>lsof -p，查看指定pid打开的文件</code></pre><p><img src="/2018/03/22/进程管理与计划任务/19.jpg" alt=""></p><pre><code>lsof -i，查看指定端口是那个进程</code></pre><p><img src="/2018/03/22/进程管理与计划任务/20.jpg" alt=""></p><pre><code>恢复删除的文件，前提此文件正在打开    lsof | grep /var/log/message    rm -f /var/log/message    lsof | grep /var/log/message    cat /proc/PID/fd/NUM &gt; FILE</code></pre><h4 id="kill"><a href="#kill" class="headerlink" title="kill"></a>kill</h4><pre><code>-l，显示信号列表</code></pre><p><img src="/2018/03/22/进程管理与计划任务/21.jpg" alt=""></p><pre><code>kill -1 PID 重读配置文件kill -2 PID 中止某PID，相当于ctrl+Ckill -3 PID 相当于ctrl+\kill -9 PID 强制杀死正在运行的进程kill -15 PID 终止正在运行的进程kill -0 PID 安全检查PIDkill -18 PID 前端运行kill -19 PID 后端运行</code></pre><h3 id="作业控制"><a href="#作业控制" class="headerlink" title="作业控制"></a>作业控制</h3><pre><code>ctrl+z，将前端运行的程序挂起到后端fg，将程序放在前端运行bg，将程序在后端运行command &amp; ，将还未运行的命令在后端运行nohup command &amp;&gt; /dev/null ，将进程与终端剥离</code></pre><h4 id="并行执行"><a href="#并行执行" class="headerlink" title="并行执行"></a>并行执行</h4><pre><code>{ command1&amp; command2&amp; }{    command1    command2}&amp;{    command1    command2}&amp;示例：    {        ping -c2 127.0.0.1        ping 127.0.0.2    }&amp;    {        ping -c2 127.0.0.3        ping 127.0.0.4    }&amp;</code></pre><h4 id="计划任务"><a href="#计划任务" class="headerlink" title="计划任务"></a>计划任务</h4><pre><code>at，在指定的时间执行一次任务,适合执行一次性任务的at -l，显示计划任务的列表</code></pre><p><img src="/2018/03/22/进程管理与计划任务/22.jpg" alt=""></p><pre><code>at -c，查看具体作业任务</code></pre><p><img src="/2018/03/22/进程管理与计划任务/23.jpg" alt=""></p><pre><code>at now+TIME，从现在起多少TIME后执行计划任务/etc/at.{allow,deny}控制用户是否能执行at任务    白名单：/etc/at.allow，默认不存在，只有该文件的用户才执行at命令    黑名单：/etc/at.deny，默认存在，拒绝该文件的用户才执行at命令周期性任务计划cron相关的程序包：     cronie：主程序包，提供crond守护进程及相关辅助工具         [root@node02 ~]# rpm -ql cronie        /usr/bin/crontab    #创建任务计划的工具           /usr/sbin/crond     #计划任务主程序        /usr/lib/systemd/system/crond.service #此服务必须启动才能确保任务能够周期性执行    cronie-anacron：cronie的补充程序，用于监控cronie任务执行状况        #对服务器用处不大    crontabs：包含CentOS提供系统维护任务        [root@node02 ~]# rpm -ql crontabs        /etc/sysconfig/run-parts            #将某个目录下的计划任务全部执行一次计划周期性执行的任务提交给crond，到指定时间会自动运行     系统cron任务：系统维护作业         /etc/crontab         格式书写：        [root@node02 ~]# vim /etc/crontab        SHELL=/bin/bash        PATH=/sbin:/bin:/usr/sbin:/usr/bin        MAILTO=root        # For details see man 4 crontabs        # Example of job definition:        # .---------------- minute (0 - 59)分        # |  .------------- hour (0 - 23)时        # |  |  .---------- day of month (1 - 31)日        # |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...月        # |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat周        # |  |  |  |  |        # *  *  *  *  * user-name  command to be executed          分 时 日 月 周  用户 执行的命令/脚本          30 2 * 3-6,12 0 root /bin/tar /data/etc.tar /etc/ &amp;&gt; /dev/null            #3-6月和12月的周日2:30备份/data/etc目录          30 2 1,10,20 * 0 root /bin/tar /data/etc.tar /etc/ &amp;&gt; /dev/null            #注意：当month和week同时设定时是或的关系            即每个月的1,10,20号和每周日都执行备份操作          30 2 1,10,20 * * root /bin/tar /data/etc.tar /etc/ &amp;&gt; /dev/null            #注意：每个月的1,10,20号并且是的周日情况下才执行？            思路：只需要在脚本里通过date +%w判断一下是不是周日即可，不是就退出脚本即可；          */10 * * * * root /bin/chekdisk.sh            #每十分钟执行一次磁盘检查           10 21 * * * wang /bin/echo &quot;Howdy!&quot;             #晚上9点10分运行echo命令         #当然在/etc/crontab创建计划任务只能通过root用户，这样对普通用户来说就不方便了，所以更多的还是        使用crontab命令    用户cron任务：         crontab命令     日志：/var/log/croncrontab命令     基本语法，以普通用户执行crontab命令    crontab -e 编辑计划任务列表    */10 * * * * root /bin/chekdisk.sh    默认文件保存路径：/var/spool/cron/编辑计划任务的用户名        #而且不管是哪个用户，只要通过crontab -e创建自己的计划任务就会在此目录下创建同名的文件    改变crontab默认的编辑器为vi，可修改为VIM    如果想修改之前编辑的任务         crontab -e -u test #以test用户修改之前创建的任务计划         01 * * * * root /bin/chekdisk.sh            #每个小时的第一分钟执行一次检查    删除计划任务：        crontab -r -u test  #删除test用户的计划任务</code></pre><p><img src="/2018/03/22/进程管理与计划任务/24.jpg" alt=""></p><pre><code>crontab -l 列出所有任务</code></pre><p><img src="/2018/03/22/进程管理与计划任务/25.jpg" alt=""></p><pre><code>示例：    如何在秒级别运行任务？         * * * * * for min in 0 1 2;do echo &quot;hi&quot;; sleep 20; done 每秒执行任务    如何实现每7分钟运行一次任务?     1、每周的工作日1：30，将/etc备份至/backup目录中，保存的文件名称格式 为&quot;etcbak-yyyy-mm-dd-HH.tar.xz&quot;，其中日期是前一天的时间         [root@node02 ~]# vim /root/bakcup.sh        #!/bin/bash        tar Hcf /backup/etcbak-`date -d &apos;-1 day&apos; +%Y-%m-%d-%H`.tar.xz /etc/ &amp;&gt; /dev/null        [root@node02 ~]# chmod +x /root/bakcup.sh        [root@node02 ~]#crontab -e        30 1 * * 1-5 /root/bakcup.sh    2、每两小时取出当前系统/proc/meminfo文件中以S或M开头的信息追加至 /tmp/meminfo.txt文件中         [root@node02 ~]# vim /root/test.sh         #!/bin/bash        cat /proc/meminfo | grep -o &quot;^[M|S].*&quot; &gt;&gt; /tmp/meminfo.txt        [root@node02 ~]# chmod +x /root/test.sh        [root@node02 ~]# crontab -e        0 */2 * * * /root/test.sh    3、工作日时间，每10分钟执行一次磁盘空间检查，一旦发现任何分区利用率高于80%，就执行wall警报        [root@node02 ~]# vim /root/diskspce.sh        #!/bin/bash        [ `df |sed -nr &apos;/^\/dev\/sd/s/.*([0-9]+)%.*/\1/p&apos;|sort -nr|head -n1` -gt 80 ] &amp;&amp; wall disk will be full        [ `df -i |sed -nr &apos;/^\/dev\/sd/s/.*([0-9]+)%.*/\1/p&apos;|sort -nr|head -n1` -gt 80 ] &amp;&amp; wall disk will be full        [root@node02 ~]# chmod +x /root/diskspce.sh        [root@node02 ~]#crontab -e        */10 * * * * /root/diskspce.sh系统自带的计划任务：    /etc/cron.d     /etc/cron.hourly    /etc/cron.daily        /etc/cron.daily/tmpwatch 定期执行清除临时文件    /etc/cron.weekly     /etc/cron.monthly </code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;进程管理与计划任务&quot;&gt;&lt;a href=&quot;#进程管理与计划任务&quot; class=&quot;headerlink&quot; title=&quot;进程管理与计划任务&quot;&gt;&lt;/a&gt;进程管理与计划任务&lt;/h3&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/nginx/"/>
    
    
      <category term="linux基础" scheme="https://www.liukui.tech/tags/linux%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>基于lnnmp搭建个人博客</title>
    <link href="https://www.liukui.tech/2018/03/22/%E5%9F%BA%E4%BA%8Elnnmp%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>https://www.liukui.tech/2018/03/22/基于lnnmp搭建个人博客/</id>
    <published>2018-03-22T00:00:00.000Z</published>
    <updated>2019-01-28T06:49:21.656Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基于openstack-docker搭建LNNMP"><a href="#基于openstack-docker搭建LNNMP" class="headerlink" title="基于openstack/docker搭建LNNMP"></a>基于openstack/docker搭建LNNMP</h3><a id="more"></a><p>-个人网站基本架构图<br><img src="/2018/03/22/基于lnnmp搭建个人博客/lnnmp架构图.png" alt="LNNMP架构图"></p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><pre><code>1.所有服务器时间要同步2.proxysql要和mysql所有服务器在同一个网段，不然会影响mysql的性能    nginx调度服务器：192.168.100.10    nginx+fpm-1服务器：192.168.100.3    nginx+fpm-2服务器：192.168.100.4    proxysql数据库读写分离：192.168.100.30    mysql_1服务器:192.168.100.9    mysql_2服务器:192.168.100.16    mysql_3服务器:192.168.100.17    NFS主：在mysql_2服务器上192.168.100.16    NFS备：在mysql_3服务器上192.168.100.17软件版本：     wordpress:         wordpress-5.0-zh_CN.zip (默认安装再升级)        wordpress-5.0.2-zh_CN.zip(用于测试升级版本)        依赖于php7.3版本之上和mysql5.6或者mariadb10.0版本之上    mysql:mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz(和一键安装脚本)    nginx:nginx-1.12.2.tar.gz    php-fpm:php-7.2.14.tar.gz    nfs: nfs-utils</code></pre><h3 id="1-搭建一主二从数据库"><a href="#1-搭建一主二从数据库" class="headerlink" title="1.搭建一主二从数据库"></a>1.搭建一主二从数据库</h3><pre><code>二进制安装mysql，此处用事先准备好的脚本进行安装(供参考)；</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql_1 ~]# vim mysql-install.sh   </span><br><span class="line">#!/bin/bash</span><br><span class="line">DIR=`pwd`</span><br><span class="line">NAME=&quot;mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz&quot;</span><br><span class="line">FULL_NAME=$&#123;DIR&#125;/$&#123;NAME&#125;</span><br><span class="line">DATA_DIR=&quot;/data/mysql&quot;</span><br><span class="line"></span><br><span class="line">yum install vim gcc gcc-c++ wget autoconf  net-tools lrzsz iotop lsof iotop bash-completion -y</span><br><span class="line">yum install curl policycoreutils openssh-server openssh-clients postfix -y</span><br><span class="line"></span><br><span class="line">if [ -f $&#123;FULL_NAME&#125; ];then</span><br><span class="line">    echo &quot;安装文件存在&quot;</span><br><span class="line">else</span><br><span class="line">    echo &quot;安装文件不存在&quot;</span><br><span class="line">    exit 3</span><br><span class="line">fi</span><br><span class="line">if [ -h /usr/local/mysql ];then</span><br><span class="line">    echo &quot;Mysql已经安装&quot;</span><br><span class="line">    exit 3</span><br><span class="line">else</span><br><span class="line">    tar xvf $&#123;FULL_NAME&#125;   -C /usr/local/src</span><br><span class="line">    ln -sv /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64  /usr/local/mysql</span><br><span class="line">    if id  mysql;then</span><br><span class="line">        echo &quot;mysql用户已经存在&quot;</span><br><span class="line">    fi</span><br><span class="line">        useradd  mysql  -s /sbin/nologin</span><br><span class="line">    if  id  mysql;then</span><br><span class="line">        chown  -R mysql.mysql  /usr/local/mysql/* -R</span><br><span class="line">        if [ ! -d  /data/mysql ];then</span><br><span class="line">            mkdir -pv /data/mysql &amp;&amp; chown -R mysql.mysql  /data   -R</span><br><span class="line">            /usr/local/mysql/scripts/mysql_install_db  --user=mysql --datadir=/data/mysql  --basedir=/usr/local/mysql/</span><br><span class="line">            cp  /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64/support-files/mysql.server /etc/init.d/mysqld</span><br><span class="line">            chmod a+x /etc/init.d/mysqld</span><br><span class="line">            cp $&#123;DIR&#125;/my.cnf   /etc/my.cnf</span><br><span class="line">            ln -sv /usr/local/mysql/bin/mysql  /usr/bin/mysql</span><br><span class="line">            chkconfig --add mysqld</span><br><span class="line">            service mysqld start</span><br><span class="line">        else</span><br><span class="line">            echo &quot;MySQL数据目录已经存在&quot;</span><br><span class="line">            exit 2</span><br><span class="line">        fi</span><br><span class="line">    fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><pre><code>主节点数据库：    1.启用二进制日志和跳过主机名称解析        server-id=1        log_bin=/data/mysql/master-log        skip_name_resolve = on    2.授权主从复制账号        grant replication slave on *.* to repluser@&apos;192.168.100.%&apos; identified by &apos;root123&apos;;    3.show master logs;        查看二进制日志位置，准备change master to信息    4.创建wordpress数据库        create database wordpress;    5.创建php连接mysql的用户和proxysql读写分离的用户         grant all on *.* to wordpress@&apos;192.168.100.%&apos; identified by &apos;wordpress123&apos;        此账号既作为php连接数据库的账号，又作为proxysql中读写分离的账户从节点数据库：    1.每个从节点都需要如下设置，设置只读，启用中继日志        server-id=2|3        read-only        relay_log=/data/mysql    2.设置change master to:        CHANGE MASTER TO          MASTER_HOST=&apos;192.168.100.9&apos;,          MASTER_USER=&apos;repluser&apos;,          MASTER_PASSWORD=&apos;root123&apos;,          MASTER_PORT=3306,          MASTER_LOG_FILE=&apos;master-log.000001&apos;,          MASTER_LOG_POS=4,          MASTER_CONNECT_RETRY=120;    3.start slave;启动MySQL主从    service mysqld start</code></pre><h3 id="安装配置proxysql读写分离器"><a href="#安装配置proxysql读写分离器" class="headerlink" title="安装配置proxysql读写分离器"></a>安装配置proxysql读写分离器</h3><pre><code>1.基于YUM仓库安装    vim /etc/yum.repos.d/proxysql.repo    [proxysql_repo]    name= ProxySQL YUM repository    baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever    gpgcheck=1    gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key2.安装启动    yum install proxysql &amp;&amp; systemctl start proxysql3.向ProxySQL中添加MySQL所有节点，以下操作不需要use main也可成功    MySQL &gt; select * from mysql_servers;    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.9&apos;,3306);    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.16&apos;,3306);    MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)    values(10,&apos;192.168.100.17&apos;,3306);    MySQL &gt; load mysql servers to runtime;    MySQL &gt; save mysql servers to disk;4.配置监控账号：    a.在主节点上，创建监控账号        grant replication client on *.* to monitor@&apos;192.168.100.%&apos; identified by &apos;root123&apos;;        备注：replication client权限是负责监控的，和replication slave是不同的权限    b.Proxysql上配置监控        实际上是保存在global_variables表中，可以查看是否修改成功        MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;;        MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;;    c.使global_variables表生效        MySQL [mian]&gt; load mysql variables to runtime;        MySQL [mian]&gt; save mysql variables to disk;5.设置分组信息和读写规则    main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20    插入读写组的编号：        insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;);    生效和保存：        MySQL [monitor]&gt; load mysql servers to runtime;        MySQL [monitor]&gt; save mysql servers to disk;    再次查看        select hostgroup_id,hostname,port,status,weight from mysql_servers;6.创建用于测试读写分离的账号    主节点上创建访问用户：        用上面创建的wordpress账户即可    在ProxySQL配置，将用户wordpress添加到mysql_users表中：        insert into mysql_users(username,password,default_hostgroup)values(&apos;wordpress&apos;,&apos;wordpress123&apos;,10);    生效和保存：        MySQL [monitor]&gt; load mysql users to runtime;        MySQL [monitor]&gt; save mysql users to disk;7.配置路由规则，实现读写分离    与规则相关的表：mysql_qeury_rules    插入路由规则,实现读写分离的规则        insert into mysql_query_rules        (rule_id,active,match_digest,destination_hostgroup,apply)        VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1);    生效和保存到磁盘：        load mysql query rules to runtime;        save mysql query rules to disk;8.可以现在本机用wordpress测试是否可以实现读写分离    读：因为是读操作会在2和3上随机选择    mysql -wordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos;    写：事务是非select开头的，所以查询的都是1上    mysql -uwordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos;  </code></pre><h3 id="编译安装php"><a href="#编译安装php" class="headerlink" title="编译安装php"></a>编译安装php</h3><pre><code>1.准备环境依赖包：    yum -y install wget vim pcre pcre-devel openssl openssl-devel libicu-devel gcc gcc-c++     autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2     libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel ncurses ncurses-devel     curl curl-devel krb5-devel libidn libidn-devel openldap openldap-devel nss_ldap     jemalloc-devel cmake boost-devel bison automake libevent libevent-devel gd gd-devel     libtool* libmcrypt libmcrypt-devel mcrypt mhash libxslt libxslt-devel readline     readline-devel gmp gmp-devel libcurl libcurl-devel openjpeg-devel2.编译php:    ./configure  --prefix=/usr/local/php \    --with-config-file-path=/usr/local/php/etc \    --with-config-file-scan-dir=/usr/local/php/etc/conf.d \    --enable-fpm --with-fpm-user=www \    --with-fpm-group=www --with-pear \    --with-curl  --with-png-dir --with-freetype-dir \    --with-iconv   --with-mhash   --with-zlib --with-xmlrpc \    --with-xsl --with-openssl  --with-mysqli --with-pdo-mysql \    --disable-debug --enable-zip --enable-sockets \    --enable-soap   --enable-inline-optimization  --enable-xml \    --enable-ftp --enable-exif --enable-wddx \    --enable-bcmath --enable-calendar   --enable-shmop \    --enable-dba --enable-sysvsem --enable-sysvshm --enable-sysvmsg    make &amp;&amp; make install3.创建用户    useradd www4.准备配置文件    cd /usr/local/php/etc/    cp php-fpm.conf.default php-fpm.conf    cp php-fpm.d/www.conf.default php-fpm.d/www.conf    1.修改php-fpm.d/www.conf配置文件，使用dynamic动态模式，并设置最大，最少        空闲进程等信息    2.修改启动php的用户为www5.准备启动脚本    cp /root/ php-7.2.14/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm        chmod +x /etc/init.d/php-fpm        chkconfig --add php-fpm        chkconfig php-fpm on    也可以使用编译生成的        /usr/local/php/sbin/php-fpm直接启动</code></pre><h3 id="编译安装nginx实现web服务"><a href="#编译安装nginx实现web服务" class="headerlink" title="编译安装nginx实现web服务"></a>编译安装nginx实现web服务</h3><pre><code>因为在上文架构图中nginx既做web服务，又作为前端负载均衡服务器在这两台服务器上编译安装nginx,实现转发wordpress请求    nginx+fpm-1服务器：192.168.100.3    nginx+fpm-2服务器：192.168.100.41.解压并编译    tar xf nginx-1.12.2.tar.gz    cd nginx-1.12.2    ./configure \    --prefix=/usr/local/nginx  \    --with-pcre \    --with-http_stub_status_module \    --with-http_ssl_module    make &amp; make install2.修改配置文件将php资源请求调度到php-fpm    在server的上下文定义：因为nginx和php在同一台服务器，所以直接写127.0.0.1:9000    location / {    root   /data/nginx/wordpress;    index  index.php index.html index.htm;    }    location ~ \.php$ {        root          /data/nginx/wordpress;(可不写)        fastcgi_pass   127.0.0.1:9000;        fastcgi_index  index.php;        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;            include        fastcgi_params;    }    如果location中不写root，$document_root就要写/data/nginx/wordpress$fastcgi_script_name;3.启动服务    /usr/local/nginx/sbin/nginx </code></pre><h3 id="部署wordpress-5-0"><a href="#部署wordpress-5-0" class="headerlink" title="部署wordpress-5.0"></a>部署wordpress-5.0</h3><pre><code>在两台nginxweb服务器上安装同样的wordpress和配置1.创建存放wordpress目录    mkdir -pv /data/nginx/wordpress2.解压并将全部文件拷贝到/data/nginx/wordpress下    tar xf wordpress-5.0-zh_CN.zip    mv wordpress/* /data/nginx/wordpress/3.修改/data/nginx/wordpress的所有者和所属组    chown -R www.www /data/nginx/wordpress4.准备连接数据库的文件    cp wp-config-sample.php wp-config.php    vim wp-config.php        /** WordPress数据库的名称 */        define(&apos;DB_NAME&apos;, &apos;wordpress&apos;);        /** MySQL数据库用户名 */        define(&apos;DB_USER&apos;, &apos;wordpress&apos;);        /** MySQL数据库密码 */        define(&apos;DB_PASSWORD&apos;, &apos;wordpress123&apos;);        /** MySQL主机 */        define(&apos;DB_HOST&apos;, &apos;192.168.100.30:6033&apos;);    此处连接的mysql数据库主机是proxysql读写分离的IP和端口</code></pre><h3 id="通过NFS共享图片目录"><a href="#通过NFS共享图片目录" class="headerlink" title="通过NFS共享图片目录"></a>通过NFS共享图片目录</h3><pre><code>准备NFS主备后端存储：    1.这里nfs主备用mysql的两台从服务来实现        yum install nfs-utils -y        一定要安装nfs-utils，实际环境测试不安装utils，访问nfs的速度很慢        准备共享目录：            mkdir -pv /nfsdata/images        设置权限nfs共享目录权限            vim /etc/exports            /nfsdata/images *(rw,no_root_squash)    2.实现主备NFS的图片同步    rsync -avrlopg /nfsdata/images/* 192.168.100.17:/nfsdata/images/在nginx+pfp-fpm的两台服务器挂载nfs的共享目录    showmount -e 192.168.100.16    显示该主机上可以挂载的nfs目录1.挂载目录并设置开机自动挂载    因为wordpress的图片是保存在/data/nginx/wordpress/wp-content/uploads中的    所以要把该目录用nfs共享    1.vim /etc/fstab        192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads/ nfs defaults,_netdev 0 0        写在fstab文件中一定要加_netdev选项,刚开机没有IP地址时，即使挂载不上也可以启动    2.也可以写在/etc/rc.d/rc.local中，因为该文件是系统启动最后加载的文件，此时        已经获取到IP地址了，当然可以实现自动挂载,要设置执行权限        vim /etc/rc.d/rc.local        mount -t nfs 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads        chmod +x /etc/rc.d/rc.local3.备注：    NFS共享，为了避免IP地址的问题，最好要配置一个DNS服务器来主机名和IP地址    挂载的时候最好使用主机名取挂载，即使IP地址出问题了，也可以临时在DNS服务器上    修改主机名和IP地址的对应关系.</code></pre><h3 id="编译安装nginx实现负载均衡"><a href="#编译安装nginx实现负载均衡" class="headerlink" title="编译安装nginx实现负载均衡"></a>编译安装nginx实现负载均衡</h3><pre><code>nginx调度服务器：192.168.100.101.解压并编译    tar xf nginx-1.12.2.tar.gz    cd nginx-1.12.2    ./configure \    --prefix=/usr/local/nginx  \    --with-pcre \    --with-http_stub_status_module \    --with-http_ssl_module    make &amp; make install2.修改配置文件实现七层调度    在http上下文定义：vim /usr/local/nginx/conf/nginx.confupstream blogs {server 192.168.100.3:80 weight=1 max_fails=3 fail_timeout=100s;server 192.168.100.4:80 weight=1 max_fails=3 fail_timeout=100s;hash $remote_addr consistent; (做会话保持)}server {    listen 80;    server_name www.lkblog.net;    index index.html index.php;    location / {        proxy_pass http://blogs;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        add_header X-Via  $server_addr;        proxy_next_upstream http_502 http_504 error timeout invalid_header;    }}3.启动服务    /usr/local/nginx/sbin/nginx     /usr/local/nginx/sbin/nginx -t     /usr/local/nginx/sbin/nginx -s reload 配置完后重新加载</code></pre><h3 id="启动各服务，并测试读写"><a href="#启动各服务，并测试读写" class="headerlink" title="启动各服务，并测试读写"></a>启动各服务，并测试读写</h3><p>-<br><img src="/2018/03/22/基于lnnmp搭建个人博客/初次登录注册.png" alt="初次登录注册页面"><br>注册完后生成数据库各表<br><img src="/2018/03/22/基于lnnmp搭建个人博客/数据库表.png" alt="数据库"><br>-<br><img src="/2018/03/22/基于lnnmp搭建个人博客/上传图片测试.png" alt="上传图片测试"><br>上传图片测试，在nfs也是可以看到的，说明挂载是成功的</p><p>-浏览站点，因为是普通的http请求，用轮询的方式是没问题的<br><img src="/2018/03/22/基于lnnmp搭建个人博客/后台日志.png" alt="后台日志"></p><p>-对于登录页面，如果没有做会话保持是登不上去的，这也是为什么Nginx负载均衡器上做源地址hash的原因.<br><img src="/2018/03/22/基于lnnmp搭建个人博客/用户登录测试.png" alt="用户登录测试"></p><h3 id="升级wordpress版本"><a href="#升级wordpress版本" class="headerlink" title="升级wordpress版本"></a>升级wordpress版本</h3><pre><code>版本更新需要注意最好不要跨大版本进行更新，一般更新也是在大版本下进行小版本的更新以下以wordpress-5.0--&gt;wordpress-5.0.2步骤：    1.停止Nginx服务    2.备份元数据或删除    3.升级版本    4.启动服务简单的以脚本方式实现一台wordpress升级    vim updates.sh        ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx -s stop&quot;        ssh 192.168.100.4 &quot;rm -rf /data/nginx/wordpress/*&quot;        scp wordpress-5.0.2-zh_CN.zip 192.168.100.4:/data        ssh 192.168.100.4 &quot;unzip wordpress-5.0.2-zh_CN.zip -d /data/nginx/wordpress/&quot;        ssh 192.168.100.4 &quot;chown -R www.www /data/nginx/wordpress/&quot;        ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx&quot;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;基于openstack-docker搭建LNNMP&quot;&gt;&lt;a href=&quot;#基于openstack-docker搭建LNNMP&quot; class=&quot;headerlink&quot; title=&quot;基于openstack/docker搭建LNNMP&quot;&gt;&lt;/a&gt;基于openstack/docker搭建LNNMP&lt;/h3&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现反向代理功能</title>
    <link href="https://www.liukui.tech/2018/03/22/nginx%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%8A%9F%E8%83%BD/"/>
    <id>https://www.liukui.tech/2018/03/22/nginx实现反向代理功能/</id>
    <published>2018-03-22T00:00:00.000Z</published>
    <updated>2019-01-22T12:20:49.758Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Nginx实现反向代理服务器的配置"><a href="#Nginx实现反向代理服务器的配置" class="headerlink" title="Nginx实现反向代理服务器的配置"></a>Nginx实现反向代理服务器的配置</h3><a id="more"></a><p><img src="/2018/03/22/nginx实现反向代理功能/nginx代理原理.png" alt="nginx实现反向代理原理"></p><pre><code>nginx实现反代的工作原理：    1.代理服务器需要注册监听端口，用来接收用户请求，而监听端口是可以被复用的，且一个端口可以接收N路请求.    2.代理服务器本地没有资源，当请求报文送达时，由于代理服务本身就是个web服务器，所以能够充分理解请求报        文的MIME类型，URL等，差别只是本来是需要通过IO加载本地资源的，但是由于本地没有，则会向后端服务器        去取资源，但是此时请求报文已经被完完整整的拆开了，是不能把请求报文发往后端的    3.所以在nginx中是由一个模块扮演成类似客户端浏览器角色的，把自己模拟成客户端程序，封装一个新的http请求，    向后端服务器发起请求.    4.而后端服务器会把响应报文发送给代理服务器，代理服务器则又会拆掉网络层封装，传输成封装，应用层封装，        看到响应报文的body主体部分，把主体部分拿出来重新封装成一个响应报文发回给客户端》    5.只要是向后端请求必然会再占用一个端口    6.代理服务器要维持两路连接，而且是彼此隔离且独立的    7.那么向后端发送的请求报文要不要带客户端请求中所独有的私有的信息数据？        如果不传递，后端服务器是无法识别并相应的，必要时要把客户端的属性信息:请求        的url,用户认证信息等等重新封装到向后端发送的请求报文中，还是引用了客户端        发来的数据，而且代理服务器是可以修改请求报文的信息和响应报文中的信息    8.代理服务器可以操纵发往后端的请求和操纵响应给客户端的请求    9.这些也只有工作在应用层并且能识别应用层协议才可以实现的，如果再加一些访问控制        的功能，那么就可以做到四层防火墙做不到的访问控制能力，这也是代理服务器叫做        代理网关的原因，对于iptables和LVS是做不到的    10.面向客户端工作http/https协议，面向后端工作http,tcp,fastCGI,memcache，uwsgi(python的web框架)        等协议，那么这个能模拟客户端的模块就需要是多种专用模块1.nginx作为代理服务器来说，面向于客户端和服务端可以代理多种协议  代理服务器又叫代理网关，因为工作在应用层可以控制用户访问请求的资源，具有防护功能    面向客户端：        一般是http/https协议：通过http模块实现        mail:简单邮件传输协议等        stream:stream模块实现代理四层协议：tcp/udp            (nginx从1.9版本后可以实现四层负载均衡的)    代理后端服务器：        nginx内嵌了很多客户端模块来适配不同的后端协议：            http协议的服务器：ngx_http_proxy_modules模块            fpm服务器：ngx_http_fastcgi_module模块            memche服务器：</code></pre><h3 id="代理后端http协议的模块：专门代理后端是http协议的服务器集群-httpd和nginx"><a href="#代理后端http协议的模块：专门代理后端是http协议的服务器集群-httpd和nginx" class="headerlink" title="代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx)"></a>代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx)</h3><p><img src="/2018/03/22/nginx实现反向代理功能/" alt="nginx代理逻辑"></p><p>1.nginx作为代理服务器是，代理客户端和后端服务器，在数据报文是有两段的：<br>    1.客户端—&gt;代理服务器<br>    2.代理服务器作为客户端—&gt;后端的httpd/fpm/memche服务器<br>    而且代理服务器可以把客户端发来的数据报文进行修改重新封装发给后端服务器，<br>    后端服务器响应给代理服务器的报文也可以被代理服务器修改，再响应给客户端<br>    在设置中，可以通过不能功能体现出数据报文被如何修改的！</p><p>2.作为代理配置和nginx作为web服务器差不多，只不过要把root/alias缓存proxy_pass<br>    如果同时又root和proxy_pass，proxy_pass的优先级高</p><p>3.在location中将<em>.php或者</em>.jpg代理到不同的后端服务器上，可以实现资源请求的动静分离<br>    实现了在一台代理服务器上的资源路由.</p><h3 id="ngx-http-proxy-module模块："><a href="#ngx-http-proxy-module模块：" class="headerlink" title="ngx_http_proxy_module模块："></a>ngx_http_proxy_module模块：</h3><pre><code>1.proxy_pass URL     代理http协议的主要功能，是将客户端的请求代理至后端服务的路径上        Context: location, if in location, limit_except；        server {            ...            server_name HOSTNAME;            location / {                proxy http://hos[:port]; 优先级高于server的root                }            location /uri/ {                    proxy http://host/new_uri/;                }            location ~|~* /uri/ {                    proxy http://host;                }            ...        }          http://HOSTNAME/uri --&gt; http://host/uri     http://HOSTNAME/uri/ --&gt; http://host/new_uri/    http://HOSTNAME/uri/ --&gt; http://host/uri/；    路径映射，前后端的location和proxy_pass是映射关系,必要加/    如果location是正则表达式路径，proxy_pass的路径必须没有/和URI，因为是正则表达        式，无法判断路径</code></pre><p>-前后端路径映射<br><img src="/2018/03/22/nginx实现反向代理功能/前后端路径映射.png" alt="前后端路径映射"> </p><pre><code>2.proxy_set_header field value;    前面说过代理服务器可以修改客户端请求数据报文的信息发送给后端服务器，而对于后端    服务器来说看到的请求报文的源IP一直是代理服务器，但是可以通过修改参数是的后端    服务器看到的IP地址是真正的客户端地址而不是代理服务器！    设定发往后端主机的请求报文的请求首部的值；Context:http,server,location    设置代理服务器：        proxy_set_header X-Real-IP  $remote_addr;        或者        proxy_set_header X-Real-HOST  $host;将        或者        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    然后修改后端服务器的日志格式：        LogFormat &quot;%{X-Real-IP}i %l %u %t \&quot;%r\&quot; %&gt;s %b&quot;重启httpd服务即可    此时，后端服务器看到的IP就是客户端的IP了，所以可以设置任何真实的信息传递给后端服务器</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/proxy_set_header.png" alt="proxy_set_header"></p><h3 id="Nginx代理Web服务的Proxy缓存功能"><a href="#Nginx代理Web服务的Proxy缓存功能" class="headerlink" title="Nginx代理Web服务的Proxy缓存功能"></a>Nginx代理Web服务的Proxy缓存功能</h3><p>Nginx是一个高性能的web服务器，尤其在高并发和处理静态页面的时候有先天的优势；很大一部分得益于缓存的开启，缓存的实现逻辑</p><pre><code>* 此处是作用于http的上下文，因为每个代理模块都有缓存功能，但是不能混用* 要想使用proxy的缓存功能，必须先定义再引用* 定义缓存所以列表：对文件进行hash生成hash串，hash串是16进制数字，如果把hash串的前三位数字，按照数字放在对应的层级生成一个三级索引列表* 根据实际情况定义缓存层级，每多一次就是对磁盘IO的消耗，灵活定义缓存层级很有必要，比如一层以1个16进制数就是16个目录，2个16进制数就是2^8=256个目录，可以通过增加每次的级数，减小层数，对磁盘的IO消耗就降低了nginx的缓存功能： 不一定启用nginx缓存，可以使用varnish,或者CDN        只有真正需要启用时，才会启用nginx缓存    3.proxy_cache_path        nginx作为代理服务器是可以使用缓存功能的        定义缓存功能键也就是索引，是放在内存中的        定义可用于proxy功能的缓存；Context:http的上下文                   proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time];    4.proxy_cache ksys_zone的name | off;        指明要调用的缓存，或关闭缓存机制；Context:http, server, location    5.proxy_cache_key string;        虽然定义了缓存，还需要定义键，而这个键就是用户访问的地址;        1.为了避免后端有两台server_name有一模一样的URI,造成缓存索引出错，这里引入            了更多的差别数据，把整个访问路径都引入进来进行hash值缓存.        2.然而把整个url都引入进来，也会有问题，比如一个server有两个主机名，路径本            来就应该是相同的，如果引入了全路径则造成缓存不能命中了        3.所以如何定义这个&quot;键&quot;是根据不同场景使用的        默认值：proxy_cache_key $scheme$proxy_host$request_uri;                有时也可以定义为：$request_uri        所以根据不同使用场景proxy_cache_key的值需要修改    6.proxy_cache_valid [code ...] time;        通过定义不同的响应码来定义不同的缓存时长；(也可以统一为一个值)    7.proxy_cache_use_stale        当后端服务器有问题时，是否能够用过期的缓存资源响应客户端请求，默认是关闭的        proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...;    8.proxy_cache_methods GET | HEAD | POST ...;        设置客户端通过什么方法查询时，才调用缓存功能    9.proxy_hide_header field;        隐藏发送给客户端的响应报文的信息；f12中的header中看到的        默认nginx在响应报文中不传递后端服务器的首部字段Date, Server, X-Pad,         X-Accel-等，用于隐藏后端服务器特定的响应首部代理服务器请求后端服务器的几个超时时长：    10.proxy_connect_timeout time;        定义代理服务器后端服务器发请求的三次握手的连接时长        默认为60s，最长75s,不需要调    11.proxy_read_timeout time;        从后端接收响应报文的超时时长    12.proxy_send_timeout time;        连接建立后，向后端发送请求报文的超时时长示例：            先在http上下文中定义缓存；        proxy_cache_path /data/cache/nginx  levels=1:1:2；keys_zone webcache:10m max_size=2G;    再在server或者location中调用缓存和设置&quot;键&quot;以及过期时长；        location ~* \.(jpg|gif|jpeg)$ {           proxy_pass http://172.17.0.2;           proxy_cache webcache;           proxy_cache_key $request_uri;(这里根据不同场景定义)           proxy_cache_valid 200 302 301 1h;           proxy_cache_valid any 1m;           proxy_cache_methods GET HEAD;           proxy_cache_use_stale error timeout http_500 http_502 http_503;    这样就表示把缓存放在/data/cache/nginx中,最好是固态硬盘，磁盘IO越快，索引    查询的速度越快，定义了1:1:2三层路由索引，第一层16个目录，第二层16个子目录    第三次256个子目录</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/" alt="proxy_pass的缓存层级"></p><h3 id="ngx-http-headers-module模块：操纵响应报文首部"><a href="#ngx-http-headers-module模块：操纵响应报文首部" class="headerlink" title="ngx_http_headers_module模块：操纵响应报文首部"></a>ngx_http_headers_module模块：操纵响应报文首部</h3><pre><code>区别于proxy_set_header：    是代理服务器把客户端请求报文中的某些信息通过修改代理服务器请求报文首部的方式发送给后端服务器headers：    代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值；达到隐藏        某些信息不发给客户端。    1.add_header name value [always];        添加自定义首部；        add_header X-Via  $server_addr;        或者        add_header X-Accel $server_name;     发送给客户端的响应报文时，显示真正的后端服务器IP或者主机名    2.expires [modified] time;        expires epoch | max | off;        响应缓存的缓存时长        用于定义Expire或Cache-Control首部的值；</code></pre><h3 id="Nginx代理后端fastCGI协议"><a href="#Nginx代理后端fastCGI协议" class="headerlink" title="Nginx代理后端fastCGI协议"></a>Nginx代理后端fastCGI协议</h3><p><img src="/2018/03/22/nginx实现反向代理功能/LNMP的多种架构.png" alt="LA/NMP的几种架构"></p><pre><code>1.fpm其实就是一种类似于httpd的MPM模型中的prefork模型    启用一个fpm主进程，生成n个子进程，由子进程内部的php解释器负责处理并发的多路    请求，再将在本地运行完的php页面程序处理结果响应给请求的调用者2.fastcgi其实就是简装版的http协议，后端对应的php的fpm就是fastcgi协议的服务器后端    的解析fastcgi协议，而且还能够让fpm的子进程加载磁盘上的php程序文件在php解释器    中运行执行出结果3.Php并不支持编译成nginx的模块，那么Nginx只能调fastcgi模块与后端的fpm(php)服务器    进行通信，实现LNMP的架构4.真正与mysql等数据库通信的是php程序代码，即php到mysql的驱动模块，而不是php解释器5.如上图，因为fpm对进程的管理能力较弱，可以用nginx与全端调度器去连接，而且nginx可    以根据fastcgi处理请求的并发数，在nginx处限制向后端的请求连接数，nginx可以实现    中间件进行流量控制的效果.6.php管理自己子进程的方式有两种，static和dynamic动态和静态管理方式7.实现fpm的负载均衡调度，也是需要</code></pre><h3 id="ngx-http-fastcgi-module模块："><a href="#ngx-http-fastcgi-module模块：" class="headerlink" title="ngx_http_fastcgi_module模块："></a>ngx_http_fastcgi_module模块：</h3><pre><code>1.fastcgi_pass address;    address为fastcgi server的地址； location, if in location；    如：fastcgi_pass localhost:9000;    http://www.ilinux.io/admin/index.php --&gt; /admin/index.php (uri)        /data/application/admin/index.php2.fastcgi_index name;    fastcgi默认的主页资源; web的是index.html,php应该为index.php    如：fastcgi_index index.php3.fastcgi_param parameter value [if_not_empty];    1.由于动态站点在处理请求时，需要取得客户端在连接请求报文中的很多信息(IP,请求        方法,flag,param等)，所以nginx代理必须把保存在变量中与客户端连接状态的        数据，原样的传递给后端的fpm-server或fastcgi.    2.但是保存在nginx的变量名格式和fastcgi的变量名表示格式是不一样的，nginx的        是$+全小写的变量名，fpm是全大写的变量名    3.安装nginx默认就带有/etc/nginx/fastcgi_params,这个文件记录了需要向后端        fpm传递的所有变量.    4.除了传递变量，还需要将请求的uri与后端fpm服务器的路径建立映射关系，即定义        fpm上存放请求页面资源的真正路径.    配置示例：        比如先起一个fpm的容器：并且将动态资源保存在php容器的/data目录下        docker run --name php1 -d -v /data/php1:/data php:7-fpm-alpine    在nginx代理上如下设置：        location ~* \.php$ {            fastcgi_pass   172.17.0.4:9000;            fastcgi_index  index.php;            fastcgi_param  SCRIPT_FILENAME  /data$fastcgi_script_name;            include        fastcgi_params;        }</code></pre><h3 id="fpm的状态监控"><a href="#fpm的状态监控" class="headerlink" title="fpm的状态监控"></a>fpm的状态监控</h3><pre><code>4.php的状态监控    1.fpm的进程有static和dynamic两种管理方式，而且为了监控fpm是否正常工作，fpm的        配置文件中内嵌了/pm_status和/ping两个url来监控，status用来输出内嵌信息的        ，而默认是通过fastcgi协议显示的，不能直接看到状态信息，所以可以通过http协        议进行反代来检测fpm的工作状态.    2.可以通过显示监控状态的值，再通过ab,JMeter等工具进行压力测试，调整fpm的实际        场景下的并发访问量配置示例：通过/pm_status和/ping来获取fpm server状态信息；    location ~* ^/(status|ping)$ {            fastcgi_pass 172.17.0.2:9000;            fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;            include fastcgi_params;         }  测试： 如下图可以通过http://192.168.34.107:8082/status?xml&amp;full    或者html、json格式输出并显示出来，而且还可以通过接口调用加入到zabbix监控中</code></pre><p><img src="/2018/03/22/nginx实现反向代理功能/fpm状态监控.png" alt="fpm监控状态"> </p><h3 id="fastcgi的压力测试和缓存功能"><a href="#fastcgi的压力测试和缓存功能" class="headerlink" title="fastcgi的压力测试和缓存功能"></a>fastcgi的压力测试和缓存功能</h3><pre><code>a.fastcgi的动态资源缓存意义更大，因为php不用每次都执行代码了b.要使用缓存就需要先定义缓存；c.因为后端动态资源服务器是有用户认证和用户支付的资源的，为了信息安全对动态资源的缓    存一定不要缓存包含用户信息的资源定义缓存：和proxy的缓存是不能兼容的，需要单独定义(在server外,http的上下文定义)4.fastcgi_cache_path     path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number]     [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time]     [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time];    定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义；    levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE        leves=1:2:2    keys_zone=name:size        k/v映射的内存空间的名称及大小    inactive=time        非活动时长    max_size=size        磁盘上用于缓存数据的缓存空间上限调用缓存：        5.fastcgi_cache keys_zone的名称 | off;        调用指定的缓存空间来缓存数据；http, server, location        无定义默认使用的键，需要手动指定    6.fastcgi_cache_key string;        定义用作缓存项的key的字符串；              7.fastcgi_cache_methods GET | HEAD | POST ...;        为哪些请求方法使用缓存；               8.fastcgi_cache_min_uses number;        缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项；               9.fastcgi_cache_valid [code ...] time;        不同的响应码各自的缓存时长；    10.fastcgi_keep_conn on | off;        默认情况下，fastCGI响应一个请求后会立刻断开，如果是on状态会保持长连接fastcgi缓存定义示例：            http {        fastcgi_cache_path /data/cache/fcgi levels=1:2 keys_zone=fcgicache:10m max_size=2G;        server {            ...            location ~* \.php$ {            fastcgi_pass   172.17.0.4:9000;            fastcgi_index  index.php;            fastcgi_param  SCRIPT_FILENAME  /data$fastcgi_script_name;            include        fastcgi_params;            fastcgi_cache fcgicache;            fastcgi_cache_key $request_uri;            fastcgi_cache_valid 200 302 301 1h;            fastcgi_cache_valid any 1m;            fastcgi_cache_methods GET HEAD;        }缓存性能测试：                       ab -n 1000 -c 50 http://192.168.34.107:8082/index.php    在缓存前和缓存后通过模拟50路并发请求测试响应时间</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Nginx实现反向代理服务器的配置&quot;&gt;&lt;a href=&quot;#Nginx实现反向代理服务器的配置&quot; class=&quot;headerlink&quot; title=&quot;Nginx实现反向代理服务器的配置&quot;&gt;&lt;/a&gt;Nginx实现反向代理服务器的配置&lt;/h3&gt;
    
    </summary>
    
      <category term="web服务" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="nginx" scheme="https://www.liukui.tech/categories/web%E6%9C%8D%E5%8A%A1/nginx/"/>
    
    
      <category term="nginx" scheme="https://www.liukui.tech/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>zabbix基础</title>
    <link href="https://www.liukui.tech/2018/03/20/zabbix%E5%9F%BA%E7%A1%80/"/>
    <id>https://www.liukui.tech/2018/03/20/zabbix基础/</id>
    <published>2018-03-20T00:00:00.000Z</published>
    <updated>2019-03-16T01:39:19.594Z</updated>
    
    <content type="html"><![CDATA[<h3 id="zabbix介绍"><a href="#zabbix介绍" class="headerlink" title="zabbix介绍"></a>zabbix介绍</h3><a id="more"></a><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><pre><code>主要工作：    1.解决生产和测试环境遇到的问题    2.部署业务；    3.查看监控系统        查看服务是否出现问题和即将出现瓶颈等问题        如：mysql连接达到1500~2000时就变慢了；最近三个月的趋势        web服务的并发数达到一定值，就要考虑扩容了        实时监控服务是否down机，服务是否不可用，比如java服务内存溢出，tomcat由于内存溢出，导致访问异常，出现503，500等异常服务代码，如果zabbix对其做了监控，就可以实时及时的看到报警和展示，及时进行修复    4.监控系统是随着业务增加和服务器增加，在监控上不能出现瓶颈，不能因为监控系统的资源不够，导致监控项采集不完整和出故障时报警不及时等问题2.如何规划监控    在大规模集群中是通过不同的群组来管理：        1.根据不同业务分组        2.根据虚拟机/物理机分组        3.虚拟机内部又根据业务划分很多组</code></pre><h3 id="Zabbix核心任务"><a href="#Zabbix核心任务" class="headerlink" title="Zabbix核心任务"></a>Zabbix核心任务</h3><pre><code>主流监控系统功能介绍：    数据采集：周期性时序数据        1.主机/对象：服务器、路由器、交换机、存储、防火墙、IP、URL、自定义监控对象...        2.采集目标：监控项，指标数据（metrics data）    数据存储：        存储系统：            SQL: MySQL、PostgreSQL            NoSQL：MongoDB、HBase、InfluxDB、Prometheus、redis ...            rrd: Round Robin Database    数据：        历史数据: 每个监控项采集到的每个监控值        趋势数据:             趋势表里主要保留某个监控项一个小时内历史数据的最大值、最小值和平均值以及该监控项一个小时内所采集到的数据个数。    阈值：severity，可按照等级实现层级报警    告警：通过email, 短信, 微信,语音,故障自治愈            通过脚本将报警信息发送到公众号上Zabbix四大核心任务：    采集：zabbix-server, zabbix-proxy,zabbix-agent    1.agentless SNMP、Telnet、ssh、IPMI、JMX(监控tomcat)        #不能安装agent客户端的只能通过特殊协议来采集        #IPMI:服务器上的特殊接口，用来采集CPU温度和风扇转速等硬件进行监控    2.zabbix-server        核心组件，负责数据的存储、管理、查看    3.zabbix-agent        负责各节点的数据采集发送给server    4.zabbix-proxy        用于非常庞大的环境下是需要的：超过几百台服务器        多个agent--&gt;proxy--server  #可以有效减少server端的端口和CPU性能消耗;    存储:         zabbix database--&gt;mysql    展示：        zabbix web：支持图形聚合        graph -&gt; screen -&gt; slideshow(将多个screen以幻灯片的方式进行轮流展示)    告警：        host (host groups) &lt;---templates        host --&gt; items --&gt; triggers --&gt; action (conditions, operations)        #先创建模板，在模板里设置告警，然后把模板关联到某个主机上，使用模板的好处        是不需要在每个主机上都设置告警信息了.</code></pre><h3 id="1-安装Zabbix-server和数据库"><a href="#1-安装Zabbix-server和数据库" class="headerlink" title="1.安装Zabbix-server和数据库"></a>1.安装Zabbix-server和数据库</h3><pre><code>源码安装：zabbix-4.0.3.tar.gz版本1.环境准备：    安装常用命令：        [root@zabbix-server ~]# yum install vim iotop bc gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel zip unzip zlib-devel net-tools lrzsz tree ntpdate telnet lsof tcpdump wget libevent libevent-devel   安装依赖包：        [root@zabbix-server ~]# yum install gcc libxml2-devel net-snmp net-snmp-devel libevent-devel  curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel –y        [root@zabbix-server ~]# yum install /root/jdk-8u191-linux-x64.rpm            #安装java-jdk2.安装mariadb数据库    [root@mysql ~]# yum install mariadb-server mariadb -y    [root@mysql ~]# systemctl start mariadb    [root@mysql ~]# systemctl enable mariadb    [root@mysql ~]# mysql -proot123    [root@mysql ~]# MariaDB [(none)]&gt; create database zabbix character set utf8 collate utf8_bin;        #创建一个zabbix库，专门存放监控数据    [root@mysql ~]# MariaDB [(none)]&gt; grant all privileges on zabbix.* to zabbix@&quot;192.168.34.%&quot; identified by &apos;zabbix123&apos;;        #授权zabbix用户有权限访问zabbix库任何操作3.编译安装zabbix-server端    [root@zabbix-server ~]# cd /usr/local/src/    [root@zabbix-server src]# tar xf zabbix-4.0.3.tar.gz     [root@zabbix-server src]# cd zabbix-4.0.3    [root@zabbix-server zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java    [root@zabbix-server zabbix-4.0.3]# make &amp;&amp; make install    [root@zabbix-server zabbix-4.0.3]# cd /usr/local/zabbix/    [root@zabbix-server zabbix]# cd etc/    修改配置文件：        [root@zabbix-server etc]# grep &quot;^[a-Z]&quot; zabbix_server.conf        LogFile=/usr/local/zabbix//zabbix_server.log  #日志路径        DebugLevel=3                                  #日志级别        PidFile=/usr/local/zabbix/zabbix_server.pid   #pid路径        SocketDir=/usr/local/zabbix                   #zabbix目录        DBHost=192.168.34.126                     #mysql的IP地址        DBName=zabbix                             #连接的数据名        DBUser=zabbix                             #连接数据的用户                  DBPassword=zabbix123                      #连接数据库的密码        DBPort=3306                               #数据库的端口        Timeout=4                                 #        LogSlowQueries=3000                       #    准备启动脚本：        [root@node02 zabbix-4.0.3]# cp  misc/init.d/fedora/core/zabbix_* /etc/init.d/        [root@node02 zabbix-4.0.3]# cd /etc/init.d/        [root@node02 zabbix-4.0.3]# vim zabbix_server        BASEDIR=/usr/local/zabbix        PIDFILE=/usr/local/zabbix/$BINARY_NAME.pid            #将启动脚本里的zabbix的目录修改为编译安装的路径            #将pid路径修改和配置文件的路径一致(编译目录)    创建用户：        [root@node02 init.d]# useradd zabbix -s /sbin/nologin    修改zabbix编译目录权限：        [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R    初始化zabbix数据库：        [root@node02 ~]# cd /usr/local/src/zabbix-4.0.3        [root@node02 zabbix-4.0.3]# cd database/mysql/        [root@node02 mysql]# mysql -uzabbix -pzabbix123 -h192.168.34.126 zabbix &lt; schema.sql    启动zabbix:        [root@node02 zabbix]# /usr/local/zabbix/sbin/zabbix_server -c /usr/local/zabbix/etc/zabbix_server.conf            #通过编译生成目录下的二进制命令指定配置文件启动zabbix    查看端口：        [root@node02 zabbix]# ss -tnl        LISTEN     0      128               *:10051               #zabbix-server启动后监听在10051端口     </code></pre><h3 id="2-安装zabbix-web页面"><a href="#2-安装zabbix-web页面" class="headerlink" title="2.安装zabbix-web页面"></a>2.安装zabbix-web页面</h3><pre><code>zabbix的前端服务是PHP程序，需要安装httpd[root@node02 zabbix]# yum install php httpd    #安装php和httpd[root@node02 zabbix-4.0.3]# mkdir /var/www/html/zabbix    #创建zabbix目录[root@node02 zabbix]# cd /usr/local/src/zabbix-4.0.3[root@node02 zabbix-4.0.3]# cp -a frontends/php/* /var/www/html/zabbix/    #因为zabbix的前端程序都在解压的目录下，所以把其拷贝到httpd下的目录启动httpd:    [root@node02 zabbix]# systemctl start httpd访问：    http://192.168.34.118/zabbix</code></pre><p>–启动报错<br><img src="/2018/03/20/zabbix基础/启动报错.png" alt="启动报错"></p><pre><code>解决报错信息：1.安装依赖包：    [root@node02 zabbix]# yum install php-gettext php-session php-ctype php-xmlreader php-xmlwriter php-xml php-net-socket php-gd php-mysql2.更改vim /etc/php.ini参数：    post_max_size = 8M 改为 post_max_size = 16M     max_execution_time = 30 改为 max_execution_time = 300    max_input_time = 60 改为 max_input_time = 300    date.timezone = 改为 date.timezone = date.timezone = Asia/Shanghai 3.重启httpd,进入zabbix配置    注意：        如果在页面上连接mysql时出错，可以检查一下httpd_can_network_connect的值是不是on的；        [root@node02 conf]# getsebool -a | grep httpd_can_network_connect        httpd_can_network_connect --&gt; off        如果是off，需要修改成on        [root@node02 conf]# setsebool httpd_can_network_connect 1        上述状态改变只是暂时性的，一旦系统重启，该变量状态将改变回初始状态，因此，可以使用如下命令永久性改变状态：        [root@node02 conf]# setsebool -P httpd_can_network_connect_db on4.配置完成后将zabbix.conf.php放到/var/www/html/zabbix/conf下    zabbix.conf.php保存了刚才在页面上填写的信息，可以修改5.登录    账户：Admin 密码：zabbix6.登录后：    1.确认zabbix server是running状态；    2.默认会有一个报警，因为zabbix-server上的zabbix-agent进程没启动;    3.在Administartion-Users-ADMIN模板中修改语言和默认账户密码7.启动zabbix-server的agent服务    [root@node02 etc]# vim zabbix_agentd.conf    Server=127.0.0.1            #被动模式下的Server的IP    StartAgents=3               #agent进程起来之后，启动几个子进程收集日志                                #需要启动起来    ServerActive=127.0.0.1        #主动模式下的Server的IP    Hostname=Zabbix server     #当前主机的IP地址        #hostname是zabbix中用于区分监控主机的有效值，必须保留且不能重复        即一定要与web页面上的配置--&gt;主机--&gt;模板--&gt;主机名称保持一致，基于设置的hostname来监控，一般是改成IP地址8.启动zabbix-agent    [root@node02 etc]# /etc/init.d/zabbix_agentd start        #监听在10050端口    然后再web页面就可以看到主机zabbix server的ZBX为绿色正常状态了.9.字体优化    将windows下或者网上下载合适的字体上传到zabbix上    [root@node02 ~]# cd /var/www/html/zabbix/fonts/    DejaVuSans.ttf    root@node02 fonts]# grep &quot;DejaVuSans&quot; ../* -R    Binary file ../fonts/DejaVuSans.ttf matches    ../include/defines.inc.php:define(&apos;ZBX_GRAPH_FONT_NAME&apos;,        &apos;DejaVuSans&apos;); // font file name    ../include/defines.inc.php:define(&apos;ZBX_FONT_NAME&apos;, &apos;DejaVuSans&apos;);    修改方式：        1.将上传的字体改成DejaVuSans.ttf把原来的字体删除        2.将上面两个文件中调用的字体修改为上传的字体名</code></pre><h3 id="在需要监控的主机上部署zabbix-agent"><a href="#在需要监控的主机上部署zabbix-agent" class="headerlink" title="在需要监控的主机上部署zabbix-agent"></a>在需要监控的主机上部署zabbix-agent</h3><pre><code>1.环境准备：    [root@zabbix-server ~]# yum install gcc libxml2-devel net-snmp net-snmp-devel libevent-devel  curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel –y        [root@zabbix-server ~]# yum install /root/jdk-8u191-linux-x64.rpm            #安装java-jdk2.安装zabbix-agent    [root@node01 src]# tar xf zabbix-4.0.3.tar.gz    [root@node01 src]# cd zabbix-4.0.3    [root@node01 zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-agent    [root@node01 zabbix-4.0.3]# make &amp;&amp; make install    [root@node01 zabbix-4.0.3]# cd /usr/local/zabbix/3.配置zabbix-agent    [root@node01 zabbix]# cd etc/    [root@node03 etc]# vim zabbix_agentd.conf    PidFile=/usr/local/zabbix/zabbix_agentd.pid    LogFile=/usr/local/zabbix/zabbix_agentd.log    DebugLevel=3    Server=172.18.140.5        #被动模式下的server的IP    ListenPort=10050           #agent的端口    ListenIP=0.0.0.0           #agent本机监听的地址    StartAgents=3              #启用几个agent子进程用于收集数据    ServerActive=127.0.0.1     #主动模式的IP(可以是server或者proxy)    Timeout=30              #收集数据的超时时长，一定要设置成最长的30s        ##上面的选项都是agent客户端的通用配置    Hostname=192.168.34.107    ##一定要写成每个agent客户端自己的IP地址                                #因为server是依靠Hostname来区分客户端的    #AllowRoot=0    # User=zabbix    # Include=/usr/local/etc/zabbix_agentd.userparams.conf    # Include=/usr/local/etc/zabbix_agentd.conf.d/    # Include=/usr/local/etc/zabbix_agentd.conf.d/*.conf        #用于存放自定义监控项和脚本的    UnsafeUserParameters=1        #需要改成1即启用特殊字符，因为脚本里需要特殊字符    # UserParameter=        #自定义监控项(启用)4.准备启动脚本并修改    ##此处在公司是通过ansible推送到各个主机上的    ##安装的zabbix路径都是/usr/local/zabbix的，所以启动脚本也都一样    ###创建用户也是通过ansible来管理的    [root@node03 etc]# cp /usr/local/src/zabbix-4.0.3/misc/init.d/fedora/core/zabbix_agentd /etc/init.d/    ##此处在公司是通过ansible推送到各个主机上的5.创建用户    [root@node03 init.d]# useradd zabbix -s /sbin/nologin 6.修改zabbix目录权限    [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R   7.启动zabbix-agent    [root@node03 init.d]# /etc/init.d/zabbix_agentd start测试相关命令：    当把主机加入server时没有数据，可以先通过zabbix-get进行测试    [root@node02 bin]# cp /usr/local/zabbix/bin/zabbix_get /usr/bin/    [root@node02 bin]# zabbix_get -s 172.18.140.7 -p10050 -k &quot;agent.ping&quot;    1        #1表示172.18.140.7客户端时正常的</code></pre><h3 id="1-监控tomcat"><a href="#1-监控tomcat" class="headerlink" title="1.监控tomcat"></a>1.监控tomcat</h3><p>注意：<br>    1.java gateway如果要监控的后端java程序比较多，最好部署在一台单独的服务器上；<br>    2.使用阿里云上的java-gateway安装包，直接yum安装即可<br>        <a href="https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-java-gateway-4.0.1-1.el7.x86_64.rpm" target="_blank" rel="noopener">https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-java-gateway-4.0.1-1.el7.x86_64.rpm</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">1.要想监控java-tomcat,需要先在编译安装zabbix-server时加--enable-java选项;</span><br><span class="line">2.监控逻辑：</span><br><span class="line">    zabbix监控java服务的时候很特殊，并不是有agent和server直接监控的，而是在中间加</span><br><span class="line">    了一个代理层叫做java gateway，需要在tomcat服务中开启JMX服务(监听在TCP：12345</span><br><span class="line">        端口)，然后java gateway连接到JMX：12345端口，将监控项发给JMX，再将采集的数据发给zabbix-server.</span><br><span class="line"></span><br><span class="line">3.修改启动java-getway服务：</span><br><span class="line">    [root@node02 ~]# cd /usr/local/zabbix/sbin/zabbix_java/</span><br><span class="line">    [root@node02 zabbix_java]# vim settings.sh </span><br><span class="line">    LISTEN_IP=&quot;0.0.0.0&quot;         #java-gateway监听的地址</span><br><span class="line">    LISTEN_PORT=10052           #java-gateway端口</span><br><span class="line">    PID_FILE=&quot;/usr/local/zabbix/zabbix_java.pid&quot;</span><br><span class="line">    START_POLLERS=5             #启动多少线程数</span><br><span class="line">        #因为如果有后端100个java(tomcat)程序，最好设置20个线程，那就采集5次，</span><br><span class="line">        避免采集的很慢，根据实际情况修改</span><br><span class="line">    TIMEOUT=30                  ##采集数据的超时时长，一定要设置成最长的30s</span><br><span class="line">    启动：</span><br><span class="line">        [root@node02 zabbix_java]# /usr/local/zabbix/sbin/zabbix_java/startup.sh</span><br><span class="line">            #监听在10052端口</span><br><span class="line">    备注：</span><br><span class="line">        如果是以单独的服务安装的java-gateway,可以通过systemctl来控制启动关闭！</span><br><span class="line"></span><br><span class="line">4.在zabbix-server上配置java-getway服务的地址和端口</span><br><span class="line">    [root@node02 etc]# vim zabbix_server.conf</span><br><span class="line">    JavaGateway=172.18.140.5    #Java-gate的IP地址</span><br><span class="line">    JavaGatewayPort=10052       #Java-gate的端口</span><br><span class="line">    StartJavaPollers=5          #启动多少线程数要和java-gate配置文件中一致</span><br><span class="line"></span><br><span class="line">5.配置JDK环境：</span><br><span class="line">    [root@node01 ~]# tar xf jdk-8u191-linux-x64.tar.gz -C /usr/local/src/</span><br><span class="line">    [root@node01 src]# ln -sv /usr/local/src/jdk1.8.0_191/ /usr/local/jdk</span><br><span class="line">        #为了JDK升级方便，将其创建一个软链接，后期只要创建一个新的软链接即可</span><br><span class="line">    [root@node01 local]# vim /etc/profile</span><br><span class="line">    export JAVA_HOME=/usr/local/jdk</span><br><span class="line">    export TOMCAT_HOME=/apps/tomcat</span><br><span class="line">    export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$TOMCAT_HOME/bin:$PATH</span><br><span class="line">    export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar</span><br><span class="line">    [root@node01 local]# source /etc/profile</span><br><span class="line">        #是配置生效</span><br><span class="line">    [root@node01 local]# java -version  #查看是否为安装的JDK版本</span><br><span class="line"></span><br><span class="line">6.配置tomcat</span><br><span class="line">    [root@node01]# tar xf apache-tomcat-8.5.37.tar.gz -C /usr/local/src/</span><br><span class="line">    [root@node01]# cd /usr/local/src/apache-tomcat-8.5.37/</span><br><span class="line">    [root@node01 apache-tomcat-8.5.37]# cd webapps/</span><br><span class="line">    [root@node01 apache-tomcat-8.5.37]# bin/startup.sh </span><br><span class="line">        #启动tomcat服务</span><br><span class="line">7.配置tomcat监控参数</span><br><span class="line">    #修改catalina.sh启动脚本，放在第一个非注释行的前面</span><br><span class="line">    [root@node01 apache-tomcat-8.5.37]# vim bin/catalina.sh </span><br><span class="line">    CATALINA_OPTS=&quot;$CATALINA_OPTS </span><br><span class="line">    -Dcom.sun.management.jmxremote  #启用远程监控JMX</span><br><span class="line">    -Dcom.sun.management.jmxremote.port=12345   </span><br><span class="line">            #默认启动的JMX端口号，要和zabbix添加主机时候的端口一致即可</span><br><span class="line">    -Dcom.sun.management.jmxremote.authenticate=false #不使用用户名密码认证</span><br><span class="line">    -Dcom.sun.management.jmxremote.ssl=false #不使用ssl认证</span><br><span class="line">    -Djava.rmi.server.hostname=172.18.140.6&quot; </span><br><span class="line">            #tomcat主机自己的IP地址，不要写zabbix服务器的地址</span><br><span class="line">8.重新启动tomcat即可</span><br><span class="line">    [root@node01 etc]# /usr/local/tomcat/bin/startup.sh</span><br><span class="line">9.在zabbix监控页面配置</span><br><span class="line">    1.填写JMX的IP和端口</span><br><span class="line">    2.关联tomcat监控模板</span><br><span class="line">    3.导入制作好的tomcat模板，然后将主机关联到此模板即可.</span><br><span class="line">10.测试</span><br><span class="line">    如果window上安装了JDK，可以使用jconsole.exe进行登录测试JMX服务是否采集到数据</span><br><span class="line">    C:\Program Files\Java\jdk1.8.0_191\bin\jconsole.exe</span><br><span class="line">11.监控java排错方法</span><br><span class="line">    测试能否获取到java 当前已经分配的 线程数</span><br><span class="line">    # java -jar cmdline-jmxclient-0.10.3.jar - 192.168.15.203:12345 &apos;Catalina:name=&quot;http-bio-8080&quot;,type=ThreadPool&apos; currentThreadCount</span><br><span class="line">12.自制tomcat监控模板</span><br><span class="line">        busy-nio  #nio线程达到某个值时，通知给管理员</span><br></pre></td></tr></table></figure></p><p>–正常的tomcat的JMX状态<br><img src="/2018/03/20/zabbix基础/正常的tomcat的JMX状态.png" alt="正常的tomcat的JMX状态.png"></p><h3 id="2-zabbix的主动模式和被动模式"><a href="#2-zabbix的主动模式和被动模式" class="headerlink" title="2.zabbix的主动模式和被动模式"></a>2.zabbix的主动模式和被动模式</h3><p>–zabbix监控架构<br><img src="/2018/03/20/zabbix基础/zabbix监控架构.png" alt="zabbix监控架构"></p><pre><code>1.主动与被动    这是对于zabbix agent来说的工作模式    1.被动模式就是由zabbix server向zabbix agent发出指令获取数据，即zabbix     agent被动的去获取数据并返回给zabbix server，zabbix server周期性的向agent     索取数据，这种模式的最大问题就是会加大zabbix server的工作量，在数百台服务器的    环境下zabbix server不能及时获取到最新数据，但这也是默认的工作方式;        而且在server上回打开很多随机端口；    2.主动模式是有zabbix agent主动向server索取监控项，根据拿到的监控项再去采集数据然后返回给zabbix server，不再需要zabbix serve进行干预，因此主动模式在一定程度上可减轻zabbix server的压力；        主动模式下，只会向zabbix server的10051端口发出请求连接，就不会有随机端口</code></pre><h3 id="3-基于zabbix-proxy代理实现监控"><a href="#3-基于zabbix-proxy代理实现监控" class="headerlink" title="3.基于zabbix-proxy代理实现监控"></a>3.基于zabbix-proxy代理实现监控</h3><p>–zabbix主动模式<br><img src="/2018/03/20/zabbix基础/zabbix-proxy主动模式.png" alt="zabbix主动模式"></p><pre><code>1.zabbix_proxy    zabbix 是一个分布式的监控系统，支持通过代理服务器zabbix proxy收集zabbix agent的数据，然后把收集保存在本地数据库并发送给zabbix server进行统一存储和展示；2.优点：    1.更轻量，无图形化界面    2.临时保存在本地        可以独立采集数据并存储，临时的    3.易维护：配置完成后基本无需管理    4.报警通知：        代理服务器不发送邮件通知     5.独立数据库         保留少量最近数据3.编译安装zabbix-proxy</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">    1.环境准备：</span><br><span class="line">        [root@node01]#yum install gcc libxml2-devel net-snmp net-snmp-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel java-1.8.0-openjdk-devel</span><br><span class="line">    2.创建数据库</span><br><span class="line">       MariaDB [(none)]&gt; create database zabbix_proxy character set utf8 collate utf8_bin;</span><br><span class="line">       MariaDB [(none)]&gt; grant all privileges on zabbix_proxy.* to proxy@&apos;172.18.140.%&apos; identified by &apos;zabbix123&apos;;</span><br><span class="line">    3.安装zabbix-proxy</span><br><span class="line">        [root@node04 zabbix-4.0.3]# useradd zabbix -s /sbin/nologin</span><br><span class="line">        [root@node04 src]# tar xf zabbix-4.0.3.tar.gz</span><br><span class="line">        [root@node04 src]# c zabbix-4.0.3</span><br><span class="line">        [root@node04 zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-proxy --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java</span><br><span class="line">        [root@node04 zabbix-4.0.3]# make &amp;&amp; make install</span><br><span class="line">    4.初始化数据库</span><br><span class="line">        [root@node02 mysql]# mysql -uproxy -pzabbix123 -h172.18.140.7 zabbix_proxy &lt; schema.sql</span><br><span class="line"></span><br><span class="line">4.修改zabbix-proxy配置文件</span><br><span class="line">    ProxyMode=1                 #0为主动，1为被动</span><br><span class="line">    Server=172.18.140.5         #被动模式下zabbix server服务器的地址或主机名</span><br><span class="line">                    #如果proxyMode是0，就不需要填此地址</span><br><span class="line">    Hostname=zabbix-proxy-active</span><br><span class="line">        #代理服务器名称，需要与zabbix server添加代理时候的proxy name是一致的！</span><br><span class="line">    LogFile=/tmp/zabbix_proxy.log</span><br><span class="line">    DBHost=172.18.140.7         #数据库服务器地址</span><br><span class="line">    DBName=zabbix_proxy         #使用的数据库名称</span><br><span class="line">    DBUser=proxy                #连接数据库的用户名称</span><br><span class="line">    DBPassword=zabbix123        #数据库用户密码</span><br><span class="line">    DBPort=3306                 #数据库端口</span><br><span class="line">    ###################################################################</span><br><span class="line">        框中的配置只会在主动模式下生效，被动模式不生效</span><br><span class="line">    ###################################################################</span><br><span class="line">    ProxyLocalBuffer=3 </span><br><span class="line">                #已经提交到zabbix server的数据保留时间(单位小时，最大720)</span><br><span class="line">    ProxyOfflineBuffer=24 </span><br><span class="line">                #未提交到zabbix server的时间保留时间(单位小时，最大720)</span><br><span class="line">    HeartbeatFrequency=60 </span><br><span class="line">                #心跳间隔检测时间，默认60秒，范围0-3600秒，被动模式不使用</span><br><span class="line">    ConfigFrequency=5           #建议时间短一点</span><br><span class="line">                #间隔多久从zabbix server索取获取监控信息</span><br><span class="line">    DataSenderFrequency=5 #需要改长</span><br><span class="line">                #数据发送时间间隔，默认为1秒，范围为1-3600秒，被动模式不使用</span><br><span class="line">    ###################################################################    </span><br><span class="line">    StartPollers=20             #启动的数据采集器线程数量(生产环境下尽量多点)</span><br><span class="line">    StartHTTPPollers=5          #启动多少线程响应http的请求</span><br><span class="line">    JavaGateway=172.18.140.5 </span><br><span class="line">        #java gateway服务器地址,当需要监控java的时候必须配置否则监控不到数据</span><br><span class="line">    JavaGatewayPort=10052       #Javagatewa服务端口</span><br><span class="line">    StartJavaPollers=5         #启动多少个线程采集数据和java-gate一致</span><br><span class="line">    ###################################################################</span><br><span class="line">            !!!和性能相关的非常重要的两项优化!!!</span><br><span class="line">            !!!zabbix-server和zabbix-proxy都需要优化这两项!!!</span><br><span class="line">        zabbix保存监控项是放在内存中的，所以CacheSize默认的8M内存空间是不够的</span><br><span class="line">        在zabbix-proxy服务器内存较大时，一定要把这个值调大(2G/4G)！！</span><br><span class="line">    ###################################################################</span><br><span class="line">    CacheSize=2G                #保存所有主机的监控项而占用的最大内存</span><br><span class="line">    HistoryCacheSize=2G         #保存监控历史数据占用的最大内存</span><br><span class="line">    HistoryIndexCacheSize=4M   #建议改成128M</span><br><span class="line">    TrendCacheSize=128M     #建议改成128M</span><br><span class="line">    ValueCacheSize=128M     #建议改成128M</span><br><span class="line">    ###################################################################</span><br><span class="line">    HistoryCacheSize默认才16M，建议一定要改成做大的2G内存</span><br><span class="line">    ###################################################################</span><br><span class="line">    Timeout=30                  #监控项超时时间，单位为秒</span><br><span class="line">    LogSlowQueries=3000         #毫秒，多久的数据库查询会被记录到日志</span><br><span class="line"></span><br><span class="line">5.授权并启动：</span><br><span class="line">    [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R</span><br><span class="line">    [root@node04 zabbix]# /usr/local/zabbix/sbin/zabbix_proxy -c /usr/local/zabbix/etc/zabbix_proxy.conf</span><br><span class="line">        #这里直接使用二进制命令指定配置文件启动了</span><br><span class="line">    或者</span><br><span class="line">        将yum安装的zabbix-proxy的启动脚本拷贝过来，修改里面的配置文件路径和二进制命令的路径即可启动.</span><br></pre></td></tr></table></figure><h3 id="zabbix自动注册和自动发现"><a href="#zabbix自动注册和自动发现" class="headerlink" title="zabbix自动注册和自动发现"></a>zabbix自动注册和自动发现</h3><pre><code>1.自动发现：zabbix Server 主动发现所有客户端，然后将客户端登记自己的小本本上，缺点 zabbix server压力山大（网段大，客户端多），时间消耗多。自动注册：zabbix agent 主动到 zabbix Server 上报到，登记；缺点 agent 有可能找不到 Server（配置出错）被动模式：默认，都是站在 agent 的立场上说话，agent 被 server 抓取数据主动模式：都是站在 agent 的立场上说话，agent 主动的将数据发送给 Server两种模式都是在 agent 上的配置文件配置的1.1 自动发现（被动模式）    第一步：zabbix Server 安装完毕 （完成）    第二步：zabbix agent 安装完毕，Server=172.16.1.61 （完毕）    第三步：网页上配置自动发现规则1.2 自动注册（主动模式）    第一步：zabbix Server 安装完毕 （完成）    第二步：zabbix agent 安装完毕，需要额外增加的配置    [root@node04 zabbix]# vim /etc/zabbix/zabbix_agentd.conf    ServerActive=172.16.1.61    # Hostname=Zabbix server    HostnameItem=system.hostname    [root@node04 zabbix]# systemctl restart zabbix-agent.service</code></pre><p>–自动发现<br><img src="/2018/03/20/zabbix基础/自动发现.png" alt="自动发现"><br>–自动发现规则<br><img src="/2018/03/20/zabbix基础/自动发现规则.png" alt="自动发现规则"><br>–自动发现动作<br><img src="/2018/03/20/zabbix基础/自动发现动作.png" alt="自动发现动作"><br>–自动发现1<br><img src="/2018/03/20/zabbix基础/自动发现1.png" alt="自动发现1"><br>–自动发现条件<br><img src="/2018/03/20/zabbix基础/自动发现条件.png" alt="自动发现条件"><br>–自动发现操作<br><img src="/2018/03/20/zabbix基础/自动发现操作.png" alt="自动发现操作"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;zabbix介绍&quot;&gt;&lt;a href=&quot;#zabbix介绍&quot; class=&quot;headerlink&quot; title=&quot;zabbix介绍&quot;&gt;&lt;/a&gt;zabbix介绍&lt;/h3&gt;
    
    </summary>
    
      <category term="监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="zabbix监控" scheme="https://www.liukui.tech/categories/%E7%9B%91%E6%8E%A7/zabbix%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="zabbix" scheme="https://www.liukui.tech/tags/zabbix/"/>
    
  </entry>
  
</feed>
