<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coool&#39;s Blog</title>
  
  <subtitle>As we watch our love grow.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.liukui.tech/"/>
  <updated>2018-12-14T01:43:49.647Z</updated>
  <id>https://www.liukui.tech/</id>
  
  <author>
    <name>空腹吃早餐</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mysql</title>
    <link href="https://www.liukui.tech/2018/08/06/mysql/"/>
    <id>https://www.liukui.tech/2018/08/06/mysql/</id>
    <published>2018-08-05T16:00:00.000Z</published>
    <updated>2018-12-14T01:43:49.647Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="数据库" scheme="https://www.liukui.tech/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="mysql" scheme="https://www.liukui.tech/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>ansible</title>
    <link href="https://www.liukui.tech/2018/03/06/ansible/"/>
    <id>https://www.liukui.tech/2018/03/06/ansible/</id>
    <published>2018-03-05T16:00:00.000Z</published>
    <updated>2018-12-13T05:40:23.025Z</updated>
    
    <content type="html"><![CDATA[<h1 id="运维自动化管理工具之Ansible"><a href="#运维自动化管理工具之Ansible" class="headerlink" title="运维自动化管理工具之Ansible"></a>运维自动化管理工具之Ansible</h1><p><img src="/2018/03/06/ansible/ansible.png" alt=""><br><a id="more"></a></p><h3 id="内容：1-软件发布环境机制优势对比-和-2-ansible的应用"><a href="#内容：1-软件发布环境机制优势对比-和-2-ansible的应用" class="headerlink" title="内容：1.软件发布环境机制优势对比  和   2.ansible的应用"></a>内容：1.软件发布环境机制优势对比  和   2.ansible的应用</h3><p><font color="#FF0000">ansible的相关的文档</font><br>ansible的中文权威指南：<a href="http://ansible.com.cn/" target="_blank" rel="noopener">ansible中文指南</a><br>Github上的ansible-galaxy示例：<a href="http://galaxy.ansible.com" target="_blank" rel="noopener">ansible-galaxy</a></p><p>其他相关运维管理工具使用方法：<br>pssh的使用方法参照链接文章：<a href="https://www.jianshu.com/p/d15b6b8f17a5" target="_blank" rel="noopener">pssh</a><br>saltstack介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">saltstack</a><br>puppet介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">puppet</a></p><pre><code>当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric常用自动化运维工具    PSSH：适用于主机数量很少的环境(基础ssh的key验证)    Ansible:python,Agentless,中小型应用环境(自带代理功能)    Saltstack:python，一般需部署agent，执行效率更高    Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境    Fabric：python，agentless    Chef: ruby,国内应用少    Cfengine    func</code></pre><h3 id="发布更新环境"><a href="#发布更新环境" class="headerlink" title="发布更新环境"></a>发布更新环境</h3><p><img src="/2018/03/06/ansible/01.jpg" alt=""></p><h4 id="灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机"><a href="#灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机" class="headerlink" title="灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)"></a>灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)</h4><pre><code>比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器    而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径     如：     软件路径为:/data/app     正在用的软件版本V1.0：/data/app1.0     更新的软件版本V2.0：/data/app2.0    则需要把删除原来的软链接：/data/app1.0---&gt;/data/app    创建新的软链接：/data/app2.0---&gt;/data/app10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线发布步骤：    1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。    2.从负载均衡列表中移除掉「金丝雀」服务器。    3.升级「金丝雀」应用（排掉原有流量并进行部署）。    4.对应用进行自动化测试。    5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。    6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。A/B Testing    A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。优势与不足：    优势：用户体验影响小，灰度发布过程出现问题只影响少量用户    不足：发布自动化程度不够，发布期间可引发服务中断预发布验证：    新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器灰度发布：    可以基于主机，用户或者业务，又细分为地区，VIP和普通用户</code></pre><h4 id="蓝绿发布：核心：主备两套环境"><a href="#蓝绿发布：核心：主备两套环境" class="headerlink" title="蓝绿发布：核心：主备两套环境"></a>蓝绿发布：核心：主备两套环境</h4><pre><code>定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同     时也升级到新版本主：绿色环境-活动环境：负责对外提供服务，版本：v1.0备：绿色环境-非活动环境：版本：v2.0工作机制：    先把备环境升级v1.0---&gt;v2.0版本，然后上线    把主环境的v1.0版本下线，已经升级的备环境进行替换特点：    蓝绿部署无需停机，并且风险较小.注意事项：    1.需要提前考虑数据库与应用部署同步迁移/回滚的问题    2.蓝绿部署需要有基础设施支持    3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境      和绿色环境有被摧毁的风险.优势与不足：    优势：升级切换和回退速度非常快    不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响</code></pre><h4 id="滚动发布：在灰度发布的基础上进行进一步优化"><a href="#滚动发布：在灰度发布的基础上进行进一步优化" class="headerlink" title="滚动发布：在灰度发布的基础上进行进一步优化"></a>滚动发布：在灰度发布的基础上进行进一步优化</h4><pre><code>定义：    一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式.特点：    1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数.  可以部分部署，例如每次只取出集群的20%进行升级。    2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出优势和不足:    优势：用户体验影响小，体验较平滑    不足：发布和回退时间比较缓慢。         发布工具比较复杂，LB需要平滑的流量摘除和拉入能力滚动发布目前成熟型技术组织所采用的主流发布方式</code></pre><h1 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h1><p><img src="/2018/03/06/ansible/ansible架构.png" alt="ansible架构"></p><h4 id="ansible特性：-最多管理500台主机，更多效率会降低"><a href="#ansible特性：-最多管理500台主机，更多效率会降低" class="headerlink" title="ansible特性：-最多管理500台主机，更多效率会降低"></a>ansible特性：-最多管理500台主机，更多效率会降低</h4><pre><code>1.模块化：调用特定的模块，完成特定任务   -类似linux中的小命令2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块3.支持自定义模块4.基于Python语言实现5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务)6.安全，基于OpenSSH7.支持playbook编排任务   -类似于脚本功能，多个脚本的集合成为Roles8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况9.无需代理不依赖PKI（无需ssl）10.可使用任何编程语言写模块11.YAML格式，编排任务，支持丰富的数据结构12.较强大的多层解决方案</code></pre><h3 id="Ansible的学习过程："><a href="#Ansible的学习过程：" class="headerlink" title="Ansible的学习过程："></a>Ansible的学习过程：</h3><pre><code>1.ansible基本命令使用2.ansible常用模块详解，介绍ansible单个命令的使用3.YAML语法介绍4.ansible playbook基础：剧本初体验，类似于写脚本5.playbook中的变量：tags，handlers使用6.plsybook模板：templates7.playbook的条件判断：when8.playbook的字典：with_items9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合</code></pre><p>会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。</p><h3 id="ansible命令执行过程"><a href="#ansible命令执行过程" class="headerlink" title="ansible命令执行过程"></a>ansible命令执行过程</h3><pre><code>ansible命令执行过程1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg2. 加载自己对应的模块文件，如command3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件4. 给文件+x执行5. 执行并返回结果6. 删除临时py文件，sleep 0退出执行状态：(颜色定义在/etc/ansible/ansible.cfg中)    绿色：执行成功并且不需要做改变的操作    黄色：执行成功并且对目标主机做变更    红色：执行失败</code></pre><h3 id="CMDB作用介绍"><a href="#CMDB作用介绍" class="headerlink" title="CMDB作用介绍:"></a>CMDB作用介绍:</h3><pre><code>CMDB:Configuration Management Database 配置管理数据库        将服务器的配置，网络配置写到数据库里CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管理等流程提供准确的配置信息.</code></pre><p>了解更多CMDB可参照文章：<a href="">CMDB</a></p><h2 id="1-ansible基本命令使用"><a href="#1-ansible基本命令使用" class="headerlink" title="1.ansible基本命令使用"></a>1.ansible基本命令使用</h2><h3 id="ansible软件安装：多种安装方法"><a href="#ansible软件安装：多种安装方法" class="headerlink" title="ansible软件安装：多种安装方法"></a>ansible软件安装：多种安装方法</h3><pre><code>1.基于epel源安装：    yum install ansible,非服务，只是一个管理工具2.编译安装：3.Github方式安装：可以同步安装4.pip安装：pip是安装Python包的管理器，类似yum</code></pre><h4 id="ansible的重要-amp-主要文件"><a href="#ansible的重要-amp-主要文件" class="headerlink" title="ansible的重要&amp;主要文件"></a>ansible的重要&amp;主要文件</h4><pre><code>配置文件：    /etc/ansible/ansible.cfg  配置ansible的工作特性    /etc/ansible/hosts  主机清单    /etc/ansible/roles  存放的角色目录程序文件：    /usr/bin/ansible   ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想    /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助    /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台    /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务    /usr/bin/ansible-vault 文件加密工具    /usr/bin/ansible-console 基于Console界面与用户交互的执行工具</code></pre><h4 id="ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法"><a href="#ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法" class="headerlink" title="ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)"></a>ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)</h4><pre><code>支持不分组，分组，等方式    如：        192.168.34.100        [webservers]        192.168.34.101        192.168.34.102        [dbservers]        192.168.34.[1:6]7 (17,27..67)        db[01:100].cenntos.com</code></pre><h4 id="ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）"><a href="#ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）" class="headerlink" title="ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）"></a>ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）</h4><pre><code>配置文件只提供默认值，但可以通过playbook的设置进行覆盖配置文件可以放在/etc/ansible/ansible.cfg中也可以放到一个工作目录下命名为.ansible.cfg[defaults]inventory = /etc/ansible/hosts - 主机列表配置文件library = /usr/share/my_modules/ - 库文件存放目录remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录forks = 5 - 默认并发数sudo_user = root - 默认sudo 用户ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码ask_pass = Trueremote_port = 22host_key_checking = False  -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错[color] 定义ansible命令的执行结果颜色的</code></pre><h3 id="配置文件说明和建议修改的项："><a href="#配置文件说明和建议修改的项：" class="headerlink" title="配置文件说明和建议修改的项："></a>配置文件说明和建议修改的项：</h3><pre><code>local_tmp和remote_tmp：    本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地    家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除.host_key_checking = False -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错module_name = command   -默认使用的命令模块，可以修改成shell    module_name = shell</code></pre><h2 id="2-ansible常用模块详解，介绍ansible单个命令的使用"><a href="#2-ansible常用模块详解，介绍ansible单个命令的使用" class="headerlink" title="2.ansible常用模块详解，介绍ansible单个命令的使用"></a>2.ansible常用模块详解，介绍ansible单个命令的使用</h2><h3 id="ansible模块的使用查询方法"><a href="#ansible模块的使用查询方法" class="headerlink" title="ansible模块的使用查询方法"></a>ansible模块的使用查询方法</h3><pre><code>ansible-doc: 显示模块帮助ansible-doc [options] [module...]    -a 显示所有模块的文档    -l, --list 列出可用模块    -s, --snippet显示指定模块的playbook片段示例：    ansible-doc –l 列出所有功能模块    ansible-doc ping 查看ansible中的ping用法    ansible-doc -s shell 查看shell模块的使用方法</code></pre><h3 id="ansible的常用基本选项"><a href="#ansible的常用基本选项" class="headerlink" title="ansible的常用基本选项"></a>ansible的常用基本选项</h3><pre><code>ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible    端能基于密钥认证的方式联系各被管理节点ansible语法：    ansible &lt;host-pattern&gt; [-m module_name] [-a args]    --version 显示版本    -m module 指定模块，默认为command，主要使用选项    -v 详细过程 –vv -vvv更详细    --list-hosts 显示主机列表，可简写 --list    -k, --ask-pass 提示输入ssh连接密码，默认Key验证    -K, --ask-become-pass 提示输入sudo时的口令    -C, --check 检查，并不执行    -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s    -u, --user=REMOTE_USER 执行远程执行的用户    -b, --become 代替旧版的sudo 切换</code></pre><h3 id="ansible的主机清单表示方法-Host-pattern"><a href="#ansible的主机清单表示方法-Host-pattern" class="headerlink" title="ansible的主机清单表示方法:Host-pattern"></a>ansible的主机清单表示方法:Host-pattern</h3><pre><code>1.All ：表示所有Inventory中的所有主机    如：ansible all -m ping        ansible all --list-hosts列出所有主机清单        ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP2.* :通配符    如：ansible &quot;*&quot; = ansible all        ansible 192.168.34.* 表示34网段的所有IP3.或的关系    如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作        ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作4.与的关系(且)    如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机5.非，取反    如：ansible &apos;websrvs:!dbsrvs&apos;        在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号6.正则表达式    如：ansible &quot;~(web|db).*\.centos\.com&quot; </code></pre><h2 id="ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块"><a href="#ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块" class="headerlink" title="ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)"></a>ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)</h2><h5 id="ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项"><a href="#ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项" class="headerlink" title="ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项"></a>ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项</h5><pre><code>1.Command：在远程主机执行命令，默认模块，可忽略-m选项    可以在ansible.cfg中修改默认模块项    支持：chdir(切换目录)    command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现使用示例：    ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh    ansible all -a &apos;useradd test&apos; 所有主机上创建test用户2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项    支持功能：支持$ &lt; &gt; | ; &amp; 等            chdir 执行前，先切换到该文件夹示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos;        显示appsrvs组的主机名    ansible all -m shell -a &apos;chdir=/data rm -rf *&apos;    先切换到/data目录下，再执行删除命令3.Script: 批量运行脚本    可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理    功能：creates:远程主机的文件存在，则不运行        removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令示例：ansible all -m script -a &quot;/data/test.sh&quot;    ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot;        因为fstab文件存在，则不执行rm -rf /data/*命令    ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot;        因为fstab文件存在，则执行rm -rf /data/*命令4.Copy:从服务器复制文件到目标主机    src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos;    根据自己写的字符串生成文件5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取    src，dest(抓取到本机目录)示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;        将远程主机fstab2文件抓取到本机/data下    如果抓取的是目录，先打包再抓取    打包：ansible all -a &apos;tar cf /root/data.tar /data&apos;     抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;6.File：设置文件属性，创建/删除文件    src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos;     创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos;     删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos;7.Hostname：管理主机名     可以通过后面的变量来实现    a.先在hosts后定义hostname变量名        [centos6]        192.168.34.106 hostname=mini6-2        192.168.34.101 hostname=node6-1         [centos7]        192.168.34.107 hostname=mini7-1    b.再通过hostname模块批量修改        ansible all -m hostname -a &apos;name={{hostname}}&apos;8.Cron：计划任务    支持：minute，hour，day，month，weekday示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate        172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务     ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名     ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名9.Yum：管理包    支持：name,state=(started stopped reloaded restarted),absent    更新缓存：update_cache=yes，示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包      ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包10.Service：管理服务(同一systemctl&amp;service)    name，state(stopped,started,reloaded,restarted) enable(设置开启启动)示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务     ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务     ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务     ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动11.User：管理用户    name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录)示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos;    创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录12.Group：管理组    支持：group,name,gid,system,state=(absent)示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组    ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 </code></pre><h2 id="ansible系列的一些模块-用的不多"><a href="#ansible系列的一些模块-用的不多" class="headerlink" title="ansible系列的一些模块(用的不多)"></a>ansible系列的一些模块(用的不多)</h2><pre><code>简单介绍与了解：ansible-galaxy 互联网上的角色分享ansible-pull      推送命令至远程，效率无限提升，对运维要求较高  Ansible-vault管理yaml文件    功能：管理加密解密yml文件        ansible-vault [create|decrypt|edit|encrypt|rekey|view]        ansible-vault encrypt hello.yml 加密        ansible-vault decrypt hello.yml 解密        ansible-vault view hello.yml 查看        ansible-vault edit hello.yml 编辑加密文件        ansible-vault rekey hello.yml 修改口令        ansible-vault create new.yml 创建新文件Ansible-console</code></pre><h2 id="ansible重要知识之playbook-上面的各种模块的组合"><a href="#ansible重要知识之playbook-上面的各种模块的组合" class="headerlink" title="ansible重要知识之playbook(上面的各种模块的组合)"></a>ansible重要知识之playbook(上面的各种模块的组合)</h2><p><img src="/2018/03/06/ansible/" alt="playbook原理"></p><h3 id="YAML语言（编写playbook的专门语言）"><a href="#YAML语言（编写playbook的专门语言）" class="headerlink" title="YAML语言（编写playbook的专门语言）"></a>YAML语言（编写playbook的专门语言）</h3><pre><code>YAML语法：     在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三    个点号( ... )用来表示档案结尾    次行开始正常写Playbook的内容，一般建议写明该Playbook的功能    使用#号注释代码    缩进必须是统一的，不能空格和tab混用    缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过    缩进结合换行来实现的    YAML文件内容是区别大小写的，k/v的值均需大小写敏感    k/v的值可同行写也可换行写。同行使用:分隔    v可是个字符串，也可是另一个列表    一个完整的代码块功能需最少元素需包括 name: task    一个name只能包括一个task    YAML文件扩展名通常为yml或yaml    List：列表，其所有元素均使用“-”打头    Dictionary：字典，通常由多个key与value构成</code></pre><h2 id="Playbook中的核心元素"><a href="#Playbook中的核心元素" class="headerlink" title="Playbook中的核心元素:"></a>Playbook中的核心元素:</h2><pre><code>1.Hosts 执行的远程主机列表2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远    程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使    用sudo_user指定sudo时切换的用户3.Tasks 任务集4.Varniables 内置变量或自定义变量在playbook中调用5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断8.handlers和notify  </code></pre><h2 id="运行playbook"><a href="#运行playbook" class="headerlink" title="运行playbook"></a>运行playbook</h2><pre><code>运行playbook的方式ansible-playbook &lt;filename.yml&gt; ... [options]常见选项    -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测    --list-hosts 列出运行任务的主机    --limit 主机列表 只针对主机列表中的主机执行    -v 显示过程 -vv -vvv 更详细 备注：    执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误    ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行</code></pre><h3 id="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"><a href="#执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。" class="headerlink" title="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"></a>执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。</h3><h2 id="示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验"><a href="#示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验" class="headerlink" title="示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验"></a>示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验</h2><h4 id="将centos7的httpd-conf复制到centos7主机，6上的配置文件不同"><a href="#将centos7的httpd-conf复制到centos7主机，6上的配置文件不同" class="headerlink" title="将centos7的httpd.conf复制到centos7主机，6上的配置文件不同"></a>将centos7的httpd.conf复制到centos7主机，6上的配置文件不同</h4><pre><code>示例1：写一个安装启动httpd的playbook:install_httpd.yml        包括创建用户，安装httpd包，开启服务，并设置开机启动- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd    - name: copy config      copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf    - name: install package      yum: name=httpd    - name: service      service: name=httpd state=started enabled=yes备注：    执行完通过以下命令判断每个任务都否都执行成功了    1.ansible all -a &apos;getent passwd httpd&apos;    2.ansible all -a &apos;rpm -q httpd&apos;    3..ansible all -a &apos;ss -ntlp|grep 80&apos;示例2：写一个删除上面的playbook:remove_httpd.yml        包括：删除用户，卸载httpd包- hosts: all  remote_user: root  tasks:    - name: del user      user: name=httpd state=absent remove=yes    - name: remove package      yum: name=httpd state=absent备注：    如果只删除特定主机的httpd，而不是全部，需要加--limit选项    ansible-playbook --limit 192.168.34.105 remove_httpd.yml        只限制在192.168.34.105的主机执行</code></pre><h4 id="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"><a href="#上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。" class="headerlink" title="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"></a>上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。</h4><h3 id="handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。"><a href="#handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。" class="headerlink" title="handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。"></a>handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。</h3><pre><code>Handlers:    是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生        变化时，才会采取一定的操作Notify:    此action可用于在每个play的最后被触发，这样可避免多次有改变发生    时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。    在notify中列出的操作称为handler，也即notify中调用handler中定义的操作</code></pre><h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><pre><code>示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200）- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted 备注：停止并删除用户和安装包    ansible all -a &apos;service memcached stop&apos;    ansible all -a &apos;ss -ntl&apos;    ansible all -a &apos;rpm -q memcached&apos;    ansible all -a &apos;getent passwd memcached&apos;</code></pre><h3 id="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"><a href="#可以多个notify对应一个handlers，也可以多个motify对应多个handlers" class="headerlink" title="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"></a>可以多个notify对应一个handlers，也可以多个motify对应多个handlers</h3><pre><code>示例4：多个notify对应一个handlers- hosts: websrvs  remote_user: root  tasks:    - name: Install httpd      yum: name=httpd state=present    - name: Install configure file      copy: src=files/httpd.conf dest=/etc/httpd/conf/      notify: restart httpd  第一个notify    - name: ensure apache is running      service: name=httpd state=started enabled=yes      notify: restart httpd  第二个notify  handlers:      - name: restart httpd   对应一个handlers      service: name=httpd status=restarted</code></pre><h3 id="示例5：多个notify对应多个handlers"><a href="#示例5：多个notify对应多个handlers" class="headerlink" title="示例5：多个notify对应多个handlers"></a>示例5：多个notify对应多个handlers</h3><pre><code>- hosts: websrvs  remote_user: root  tasks:    - name: config      copy: src=/root/config.txt dest=/etc/nginx/nginx.conf      notify:        - Restart Nginx        - Check Nginx Process  多个notify的写法  handlers:    - name: Restart Nginx     对应写多个handlers      service: name=nginx state=restarted enabled=yes    - name: Check Nginx process      shell: killall -0 nginx &gt; /tmp/nginx.log</code></pre><h3 id="tags的用法：作用：挑选某一段的task来执行"><a href="#tags的用法：作用：挑选某一段的task来执行" class="headerlink" title="tags的用法：作用：挑选某一段的task来执行"></a>tags的用法：作用：挑选某一段的task来执行</h3><pre><code>将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行然后执行：ansible-plsybook -t ceshi install_memcached.yml        只会触发拷贝文件和handlers的动作---#test yaml file- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致      tags: ceshi   对拷贝动作加一个标签    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted</code></pre><h2 id="Playbook中变量使用-可以多出定义，但是存在优先级"><a href="#Playbook中变量使用-可以多出定义，但是存在优先级" class="headerlink" title="Playbook中变量使用:可以多出定义，但是存在优先级"></a>Playbook中变量使用:可以多出定义，但是存在优先级</h2><h4 id="优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量"><a href="#优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量" class="headerlink" title="优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量"></a>优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量</h4><pre><code>变量名：仅能由字母、数字和下划线组成，且只能以字母开头变量来源：1 ansible setup facts 远程主机的所有变量都可直接调用    setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的        代码块，然后用代码块当变量    比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的          ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量3 通过命令行指定变量，优先级最高    可以对单个变量赋值：ansible-playbook –e varname=value     也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot;4 在playbook中定义    vars:         - var1: value1         - var2: value25 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件            很适合在roles中进行单独定义6 在role中定义（下文中有介绍）</code></pre><h3 id="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令"><a href="#从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令" class="headerlink" title="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令"></a>从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令</h3><p>#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作<br>        ansible_fqdn 主机名的变量<br>        ansible_hostname 主机名<br>        ansible_distribution_major_version: “6” 版本名变量<br>        ansible_processor_vcpus 虚拟cpu个数变量<br>        ansible_memtotal_mb 内存的变量<br>    示例：<br>    ansible all -m setup -a “filter=ansible_memtotal_mb”<br>        用此命令来查看系统内变量的值</p><h4 id="调用不同变量来源的示例：得出变量的优先级顺序"><a href="#调用不同变量来源的示例：得出变量的优先级顺序" class="headerlink" title="调用不同变量来源的示例：得出变量的优先级顺序"></a>调用不同变量来源的示例：得出变量的优先级顺序</h4><pre><code>示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml- hosts: all  remote_user: root  tasks:    - name: touch file      file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量    /etc/ansible/hosts：中定义的变量：        [websrvs]        192.168.34.105 port1=80        192.168.34.106 port1=90   -普通变量        [websrvs:vars]   -公共组变量        mark=&quot;-&quot;        [appsrvs]        192.168.34.101 port1=100        [appsrvs:vars]        mark=&quot;=&quot;    vars.yml中书写格式：        - hosts: all          remote_user: root          tasks:            - name: touch file              file: name=/data/app{{mark}}{{ port1 }}.log state=touch最后生成的文件为：            app=100.log，app-80.logapp-90.log示例3：在示例1的基础上，再通过命令行中定义变量:    在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果：    ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml    可以看出，最后新建的文件名为hahaha.log示例4：在playbook中定义变量    - hosts: all      remote_user: root      vars:        - port1: 200        - mark: +++      tasks:        - name: touch file          file: name=/data/app{{mark}}{{ port1 }}.log state=touch    生成的文件：        app+++200.log示例5：先写在var.yml中定义变量，    1.先准备cat vars.yml:文件内容格式        var1: httpd        var2: nginx    2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义        - hosts: web          remote_user: root          vars_files:            - vars.yml         tasks:           - name: create httpd log             file: name=/app/{{ var1 }}.log state=touch           - name: create nginx log             file: name=/app/{{ var2 }}.log state=touch</code></pre><h2 id="模板templates，作用："><a href="#模板templates，作用：" class="headerlink" title="模板templates，作用："></a>模板templates，作用：</h2><pre><code>文本文件，嵌套有脚本（使用模板编程语言编写）Jinja2语言，使用字面量，有下面形式字符串：使用单引号或双引号数字：整数，浮点数列表：[item1, item2, ...]元组：(item1, item2, ...)字典：{key1:value1, key2:value2, ...}布尔型：true/false算术运算：+, -, *, /, //, %, **比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;=逻辑运算：and, or, not流表达式：For If When</code></pre><h3 id="templates功能：根据模块文件动态生成对应的配置文件"><a href="#templates功能：根据模块文件动态生成对应的配置文件" class="headerlink" title="templates功能：根据模块文件动态生成对应的配置文件"></a>templates功能：根据模块文件动态生成对应的配置文件</h3><p>   templates文件必须存放于templates目录下，且命名为 .j2 结尾</p><pre><code>yaml/yml 文件需和templates目录平级，目录结构如下：./├── temnginx.yml└── templates   └── nginx.conf.j2</code></pre><h4 id="示例1：通过templates模板nginx"><a href="#示例1：通过templates模板nginx" class="headerlink" title="示例1：通过templates模板nginx"></a>示例1：通过templates模板nginx</h4><pre><code>1.先生成nginx.conf.j2模板cp /etc/nginx/nginx.conf templates/nginx.conf.j22.创建playbook- hosts: all  remote_user: root  tasks:    - name: inastll nginx      yum: name=nginx    - name: template      template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf                                       notify: service    - name: start service      service: name=nginx state=started  handlers:    - name: service      service: name=nginx state=restarted</code></pre><h3 id="when配合templates实现根据不同版本执行不同的功能"><a href="#when配合templates实现根据不同版本执行不同的功能" class="headerlink" title="when配合templates实现根据不同版本执行不同的功能"></a>when配合templates实现根据不同版本执行不同的功能</h3><pre><code>条件测试:    如果需要根据变量、facts或此前任务的执行结果来做为某task执行与    否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法    格式when语句    在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法示例：tasks:     - name: &quot;shutdown RedHat flavored systems&quot;     command: /sbin/shutdown -h now     when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值</code></pre><h4 id="示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when"><a href="#示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when" class="headerlink" title="示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when"></a>示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when</h4><pre><code>步骤：涉及到多个notify对应一个handlers,定义端口变量1.hosts文件配置：修改了4台主机httpd的端口    [centos6]    192.168.34.105 http_port=86    192.168.34.106 http_port=87    192.168.34.101 http_port=88    [centos7]    192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件    httpd_6.conf.j2      httpd_7.conf.j23.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的    Listen {{http_port}} 调用hosts列表中的端口变量4.plsybook如下：---- hosts: all  remote_user: root  tasks:    - name: install httpd      yum: name=httpd    - name: templates 6      template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf      notify: restart service      when: ansible_distribution_major_version == &quot;6&quot;    - name: templates 7      template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf                                when: ansible_distribution_major_version == &quot;7&quot;      notify: restart service    - name: service      service: name=httpd state=started  handlers:    - name: restart service      service: name=httpd state=restarted</code></pre><h2 id="迭代：with-items，类似于shell中的for循环"><a href="#迭代：with-items，类似于shell中的for循环" class="headerlink" title="迭代：with_items，类似于shell中的for循环"></a>迭代：with_items，类似于shell中的for循环</h2><pre><code>迭代：当有需要重复性执行的任务时，可以使用迭代机制对迭代项的引用，固定变量名为”item“要在task中使用with_items给定要迭代的元素列表列表格式：    字符串    字典   字典构成一个键值对{key:vavul},如示例3</code></pre><h4 id="迭代的示例："><a href="#迭代的示例：" class="headerlink" title="迭代的示例："></a>迭代的示例：</h4><pre><code>示例1：比如创建user1.user2.user3个用户    - hosts: all      remote_user: root      tasks:        - name: touch users          user: name={{item}}          with_items:            - haha1            - haha2            - haha3示例2：拷贝3个文件，file1 file2 file3    - hosts: all     remote_user: root    tasks:      - name: copy files        copy: src=/data/playbook/{{item}} dest=/data/        with_items:          - file1          - file2          - file3</code></pre><h2 id="迭代嵌套子变量-涉及到多个键值对的表达方式"><a href="#迭代嵌套子变量-涉及到多个键值对的表达方式" class="headerlink" title="迭代嵌套子变量:涉及到多个键值对的表达方式"></a>迭代嵌套子变量:涉及到多个键值对的表达方式</h2><pre><code>示例3：创建3个组，再创建3个用户，指定加入一一对应的组    - hosts: all      remote_user: root      tasks:        - name: creat groups          group: name={{item}}          with_items:            - group1            - group2            - group3        - name: creat users          user: name={{item.name}} group={{item.group}}          with_items:            - { name: &apos;haha1&apos;, group: &apos;group1&apos; }            - { name: &apos;haha2&apos;, group: &apos;group2&apos; }            - { name: &apos;haha3&apos;, group: &apos;group3&apos; }备注：注意创建用户时，键值对的表达和使用方法    上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3;</code></pre><h3 id="Playbook中template结合for循环生成具有重复性的代码段"><a href="#Playbook中template结合for循环生成具有重复性的代码段" class="headerlink" title="Playbook中template结合for循环生成具有重复性的代码段"></a>Playbook中template结合for循环生成具有重复性的代码段</h3><pre><code>语法:for的写法：    {% for vhost in nginx_vhosts %}        server {        listen {{ vhost.listen | default('80 default_server') }}### Playbook中template结合for循环生成具有重复性的代码段         if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用                        如果没定义，则不执行接下来的代码：示例2        {% if vhost.server_name is defined %}                server_name {{ vhost.server_name }};        {% endif %}        {% if vhost.root is defined %}                root {{ vhost.root }};        {% endif %}### for和if的示例，帮助理解其要执行语句的含义        示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成    先创建for.j2文件：                {% for i in ports %}                server{                        listen {{i.listen}}                        name {{i.name}}                        root {{i.root}}                }                {% endfor %}        创建playbook:再其中调用for.j2文件            - hosts: all              remote_user: root              vars:                ports:                  - web1:                    listen: 81                    name: www.baidu.com                    root: /data/web1                  - web2:                    listen: 82                    name: www.baidu1.com                    root: /data/web2              tasks:                - name: test for                  template: src=for.j2 dest=/data/for1.conf    效果为：        server{            listen 81            name www.baidu.com            root /data/web1        }        server{            listen 82            name www.baidu1.com            root /data/web2        }示例2：template配合if的涵义：    在示例1中的playbook中，把name注释掉，即不定义name的值            - web1:                    listen: 81                   # name: www.baidu.com                    root: /data/web1    然后playbook:再调用for.j2文件        {% for i in ports %}            server{                    listen {{i.listen}}            {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用                    name {{i.name}}            {% endif %}                    root {{i.root}}            }            {% endfor %}    结果：则web1没有name的值，即可以理解if的用法        server{            listen 81            root /data/web1  少了web1的name的值        }        server{            listen 82            name www.baidu1.com            root /data/web2        }</code></pre><h3 id="Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？"><a href="#Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？" class="headerlink" title="Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？"></a>Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？</h3><h2 id="ansible重要内容之Roles；playbook的集合和拆分"><a href="#ansible重要内容之Roles；playbook的集合和拆分" class="headerlink" title="ansible重要内容之Roles；playbook的集合和拆分"></a>ansible重要内容之Roles；playbook的集合和拆分</h2><pre><code> ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles    能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需    要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、    文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一    种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程    等场景中复杂场景：建议使用roles，代码复用度高变更指定主机或主机组如命名不规范维护和传承成本大某些功能需多个Playbook，通过Includes即可实现</code></pre><h3 id="roles的意义和适用场景："><a href="#roles的意义和适用场景：" class="headerlink" title="roles的意义和适用场景："></a>roles的意义和适用场景：</h3><pre><code>角色(roles)：角色集合    适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把    同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了，    当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。        如系统内会存在如下的各类服务，可以先编排好角色        roles/        ├── httpd/        ├── memcached/        ├── mysql/        └── nginx/</code></pre><h3 id="roles的目录结构（一般分成以下目录进行存放一类的文件）"><a href="#roles的目录结构（一般分成以下目录进行存放一类的文件）" class="headerlink" title="roles的目录结构（一般分成以下目录进行存放一类的文件）"></a>roles的目录结构（一般分成以下目录进行存放一类的文件）</h3><pre><code>Roles各目录作用：/roles/project/ :项目名称,有以下子目录    如创建http，memcached，nginx等目录files/ ：存放由copy或script模块等调用的文件    保存需要拷贝的配置文件templates/：template模块查找所需要模板文件的目录    保存通过template的jinja2模板调用的配置文件tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；        其它的文件需要在此文件中通过include进行包含handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此           文件中通过include进行包含vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要       在此文件中通过include进行包含，可以单独定义变量的目录meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，其它文件需在此文件中通过include进行包含            tasks目录下，组合任务顺序的文件default/：设定默认变量时使用此目录中的main.yml文件</code></pre><h3 id="roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色"><a href="#roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色" class="headerlink" title="roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色."></a>roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.</h3><pre><code>- hosts: all  remote_user: root  roles:    - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]}       - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}    - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}</code></pre><h3 id="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"><a href="#playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量" class="headerlink" title="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"></a>playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量</h3><pre><code>方法一：把需要调用的角色写在一个playbook里    - hosts: all      remote_user: root      roles:        - role: httpd        - role: memcached        - role: nginx    弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活方法二；可以把变量在角色中定义    传递变量给角色    - hosts:      remote_user:      roles:        - mysql        - { role: nginx, username: nginx }          键role用于指定角色名称          后续的k/v用于传递变量给角色          调用角色方法3：还可基于条件测试实现角色调用方法三：还可基于条件测试实现角色调用    roles:      - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ }</code></pre><h2 id="roles示例："><a href="#roles示例：" class="headerlink" title="roles示例："></a>roles示例：</h2><h3 id="以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml"><a href="#以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml" class="headerlink" title="以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml"></a>以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml</h3><h4 id="roles的目录结构下的httpd-amp-nginxmemcached"><a href="#roles的目录结构下的httpd-amp-nginxmemcached" class="headerlink" title="roles的目录结构下的httpd&amp;nginxmemcached"></a>roles的目录结构下的httpd&amp;nginxmemcached</h4><pre><code>roles├── httpd│   ├── files│   │   ├── index_6.html│   │   └── index_7.html│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── copyhtml_6.yml│   │   ├── copyhtml_7.yml│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig_6.yml│   │   ├── tempconfig_7.yml│   │   └── user.yml│   ├── templates│   │   ├── httpd_6.conf.j2│   │   └── httpd_7.conf.j2│   └── vars├── memcached│   ├── files│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig.yml│   │   └── user.yml│   ├── templates│   │   └── memcached.j2│   └── vars└── nginx    ├── files    │   ├── index_6.html    │   └── index_7.html    ├── handlers    │   └── main.yml    ├── tasks    │   ├── copyhtml_6.yml    │   ├── copyhtml_7.yml    │   ├── group.yml    │   ├── main.yml    │   ├── package.yml    │   ├── service.yml    │   ├── tempconfig.yml    │   └── user.yml    ├── templates    │   └── nginx.conf.j2    └── vars       └── main.yml</code></pre><h3 id="调用角色的playbook-roles-yml"><a href="#调用角色的playbook-roles-yml" class="headerlink" title="调用角色的playbook:roles.yml"></a>调用角色的playbook:roles.yml</h3><h5 id="可以通过加变量和标签和条件测试调用更灵活的调用各种角色"><a href="#可以通过加变量和标签和条件测试调用更灵活的调用各种角色" class="headerlink" title="可以通过加变量和标签和条件测试调用更灵活的调用各种角色)"></a>可以通过加变量和标签和条件测试调用更灵活的调用各种角色)</h5><pre><code>    vim /data/roles.yml            - hosts: all            remote_user: root          roles:        - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“}        - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}        - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}比如：     1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法     2.ansible-playbook -t httpd roles.yml 只选择安装httpd     3.ansible-playbook -t nginx roles.yml 只选择安装nginx     4.ansible-playbook -t web roles.yml 安装httpd和memcached     5.ansible-playbook -t web1 roles.yml 只选择安装nginx</code></pre><h3 id="下图为每个role的各个文件内容："><a href="#下图为每个role的各个文件内容：" class="headerlink" title="下图为每个role的各个文件内容："></a>下图为每个role的各个文件内容：</h3><h4 id="图一：参照roles的httpd的目录各个文件内容"><a href="#图一：参照roles的httpd的目录各个文件内容" class="headerlink" title="图一：参照roles的httpd的目录各个文件内容"></a>图一：参照roles的httpd的目录各个文件内容</h4><p><img src="ansible/roles_http.png" alt="roles_httpd"></p><h4 id="图二：参照roles的nginx的目录各个文件内容"><a href="#图二：参照roles的nginx的目录各个文件内容" class="headerlink" title="图二：参照roles的nginx的目录各个文件内容"></a>图二：参照roles的nginx的目录各个文件内容</h4><pre><code>涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有    跨角色调用配置文件写法：   - name: copy index6  copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html</code></pre><p><img src="/2018/03/06/ansible/roles_nginx.png" alt="roles_nginx"></p><h4 id="图三：参照roles的memcached的目录各个文件内容"><a href="#图三：参照roles的memcached的目录各个文件内容" class="headerlink" title="图三：参照roles的memcached的目录各个文件内容"></a>图三：参照roles的memcached的目录各个文件内容</h4><p><img src="/2018/03/06/ansible/roles_memcached.png" alt="roles_memcached"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;a href=&quot;#运维自动化管理工具之Ansible&quot; class=&quot;headerlink&quot; title=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;/a&gt;运维自动化管理工具之Ansible&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2018/03/06/ansible/ansible.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="自动化运维" scheme="https://www.liukui.tech/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="ansible,运维技术" scheme="https://www.liukui.tech/tags/ansible-%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>httpd</title>
    <link href="https://www.liukui.tech/2017/10/18/httpd/"/>
    <id>https://www.liukui.tech/2017/10/18/httpd/</id>
    <published>2017-10-18T00:00:00.000Z</published>
    <updated>2018-12-14T06:49:30.166Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>危栏倚遍都无寐，只恐星河堕入楼。 ——《秋夕楼居》吴融</p></blockquote><audio id="audio" controls preload="none"><br>      <source id="mp3" src="http://other.web.ri01.sycdn.kuwo.cn/resource/n3/1/70/780373770.mp3"><br></audio><a id="more"></a><blockquote class="blockquote-center">Till I reach the end, then I’ll start again<br>《Try Everything》<br></blockquote><h1 id="This-is-an-H1"><a href="#This-is-an-H1" class="headerlink" title="This is an H1"></a>This is an H1</h1><ul><li>Red</li><li>Green</li><li>Blue<blockquote><p>This is a blockquote<br>inside a list item.</p></blockquote></li></ul><hr><p><a href="http://example.com/" target="_blank" rel="noopener">http://example.com/</a></p><ul><li>Red<br><code>aa</code></li></ul><h3 id="This-is-an-H2"><a href="#This-is-an-H2" class="headerlink" title="This is an H2"></a>This is an H2</h3><font size="3" color="#FF0000"> size定义字体大小，color定义颜色</font><br><font size="3" color="#70DB93"> size定义字体大小，color定义颜色</font><br><font size="3" color="#9F5F9F"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D9D919"> size定义字体大小，color定义颜色</font><br><font size="3" color="#FF7F00"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D98719"> size定义字体大小，color定义颜色</font><br><font size="3" color="#2ae0c8"> size定义字体大小，color定义颜色</font><br><font size="3" color="#fad8be"> size定义字体大小，color定义颜色</font><br><font size="3" color="#cbf5fb"> size定义字体大小，color定义颜色</font><br><font size="3" color="#acf6ef"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D9D919"> size定义字体大小，color定义颜色</font><br><font size="3" color="#70DB93"> size定义字体大小，color定义颜色</font><br><font size="3" color="#BC8F8F"> size定义字体大小，color定义颜色</font><br><font size="3" color="#DB70DB"> size定义字体大小，color定义颜色</font><br><font size="3" color="#CFB53B"> size定义字体大小，color定义颜色</font><br><font size="3" color="#FF2400"> size定义字体大小，color定义颜色</font><br><font size="3" color="#CD7F32"> size定义字体大小，color定义颜色</font><br><font size="3" color="#23238E "> size定义字体大小，color定义颜色</font>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;危栏倚遍都无寐，只恐星河堕入楼。 ——《秋夕楼居》吴融&lt;/p&gt;
&lt;/blockquote&gt;
&lt;audio id=&quot;audio&quot; controls preload=&quot;none&quot;&gt;&lt;br&gt;      &lt;source id=&quot;mp3&quot; src=&quot;http://other.web.ri01.sycdn.kuwo.cn/resource/n3/1/70/780373770.mp3&quot;&gt;&lt;br&gt;&lt;/audio&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>httpd2</title>
    <link href="https://www.liukui.tech/2017/10/18/httpd2/"/>
    <id>https://www.liukui.tech/2017/10/18/httpd2/</id>
    <published>2017-10-18T00:00:00.000Z</published>
    <updated>2018-12-14T08:52:32.357Z</updated>
    
    <content type="html"><![CDATA[<!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --><blockquote class="blockquote-center">1</blockquote><!-- 标签 方式，要求版本在0.4.5或以上 --><blockquote class="blockquote-center"><p>这个城市的灯火辉煌，与你无关</p></blockquote><!-- 33 --><blockquote class="blockquote-center"><p>这个城市的灯火辉煌，与你无关</p></blockquote><a id="more"></a><h3 id="http协议-应用层协议-主流http-1-1版本"><a href="#http协议-应用层协议-主流http-1-1版本" class="headerlink" title="http协议:应用层协议,主流http/1.1版本"></a>http协议:应用层协议,主流http/1.1版本</h3><p>http0.9、http1.0、http1.1和http2.0的版本区别</p><ul><li>http/0.9:<blockquote><p>只有一个GET命令，且只能回应<em>.html文件格式，像</em>.txt等都不支持</p></blockquote></li><li>http/1.0:效率太低<blockquote><p>1.支持cache, MIME(支持各种资源类型), method<br>2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低<br>3.引入了POST命令和HEAD命令，头部信息和<br>4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用</p></blockquote></li><li>http/1.1:<blockquote><p>1.主流使用版本<br>2.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭，<br>  对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性<br>3.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率<br>4.新增方法：PUT、PATCH、OPTIONS、DELETE()<br>5.缺点：</p><blockquote><p>同一个TCP连接里，所有的数据通信是按次序进行的。服务器只能顺序处理回应，前面的回应慢，会有许多请求排队，造成”队头堵塞”<br>6.为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等<br>7.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度:不像tcp的有限状态机，http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点</p></blockquote></blockquote></li><li>http/2.0：解决 HTTP/1.1 效率不高问题</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --&gt;
&lt;blockquote class=&quot;blockquote-center&quot;&gt;1&lt;/blockquote&gt;


&lt;!-- 标签 方式，要求版本在0.4.5或以上 --&gt;
&lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;这个城市的灯火辉煌，与你无关&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- 33 --&gt;
&lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;这个城市的灯火辉煌，与你无关&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>文本三剑客之awk</title>
    <link href="https://www.liukui.tech/2017/10/18/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk/"/>
    <id>https://www.liukui.tech/2017/10/18/文本三剑客之awk/</id>
    <published>2017-10-17T16:00:00.000Z</published>
    <updated>2018-08-31T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文本处理三剑客之Awk"><a href="#文本处理三剑客之Awk" class="headerlink" title="文本处理三剑客之Awk"></a>文本处理三剑客之Awk</h1><p><img src="/2017/10/18/文本三剑客之awk/awk.png" alt=""></p><a id="more"></a><p>Awk的用户使用指南<a href="http://www.gnu.org/software/gawk/manual/gawk.html" target="_blank" rel="noopener">awk用户指南</a></p><p>相关链接文章：<br>正则表达式： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">正则表达式</a><br>grep文本编辑： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">grep用法</a><br>sed文本编辑： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">sed用法</a></p><h3 id="总结对比一下这三个剑客的特长之处"><a href="#总结对比一下这三个剑客的特长之处" class="headerlink" title="总结对比一下这三个剑客的特长之处"></a>总结对比一下这三个剑客的特长之处</h3><p>grep、sed、awk被称为linux中的三剑客</p><p>grep更适合单纯的查找或匹配文件.<br>sed更适合编辑皮匹配到的文本<br>awk更适合格式化文本，对文本进行比较复杂格式处理</p><p>文本三剑客都是默认逐行处理，自带循环<br>sed 可以对文本进行修改，而grep&amp;awk 只是对文本进行过滤,不进行内容修改</p><p>awk中的-F后面的分隔符,要用单引号’’,双引号””会产生弱引用,比如特殊符号’\\‘ ‘\\$’<br>关于awk中的单引号和双引号的问题参照：<a href="https://blog.csdn.net/swinfans/article/details/82991077" target="_blank" rel="noopener">awk中的输入分隔符单引号&amp;双引号</a></p><p>学习awk的一个重要知识点</p><pre><code>先举两个例子：awk &apos;/^UUID/&apos; /etc/fstab = awk &apos;/^UUID/{print $0}&apos; /etc/fstab 其实是隐藏了{print $0}的写法数组中的例子awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6实际上是隐藏了{print $0}</code></pre><h3 id="学习中遇到的混淆的问题："><a href="#学习中遇到的混淆的问题：" class="headerlink" title="学习中遇到的混淆的问题："></a>学习中遇到的混淆的问题：</h3><pre><code>&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印而后面的数组里的是加了双括号{}，即用的patter的空模式，即文本中的每一行都处理</code></pre><hr><hr><h2 id="Awk"><a href="#Awk" class="headerlink" title="Awk"></a>Awk</h2><p>基本用法和功能以及各个功能示例：<br>awk介绍<br>awk基本用法<br>awk变量<br>awk格式化-printf<br>awk操作符<br>awk条件判断<br>awk循环<br>awk数组<br>awk函数<br>调用系统命令</p><hr><hr><h3 id="awk介绍："><a href="#awk介绍：" class="headerlink" title="awk介绍："></a>awk介绍：</h3><pre><code>whatis awk？awk：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出，输出成报表格式linux上默认使用 GNU awk(gawk)[root@centos7 data]which awk/usr/bin/awk[root@centos7 data]ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Sep 19 11:45 /usr/bin/awk -&gt; gawkwhich awk=/usr/bin/awk 是gawk的软链接 </code></pre><hr><hr><h3 id="awk基本用法"><a href="#awk基本用法" class="headerlink" title="awk基本用法"></a>awk基本用法</h3><pre><code>awk [options] &apos;program&apos; var=value file…awk [options] -f programfile var=value file…awk [options] &apos;BEGIN{action;… }pattern{action;… }END{action;… }&apos; file ...awk 程序可由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块，共3部分组成program 通常是被放在单引号中 选项：    -F “分隔符” 指明输入时用到的字段分隔符    -v var=value 变量赋值基本格式：awk [options] &apos;program&apos; file…         Program：pattern{action statements;..}也就是说awk用法：awk [options] &apos;pattern{action statements;..}&apos; file…    pattern和action    • pattern部分决定动作语句何时触发及触发事件    BEGIN,END    • action statements对数据进行处理，放在{}内指明print, printf分割符、域和记录    • awk执行时，由分隔符分隔的字段（域）标记$1,$2...$n称为域标识。$0    为所有域，注意：此时和shell中变量$符含义不同    • 文件的每一行称为记录    • 省略action，则默认执行 print $0 的操作print格式：print item1, item2, ...    要点：    (1) 逗号分隔符    (2) 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式    (3) 如省略item，相当于print $0</code></pre><h3 id="用法解析及示例："><a href="#用法解析及示例：" class="headerlink" title="用法解析及示例："></a>用法解析及示例：</h3><pre><code>$0=代表处理的整行的内容$1,$2,$3..代表每一列，也就域BEGIN，END是为生成一个报表的头和尾准备的，用法通常为：BEGIN：为生成报告模式 添加表头;END:为生成的报告 进行信息汇总awk &apos;BEGIN{print xxx}{print xxx}END{print xxx}&apos;注意：BEGIN{print *xxx}处理文本前，打印一遍xxx的内容当成表头     END{print xxx},处理文本后，打印一遍xxx的内容作为表尾</code></pre><h2 id="BEGIN-amp-END"><a href="#BEGIN-amp-END" class="headerlink" title="BEGIN&amp;END"></a>BEGIN&amp;END</h2><pre><code>BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。END：让用户在最后一条输入记录被读取之后发生的动作。</code></pre><h2 id="分隔符："><a href="#分隔符：" class="headerlink" title="分隔符："></a>分隔符：</h2><pre><code>awk默认使用空白符作为字段或列的分隔符；多个空白符被认为是一个，空白符包括空格，tab键/t，回车\n也可以自定义-F&quot;分隔符&quot;自定义分隔符</code></pre><h3 id="print-amp-printf的区别："><a href="#print-amp-printf的区别：" class="headerlink" title="print&amp;printf的区别："></a>print&amp;printf的区别：</h3><pre><code>print命令只是单纯的把特定的内容进行打印，默认换行printf命令可以把内容以灵活的格式进行显示,如左对齐,右对齐</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre><code>1.awk支持标准输入输出，后面可以不跟文件[root@centos7 ~]#awk &apos;{print $0}&apos;aaaaaaaaabcabcabcabc2.打印/etc/passwd：对比几个输出结果awk &apos;{print $0}&apos; /etc/passwd 把passwd文件全部打印出来awk &apos;{print &quot;abc&quot;}&apos; /etc/passwd   读入的是passwd文件所有行，打印的是abcawk -v abc=1 &apos;{print abc}&apos; /etc/passwd  读入的是passwd文件所有行，打印的都是1awk &apos;{print &quot;abc&quot;$0}&apos; /etc/passwd 把passwd文件所有行前都加一个abc,进行输出所以在awk中不加双引号，abc被识别为变量，如果要引用变量，需要-v先定义值如果只是想输出abc字符串，需要加双引号3.awk{}中支持数字运算awk &apos;{print 1+2}&apos; /etc/passwd 打印多行1+2=3的值awk &apos;{print &quot;1+2&quot;}&apos; /etc/passwd 加双引号会把1+2当成字符串，输出多行1+24.取分区利用率df,df |awk &apos;{print $1,$5}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos;5.以输入重定向方式，打印 passwd 文件的第1列，即获取当前系统中存在的所有用户和UIDawk -F: &apos;{print $1,$3}&apos; &lt; /etc/passwdcat /etc/passwd | awk -F: &apos;{print $1,$3}&apos;awk -F: &apos;{print $1：$3}&apos;  /etc/passwd  两列输出时，指定以：进行隔开，默认为空格隔开awk -F: &apos;{print $1、$3}&apos;  /etc/passwd  两列输出时，指定以：进行隔开，默认为空格隔开cat /etc/passwd | awk -F: &apos;{print $1&quot;\n&quot; $3}&apos; 两列输出时,进行换行cat /etc/passwd | awk -F: &apos;{print $1&quot;\t&quot; $3}&apos; 两列输出时,以tab键隔开备注：多行输出时，可以在双引号之间加自定义的分隔符格式：awk -F: &apos;{print $1&quot;=======&quot;$3}&apos;  /etc/passwd </code></pre><hr><hr><h2 id="Awk中的变量："><a href="#Awk中的变量：" class="headerlink" title="Awk中的变量："></a>Awk中的变量：</h2><h3 id="变量分为：内置变量和自定义变量"><a href="#变量分为：内置变量和自定义变量" class="headerlink" title="变量分为：内置变量和自定义变量"></a>变量分为：内置变量和自定义变量</h3><pre><code>awk中的内置变量除了$0,$1,$2等，还有以下几种；如果要使用这些变量需要加-v 选项先进行定义FS：输入字段分隔符，默认为空白字符  =filed separator=域或列的分隔符等于-F的选项，-F是选项，而FS是变量，实际作用是相等的与-F的区别在于：可以下次调用FS变量awk -v FS=&apos;:&apos; &apos;{print $1,$3}&apos; /etc/passwd  = awk -F:&apos;{print $1,$3}&apos; /etc/passwdawk -v FS=&apos;:&apos; &apos;{print $1,FS$3}&apos; /etc/passwd  两列输出时以：做分隔符，调用变量FSawk -v FS=&apos;:&apos; &apos;{print $1,FS FS$3}&apos; /etc/passwd  两列输出时以：：做分隔符，调用2次变量FS 以空格隔开可以先定义shell中的变量fs=:,awk再进行调用fs=:;awk -v FS=$fs &apos;{print $1,FS,$3}&apos; /etc/passwd  fs=:;awk –F$fs &apos;{print $1,$3,$7}&apos; /etc/passwdOFS：输出字段分隔符，默认为空白字符 =output filed separator定义输出分隔符，不指定默认空空格做分隔符awk -v FS=: -v OFS=+++ &apos;{print $1,$3,$7}&apos; /etc/passwdfs=+++;awk -v FS=: -v OFS=$fs &apos;{print $1,$3}&apos; /etc/passwd  调用shell变量做输出分隔符RS：输入记录分隔符，指定输入时的换行符,自定义行的分隔符 =record记录默认一行叫记录，行是以\n回车作为切割符的，RS可以自定义不用回车作为分隔符    awk -v RS=&apos; &apos; ‘{print }’ /etc/passwd    awk -v RS=&apos;:&apos; &apos;{print NR,$0}&apos;/etc/passwd     [root@centos7 ~]cat f1    aa;xxx:bb;bzzzz:cc    dd:eex;zccc:xxxx    [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print $0}&apos;    aa;xxx    bb;bzzzz    cc    dd    eex;zccc    xxxx    以RS=：冒号自定义行的分隔符，输出结果如上    [root@centos7 ~]#cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; &apos;{print $1}&apos;    aa    bb    cc    dd    eex    xxxx    自定义FS&amp;RS，输出结果如上ORS：输出记录分隔符，输出时用指定符号代替换行符 awk -v RS=&apos; &apos; -v ORS=&apos;###&apos;‘{print }’ /etc/passwd[root@centos7 ~]cat f1aa;xxx:bb;bzzzz:ccdd:eex;zccc:xxxx[root@centos7 ~]cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; -v ORS&quot;===&quot; &apos;{print $1}&apos;aa==bb==ccdd==eex==xxxx==自定义FS,RS,ORS结果很明显接下来是一个比较重要的变量NF：字段数量,也就是域或列的总数量awk -F: &apos;{print NF}&apos; /etc/passwd 以冒号做分隔符，显示每行的列的总数量awk -F: &apos;{print $NF}&apos; /etc/passwd 显示以冒号做分隔符，每一行的最后一个字段即bash类型awk -F：&apos;{print $(NF-1)}&apos; /etc/passwd 显示以冒号做分隔符，每一行的倒数第二个字段统计光盘中所有安装包适用的cpu架构类型root@centos7 mnt]#ls /mnt/Packages/*.rpm | awk -F&quot;.&quot; &apos;{print $(NF-1)}&apos;|sort|uniq -c   1371 noarch   2600 x86_64NR：记录号，可以显示行数，如果有多个文件会合并后再统计总行awk &apos;{print NR,$0}&apos; /etc/fstab 在每一行前加一个行号awk BEGIN&apos;{print NR}&apos; /etc/fstab 输出结果为0  awk还没开始处理行，所以记录为0awk END&apos;{print NR}&apos; /etc/fstab  输出结果为12 可以看出END是统计,awk处理的行数1.通过加行号，可以很明显看出以冒号作为行的分隔符，每一行的都有什么；可以看出cc dd是一行的[root@centos7 ~]cat f1aa;xxx:bb;bzzzz:ccdd:eex;zccc:xxxx[root@centos7 ~]cat f1| awk  -v RS=&quot;:&quot; &apos;{print NR$0}&apos;1aa;xxx2bb;bzzzz3ccdd4eex;zccc5xxxx2.备注：如果awk跟两个文件，awk会把两文件合并成一个文件，统计总行数，都取第一个字段的信息如果需要分开显示统计，则用FNR[root@centos7 ~]awk -F: &apos;{print NR,$1}&apos; /etc/passwd /etc/group1 root2 bin3 daemon4 admFNR：各文件分别计数,记录号1.FNR:多个文件，每个分别统计显示第一个字段并列出来awk &apos;{print FNR}&apos; /etc/fstab /etc/inittab[root@centos7 ~]awk -F: &apos;{print FNR,$1}&apos; /etc/passwd /etc/group1 root2 bin3 daemon48 quagga49 httpd1 root2 binFILENAME：当前文件名1.统计时，加上变量可以显示文件名awk &apos;{print FILENAME}&apos; /etc/fstab[root@centos7 ~]awk -F: &apos;{print FILENAME,FNR,$1}&apos; /etc/passwd /etc/passwd 1 root/etc/passwd 2 bin/etc/passwd 3 daemonARGC：命令行参数的个数awk &apos;{print ARGC}&apos; /etc/fstab /etc/inittab 结果为3awk &apos;BEGIN {print ARGC}&apos; /etc/fstab /etc/inittab 结果为3ARGC统计参数：awk单独算一个参数，后面的每个文件算一个参数,通过下面的数组可以体现出来ARGV：数组，保存的是命令行所给定的各参数1.显示awk的每个参数分别是哪个[root@centos7 ~]awk &apos;{print ARGV[0]}&apos; /etc/fstab /etc/inittabawk[root@centos7 ~]awk &apos;{print ARGV[1]}&apos; /etc/fstab /etc/inittab/etc/fstab</code></pre><h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><pre><code>1.统计当前网络连接情况的ip地址是 ss -ntss -nt | awk &apos;{print $5}&apos;2.取/var/log/httpd/access_log的时间如下：root@centos7 ~]cat /var/log/httpd/access_log192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; 分两步取：cat /var/log/httpd/access_log | awk &apos;{print $4}&apos;|awk -F&quot;[&quot; &apos;{print $2}&apos;一步取：cat /var/log/httpd/access_log | awk -F &quot;[\[ ]&quot; &apos;{print $5}&apos;原理分析：[\[ ]代表（转义）\[和空格都算是分隔符，正则表达式的写法,或的关系，而以空格分隔符，时间段为$4,那为什么是$5?在空格的标准里，[算$4,所以时间段为$53.取出磁盘分区利用率 -这次只取出利用率两步取出：df | awk -F% &apos;{print $1}&apos;|awk &apos;{print $5}&apos;一步取出：df | awk -F&quot;[[:space:]]+|%&quot; &apos;{print $5}&apos; awk用的是扩展的正则表达式面试题：3-1,取出fstab中挂载的目录[root@centos7 ~]cat /etc/fstab # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=9612633f-e7f1-4b28-8813-403d209d7abc /                       xfs     defaults        0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot                   xfs     defaults        0 0UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data                   xfs     defaults        0 0UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap                    swap    defaults        0 0[root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos;bootdataswap或者[root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos;bootdataswap4.面试题：将文件f3中的第一个点前的字符串取出再写进去[root@centos7 ~]cat f31 test.sina.com.cn2 music.sina.com.cn3 sports.sina.com.cn4.news.sina.com.cn[root@centos7 ~]cat f3 | awk -F&quot;[ .]&quot; &apos;{print $2}&apos; &gt;&gt; f3[root@centos7 ~]cat f31 test.sina.com.cn2 music.sina.com.cn3 sports.sina.com.cn4.news.sina.com.cntestmusicsportsnews4-1,扩展前面-F&quot;[ .]&quot;既然是表达或的意思，那么是否可以这么写-F&quot;[ ]|.&quot;？？？答案：不可以！原因：因为此处用的是正则表达式，在正则表达式中点(.)代表任意单个字符，会把空格后的字母当成分隔符！所以是不可以的，那么如何写？如果不是点而是%呢？%是可以的，因为在正则表达式中%就是代表%，但是$,或其他在正则表达式中有特殊含义的不可以作为分隔符，如果一定要做分隔符，需要反斜线转义如下：此处用3个反斜线转义[root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\.&quot; &apos;{print $2}&apos;testmusicsportsnews那如果文本中的第一个点是$呢？此处是4个反斜线进行转义[root@centos7 ~]cat f21 test$sina.com.cn2 music$sina.com.cn3 sports$sina.com.cn4 news$sina.com.cn[root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\\$&quot; &apos;{print $2}&apos;testmusicsportsnews[root@centos7 ~]cat f2 | awk -F&quot;[ $]&quot; &apos;{print $2}&apos;testmusicsportsnews当用一个空格和具有特殊含义的符号时，最好是写在中括号[]里的</code></pre><h3 id="AWK中自定义变量"><a href="#AWK中自定义变量" class="headerlink" title="AWK中自定义变量"></a>AWK中自定义变量</h3><pre><code>自定义变量(区分字符大小写)(1) -v var=value(2) 在program中直接定义(2-1)program可以放到一个文本里,awk -f 直接调用即可</code></pre><h5 id="示例：-1"><a href="#示例：-1" class="headerlink" title="示例："></a>示例：</h5><pre><code>自定义变量可以-v var定义，也可以放到program即{}里，变量要先定义，后使用awk -F:  &apos;{name=&quot;magedu&quot;;print $1,name}&apos; /etc/passwdawk -F: -v name=&quot;magedu&quot; &apos;{print $1,name}&apos; /etc/passwd例如cat awk.txt{print $1,$2,$6}awk -F： -f awk.txt /etc/passwd =awk -F: &apos;{print $1,$2,$6}&apos; /etc/passwd</code></pre><hr><hr><h3 id="Awk中的格式化"><a href="#Awk中的格式化" class="headerlink" title="Awk中的格式化"></a>Awk中的格式化</h3><p>在介绍printf前，先对其进行总结：<br>1.使用printf动作输出的文本不会换行，如果需要换行，可以在对应的格式替换符后加入”\n”进行转义<br>2.使用printf动作时，指定的格式和被格式化的文本之间，需要用”逗号”隔开。<br>3.使用printf动作时，格式中的格式替换符比喻与被格式化的文本一一对应</p><h4 id="printf命令-类似于shell里的printf"><a href="#printf命令-类似于shell里的printf" class="headerlink" title="printf命令-类似于shell里的printf"></a>printf命令-类似于shell里的printf</h4><pre><code>printf命令可以把内容以灵活的格式进行显示，如左对齐,右对齐格式化输出：printf &quot;FORMAT&quot;, item1, item2, ...(1) 必须指定FORMAT(2) 不会自动换行，需要显式给出换行控制符，\n(3) FORMAT中需要分别为后面每个item指定格式符格式符：与item一一对应%c：显示字符的ASCII码%d, %i：显示十进制整数   -用的比较多%e, %E：显示科学计数法数值%f：显示为浮点数%g, %G：以科学计数法或浮点形式显示数值%s：显示字符串  -用的比较多%u：无符号整数 -用的比较多%%：显示%自身修饰符#[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f+ 左对齐（默认右对齐） %-15s* 显示数值的正负符号 %+d</code></pre><h4 id="printf示例："><a href="#printf示例：" class="headerlink" title="printf示例："></a>printf示例：</h4><pre><code>1.设置对齐格式以及字符数[root@centos7 ~]awk -F: &apos;{printf &quot;%-20s %-5d\n&quot;,$1,$3}&apos; /etc/passwdroot                 0    bin                  1       pulse                171  gdm                  42   gnome-initial-setup  990  $1为字符串，所以设置左对齐为20s个字符，$3为数字所以设置左对齐为5d个字符printf默认不换行，所以需要加一个换行符  2.打印一个完整的报表格式root@centos7 ~]awk -F: &apos;BEGIN{print &quot;username   |uid\n--------&quot;}{printf &quot;%-10s |%-5d\n&quot;,$1,$3}END{print &quot;-------------&quot;}&apos; /etc/passwdusername             |uid-----------------------root                 |0    bin                  |1    daemon               |2 memcached            |987  ceshi                |1009 quagga               |92   httpd                |80   -------------------------awk生成报表格式大概就是这个样子，所以awk称为报表生成器3.[root@centos7 ~]awk -F: &apos;{printf &quot;Username: %s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwdUsername: root,UID:0Username: bin,UID:1Username: daemon,UID:2Username: adm,UID:34.[root@centos7 ~]awk -F: &apos;{printf &quot;Username: %-15s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwdUsername: root           ,UID:0Username: bin            ,UID:1Username: daemon         ,UID:2</code></pre><hr><hr><h3 id="awk操作符"><a href="#awk操作符" class="headerlink" title="awk操作符"></a>awk操作符</h3><pre><code>a.算术操作符：x+y, x-y, x*y, x/y, x^y, x%y- x：转换为负数+x：将字符串转换为数值字符串操作符：没有符号的操作符，字符串连接赋值操作符：=, +=, -=, *=, /=, %=, ^=，++, --,b.比较操作符：==, !=, &gt;, &gt;=, &lt;, &lt;=模式匹配符： ~：左边是否和右边匹配包含 !~：是否不匹配c.逻辑操作符：与&amp;&amp;，或||，非!d.条件表达式（三目表达式） selector?if-true-expression:if-false-expression 表达式；if-ture-xx:else-xxx eg:x&gt;y?var=x;var=y</code></pre><h3 id="操作符用法示例："><a href="#操作符用法示例：" class="headerlink" title="操作符用法示例："></a>操作符用法示例：</h3><pre><code>1.下面两语句有何不同• awk &apos;BEGIN{i=0;print ++i,i}&apos; 结果 1 1• awk &apos;BEGIN{i=0;print i++,i}&apos; 结果 0 1实际上AWK的语法是采用VC语言风格的2.示例：awk中~&amp;!~是否包含的用法：[root@centos7 ~]awk -F: &apos;$0 ~ /root/{print $1}&apos; /etc/passwdrootoperator意思是如果过滤的行中有包含root字符串的，则打印出这行的用户名用到下文提到的patter模式，在这里是匹配是否包含root字符串[root@centos7 ~]awk -F: &apos;$0 ~ &quot;/root&quot;{print $1}&apos; /etc/passwdrootoperator区别上面的这个写法，在这里是包含/root字符串的行[root@centos7 ~]awk -F: &apos;$0 !~ /root/{print $1}&apos; /etc/passwdbindaemonadm和上面的命令刚好相反，如果行不包含字符串root，则打印该行用户名[root@centos7 ~]awk -F: &apos;$3==0&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash意思：判断UID是否等于0，是则打印该行，判断是否为管理员[root@centos7 ~]awk &apos;$0~&quot;^root&quot;&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash意思：判断该行是不是以root开头的行，是则打印3.awk中的与&amp;&amp;，或|| 非!的使用示例：示例：• awk –F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000 {print $1}&apos; /etc/passwd如果0&lt;=UID&lt;=1000，则打印出该用户• awk -F: &apos;$3==0 || $3&gt;=1000 {print $1,$3}&apos; /etc/passwd打印出UID等于0和UID&gt;=1000的用户名和他的UID• awk -F: &apos;!($3==0) {print $1}&apos; /etc/passwd -要加括号打印出UID不等于0的用户名• awk -F: &apos;!($3&gt;=500) {print $3}&apos; /etc/passwd如果UID&lt;=500,时，打印出该用户的UID4.AWK中的条件判断表达式即三目表达式相当于把shell中的if;then,else,fi的放到awk中• 示例：[root@centos7 ~]awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwdsys root 0sys bin 1sys tcpdump 72common test 1000common nginx 1008判断用户是否为系统用户，是则打印并在开头加common,不是也打印在开头加sys</code></pre><hr><hr><h3 id="awk中的PATTERN和action"><a href="#awk中的PATTERN和action" class="headerlink" title="awk中的PATTERN和action"></a>awk中的PATTERN和action</h3><p>模式匹配和处理动作=sed的地址定界+修饰符<br>功能：和sed中的pattern一样起到过滤的功能，=sed的地址定界</p><h5 id="PATTERN-根据pattern条件，过滤匹配的行，再做处理"><a href="#PATTERN-根据pattern条件，过滤匹配的行，再做处理" class="headerlink" title="PATTERN:根据pattern条件，过滤匹配的行，再做处理"></a>PATTERN:根据pattern条件，过滤匹配的行，再做处理</h5><pre><code>(1)如果未指定：空模式，匹配每一行(2) /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来awk &apos;/^UUID/{print $1}&apos; /etc/fstabawk &apos;!/^UUID/{print $1}&apos; /etc/fstabawk的匹配模式支持的是扩展的正则表达式注意：不支持直接给出数字格式，但是可以变向的打印输出，详见下面的示例(3) relational expression: 关系表达式，结果为“真”才会被处理真：结果为非0值，非空字符串假：结果为空字符串或0值都是假字符串为空或者0为假(4) line ranges：行范围startline,endline：/pat1/,/pat2/ 不支持直接给出数字格式awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/{print $1}&apos; /etc/passwdawk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20){print NR,$1}&apos; /etc/passwdNR表示行(5) BEGIN/END模式BEGIN{}: 仅在开始处理文件中的文本之前执行一次END{}：仅在文本处理完成之后执行一次</code></pre><p>模式：指定一个行的范围。该语法不能包括BEGIN和END模式。<br>BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。<br>END：让用户在最后一条输入记录被读取之后发生的动作。</p><h5 id="patter用法示例："><a href="#patter用法示例：" class="headerlink" title="patter用法示例："></a>patter用法示例：</h5><pre><code>先写一个特殊的用法1.当在awk命令中使用正则模式时，使用到的正则用法属于&quot;扩展的正则表达式&quot;2.当使用{x,y}这种次数匹配正则表达式，需要配合--posix或者--re-interval选项备注：这是网上找到一个示例，文中提到{x,y}必须加这个选项，然而不加选项也是可以过滤的awk是是支持posix字符集的[root@centos7 ~]cat f3 seexsexseeexseeeeex[root@centos7 ~]cat f3 | awk &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3 | awk -posix &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3 | awk --re-interval  &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3|grep  -E &quot;se{2,3}x&quot;seexseeex[root@centos7 ~]cat f3|sed -nr &apos;/se{2,3}x/p&apos;seexseeex1.取系统磁盘分区空间利用率df,/dev/sd开头的分区(上文中虽然取出来了，但是没过滤)[root@centos7 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &apos;/^\/dev\/sd/{print $1,$5}&apos;/dev/sda2 8/dev/sda3 1/dev/sda1 172.取当前连接主机的IP地址(上文中虽然取出来了，但是没过滤)[root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $6}&apos;192.168.34.1192.168.34.105或者用NF的表达方式[root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;192.168.34.1192.168.34.1053.取登录当前系统失败（lastb）用户的IP[root@centos7 ~]#lastbroot     ssh:notty    192.168.34.105   Sun Nov 11 17:25 - 17:25  (00:00)    root23   ssh:notty    192.168.34.1     Mon Nov  5 15:43 - 15:43  (00:00)    btmp begins Fri Nov  2 09:58:52 2018[root@centos7 ~]#lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c3 192.168.34.11 192.168.34.101因为最后一行有btmp这样的字样，只能通过包含的功能来过滤掉最后一行如果要取失败连接次数大于3的扔到防火墙，可以先取出来root@centos7 ~]lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c| awk &apos;$1 &gt;=3{print $2}&apos;192.168.34.14.patter中为关系表达式的示例空字符串或0值都是假，其他为真awk &apos;0{print $0}&apos; /etc/passwd -0为假，结果为空awk &apos;&quot;&quot;{print $0}&apos; /etc/passwd -空也为假，结果为空awk &apos;1{print $0}&apos; /etc/passwd -1为真awk &apos;&quot; &quot;{print $0}&apos; /etc/passwd -空白符也为真awk -v abc=&quot; &quot; &apos;abc{print $0}&apos; /etc/passwd -abc为空白,不是空字符串,也为真awk -v abc=&quot; &quot; &apos;! abc{print $0}&apos; /etc/passwd -abc为空白,为真,对真取反，结果为假5.awk中patter的地址定界root@centos7 ~]#awk -F: &apos;/^root/,/^adm/{print $0}&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologin打印以root开头的行到以adm开头的行之间的所有行等于 sed -nr &apos;/^root/,/^adm/p&apos; /etc/passwd6.如何打印从多少行到多少行之间的行？？[root@centos7 ~]#awk -F: &apos;NR&gt;=10 &amp;&amp; NR&lt;=12 {print NR,$0}&apos; /etc/passwd10 operator:x:11:0:operator:/root:/sbin/nologin11 games:x:12:100:games:/usr/games:/sbin/nologin12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin通过变量NR变向的打印出行7.取出/etc/fstab配置文件中以UUID开头的行[root@centos7 ~]#cat /etc/fstab | awk &apos;/^UUID/{print $0}&apos;UUID=9612633f-e7f1-4b28-8813-403d209d7abc /    xfs  defaults 0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot   xfs defaults  0 0效果等于  grep &quot;^UUID&quot; /etc/fstab效果等于  sed -n &apos;/^UUID/p&apos; /etc/fstab8.awk &apos;!0&apos; /etc/passwd =awk &apos;!0{print $0}&apos; /etc/passwd 省略了{print $0}的写法结果为真，即打印全部行root@centos7 ~]#awk -F: &apos;i=1;j=1{print i,j}&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash1 1bin:x:1:1:bin:/bin:/sbin/nologin1 1？？？[root@centos7 ~]#awk -F: &apos;$NF ~ /bash$/{print $1,$NF}&apos; /etc/passwdroot /bin/bashtest /bin/bash判断用户shell是否为/bin/bash，是则打印用户名和shell类型，此处用变量NF来实现效果等于 awk -F: &apos;$NF==&quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd效果等于 awk -F: &apos;$7 == &quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd效果等于 awk -F: &apos;$0 ~ /bash$/{print $1,$NF}&apos; /etc/passwd9.打印奇数行和偶数行[root@centos7 ~]#seq 6 | awk &apos;i=!i&apos;  打印奇数行135原理：i初始值为空，为假，取反时，则打印第一行，此时i=1i=1时，为真，取反为假，所以第二行不打印，然后i=0依次类推所以只打印奇数行[root@centos7 ~]#seq 6 | awk &apos;!(i=!i)&apos; 打印偶数行246效果等于 seq 10 |awk -v i=1 &apos;i=!i&apos;原理：同上，只要先定义i=1，为真，第一行就不打印了或者用sed打印奇数行和偶数行(用sed步进的方式) seq 6 | sed -n &apos;1~2p&apos; 打印奇数行 seq 6 | sed -n &apos;2~2p&apos; 打印偶数行</code></pre><hr><hr><h3 id="awk-action"><a href="#awk-action" class="headerlink" title="awk action"></a>awk action</h3><h4 id="action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能"><a href="#action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能" class="headerlink" title="action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能"></a>action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能</h4><pre><code>• (1) Expressions:算术，比较表达式等• (2) Control statements：if, while等• (3) Compound statements：组合语句• (4) input statements• (5) output statements：print等</code></pre><h4 id="下面专门研究awk的控制语句包含if-while-do-for-break-continue-数组，exit等控制语句"><a href="#下面专门研究awk的控制语句包含if-while-do-for-break-continue-数组，exit等控制语句" class="headerlink" title="下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句"></a>下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句</h4><h5 id="awk中if-else控制语句的语法及用法"><a href="#awk中if-else控制语句的语法及用法" class="headerlink" title="awk中if-else控制语句的语法及用法"></a>awk中if-else控制语句的语法及用法</h5><pre><code>语法：双分支ifif(condition){statement;…}(多条语句用;隔开)[else statement]多分支ifif(condition1){statement1}else if(condition2){statement2}else{statement3}使用场景：对awk取得的整行或某个字段做条件判断</code></pre><h6 id="if-else示例："><a href="#if-else示例：" class="headerlink" title="if-else示例："></a>if-else示例：</h6><pre><code>如判断考试分数，写法如下[root@centos7 ~]awk -v score==80 &apos;BEGIN{if(score &lt;60){print &quot;no pass&quot;}else if(score &lt;=80){print &quot;soso&quot;}else {print good}}&apos;sosoawk -F: &apos;{if($3&gt;=1000)print $1,$3}&apos; /etc/passwd判断UID是否大于1000，是则打印用户名和UIDawk -F: &apos;{if($NF==&quot;/bin/bash&quot;) print $1}&apos; /etc/passwd判断用户shell是否为/bin/bash,是则打印用户名awk &apos;{if(NF&gt;5) print $0}&apos; /etc/fstab判断域或列个数是否大于5，是则打印该行awk -F: &apos;{if($3&gt;=1000) {printf &quot;Common user: %s\n&quot;,$1} else {printf &quot;root orSysuser: %s\n&quot;,$1}}&apos; /etc/passwd等于上文中的 awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd例如：随机生成1000个数字，用awk取出最大值和最小值(可以用shell写法)    1.生成1000个数字        for i in {1..1000};do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot;             &gt;&gt; f1.txt;else echo -e &quot;,$RANDOM\c&quot; &gt;&gt; f1.txt ;fi;done    2.用awk取出最大值和最小值        awk -F&apos;,&apos; &apos;{i=2;max=$1,while(i&lt;=NF){if($i &gt; max){max=$i}else         if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; f1.txt验证用awk是否取出的值为正确的：    方法一：用tr验证        tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | head -n1        tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | tail -n1    方法二：用shell脚本验证    #!/bin/bash    for i in {1..1000};do</code></pre><h4 id="awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，"><a href="#awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，" class="headerlink" title="awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，"></a>awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，</h4><h4 id="这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理"><a href="#这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理" class="headerlink" title="这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理"></a>这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理</h4><h4 id="awk中while循环控制语句的语法及用法"><a href="#awk中while循环控制语句的语法及用法" class="headerlink" title="awk中while循环控制语句的语法及用法"></a>awk中while循环控制语句的语法及用法</h4><pre><code>语法：while(condition){statement;…}条件“真”，进入循环；条件“假”，退出循环使用场景：对一行内的多个字段逐一类似处理时使用对数组中的各元素逐一处理时使用此时涉及到系统自带的一个函数length(函数在下面会有介绍)示例：1.统计每一行第一个字段的长度root@centos7 ~]awk -F: &apos;{print length($1),$1}&apos; /etc/passwd4 root3 bin6 daemon3 adm2.统计/etc/passwd第一行的每个字段的长度[root@centos7 ~]awk -F: &apos;NR==1{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/passwdroot 4x 10 10 1root 4/root 5/bin/bash 93.统计grub2.cfg文件中linux16那行的每个字段的长度[root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/grub2.cfglinux16 7/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46ro 2crashkernel=auto 16rhgb 4quiet 5LANG=en_US.UTF-8 16linux16 7/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46ro 2crashkernel=auto 16rhgb 4quiet 54.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用while循环root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){if(length($i)&gt;=10){print $i,length($i)};i++}}&apos; /etc/grub2.cfg/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16LANG=en_US.UTF-8 16/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 165.面试题用awk取出文本f5的最大值和最小值，需要先生成1000个随机数存到f5中如何做？1.不用awk，可以通过脚本实现最大值和最小值2.用awk如何来做？？先生成1000个随机数[root@centos7 ~]for i in `seq 1000`;do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f5;else echo -e &quot;,$aRANDOM\c&quot; &gt;&gt; f5 ;fi;done生成了1000随机数，如何取最大值最小值？[root@centos7 ~]awk -F&quot;,&quot; &apos;{i=2;max=$1;min=$1;while(i&lt;=NF){if($i &gt; max){max=$i}else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; &lt; f5max=32643 min=60</code></pre><h3 id="awk中do-while循环控制语句"><a href="#awk中do-while循环控制语句" class="headerlink" title="awk中do-while循环控制语句"></a>awk中do-while循环控制语句</h3><pre><code>语法：do {statement;…}while(condition)意义：无论真假，至少执行一次循环体</code></pre><h5 id="do-while使用示例："><a href="#do-while使用示例：" class="headerlink" title="do-while使用示例："></a>do-while使用示例：</h5><pre><code>求1-100正整数的和[root@centos7 ~]awk &apos;BEGIN{ total=0;i=0;do{ total+=i;i++;}while(i&lt;=100);print total}&apos;5050</code></pre><h3 id="awk中for循环控制语句"><a href="#awk中for循环控制语句" class="headerlink" title="awk中for循环控制语句"></a>awk中for循环控制语句</h3><pre><code>语法：for(expr1;expr2;expr3) {statement;…}常见用法：for(variable assignment;condition;iteration process){for-body}特殊用法：能够遍历数组中的元素语法：for(var in array) {for-body}</code></pre><h6 id="for循环使用示例："><a href="#for循环使用示例：" class="headerlink" title="for循环使用示例："></a>for循环使用示例：</h6><pre><code>1.求1-100正整数的和：[root@centos7 ~]awk &apos;BEGIN{for(i=1;i&lt;=100;i++)sum+=i;print sum}&apos;50502.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用for循环[root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{for(i=1;i&lt;=NF;i++){if(length($i)&gt;=10){print $i,length($i)}}}&apos; /etc/grub2.cfg/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16LANG=en_US.UTF-8 16/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16</code></pre><h3 id="awk中的switch控制语句"><a href="#awk中的switch控制语句" class="headerlink" title="awk中的switch控制语句"></a>awk中的switch控制语句</h3><pre><code>类似于shell中的case语句语法：switch(expression) {case VALUE1 or /REGEXP/: statement1; caseVALUE2 or /REGEXP2/: statement2; ...; default: statementn}</code></pre><h3 id="awk中的continue-break，next控制语句"><a href="#awk中的continue-break，next控制语句" class="headerlink" title="awk中的continue,break，next控制语句"></a>awk中的continue,break，next控制语句</h3><p>break和continue<br>next:<br>提前结束对本行处理而直接进入下一行处理（awk自身循环）</p><h5 id="continue的示例"><a href="#continue的示例" class="headerlink" title="continue的示例"></a>continue的示例</h5><pre><code>求1000以内偶数的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==0)continue;sum+=i}print sum}&apos;2500求1000以内奇数的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==1)continue;sum+=i}print sum}&apos;2550求1000以内除了66的所有数字的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i==66)continue;sum+=i}print sum}&apos;4984</code></pre><h5 id="break的示例："><a href="#break的示例：" class="headerlink" title="break的示例："></a>break的示例：</h5><pre><code>求1000数字中，当大于100时，跳出循环，即求100以内的和[root@centos7 ~]#awk &apos;BEGIN{sum=0;for(i=1;i&lt;=1000;i++){if(i&gt;100)break;sum+=i}print sum}&apos;5050</code></pre><h5 id="next的示例："><a href="#next的示例：" class="headerlink" title="next的示例："></a>next的示例：</h5><pre><code>因为提前结束对本行处理而直接进入下一行处理（因为awk本身就是循环行的功能），所以示例打印/etc/passwd下的奇数行[root@centos7 ~]awk -F: &apos;{if(NR%2==0)next;print NR,$0}&apos; /etc/passwd1 root:x:0:0:root:/root:/bin/bash3 daemon:x:2:2:daemon:/sbin:/sbin/nologin5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin11 games:x:12:100:games:/usr/games:/sbin/nologin13 nobody:x:99:99:Nobody:/:/sbin/nologin还可以这样写：awk -F: &apos;NR%2==1{print NR,$0}&apos; /etc/passwd</code></pre><hr><hr><h3 id="awk数组-一个非常使用的功能"><a href="#awk数组-一个非常使用的功能" class="headerlink" title="awk数组-一个非常使用的功能"></a>awk数组-一个非常使用的功能</h3><h6 id="awk的数组全都是关联数组"><a href="#awk的数组全都是关联数组" class="headerlink" title="awk的数组全都是关联数组"></a>awk的数组全都是关联数组</h6><pre><code>关联数组：array[index-expression]index-expression:• (1) 可使用任意字符串；字符串要使用双引号括起来• (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”• (3) 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历</code></pre><h4 id="数组的去重的效果示例："><a href="#数组的去重的效果示例：" class="headerlink" title="数组的去重的效果示例："></a>数组的去重的效果示例：</h4><pre><code>awk &apos;!arr[$0]++&apos; dupfileawk &apos;{!arr[$0]++;print $0, arr[$0]}&apos; dupfileecho abc abc ccc bcd ddd ddd abc abc &gt;&gt; f1.txt</code></pre><h4 id="awk关联数组的遍历："><a href="#awk关联数组的遍历：" class="headerlink" title="awk关联数组的遍历："></a>awk关联数组的遍历：</h4><pre><code>若要遍历数组中的每个元素，要使用for循环:因为关联数组下标是无序性for(var in array) {for-body}注意：var会遍历array的每个索引</code></pre><h4 id="数组的使用示例："><a href="#数组的使用示例：" class="headerlink" title="数组的使用示例："></a>数组的使用示例：</h4><pre><code>示例1.定义awk数组[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]}&apos;zhang可以用for循环把每一个数组的值都表示出来[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;];for(i in title){print i,title[i]}}&apos;zhangcoo liuceo zhangcto wang但输出时数组元素时，是无序的，这就是关联数组的特性示例2.awk数组中的重要功能    [root@centos7 ~]cat f6    abc    abc    ddd    ccc    aaa    ccc    ccc    [root@centos7 ~]awk &apos;!line[$0]++&apos; f6    abc    ddd    ccc    aaa问题：为什么执行结果是这个？？原因：awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6实际上是隐藏了{print $0}，这个隐藏功能在awk很重要！！！，但是要和后面patter中的空模式区别开&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印而后面的数组里的是加了双括号{}，{line[$0]++}即用的patter的空模式，即文本中的每一行都处理这两个写法是不一样的，别混淆了分析：基于这个考虑进行分析 &apos;!line[$0]++&apos; = &apos;!line[$0]++{print $0}&apos;当读取文本f6的第一行时=abc!line[&quot;abc&quot;]++，因为abc没有值，line[&quot;abc&quot;]=0为假，取反！line[&quot;abc&quot;]后为真所以把第一行的abc打印了一次，打印第一行结束后line[&quot;abc&quot;]=1当读取文本f6的第二行时=abc!line[&quot;abc&quot;]++，在之前基础上line[&quot;abc&quot;]=1为假，取反！line[&quot;abc&quot;]=0后为假所以把第二行的abc不打印，结束后line[&quot;abc&quot;]=2以此类推，发现后续出现abc都不会打印，但是line[&quot;abc&quot;]都会在之前的基础上+1，即达到去重并统计的目的而处理第三行!line[&quot;ddd&quot;]++时，和上述abc一样，第一次出现则打印，后续也不会打印所以，命令执行结果为去重的效果从这个命令执行结果也可以明显看到上述的分析结果可以看出abc的值是递增的，也就是abc出现的次数[root@centos7 ~]awk &apos;{!line[$0]++;print $0, line[$0]}&apos; f6abc 1abc 2ddd 1ccc 1aaa 1ccc 2</code></pre><hr><h3 id="awk数组中的重要功能之for循环遍历数组，很具有实用性"><a href="#awk数组中的重要功能之for循环遍历数组，很具有实用性" class="headerlink" title="awk数组中的重要功能之for循环遍历数组，很具有实用性"></a>awk数组中的重要功能之for循环遍历数组，很具有实用性</h3><h6 id="在后面的统计服务的一些日志文件很有作用"><a href="#在后面的统计服务的一些日志文件很有作用" class="headerlink" title="在后面的统计服务的一些日志文件很有作用"></a>在后面的统计服务的一些日志文件很有作用</h6><pre><code>如果要理解遍历awk数组，需要深刻理解上述的示例2:awk &apos;!line[$0]++&apos; f6是怎么实现的但还是有些和数组里的，遍历$2,把$2不同的值，当成数组的下标有些区别的</code></pre><h3 id="若要遍历数组中的每个元素，要使用for循环"><a href="#若要遍历数组中的每个元素，要使用for循环" class="headerlink" title="若要遍历数组中的每个元素，要使用for循环"></a>若要遍历数组中的每个元素，要使用for循环</h3><pre><code>for(var in array) {for-body}注意：var会遍历array的每个索引</code></pre><h6 id="为什么要通过特殊写法去遍历awk中的数组？"><a href="#为什么要通过特殊写法去遍历awk中的数组？" class="headerlink" title="为什么要通过特殊写法去遍历awk中的数组？"></a>为什么要通过特殊写法去遍历awk中的数组？</h6><pre><code>如果是普通数组，用循环0,1,2,3做个循环即可；而awk的数组都是关联数组，[]中括号里的下标都不固定所以要通过 for(var in array(数组名称)) {for-body}这样的特殊写法，var的值会从array数组元素取其下标，相当于每次循环var的值是等于array数组的下标的注意：当我们直接引用一个数组中不存在的元素时，awk会自动创建这个元素，并且为其赋值为&quot;空字符串&quot;</code></pre><h4 id="for循环遍历数组使用示例："><a href="#for循环遍历数组使用示例：" class="headerlink" title="for循环遍历数组使用示例："></a>for循环遍历数组使用示例：</h4><pre><code>示例1：[root@centos7 ~]awk &apos;BEGIN{print test[&quot;ip&quot;];test[&quot;ip&quot;]++;print test[&quot;ip&quot;]}&apos;1第一次输出为空，第二次自动加1示例2：1.[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;for(i in title){print title[i]}}&apos;liuzhangwang分析：for(i in title){print title[i]，i的值来自于title的下标，即i=ceo coo cto,而且是无序打印示例3：[root@centos7 ~]netstat -tanActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN     tcp        0      0 192.168.122.1:53        0.0.0.0:*               ESTABLISTEN     tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN     tcp        0     52 192.168.34.103:22       192.168.34.1:8816       ESTABLISHEDtcp        0      0 192.168.34.103:22       192.168.34.105:49746    ESTABLISHEDtcp6       0      0 :::111                  :::*                    LISTEN     tcp6       0      0 :::22                   :::*                    LISTEN     tcp6       0      0 ::1:631                 :::*                    LISTEN     tcp6       0      0 ::1:25                  :::*                    LISTEN     [root@centos7 ~]netstat -tan | awk &apos;/^tcp/{state[$NF]++}END{for(i in state) { print i,state[i]}}&apos;LISTEN 8ESTABLISHED 3分析：state[$NF]++以空白做分隔符，统计同一类型的状态有多少个for(i in state) { print i,state[i]} 即统计了出现状态的多少种以及出现的次数不明白的可以看上文中的示例2：awk数组中的重要功能当然，看懂这个命令，需要知道两个知识点1.空模式，即全文反复提到的{state[$NF]++}={state[$NF]++}{print $0}2.END模式，END的模式是在前面动作结束之后，最后执行依次END模式中的命令，所以先不用考虑空模式下面再一次对空模式中的处理过程，做详细的描述空模式中，我们创建了一个state数组，并将状态值(LISTEN、ESTABLISHED)作为引用下标，所以执行到第一行时，我们引用的是state[&quot;LISTEN&quot;],很明显，这个元素并不存在，所以，当第一行被空模式的动作处理完毕后state[&quot;LISTEN&quot;]的值已经被赋值为1了。这时，空模式中的动作继续处理下一行，而下一行的$NF=ESTABLISTEN；state[&quot;ESTABLISTEN&quot;]所以，state[&quot;ESTABLISTEN&quot;]第一次参与运算过程与上一个原理相同直到再次遇到相同的状态时，使用同样一个IP地址作为下标的元素将会再次被自加直到处理完所有的行，开始执行END模式中的动作。而END模式中，我们打印出state数组中的所有元素的下标，以及元素对应的值。此刻，state数组中的下标即为各种状态，元素的值即为对应状态出现的次数，最终，我们统计出每个状态出现的次数。3.统计/var/log/httpd/access_log，每个IP链接的次数root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; &quot;Mozil&quot;192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;192.168.34.103 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;[root@centos7 ~]awk &apos;{ip[$1]++}END{for(i in ip){print i,ip[i]}}&apos; /var/log/httpd/access_log192.168.34.101 9192.168.34.103 13::1 4192.168.34.1 88效果等于：[root@centos7 ~]awk &apos;{print $1}&apos; /var/log/httpd/access_log |sort|uniq -c4 ::188 192.168.34.19 192.168.34.10113 192.168.34.1034.统计ss -nt ip链接次数[root@centos7 ~]ss -ntState      Recv-Q Send-Q                 Local Address:Port                                Peer Address:Port              ESTAB      0      52                    192.168.34.103:22                                  192.168.34.1:8816               ESTAB      0      0                     192.168.34.103:22                                192.168.34.105:49746              [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{ip[$(NF-2)]++}END{for(i in ip){print i,ip[i]}}&apos;192.168.34.105 1192.168.34.1 1效果等于：[root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;|sort|uniq -c1 192.168.34.11 192.168.34.1055.统计/etc/fstab文件系统类型分别有多少个[root@centos7 ~]cat /etc/fstab # /etc/fstab# Created by anaconda on Wed Sep 19 11:44:48 2018UUID=9612633f-e7f1-4b28-8813-403d209d7abc /                       xfs     defaults        0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot                   xfs     defaults        0 0UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data                   xfs     defaults        0 0UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap                    swap    defaults        0 0[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos;swap 1xfs 36.求下表中的男生和女生的平均成绩[root@centos7 ~]cat f9name sex scorea     m   90b     f   80c     f   99d     m   88e     m   80如何利用awk的数组功能来求？思路先求男的和和女的和？利用两个数组？[root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3}END{for(i in sum){print i,sum[i]}}&apos; -求男女分的和m 258f 179[root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3;num[$2]++}END{for(i in sum){print i,sum[i]/num[i]}}&apos;m 86f 89.57.统计下面每个名字出现的次数[root@centos7 ~]cat f1Allen PhillipsGreen LeeWilliam Aiden Janmes LeeAngel JackJack ThomasLucas KevinTyler LeeWilliam Allen[root@centos7 ~]cat f1 | awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,cuont[j]}}&apos;Tyler Angel Lucas William Thomas Green Jack Phillips Kevin </code></pre><hr><hr><h3 id="awk函数"><a href="#awk函数" class="headerlink" title="awk函数"></a>awk函数</h3><h6 id="awk也包括内置函数和自定义函数"><a href="#awk也包括内置函数和自定义函数" class="headerlink" title="awk也包括内置函数和自定义函数"></a>awk也包括内置函数和自定义函数</h6><h6 id="内置函数包括-rand-length，sub-gsub-split，system"><a href="#内置函数包括-rand-length，sub-gsub-split，system" class="headerlink" title="内置函数包括 rand,length，sub,gsub,split，system"></a>内置函数包括 rand,length，sub,gsub,split，system</h6><pre><code>数值处理：rand(i)：返回0和1之间一个随机数awk &apos;BEGIN{srand(); for (i=1;i&lt;=10;i++)print int(rand()*100) }&apos;字符串处理：• length([s])：返回指定字符串的长度• sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为secho &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,“-&quot;,$1)&apos;• gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表示的内容echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos;• split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所表示的数组中，第一个索引值为1,第二个索引值为2,…netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}&apos;END{for (i in count) {print i,count[i]}</code></pre><h4 id="awk内置函数之sub、gsub、split实现搜索替换切割的用法"><a href="#awk内置函数之sub、gsub、split实现搜索替换切割的用法" class="headerlink" title="awk内置函数之sub、gsub、split实现搜索替换切割的用法"></a>awk内置函数之sub、gsub、split实现搜索替换切割的用法</h4><pre><code>示例1：sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为sgsub(r,s,[t])表示全局替换sub(r,s,[t])不是贪婪模式，默认值替换搜索出来的第一个[root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,&quot;-&quot;,$1)&apos;2008-08:08 08:08:08只替换$1root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$1)&apos;2008-08-08 08:08:08全局替换$0[root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos;2008-08-08 08-08-08示例2：统计字符串中每个字母出现的次数abcdaabbccdd[root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 3b 3c 3d 3在文章最后会用另外一种写法进行过滤(文章最后会以以空位分隔符的特殊写法来表示)</code></pre><h5 id="awk内置函数split的切割功能"><a href="#awk内置函数split的切割功能" class="headerlink" title="awk内置函数split的切割功能"></a>awk内置函数split的切割功能</h5><pre><code>示例1:    统计链接本机的IP和端口号    [root@centos7 ~]#netstat -tn    Active Internet connections (w/o servers)    Proto Recv-Q Send-Q Local Address           Foreign Address         State          tcp        0     52 192.168.34.103:22       192.168.34.1:8816       ESTABLISHED    tcp        0      0 192.168.34.103:22       192.168.34.105:49746    ESTABLISHED    [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}END{for (i in count) {print i,count[i]}}&apos;    192.168.34.105 1    192.168.34.1 1    [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[2]]++}END{for (i in count) {print i,count[i]}}&apos;    8816 1    49746 1    分析：    split($5,ip,&quot;:&quot;)将192.168.34.1:8816进行切割，数组ip的下标1放IP地址，下标2放端口号    count[ip[1]]++ 把ip下标为1也就是IP地址，把出现的IP个数，又给count当下标，就统计每个IP出现的次数    count[ip[2]]++ 把ip下标为2也就是端口号，把出现的端口号个数，又给count当下标，就统计每个端口号出现的次数</code></pre><h3 id="awk中的自定义函数格式："><a href="#awk中的自定义函数格式：" class="headerlink" title="awk中的自定义函数格式："></a>awk中的自定义函数格式：</h3><pre><code>awk自定义函数是用正规开发语言的函数格式function name ( parameter, parameter, ... ) { statements return expression}</code></pre><h5 id="awk自定义函数的用法："><a href="#awk自定义函数的用法：" class="headerlink" title="awk自定义函数的用法："></a>awk自定义函数的用法：</h5><pre><code>cat fun.awk,把函数写到文件中function max(x,y) {x&gt;y?var=x:var=yreturn var}BEGIN{print max(i,j)}awk -v i=10 -v j=20 -f fun.awk 调用函数即可，和shell中的函数类似</code></pre><h4 id="awk中很实用的内置函数system命令"><a href="#awk中很实用的内置函数system命令" class="headerlink" title="awk中很实用的内置函数system命令"></a>awk中很实用的内置函数system命令</h4><h6 id="system函数作用：在awk可以反过来调用linux里的命令"><a href="#system函数作用：在awk可以反过来调用linux里的命令" class="headerlink" title="system函数作用：在awk可以反过来调用linux里的命令"></a>system函数作用：在awk可以反过来调用linux里的命令</h6><pre><code>示例：    空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用    空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来示例1:显示/boot/grub2下的文件列表；调用命令时要加双引号[root@centos7 ~]#awk &apos;BEGIN{system(&quot;ls /boot/grub2&quot;)}&apos;device.map  fonts  grub.cfg  grubenv  i386-pc  locale或者这么写，先定义变量等于路径，再调用变量[root@centos7 ~]#awk &apos;BEGIN{dir=&quot;/boot/grub2&quot;;system(&quot;ls &quot;dir)}&apos;device.map  fonts  grub.cfg  grubenv  i386-pc  locale调用hostname命令，显示主机名[root@centos7 ~]#awk &apos;BEGIN{system(&quot;hostname&quot;)}&apos;centos7.localdomain示例2：之前处理过lastb中登录失败的IP，如果失败登录次数大于3次，扔到防火墙里，当时是先取出IP放到文件里，然后iptables再禁用；现在可以在awk中先取出IP,然后通过system(&quot;iptables &quot; IP)就可以直接扔到防火墙中具体实现？</code></pre><h3 id="awk脚本"><a href="#awk脚本" class="headerlink" title="awk脚本"></a>awk脚本</h3><pre><code>将awk程序写成脚本，直接调用或执行awk脚本使用示例：1.先写文本再调用cat f1.awk{if($3&gt;=1000)print $1,$3} awk -F: -f f1.awk /etc/passwd2.也可以写成脚本形式先写再调用[root@centos7 ~]vim f2.awk#!/bin/awk -f{if($3 &gt;=1000)print $1,$3} [root@centos7 ~]./f2.awk -F: /etc/passwdnfsnobody 65534test 1000gentoo 1007nginx 1008ceshi 1009</code></pre><h4 id="向awk脚本传递参数"><a href="#向awk脚本传递参数" class="headerlink" title="向awk脚本传递参数"></a>向awk脚本传递参数</h4><pre><code>格式：awkfile var=value var2=value2... Inputfile注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变量都需要一个-v参数</code></pre><h6 id="awk脚本传参使用示例："><a href="#awk脚本传参使用示例：" class="headerlink" title="awk脚本传参使用示例："></a>awk脚本传参使用示例：</h6><pre><code>cat test.awk #!/bin/awk –f {if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3}chmod +x test.awktest.awk -F: min=100 max=200 /etc/passwd</code></pre><h4 id="工作中遇到的常用awk文本解决案例："><a href="#工作中遇到的常用awk文本解决案例：" class="headerlink" title="工作中遇到的常用awk文本解决案例："></a>工作中遇到的常用awk文本解决案例：</h4><h5 id="Linux-Web服务器网站故障分析常用的命令"><a href="#Linux-Web服务器网站故障分析常用的命令" class="headerlink" title="Linux Web服务器网站故障分析常用的命令"></a>Linux Web服务器网站故障分析常用的命令</h5><pre><code>系统连接状态篇：1.查看TCP连接状态netstat -nat |awk &apos;{print $6}&apos;|sort|uniq -c|sort -rn每出现一被/^tcp/模式匹配到的行，数组S[$NF]就加1，NF为当前匹配到的行的最后一个字段，此处用其值做为数组S的元素索引；netstat -n | awk &apos;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}&apos; 或netstat -n | awk &apos;/^tcp/ {++state[$NF]}; END {for(key in state) print key,&quot;\t&quot;,state[key]}&apos;netstat -n | awk &apos;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,&quot;t&quot;,arr[k]}&apos;netstat -n |awk &apos;/^tcp/ {print $NF}&apos;|sort|uniq -c|sort -rnnetstat -ant | awk &apos;{print $NF}&apos; | grep -v &apos;[a-z]&apos; | sort | uniq -c    2.查找请求数请20个IP（常用于查找攻来源）：方法一：netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20方法二：netstat -ant |awk &apos;/:80/{split($5,ip,&quot;:&quot;);++A[ip[1]]}END{for(i in A) print A[i],i}&apos; |sort -rn|head -n203.用tcpdump嗅探80端口的访问看看谁最高tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; ‘{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}’ | sort | uniq -c | sort -nr |head -204.查找较多time_wait连接netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n205.找查较多的SYN连接netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more6.根据端口列进程netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1</code></pre><h5 id="网站日志分析篇1（Apache）："><a href="#网站日志分析篇1（Apache）：" class="headerlink" title="网站日志分析篇1（Apache）："></a>网站日志分析篇1（Apache）：</h5><pre><code>1.获得访问前10位的ip地址cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’2.访问次数最多的文件或页面,取前20cat access.log|awk ‘{print $11}’|sort|uniq -c|sort -nr|head -203.列出传输最大的几个exe文件（分析下载站的时候常用）cat access.log |awk ‘($7~/.exe/){print $10 &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -204.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数cat access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -1005.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面cat access.log |awk ‘($7~/.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -1006.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -1007.列出传输时间超过 30 秒的文件cat access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -208.统计网站流量（G)cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’9.统计404的连接awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort10. 统计http statuscat access.log |awk &apos;{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}&apos;cat access.log |awk &apos;{print $9}&apos;|sort|uniq -c|sort -rn10.蜘蛛分析，查看是哪些蜘蛛在抓取内容。/usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E &apos;bot|crawler|slurp|spider&apos;</code></pre><h5 id="网站日分析2-Squid篇）按域统计流量"><a href="#网站日分析2-Squid篇）按域统计流量" class="headerlink" title="网站日分析2(Squid篇）按域统计流量"></a>网站日分析2(Squid篇）按域统计流量</h5><pre><code>cat squid_access.log.tar.gz| awk &apos;{print $10,$7}&apos; |awk &apos;BEGIN{FS=&quot;[ /]&quot;}{trfc[$4]+=$1}END{for(domain in trfc){printf &quot;%st%dn&quot;,domain,trfc[domain]}}&apos;</code></pre><h5 id="安全篇：-ssh-lastb"><a href="#安全篇：-ssh-lastb" class="headerlink" title="安全篇：(ssh lastb)"></a>安全篇：(ssh lastb)</h5><pre><code>ssh日志中失败登录的IP，取出来 /var/log/secureawk &apos;/Failed PASSWORD/{IP[$(NF-3)]++}END{for(i in IP){print i,IP[i]}&apos; /var/log/secure1、文件ip_list.txt如下格式，请提取”.magedu.com”前面的主机名部分并写入到回到该文件中1 blog.magedu.com2 www.magedu.com…999 study.magedu.com2、统计/etc/fstab文件中每个文件系统类型出现的次数[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{print $3}&apos;|sort|uniq -c |sort -nr      3 xfs      1 swap[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos;swap 1xfs 33、统计/etc/fstab文件中每个单词出现的次数root@centos7 ~]cat /etc/fstab |awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,count[j]}}&apos;man 14、提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字[root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|awk &apos;gsub(/[^0-9]/,&quot;&quot;,$0)&apos;05973[root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|tr -dc &quot;[0-9]&quot;059735、有一文件记录了1-100000之间随机的整数共5000个，存储的格式100,50,35,89…请取出其中最大和最小的整数6、解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT[root@centos7 ~]awk &apos;{access[$1]++}END{for(i in access){if(access[i]&gt;=1){print i,access[i]}}}&apos; /var/log/httpd/access_log 192.168.34.101 9192.168.34.103 13只过滤出IP，监控任务可以写到计划任务里，或者用内置函数system[&quot;iptables&quot;]调用？7、将以下文件内容中FQDN取出并根据其进行计数从高到低排序http://mail.magedu.com/index.htmlhttp://www.magedu.com/test.htmlhttp://study.magedu.com/index.htmlhttp://blog.magedu.com/index.htmlhttp://www.magedu.com/images/logo.jpghttp://blog.magedu.com/20080102.html[root@centos7 ~]#cat f5|sed -nr &apos;s@.*//([^/]+)/.*@\1@p&apos;|sort|uniq -c|sort -nr      2 www.magedu.com      2 blog.magedu.com      1 study.magedu.com      1 mail.magedu.com[root@centos7 ~]#cat f5|awk -F&quot;/&quot; &apos;{print $3}&apos;|sort|uniq -c|sort -nr      2 www.magedu.com      2 blog.magedu.com      1 study.magedu.com      1 mail.magedu.com8、将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出同一inode中，beginnumber的最小值和endnumber的最大值inode|beginnumber|endnumber|counts|106|3363120000|3363129999|10000|106|3368560000|3368579999|20000|310|3337000000|3337000100|101|310|3342950000|3342959999|10000|310|3362120960|3362120961|2|311|3313460102|3313469999|9898|311|3313470000|3313499999|30000|311|3362120962|3362120963|2|输出的结果格式为：310|3337000000|3362120961|10103|311|3313460102|3362120963|39900|106|3363120000|3368579999|30000|awk -F&apos;|&apos; &apos;NR==1{print;next}{a[$1]?(a[$1]&gt;$2?a[$1]=$2:0):(a[$1]=$2);b[$1]?(b[$1]&lt;$3?b[$1]=$3:0):(b[$1]=$3);c[$1]+=$4}END{l=asorti(a,d);for(i=1;i&lt;=l;i++)print d[i] FS a[d[i]] FS b[d[i]] FS c[d[i]] FS}&apos; file[解析]  第一行直接打印。从第2行开始以$1为下标，建立3个数组，比较出$2的最小值，$3的最大值，然后把$4进行累加，最后进行排序后依次取出各项值。  这其中运用了三目运算的嵌套，跟我们 if(){if(){}}else{} 的使用是一个道理，不要认为复杂，如果觉得模糊不清，仔细读懂流程控制。9.统计字符串中每个字母出现的次数abcdaabbccdd[root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 3b 3c 3d 3下面的写法在双引号前一定要加一个空格才能匹配出来或者用单引号，但是也需要在前面几个空格[root@centos7 mnt]#echo abcdaabbccdd|awk -F &quot;&quot; &apos;{for(i=1;i&lt;=NF;i++)x[$i]++}END{for(i in x){print i,x[i]}}&apos; a 3                                 此处一定有个空格b 3c 3d 3或者用单引号，但是也需要在前面几个空格[root@mini7-1 ~]#echo abcdaabbccdd |awk -F &apos;&apos; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 2b 3c 3d 2root@centos7 mnt]#echo abcdaabbccdd | grep -o &quot;[a-z]&quot;|sort|uniq -c      3 a      3 b      3 c      3 d10.面试题：取出/etc/fstab中的挂载目录    [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos;    boot    data    swap    [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos;    boot    data    swap</code></pre><h3 id="AWK中的输入分隔符"><a href="#AWK中的输入分隔符" class="headerlink" title="AWK中的输入分隔符"></a>AWK中的输入分隔符</h3><h6 id="我们可以使用两次awk-F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。"><a href="#我们可以使用两次awk-F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。" class="headerlink" title="我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。"></a>我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。</h6><pre><code>要一次指定多个分隔符，需要将分隔符用中括号[]包裹起来，如果多个分隔符中有至少一个特殊字符，那么还需要在中括号外加上双引号或者单引号，并且使用两个或两个以上的\将其进行转义$、^、(、)、[、]、?、.、|示例1：        [root@node7-1 data]cat b.txt         ssh:user1@192.168.1.10        ssh:user2@192.168.1.11        ssh:user3@192.168.1.12    1.取user和IP        [root@node7-1 data]awk -F [:@] &apos;{print $2,$3}&apos; b.txt         user1 192.168.1.10        user2 192.168.1.11        user3 192.168.1.12    2.上面b.txt中的：和@换成^和|，又该怎么取？        [root@node7-1 data]awk -F &apos;[\\^\\|]&apos; &apos;{print $2,$3}&apos; b.txt         user1 192.168.1.10        user2 192.168.1.11        user3 192.168.1.12示例2：    示例1：        george[walker]bush        william[jefferson]clinton    如果要打印出由分隔符[和]分隔的三段数据，即可以分别使用两个或两个以上的\对[和]进行转义，如下所示    方法一：        awk -F &apos;[\\[\\]]&apos; &apos;{ print $1,$2,$3}&apos; name.txt        george walker bush        william jefferson clinton    方法二：        awk -F &apos;[][]&apos; &apos;{ print $1,$2,$3}&apos; name.txt        george walker bush        william jefferson clinton11.取出文本中的姓名和FQDN，awk的方法参照文章最上面的链接文章    [root@node7-1 data]cat a.txt     xiaoming\t20\thttp://sougou.com    xiaohua\t25\thttp://www.baidu.com    xiaodong\t30\thttp://www.jidong.com方法一：用awk取，以\t做分隔符，但是在表示方法上比较特殊    root@node7-1 data]awk -F&apos;\\\\t&apos; &apos;{print $1,$3}&apos; a.txt     xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com分析：    第一个给第二个转义，第三个给第四个转义，传给awk对就是\\t，awk再将\\解释成\t方法二：用awk和sed取    [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )t(.*)@\1\2@&apos;    xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com12.扩展11题的内容把t换成$,又该如何取？    [root@node7-1 data]cat a.txt     xiaoming\$20\$http://sougou.com    xiaohua\$25\$http://www.baidu.com    xiaodong\$30\$http://www.jidong.com方法一：还是只用awk来取    [root@node7-1 data]awk -F&apos;\\\\\\$&apos; &apos;{print $1,$3}&apos; a.txt     xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com    分析：        1.\\$是转义$的        2.前四个\\\\是转义\的方法二：awk和sed取    [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )\$(.*)@\1\2@&apos;    xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com分析：先用awk用\做分隔符来取，再用sed取，sed中的$需要转义</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;文本处理三剑客之Awk&quot;&gt;&lt;a href=&quot;#文本处理三剑客之Awk&quot; class=&quot;headerlink&quot; title=&quot;文本处理三剑客之Awk&quot;&gt;&lt;/a&gt;文本处理三剑客之Awk&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2017/10/18/文本三剑客之awk/awk.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>旧事-大好河山</title>
    <link href="https://www.liukui.tech/2017/10/01/%E6%97%A7%E4%BA%8B-%E5%A4%A7%E5%A5%BD%E6%B2%B3%E5%B1%B1/"/>
    <id>https://www.liukui.tech/2017/10/01/旧事-大好河山/</id>
    <published>2017-10-01T00:00:00.000Z</published>
    <updated>2018-12-13T05:44:39.016Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2017/10/01/旧事-大好河山/纳木错.JPG" width="60%" height="60%"></p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/2017/10/01/旧事-大好河山/纳木错.JPG&quot; width=&quot;60%&quot; height=&quot;60%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="旧事，杂记" scheme="https://www.liukui.tech/categories/%E6%97%A7%E4%BA%8B%EF%BC%8C%E6%9D%82%E8%AE%B0/"/>
    
    
      <category term="旧事，杂记" scheme="https://www.liukui.tech/tags/%E6%97%A7%E4%BA%8B%EF%BC%8C%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
</feed>
