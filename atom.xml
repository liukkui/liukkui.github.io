<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coool&#39;s Blog</title>
  
  <subtitle>As we watch our love grow.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.liukui.tech/"/>
  <updated>2018-12-14T01:43:49.647Z</updated>
  <id>https://www.liukui.tech/</id>
  
  <author>
    <name>空腹吃早餐</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mysql</title>
    <link href="https://www.liukui.tech/2018/08/06/mysql/"/>
    <id>https://www.liukui.tech/2018/08/06/mysql/</id>
    <published>2018-08-05T16:00:00.000Z</published>
    <updated>2018-12-14T01:43:49.647Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="数据库" scheme="https://www.liukui.tech/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="mysql" scheme="https://www.liukui.tech/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>ansible</title>
    <link href="https://www.liukui.tech/2018/03/06/ansible/"/>
    <id>https://www.liukui.tech/2018/03/06/ansible/</id>
    <published>2018-03-05T16:00:00.000Z</published>
    <updated>2018-12-17T07:14:16.667Z</updated>
    
    <content type="html"><![CDATA[<h1 id="运维自动化管理工具之Ansible"><a href="#运维自动化管理工具之Ansible" class="headerlink" title="运维自动化管理工具之Ansible"></a>运维自动化管理工具之Ansible</h1><p><img src="/2018/03/06/ansible/ansible.png" alt=""><br><a id="more"></a></p><h3 id="内容：1-软件发布环境机制优势对比-和-2-ansible的应用"><a href="#内容：1-软件发布环境机制优势对比-和-2-ansible的应用" class="headerlink" title="内容：1.软件发布环境机制优势对比  和   2.ansible的应用"></a>内容：1.软件发布环境机制优势对比  和   2.ansible的应用</h3><p><font color="#FF0000">ansible的相关的文档</font><br>ansible的中文权威指南：<a href="http://ansible.com.cn/" target="_blank" rel="noopener">ansible中文指南</a><br>Github上的ansible-galaxy示例：<a href="http://galaxy.ansible.com" target="_blank" rel="noopener">ansible-galaxy</a></p><p>其他相关运维管理工具使用方法：<br>pssh的使用方法参照链接文章：<a href="https://www.jianshu.com/p/d15b6b8f17a5" target="_blank" rel="noopener">pssh</a><br>saltstack介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">saltstack</a><br>puppet介绍及使用参照链接文章：<a href="https://www.jianshu.com/p/4c6798d32f64" target="_blank" rel="noopener">puppet</a></p><pre><code>当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric常用自动化运维工具    PSSH：适用于主机数量很少的环境(基础ssh的key验证)    Ansible:python,Agentless,中小型应用环境(自带代理功能)    Saltstack:python，一般需部署agent，执行效率更高    Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境    Fabric：python，agentless    Chef: ruby,国内应用少    Cfengine    func</code></pre><h3 id="发布更新环境"><a href="#发布更新环境" class="headerlink" title="发布更新环境"></a>发布更新环境</h3><h4 id="灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机"><a href="#灰度发布：又叫金丝雀发布-核心概念：一次只发布一部分主机" class="headerlink" title="灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)"></a>灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)</h4><pre><code>比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器    而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径     如：     软件路径为:/data/app     正在用的软件版本V1.0：/data/app1.0     更新的软件版本V2.0：/data/app2.0    则需要把删除原来的软链接：/data/app1.0---&gt;/data/app    创建新的软链接：/data/app2.0---&gt;/data/app10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线发布步骤：    1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。    2.从负载均衡列表中移除掉「金丝雀」服务器。    3.升级「金丝雀」应用（排掉原有流量并进行部署）。    4.对应用进行自动化测试。    5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。    6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。A/B Testing    A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。优势与不足：    优势：用户体验影响小，灰度发布过程出现问题只影响少量用户    不足：发布自动化程度不够，发布期间可引发服务中断预发布验证：    新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器灰度发布：    可以基于主机，用户或者业务，又细分为地区，VIP和普通用户</code></pre><h4 id="蓝绿发布：核心：主备两套环境"><a href="#蓝绿发布：核心：主备两套环境" class="headerlink" title="蓝绿发布：核心：主备两套环境"></a>蓝绿发布：核心：主备两套环境</h4><pre><code>定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同     时也升级到新版本主：绿色环境-活动环境：负责对外提供服务，版本：v1.0备：绿色环境-非活动环境：版本：v2.0工作机制：    先把备环境升级v1.0---&gt;v2.0版本，然后上线    把主环境的v1.0版本下线，已经升级的备环境进行替换特点：    蓝绿部署无需停机，并且风险较小.注意事项：    1.需要提前考虑数据库与应用部署同步迁移/回滚的问题    2.蓝绿部署需要有基础设施支持    3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境      和绿色环境有被摧毁的风险.优势与不足：    优势：升级切换和回退速度非常快    不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响</code></pre><h4 id="滚动发布：在灰度发布的基础上进行进一步优化"><a href="#滚动发布：在灰度发布的基础上进行进一步优化" class="headerlink" title="滚动发布：在灰度发布的基础上进行进一步优化"></a>滚动发布：在灰度发布的基础上进行进一步优化</h4><pre><code>定义：    一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式.特点：    1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数.  可以部分部署，例如每次只取出集群的20%进行升级。    2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出优势和不足:    优势：用户体验影响小，体验较平滑    不足：发布和回退时间比较缓慢。         发布工具比较复杂，LB需要平滑的流量摘除和拉入能力滚动发布目前成熟型技术组织所采用的主流发布方式</code></pre><h1 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h1><p><img src="/2018/03/06/ansible/ansible架构.png" alt="ansible架构"></p><h4 id="ansible特性：-最多管理500台主机，更多效率会降低"><a href="#ansible特性：-最多管理500台主机，更多效率会降低" class="headerlink" title="ansible特性：-最多管理500台主机，更多效率会降低"></a>ansible特性：-最多管理500台主机，更多效率会降低</h4><pre><code>1.模块化：调用特定的模块，完成特定任务   -类似linux中的小命令2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块3.支持自定义模块4.基于Python语言实现5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务)6.安全，基于OpenSSH7.支持playbook编排任务   -类似于脚本功能，多个脚本的集合成为Roles8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况9.无需代理不依赖PKI（无需ssl）10.可使用任何编程语言写模块11.YAML格式，编排任务，支持丰富的数据结构12.较强大的多层解决方案</code></pre><h3 id="Ansible的学习过程："><a href="#Ansible的学习过程：" class="headerlink" title="Ansible的学习过程："></a>Ansible的学习过程：</h3><pre><code>1.ansible基本命令使用2.ansible常用模块详解，介绍ansible单个命令的使用3.YAML语法介绍4.ansible playbook基础：剧本初体验，类似于写脚本5.playbook中的变量：tags，handlers使用6.plsybook模板：templates7.playbook的条件判断：when8.playbook的字典：with_items9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合</code></pre><p>会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。</p><h3 id="ansible命令执行过程"><a href="#ansible命令执行过程" class="headerlink" title="ansible命令执行过程"></a>ansible命令执行过程</h3><pre><code>ansible命令执行过程1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg2. 加载自己对应的模块文件，如command3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件4. 给文件+x执行5. 执行并返回结果6. 删除临时py文件，sleep 0退出执行状态：(颜色定义在/etc/ansible/ansible.cfg中)    绿色：执行成功并且不需要做改变的操作    黄色：执行成功并且对目标主机做变更    红色：执行失败</code></pre><h3 id="CMDB作用介绍"><a href="#CMDB作用介绍" class="headerlink" title="CMDB作用介绍:"></a>CMDB作用介绍:</h3><pre><code>CMDB:Configuration Management Database 配置管理数据库        将服务器的配置，网络配置写到数据库里CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管理等流程提供准确的配置信息.</code></pre><p>了解更多CMDB可参照文章：<a href="">CMDB</a></p><h2 id="1-ansible基本命令使用"><a href="#1-ansible基本命令使用" class="headerlink" title="1.ansible基本命令使用"></a>1.ansible基本命令使用</h2><h3 id="ansible软件安装：多种安装方法"><a href="#ansible软件安装：多种安装方法" class="headerlink" title="ansible软件安装：多种安装方法"></a>ansible软件安装：多种安装方法</h3><pre><code>1.基于epel源安装：    yum install ansible,非服务，只是一个管理工具2.编译安装：3.Github方式安装：可以同步安装4.pip安装：pip是安装Python包的管理器，类似yum</code></pre><h4 id="ansible的重要-amp-主要文件"><a href="#ansible的重要-amp-主要文件" class="headerlink" title="ansible的重要&amp;主要文件"></a>ansible的重要&amp;主要文件</h4><pre><code>配置文件：    /etc/ansible/ansible.cfg  配置ansible的工作特性    /etc/ansible/hosts  主机清单    /etc/ansible/roles  存放的角色目录程序文件：    /usr/bin/ansible   ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想    /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助    /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台    /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务    /usr/bin/ansible-vault 文件加密工具    /usr/bin/ansible-console 基于Console界面与用户交互的执行工具常用命令：    ansible all --list 查看ansible管理的主机群    ansible all -m &quot;模块名&quot; -a &apos;执行的命令&apos;   用什么模块执行什么命令        all也可以换成定义的--list中组的名字    ansible-playbook -C &apos;*.yml&apos; 对所有主机执行剧本    ansible-plsybook -C -t &apos;标签&apos; &apos;*.yml&apos; 对所有主机执行哪个标签的剧本</code></pre><h4 id="ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法"><a href="#ansible主机清单配置：-etc-ansible-hosts-第一步-下文中介绍主机清单的多种表示方法" class="headerlink" title="ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)"></a>ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)</h4><pre><code>支持不分组，分组，等方式    如：        192.168.34.100        [webservers]        192.168.34.101        192.168.34.102        [dbservers]        192.168.34.[1:6]7 (17,27..67)        db[01:100].cenntos.com</code></pre><h4 id="ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）"><a href="#ansible配置文件：-etc-ansible-ansible-cfg-（一般保持默认）" class="headerlink" title="ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）"></a>ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）</h4><pre><code>配置文件只提供默认值，但可以通过playbook的设置进行覆盖配置文件可以放在/etc/ansible/ansible.cfg中也可以放到一个工作目录下命名为.ansible.cfg[defaults]inventory = /etc/ansible/hosts - 主机列表配置文件library = /usr/share/my_modules/ - 库文件存放目录remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录forks = 5 - 默认并发数sudo_user = root - 默认sudo 用户ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码ask_pass = Trueremote_port = 22host_key_checking = False  -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错[color] 定义ansible命令的执行结果颜色的</code></pre><h3 id="配置文件说明和建议修改的项："><a href="#配置文件说明和建议修改的项：" class="headerlink" title="配置文件说明和建议修改的项："></a>配置文件说明和建议修改的项：</h3><pre><code>local_tmp和remote_tmp：    本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地    家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除.host_key_checking = False -检查对应服务器的host_key，建议取消注释log_path=/var/log/ansible.log -建议启用日志文件，利于排错module_name = command   -默认使用的命令模块，可以修改成shell    module_name = shell</code></pre><h2 id="2-ansible常用模块详解，介绍ansible单个命令的使用"><a href="#2-ansible常用模块详解，介绍ansible单个命令的使用" class="headerlink" title="2.ansible常用模块详解，介绍ansible单个命令的使用"></a>2.ansible常用模块详解，介绍ansible单个命令的使用</h2><h3 id="ansible模块的使用查询方法"><a href="#ansible模块的使用查询方法" class="headerlink" title="ansible模块的使用查询方法"></a>ansible模块的使用查询方法</h3><pre><code>ansible-doc: 显示模块帮助ansible-doc [options] [module...]    -a 显示所有模块的文档    -l, --list 列出可用模块    -s, --snippet显示指定模块的playbook片段示例：    ansible-doc –l 列出所有功能模块    ansible-doc ping 查看ansible中的ping用法    ansible-doc -s shell 查看shell模块的使用方法</code></pre><h3 id="ansible的常用基本选项"><a href="#ansible的常用基本选项" class="headerlink" title="ansible的常用基本选项"></a>ansible的常用基本选项</h3><pre><code>ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible    端能基于密钥认证的方式联系各被管理节点ansible语法：    ansible &lt;host-pattern&gt; [-m module_name] [-a args]    --version 显示版本    -m module 指定模块，默认为command，主要使用选项    -v 详细过程 –vv -vvv更详细    --list-hosts 显示主机列表，可简写 --list    -k, --ask-pass 提示输入ssh连接密码，默认Key验证    -K, --ask-become-pass 提示输入sudo时的口令    -C, --check 检查，并不执行    -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s    -u, --user=REMOTE_USER 执行远程执行的用户    -b, --become 代替旧版的sudo 切换</code></pre><h3 id="ansible的主机清单表示方法-Host-pattern"><a href="#ansible的主机清单表示方法-Host-pattern" class="headerlink" title="ansible的主机清单表示方法:Host-pattern"></a>ansible的主机清单表示方法:Host-pattern</h3><pre><code>1.All ：表示所有Inventory中的所有主机    如：ansible all -m ping        ansible all --list-hosts列出所有主机清单        ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP2.* :通配符    如：ansible &quot;*&quot; = ansible all        ansible 192.168.34.* 表示34网段的所有IP3.或的关系    如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作        ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作4.与的关系(且)    如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机5.非，取反    如：ansible &apos;websrvs:!dbsrvs&apos;        在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号6.正则表达式    如：ansible &quot;~(web|db).*\.centos\.com&quot; </code></pre><h2 id="ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块"><a href="#ansible的常见模块-第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块" class="headerlink" title="ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)"></a>ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)</h2><h5 id="ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项"><a href="#ansible-doc-模块名-可以查看具体使用方法：显示都有哪些选项" class="headerlink" title="ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项"></a>ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项</h5><pre><code>1.Command：在远程主机执行命令，默认模块，可忽略-m选项    可以在ansible.cfg中修改默认模块项    支持：chdir(切换目录)    command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现使用示例：    ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh    ansible all -a &apos;useradd test&apos; 所有主机上创建test用户2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项    支持功能：支持$ &lt; &gt; | ; &amp; 等            chdir 执行前，先切换到该文件夹示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos;        显示appsrvs组的主机名    ansible all -m shell -a &apos;chdir=/data rm -rf *&apos;    先切换到/data目录下，再执行删除命令3.Script: 批量运行脚本    可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理    功能：creates:远程主机的文件存在，则不运行        removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令示例：ansible all -m script -a &quot;/data/test.sh&quot;    ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot;        因为fstab文件存在，则不执行rm -rf /data/*命令    ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot;        因为fstab文件存在，则执行rm -rf /data/*命令4.Copy:从服务器复制文件到目标主机    src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos;    根据自己写的字符串生成文件5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取    src，dest(抓取到本机目录)示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;        将远程主机fstab2文件抓取到本机/data下    如果抓取的是目录，先打包再抓取    打包：ansible all -a &apos;tar cf /root/data.tar /data&apos;     抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos;6.File：设置文件属性，创建/删除文件    src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos;     创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos;     删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos;7.Hostname：管理主机名     可以通过后面的变量来实现    a.先在hosts后定义hostname变量名        [centos6]        192.168.34.106 hostname=mini6-2        192.168.34.101 hostname=node6-1         [centos7]        192.168.34.107 hostname=mini7-1    b.再通过hostname模块批量修改        ansible all -m hostname -a &apos;name={{hostname}}&apos;8.Cron：计划任务    支持：minute，hour，day，month，weekday示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate        172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务     ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名     ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名9.Yum：管理包    支持：name,state=(started stopped reloaded restarted),absent    更新缓存：update_cache=yes，示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包      ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包10.Service：管理服务(同一systemctl&amp;service)    name，state(stopped,started,reloaded,restarted) enable(设置开启启动)示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务     ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务     ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务     ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动11.User：管理用户    name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录)示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos;    创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录12.Group：管理组    支持：group,name,gid,system,state=(absent)示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组    ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 </code></pre><h2 id="ansible系列的一些模块-用的不多"><a href="#ansible系列的一些模块-用的不多" class="headerlink" title="ansible系列的一些模块(用的不多)"></a>ansible系列的一些模块(用的不多)</h2><pre><code>简单介绍与了解：ansible-galaxy 互联网上的角色分享ansible-pull      推送命令至远程，效率无限提升，对运维要求较高  Ansible-vault管理yaml文件    功能：管理加密解密yml文件        ansible-vault [create|decrypt|edit|encrypt|rekey|view]        ansible-vault encrypt hello.yml 加密        ansible-vault decrypt hello.yml 解密        ansible-vault view hello.yml 查看        ansible-vault edit hello.yml 编辑加密文件        ansible-vault rekey hello.yml 修改口令        ansible-vault create new.yml 创建新文件Ansible-console</code></pre><h2 id="ansible重要知识之playbook-上面的各种模块的组合"><a href="#ansible重要知识之playbook-上面的各种模块的组合" class="headerlink" title="ansible重要知识之playbook(上面的各种模块的组合)"></a>ansible重要知识之playbook(上面的各种模块的组合)</h2><p><img src="/2018/03/06/ansible/" alt="playbook原理"></p><h3 id="YAML语言（编写playbook的专门语言）"><a href="#YAML语言（编写playbook的专门语言）" class="headerlink" title="YAML语言（编写playbook的专门语言）"></a>YAML语言（编写playbook的专门语言）</h3><pre><code>YAML语法：     在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三    个点号( ... )用来表示档案结尾    次行开始正常写Playbook的内容，一般建议写明该Playbook的功能    使用#号注释代码    缩进必须是统一的，不能空格和tab混用    缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过    缩进结合换行来实现的    YAML文件内容是区别大小写的，k/v的值均需大小写敏感    k/v的值可同行写也可换行写。同行使用:分隔    v可是个字符串，也可是另一个列表    一个完整的代码块功能需最少元素需包括 name: task    一个name只能包括一个task    YAML文件扩展名通常为yml或yaml    List：列表，其所有元素均使用“-”打头    Dictionary：字典，通常由多个key与value构成</code></pre><h2 id="Playbook中的核心元素"><a href="#Playbook中的核心元素" class="headerlink" title="Playbook中的核心元素:"></a>Playbook中的核心元素:</h2><pre><code>1.Hosts 执行的远程主机列表2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远    程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使    用sudo_user指定sudo时切换的用户3.Tasks 任务集4.Varniables 内置变量或自定义变量在playbook中调用5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断8.handlers和notify  </code></pre><h2 id="运行playbook"><a href="#运行playbook" class="headerlink" title="运行playbook"></a>运行playbook</h2><pre><code>运行playbook的方式ansible-playbook &lt;filename.yml&gt; ... [options]常见选项    -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测    --list-hosts 列出运行任务的主机    --limit 主机列表 只针对主机列表中的主机执行    -v 显示过程 -vv -vvv 更详细 备注：    执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误    ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行</code></pre><h3 id="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"><a href="#执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。" class="headerlink" title="执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。"></a>执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。</h3><h2 id="示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验"><a href="#示例：以下实验均在centos7管理centos7集群，因为6-amp-7配置文件不同，均在7上实验" class="headerlink" title="示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验"></a>示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验</h2><h4 id="将centos7的httpd-conf复制到centos7主机，6上的配置文件不同"><a href="#将centos7的httpd-conf复制到centos7主机，6上的配置文件不同" class="headerlink" title="将centos7的httpd.conf复制到centos7主机，6上的配置文件不同"></a>将centos7的httpd.conf复制到centos7主机，6上的配置文件不同</h4><pre><code>示例1：写一个安装启动httpd的playbook:install_httpd.yml        包括创建用户，安装httpd包，开启服务，并设置开机启动- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd    - name: copy config      copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf    - name: install package      yum: name=httpd    - name: service      service: name=httpd state=started enabled=yes备注：    执行完通过以下命令判断每个任务都否都执行成功了    1.ansible all -a &apos;getent passwd httpd&apos;    2.ansible all -a &apos;rpm -q httpd&apos;    3..ansible all -a &apos;ss -ntlp|grep 80&apos;示例2：写一个删除上面的playbook:remove_httpd.yml        包括：删除用户，卸载httpd包- hosts: all  remote_user: root  tasks:    - name: del user      user: name=httpd state=absent remove=yes    - name: remove package      yum: name=httpd state=absent备注：    如果只删除特定主机的httpd，而不是全部，需要加--limit选项    ansible-playbook --limit 192.168.34.105 remove_httpd.yml        只限制在192.168.34.105的主机执行</code></pre><h4 id="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"><a href="#上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。" class="headerlink" title="上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。"></a>上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。</h4><h3 id="handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。"><a href="#handlers和notify结合使用触发条件-当达到某个条件时，触发执行对应的task任务。" class="headerlink" title="handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。"></a>handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。</h3><pre><code>Handlers:    是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生        变化时，才会采取一定的操作Notify:    此action可用于在每个play的最后被触发，这样可避免多次有改变发生    时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。    在notify中列出的操作称为handler，也即notify中调用handler中定义的操作</code></pre><h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><pre><code>示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200）- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted 备注：停止并删除用户和安装包    ansible all -a &apos;service memcached stop&apos;    ansible all -a &apos;ss -ntl&apos;    ansible all -a &apos;rpm -q memcached&apos;    ansible all -a &apos;getent passwd memcached&apos;</code></pre><h3 id="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"><a href="#可以多个notify对应一个handlers，也可以多个motify对应多个handlers" class="headerlink" title="可以多个notify对应一个handlers，也可以多个motify对应多个handlers"></a>可以多个notify对应一个handlers，也可以多个motify对应多个handlers</h3><pre><code>示例4：多个notify对应一个handlers- hosts: websrvs  remote_user: root  tasks:    - name: Install httpd      yum: name=httpd state=present    - name: Install configure file      copy: src=files/httpd.conf dest=/etc/httpd/conf/      notify: restart httpd  第一个notify    - name: ensure apache is running      service: name=httpd state=started enabled=yes      notify: restart httpd  第二个notify  handlers:      - name: restart httpd   对应一个handlers      service: name=httpd status=restarted</code></pre><h3 id="示例5：多个notify对应多个handlers"><a href="#示例5：多个notify对应多个handlers" class="headerlink" title="示例5：多个notify对应多个handlers"></a>示例5：多个notify对应多个handlers</h3><pre><code>- hosts: websrvs  remote_user: root  tasks:    - name: config      copy: src=/root/config.txt dest=/etc/nginx/nginx.conf      notify:        - Restart Nginx        - Check Nginx Process  多个notify的写法  handlers:    - name: Restart Nginx     对应写多个handlers      service: name=nginx state=restarted enabled=yes    - name: Check Nginx process      shell: killall -0 nginx &gt; /tmp/nginx.log</code></pre><h3 id="tags的用法：作用：挑选某一段的task来执行"><a href="#tags的用法：作用：挑选某一段的task来执行" class="headerlink" title="tags的用法：作用：挑选某一段的task来执行"></a>tags的用法：作用：挑选某一段的task来执行</h3><pre><code>将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行然后执行：ansible-plsybook -t ceshi install_memcached.yml        只会触发拷贝文件和handlers的动作---#test yaml file- hosts: all  remote_user: root  tasks:    - name: creat user      user: name=memcached shell=/sbin/nologin uid=2345    - name: install package      yum: name=memcached    - name: copy config      copy: src=/data/memcached dest=/etc/sysconfig/memcached      notify: restart service   和handlers名称一致      tags: ceshi   对拷贝动作加一个标签    - name: service      service: name=memcached state=started enabled=yes  handlers:    - name: restart service  和notify名称一致      service: name=memcached state=restarted</code></pre><h2 id="Playbook中变量使用-可以多出定义，但是存在优先级"><a href="#Playbook中变量使用-可以多出定义，但是存在优先级" class="headerlink" title="Playbook中变量使用:可以多出定义，但是存在优先级"></a>Playbook中变量使用:可以多出定义，但是存在优先级</h2><h4 id="优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量"><a href="#优先级的顺序为：-e-var-gt-yaml中的var-gt-hosts中的普通变量-gt-hosts公共变量" class="headerlink" title="优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量"></a>优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量</h4><pre><code>变量名：仅能由字母、数字和下划线组成，且只能以字母开头变量来源：1 ansible setup facts 远程主机的所有变量都可直接调用    setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的        代码块，然后用代码块当变量    比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的          ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量3 通过命令行指定变量，优先级最高    可以对单个变量赋值：ansible-playbook –e varname=value     也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot;4 在playbook中定义    vars:         - var1: value1         - var2: value25 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件            很适合在roles中进行单独定义6 在role中定义（下文中有介绍）</code></pre><h3 id="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令"><a href="#从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version-7？然后再执行不同的命令" class="headerlink" title="从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令"></a>从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令</h3><p>#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作<br>        ansible_fqdn 主机名的变量<br>        ansible_hostname 主机名<br>        ansible_distribution_major_version: “6” 版本名变量<br>        ansible_processor_vcpus 虚拟cpu个数变量<br>        ansible_memtotal_mb 内存的变量<br>    示例：<br>    ansible all -m setup -a “filter=ansible_memtotal_mb”<br>        用此命令来查看系统内变量的值</p><h4 id="调用不同变量来源的示例：得出变量的优先级顺序"><a href="#调用不同变量来源的示例：得出变量的优先级顺序" class="headerlink" title="调用不同变量来源的示例：得出变量的优先级顺序"></a>调用不同变量来源的示例：得出变量的优先级顺序</h4><pre><code>示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml- hosts: all  remote_user: root  tasks:    - name: touch file      file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量    /etc/ansible/hosts：中定义的变量：        [websrvs]        192.168.34.105 port1=80        192.168.34.106 port1=90   -普通变量        [websrvs:vars]   -公共组变量        mark=&quot;-&quot;        [appsrvs]        192.168.34.101 port1=100        [appsrvs:vars]        mark=&quot;=&quot;    vars.yml中书写格式：        - hosts: all          remote_user: root          tasks:            - name: touch file              file: name=/data/app{{mark}}{{ port1 }}.log state=touch最后生成的文件为：            app=100.log，app-80.logapp-90.log示例3：在示例1的基础上，再通过命令行中定义变量:    在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果：    ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml    可以看出，最后新建的文件名为hahaha.log示例4：在playbook中定义变量    - hosts: all      remote_user: root      vars:        - port1: 200        - mark: +++      tasks:        - name: touch file          file: name=/data/app{{mark}}{{ port1 }}.log state=touch    生成的文件：        app+++200.log示例5：先写在var.yml中定义变量，    1.先准备cat vars.yml:文件内容格式        var1: httpd        var2: nginx    2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义        - hosts: web          remote_user: root          vars_files:            - vars.yml         tasks:           - name: create httpd log             file: name=/app/{{ var1 }}.log state=touch           - name: create nginx log             file: name=/app/{{ var2 }}.log state=touch</code></pre><h2 id="模板templates，作用："><a href="#模板templates，作用：" class="headerlink" title="模板templates，作用："></a>模板templates，作用：</h2><pre><code>文本文件，嵌套有脚本（使用模板编程语言编写）Jinja2语言，使用字面量，有下面形式字符串：使用单引号或双引号数字：整数，浮点数列表：[item1, item2, ...]元组：(item1, item2, ...)字典：{key1:value1, key2:value2, ...}布尔型：true/false算术运算：+, -, *, /, //, %, **比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;=逻辑运算：and, or, not流表达式：For If When</code></pre><h3 id="templates功能：根据模块文件动态生成对应的配置文件"><a href="#templates功能：根据模块文件动态生成对应的配置文件" class="headerlink" title="templates功能：根据模块文件动态生成对应的配置文件"></a>templates功能：根据模块文件动态生成对应的配置文件</h3><p>   templates文件必须存放于templates目录下，且命名为 .j2 结尾</p><pre><code>yaml/yml 文件需和templates目录平级，目录结构如下：./├── temnginx.yml└── templates   └── nginx.conf.j2</code></pre><h4 id="示例1：通过templates模板nginx"><a href="#示例1：通过templates模板nginx" class="headerlink" title="示例1：通过templates模板nginx"></a>示例1：通过templates模板nginx</h4><pre><code>1.先生成nginx.conf.j2模板cp /etc/nginx/nginx.conf templates/nginx.conf.j22.创建playbook- hosts: all  remote_user: root  tasks:    - name: inastll nginx      yum: name=nginx    - name: template      template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf                                       notify: service    - name: start service      service: name=nginx state=started  handlers:    - name: service      service: name=nginx state=restarted</code></pre><h3 id="when配合templates实现根据不同版本执行不同的功能"><a href="#when配合templates实现根据不同版本执行不同的功能" class="headerlink" title="when配合templates实现根据不同版本执行不同的功能"></a>when配合templates实现根据不同版本执行不同的功能</h3><pre><code>条件测试:    如果需要根据变量、facts或此前任务的执行结果来做为某task执行与    否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法    格式when语句    在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法示例：tasks:     - name: &quot;shutdown RedHat flavored systems&quot;     command: /sbin/shutdown -h now     when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值</code></pre><h4 id="示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when"><a href="#示例2：通过templates模板根据不同的centos版本，安装不同的httpd-就用到了when" class="headerlink" title="示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when"></a>示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when</h4><pre><code>步骤：涉及到多个notify对应一个handlers,定义端口变量1.hosts文件配置：修改了4台主机httpd的端口    [centos6]    192.168.34.105 http_port=86    192.168.34.106 http_port=87    192.168.34.101 http_port=88    [centos7]    192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件    httpd_6.conf.j2      httpd_7.conf.j23.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的    Listen {{http_port}} 调用hosts列表中的端口变量4.plsybook如下：---- hosts: all  remote_user: root  tasks:    - name: install httpd      yum: name=httpd    - name: templates 6      template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf      notify: restart service      when: ansible_distribution_major_version == &quot;6&quot;    - name: templates 7      template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf                                when: ansible_distribution_major_version == &quot;7&quot;      notify: restart service    - name: service      service: name=httpd state=started  handlers:    - name: restart service      service: name=httpd state=restarted</code></pre><h2 id="迭代：with-items，类似于shell中的for循环"><a href="#迭代：with-items，类似于shell中的for循环" class="headerlink" title="迭代：with_items，类似于shell中的for循环"></a>迭代：with_items，类似于shell中的for循环</h2><pre><code>迭代：当有需要重复性执行的任务时，可以使用迭代机制对迭代项的引用，固定变量名为”item“要在task中使用with_items给定要迭代的元素列表列表格式：    字符串    字典   字典构成一个键值对{key:vavul},如示例3</code></pre><h4 id="迭代的示例："><a href="#迭代的示例：" class="headerlink" title="迭代的示例："></a>迭代的示例：</h4><pre><code>示例1：比如创建user1.user2.user3个用户    - hosts: all      remote_user: root      tasks:        - name: touch users          user: name={{item}}          with_items:            - haha1            - haha2            - haha3示例2：拷贝3个文件，file1 file2 file3    - hosts: all     remote_user: root    tasks:      - name: copy files        copy: src=/data/playbook/{{item}} dest=/data/        with_items:          - file1          - file2          - file3</code></pre><h2 id="迭代嵌套子变量-涉及到多个键值对的表达方式"><a href="#迭代嵌套子变量-涉及到多个键值对的表达方式" class="headerlink" title="迭代嵌套子变量:涉及到多个键值对的表达方式"></a>迭代嵌套子变量:涉及到多个键值对的表达方式</h2><pre><code>示例3：创建3个组，再创建3个用户，指定加入一一对应的组    - hosts: all      remote_user: root      tasks:        - name: creat groups          group: name={{item}}          with_items:            - group1            - group2            - group3        - name: creat users          user: name={{item.name}} group={{item.group}}          with_items:            - { name: &apos;haha1&apos;, group: &apos;group1&apos; }            - { name: &apos;haha2&apos;, group: &apos;group2&apos; }            - { name: &apos;haha3&apos;, group: &apos;group3&apos; }备注：注意创建用户时，键值对的表达和使用方法    上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3;</code></pre><h3 id="Playbook中template结合for循环生成具有重复性的代码段"><a href="#Playbook中template结合for循环生成具有重复性的代码段" class="headerlink" title="Playbook中template结合for循环生成具有重复性的代码段"></a>Playbook中template结合for循环生成具有重复性的代码段</h3><pre><code>语法:for的写法：    {% for vhost in nginx_vhosts %}        server {        listen {{ vhost.listen | default('80 default_server') }}### Playbook中template结合for循环生成具有重复性的代码段         if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用                        如果没定义，则不执行接下来的代码：示例2        {% if vhost.server_name is defined %}                server_name {{ vhost.server_name }};        {% endif %}        {% if vhost.root is defined %}                root {{ vhost.root }};        {% endif %}### for和if的示例，帮助理解其要执行语句的含义        示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成    先创建for.j2文件：                {% for i in ports %}                server{                        listen {{i.listen}}                        name {{i.name}}                        root {{i.root}}                }                {% endfor %}        创建playbook:再其中调用for.j2文件            - hosts: all              remote_user: root              vars:                ports:                  - web1:                    listen: 81                    name: www.baidu.com                    root: /data/web1                  - web2:                    listen: 82                    name: www.baidu1.com                    root: /data/web2              tasks:                - name: test for                  template: src=for.j2 dest=/data/for1.conf    效果为：        server{            listen 81            name www.baidu.com            root /data/web1        }        server{            listen 82            name www.baidu1.com            root /data/web2        }示例2：template配合if的涵义：    在示例1中的playbook中，把name注释掉，即不定义name的值            - web1:                    listen: 81                   # name: www.baidu.com                    root: /data/web1    然后playbook:再调用for.j2文件        {% for i in ports %}            server{                    listen {{i.listen}}            {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用                    name {{i.name}}            {% endif %}                    root {{i.root}}            }            {% endfor %}    结果：则web1没有name的值，即可以理解if的用法        server{            listen 81            root /data/web1  少了web1的name的值        }        server{            listen 82            name www.baidu1.com            root /data/web2        }</code></pre><h3 id="Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？"><a href="#Roles：什么是roles-为什么要用roles？什么场景适合于roles-roles的结构？" class="headerlink" title="Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？"></a>Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？</h3><h2 id="ansible重要内容之Roles；playbook的集合和拆分"><a href="#ansible重要内容之Roles；playbook的集合和拆分" class="headerlink" title="ansible重要内容之Roles；playbook的集合和拆分"></a>ansible重要内容之Roles；playbook的集合和拆分</h2><pre><code> ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles    能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需    要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、    文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一    种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程    等场景中复杂场景：建议使用roles，代码复用度高变更指定主机或主机组如命名不规范维护和传承成本大某些功能需多个Playbook，通过Includes即可实现</code></pre><h3 id="roles的意义和适用场景："><a href="#roles的意义和适用场景：" class="headerlink" title="roles的意义和适用场景："></a>roles的意义和适用场景：</h3><pre><code>角色(roles)：角色集合    适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把    同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了，    当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。        如系统内会存在如下的各类服务，可以先编排好角色        roles/        ├── httpd/        ├── memcached/        ├── mysql/        └── nginx/</code></pre><h3 id="roles的目录结构（一般分成以下目录进行存放一类的文件）"><a href="#roles的目录结构（一般分成以下目录进行存放一类的文件）" class="headerlink" title="roles的目录结构（一般分成以下目录进行存放一类的文件）"></a>roles的目录结构（一般分成以下目录进行存放一类的文件）</h3><pre><code>Roles各目录作用：/roles/project/ :项目名称,有以下子目录    如创建http，memcached，nginx等目录files/ ：存放由copy或script模块等调用的文件    保存需要拷贝的配置文件templates/：template模块查找所需要模板文件的目录    保存通过template的jinja2模板调用的配置文件tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；        其它的文件需要在此文件中通过include进行包含handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此           文件中通过include进行包含vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要       在此文件中通过include进行包含，可以单独定义变量的目录meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，其它文件需在此文件中通过include进行包含            tasks目录下，组合任务顺序的文件default/：设定默认变量时使用此目录中的main.yml文件</code></pre><h3 id="roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色"><a href="#roles-playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色" class="headerlink" title="roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色."></a>roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.</h3><pre><code>- hosts: all  remote_user: root  roles:    - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]}       - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}    - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}</code></pre><h3 id="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"><a href="#playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量" class="headerlink" title="playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量"></a>playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量</h3><pre><code>方法一：把需要调用的角色写在一个playbook里    - hosts: all      remote_user: root      roles:        - role: httpd        - role: memcached        - role: nginx    弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活方法二；可以把变量在角色中定义    传递变量给角色    - hosts:      remote_user:      roles:        - mysql        - { role: nginx, username: nginx }          键role用于指定角色名称          后续的k/v用于传递变量给角色          调用角色方法3：还可基于条件测试实现角色调用方法三：还可基于条件测试实现角色调用    roles:      - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ }</code></pre><h2 id="roles示例："><a href="#roles示例：" class="headerlink" title="roles示例："></a>roles示例：</h2><h3 id="以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml"><a href="#以httpd-amp-nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook-role-playbook-yml" class="headerlink" title="以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml"></a>以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.yml</h3><h4 id="roles的目录结构下的httpd-amp-nginxmemcached"><a href="#roles的目录结构下的httpd-amp-nginxmemcached" class="headerlink" title="roles的目录结构下的httpd&amp;nginxmemcached"></a>roles的目录结构下的httpd&amp;nginxmemcached</h4><pre><code>roles├── httpd│   ├── files│   │   ├── index_6.html│   │   └── index_7.html│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── copyhtml_6.yml│   │   ├── copyhtml_7.yml│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig_6.yml│   │   ├── tempconfig_7.yml│   │   └── user.yml│   ├── templates│   │   ├── httpd_6.conf.j2│   │   └── httpd_7.conf.j2│   └── vars├── memcached│   ├── files│   ├── handlers│   │   └── main.yml│   ├── tasks│   │   ├── group.yml│   │   ├── main.yml│   │   ├── package.yml│   │   ├── service.yml│   │   ├── tempconfig.yml│   │   └── user.yml│   ├── templates│   │   └── memcached.j2│   └── vars└── nginx    ├── files    │   ├── index_6.html    │   └── index_7.html    ├── handlers    │   └── main.yml    ├── tasks    │   ├── copyhtml_6.yml    │   ├── copyhtml_7.yml    │   ├── group.yml    │   ├── main.yml    │   ├── package.yml    │   ├── service.yml    │   ├── tempconfig.yml    │   └── user.yml    ├── templates    │   └── nginx.conf.j2    └── vars       └── main.yml</code></pre><h3 id="调用角色的playbook-roles-yml"><a href="#调用角色的playbook-roles-yml" class="headerlink" title="调用角色的playbook:roles.yml"></a>调用角色的playbook:roles.yml</h3><h5 id="可以通过加变量和标签和条件测试调用更灵活的调用各种角色"><a href="#可以通过加变量和标签和条件测试调用更灵活的调用各种角色" class="headerlink" title="可以通过加变量和标签和条件测试调用更灵活的调用各种角色)"></a>可以通过加变量和标签和条件测试调用更灵活的调用各种角色)</h5><pre><code>    vim /data/roles.yml            - hosts: all            remote_user: root          roles:        - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“}        - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]}        - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]}比如：     1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法     2.ansible-playbook -t httpd roles.yml 只选择安装httpd     3.ansible-playbook -t nginx roles.yml 只选择安装nginx     4.ansible-playbook -t web roles.yml 安装httpd和memcached     5.ansible-playbook -t web1 roles.yml 只选择安装nginx</code></pre><h3 id="下图为每个role的各个文件内容："><a href="#下图为每个role的各个文件内容：" class="headerlink" title="下图为每个role的各个文件内容："></a>下图为每个role的各个文件内容：</h3><p>图一：参照roles的httpd的目录各个文件内容</p><p><img src="/2018/03/06/ansible/roles.png" alt="roles_memcached"></p><p>图二：参照roles的nginx的目录各个文件内容</p><pre><code>涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有    跨角色调用配置文件写法：   - name: copy index6  copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html</code></pre><p><img src="/2018/03/06/ansible/roles_nginx.png" alt="roles_nginx"><br>图三：参照roles的memcached的目录各个文件内容<br><img src="/2018/03/06/ansible/roles_memcached.png" alt="roles_memcached"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;a href=&quot;#运维自动化管理工具之Ansible&quot; class=&quot;headerlink&quot; title=&quot;运维自动化管理工具之Ansible&quot;&gt;&lt;/a&gt;运维自动化管理工具之Ansible&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2018/03/06/ansible/ansible.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="自动化运维" scheme="https://www.liukui.tech/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
    
      <category term="ansible,运维技术" scheme="https://www.liukui.tech/tags/ansible-%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>httpd</title>
    <link href="https://www.liukui.tech/2017/10/18/httpd/"/>
    <id>https://www.liukui.tech/2017/10/18/httpd/</id>
    <published>2017-10-18T00:00:00.000Z</published>
    <updated>2018-12-16T07:59:38.219Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>危栏倚遍都无寐，只恐星河堕入楼。 ——《秋夕楼居》吴融<br><a id="more"></a></p></blockquote><blockquote class="blockquote-center" color="#FF0000">Till I reach the end, then I’ll start again<br>《Try Everything》<br></blockquote><h1 id="This-is-an-H1"><a href="#This-is-an-H1" class="headerlink" title="This is an H1"></a>This is an H1</h1><ul><li>Red</li><li>Green</li><li>Blue<blockquote><p>This is a blockquote<br>inside a list item.</p></blockquote></li></ul><hr><p><a href="http://example.com/" target="_blank" rel="noopener">http://example.com/</a></p><ul><li>Red<br><code>aa</code></li></ul><h3 id="This-is-an-H2"><a href="#This-is-an-H2" class="headerlink" title="This is an H2"></a>This is an H2</h3><font size="3" color="#FF0000"> size定义字体大小，color定义颜色</font><br><font size="3" color="#70DB93"> size定义字体大小，color定义颜色</font><br><font size="3" color="#9F5F9F"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D9D919"> size定义字体大小，color定义颜色</font><br><font size="3" color="#FF7F00"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D98719"> size定义字体大小，color定义颜色</font><br><font size="3" color="#2ae0c8"> size定义字体大小，color定义颜色</font><br><font size="3" color="#fad8be"> size定义字体大小，color定义颜色</font><br><font size="3" color="#cbf5fb"> size定义字体大小，color定义颜色</font><br><font size="3" color="#acf6ef"> size定义字体大小，color定义颜色</font><br><font size="3" color="#D9D919"> size定义字体大小，color定义颜色</font><br><font size="3" color="#70DB93"> size定义字体大小，color定义颜色</font><br><font size="3" color="#BC8F8F"> size定义字体大小，color定义颜色</font><br><font size="3" color="#DB70DB"> size定义字体大小，color定义颜色</font><br><font size="3" color="#CFB53B"> size定义字体大小，color定义颜色</font><br><font size="3" color="#FF2400"> size定义字体大小，color定义颜色</font><br><font size="3" color="#CD7F32"> size定义字体大小，color定义颜色</font><br><font size="3" color="#23238E "> size定义字体大小，color定义颜色</font>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;危栏倚遍都无寐，只恐星河堕入楼。 ——《秋夕楼居》吴融&lt;br&gt;&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本三剑客" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>httpd2</title>
    <link href="https://www.liukui.tech/2017/10/18/httpd2/"/>
    <id>https://www.liukui.tech/2017/10/18/httpd2/</id>
    <published>2017-10-18T00:00:00.000Z</published>
    <updated>2018-12-17T13:25:13.986Z</updated>
    
    <content type="html"><![CDATA[<p><blockquote class="blockquote-center">Till I reach the end, then I’ll start again<br>《Try Everything》<br></blockquote><br><a id="more"></a></p><h3 id="HTTP协议和APACHE原理"><a href="#HTTP协议和APACHE原理" class="headerlink" title="HTTP协议和APACHE原理"></a>HTTP协议和APACHE原理</h3><p>Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等<br>本文说的是HTTP SERVER<a href="http://www.apache.org/" target="_blank" rel="noopener">apache</a></p><p>HTTP2.4的官方文档<a href="http://httpd.apache.org/docs/2.4/" target="_blank" rel="noopener">http2.4文档：安装，模块，指令等说明</a></p><h3 id="http协议-应用层协议-主流http-1-1版本"><a href="#http协议-应用层协议-主流http-1-1版本" class="headerlink" title="http协议:应用层协议,主流http/1.1版本"></a>http协议:应用层协议,主流http/1.1版本</h3><h4 id="http协议的版本区别"><a href="#http协议的版本区别" class="headerlink" title="http协议的版本区别"></a>http协议的版本区别</h4><p>http0.9、http1.0、http1.1和http2.0的版本区别</p><ul><li><p>http/0.9:</p><blockquote><p>只有一个GET命令，且只能回应<em>.html文件格式，像</em>.txt等都不支持</p></blockquote></li><li><p>http/1.0:效率太低</p><blockquote><p>1.支持cache, MIME(支持各种资源类型), method<br>2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低<br>3.引入了POST命令和HEAD命令，头部信息和<br>4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用</p></blockquote></li><li><p>http/1.1:主流使用版本</p><blockquote><p>1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭，<br>  对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性</p><pre><code>这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求</code></pre><p>2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率<br>3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)<br>4.缺点：<br>  同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象<br>5.解决队头堵塞的办法：<br>  为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等<br>6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度:</p><pre><code>不带状态怎么理解？http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点</code></pre></blockquote></li><li><p>http/2.0：解决 HTTP/1.1效率不高的问题</p><blockquote><p>1.头信息和数据体都是二进制，称为头信息帧和数据帧<br>2.和http1.1区别：请求不需要排队，提高效率<br>  复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）<br>3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度<br>4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息)</p></blockquote></li></ul><h3 id="HTTP工作机制"><a href="#HTTP工作机制" class="headerlink" title="HTTP工作机制"></a>HTTP工作机制</h3><ul><li>工作机制主要分为两步：请求和响应<blockquote><p>http请求：http request<br>http响应：http response<br>一次http事务：请求<-->响应</--></p></blockquote></li><li>Web资源：web resource<br>一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资<br>源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源<br>的集合<blockquote><p>静态文件：无需服务端做出额外处理;</p><pre><code>服务器端是什么样传到客户端就是什么样，比如下面这些比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi只不过浏览器有时会解析出来以好看的页面展示给用户</code></pre><p>动态文件：服务端执行程序，返回执行的结果</p><pre><code>服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果文件后缀：.php, .jsp ,.asp,.sh等将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户</code></pre></blockquote></li><li><p>提高HTTP连接性能</p><blockquote><p>并行连接：通过开多个TCP连接发起并发的HTTP请求<br>持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，<br>管道化连接：通过共享TCP连接发起并发的HTTP请求<br>复用的连接：交替传送请求和响应报文（实验阶段）</p></blockquote></li><li><p>HTTP协议的其他相关技术</p></li><li><p>1.URI：一般把URI认为是URL<br>URI: Uniform Resource Identifier 统一资源标识，分为URL和URN</p><blockquote><p>1.URN: Uniform Resource Naming，统一资源命名</p><pre><code>如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名</code></pre><p>2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置</p><pre><code>如输入一个网址，能具体体现出这个资源在互联网上的位置</code></pre><p>两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址</p></blockquote></li><li><p>URL的组成<br><scheme>://<user>:<password>@<host>:<port>/<path></path>;<params>?<query>#<frag></frag></query></params></port></host></password></user></scheme></p><blockquote><p>scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等<br>user:用户，某些方案访问资源时需要的用户名<br>password:密码，用户对应的密码，中间用：分隔<br>Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析<br>port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080<br>/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔<br>params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对<br>query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能<br>frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔</p></blockquote></li><li><p>网站访问量</p><blockquote><p>1.IP(独立IP)：即Internet Protocol,指独立IP数。</p><pre><code>如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个</code></pre><p>2.PV(访问量)： 即Page View, </p><pre><code>页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量一般为了博客为了好看的访问量，都是统计PV量</code></pre><p>3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。</p><pre><code>网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1</code></pre></blockquote></li></ul><h3 id="Web服务请求处理步骤"><a href="#Web服务请求处理步骤" class="headerlink" title="Web服务请求处理步骤"></a>Web服务请求处理步骤</h3><p>很切合实际生活：比如<br>当我们打开一个浏览器，输入一个<a href="http://www.taobao.com，在互联网后台发生了什么？" target="_blank" rel="noopener">www.taobao.com，在互联网后台发生了什么？</a><br>这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图<br><img src="/2017/10/18/httpd2/" alt="web请求步骤"></p><p>当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程<br>每个过程都是一段需要原理详细描述的.</p><h4 id="一次完整的http请求处理过程"><a href="#一次完整的http请求处理过程" class="headerlink" title="一次完整的http请求处理过程"></a>一次完整的http请求处理过程</h4><pre><code>1.建立连接：接收或拒绝连接请求2.接收请求：接收客户端请求报文中对某资源的一次请求的过程Web访问响应模型（Web I/O）    单进程I/O模型：访问量不大        启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应        会造成请求排队现象，只适用于访问并发不大的情况    多进程I/O模型：        系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求        如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点        而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的    复用I/O结构：        开启多个进程进程，而一个进程又同时监控N个连接请求        只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗        实现方法：多线程模型和事件驱动        多线程模型：一个进程生成N个线程，每线程响应一个连接请求        事件驱动：一个进程处理N个请求    复用的多进程I/O模型：        启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求        充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的        nginx使用的复用多进程I/O模型</code></pre><font size="3" color="#FF0000"><br>    1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求<br>    2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应<br>    避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费<br>    同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题<br></font><p><img src="/2017/10/18/httpd2/" alt="web访问响应四种模型"><br>参考下面的HTTP的MPM三种工作模式<a href=""></a></p><pre><code>3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理    分析元数据：请求报文首部信息获得method    &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt;    HEADERS 格式 name:value    &lt;request body&gt;    通过method来响应用户请求，比如下载(get)，上传等信息    HTTP常用请求方式，Method        GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS4.访问资源：    服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源    在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件    web服务器资源路径映射方式：        (a) docroot        (b) alias        (c) 虚拟主机docroot        (d) 用户家目录docroot5.构建响应报文：    一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体   1）响应实体        描述了响应主体MIME类型的Content-Type首部        描述了响应主体长度的Content-Length   2）URL重定向        web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径   3）MIME类型   当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文    将构建完的响应报文发送给用户    将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户    用户再层层解封装获得index.html的内容7.记录日志    最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务    通过在/var/log/httpd/acess_log日志中记录http的响应记录数    方便分析日志统计该网站的IP，PV量等信息</code></pre><h3 id="HTTP介绍"><a href="#HTTP介绍" class="headerlink" title="HTTP介绍"></a>HTTP介绍</h3><p>特性：<br>高度模块化：core + modules<br>DSO: Dynamic Shared Object 动态加/卸载<br>MPM：multi-processing module多路处理模块</p><h4 id="HTTP的三种工作模型：MPM工作模式"><a href="#HTTP的三种工作模型：MPM工作模式" class="headerlink" title="HTTP的三种工作模型：MPM工作模式"></a>HTTP的三种工作模型：MPM工作模式</h4><font size="3" color="#FF0000"><br>多用途的处理模块，三种模型分别是，默认使用prefork模型<br>因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型<br></font><p>可以参考Web访问响应模型（Web I/O）<a href="">HTTP原理</a></p><ul><li>1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型<br>  一个主进程：生成和回收n个子进程，创建套接字，不响应请求<br>  多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个，消耗比较大内存资源</li><li>2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型<br>  一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性<br>  缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！</li><li>3.event：事件驱动模型（worker模型的优化,worker模型的变种）<br>  event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用<br>  一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n<br>  相比较worker的有点：<br>  有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的请求处理能力</li></ul><h4 id="进程工作的角色切换"><a href="#进程工作的角色切换" class="headerlink" title="进程工作的角色切换"></a>进程工作的角色切换</h4><h3 id="Httpd的功能特性"><a href="#Httpd的功能特性" class="headerlink" title="Httpd的功能特性"></a>Httpd的功能特性</h3><p>httpd的常见特性：</p><ul><li>虚拟主机：在一个物理服务器上搭建多个网站<br>  IP、Port、FQDN</li><li>CGI：Common Gateway Interface，通用网关接口<br>  通过CGI接口处理动态的程序处理</li><li>反向代理<br>  当有用户访问量大时，在前端有一个服务器充当调度器的角色<br>  通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息<br>  看不到后端真正提供服务的服务器群</li><li>负载均衡</li><li>路径别名</li><li>丰富的用户认证机制<br>  basic<br>  digest</li><li>支持第三方模块</li></ul><h3 id="Httpd2-4新特性和安装以及配置"><a href="#Httpd2-4新特性和安装以及配置" class="headerlink" title="Httpd2.4新特性和安装以及配置"></a>Httpd2.4新特性和安装以及配置</h3><pre><code>新特性    MPM支持运行为DSO机制；以模块形式按需加载        在centos7上的httpd2.4上只有一个二进制程序            /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可        但是在centos6上的httpd2.2版本：            每个MPM模式都有各自对应的二进制程序                /usr/sbin/httpd                /usr/sbin/httpd.event                /usr/sbin/httpd.worker            如果更改MPM的模式，是需要改对应的二进制程序的    event MPM生产环境可用    异步读写机制    支持每模块及每目录的单独日志级别定义    每请求相关的专用配置    增强版的表达式分析式    毫秒级持久连接时长定义：httpd2.2只能精确到秒级别        上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的        所以在http中是可以定义连接时长(时长和传输请求两种方式)的    基于FQDN的虚拟主机不需要NameVirutalHost指令        httpd2.2创建虚拟主机时还需要NameVirutalHost指令        httpd2.4就不需要了    新指令，AllowOverrideList    支持用户自定义变量    更低的内存消耗</code></pre><h3 id="Httpd2-4的具体安装和配置"><a href="#Httpd2-4的具体安装和配置" class="headerlink" title="Httpd2.4的具体安装和配置"></a>Httpd2.4的具体安装和配置</h3><p>Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了<br>还支持第三方的模块，按需加载模块<br>存放模块的路径：/etc/httpd/modules</p><pre><code>CentOS7程序环境安装：httpd-2.4    yum install httpd     yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档主要配置文件：    /usr/sbin/httpd     httpd的主程序文件    /usr/lib/systemd/system/httpd.service   httpd的启动单元文件    /etc/httpd/conf/httpd.conf              主要配置文件        配置文件里的路径都是以/etc/httpd/为参考点的    /etc/httpd/conf.d/*.conf    /etc/httpd/conf.modules.d/00-mpm.conf    mpm相关    /etc/httpd/conf.modules.d/00-proxy.conf  配置代理相关    /etc/httpd/conf.modules.d/00-systemd.conf     /etc/httpd/conf.modules.d/01-cgi.conf    CGI相关    /var/cache/httpd    httpd的缓存目录    /var/log/httpd      httpd的日志文件目录            access_log: 访问日志            error_log：错误日志    /etc/httpd/modules  httpd的模块存放路径，软件比较复杂    /usr/lib64/httpd/modules   也是httpd的模块存放路径        两个模块的路径实际上是软链接关系    /var/www/html       httpd存放网页的目录：默认index.html帮助文档包：在没有网络时查看帮助文档，建议安装    httpd-manual检查配置文件语法：    httpd –t    类似DNS的rndc语法检查功能    sudo：visudo功能    ansible:ansible -C|--check 执行前检查语法功能    cobbler 也有httpd的控制和启动命令    systemctl enable|disable httpd.service    systemctl {start|stop|restart|status|reload} httpd.service    备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作        有时reload是无效的，只能restart服务</code></pre><h3 id="Httpd2-4的常见配置"><a href="#Httpd2-4的常见配置" class="headerlink" title="Httpd2.4的常见配置"></a>Httpd2.4的常见配置</h3><ul><li><p>1.显示服务器版本信息HTTP2.4官方指令参考文档<a href="http://httpd.apache.org/docs/2.4/mod/quickreference.html" target="_blank" rel="noopener">指令参考文档</a></p><p>  主要组成:</p><pre><code>Global Environment   全局配置Main server configuration   一个服务器上搭建一个网站叫主服务器virtual host   虚拟主机，一台主机上搭建多个网站</code></pre></li></ul><p>练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)<br>egrep -v ‘^ <em>#.</em>|^$’ /etc/httpd/conf/httpd.conf</p><font size="3" color="#FF0000"><br>常见配置一般都在/etc/httpd/conf/httpd.conf的文件中<br>没有的配置选项可以加在httpd.conf文件最后，也可以放在<br>/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf<br>下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加<br></font><ul><li>1.显示服务器版本信息<br>  访问<a href="http://192.168.34.103" target="_blank" rel="noopener">http://192.168.34.103</a><br>  打开f12调试模式，可以看到回应头的信息中带有apache的版本信息<br>  也可以通过curl -I <a href="http://192.168.34.103来显示头信息" target="_blank" rel="noopener">http://192.168.34.103来显示头信息</a><br>  可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全<br>  查看指令参考文档：修改ServerTokens选项<pre><code>建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全</code></pre></li><li><p>2.修改监听的IP和Port<br>  Listen [IP:]PORT<br>  (1) 省略IP表示为本机所有IP<br>  (2) Listen监听端口至少一个，可以有多个端口<br>  (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口</p><pre><code>test.conf添加listen端口：listen 172.18.132.151:6666 6666端口只能通过此IP才能访问</code></pre></li><li><p>3.持久连接：默认KeepAlive是开启的<br>  Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接<br>  断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级<br>  副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞<br>  折衷：使用较短的持久连接时间</p><pre><code>设置：    KeepAlive On|Off       设置持久连接开启或者关闭    KeepAliveTimeout 15    设置持久连接为15s测试：telnet WEB_SERVER_IP PORT    GET /index.html HTTP/1.1    Host: WEB_SERVER_IP  host可以随便填写，但是在虚拟主机中是有区别的</code></pre></li><li><p>4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event<br>  默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf  修改mpm的文件<br>  建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的<br>  查看静态编译的模块<br>  httpd -l<br>  查看当前系统中httpd的静态编译及动态装载的加载的模块<br>  httpd –M<br>  动态模块加载：不需重启即生效<br>  动态模块路径<br>   /usr/lib64/httpd/modules/</p><pre><code>切换使用的MPM模块    在/etc/httpd/conf.modules.d/00-mpm.conf中    选择要启用的MPM相关的LoadModule指令即可prefork的配置：    StartServers 8               MinSpareServers 5       保留5个空闲子进程处理新的请求    MaxSpareServers 20      允许的最大空闲进程数    ServerLimit 256         最多进程数,最大20000，并发量建议最多10000         MaxRequestsPerChild     4000 子进程最多能处理的请求数量。在处理    MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进    程占用的内存就会释放(为0时永远不释放）worker和prefork配置类似，只不过会有线程数量的限制</code></pre></li><li><p>5.DSO： Dynamic Shared Object<br>  加载动态模块配置<br>  /etc/httpd/conf/httpd.conf<br>  Include conf.modules.d/*.conf<br>  配置指定实现模块加载格式：<br>  LoadModule &lt;mod_name&gt; &lt;mod_path&gt;<br>  模块文件路径可使用相对路径：<br>  相对于ServerRoot（默认/etc/httpd）</p></li><li><p>6.定义’Main’ server的文档页面路径：存放页面的主目录<br>  主目录是由DocumentRoot指令来设置的<br>  网页文件默认是存在/var/www/html/下的，此处可以自定义<br>  在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html”</p><pre><code>如果要自定义主目录，还需要设置该目录为允许访问在httpd2.2上是不需要设置权限访问的但是在httpd2.4上是需要设置该目录允许访问的修改格式如下：#DocumentRoot &quot;/var/www/html&quot;DocumentRoot &quot;/data/www&quot;&lt;directory /data/www&gt;    Require all granted&lt;/directory&gt; </code></pre></li><li><p>7.定义站点默认主页面<br>  访问192.168.34.103默认显示的是index.html的内容，<br>  这一项是由DirectoryIndex指令设置的</p><pre><code>在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件</code></pre></li><li><p>8.站点访问控制常见机制<br>  可基于两种机制指明对哪些资源进行何种访问控制<br>  访问控制机制有两种：1.客户端来源地址，2.用户账号<br>  而文件系统路径：可以是<br>  1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配<br>  示例：<br>  ‘<filesmatch "\.(gif|jpe?g|png)$"="">‘’   用的是扩展的正则表达式<br>  <files “?at.*”="">                     通配符<br>  &lt;Location /status&gt;</files></filesmatch></p>  <locationmatch "="" (extra|special)="" data"=""></locationmatch></li><li><p>9.<directory>中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制<br>   (1) Options：后跟1个或多个以空白字符分隔的选项列<br>  在选项前的+，- 表示增加或删除指定选项<br>  常见选项：<br>  Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制<br>  适用于下载网站和镜像网站，不适合电商网站<br>  FollowSymLinks：允许访问符号链接文件所指向的源文件,<br>  None：全部禁用<br>  All： 全部允许</directory></p><pre><code>Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站    &lt;directory &quot;/data/www&quot;&gt;    options Indexes                                              Require all granted    &lt;/directory&gt;FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件    &lt;directory &quot;/data/www&quot;&gt;    options Indexes  FollowSymLinks           Require all granted    &lt;/directory&gt;</code></pre><font size="4" color="#FF0000"><br>实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.html页面，welcome.html文件就是页面上经常看到的测试123页面，把welcome.html文件改名或删除，就会显示主目录下的所有列表文件了.<br></font><p>  (2) AllowOverride<br>  allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可<br>  只对<directory>语句有效;<br>  allowoverride权限时卸载httpd的*.conf配置文件中的<br>  AllowOverride All: .htaccess中所有指令都有效<br>  AllowOverride None： .htaccess 文件无效<br>  AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它</directory></p><pre><code>配置allowoverride示例：/etc/httpd/conf.d/test.conf中添加访问控制的目录    &lt;directory /data/www&gt;    allowoverride all  --&gt;这条必须写，代表.htaccess文件中的options生效    Require all granted    &lt;/directory&gt;在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中    options indexes FollowSymLinks</code></pre><p>  (3) 基于IP的访问控制:<br>  无明确授权的目录，默认拒绝<br>  允许所有主机访问：Require all granted<br>  拒绝所有主机访问：Require all denied<br>  控制特定的IP访问：<br>  Require ip IPADDR：授权指定来源的IP访问<br>  Require not ip IPADDR：拒绝特定的IP访问<br>  控制特定的主机访问：<br>  Require host HOSTNAME：授权特定主机访问<br>  Require not host HOSTNAME：拒绝<br>  HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机</p><pre><code>基于IP的访问控制示例：如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表除了/data/www/ceshi文件夹    &lt;directory /data/www&gt;    options indexes                                                      &lt;RequireAll&gt;    Require all granted    Require not ip 192.168.34.107    &lt;/RequireAll&gt;    &lt;/directory&gt;2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问&lt;directory /data/www&gt;options indexesRequire all granted&lt;/directory&gt;&lt;directory /data/www/ceshi&gt;&lt;RequireAny&gt;Require all deniedRequire ip 192.168.34.107&lt;/RequireAny&gt;                                                 &lt;/directory&gt;</code></pre></li><li><p>10.日志设定：日志默认/var/log/httpd/下<br>  日志类型：访问日志(access_log)和错误日志(error_log)<br>  在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径<br>  CustomLog “logs/access_log”<br>  ErrorLog “logs/error_log”<br>  可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径<br>  而</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;blockquote class=&quot;blockquote-center&quot;&gt;Till I reach the end, then I’ll start again&lt;br&gt;《Try Everything》&lt;br&gt;&lt;/blockquote&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本处理工具" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>文本三剑客之awk</title>
    <link href="https://www.liukui.tech/2017/10/18/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk/"/>
    <id>https://www.liukui.tech/2017/10/18/文本三剑客之awk/</id>
    <published>2017-10-17T16:00:00.000Z</published>
    <updated>2018-08-31T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文本处理三剑客之awk"><a href="#文本处理三剑客之awk" class="headerlink" title="文本处理三剑客之awk"></a>文本处理三剑客之awk</h1><p><img src="/2017/10/18/文本三剑客之awk/awk.png" alt=""><br><a id="more"></a></p><p>Awk的用户使用指南<a href="http://www.gnu.org/software/gawk/manual/gawk.html" target="_blank" rel="noopener">awk用户指南</a></p><p>相关链接文章：<br>正则表达式： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">正则表达式</a><br>grep文本编辑： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">grep用法</a><br>sed文本编辑： <a href="https://www.jianshu.com/p/4a0d64bf615f" target="_blank" rel="noopener">sed用法</a></p><h3 id="总结对比一下这三个剑客的特长之处"><a href="#总结对比一下这三个剑客的特长之处" class="headerlink" title="总结对比一下这三个剑客的特长之处"></a>总结对比一下这三个剑客的特长之处</h3><p>grep、sed、awk被称为linux中的三剑客</p><p>grep更适合单纯的查找或匹配文件.<br>sed更适合编辑皮匹配到的文本<br>awk更适合格式化文本，对文本进行比较复杂格式处理</p><p>文本三剑客都是默认逐行处理，自带循环<br>sed 可以对文本进行修改，而grep&amp;awk 只是对文本进行过滤,不进行内容修改</p><p>awk中的-F后面的分隔符,要用单引号’’,双引号””会产生弱引用,比如特殊符号’\\‘ ‘\\$’<br>关于awk中的单引号和双引号的问题参照：<a href="https://blog.csdn.net/swinfans/article/details/82991077" target="_blank" rel="noopener">awk中的输入分隔符单引号&amp;双引号</a></p><p>学习awk的一个重要知识点</p><pre><code>先举两个例子：awk &apos;/^UUID/&apos; /etc/fstab = awk &apos;/^UUID/{print $0}&apos; /etc/fstab 其实是隐藏了{print $0}的写法数组中的例子awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6实际上是隐藏了{print $0}</code></pre><h3 id="学习中遇到的混淆的问题："><a href="#学习中遇到的混淆的问题：" class="headerlink" title="学习中遇到的混淆的问题："></a>学习中遇到的混淆的问题：</h3><pre><code>&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印而后面的数组里的是加了双括号{}，即用的patter的空模式，即文本中的每一行都处理</code></pre><hr><hr><h2 id="Awk"><a href="#Awk" class="headerlink" title="Awk"></a>Awk</h2><p>基本用法和功能以及各个功能示例：<br>awk介绍<br>awk基本用法<br>awk变量<br>awk格式化-printf<br>awk操作符<br>awk条件判断<br>awk循环<br>awk数组<br>awk函数<br>调用系统命令</p><hr><hr><h3 id="awk介绍："><a href="#awk介绍：" class="headerlink" title="awk介绍："></a>awk介绍：</h3><pre><code>whatis awk？awk：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出，输出成报表格式linux上默认使用 GNU awk(gawk)[root@centos7 data]which awk/usr/bin/awk[root@centos7 data]ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Sep 19 11:45 /usr/bin/awk -&gt; gawkwhich awk=/usr/bin/awk 是gawk的软链接 </code></pre><hr><hr><h3 id="awk基本用法"><a href="#awk基本用法" class="headerlink" title="awk基本用法"></a>awk基本用法</h3><pre><code>awk [options] &apos;program&apos; var=value file…awk [options] -f programfile var=value file…awk [options] &apos;BEGIN{action;… }pattern{action;… }END{action;… }&apos; file ...awk 程序可由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块，共3部分组成program 通常是被放在单引号中 选项：    -F “分隔符” 指明输入时用到的字段分隔符    -v var=value 变量赋值基本格式：awk [options] &apos;program&apos; file…         Program：pattern{action statements;..}也就是说awk用法：awk [options] &apos;pattern{action statements;..}&apos; file…    pattern和action    • pattern部分决定动作语句何时触发及触发事件    BEGIN,END    • action statements对数据进行处理，放在{}内指明print, printf分割符、域和记录    • awk执行时，由分隔符分隔的字段（域）标记$1,$2...$n称为域标识。$0    为所有域，注意：此时和shell中变量$符含义不同    • 文件的每一行称为记录    • 省略action，则默认执行 print $0 的操作print格式：print item1, item2, ...    要点：    (1) 逗号分隔符    (2) 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式    (3) 如省略item，相当于print $0</code></pre><h3 id="用法解析及示例："><a href="#用法解析及示例：" class="headerlink" title="用法解析及示例："></a>用法解析及示例：</h3><pre><code>$0=代表处理的整行的内容$1,$2,$3..代表每一列，也就域BEGIN，END是为生成一个报表的头和尾准备的，用法通常为：BEGIN：为生成报告模式 添加表头;END:为生成的报告 进行信息汇总awk &apos;BEGIN{print xxx}{print xxx}END{print xxx}&apos;注意：BEGIN{print *xxx}处理文本前，打印一遍xxx的内容当成表头     END{print xxx},处理文本后，打印一遍xxx的内容作为表尾</code></pre><h2 id="BEGIN-amp-END"><a href="#BEGIN-amp-END" class="headerlink" title="BEGIN&amp;END"></a>BEGIN&amp;END</h2><pre><code>BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。END：让用户在最后一条输入记录被读取之后发生的动作。</code></pre><h2 id="分隔符："><a href="#分隔符：" class="headerlink" title="分隔符："></a>分隔符：</h2><pre><code>awk默认使用空白符作为字段或列的分隔符；多个空白符被认为是一个，空白符包括空格，tab键/t，回车\n也可以自定义-F&quot;分隔符&quot;自定义分隔符</code></pre><h3 id="print-amp-printf的区别："><a href="#print-amp-printf的区别：" class="headerlink" title="print&amp;printf的区别："></a>print&amp;printf的区别：</h3><pre><code>print命令只是单纯的把特定的内容进行打印，默认换行printf命令可以把内容以灵活的格式进行显示,如左对齐,右对齐</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre><code>1.awk支持标准输入输出，后面可以不跟文件[root@centos7 ~]#awk &apos;{print $0}&apos;aaaaaaaaabcabcabcabc2.打印/etc/passwd：对比几个输出结果awk &apos;{print $0}&apos; /etc/passwd 把passwd文件全部打印出来awk &apos;{print &quot;abc&quot;}&apos; /etc/passwd   读入的是passwd文件所有行，打印的是abcawk -v abc=1 &apos;{print abc}&apos; /etc/passwd  读入的是passwd文件所有行，打印的都是1awk &apos;{print &quot;abc&quot;$0}&apos; /etc/passwd 把passwd文件所有行前都加一个abc,进行输出所以在awk中不加双引号，abc被识别为变量，如果要引用变量，需要-v先定义值如果只是想输出abc字符串，需要加双引号3.awk{}中支持数字运算awk &apos;{print 1+2}&apos; /etc/passwd 打印多行1+2=3的值awk &apos;{print &quot;1+2&quot;}&apos; /etc/passwd 加双引号会把1+2当成字符串，输出多行1+24.取分区利用率df,df |awk &apos;{print $1,$5}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos;5.以输入重定向方式，打印 passwd 文件的第1列，即获取当前系统中存在的所有用户和UIDawk -F: &apos;{print $1,$3}&apos; &lt; /etc/passwdcat /etc/passwd | awk -F: &apos;{print $1,$3}&apos;awk -F: &apos;{print $1：$3}&apos;  /etc/passwd  两列输出时，指定以：进行隔开，默认为空格隔开awk -F: &apos;{print $1、$3}&apos;  /etc/passwd  两列输出时，指定以：进行隔开，默认为空格隔开cat /etc/passwd | awk -F: &apos;{print $1&quot;\n&quot; $3}&apos; 两列输出时,进行换行cat /etc/passwd | awk -F: &apos;{print $1&quot;\t&quot; $3}&apos; 两列输出时,以tab键隔开备注：多行输出时，可以在双引号之间加自定义的分隔符格式：awk -F: &apos;{print $1&quot;=======&quot;$3}&apos;  /etc/passwd </code></pre><hr><hr><h2 id="Awk中的变量："><a href="#Awk中的变量：" class="headerlink" title="Awk中的变量："></a>Awk中的变量：</h2><h3 id="变量分为：内置变量和自定义变量"><a href="#变量分为：内置变量和自定义变量" class="headerlink" title="变量分为：内置变量和自定义变量"></a>变量分为：内置变量和自定义变量</h3><pre><code>awk中的内置变量除了$0,$1,$2等，还有以下几种；如果要使用这些变量需要加-v 选项先进行定义FS：输入字段分隔符，默认为空白字符  =filed separator=域或列的分隔符等于-F的选项，-F是选项，而FS是变量，实际作用是相等的与-F的区别在于：可以下次调用FS变量awk -v FS=&apos;:&apos; &apos;{print $1,$3}&apos; /etc/passwd  = awk -F:&apos;{print $1,$3}&apos; /etc/passwdawk -v FS=&apos;:&apos; &apos;{print $1,FS$3}&apos; /etc/passwd  两列输出时以：做分隔符，调用变量FSawk -v FS=&apos;:&apos; &apos;{print $1,FS FS$3}&apos; /etc/passwd  两列输出时以：：做分隔符，调用2次变量FS 以空格隔开可以先定义shell中的变量fs=:,awk再进行调用fs=:;awk -v FS=$fs &apos;{print $1,FS,$3}&apos; /etc/passwd  fs=:;awk –F$fs &apos;{print $1,$3,$7}&apos; /etc/passwdOFS：输出字段分隔符，默认为空白字符 =output filed separator定义输出分隔符，不指定默认空空格做分隔符awk -v FS=: -v OFS=+++ &apos;{print $1,$3,$7}&apos; /etc/passwdfs=+++;awk -v FS=: -v OFS=$fs &apos;{print $1,$3}&apos; /etc/passwd  调用shell变量做输出分隔符RS：输入记录分隔符，指定输入时的换行符,自定义行的分隔符 =record记录默认一行叫记录，行是以\n回车作为切割符的，RS可以自定义不用回车作为分隔符    awk -v RS=&apos; &apos; ‘{print }’ /etc/passwd    awk -v RS=&apos;:&apos; &apos;{print NR,$0}&apos;/etc/passwd     [root@centos7 ~]cat f1    aa;xxx:bb;bzzzz:cc    dd:eex;zccc:xxxx    [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print $0}&apos;    aa;xxx    bb;bzzzz    cc    dd    eex;zccc    xxxx    以RS=：冒号自定义行的分隔符，输出结果如上    [root@centos7 ~]#cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; &apos;{print $1}&apos;    aa    bb    cc    dd    eex    xxxx    自定义FS&amp;RS，输出结果如上ORS：输出记录分隔符，输出时用指定符号代替换行符 awk -v RS=&apos; &apos; -v ORS=&apos;###&apos;‘{print }’ /etc/passwd[root@centos7 ~]cat f1aa;xxx:bb;bzzzz:ccdd:eex;zccc:xxxx[root@centos7 ~]cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; -v ORS&quot;===&quot; &apos;{print $1}&apos;aa==bb==ccdd==eex==xxxx==自定义FS,RS,ORS结果很明显接下来是一个比较重要的变量NF：字段数量,也就是域或列的总数量awk -F: &apos;{print NF}&apos; /etc/passwd 以冒号做分隔符，显示每行的列的总数量awk -F: &apos;{print $NF}&apos; /etc/passwd 显示以冒号做分隔符，每一行的最后一个字段即bash类型awk -F：&apos;{print $(NF-1)}&apos; /etc/passwd 显示以冒号做分隔符，每一行的倒数第二个字段统计光盘中所有安装包适用的cpu架构类型root@centos7 mnt]#ls /mnt/Packages/*.rpm | awk -F&quot;.&quot; &apos;{print $(NF-1)}&apos;|sort|uniq -c   1371 noarch   2600 x86_64NR：记录号，可以显示行数，如果有多个文件会合并后再统计总行awk &apos;{print NR,$0}&apos; /etc/fstab 在每一行前加一个行号awk BEGIN&apos;{print NR}&apos; /etc/fstab 输出结果为0  awk还没开始处理行，所以记录为0awk END&apos;{print NR}&apos; /etc/fstab  输出结果为12 可以看出END是统计,awk处理的行数1.通过加行号，可以很明显看出以冒号作为行的分隔符，每一行的都有什么；可以看出cc dd是一行的[root@centos7 ~]cat f1aa;xxx:bb;bzzzz:ccdd:eex;zccc:xxxx[root@centos7 ~]cat f1| awk  -v RS=&quot;:&quot; &apos;{print NR$0}&apos;1aa;xxx2bb;bzzzz3ccdd4eex;zccc5xxxx2.备注：如果awk跟两个文件，awk会把两文件合并成一个文件，统计总行数，都取第一个字段的信息如果需要分开显示统计，则用FNR[root@centos7 ~]awk -F: &apos;{print NR,$1}&apos; /etc/passwd /etc/group1 root2 bin3 daemon4 admFNR：各文件分别计数,记录号1.FNR:多个文件，每个分别统计显示第一个字段并列出来awk &apos;{print FNR}&apos; /etc/fstab /etc/inittab[root@centos7 ~]awk -F: &apos;{print FNR,$1}&apos; /etc/passwd /etc/group1 root2 bin3 daemon48 quagga49 httpd1 root2 binFILENAME：当前文件名1.统计时，加上变量可以显示文件名awk &apos;{print FILENAME}&apos; /etc/fstab[root@centos7 ~]awk -F: &apos;{print FILENAME,FNR,$1}&apos; /etc/passwd /etc/passwd 1 root/etc/passwd 2 bin/etc/passwd 3 daemonARGC：命令行参数的个数awk &apos;{print ARGC}&apos; /etc/fstab /etc/inittab 结果为3awk &apos;BEGIN {print ARGC}&apos; /etc/fstab /etc/inittab 结果为3ARGC统计参数：awk单独算一个参数，后面的每个文件算一个参数,通过下面的数组可以体现出来ARGV：数组，保存的是命令行所给定的各参数1.显示awk的每个参数分别是哪个[root@centos7 ~]awk &apos;{print ARGV[0]}&apos; /etc/fstab /etc/inittabawk[root@centos7 ~]awk &apos;{print ARGV[1]}&apos; /etc/fstab /etc/inittab/etc/fstab</code></pre><h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><pre><code>1.统计当前网络连接情况的ip地址是 ss -ntss -nt | awk &apos;{print $5}&apos;2.取/var/log/httpd/access_log的时间如下：root@centos7 ~]cat /var/log/httpd/access_log192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; 分两步取：cat /var/log/httpd/access_log | awk &apos;{print $4}&apos;|awk -F&quot;[&quot; &apos;{print $2}&apos;一步取：cat /var/log/httpd/access_log | awk -F &quot;[\[ ]&quot; &apos;{print $5}&apos;原理分析：[\[ ]代表（转义）\[和空格都算是分隔符，正则表达式的写法,或的关系，而以空格分隔符，时间段为$4,那为什么是$5?在空格的标准里，[算$4,所以时间段为$53.取出磁盘分区利用率 -这次只取出利用率两步取出：df | awk -F% &apos;{print $1}&apos;|awk &apos;{print $5}&apos;一步取出：df | awk -F&quot;[[:space:]]+|%&quot; &apos;{print $5}&apos; awk用的是扩展的正则表达式面试题：3-1,取出fstab中挂载的目录[root@centos7 ~]cat /etc/fstab # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=9612633f-e7f1-4b28-8813-403d209d7abc /                       xfs     defaults        0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot                   xfs     defaults        0 0UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data                   xfs     defaults        0 0UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap                    swap    defaults        0 0[root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos;bootdataswap或者[root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos;bootdataswap4.面试题：将文件f3中的第一个点前的字符串取出再写进去[root@centos7 ~]cat f31 test.sina.com.cn2 music.sina.com.cn3 sports.sina.com.cn4.news.sina.com.cn[root@centos7 ~]cat f3 | awk -F&quot;[ .]&quot; &apos;{print $2}&apos; &gt;&gt; f3[root@centos7 ~]cat f31 test.sina.com.cn2 music.sina.com.cn3 sports.sina.com.cn4.news.sina.com.cntestmusicsportsnews4-1,扩展前面-F&quot;[ .]&quot;既然是表达或的意思，那么是否可以这么写-F&quot;[ ]|.&quot;？？？答案：不可以！原因：因为此处用的是正则表达式，在正则表达式中点(.)代表任意单个字符，会把空格后的字母当成分隔符！所以是不可以的，那么如何写？如果不是点而是%呢？%是可以的，因为在正则表达式中%就是代表%，但是$,或其他在正则表达式中有特殊含义的不可以作为分隔符，如果一定要做分隔符，需要反斜线转义如下：此处用3个反斜线转义[root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\.&quot; &apos;{print $2}&apos;testmusicsportsnews那如果文本中的第一个点是$呢？此处是4个反斜线进行转义[root@centos7 ~]cat f21 test$sina.com.cn2 music$sina.com.cn3 sports$sina.com.cn4 news$sina.com.cn[root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\\$&quot; &apos;{print $2}&apos;testmusicsportsnews[root@centos7 ~]cat f2 | awk -F&quot;[ $]&quot; &apos;{print $2}&apos;testmusicsportsnews当用一个空格和具有特殊含义的符号时，最好是写在中括号[]里的</code></pre><h3 id="AWK中自定义变量"><a href="#AWK中自定义变量" class="headerlink" title="AWK中自定义变量"></a>AWK中自定义变量</h3><pre><code>自定义变量(区分字符大小写)(1) -v var=value(2) 在program中直接定义(2-1)program可以放到一个文本里,awk -f 直接调用即可</code></pre><h5 id="示例：-1"><a href="#示例：-1" class="headerlink" title="示例："></a>示例：</h5><pre><code>自定义变量可以-v var定义，也可以放到program即{}里，变量要先定义，后使用awk -F:  &apos;{name=&quot;magedu&quot;;print $1,name}&apos; /etc/passwdawk -F: -v name=&quot;magedu&quot; &apos;{print $1,name}&apos; /etc/passwd例如cat awk.txt{print $1,$2,$6}awk -F： -f awk.txt /etc/passwd =awk -F: &apos;{print $1,$2,$6}&apos; /etc/passwd</code></pre><hr><hr><h3 id="Awk中的格式化"><a href="#Awk中的格式化" class="headerlink" title="Awk中的格式化"></a>Awk中的格式化</h3><p>在介绍printf前，先对其进行总结：<br>1.使用printf动作输出的文本不会换行，如果需要换行，可以在对应的格式替换符后加入”\n”进行转义<br>2.使用printf动作时，指定的格式和被格式化的文本之间，需要用”逗号”隔开。<br>3.使用printf动作时，格式中的格式替换符比喻与被格式化的文本一一对应</p><h4 id="printf命令-类似于shell里的printf"><a href="#printf命令-类似于shell里的printf" class="headerlink" title="printf命令-类似于shell里的printf"></a>printf命令-类似于shell里的printf</h4><pre><code>printf命令可以把内容以灵活的格式进行显示，如左对齐,右对齐格式化输出：printf &quot;FORMAT&quot;, item1, item2, ...(1) 必须指定FORMAT(2) 不会自动换行，需要显式给出换行控制符，\n(3) FORMAT中需要分别为后面每个item指定格式符格式符：与item一一对应%c：显示字符的ASCII码%d, %i：显示十进制整数   -用的比较多%e, %E：显示科学计数法数值%f：显示为浮点数%g, %G：以科学计数法或浮点形式显示数值%s：显示字符串  -用的比较多%u：无符号整数 -用的比较多%%：显示%自身修饰符#[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f+ 左对齐（默认右对齐） %-15s* 显示数值的正负符号 %+d</code></pre><h4 id="printf示例："><a href="#printf示例：" class="headerlink" title="printf示例："></a>printf示例：</h4><pre><code>1.设置对齐格式以及字符数[root@centos7 ~]awk -F: &apos;{printf &quot;%-20s %-5d\n&quot;,$1,$3}&apos; /etc/passwdroot                 0    bin                  1       pulse                171  gdm                  42   gnome-initial-setup  990  $1为字符串，所以设置左对齐为20s个字符，$3为数字所以设置左对齐为5d个字符printf默认不换行，所以需要加一个换行符  2.打印一个完整的报表格式root@centos7 ~]awk -F: &apos;BEGIN{print &quot;username   |uid\n--------&quot;}{printf &quot;%-10s |%-5d\n&quot;,$1,$3}END{print &quot;-------------&quot;}&apos; /etc/passwdusername             |uid-----------------------root                 |0    bin                  |1    daemon               |2 memcached            |987  ceshi                |1009 quagga               |92   httpd                |80   -------------------------awk生成报表格式大概就是这个样子，所以awk称为报表生成器3.[root@centos7 ~]awk -F: &apos;{printf &quot;Username: %s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwdUsername: root,UID:0Username: bin,UID:1Username: daemon,UID:2Username: adm,UID:34.[root@centos7 ~]awk -F: &apos;{printf &quot;Username: %-15s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwdUsername: root           ,UID:0Username: bin            ,UID:1Username: daemon         ,UID:2</code></pre><hr><hr><h3 id="awk操作符"><a href="#awk操作符" class="headerlink" title="awk操作符"></a>awk操作符</h3><pre><code>a.算术操作符：x+y, x-y, x*y, x/y, x^y, x%y- x：转换为负数+x：将字符串转换为数值字符串操作符：没有符号的操作符，字符串连接赋值操作符：=, +=, -=, *=, /=, %=, ^=，++, --,b.比较操作符：==, !=, &gt;, &gt;=, &lt;, &lt;=模式匹配符： ~：左边是否和右边匹配包含 !~：是否不匹配c.逻辑操作符：与&amp;&amp;，或||，非!d.条件表达式（三目表达式） selector?if-true-expression:if-false-expression 表达式；if-ture-xx:else-xxx eg:x&gt;y?var=x;var=y</code></pre><h3 id="操作符用法示例："><a href="#操作符用法示例：" class="headerlink" title="操作符用法示例："></a>操作符用法示例：</h3><pre><code>1.下面两语句有何不同• awk &apos;BEGIN{i=0;print ++i,i}&apos; 结果 1 1• awk &apos;BEGIN{i=0;print i++,i}&apos; 结果 0 1实际上AWK的语法是采用VC语言风格的2.示例：awk中~&amp;!~是否包含的用法：[root@centos7 ~]awk -F: &apos;$0 ~ /root/{print $1}&apos; /etc/passwdrootoperator意思是如果过滤的行中有包含root字符串的，则打印出这行的用户名用到下文提到的patter模式，在这里是匹配是否包含root字符串[root@centos7 ~]awk -F: &apos;$0 ~ &quot;/root&quot;{print $1}&apos; /etc/passwdrootoperator区别上面的这个写法，在这里是包含/root字符串的行[root@centos7 ~]awk -F: &apos;$0 !~ /root/{print $1}&apos; /etc/passwdbindaemonadm和上面的命令刚好相反，如果行不包含字符串root，则打印该行用户名[root@centos7 ~]awk -F: &apos;$3==0&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash意思：判断UID是否等于0，是则打印该行，判断是否为管理员[root@centos7 ~]awk &apos;$0~&quot;^root&quot;&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash意思：判断该行是不是以root开头的行，是则打印3.awk中的与&amp;&amp;，或|| 非!的使用示例：示例：• awk –F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000 {print $1}&apos; /etc/passwd如果0&lt;=UID&lt;=1000，则打印出该用户• awk -F: &apos;$3==0 || $3&gt;=1000 {print $1,$3}&apos; /etc/passwd打印出UID等于0和UID&gt;=1000的用户名和他的UID• awk -F: &apos;!($3==0) {print $1}&apos; /etc/passwd -要加括号打印出UID不等于0的用户名• awk -F: &apos;!($3&gt;=500) {print $3}&apos; /etc/passwd如果UID&lt;=500,时，打印出该用户的UID4.AWK中的条件判断表达式即三目表达式相当于把shell中的if;then,else,fi的放到awk中• 示例：[root@centos7 ~]awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwdsys root 0sys bin 1sys tcpdump 72common test 1000common nginx 1008判断用户是否为系统用户，是则打印并在开头加common,不是也打印在开头加sys</code></pre><hr><hr><h3 id="awk中的PATTERN和action"><a href="#awk中的PATTERN和action" class="headerlink" title="awk中的PATTERN和action"></a>awk中的PATTERN和action</h3><p>模式匹配和处理动作=sed的地址定界+修饰符<br>功能：和sed中的pattern一样起到过滤的功能，=sed的地址定界</p><h5 id="PATTERN-根据pattern条件，过滤匹配的行，再做处理"><a href="#PATTERN-根据pattern条件，过滤匹配的行，再做处理" class="headerlink" title="PATTERN:根据pattern条件，过滤匹配的行，再做处理"></a>PATTERN:根据pattern条件，过滤匹配的行，再做处理</h5><pre><code>(1)如果未指定：空模式，匹配每一行(2) /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来awk &apos;/^UUID/{print $1}&apos; /etc/fstabawk &apos;!/^UUID/{print $1}&apos; /etc/fstabawk的匹配模式支持的是扩展的正则表达式注意：不支持直接给出数字格式，但是可以变向的打印输出，详见下面的示例(3) relational expression: 关系表达式，结果为“真”才会被处理真：结果为非0值，非空字符串假：结果为空字符串或0值都是假字符串为空或者0为假(4) line ranges：行范围startline,endline：/pat1/,/pat2/ 不支持直接给出数字格式awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/{print $1}&apos; /etc/passwdawk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20){print NR,$1}&apos; /etc/passwdNR表示行(5) BEGIN/END模式BEGIN{}: 仅在开始处理文件中的文本之前执行一次END{}：仅在文本处理完成之后执行一次</code></pre><p>模式：指定一个行的范围。该语法不能包括BEGIN和END模式。<br>BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。<br>END：让用户在最后一条输入记录被读取之后发生的动作。</p><h5 id="patter用法示例："><a href="#patter用法示例：" class="headerlink" title="patter用法示例："></a>patter用法示例：</h5><pre><code>先写一个特殊的用法1.当在awk命令中使用正则模式时，使用到的正则用法属于&quot;扩展的正则表达式&quot;2.当使用{x,y}这种次数匹配正则表达式，需要配合--posix或者--re-interval选项备注：这是网上找到一个示例，文中提到{x,y}必须加这个选项，然而不加选项也是可以过滤的awk是是支持posix字符集的[root@centos7 ~]cat f3 seexsexseeexseeeeex[root@centos7 ~]cat f3 | awk &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3 | awk -posix &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3 | awk --re-interval  &apos;/se{2,3}x/{print $0}&apos;seexseeex[root@centos7 ~]cat f3|grep  -E &quot;se{2,3}x&quot;seexseeex[root@centos7 ~]cat f3|sed -nr &apos;/se{2,3}x/p&apos;seexseeex1.取系统磁盘分区空间利用率df,/dev/sd开头的分区(上文中虽然取出来了，但是没过滤)[root@centos7 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &apos;/^\/dev\/sd/{print $1,$5}&apos;/dev/sda2 8/dev/sda3 1/dev/sda1 172.取当前连接主机的IP地址(上文中虽然取出来了，但是没过滤)[root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $6}&apos;192.168.34.1192.168.34.105或者用NF的表达方式[root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;192.168.34.1192.168.34.1053.取登录当前系统失败（lastb）用户的IP[root@centos7 ~]#lastbroot     ssh:notty    192.168.34.105   Sun Nov 11 17:25 - 17:25  (00:00)    root23   ssh:notty    192.168.34.1     Mon Nov  5 15:43 - 15:43  (00:00)    btmp begins Fri Nov  2 09:58:52 2018[root@centos7 ~]#lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c3 192.168.34.11 192.168.34.101因为最后一行有btmp这样的字样，只能通过包含的功能来过滤掉最后一行如果要取失败连接次数大于3的扔到防火墙，可以先取出来root@centos7 ~]lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c| awk &apos;$1 &gt;=3{print $2}&apos;192.168.34.14.patter中为关系表达式的示例空字符串或0值都是假，其他为真awk &apos;0{print $0}&apos; /etc/passwd -0为假，结果为空awk &apos;&quot;&quot;{print $0}&apos; /etc/passwd -空也为假，结果为空awk &apos;1{print $0}&apos; /etc/passwd -1为真awk &apos;&quot; &quot;{print $0}&apos; /etc/passwd -空白符也为真awk -v abc=&quot; &quot; &apos;abc{print $0}&apos; /etc/passwd -abc为空白,不是空字符串,也为真awk -v abc=&quot; &quot; &apos;! abc{print $0}&apos; /etc/passwd -abc为空白,为真,对真取反，结果为假5.awk中patter的地址定界root@centos7 ~]#awk -F: &apos;/^root/,/^adm/{print $0}&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologin打印以root开头的行到以adm开头的行之间的所有行等于 sed -nr &apos;/^root/,/^adm/p&apos; /etc/passwd6.如何打印从多少行到多少行之间的行？？[root@centos7 ~]#awk -F: &apos;NR&gt;=10 &amp;&amp; NR&lt;=12 {print NR,$0}&apos; /etc/passwd10 operator:x:11:0:operator:/root:/sbin/nologin11 games:x:12:100:games:/usr/games:/sbin/nologin12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin通过变量NR变向的打印出行7.取出/etc/fstab配置文件中以UUID开头的行[root@centos7 ~]#cat /etc/fstab | awk &apos;/^UUID/{print $0}&apos;UUID=9612633f-e7f1-4b28-8813-403d209d7abc /    xfs  defaults 0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot   xfs defaults  0 0效果等于  grep &quot;^UUID&quot; /etc/fstab效果等于  sed -n &apos;/^UUID/p&apos; /etc/fstab8.awk &apos;!0&apos; /etc/passwd =awk &apos;!0{print $0}&apos; /etc/passwd 省略了{print $0}的写法结果为真，即打印全部行root@centos7 ~]#awk -F: &apos;i=1;j=1{print i,j}&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash1 1bin:x:1:1:bin:/bin:/sbin/nologin1 1？？？[root@centos7 ~]#awk -F: &apos;$NF ~ /bash$/{print $1,$NF}&apos; /etc/passwdroot /bin/bashtest /bin/bash判断用户shell是否为/bin/bash，是则打印用户名和shell类型，此处用变量NF来实现效果等于 awk -F: &apos;$NF==&quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd效果等于 awk -F: &apos;$7 == &quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd效果等于 awk -F: &apos;$0 ~ /bash$/{print $1,$NF}&apos; /etc/passwd9.打印奇数行和偶数行[root@centos7 ~]#seq 6 | awk &apos;i=!i&apos;  打印奇数行135原理：i初始值为空，为假，取反时，则打印第一行，此时i=1i=1时，为真，取反为假，所以第二行不打印，然后i=0依次类推所以只打印奇数行[root@centos7 ~]#seq 6 | awk &apos;!(i=!i)&apos; 打印偶数行246效果等于 seq 10 |awk -v i=1 &apos;i=!i&apos;原理：同上，只要先定义i=1，为真，第一行就不打印了或者用sed打印奇数行和偶数行(用sed步进的方式) seq 6 | sed -n &apos;1~2p&apos; 打印奇数行 seq 6 | sed -n &apos;2~2p&apos; 打印偶数行</code></pre><hr><hr><h3 id="awk-action"><a href="#awk-action" class="headerlink" title="awk action"></a>awk action</h3><h4 id="action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能"><a href="#action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能" class="headerlink" title="action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能"></a>action除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能</h4><pre><code>• (1) Expressions:算术，比较表达式等• (2) Control statements：if, while等• (3) Compound statements：组合语句• (4) input statements• (5) output statements：print等</code></pre><h4 id="下面专门研究awk的控制语句包含if-while-do-for-break-continue-数组，exit等控制语句"><a href="#下面专门研究awk的控制语句包含if-while-do-for-break-continue-数组，exit等控制语句" class="headerlink" title="下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句"></a>下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句</h4><h5 id="awk中if-else控制语句的语法及用法"><a href="#awk中if-else控制语句的语法及用法" class="headerlink" title="awk中if-else控制语句的语法及用法"></a>awk中if-else控制语句的语法及用法</h5><pre><code>语法：双分支ifif(condition){statement;…}(多条语句用;隔开)[else statement]多分支ifif(condition1){statement1}else if(condition2){statement2}else{statement3}使用场景：对awk取得的整行或某个字段做条件判断</code></pre><h6 id="if-else示例："><a href="#if-else示例：" class="headerlink" title="if-else示例："></a>if-else示例：</h6><pre><code>如判断考试分数，写法如下[root@centos7 ~]awk -v score==80 &apos;BEGIN{if(score &lt;60){print &quot;no pass&quot;}else if(score &lt;=80){print &quot;soso&quot;}else {print good}}&apos;sosoawk -F: &apos;{if($3&gt;=1000)print $1,$3}&apos; /etc/passwd判断UID是否大于1000，是则打印用户名和UIDawk -F: &apos;{if($NF==&quot;/bin/bash&quot;) print $1}&apos; /etc/passwd判断用户shell是否为/bin/bash,是则打印用户名awk &apos;{if(NF&gt;5) print $0}&apos; /etc/fstab判断域或列个数是否大于5，是则打印该行awk -F: &apos;{if($3&gt;=1000) {printf &quot;Common user: %s\n&quot;,$1} else {printf &quot;root orSysuser: %s\n&quot;,$1}}&apos; /etc/passwd等于上文中的 awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd例如：随机生成1000个数字，用awk取出最大值和最小值(可以用shell写法)    1.生成1000个数字        for i in {1..1000};do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot;             &gt;&gt; f1.txt;else echo -e &quot;,$RANDOM\c&quot; &gt;&gt; f1.txt ;fi;done    2.用awk取出最大值和最小值        awk -F&apos;,&apos; &apos;{i=2;max=$1,while(i&lt;=NF){if($i &gt; max){max=$i}else         if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; f1.txt验证用awk是否取出的值为正确的：    方法一：用tr验证        tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | head -n1        tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | tail -n1    方法二：用shell脚本验证    #!/bin/bash    for i in {1..1000};do</code></pre><h4 id="awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，"><a href="#awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，" class="headerlink" title="awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，"></a>awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，</h4><h4 id="这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理"><a href="#这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理" class="headerlink" title="这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理"></a>这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理</h4><h4 id="awk中while循环控制语句的语法及用法"><a href="#awk中while循环控制语句的语法及用法" class="headerlink" title="awk中while循环控制语句的语法及用法"></a>awk中while循环控制语句的语法及用法</h4><pre><code>语法：while(condition){statement;…}条件“真”，进入循环；条件“假”，退出循环使用场景：对一行内的多个字段逐一类似处理时使用对数组中的各元素逐一处理时使用此时涉及到系统自带的一个函数length(函数在下面会有介绍)示例：1.统计每一行第一个字段的长度root@centos7 ~]awk -F: &apos;{print length($1),$1}&apos; /etc/passwd4 root3 bin6 daemon3 adm2.统计/etc/passwd第一行的每个字段的长度[root@centos7 ~]awk -F: &apos;NR==1{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/passwdroot 4x 10 10 1root 4/root 5/bin/bash 93.统计grub2.cfg文件中linux16那行的每个字段的长度[root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/grub2.cfglinux16 7/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46ro 2crashkernel=auto 16rhgb 4quiet 5LANG=en_US.UTF-8 16linux16 7/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46ro 2crashkernel=auto 16rhgb 4quiet 54.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用while循环root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){if(length($i)&gt;=10){print $i,length($i)};i++}}&apos; /etc/grub2.cfg/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16LANG=en_US.UTF-8 16/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 165.面试题用awk取出文本f5的最大值和最小值，需要先生成1000个随机数存到f5中如何做？1.不用awk，可以通过脚本实现最大值和最小值2.用awk如何来做？？先生成1000个随机数[root@centos7 ~]for i in `seq 1000`;do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f5;else echo -e &quot;,$aRANDOM\c&quot; &gt;&gt; f5 ;fi;done生成了1000随机数，如何取最大值最小值？[root@centos7 ~]awk -F&quot;,&quot; &apos;{i=2;max=$1;min=$1;while(i&lt;=NF){if($i &gt; max){max=$i}else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; &lt; f5max=32643 min=60</code></pre><h3 id="awk中do-while循环控制语句"><a href="#awk中do-while循环控制语句" class="headerlink" title="awk中do-while循环控制语句"></a>awk中do-while循环控制语句</h3><pre><code>语法：do {statement;…}while(condition)意义：无论真假，至少执行一次循环体</code></pre><h5 id="do-while使用示例："><a href="#do-while使用示例：" class="headerlink" title="do-while使用示例："></a>do-while使用示例：</h5><pre><code>求1-100正整数的和[root@centos7 ~]awk &apos;BEGIN{ total=0;i=0;do{ total+=i;i++;}while(i&lt;=100);print total}&apos;5050</code></pre><h3 id="awk中for循环控制语句"><a href="#awk中for循环控制语句" class="headerlink" title="awk中for循环控制语句"></a>awk中for循环控制语句</h3><pre><code>语法：for(expr1;expr2;expr3) {statement;…}常见用法：for(variable assignment;condition;iteration process){for-body}特殊用法：能够遍历数组中的元素语法：for(var in array) {for-body}</code></pre><h6 id="for循环使用示例："><a href="#for循环使用示例：" class="headerlink" title="for循环使用示例："></a>for循环使用示例：</h6><pre><code>1.求1-100正整数的和：[root@centos7 ~]awk &apos;BEGIN{for(i=1;i&lt;=100;i++)sum+=i;print sum}&apos;50502.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用for循环[root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{for(i=1;i&lt;=NF;i++){if(length($i)&gt;=10){print $i,length($i)}}}&apos; /etc/grub2.cfg/vmlinuz-3.10.0-862.el7.x86_64 30root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16LANG=en_US.UTF-8 16/vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46crashkernel=auto 16</code></pre><h3 id="awk中的switch控制语句"><a href="#awk中的switch控制语句" class="headerlink" title="awk中的switch控制语句"></a>awk中的switch控制语句</h3><pre><code>类似于shell中的case语句语法：switch(expression) {case VALUE1 or /REGEXP/: statement1; caseVALUE2 or /REGEXP2/: statement2; ...; default: statementn}</code></pre><h3 id="awk中的continue-break，next控制语句"><a href="#awk中的continue-break，next控制语句" class="headerlink" title="awk中的continue,break，next控制语句"></a>awk中的continue,break，next控制语句</h3><p>break和continue<br>next:<br>提前结束对本行处理而直接进入下一行处理（awk自身循环）</p><h5 id="continue的示例"><a href="#continue的示例" class="headerlink" title="continue的示例"></a>continue的示例</h5><pre><code>求1000以内偶数的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==0)continue;sum+=i}print sum}&apos;2500求1000以内奇数的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==1)continue;sum+=i}print sum}&apos;2550求1000以内除了66的所有数字的和[root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i==66)continue;sum+=i}print sum}&apos;4984</code></pre><h5 id="break的示例："><a href="#break的示例：" class="headerlink" title="break的示例："></a>break的示例：</h5><pre><code>求1000数字中，当大于100时，跳出循环，即求100以内的和[root@centos7 ~]#awk &apos;BEGIN{sum=0;for(i=1;i&lt;=1000;i++){if(i&gt;100)break;sum+=i}print sum}&apos;5050</code></pre><h5 id="next的示例："><a href="#next的示例：" class="headerlink" title="next的示例："></a>next的示例：</h5><pre><code>因为提前结束对本行处理而直接进入下一行处理（因为awk本身就是循环行的功能），所以示例打印/etc/passwd下的奇数行[root@centos7 ~]awk -F: &apos;{if(NR%2==0)next;print NR,$0}&apos; /etc/passwd1 root:x:0:0:root:/root:/bin/bash3 daemon:x:2:2:daemon:/sbin:/sbin/nologin5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin11 games:x:12:100:games:/usr/games:/sbin/nologin13 nobody:x:99:99:Nobody:/:/sbin/nologin还可以这样写：awk -F: &apos;NR%2==1{print NR,$0}&apos; /etc/passwd</code></pre><hr><hr><h3 id="awk数组-一个非常使用的功能"><a href="#awk数组-一个非常使用的功能" class="headerlink" title="awk数组-一个非常使用的功能"></a>awk数组-一个非常使用的功能</h3><h6 id="awk的数组全都是关联数组"><a href="#awk的数组全都是关联数组" class="headerlink" title="awk的数组全都是关联数组"></a>awk的数组全都是关联数组</h6><pre><code>关联数组：array[index-expression]index-expression:• (1) 可使用任意字符串；字符串要使用双引号括起来• (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”• (3) 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历</code></pre><h4 id="数组的去重的效果示例："><a href="#数组的去重的效果示例：" class="headerlink" title="数组的去重的效果示例："></a>数组的去重的效果示例：</h4><pre><code>awk &apos;!arr[$0]++&apos; dupfileawk &apos;{!arr[$0]++;print $0, arr[$0]}&apos; dupfileecho abc abc ccc bcd ddd ddd abc abc &gt;&gt; f1.txt</code></pre><h4 id="awk关联数组的遍历："><a href="#awk关联数组的遍历：" class="headerlink" title="awk关联数组的遍历："></a>awk关联数组的遍历：</h4><pre><code>若要遍历数组中的每个元素，要使用for循环:因为关联数组下标是无序性for(var in array) {for-body}注意：var会遍历array的每个索引</code></pre><h4 id="数组的使用示例："><a href="#数组的使用示例：" class="headerlink" title="数组的使用示例："></a>数组的使用示例：</h4><pre><code>示例1.定义awk数组[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]}&apos;zhang可以用for循环把每一个数组的值都表示出来[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;];for(i in title){print i,title[i]}}&apos;zhangcoo liuceo zhangcto wang但输出时数组元素时，是无序的，这就是关联数组的特性示例2.awk数组中的重要功能    [root@centos7 ~]cat f6    abc    abc    ddd    ccc    aaa    ccc    ccc    [root@centos7 ~]awk &apos;!line[$0]++&apos; f6    abc    ddd    ccc    aaa问题：为什么执行结果是这个？？原因：awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6实际上是隐藏了{print $0}，这个隐藏功能在awk很重要！！！，但是要和后面patter中的空模式区别开&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印而后面的数组里的是加了双括号{}，{line[$0]++}即用的patter的空模式，即文本中的每一行都处理这两个写法是不一样的，别混淆了分析：基于这个考虑进行分析 &apos;!line[$0]++&apos; = &apos;!line[$0]++{print $0}&apos;当读取文本f6的第一行时=abc!line[&quot;abc&quot;]++，因为abc没有值，line[&quot;abc&quot;]=0为假，取反！line[&quot;abc&quot;]后为真所以把第一行的abc打印了一次，打印第一行结束后line[&quot;abc&quot;]=1当读取文本f6的第二行时=abc!line[&quot;abc&quot;]++，在之前基础上line[&quot;abc&quot;]=1为假，取反！line[&quot;abc&quot;]=0后为假所以把第二行的abc不打印，结束后line[&quot;abc&quot;]=2以此类推，发现后续出现abc都不会打印，但是line[&quot;abc&quot;]都会在之前的基础上+1，即达到去重并统计的目的而处理第三行!line[&quot;ddd&quot;]++时，和上述abc一样，第一次出现则打印，后续也不会打印所以，命令执行结果为去重的效果从这个命令执行结果也可以明显看到上述的分析结果可以看出abc的值是递增的，也就是abc出现的次数[root@centos7 ~]awk &apos;{!line[$0]++;print $0, line[$0]}&apos; f6abc 1abc 2ddd 1ccc 1aaa 1ccc 2</code></pre><hr><h3 id="awk数组中的重要功能之for循环遍历数组，很具有实用性"><a href="#awk数组中的重要功能之for循环遍历数组，很具有实用性" class="headerlink" title="awk数组中的重要功能之for循环遍历数组，很具有实用性"></a>awk数组中的重要功能之for循环遍历数组，很具有实用性</h3><h6 id="在后面的统计服务的一些日志文件很有作用"><a href="#在后面的统计服务的一些日志文件很有作用" class="headerlink" title="在后面的统计服务的一些日志文件很有作用"></a>在后面的统计服务的一些日志文件很有作用</h6><pre><code>如果要理解遍历awk数组，需要深刻理解上述的示例2:awk &apos;!line[$0]++&apos; f6是怎么实现的但还是有些和数组里的，遍历$2,把$2不同的值，当成数组的下标有些区别的</code></pre><h3 id="若要遍历数组中的每个元素，要使用for循环"><a href="#若要遍历数组中的每个元素，要使用for循环" class="headerlink" title="若要遍历数组中的每个元素，要使用for循环"></a>若要遍历数组中的每个元素，要使用for循环</h3><pre><code>for(var in array) {for-body}注意：var会遍历array的每个索引</code></pre><h6 id="为什么要通过特殊写法去遍历awk中的数组？"><a href="#为什么要通过特殊写法去遍历awk中的数组？" class="headerlink" title="为什么要通过特殊写法去遍历awk中的数组？"></a>为什么要通过特殊写法去遍历awk中的数组？</h6><pre><code>如果是普通数组，用循环0,1,2,3做个循环即可；而awk的数组都是关联数组，[]中括号里的下标都不固定所以要通过 for(var in array(数组名称)) {for-body}这样的特殊写法，var的值会从array数组元素取其下标，相当于每次循环var的值是等于array数组的下标的注意：当我们直接引用一个数组中不存在的元素时，awk会自动创建这个元素，并且为其赋值为&quot;空字符串&quot;</code></pre><h4 id="for循环遍历数组使用示例："><a href="#for循环遍历数组使用示例：" class="headerlink" title="for循环遍历数组使用示例："></a>for循环遍历数组使用示例：</h4><pre><code>示例1：[root@centos7 ~]awk &apos;BEGIN{print test[&quot;ip&quot;];test[&quot;ip&quot;]++;print test[&quot;ip&quot;]}&apos;1第一次输出为空，第二次自动加1示例2：1.[root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;for(i in title){print title[i]}}&apos;liuzhangwang分析：for(i in title){print title[i]，i的值来自于title的下标，即i=ceo coo cto,而且是无序打印示例3：[root@centos7 ~]netstat -tanActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN     tcp        0      0 192.168.122.1:53        0.0.0.0:*               ESTABLISTEN     tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN     tcp        0     52 192.168.34.103:22       192.168.34.1:8816       ESTABLISHEDtcp        0      0 192.168.34.103:22       192.168.34.105:49746    ESTABLISHEDtcp6       0      0 :::111                  :::*                    LISTEN     tcp6       0      0 :::22                   :::*                    LISTEN     tcp6       0      0 ::1:631                 :::*                    LISTEN     tcp6       0      0 ::1:25                  :::*                    LISTEN     [root@centos7 ~]netstat -tan | awk &apos;/^tcp/{state[$NF]++}END{for(i in state) { print i,state[i]}}&apos;LISTEN 8ESTABLISHED 3分析：state[$NF]++以空白做分隔符，统计同一类型的状态有多少个for(i in state) { print i,state[i]} 即统计了出现状态的多少种以及出现的次数不明白的可以看上文中的示例2：awk数组中的重要功能当然，看懂这个命令，需要知道两个知识点1.空模式，即全文反复提到的{state[$NF]++}={state[$NF]++}{print $0}2.END模式，END的模式是在前面动作结束之后，最后执行依次END模式中的命令，所以先不用考虑空模式下面再一次对空模式中的处理过程，做详细的描述空模式中，我们创建了一个state数组，并将状态值(LISTEN、ESTABLISHED)作为引用下标，所以执行到第一行时，我们引用的是state[&quot;LISTEN&quot;],很明显，这个元素并不存在，所以，当第一行被空模式的动作处理完毕后state[&quot;LISTEN&quot;]的值已经被赋值为1了。这时，空模式中的动作继续处理下一行，而下一行的$NF=ESTABLISTEN；state[&quot;ESTABLISTEN&quot;]所以，state[&quot;ESTABLISTEN&quot;]第一次参与运算过程与上一个原理相同直到再次遇到相同的状态时，使用同样一个IP地址作为下标的元素将会再次被自加直到处理完所有的行，开始执行END模式中的动作。而END模式中，我们打印出state数组中的所有元素的下标，以及元素对应的值。此刻，state数组中的下标即为各种状态，元素的值即为对应状态出现的次数，最终，我们统计出每个状态出现的次数。3.统计/var/log/httpd/access_log，每个IP链接的次数root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; &quot;Mozil&quot;192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;192.168.34.103 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot;[root@centos7 ~]awk &apos;{ip[$1]++}END{for(i in ip){print i,ip[i]}}&apos; /var/log/httpd/access_log192.168.34.101 9192.168.34.103 13::1 4192.168.34.1 88效果等于：[root@centos7 ~]awk &apos;{print $1}&apos; /var/log/httpd/access_log |sort|uniq -c4 ::188 192.168.34.19 192.168.34.10113 192.168.34.1034.统计ss -nt ip链接次数[root@centos7 ~]ss -ntState      Recv-Q Send-Q                 Local Address:Port                                Peer Address:Port              ESTAB      0      52                    192.168.34.103:22                                  192.168.34.1:8816               ESTAB      0      0                     192.168.34.103:22                                192.168.34.105:49746              [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{ip[$(NF-2)]++}END{for(i in ip){print i,ip[i]}}&apos;192.168.34.105 1192.168.34.1 1效果等于：[root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;|sort|uniq -c1 192.168.34.11 192.168.34.1055.统计/etc/fstab文件系统类型分别有多少个[root@centos7 ~]cat /etc/fstab # /etc/fstab# Created by anaconda on Wed Sep 19 11:44:48 2018UUID=9612633f-e7f1-4b28-8813-403d209d7abc /                       xfs     defaults        0 0UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot                   xfs     defaults        0 0UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data                   xfs     defaults        0 0UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap                    swap    defaults        0 0[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos;swap 1xfs 36.求下表中的男生和女生的平均成绩[root@centos7 ~]cat f9name sex scorea     m   90b     f   80c     f   99d     m   88e     m   80如何利用awk的数组功能来求？思路先求男的和和女的和？利用两个数组？[root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3}END{for(i in sum){print i,sum[i]}}&apos; -求男女分的和m 258f 179[root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3;num[$2]++}END{for(i in sum){print i,sum[i]/num[i]}}&apos;m 86f 89.57.统计下面每个名字出现的次数[root@centos7 ~]cat f1Allen PhillipsGreen LeeWilliam Aiden Janmes LeeAngel JackJack ThomasLucas KevinTyler LeeWilliam Allen[root@centos7 ~]cat f1 | awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,cuont[j]}}&apos;Tyler Angel Lucas William Thomas Green Jack Phillips Kevin </code></pre><hr><hr><h3 id="awk函数"><a href="#awk函数" class="headerlink" title="awk函数"></a>awk函数</h3><h6 id="awk也包括内置函数和自定义函数"><a href="#awk也包括内置函数和自定义函数" class="headerlink" title="awk也包括内置函数和自定义函数"></a>awk也包括内置函数和自定义函数</h6><h6 id="内置函数包括-rand-length，sub-gsub-split，system"><a href="#内置函数包括-rand-length，sub-gsub-split，system" class="headerlink" title="内置函数包括 rand,length，sub,gsub,split，system"></a>内置函数包括 rand,length，sub,gsub,split，system</h6><pre><code>数值处理：rand(i)：返回0和1之间一个随机数awk &apos;BEGIN{srand(); for (i=1;i&lt;=10;i++)print int(rand()*100) }&apos;字符串处理：• length([s])：返回指定字符串的长度• sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为secho &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,“-&quot;,$1)&apos;• gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表示的内容echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos;• split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所表示的数组中，第一个索引值为1,第二个索引值为2,…netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}&apos;END{for (i in count) {print i,count[i]}</code></pre><h4 id="awk内置函数之sub、gsub、split实现搜索替换切割的用法"><a href="#awk内置函数之sub、gsub、split实现搜索替换切割的用法" class="headerlink" title="awk内置函数之sub、gsub、split实现搜索替换切割的用法"></a>awk内置函数之sub、gsub、split实现搜索替换切割的用法</h4><pre><code>示例1：sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为sgsub(r,s,[t])表示全局替换sub(r,s,[t])不是贪婪模式，默认值替换搜索出来的第一个[root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,&quot;-&quot;,$1)&apos;2008-08:08 08:08:08只替换$1root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$1)&apos;2008-08-08 08:08:08全局替换$0[root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos;2008-08-08 08-08-08示例2：统计字符串中每个字母出现的次数abcdaabbccdd[root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 3b 3c 3d 3在文章最后会用另外一种写法进行过滤(文章最后会以以空位分隔符的特殊写法来表示)</code></pre><h5 id="awk内置函数split的切割功能"><a href="#awk内置函数split的切割功能" class="headerlink" title="awk内置函数split的切割功能"></a>awk内置函数split的切割功能</h5><pre><code>示例1:    统计链接本机的IP和端口号    [root@centos7 ~]#netstat -tn    Active Internet connections (w/o servers)    Proto Recv-Q Send-Q Local Address           Foreign Address         State          tcp        0     52 192.168.34.103:22       192.168.34.1:8816       ESTABLISHED    tcp        0      0 192.168.34.103:22       192.168.34.105:49746    ESTABLISHED    [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}END{for (i in count) {print i,count[i]}}&apos;    192.168.34.105 1    192.168.34.1 1    [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[2]]++}END{for (i in count) {print i,count[i]}}&apos;    8816 1    49746 1    分析：    split($5,ip,&quot;:&quot;)将192.168.34.1:8816进行切割，数组ip的下标1放IP地址，下标2放端口号    count[ip[1]]++ 把ip下标为1也就是IP地址，把出现的IP个数，又给count当下标，就统计每个IP出现的次数    count[ip[2]]++ 把ip下标为2也就是端口号，把出现的端口号个数，又给count当下标，就统计每个端口号出现的次数</code></pre><h3 id="awk中的自定义函数格式："><a href="#awk中的自定义函数格式：" class="headerlink" title="awk中的自定义函数格式："></a>awk中的自定义函数格式：</h3><pre><code>awk自定义函数是用正规开发语言的函数格式function name ( parameter, parameter, ... ) { statements return expression}</code></pre><h5 id="awk自定义函数的用法："><a href="#awk自定义函数的用法：" class="headerlink" title="awk自定义函数的用法："></a>awk自定义函数的用法：</h5><pre><code>cat fun.awk,把函数写到文件中function max(x,y) {x&gt;y?var=x:var=yreturn var}BEGIN{print max(i,j)}awk -v i=10 -v j=20 -f fun.awk 调用函数即可，和shell中的函数类似</code></pre><h4 id="awk中很实用的内置函数system命令"><a href="#awk中很实用的内置函数system命令" class="headerlink" title="awk中很实用的内置函数system命令"></a>awk中很实用的内置函数system命令</h4><h6 id="system函数作用：在awk可以反过来调用linux里的命令"><a href="#system函数作用：在awk可以反过来调用linux里的命令" class="headerlink" title="system函数作用：在awk可以反过来调用linux里的命令"></a>system函数作用：在awk可以反过来调用linux里的命令</h6><pre><code>示例：    空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用    空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来示例1:显示/boot/grub2下的文件列表；调用命令时要加双引号[root@centos7 ~]#awk &apos;BEGIN{system(&quot;ls /boot/grub2&quot;)}&apos;device.map  fonts  grub.cfg  grubenv  i386-pc  locale或者这么写，先定义变量等于路径，再调用变量[root@centos7 ~]#awk &apos;BEGIN{dir=&quot;/boot/grub2&quot;;system(&quot;ls &quot;dir)}&apos;device.map  fonts  grub.cfg  grubenv  i386-pc  locale调用hostname命令，显示主机名[root@centos7 ~]#awk &apos;BEGIN{system(&quot;hostname&quot;)}&apos;centos7.localdomain示例2：之前处理过lastb中登录失败的IP，如果失败登录次数大于3次，扔到防火墙里，当时是先取出IP放到文件里，然后iptables再禁用；现在可以在awk中先取出IP,然后通过system(&quot;iptables &quot; IP)就可以直接扔到防火墙中具体实现？</code></pre><h3 id="awk脚本"><a href="#awk脚本" class="headerlink" title="awk脚本"></a>awk脚本</h3><pre><code>将awk程序写成脚本，直接调用或执行awk脚本使用示例：1.先写文本再调用cat f1.awk{if($3&gt;=1000)print $1,$3} awk -F: -f f1.awk /etc/passwd2.也可以写成脚本形式先写再调用[root@centos7 ~]vim f2.awk#!/bin/awk -f{if($3 &gt;=1000)print $1,$3} [root@centos7 ~]./f2.awk -F: /etc/passwdnfsnobody 65534test 1000gentoo 1007nginx 1008ceshi 1009</code></pre><h4 id="向awk脚本传递参数"><a href="#向awk脚本传递参数" class="headerlink" title="向awk脚本传递参数"></a>向awk脚本传递参数</h4><pre><code>格式：awkfile var=value var2=value2... Inputfile注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变量都需要一个-v参数</code></pre><h6 id="awk脚本传参使用示例："><a href="#awk脚本传参使用示例：" class="headerlink" title="awk脚本传参使用示例："></a>awk脚本传参使用示例：</h6><pre><code>cat test.awk #!/bin/awk –f {if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3}chmod +x test.awktest.awk -F: min=100 max=200 /etc/passwd</code></pre><h4 id="工作中遇到的常用awk文本解决案例："><a href="#工作中遇到的常用awk文本解决案例：" class="headerlink" title="工作中遇到的常用awk文本解决案例："></a>工作中遇到的常用awk文本解决案例：</h4><h5 id="Linux-Web服务器网站故障分析常用的命令"><a href="#Linux-Web服务器网站故障分析常用的命令" class="headerlink" title="Linux Web服务器网站故障分析常用的命令"></a>Linux Web服务器网站故障分析常用的命令</h5><pre><code>系统连接状态篇：1.查看TCP连接状态netstat -nat |awk &apos;{print $6}&apos;|sort|uniq -c|sort -rn每出现一被/^tcp/模式匹配到的行，数组S[$NF]就加1，NF为当前匹配到的行的最后一个字段，此处用其值做为数组S的元素索引；netstat -n | awk &apos;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}&apos; 或netstat -n | awk &apos;/^tcp/ {++state[$NF]}; END {for(key in state) print key,&quot;\t&quot;,state[key]}&apos;netstat -n | awk &apos;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,&quot;t&quot;,arr[k]}&apos;netstat -n |awk &apos;/^tcp/ {print $NF}&apos;|sort|uniq -c|sort -rnnetstat -ant | awk &apos;{print $NF}&apos; | grep -v &apos;[a-z]&apos; | sort | uniq -c    2.查找请求数请20个IP（常用于查找攻来源）：方法一：netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20方法二：netstat -ant |awk &apos;/:80/{split($5,ip,&quot;:&quot;);++A[ip[1]]}END{for(i in A) print A[i],i}&apos; |sort -rn|head -n203.用tcpdump嗅探80端口的访问看看谁最高tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; ‘{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}’ | sort | uniq -c | sort -nr |head -204.查找较多time_wait连接netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n205.找查较多的SYN连接netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more6.根据端口列进程netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1</code></pre><h5 id="网站日志分析篇1（Apache）："><a href="#网站日志分析篇1（Apache）：" class="headerlink" title="网站日志分析篇1（Apache）："></a>网站日志分析篇1（Apache）：</h5><pre><code>1.获得访问前10位的ip地址cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’2.访问次数最多的文件或页面,取前20cat access.log|awk ‘{print $11}’|sort|uniq -c|sort -nr|head -203.列出传输最大的几个exe文件（分析下载站的时候常用）cat access.log |awk ‘($7~/.exe/){print $10 &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -204.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数cat access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -1005.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面cat access.log |awk ‘($7~/.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -1006.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -1007.列出传输时间超过 30 秒的文件cat access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -208.统计网站流量（G)cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’9.统计404的连接awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort10. 统计http statuscat access.log |awk &apos;{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}&apos;cat access.log |awk &apos;{print $9}&apos;|sort|uniq -c|sort -rn10.蜘蛛分析，查看是哪些蜘蛛在抓取内容。/usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E &apos;bot|crawler|slurp|spider&apos;</code></pre><h5 id="网站日分析2-Squid篇）按域统计流量"><a href="#网站日分析2-Squid篇）按域统计流量" class="headerlink" title="网站日分析2(Squid篇）按域统计流量"></a>网站日分析2(Squid篇）按域统计流量</h5><pre><code>cat squid_access.log.tar.gz| awk &apos;{print $10,$7}&apos; |awk &apos;BEGIN{FS=&quot;[ /]&quot;}{trfc[$4]+=$1}END{for(domain in trfc){printf &quot;%st%dn&quot;,domain,trfc[domain]}}&apos;</code></pre><h5 id="安全篇：-ssh-lastb"><a href="#安全篇：-ssh-lastb" class="headerlink" title="安全篇：(ssh lastb)"></a>安全篇：(ssh lastb)</h5><pre><code>ssh日志中失败登录的IP，取出来 /var/log/secureawk &apos;/Failed PASSWORD/{IP[$(NF-3)]++}END{for(i in IP){print i,IP[i]}&apos; /var/log/secure1、文件ip_list.txt如下格式，请提取”.magedu.com”前面的主机名部分并写入到回到该文件中1 blog.magedu.com2 www.magedu.com…999 study.magedu.com2、统计/etc/fstab文件中每个文件系统类型出现的次数[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{print $3}&apos;|sort|uniq -c |sort -nr      3 xfs      1 swap[root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos;swap 1xfs 33、统计/etc/fstab文件中每个单词出现的次数root@centos7 ~]cat /etc/fstab |awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,count[j]}}&apos;man 14、提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字[root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|awk &apos;gsub(/[^0-9]/,&quot;&quot;,$0)&apos;05973[root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|tr -dc &quot;[0-9]&quot;059735、有一文件记录了1-100000之间随机的整数共5000个，存储的格式100,50,35,89…请取出其中最大和最小的整数6、解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT[root@centos7 ~]awk &apos;{access[$1]++}END{for(i in access){if(access[i]&gt;=1){print i,access[i]}}}&apos; /var/log/httpd/access_log 192.168.34.101 9192.168.34.103 13只过滤出IP，监控任务可以写到计划任务里，或者用内置函数system[&quot;iptables&quot;]调用？7、将以下文件内容中FQDN取出并根据其进行计数从高到低排序http://mail.magedu.com/index.htmlhttp://www.magedu.com/test.htmlhttp://study.magedu.com/index.htmlhttp://blog.magedu.com/index.htmlhttp://www.magedu.com/images/logo.jpghttp://blog.magedu.com/20080102.html[root@centos7 ~]#cat f5|sed -nr &apos;s@.*//([^/]+)/.*@\1@p&apos;|sort|uniq -c|sort -nr      2 www.magedu.com      2 blog.magedu.com      1 study.magedu.com      1 mail.magedu.com[root@centos7 ~]#cat f5|awk -F&quot;/&quot; &apos;{print $3}&apos;|sort|uniq -c|sort -nr      2 www.magedu.com      2 blog.magedu.com      1 study.magedu.com      1 mail.magedu.com8、将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出同一inode中，beginnumber的最小值和endnumber的最大值inode|beginnumber|endnumber|counts|106|3363120000|3363129999|10000|106|3368560000|3368579999|20000|310|3337000000|3337000100|101|310|3342950000|3342959999|10000|310|3362120960|3362120961|2|311|3313460102|3313469999|9898|311|3313470000|3313499999|30000|311|3362120962|3362120963|2|输出的结果格式为：310|3337000000|3362120961|10103|311|3313460102|3362120963|39900|106|3363120000|3368579999|30000|awk -F&apos;|&apos; &apos;NR==1{print;next}{a[$1]?(a[$1]&gt;$2?a[$1]=$2:0):(a[$1]=$2);b[$1]?(b[$1]&lt;$3?b[$1]=$3:0):(b[$1]=$3);c[$1]+=$4}END{l=asorti(a,d);for(i=1;i&lt;=l;i++)print d[i] FS a[d[i]] FS b[d[i]] FS c[d[i]] FS}&apos; file[解析]  第一行直接打印。从第2行开始以$1为下标，建立3个数组，比较出$2的最小值，$3的最大值，然后把$4进行累加，最后进行排序后依次取出各项值。  这其中运用了三目运算的嵌套，跟我们 if(){if(){}}else{} 的使用是一个道理，不要认为复杂，如果觉得模糊不清，仔细读懂流程控制。9.统计字符串中每个字母出现的次数abcdaabbccdd[root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 3b 3c 3d 3下面的写法在双引号前一定要加一个空格才能匹配出来或者用单引号，但是也需要在前面几个空格[root@centos7 mnt]#echo abcdaabbccdd|awk -F &quot;&quot; &apos;{for(i=1;i&lt;=NF;i++)x[$i]++}END{for(i in x){print i,x[i]}}&apos; a 3                                 此处一定有个空格b 3c 3d 3或者用单引号，但是也需要在前面几个空格[root@mini7-1 ~]#echo abcdaabbccdd |awk -F &apos;&apos; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos;a 2b 3c 3d 2root@centos7 mnt]#echo abcdaabbccdd | grep -o &quot;[a-z]&quot;|sort|uniq -c      3 a      3 b      3 c      3 d10.面试题：取出/etc/fstab中的挂载目录    [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos;    boot    data    swap    [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos;    boot    data    swap</code></pre><h3 id="AWK中的输入分隔符"><a href="#AWK中的输入分隔符" class="headerlink" title="AWK中的输入分隔符"></a>AWK中的输入分隔符</h3><h6 id="我们可以使用两次awk-F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。"><a href="#我们可以使用两次awk-F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。" class="headerlink" title="我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。"></a>我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。</h6><pre><code>要一次指定多个分隔符，需要将分隔符用中括号[]包裹起来，如果多个分隔符中有至少一个特殊字符，那么还需要在中括号外加上双引号或者单引号，并且使用两个或两个以上的\将其进行转义$、^、(、)、[、]、?、.、|示例1：        [root@node7-1 data]cat b.txt         ssh:user1@192.168.1.10        ssh:user2@192.168.1.11        ssh:user3@192.168.1.12    1.取user和IP        [root@node7-1 data]awk -F [:@] &apos;{print $2,$3}&apos; b.txt         user1 192.168.1.10        user2 192.168.1.11        user3 192.168.1.12    2.上面b.txt中的：和@换成^和|，又该怎么取？        [root@node7-1 data]awk -F &apos;[\\^\\|]&apos; &apos;{print $2,$3}&apos; b.txt         user1 192.168.1.10        user2 192.168.1.11        user3 192.168.1.12示例2：    示例1：        george[walker]bush        william[jefferson]clinton    如果要打印出由分隔符[和]分隔的三段数据，即可以分别使用两个或两个以上的\对[和]进行转义，如下所示    方法一：        awk -F &apos;[\\[\\]]&apos; &apos;{ print $1,$2,$3}&apos; name.txt        george walker bush        william jefferson clinton    方法二：        awk -F &apos;[][]&apos; &apos;{ print $1,$2,$3}&apos; name.txt        george walker bush        william jefferson clinton11.取出文本中的姓名和FQDN，awk的方法参照文章最上面的链接文章    [root@node7-1 data]cat a.txt     xiaoming\t20\thttp://sougou.com    xiaohua\t25\thttp://www.baidu.com    xiaodong\t30\thttp://www.jidong.com方法一：用awk取，以\t做分隔符，但是在表示方法上比较特殊    root@node7-1 data]awk -F&apos;\\\\t&apos; &apos;{print $1,$3}&apos; a.txt     xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com分析：    第一个给第二个转义，第三个给第四个转义，传给awk对就是\\t，awk再将\\解释成\t方法二：用awk和sed取    [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )t(.*)@\1\2@&apos;    xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com12.扩展11题的内容把t换成$,又该如何取？    [root@node7-1 data]cat a.txt     xiaoming\$20\$http://sougou.com    xiaohua\$25\$http://www.baidu.com    xiaodong\$30\$http://www.jidong.com方法一：还是只用awk来取    [root@node7-1 data]awk -F&apos;\\\\\\$&apos; &apos;{print $1,$3}&apos; a.txt     xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com    分析：        1.\\$是转义$的        2.前四个\\\\是转义\的方法二：awk和sed取    [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )\$(.*)@\1\2@&apos;    xiaoming http://sougou.com    xiaohua http://www.baidu.com    xiaodong http://www.jidong.com分析：先用awk用\做分隔符来取，再用sed取，sed中的$需要转义</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;文本处理三剑客之awk&quot;&gt;&lt;a href=&quot;#文本处理三剑客之awk&quot; class=&quot;headerlink&quot; title=&quot;文本处理三剑客之awk&quot;&gt;&lt;/a&gt;文本处理三剑客之awk&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2017/10/18/文本三剑客之awk/awk.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux基础" scheme="https://www.liukui.tech/categories/linux%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="文本处理工具" scheme="https://www.liukui.tech/tags/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>旧事-大好河山</title>
    <link href="https://www.liukui.tech/2017/10/01/%E6%97%A7%E4%BA%8B-%E5%A4%A7%E5%A5%BD%E6%B2%B3%E5%B1%B1/"/>
    <id>https://www.liukui.tech/2017/10/01/旧事-大好河山/</id>
    <published>2017-10-01T00:00:00.000Z</published>
    <updated>2018-12-17T02:59:31.538Z</updated>
    
    <content type="html"><![CDATA[<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script> <div id="hbe-security"> <div class="input-container"> <input type="password" class="form-control" id="pass" placeholder=" 输入密码,PC:Enter查看,Phone:输入法换行查看. " /> <label for="pass"> 输入密码,PC:Enter查看,Phone:输入法换行查看. </label> <div class="bottom-line"></div> </div> </div> <div id="encrypt-blog" style="display:none"> U2FsdGVkX19trDfmPBISD5MtSew7zJdrqL64sSplDuS3ivhORhb+2prcbR/Iqkm82T+W7tnvnTbmZSoUUL7tcYIMxYoPVp8himx57rEDbLOjJRstYYAc6nO1ZGRPp5zjwqVUSsHJZSMcnLoo4hSWAMDq22Mx3K29cWaHxOdcUf5vMAqErzZbeSt0FrT7ClRAxyULcZqbK7CMxrQazbBlBflHKaNQPVEJMJbGr6+glvPazZ7H5DJO1CNQkIz+jHjA7hcy7MKbeF4JdKJOmw8FgwKK+iCS3Fj8/rlWLq6LDLmObNlMzPq5RO7huCUXTlALxqtb+vEof4U4hOpq6nJtf+AdjB6KjfV3I+Ms5dOP3RJw3Qh1Ru/0t80l8OtNRbDs </div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      &lt;font size=3 color=&quot;#FF0000&quot;&gt;私密文章，需要输入密码.&lt;/font&gt;&lt;/br&gt;
    
    </summary>
    
      <category term="旧事，杂记" scheme="https://www.liukui.tech/categories/%E6%97%A7%E4%BA%8B%EF%BC%8C%E6%9D%82%E8%AE%B0/"/>
    
    
      <category term="旧事，杂记" scheme="https://www.liukui.tech/tags/%E6%97%A7%E4%BA%8B%EF%BC%8C%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Cobbler</title>
    <link href="https://www.liukui.tech/2017/05/06/Cobbler/"/>
    <id>https://www.liukui.tech/2017/05/06/Cobbler/</id>
    <published>2017-05-06T00:00:00.000Z</published>
    <updated>2018-12-16T10:01:07.099Z</updated>
    
    <content type="html"><![CDATA[<p><strong>在服务器很多的情况下，用U盘或者光盘安装时，就显得有点吃力了，虽然可以用PXE进行安装，但是PXE不支持UEFI<br>所以现在更多使用Cobbler来实现自动化部署.</strong></p><a id="more"></a><h3 id="Cobbler工作原理"><a href="#Cobbler工作原理" class="headerlink" title="Cobbler工作原理"></a>Cobbler工作原理</h3><p><img src="/2017/05/06/Cobbler/cobbler工作原理.png" alt=""></p><h3 id="系统自动安装之-cobbler"><a href="#系统自动安装之-cobbler" class="headerlink" title="系统自动安装之-cobbler"></a>系统自动安装之-cobbler</h3><p>之前写过PXE自动化安装的文档，但是PXE只支持BIOS，不支持UEFI:<a href="">PXE系统自动化部署</a><br>Cobbler可以同时支持BIOS和UEFI两种：基于PXE技术为基础的整合</p><p>BIOS+MBR：分区最多支持2T的<br>UEFI+GPT：分区可以支持大于2T的分区<br>    在之前的工作中，需要建立大于2T的分区时，PXE安装就不合适了</p><h3 id="cobbler-具有图形化管理界面的工具"><a href="#cobbler-具有图形化管理界面的工具" class="headerlink" title="cobbler:具有图形化管理界面的工具"></a>cobbler:具有图形化管理界面的工具</h3><pre><code>cobbler是什么？    实际上是把PXE技术用python代码做了封装，形成了相对完整的自动化安装，    但是实现PXE的原有的httpd，DHCP，tftp服务还是需要提前安装的。Cobbler:快速网络安装linux操作系统的服务，支持众多的Linux发行版：Red Hat、    Fedora、CentOS、Debian、Ubuntu和SuSE，也可以支持网络安装windowsPXE的二次封装，将多种安装参数封装到一个菜单Python编写提供了CLI和Web的管理形式</code></pre><h3 id="安装cobbler：EPEL源"><a href="#安装cobbler：EPEL源" class="headerlink" title="安装cobbler：EPEL源"></a>安装cobbler：EPEL源</h3><pre><code>安装包    cobbler 基于EPEL源    cobbler 服务集成        前面说过因为是基于PXE的,安装cobbler因为有依赖性，会自动安装下面的服务        PXE        DHCP        rsync        Httpd        DNS        Kickstart        syslinux         tftp-server         IPMI 电源管理启动cobbler:依赖于httpd，要想启动cobbler,必须先启动httpd    systemctl start httpd tftp dhcp    systemctl start cobblerd然后再检查cobbler环境    cobbler check</code></pre><h3 id="cobbler的相关配置文件"><a href="#cobbler的相关配置文件" class="headerlink" title="cobbler的相关配置文件"></a>cobbler的相关配置文件</h3><pre><code>安装：yum install cobbler dhcp配置文件目录 /etc/cobbler    /etc/cobbler/settings : cobbler 主配置文件(下文会对该文件修改4行)    /etc/cobbler/iso/: iso模板配置文件    /etc/cobbler/pxe: pxe模板文件    /etc/cobbler/power: 电源配置文件    /etc/cobbler/user.conf: web服务授权配置文件    /etc/cobbler/users.digest: web访问的用户名密码配置文件    /etc/cobbler/dhcp.template : dhcp服务器的的配置末班    /etc/cobbler/dnsmasq.template : dns服务器的配置模板    /etc/cobbler/tftpd.template : tftp服务的配置模板    /etc/cobbler/modules.conf : 模块的配置文件数据目录    /var/lib/cobbler/config/: 用于存放distros，system，profiles 等信息配置文件    /var/lib/cobbler/triggers/: 用于存放用户定义的cobbler命令    /var/lib/cobbler/kickstart/: 默认存放kickstart文件    /var/lib/cobbler/loaders/: 存放各种引导程序镜像目录    /var/www/cobbler/ks_mirror/: 导入的发行版系统的所有数据    /var/www/cobbler/images/ : 导入发行版的kernel和initrd镜像用于远程网络启动    /var/www/cobbler/repo_mirror/: yum 仓库存储目录日志目录    /var/log/cobbler/installing: 客户端安装日志    /var/log/cobbler/cobbler.log : cobbler日志</code></pre><h3 id="cobbler命令介绍"><a href="#cobbler命令介绍" class="headerlink" title="cobbler命令介绍"></a>cobbler命令介绍</h3><pre><code>cobbler commands介绍cobbler check 核对当前设置是否有问题cobbler list 列出所有的cobbler元素cobbler report 列出元素的详细信息cobbler sync 同步配置到数据目录,更改配置最好都要执行下cobbler reposync 同步yum仓库cobbler distro 查看导入的发行版系统信息cobbler system 查看添加的系统信息cobbler profile 查看配置信息</code></pre><h3 id="cobbler重要的参数-及下面需要修改的4行内容"><a href="#cobbler重要的参数-及下面需要修改的4行内容" class="headerlink" title="cobbler重要的参数:及下面需要修改的4行内容"></a>cobbler重要的参数:及下面需要修改的4行内容</h3><pre><code>/etc/cobbler/settings中重要的参数设置    default_password_crypted: &quot;$1$gEc7ilpP$pg5iSOj/mlxTxEslhRvyp/&quot;    server: 192.168.34.17    next_server: 192.168.34.17          server：&lt;cobbler服务器的 IP 地址&gt;    manage_dhcp: 1    manage_tftpd：1    pxe_just_once：1</code></pre><h3 id="cobbler环境检查：先启动cobbler服务再检查"><a href="#cobbler环境检查：先启动cobbler服务再检查" class="headerlink" title="cobbler环境检查：先启动cobbler服务再检查"></a>cobbler环境检查：先启动cobbler服务再检查</h3><pre><code>1.先启动cobbler服务，再用cobbler check 进行检查执行Cobbler check命令会报如下异常1 : The ‘server’ field in /etc/cobbler/settings must be set to something     other than localhost, or kickstarting features will not work. This    should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the ‘next_server’ field in /etc/cobbler/    settings must be set to something other than 127.0.0.1, and should    match the IP of the boot server on the PXE network.3 : some network boot-loaders are missing from /var/lib/cobbler/loaders,     you may run ‘cobbler get-loaders’ to download them, or, if you    only want to handle x86/x86_64 netbooting, you may ensure that you have installed a recent version of the syslinux package installed and    can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32,    elilo.efi, and yaboot. The ‘cobbler get-loaders’ command is the easiest way to resolve these requirements.4 : change ‘disable’ to ‘no’ in /etc/xinetd.d/rsync5 : comment ‘dists’ on /etc/debmirror.conf for proper debian support6 : comment ‘arches’ on /etc/debmirror.conf for proper debian support7 : The default password used by the sample templates for newly installed     machines (default_password_crypted in /etc/cobbler/settings)    is still set to ‘cobbler’ and should be changed, try: “openssl passwd -1 -salt ‘random-phrase-here’ ‘your-password-here’” to generate new    one8 : fencing tools were not found, and are required to use the (optional)     power management features. install cman or fence-agents to use them</code></pre><h3 id="Cobbler的8项报错解决方法"><a href="#Cobbler的8项报错解决方法" class="headerlink" title="Cobbler的8项报错解决方法"></a>Cobbler的8项报错解决方法</h3><pre><code>错误信息都是在/etc/cobbler/settings文件改了4行，在下文体现执行Cobbler check报错解决方式    第一个错误解决方法：    1.修改/etc/cobbler/settings文件中的server参数的值为提供cobbler服务的主机相        应的IP地址或主机名：384行，然后重新启动cobbler            server: 192.168.34.107    2.修改/etc/cobbler/settings文件中的next_server参数的值为提供PXE服务的主机        相应的IP地址:272行，指定的tftp的服务器地址            next_server: 192.168.34.107    3.执行cobbler get-loaders和cobbler sync；        如果当前节点可以访问互联网，执行&quot;cobbler get-loaders&quot;命令即可；         cobbler会自动通过互联网把最小化的系统启动文件下载下来放到        /var/lib/cobbler/loaders/下，再通过&quot;cobbler sync&quot;命令同步到/var/lib/tftpboot/下    4.cobbler认为是在centos6上，tftp服务是依赖于xinetd的，提示启动xinetd,在        这里，由于是在cnetos7上安装的，这项可以忽略    5.执行“chkconfig rsync on”命令即可        4,5,6项如果是在centos7上安装的cobbler是不需要修改也可以启动的    7.第7项是说安装的操作系统密码cobbler事先已经帮忙设置好了，但是不安全，需要自己        去修改一个自定义的密码(通过openssl passwd -1)生成：101行            default_password_crypted：修改成自己设置的密码备注：在这个提示里，还有一项建议修改，之前用PXE的时候，搭建的DHCP服务，dhcpd.conf    文件时通过模板生成的，但是在cobbler中，可以通过colbber来生成，但是需要改    /etc/cobbler/settings一项配置：242行        manage_dhcp: 0 改成 manage_dhcp: 1    再通过cobbler自带的dhcp模板：/etc/cobbler/dhcp.template，生成dhcpd.conf    只需要把这个模板改一下就行了，而不用想PXE那样通过模板生成dhcpd.conf文件    把dhcp.template里的网段地址改一下        subnet 192.168.34.0 netmask 255.255.255.0 {             option subnet-mask         255.255.255.0;             range dynamic-bootp        192.168.34.20 192.168.34.100;    再通过cobbler sync重新生成/etc/dhcp/dhcpd.conf,并且会开启DHCP服务</code></pre><h3 id="上面的报错全部解决之后，且httpd-tftp，dhcp-cobbler都启动之后，实际上就已经具备了雏形了"><a href="#上面的报错全部解决之后，且httpd-tftp，dhcp-cobbler都启动之后，实际上就已经具备了雏形了" class="headerlink" title="上面的报错全部解决之后，且httpd,tftp，dhcp,cobbler都启动之后，实际上就已经具备了雏形了"></a>上面的报错全部解决之后，且httpd,tftp，dhcp,cobbler都启动之后，实际上就已经具备了雏形了</h3><h3 id="var-lib-tftpboot的目录结构-上面的第三步完成后就生成下面的所有文件了"><a href="#var-lib-tftpboot的目录结构-上面的第三步完成后就生成下面的所有文件了" class="headerlink" title="/var/lib/tftpboot的目录结构:上面的第三步完成后就生成下面的所有文件了"></a>/var/lib/tftpboot的目录结构:上面的第三步完成后就生成下面的所有文件了</h3><pre><code>[root@mini7-1 tftpboot]#tree /var/lib/tftpboot    /var/lib/tftpboot    ├── boot    │   └── grub    │       └── menu.lst    ├── etc    ├── grub    │   ├── efidefault    │   ├── grub-x86_64.efi    │   ├── grub-x86.efi    │   └── images -&gt; ../images    ├── images    ├── images2    ├── memdisk    ├── menu.c32    ├── ppc    ├── pxelinux.0    ├── pxelinux.cfg    │   └── default    ├── s390x    │   └── profile_list    └── yaboot</code></pre><h3 id="接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘-centos6-amp-centos7"><a href="#接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘-centos6-amp-centos7" class="headerlink" title="接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘(centos6&amp;centos7)"></a>接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘(centos6&amp;centos7)</h3><pre><code>cobbler命令的选项：cobbler &lt;distro|profile|system|repo|image|mgmtclass|package|file&gt; ...         [add|edit|copy|getks*|list|remove|rename|report] [options|--help]cobbler &lt;aclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink&gt; [options|--help]这里用import选项将6和7的光盘导入cobbler的主机上    mount /dev/sr0 /mnt/   ---&gt;挂载centos7光盘    mount /dev/sr1 /media  ---&gt;挂载centos6光盘    cobbler import --path=/mnt/ --name=Centos-7.5-x86_64 --arch=x86_64    cobbler import --path=/media/ --name=Centos-6.10-x86_64 --arch=x86_64cobbler会把光盘拷贝到/var/www/cobbler/下分开存放，目录结构如下[root@mini7-1 cobbler]#tree -d /var/www/cobbler/var/www/cobbler├── images│   ├── Centos-6.10-x86_64│   └── Centos-7.5-x86_64├── ks_mirror│   ├── Centos-6.10-x86_64│   │   ├── EFI│   │   │   └── BOOT│   │   ├── images│   │   │   └── pxeboot│   │   ├── isolinux│   │   ├── Packages│   │   └── repodata│   ├── Centos-7.5-x86_64│   │   ├── EFI│   │   │   └── BOOT│   │   │       └── fonts│   │   ├── images│   │   │   └── pxeboot│   │   ├── isolinux│   │   ├── LiveOS│   │   ├── Packages│   │   └── repodata│   └── config├── links│   ├── Centos-6.10-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-6.10-x86_64│   └── Centos-7.5-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-7.5-x86_64├── localmirror├── misc├── pub├── rendered├── repo_mirror└── svc拷贝完，cobbler sync再同步一次然后cobbler会把/var/lib/tftpboot/pxelinux.cfg/default文件自动更新，生成新的菜单DEFAULT menuPROMPT 0MENU TITLE Cobbler | http://cobbler.github.io/TIMEOUT 200TOTALTIMEOUT 6000ONTIMEOUT localLABEL local        MENU LABEL (local)        MENU DEFAULT        LOCALBOOT -1LABEL Centos-6.10-x86_64        kernel /images/Centos-6.10-x86_64/vmlinuz        MENU LABEL Centos-6.10-x86_64        append initrd=/images/Centos-6.10-x86_64/initrd.img ksdevice=bootif lang=  kssendmac text  ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-6.10-x86_64        ipappend 2LABEL Centos-7.5-x86_64        kernel /images/Centos-7.5-x86_64/vmlinuz        MENU LABEL Centos-7.5-x86_64        append initrd=/images/Centos-7.5-x86_64/initrd.img ksdevice=bootif lang=  kssendmac text  ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-7.5-x86_64        ipappend 2MENU end</code></pre><p> 此时，就可以用cobbler实现自动化安装了，但是不能自定义ks应答文件安装，下面会讲解如何自定义cobbler的应答文件</p><h3 id="Cobbler中自定义应答文件"><a href="#Cobbler中自定义应答文件" class="headerlink" title="Cobbler中自定义应答文件"></a>Cobbler中自定义应答文件</h3><p>之前在PXE安装时，是自定义的kickstart应答文件，在cobbler中如何实现？</p><pre><code>1.在cobbler中，应答文件是放在/var/lib/cobbler/kickstarts/中2.把之前制作的ks6-mini.cfg，ks7-mini.cfg拷贝到此目录，但是拷贝完，但cobbler是无    法识别这些应答文件是对应的那个发行版本的，所以要绑定3.将自定义的应答文件和安装版本进行绑定4.这两个应答文件有一项需要修改    即url --url=这一项，要改成cobbler的yum源路径，$tree这里只显示ks6-mini.cfg的详细信息    install    url --url=http://192.168.34.103/centos/6/os/x86_64/  (PXE下的源路径)        #httpd的yum源路径，要改成$tree        或者改成具体的地址：即光盘拷贝到cobbler的具体路径        http://192.168.34.107/cobbler/ks_mirror/Centos-6.10-x86_64/    lang en_US.UTF-8    keyboard us    text      #纯文本安装    reboot    #安装完重启    network --onboot yes --device eth0 --bootproto dhcp --noipv6    rootpw  --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt    JjA57WrZO0    firewall --service=ssh      关闭防火墙    authconfig --enableshadow --passalgo=sha512    selinux --enforcing         关闭selinux    timezone Asia/Shanghai      时区信息    bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot;     # The following is the partition information you requested    # Note that any partitions you deleted are not expressed    # here so unless you clear all partitions first, this is    # not guaranteed to work    clearpart --all        清空分区信息    zerombr                清空mbr    #自定义的分区信息    part /boot --fstype=ext4 --size=1024    part / --fstype=ext4 --size=50000    part /data --fstype=ext4 --size=30000    part swap --size=2048    #自定义的分区信息    %packages    @core    %end   只安装最基本的核心包，后面也可以加上安装后脚本</code></pre><h3 id="将KS和OS关联，生成启动新的菜单"><a href="#将KS和OS关联，生成启动新的菜单" class="headerlink" title="将KS和OS关联，生成启动新的菜单"></a>将KS和OS关联，生成启动新的菜单</h3><p>自定义的应答文件的绑定、删除、重命名、显示菜单栏对应的ks应答文件信息</p><pre><code>在cobberl中    distro中记录的是cobbler中安装的发型版本对应的原文件的    [root@mini7-1 kickstarts]#cobbler distro list       Centos-6.10-x86_64       Centos-7.5-x86_64在cobberl中    profile是对应的各个发型版本的安装方法，就是安装启动界面的选择菜单栏，有多少个        就对应多少个菜单栏：如下图只有两个    [root@mini7-1 kickstarts]#cobbler profile list       Centos-6.10-x86_64       Centos-7.5-x86_64将自定义的应答文件和安装版本进行绑定：cobbler profile命令绑定将ks6-mini.cfg和centos6进行绑定    cobbler profile add --name=centos-6.10-x86_64_mini --distro=Centos-6.10-x86_64      --kickstart=/var/lib/cobbler/kickstarts/ks6-mini.cfgcobbler profile add --name=centos-7.5-x86_64_mini     --distro=Centos-7.5-x86_64     --kickstart=/var/lib/cobbler/kickstarts/ks7-mini.cfg也可以删除应答文件：    cobbler profile remove --name=Centos-6.10-x86_64    cobbler profile remove --name=Centos-7.5-x86_64也可以修改带单名    cobbler profile rename --name=Centos-7.5-x86_64             --newname=centos-7.5-x86_64_desktop查看菜单项对应的具体是哪个应答文件信息    cobbler profile report --name=centos-7.5-x86_64_mini/var/lib/tftpboot/pxelinux.cfg/default会自动生成新的菜单项，从cobbler profile list,也可以看出来[root@mini7-1 tftpboot]#cobbler profile list   Centos-6.10-x86_64   Centos-7.5-x86_64   centos-6.10-x86_64_mini   centos-7.5-x86_64_mini</code></pre><h3 id="cobbler的web管理实现"><a href="#cobbler的web管理实现" class="headerlink" title="cobbler的web管理实现"></a>cobbler的web管理实现</h3><p>此外cobbler是带有web管理界面的，不过需要安装web界面的包<br>    yum install cobbler-web -y</p><pre><code>配置文件：    [root@mini7-1 kickstarts]#rpm -qf cobbler-web    /etc/httpd/conf.d/cobbler_web.conf    cobbler-web是经过http协议的，所以 安装完，需要重启httpd服务    然后看到对应的是443端口启动了</code></pre><p>登录界面是，因为cobbler-web是https加密的<br>/etc/cobbler/modules.conf 验证方法;<br>/etc/cobbler/users.digest 记录的用户<br>增加用户</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;在服务器很多的情况下，用U盘或者光盘安装时，就显得有点吃力了，虽然可以用PXE进行安装，但是PXE不支持UEFI&lt;br&gt;所以现在更多使用Cobbler来实现自动化部署.&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="系统安装" scheme="https://www.liukui.tech/categories/%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="运维，linux，windows" scheme="https://www.liukui.tech/tags/%E8%BF%90%E7%BB%B4%EF%BC%8Clinux%EF%BC%8Cwindows/"/>
    
  </entry>
  
</feed>
