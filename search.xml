<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[httpd脚本]]></title>
    <url>%2F2018%2F12%2F30%2Fhttpd%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[httpd服务 httpd服务脚本#!/bin/bash # # httpd Startup script for the Apache HTTP Server # # chkconfig: - 85 15 # description: The Apache HTTP Server is an efficient and extensible \ # server implementing the current HTTP standards. # processname: httpd # config: /etc/httpd/conf/httpd.conf # config: /etc/sysconfig/httpd # pidfile: /var/run/httpd/httpd.pid # ### BEGIN INIT INFO # Provides: httpd # Required-Start: $local_fs $remote_fs $network $named # Required-Stop: $local_fs $remote_fs $network # Should-Start: distcache # Short-Description: start and stop Apache HTTP Server # Description: The Apache HTTP Server is an extensible server # implementing the current HTTP standards. ### END INIT INFO # Source function library. . /etc/rc.d/init.d/functions if [ -f /etc/sysconfig/httpd ]; then . /etc/sysconfig/httpd fi # Start httpd in the C locale by default. HTTPD_LANG=${HTTPD_LANG-&quot;C&quot;} # This will prevent initlog from swallowing up a pass-phrase prompt if # mod_ssl needs a pass-phrase from the user. INITLOG_ARGS=&quot;&quot; # Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server # with the thread-based &quot;worker&quot; MPM; BE WARNED that some modules may not # work correctly with a thread-based MPM; notably PHP will refuse to start. # Path to the apachectl script, server binary, and short-form for messages. apachectl=/usr/sbin/apachectl httpd=${HTTPD-/usr/sbin/httpd} prog=httpd pidfile=${PIDFILE-/var/run/httpd/httpd.pid} lockfile=${LOCKFILE-/var/lock/subsys/httpd} RETVAL=0 STOP_TIMEOUT=${STOP_TIMEOUT-10} # The semantics of these two functions differ from the way apachectl does # things -- attempting to start while running is a failure, and shutdown # when not running is also a failure. So we just do it the way init scripts # are expected to behave here. start() { echo -n $&quot;Starting $prog: &quot; LANG=$HTTPD_LANG daemon --pidfile=${pidfile} $httpd $OPTIONS RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch ${lockfile} return $RETVAL } # When stopping httpd, a delay (of default 10 second) is required # before SIGKILLing the httpd parent; this gives enough time for the # httpd parent to SIGKILL any errant children. stop() { status -p ${pidfile} $httpd &gt; /dev/null if [[ $? = 0 ]]; then echo -n $&quot;Stopping $prog: &quot; killproc -p ${pidfile} -d ${STOP_TIMEOUT} $httpd else echo -n $&quot;Stopping $prog: &quot; success fi RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f ${lockfile} ${pidfile} } reload() { echo -n $&quot;Reloading $prog: &quot; if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then RETVAL=6 echo $&quot;not reloading due to configuration syntax error&quot; failure $&quot;not reloading $httpd due to configuration syntax error&quot; else # Force LSB behaviour from killproc LSB=1 killproc -p ${pidfile} $httpd -HUP RETVAL=$? fi fi echo } # See how we were called. case &quot;$1&quot; in start) start ;; stop) stop ;; status) status -p ${pidfile} $httpd RETVAL=$? ;; restart) stop start ;; condrestart|try-restart) if status -p ${pidfile} $httpd &gt;&amp;/dev/null; then stop start fi ;; force-reload|reload) reload ;; graceful|help|configtest|fullstatus) $apachectl $@ RETVAL=$? ;; *) echo $&quot;Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|reload|status|fullstatus|grace ful|help|configtest}&quot; RETVAL=2 esac exit $RETVAL]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议]]></title>
    <url>%2F2018%2F12%2F18%2FHTTP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[HTTP协议和APACHE原理Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等本文说的是HTTP SERVERapacheHTTP2.4的官方文档http2.4文档：安装，模块，指令等说明HTTP2.4官方指令参考文档指令参考文档 http协议:应用层协议,主流http/1.1版本http协议的版本区别http0.9、http1.0、http1.1和http2.0的版本区别 http/0.9: 只有一个GET命令，且只能回应.html文件格式，像.txt等都不支持 http/1.0:效率太低 1.支持cache, MIME(支持各种资源类型), method2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低3.引入了POST命令和HEAD命令，头部信息和4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用 http/1.1:主流使用版本 1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭， 对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性 这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求 2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)4.缺点： 同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象5.解决队头堵塞的办法： 为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度: 不带状态怎么理解？ http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点 http/2.0：解决 HTTP/1.1效率不高的问题 1.头信息和数据体都是二进制，称为头信息帧和数据帧2.和http1.1区别：请求不需要排队，提高效率 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息) HTTP工作机制 工作机制主要分为两步：请求和响应 http请求：http requesthttp响应：http response一次http事务：请求响应 Web资源：web resource一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源的集合 静态页面/文件：无需服务端做出额外处理; 服务器端是什么样传到客户端就是什么样，比如下面这些 比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi 只不过浏览器有时会解析出来以好看的页面展示给用户 动态页面/文件：服务端执行程序，返回执行的结果 服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果 文件后缀：.php, .jsp ,.asp,.sh等 将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户 提高HTTP连接性能 并行连接：通过开多个TCP连接发起并发的HTTP请求持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，管道化连接：通过共享TCP连接发起并发的HTTP请求复用的连接：交替传送请求和响应报文（实验阶段） HTTP协议的其他相关技术 1.URI：一般把URI认为是URLURI: Uniform Resource Identifier 统一资源标识，分为URL和URN 1.URN: Uniform Resource Naming，统一资源命名 如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名 2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置 如输入一个网址，能具体体现出这个资源在互联网上的位置 两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址 URL的组成scheme://user:password@host:port/path;params?query#frag scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等user:用户，某些方案访问资源时需要的用户名password:密码，用户对应的密码，中间用：分隔Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔 网站访问量 1.IP(独立IP)：即Internet Protocol,指独立IP数。 如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个 2.PV(访问量)： 即Page View, 页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数， PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量 一般为了博客为了好看的访问量，都是统计PV量 3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。 网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。 如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1 Web服务请求处理步骤很切合实际生活：比如当我们打开一个浏览器，输入一个www.taobao.com，在互联网后台发生了什么？这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图 当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程每个过程都是一段需要原理详细描述的. 一次完整的http请求处理过程1.建立连接：接收或拒绝连接请求 2.接收请求：接收客户端请求报文中对某资源的一次请求的过程 Web访问响应模型（Web I/O） 单进程I/O模型：访问量不大 启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应 会造成请求排队现象，只适用于访问并发不大的情况 多进程I/O模型： 系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求 如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点 而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的 复用I/O结构： 开启多个进程进程，而一个进程又同时监控N个连接请求 只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗 实现方法：多线程模型和事件驱动 多线程模型：一个进程生成N个线程，每线程响应一个连接请求 事件驱动：一个进程处理N个请求 复用的多进程I/O模型： 启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求 充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的 nginx使用的复用多进程I/O模型 1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程 2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应 避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费 同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题 参考下面的HTTP的MPM三种工作模式 3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理 分析元数据：请求报文首部信息获得method &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt; HEADERS 格式 name:value &lt;request body&gt; 通过method来响应用户请求，比如下载(get)，上传等信息 HTTP常用请求方式，Method GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS 4.访问资源： 服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源 在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件 web服务器资源路径映射方式： (a) docroot (b) alias (c) 虚拟主机docroot (d) 用户家目录docroot 5.构建响应报文： 一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体 1）响应实体 描述了响应主体MIME类型的Content-Type首部 描述了响应主体长度的Content-Length 2）URL重定向 web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径 3）MIME类型 当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文 将构建完的响应报文发送给用户 将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户 用户再层层解封装获得index.html的内容 7.记录日志 最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务 通过在/var/log/httpd/acess_log日志中记录http的响应记录数 方便分析日志统计该网站的IP，PV量等信息 Http协议http协议 http/0.9, http/1.0, http/1.1, http/2.0 http协议：stateless 无状态 服务器无法持续追踪访问者来源 解决http协议无状态方法 cookie 客户端存放 session 服务端存放 http事务：一次访问的过程 请求：request 响应：response Session和Cookie的区别前言: HTTP是一种无状态的协议，为了分辨链接是谁发起的，就需要我们自己去解决这个问题。 不然有些情况下即使是同一个网站我们每打开一个页面也都要登录一下。而Session和 Cookie就是为解决这个问题而提出来的两个机制。 应用场景: 1.日常登录一个网站，今天输入用户名密码登录了，第二天再打开很多情况下就直接打开 了。这个时候用到的一个机制就是cookie。 2.session的一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而 服务器端如何判别呢，所以也需要存储一些信息，这里就用到了session。 Cookie的原理： HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。 也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。 这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设 计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行 保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在 请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服 务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端 保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报 文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后， 会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录， 最后得到之前的状态信息。 通俗讲，Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时 候减少一些步骤。另外一个更准确的说法是：Cookies是服务器在本地机器上存储的小段文 本并随每一个请求发送至同一个服务器，是一种在客户端保持状态的方案。 session的原理： session就是一种保存上下文信息的机制，她是针对每一个用户的，session的内容在服 务器端，通过sessionId来区分不同的客户，session是以cookie或url重写为基础的， 默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie，我们成为session cookie，以区分persistent coookies，注意session cookie是存储于浏览器内存中的 ，并不是写到硬盘上的；我们通常是看不见JSESSIONID的，但是当我们禁用浏览器的 cookie后，web服务器会采用url重写的方式传递sessionid，我们就可以在浏览器看到 sessionid=HJHADKSFHKAJSHFJ之类的字符串；session cookie针对某一次会话而言，会话结束session cookie也就消失了 session与cookie的区别： 1.session保存在服务器，客户端不知道其中的信息；cookie保存在客户端，服务端可以 知道其中的信息 2.session中保存的是对象，cookie中保存的是字符串 3.session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个 地方都可以访问到；而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不道德 session与cookie的联系： session是需要借助cookie才能正常工作的，如果客户端完全禁止cookie，session将失 效 Http应用层的报文头部:又分请求报文和响应报文两种-HTTP请求报文头部 开始行 方法：method GET： 从服务器获取一个资源 HEAD： 只从服务器获取文档的响应首部 POST： 向服务器输入数据，通常会再由网关程序继续处理 PUT： 将请求的主体部分存储在服务器中，如上传文件 DELETE： 请求删除服务器上指定的文档 TRACE： 追踪请求到达服务器中间经过的代理服务器 OPTIONS：请求服务器返回对指定资源支持使用的请求方法 URL:路径 首部行 实体行 -HTTP响应报文头部 开始行 版本：version HTTP/&lt;major&gt;.&lt;minor&gt;1.1/2等等 状态码： 三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况 短语： 状态码所标记的状态的简要描述 首部行 实体行 Http常见的状态码和状态码分类status(状态码)： 1xx：100-101 信息提示 2xx：200-206 成功 3xx：300-305 重定向 4xx：400-415 错误类信息，客户端错误 5xx：500-505 错误类信息，服务器端错误 200： 成功，请求数据通过响应报文的entity-body部分发送;OK 301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资 源现在所处的新位置；Moved Permanently 302： 响应报文Location指明资源临时新位置 Moved Temporarily 304： 如果之前访问一个网站，在本机上有缓存了，当再次访问时，就会出现304的状态码， 提示本地有不需要再去服务器上下载页面 401： 需要输入账号和密码认证方能访问资源；Unauthorized 403： 没有权限访问，请求被禁止了；Forbidden 404： 服务器无法找到客户端请求的资源；要访问的文件不存在 500： 服务器内部错误；Internal Server Error 502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；Bad Gateway 503： 服务不可用，临时服务器维护或过载，服务器无法处理请求 可能是服务器down机了，或者http服务关闭了 504： 网关超时；转给后端服务器时，时间太长 curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因curl是基于URL语法在命令行方式下工作的文件传输工具 1.它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。 2.curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证， HTTP上传，代理服务器，cookies，用户名/密码认证,下载文件断点续传，上载文件断 点续传, http代理服务器管道（ proxy tunneling） 3.还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等 4.curl的强大在于能模拟各种浏览器自定义请求报文头部等信息，来访问某些控制严格的网站 curl [options] [URL...] -A/--user-agent &lt;string&gt; 冒充浏览器类型，实际上在请求报文修改了User-Agent curl -A &apos;IE20&apos; http://192.168.34.103在http日志中可看到 一般用于测试访问网站或者爬虫功能要使用不同浏览器访问 -e/--referer &lt;URL&gt; 来源网址，防盗链相关 比如，伪装从百度跳转的192.168.34.103 curl -e &apos;www.baidu.com&apos; http://192.168.34.103 --cacert &lt;file&gt; CA证书 (SSL) -k/--insecure 允许忽略证书进行 SSL 连接 --compressed 要求返回是压缩的格式 -H/--header &lt;line&gt;自定义首部信息访问网站 -i 显示页面内容，包括报文首部信息 -I/--head 只显示响应报文首部信息 -D/--dump-header &lt;file&gt; 将url的header信息存放在指定文件中，重定向 --basic 使用HTTP基本认证，401认证 -u/--user &lt;user[:password]&gt;设置服务器的用户和密码 -L 如果有3xx响应码，重新发请求到新位置 如果访问的网页被重定向到其他地方时，系统只会提示网页被重定向了，并不会跳转 -L就可以请求到新的页面上 -O 使用URL中默认的文件名保存文件到本地 -o &lt;file&gt; 将网络文件保存为指定的文件中 --limit-rate &lt;rate&gt; 设置传输速度 -0/--http1.0 数字0，使用HTTP 1.0 -v/--verbose 更详细 -C 选项可对文件使用断点续传功能 -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中 -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址 -X/--request &lt;command&gt; 向服务器发送指定请求方法 -U/--proxy-user &lt;user:password&gt; 代理服务器用户和密码 -T 选项可将指定的本地文件上传到FTP服务器上 --data/-d 方式指定使用POST方式传递数据 -b name=data 从服务器响应set-cookie得到值，返回给服务器 elinks工具： 字符界面的浏览器，显示页面内容和源码等 elinks [OPTION]... [URL]... -dump: 非交互式模式，将URL的内容输出至标准输出 比如有些网站是不允许复制的，通过-dump就可以把网站页面文字抓取到本地了 elinks -dump www.baidu.com 不过一般都是用js脚本限制了复制功能，在浏览器关闭js，或查看源码都可以 -source:打印源码 HTTP介绍特性：高度模块化：core + modulesDSO: Dynamic Shared Object 动态加/卸载MPM：multi-processing module多路处理模块 HTTP的三种工作模型：MPM工作模式多用途的处理模块，三种模型分别是，默认使用prefork模型因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型 1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型一个主进程：生成和回收n个子进程，创建套接字，不响应请求 多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过 1024个，消耗比较大内存资源 受限于并发访问控制的内部系统调用机制： select()；内生使用限制最多只能使用1024个描述符，所以最多也就1024个进程 epoll(); Prefork MPM: 预派生模式，有一个主控制进程，然后生成多个子进程，使用select模型，最 大并发1024，每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定 ，可以设置最大和最小进程数，是最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景。 优点：稳定 缺点：慢，占用资源，不适用于高并发场景 配置文件原内容： &lt;IfModule mpm_prefork_module&gt; StartServers 5 #定义apache服务在启动时启动的子进程数量 MinSpareServers 5 #定义最小空闲进程数，空闲进程就是没有处理用户请求的进程数 MaxSpareServers 10 #定义最大空闲进程数 MaxRequestWorkers 250 #定义在prefork模式下的最大并发连接数，表示了apache的最大并发处理能力，超过的连接请求将被排队等候处理。 MaxConnectionsPerChild 0 #进程生命周期内，处理的最大请求数目。达到该数目后，进程将死掉。如果设置 为0，表示没有限制。该参数的意义在于，避免了可能存在的内存泄露带来的系统问题。 &lt;/IfModule&gt; 如果确定合适的MaxRequestWorkers呢？ 首先，通过top命令查看apache进程占用的资源，主要看%CPU和%MEM这两个指标，例如，每个进程的CPU占用率不超过 1%，每个进程的内存占用率不超过2%，考虑内存限制，比较合适的apache进程数量为50个，然后，逐步测试最大值。 通过观测得来的CPU和内存的指标有一定的误差，一般可以适当调节这个数值，例如调到1.5或者2倍，再通过峰值场景下的机器是否卡顿来判断是继续上调还是下调。 2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性 缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！ woker MPM：是一种多进程和多线程混合的模型，有一个控制进程，启动多个子进程，每个子进程里面包含固定的线程 ，使用线程程来处理请求，当线程不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求， 由于其使用了线程处理请求，因此可以承受更高的并发。 优点：相比prefork 占用的内存较少，可以同时处理更多的请求 缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放 。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生） 配置文件原内容详解： &lt;IfModule mpm_worker_module&gt; StartServers 3 # #定义apache服务在启动时启动的子进程数量，默认是3个 MinSpareThreads 75 # 整个控制进程保持最小数的空闲线程数 MaxSpareThreads 250 # 整个控制进程保持最大数的空闲线程数 #ThreadLimit 64 # 每个子进程可以启动的线程数量上限值，默认没有设置 ThreadsPerChild 25 # 每个子进程启动的线程默认数量，开启启动两个子进程每个子进程25个 线程，就是apache 启动后开启25个线程。 MaxRequestWorkers 400 # 所有子进程加起来的线程数量最大值，数量等于最大启动的进程数*ThreadsPerChild(每个进程的线程数) MaxConnectionsPerChild 0 # 每个子进程被请求多少次服务后被kill掉重新生成一个新的子进程，为了解决内存回收方面的问题，0为不设置 &lt;/IfModule&gt; 3.event：事件驱动模型（worker模型的优化,worker模型的变种）event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用 每一个cpu核心生成一个进程； 一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n 注意这里的m*n和work的m*n是不同的机制 相比较worker的有点： 有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许 释放。这样增强了高并发场景下的请求处理能力 event MPM：Apache中最新的模式，属于事件驱动模型(epoll)，每个进程响应多个请求，在现在版本里的已经是稳定 可用的模式。它和worker模式很像，最大的区别在于，它解决了keep-alive场景下，长期被占用的线程的资源浪费问题 （某些线程因为被keep-alive，空挂在哪里等待，中间几乎没有请求过来，甚至等到超时）。event MPM中，会有一个 专门的线程来管理这些keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后， 又允许它释放。这样增强了高并发场景下的请求处理能力。 event只在有数据发送的时候才开始建立连接，连接请求才会触发工作线程，即使用了TCP的一个选项，叫做延迟接受连 接TCP_DEFER_ACCEPT，加了这个选项后，若客户端只进行TCP连接，不发送请求，则不会触发Accept操作，也就不会 触发工作线程去干活，进行了简单的防攻击（TCP连接）,可以使用Telnet进行测试验证： 主机192.168.10.130为客户端机器，192.168.10.131为apache服务器机器使用event模式： 在192.168.10.130上telnet 192.168.10.131 80，然后在192.168.10.130客户端机器上使用netstat查看，发现连 接已经建立，处于ESTABLISHED状态，然后再到apache服务器192.168.10.131使用netstat查看，发现是处于 SYN_RECV状态。 优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程， 当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放 缺点：没有线程安全控制 配置文件内容： &lt;IfModule mpm_event_module&gt; StartServers 3 #apache服务启动的子进程数，默认3个 MinSpareThreads 75 #控制进程保持最小的空闲线程数 MaxSpareThreads 250 #控制进程保持的最大空闲线程数 ThreadsPerChild 25 #每个子进程启动的线程数 MaxRequestWorkers 400 #并发最大请求数，也就是所有子进程加起来的线程数量，woker模式下的 400就是并发400，但是由于是异步处理请求的，因此这里的400比woker模型下的并发处理速度要快很多，因为event省略了工作线程的会话保持。 MaxConnectionsPerChild 0 #每个子进程请求多少次以后被kill掉重新生成一个新的子进程。 &lt;/IfModule&gt; 注意： event模型的强大的I/O机制 httpd从设计上就默认支持prefork 而nginx从设计上就支持event事件驱动模型 进程工作的角色切换 Httpd的功能特性httpd的常见特性： 虚拟主机：在一个物理服务器上搭建多个网站 IP、Port、FQDN CGI：Common Gateway Interface，通用网关接口 通过CGI接口处理动态的程序处理 反向代理 当有用户访问量大时，在前端有一个服务器充当调度器的角色 通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息 看不到后端真正提供服务的服务器群 负载均衡 路径别名 丰富的用户认证机制 basic digest 支持第三方模块 Httpd2.4新特性和安装以及配置新特性 MPM支持运行为DSO机制；以模块形式按需加载 在centos7上的httpd2.4上只有一个二进制程序 /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可 但是在centos6上的httpd2.2版本： 每个MPM模式都有各自对应的二进制程序 /usr/sbin/httpd /usr/sbin/httpd.event /usr/sbin/httpd.worker 如果更改MPM的模式，是需要改对应的二进制程序的 event MPM生产环境可用 异步读写机制 支持每模块及每目录的单独日志级别定义 每请求相关的专用配置 增强版的表达式分析式 毫秒级持久连接时长定义：httpd2.2只能精确到秒级别 上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的 所以在http中是可以定义连接时长(时长和传输请求两种方式)的 基于FQDN的虚拟主机不需要NameVirutalHost指令 httpd2.2创建虚拟主机时还需要NameVirutalHost指令 httpd2.4就不需要了 新指令，AllowOverrideList 支持用户自定义变量 更低的内存消耗 Httpd2.4的具体安装和配置Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了还支持第三方的模块，按需加载模块存放模块的路径：/etc/httpd/modules CentOS7程序环境安装：httpd-2.4 yum install httpd yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档 主要配置文件： /usr/sbin/httpd httpd的主程序文件 /usr/lib/systemd/system/httpd.service httpd的启动单元文件 /etc/httpd/conf/httpd.conf 主要配置文件 配置文件里的路径都是以/etc/httpd/为参考点的 /etc/httpd/conf.d/*.conf /etc/httpd/conf.modules.d/00-mpm.conf mpm相关 /etc/httpd/conf.modules.d/00-proxy.conf 配置代理相关 /etc/httpd/conf.modules.d/00-systemd.conf /etc/httpd/conf.modules.d/01-cgi.conf CGI相关 /var/cache/httpd httpd的缓存目录 /var/log/httpd httpd的日志文件目录 access_log: 访问日志 error_log：错误日志 /etc/httpd/modules httpd的模块存放路径，软件比较复杂 /usr/lib64/httpd/modules 也是httpd的模块存放路径 两个模块的路径实际上是软链接关系 /var/www/html httpd存放网页的目录：默认index.html 帮助文档包：在没有网络时查看帮助文档，建议安装 httpd-manual 检查配置文件语法： httpd –t 类似DNS的rndc语法检查功能 sudo：visudo功能 ansible:ansible -C|--check 执行前检查语法功能 cobbler 也有 httpd的控制和启动命令 systemctl enable|disable httpd.service systemctl {start|stop|restart|status|reload} httpd.service 备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作 有时reload是无效的，只能restart服务 Httpd2.4的常见配置 1.显示服务器版本信息HTTP2.4官方指令参考文档指令参考文档 主要组成: Global Environment 全局配置 Main server configuration 一个服务器上搭建一个网站叫主服务器 virtual host 虚拟主机，一台主机上搭建多个网站 练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)egrep -v ‘^ #.|^$’ /etc/httpd/conf/httpd.conf 常见配置一般都在/etc/httpd/conf/httpd.conf的文件中没有的配置选项可以加在httpd.conf文件最后，也可以放在/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加 1.显示服务器版本信息 访问http://192.168.34.103 打开f12调试模式，可以看到回应头的信息中带有apache的版本信息 也可以通过curl -I http://192.168.34.103来显示头信息 可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全 查看指令参考文档：修改ServerTokens选项建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全 2.修改监听的IP和Port Listen [IP:]PORT (1) 省略IP表示为本机所有IP (2) Listen监听端口至少一个，可以有多个端口 (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口 test.conf添加listen端口： listen 172.18.132.151:6666 6666端口只能通过此IP才能访问 3.持久连接：默认KeepAlive是开启的 Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接 断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级 副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞 折衷：使用较短的持久连接时间 设置： KeepAlive On|Off 设置持久连接开启或者关闭 KeepAliveTimeout 15 设置持久连接为15s 测试：telnet WEB_SERVER_IP PORT GET /index.html HTTP/1.1 Host: WEB_SERVER_IP host可以随便填写，但是在虚拟主机中是有区别的 4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event 默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf 修改mpm的文件 建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的 查看静态编译的模块 httpd -l 查看当前系统中httpd的静态编译及动态装载的加载的模块 httpd –M 动态模块加载：不需重启即生效 动态模块路径 /usr/lib64/httpd/modules/ 切换使用的MPM模块 在/etc/httpd/conf.modules.d/00-mpm.conf中 选择要启用的MPM相关的LoadModule指令即可 prefork的配置： StartServers 8 MinSpareServers 5 保留5个空闲子进程处理新的请求 MaxSpareServers 20 允许的最大空闲进程数 ServerLimit 256 最多进程数,最大20000，并发量建议最多10000 MaxRequestsPerChild 4000 子进程最多能处理的请求数量。在处理 MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进 程占用的内存就会释放(为0时永远不释放） worker和prefork配置类似，只不过会有线程数量的限制 从下面ps auxf的进程图可以看书httpd是使用的prefork模型，而且因为端口是80，开启需要特殊权限，所以父进程是root,子进程是apache 5.DSO： Dynamic Shared Object 加载动态模块配置 /etc/httpd/conf/httpd.conf Include conf.modules.d/*.conf 配置指定实现模块加载格式： LoadModule &lt;mod_name&gt; &lt;mod_path&gt; 模块文件路径可使用相对路径： 相对于ServerRoot（默认/etc/httpd） 6.定义’Main’ server的文档页面路径：存放页面的主目录 主目录是由DocumentRoot指令来设置的 网页文件默认是存在/var/www/html/下的，此处可以自定义 在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html” 如果要自定义主目录，还需要设置该目录为允许访问 在httpd2.2上是不需要设置权限访问的 但是在httpd2.4上是需要设置该目录允许访问的 修改格式如下： #DocumentRoot &quot;/var/www/html&quot; DocumentRoot &quot;/data/www&quot; &lt;directory /data/www&gt; Require all granted &lt;/directory&gt; 7.定义站点默认主页面 访问192.168.34.103默认显示的是index.html的内容， 这一项是由DirectoryIndex指令设置的 在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可 添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件 此处需要了解httpd的权限和访问报错的相关问题和默认主页面：1.访问192.168.34.103跳出的页面默认是index.html页面，如果不存在，则去找conf.d/welcome.conf文件，即报错提示，如果两个都不存在，显示的是/var/www/html目录下的文件列表，因为在httpd.conf配置文件中，定义options indexes选项2.默认页面和默认访问目录都是可以通过指令来指定的3.如果没有index.html文件，没有welcome.conf文件，没有options indexes配置，访问时会报错You don’t have permission to access / on this server.的提示.4.上面三条在下面第12条配置别名时，可以体现的很明显5.所以如果自定义目录和用别名，有时是需要设置目录访问权限、设置目录对应的index.html文件或者跳转的html文件(如果该文件存在就不需要设置了)，设置options indexes选项 8.站点访问控制常见机制 可基于两种机制指明对哪些资源进行何种访问控制 访问控制机制有两种：1.客户端来源地址，2.用户账号 而文件系统路径：可以是 1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配 示例： ‘‘’ 用的是扩展的正则表达式 通配符 &lt;Location /status&gt; 9.中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制 (1) Options：后跟1个或多个以空白字符分隔的选项列 在选项前的+，- 表示增加或删除指定选项 常见选项： Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制 适用于下载网站和镜像网站，不适合电商网站 FollowSymLinks：允许访问符号链接文件所指向的源文件, None：全部禁用 All： 全部允许 Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的 就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站 &lt;directory &quot;/data/www&quot;&gt; options Indexes Require all granted &lt;/directory&gt; FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件 &lt;directory &quot;/data/www&quot;&gt; options Indexes FollowSymLinks Require all granted &lt;/directory&gt; 实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.conf文件，welcome.conf文件就是页面上经常看到的测试123页面，把welcome.conf文件改名或删除，就会显示主目录下的所有列表文件了. (2) AllowOverride allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可 只对语句有效; allowoverride权限时卸载httpd的*.conf配置文件中的 AllowOverride All: .htaccess中所有指令都有效 AllowOverride None： .htaccess 文件无效 AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它 配置allowoverride示例： /etc/httpd/conf.d/test.conf中添加访问控制的目录 &lt;directory /data/www&gt; allowoverride all --&gt;这条必须写，代表.htaccess文件中的options生效 Require all granted &lt;/directory&gt; 在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中 options indexes FollowSymLinks (3) 基于IP的访问控制: 无明确授权的目录，默认拒绝 允许所有主机访问：Require all granted 拒绝所有主机访问：Require all denied 控制特定的IP访问： Require ip IPADDR：授权指定来源的IP访问 Require not ip IPADDR：拒绝特定的IP访问 控制特定的主机访问： Require host HOSTNAME：授权特定主机访问 Require not host HOSTNAME：拒绝 HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机 基于IP的访问控制示例： 如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表 除了/data/www/ceshi文件夹 &lt;directory /data/www&gt; options indexes &lt;RequireAll&gt; Require all granted Require not ip 192.168.34.107 &lt;/RequireAll&gt; &lt;/directory&gt; 2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问 &lt;directory /data/www&gt; options indexes Require all granted &lt;/directory&gt; &lt;directory /data/www/ceshi&gt; &lt;RequireAny&gt; Require all denied Require ip 192.168.34.107 &lt;/RequireAny&gt; &lt;/directory&gt; 10.日志设定：日志默认/var/log/httpd/下format官方说明文档 日志类型：访问日志(access_log)和错误日志(error_log) 日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式 在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义 LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined --&gt;由Logformat指令定义完起一个combined名 CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式 ErrorLog &quot;logs/error_log&quot; 可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径 日志中的格式各个项说明 %h 客户端IP地址 %l 远程用户,启用mod_ident才有效，通常为减号“-” %u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-” %t 服务器收到请求时的时间 %r First line of request，即表示请求报文的首行；记录了此次请求的“方法”， “URL”以及协议版本 %&gt;s 响应状态码 %b 响应报文的大小，单位是字节；不包括响应报文http首部 %{Referer}i 请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页 是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源，所以网站一般要加防盗链，防止资源被盗和占用服务器资源 %{User-Agent}i 指客户端的浏览器版本 11.设定默认字符集 一般不需要设置：基本上使用的是utf-8; AddDefaultCharset UTF-8 此为默认值 如果需要修改字符集，在test.conf或者httpd.conf下添加 AddDefaultCharset gb2312 即可 12.定义路径别名作用：默认访问的文件夹是设置的DocumentRoot文件夹，如果不是在默认文件夹下，而需求要实现把其他路径下的目录共享出来，这就用到了定义路径别名的功能 把一个URL起一个别名不指向真正的目录 在httpd2.4里目录如果没有开启允许时，默认是不允许访问的 例如：访问 /var/www/html/111,111这个目录可有可无，只是充当别名 实际上访问的是/data/www/ceshi目录 directoryindex ceshi.html alias /111 /data/www/ceshi &lt;directory /data/www/ceshi&gt; options indexes Require all granted &lt;/directory&gt; 注意：1.111只是一个别名，在/var/www/html下不需要创建；但是如果/var/www/html下有111的文件夹，如果设置别名后，则访问的是/data/www/ceshi目录，原目录下的111文件夹就失效了。2.在这里和上文第7条设置权限时有联系的，httpd2.4设置路径别名的时候，真正的路径也是需要在test.conf下设置权限的(/data/www/ceshi目录)3.如果/data/www/ceshi/下没有index.html会报权限不允许的错误，所以要设置默认主页面directoryindex，当然可以设置options indexes选项 13.基于虚拟账户的登录访问控制：提示401状态码 认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码 认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源 两种认证方式： basic：用的多，缺点是明文，后面可以用https进行加密 digest：兼容性差，用的少 用户的账号和密码:非linux用户密码 虚拟账号：多种存储方式，只用于httpd服务的，类似vsftp，samba服务的虚拟用户 存储：账号可放在文本文件，SQL数据库，ldap目录存储，nis等 因为basic使用的多，下文以basic认证配置示例 1.提供账号和密码存储（文本文件），如创建一个tom虚拟账户管理httpd htpasswd --&gt;可以指定加密算法 -c 自动创建文件，仅应该在文件不存在时使用 -p 明文密码 -d CRYPT格式加密，默认 -m md5格式加密 -s sha格式加密 -D 删除指定用户 htpasswd -c httpdpass tom :设定密码即可;目录可指定，后面改配置文件即可 htpasswd -s httpdpass jerry 再添加jerry用户，就不需要-c选项了 htpasswd -D httpdpass jerry 从文件中删除jerry用户 修改httpdpass权限，加固安全 chmod 600 httpdpass 或者也可以创建组文件httpdgroup，通过组来管理,组文件组和成员列表 testgroup: tom jerry 2. 在test.conf或者httpd.conf下定义安全域 &lt;directory /var/www/html/ksdir&gt; AuthType Basic ---&gt;使用的认证方式 AuthName &quot;Login&quot; ----&gt;登录提示信息 AuthUserFile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;加密账户文件 AuthGroupFile &quot;/etc/httpd/conf/httpdgroup&quot; --&gt;组账户 Require user tom ---&gt;允许用户访问的列表 Require group testgroup ---&gt;允许访问的组 &lt;/directory&gt; 但是：因为httpd线程是以apache运行的，而httpdpass是600权限，所以默认tom登录是没有权限的，让apache对httpdpass有读权限： setfacl -m u:apache:r httpdpass 即可 14.实现用户家目录的http共享;并实现账户机密访问 实现基础：基于模块mod_userdir.so实现 httpd -M |grep user 可以看出user加密的模块是已经加载的，直接改配置文件即可 在/etc/httpd/conf.d/userdir.conf文件中定义了家目录共享的格式，只需要启用就行了 实现步骤： 1. vim /etc/httpd/conf.d/userdir.conf &lt;IfModule mod_userdir.c&gt; UserDir enabled ---&gt;启用即可；默认不启用 UserDir public_html ---&gt;创建一个public_html文件 &lt;/IfModule&gt; 2.在test家目录下，创建public_html文件夹和public_html文件 su test mkdir public_html/ echo 23333 &gt; /public_html/public_html 3.因为httpd线程是apache身份登录的，所以要允许apache访问test用户的家目录 setfacl -m u:apache:x /home/test 4.设置test家目录访问权限及用户加密 &lt;directory /home/test/public_html&gt; authtype basic authname &quot;test home&quot; authuserfile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;调用之前创建的虚拟账户文件即可 Require user haha &lt;/directory&gt; 5.http访问test家目录方式,即可用加密账户登录 192.168.34.103/~test 15.ServerSignature On|Off|EMail 作用：当用户访问的页面不存在的情况下服务器会产生错误文档，而当ServerSignature选项是打开的情况下，错误文档会将服务器的名字，apahce的版本信息，显示在页面上，某种程度上会对web服务器产生不安全因素，所以一般建议关闭 在配置文件添加一行： ServerSignature off 即可 16.status页面 作用：显示apache的工作状态，有助于判断apache是否正常工作 status页面功能是由下面这个模块实现的：httpd LoadModule status_module modules/mod_status.so 实现步骤：在配置文件添加 &lt;Location &quot;/status&quot;&gt; SetHandler server-status &lt;/Location&gt; ExtendedStatus ON #显示扩展信息 记录的信息包括：启动时间，线程数，等待连接数，cpu，进程，MPM等信息 在实际生产中，由于apache服务器很多，就可以通过curl 192.168.34.103/status来抓取页面，分析apache某个指标是不是正常的； 比如编写简单一个脚本： curl 192.168.34.103/status |grep &quot;Apache Status&quot; || systemctl start httpd 17.实现http的虚拟主机 作用：一个物理服务器上实现多台虚拟主机，至于为什么会用到虚拟主机，有可能是因为要上线的同一网站的有多个域名，却只有一个公网IP地址，也有可能是主机不多啊..，所以虚拟主机的价值就体现出来了… 实现虚拟主机有三种方式 基于ip：为每个虚拟主机准备至少一个ip地址，一个主机可以配多个内网IP地址 基于port：为每个虚拟主机使用至少一个独立的port；80,8081,8082等等 基于FQDN：为每个虚拟主机使用至少一个FQDN 当然这三种方式，基于IP和port的对于用户来说不太现实，一般都是通过输入域名方式来实现虚拟主机搭建. 1.基于IP的虚拟主机搭建：但是这种方式用的比较少 先准备三个网站目录，和在本机上添加三个IP地址 &lt;virtualhost 192.168.34.103&gt; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost 192.168.34.200&gt; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost 192.168.34.210&gt; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; 重启服务即可 通过curl 192.168.34.103 curl 192.168.34.200 curl 192.168.34.210 即可获取到各自的index.html文件内容，对应的日志也都生成了 2.基于port的虚拟主机搭建，监听三个port即可;使用的不多 listen 8081 listen 8082 listen 8083 &lt;virtualhost *:8081&gt; servername &quot;www.a.com&quot; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost *:8082&gt; servername &quot;www.b.cn&quot; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost *:8083&gt; servername &quot;www.c.net&quot; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; 通过本机IP+port获得不同网站的信息 curl 192.168.34.103:8081 curl 192.168.34.103:8082 curl 192.168.34.103:8083 3.基于FQDN的虚拟主机搭建：用的最多 前提：这里就不搭建DNS服务器了，使用本机的hosts文件进行域名解析 &lt;virtualhost *:80&gt; servername &quot;www.a.com&quot; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost *:80&gt; servername &quot;www.b.cn&quot; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost *:80&gt; servername &quot;www.c.net&quot; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_c.log combined &lt;/virtualhost&gt; 测试：curl www.a.com curl www.b.cn curl www.c.net 就可获得各自的主页面信息从这telnet就可以理解出，如果在互联网通过域名访问时(同一IP)，返回的结果是不同网站的信息 [root@node7-1 ~]#telnet 192.168.34.103 80 Trying 192.168.34.103... Connected to 192.168.34.103. Escape character is &apos;^]&apos;. GET /index.html HTTP/1.1 HOST: www.a.com 当访问192.168.34.103时 HOST：即网站的域名，返回的结果就是其对应的页面信息在互联网上，一般是先在本地服务器上通过第三种方式搭建多个网站，然后再通过服务商的智能DNS解析，可以通过访问不同的域名，解析到IP地址，服务器根据输入的HOST：域名判断访问的是哪个网站，进而返回对应网站站点的信息，对于主机较少或者IP有限的环境中，使用http虚拟主机还是很方便的。]]></content>
      <categories>
        <category>web服务</category>
        <category>http</category>
      </categories>
      <tags>
        <tag>Web服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译安装LAMP]]></title>
    <url>%2F2018%2F12%2F10%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85LAMP%2F</url>
    <content type="text"><![CDATA[LAMP Centos7上编译安装LAMP 备注：本文编译PHP是基于fastCGI方式，php-fpm 编译准备： 在192.168.34.105上实现，准备安装包都放在/data/src下 apr-1.6.5.tar.bz2 apr-util-1.6.1.tar.bz2 httpd-2.4.37.tar.bz2 php-7.1.18.tar.bz2 wordpress-5.0-zh_CN.zip mariadb-10.2.19-linux-x86_64.tar.gz 准备开发包组： yum install &apos;develoment tools&apos; -y 1.编译安装httpd和apr 准备依赖包和解压安装包 yum install pcre-devel openssl-devel expat-devel apr-util-devel -y tar xvf apr-1.6.5.tar.bz2 tar xvf apr-util-1.6.1.tar.bz2 tar xvf httpd-2.4.37.tar.bz2 cp -r apr-1.6.5 httpd-2.4.37/srclib/apr cp -r apr-util-1.6.1 httpd-2.4.37/srclib/apr-util a.编译 cd httpd-2.4.37 ./configure \ --prefix=/data/httpd24 \ --enable-so \ --enable-ssl \ --enable-cgi \ --enable-rewrite \ --with-zlib \ --with-pcre \ --with-included-apr \ --enable-modules=most \ --enable-mpms-shared=all \ --with-mpm=prefork make &amp;&amp; make install b.准备环境变量 用自带的服务控制脚本：/app/httpd24/bin/apachectl就需要设置环境变量了 echo &apos;PATH=/mysql/httpd24/bin:$PATH&apos; &gt; /etc/profile.d/httpd24.sh . /etc/profile.d/httpd24.sh c.修改配置文件，为了安全以apache用户运行，并监听在本地 useradd -r -s /sbin/nologin apache vim /data/httpd24/conf/httpd.conf User apache Group apache ServerName localhost:80 2.二进制安装mariadb-10.2.19 a.准备用户和mysql数据库目录 useradd -r -s /sbin/nologin -d /data/mysql mysql mkdir /data/mysql chown mysql.mysql mysql/ b.解压二进制安装包： tar xvf mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local/ cd /usr/local ln -s mariadb-10.2.19-linux-x86_64/ mysql chown -R root.mysql /usr/local/mysql/ c.创建数据库文件:(通过自带脚本工具) cd /usr/local/mysql/ scripts/mysql_install_db --datadir=/mysql/data --user=mysql d.准备配置文件(不修改/etc/my.cnf)拷贝解压完的文件 mkdir /etc/mysql/ cp support-files/my-huge.cnf /etc/mysql/my.cnf 路径优先级高于/etc/my.cnf 根据性能来拷贝配置文件 [mysqld]中添加三个选项：/etc/mysql/my.cnf datadir = /mysql/data innodb_file_per_table = on skip_name_resolve = on 禁止主机名解析，建议使用 e.准备服务脚本，并启动服务 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld service mysqld start f.准备PATH路径 echo &apos;PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh systemctl start mysqld 为wordpress准备数据库和账号密码 mysql -e &apos;create database wordpress&apos; mysql -e &quot;grant all on *.* to php1@&apos;192.168.34.%&apos; identified by &apos;php123&apos;&quot; 3.FastCGI方式编译安装php-7.1.18 tar xf php-7.1.18.tar.bz2 安装依赖包 yum install libxml2-devel bzip2-devel libmcrypt-devel -y a.编译，指定安装数据路劲和配置文件路径 cd php-7.1.18 ./configure --prefix=/data/php \ --enable-mysqlnd \ --with-mysqli=mysqlnd \ --with-openssl \ --with-pdo-mysql=mysqlnd \ --enable-mbstring \ --with-freetype-dir \ --with-jpeg-dir \ --with-png-dir \ --with-zlib \ --with-libxml-dir=/usr \ --enable-xml \ --enable-sockets \ --enable-fpm \ --with-config-file-path=/etc \ --with-config-file-scan-dir=/etc/php.d \ --enable-maintainer-zts \ --disable-fileinfo make &amp;&amp; make install b.准备php配置文件 cd php-7.1.18 cp php.ini-production /etc/php.ini 可以修改当前时区和按照生产环境修改并发连接数等信息 c.创建nginx用户 useradd -s /sbin/nologin nginx d.准备php的conf文件 cd /data/php cp php-fpm.conf.default php-fpm.conf cp php-fpm.d/www.conf.default php-fpm.d/www.conf 修改监听地址和允许连接地址，因为是在一台编译的，监听地址不用改了 vim php-fpm.d/www.conf listen = 127.0.0.1:9000 ;listen.allowed_clients = 127.0.0.1 user = nginx group = nginx e.准备服务脚本: cp /data/src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm chkconfig --add php-fpm chkconfig php-fpm on 4.修改httpd文件，支持php和启用代理 编辑apache配置文件httpd.conf，以使apache支持php,并启用代理 vim /data/httpd24/conf/httpd.conf 1.取消下面两行的注释 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 2.定位至DirectoryIndex index.html 修改为DirectoryIndex index.php index.html 3.最后添加4行 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 重启apache服务，apachectl restart 5.准备wordpress,把wordpress文件全部移动到httpd24/htdocs下 cd /data/src unzip wordpress-5.0-zh_CN.zip cd wordpress mv * /data/httpd24/htdocs 为wordpress准备配置文件和数据库连接 cd /data/httpd24/htdocs mv wp-config-sample.php wp-config.php vim wp-config.php define(&apos;DB_NAME&apos;, &apos;wordpress&apos;); define(&apos;DB_USER&apos;, &apos;php&apos;); define(&apos;DB_PASSWORD&apos;, &apos;php123&apos;); define(&apos;DB_HOST&apos;, &apos;192.168.34.105&apos;); 修改/data/httpd24/htdocs的所有者和所属组 cd /data/httpd24 chown -R nginx.nginx htdocs/ 到此所以的编译安装和准备工作都做完了，把mysql,php-fpm,httpd启动即可 apachectl start systemctl start php-fpm systemctl start mysqld http://192.168.34.105 配置wordpress即可 备注： 创建的文章和账户是放在wordpress数据库中的; 图片是放在/data/httpd24/htdocs/wp-content/uploads下的 然后把这套系统搬到自己的云服务上就可以轻松的实现了,本文是基于LAMP架构实现的不过推荐使用LNMP架构，毕竟Nginx的强大可不是吹出来的.. 安装完成后，开启了一个新的世界，就可以开心的玩耍了,helloworld！]]></content>
      <categories>
        <category>web服务</category>
        <category>个人博客搭建</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker的资源限制]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E7%9A%84%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Docker资源限制 docker容器得以实现的三个组件： Namespace:内核中的名称空间是实现容器技术非常重要的组件 CGroups：实现容器的资源配额 1.如果没有资源配额的限定，比如恶意代码会占用宿主机上的很多资源，会造成其他容器无法运行的情况， 默认是宿主机上的所有资源. 2.cgroup允许将宿主机上的所有技术资源(CPU,内存等)做资源分割,以指定方式进行分配，而CPU和内存又分别支持两种不同的配额方式 3.CPU属于可压缩型资源，如果程序运行的cpu不够，只需要等待cpu资源即可，不会造成容器崩溃。 4.内存属于不可压缩型资源，如果一个进程依赖于3g内存来运行，宿主机只分配给它1g，则会造成OOM，这个进程就会因为内存耗尽而被终止. 内存的限制方式： -m|--memory= 限制容器的最大内存使用量，进程并不是一启动就占用最大内存的，而是 运行一段时间慢慢增长的，所以要分配给进程运行的最大内存. --memory-swap * 当前容器所允许使用的交换分区大小(生产环境是禁止启用交换内存 的，因为性能会急剧下降.) --memory-swappiness 使用交换分区的倾向性：因为使用交换分区会极大影响性能， 只有到万不得已才使用交换分区，数值越小,越会较晚使用交换分区，所以一般这个 值建议调小，默认是0-100 --memory-reservation 为系统保留多的内存空间，保证系统的正常运行 --kernel-memory 为内核保留多少内存空间 --oom-kill-disable 一旦某个容器发生OOM是否立刻kill这个容器，建议设置，因为 会造成整个宿主机的崩溃，也可以事先设定好内核和系统的内存空间，然后手动处理 发生OOM的容器，以便分析发生OOM的原因. 注意： 1.在容器内使用free命令可以看到的swap空间并不具有其所展现的空间指示意义. 2.-m|--memory=和 --memory-swap *一般是结合起来生效的 CPU的限制方式： 主流的分两种：共享式和CPU绑定式 --cpu-shares 共享方式是基于权重分配的，而且是根据容器的数量和CPU的权重动态 分配调整的.如果只有一个容器在运行，那么这个容器也会尽可能的占用宿主机的CPU资源，这种分配方式依然会有可能造成系统崩溃. --cpus &lt;value&gt; 定义容器最多跑满宿主机的几个核心数，例如宿主机有8核，限制容器 最多跑满2个核心数，而且这个2核可以跑在8个核心上加起来是2个核心数，也可以是 在2个核心上跑满.真正限制了容器使用的最大核心数. docker的1.13版以后都使用这个选项来定义. --cpuset-cpus 定义容器只能跑在宿主机核心的几号核心上，例如只允许跑在1号和3号核心上，那么 这个容器最多也就只能跑满这两个核心,也叫CPU绑定. 所以在创建启动容器一定要做资源限制，即使不清楚容器中某个程序要占用多大的资源时，也应该设置只允许占用宿主机一半的资源. 资源限制压测在docker hub上的lorel/docker-stress-ng镜像 -c N 启动几个进程对CPU进行压测 -vm N 启动几个进程对内存做压测 示例：通过该镜像进行压测 限制只能跑在cpu的0号和3号上，最多只能跑满2个核心数 限制最多占用512m的内存大小 docker run --name stress --cpus 2 --cpuset-cpus 0,3 -m 512m --rm lorel/docker-stress-ng -c 2 -vm 2 -docker stats命令查看结果 -top命令显示宿主机资源(安装1显示全部的CPU核心数信息)]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker存储卷]]></title>
    <url>%2F2018%2F10%2F18%2Fdocker%E5%AD%98%E5%82%A8%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[Docker Data Volume：docker存储卷 存储卷是什么： 存储卷是容器上一个或者多个“目录”，并将此“目录”与宿主机上的某目录建立关联关系， 存储卷在容器初始化之时会被创建，由baseimage提供的卷中的数据数据会在此时完成复制 为什么需要用到存储卷: docker启动一个容器是基于镜像的只读层，并在其上添加一个读写层，而镜像是由多个只读层叠加而来。如果运行中 的容器修改了现有一个已存在的文件，那该文件将会从只读层复制到读写层，而该文件的只读版本仍然存在，只是 被读写层中该文件的副本所隐藏而已，而此时关闭该容器，该容器所修改的文件的将会丢失且不能被其它容器共享、复用，因而需要一个存储卷。 如何实现容器内的路径与容器外的存储建立关联关系？ 实际应用场景： 1.通常在可写层上只保存临时数据，有效数据保存在和宿主机关联的目录下，这样就 剥离了程序和产生的数据间紧密的耦合关系，即程序在容器的名称空间上，数据在 宿主机或存储上，数据就独立于容器的生命周期之外 2.当容器down后，再启动一个新容器，指定数据路径为宿主机或存储上的路径，则 又恢复了数据，这就叫做Docker的存储卷 存储卷存在的问题： 存在的问题 •存储于联合文件系统中，不易于宿主机访问； •容器间数据共享不便 •删除容器其数据会丢失 解决方案：“卷(volume)” •“卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机 上的某目录“绑定(关联)” •Volume于容器初始化之时即会创建，由base image提供的卷中的数据会于此期间 完成复制 •Volume的初衷是独立于容器的生命周期实现数据持久化，因此删除容器之时既不会 删除卷，也不会对哪怕未被引用的卷做垃圾回收操作； 存储卷的type: 1. Bind mount volume 绑定挂载卷，永久生效 容器内目录和宿主机中的目录都是由用户自己指定的， 2. Docker-managed volume： 称为docker自己指定的卷 容器中的卷是用户自己指定的，而宿主机上的目录是由docker-daemon进程自行 决定与宿主机的哪个目录建立 关联关系的存储卷，只能用于临时挂载。 存储卷的相关命令: docker run -v 运行时，指定存储卷 --volumes-from list 复制其他容器的卷，达到共享卷的目的 --sorkdir string docker volume ls：列出当前已和宿主建立关联关系的存储卷 create： inspect name:查看一个卷的详细信息 prune rm: 因为docker container inspect c1看到的容器内的详细信息是JSON格式的 所以就可以通过过滤特殊字段显示查询的信息 docker container inspect CONTAINER_NAME -f {{.JSON_VALUE}} Docker-managed volume • ~]# docker run -it -name c1 –v /data busybox • ~]# docker inspect -f {{.Mounts}} c1 • 查看c1容器的卷、卷标识符及挂载的主机目录 和docker container inspect c1的过滤效果一样 Bind-mount Volume • ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name c1 busybox • ~]# docker inspect -f {{.Mounts}} c1 如图以过滤IP地址为例，其他信息类似 示例1.Docker-managed volume 临时创建挂载一个mydata卷 docker run --name c1 -it --rm -v /mydata busybox:latest 并通过docker container inspect c1 探测 mydata被docker指定与宿主机的哪个目录建立了关联关系 从上图看mydata是被docker-manager指定与该容器目录下的_data建立了关系注意：创建容器的时候加–rm选项时，停止容器后，宿主机上的卷也会被删除的不加–rm选项，停止容器，并rm容器，宿主机上的卷是不会被删除的缺点是对应的宿主机上的目录难查找 示例2.Bind mount volume 现在宿主机上创建卷的目录 mkdir /data/volume/c1 docker run --name c1 -it --rm -v /data/volumes/c1:/mydata busybox:latest 并通过docker container inspect c1 可以看出宿主机的/data/volumes/c1与容器内的/mydata是建立的bind类型的卷即使容器被删除，数据还在存在的而且如果/data/volume/c1是在NFS网络文件系统上的话，即使宿主机down了，数据也是无损的 示例3：多容器之间的数据共享 1.先创建容器c1 docker run --name c1 -it --rm -v /data/volumes/c1:/mydata busybox:latest 2.创建容器c2时，共享容器c1的卷 docker run --name c2 -it --rm --volumes-from c1 busybox:latest 此时c1和c2上看到的mydata卷看的数据都是一样的，达到共享卷的目的 示例4.用docker实现类似于k8s上的pod组件机制 要求： 1.c1上挂载多个NFS存储上的卷和bridge桥 2.c3和c4使用c1的网络名称空间和c1上的卷 实现： c1: docker run --name c1 -v /data/volumes/c1:/mydata -v /data/volume2:/mydata2 busybox:latest c3. docker run --name c3 -it --rm --network container:c1 --volumes-from c1 busybox:latest c4. docker run --name c4 -it --rm --network container:c1 --volumes-from c1 busybox:latest]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker仓库管理工具Harbor]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7Harbor%2F</url>
    <content type="text"><![CDATA[Docker仓库管理工具Harbor HARBORgithub上的harbor harbor官方功能介绍： 1.基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可 以对多个镜像仓库在同一命名空间（project）里有不同的权限。 2.镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡， 高可用，混合云和多云的场景。 3.图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库， 管理项目和命名空间. 4.Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。 5.AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。 6.审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。 依赖环境和使用介绍： 1.harbor是基于distribution二次开发的企业级私有仓库，云原生registry，多租户机制，允许用户创建自己的名称空间 2.因为harbor内置了mysql,nginx等服务才能构建一个harbor,所以依赖于docker-compose进行容器编排和依赖于至少docker-17.03.0版本 3.harbor为了安全，也需要以https运行，需要在harbor服务器提供证书，而且也需要为 其他客户端提供证书，为harbor验证使用，当然可以关闭https功能 4.因为需要实时下载镜像，提供了离线安装和在线安装，也可以安装到vSphere平台(OVA方式)虚拟设备。 离线版安装和配置：harbor离线安装包下载离线版安装部署文档 1.先安装docker-compose，docker-ce yum install docker-compose docker-ce -y 2.tar xf harbor-offline-installer-v1.4.0.tgz -C /usr/local/ 3.cd /usr/local/harbor并修改主配置文件harbor.cfg [root@mysql_2 harbor]# grep &quot;^[a-Z]&quot; harbor.cfg hostname = mysql_2 #设置主机名/IP ui_url_protocol = http #访问协议，支持http和https max_job_workers = 10 #最大进程连接数 #####设置使用https协议的证书和路径##### customize_crt = on #是否使用自定义证书 ssl_cert = /data/cert/server.crt ssl_cert_key = /data/cert/server.key secretkey_path = /data log_rotate_count = 50 #本地最多保存50次日志滚动 log_rotate_size = 200M #当日志达到200M时滚动一次 http_proxy = #是否使用代理 https_proxy = no_proxy = 127.0.0.1,localhost,core,registry ####设置用户上下载镜像时，是否启用发邮件功能######### email_identity = email_server = smtp.mydomain.com email_server_port = 25 email_username = sample_admin@mydomain.com email_password = abc email_from = admin &lt;sample_admin@mydomain.com&gt; email_ssl = false email_insecure = false ####使用互联网上的邮箱############## harbor_admin_password = Harbor12345 #harbor默认的管理员密码 auth_mode = db_auth #默认使用的数据库类型 db_host = mysql #设置连接mysql的端口和用户密码 db_password = root123 db_port = 3306 db_user = root #这里还支持 ldap 以及 本地文件存储方式。 #####修改数据库类型和用户和密码######### 4.运行install.sh 因为是离线安装包，会从tar文件中装入所需的镜像文件并启动，启动时会检查 docker-ce和docker-compose的版本开始加载镜像(mysql,redis,nginx等等) [root@mysql_2 harbor]# ./install.sh [Step 0]: checking installation environment ... Note: docker version: 18.09.0 Note: docker-compose version: 1.18.0 [Step 1]: loading Harbor images ... - 5.启用的容器可能会使用宿主机的名称空间 6.通过docker-compose管理harbor cd /usr/local/harbor/ docker-compose stop docker-compose start 登录web管理界面：http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码 7.创建用户和测试仓库： 创建lk用户，测试登录 创建test仓库用于测试上传镜像 直接创建test仓库即可 内网服务器登录harbor-登录报错–Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。如果配置文件中启用了https，而且也有证书等信息，就不会有这个报错 解决方法： 1.在所有的内网需要上传下载镜像的服务器上都创建daemon.json文件 vim /etc/docker/daemon.json { &quot;insecure-registries&quot;:[&quot;192.168.100.17&quot;] ###该选项表示从不安全的仓库下载或上传镜像 } 2.还要注意： 如果[&quot;192.168.100.17&quot;]中使用的主机名，那么需要在本地hosts文件或者局域网DNS 服务器上进行主机名解析 3.也可以修改vim /usr/lib/systemd/system/docker.service文件 vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd --insecure-registry 192.168.100.17 重启docker systemctl daemon-reload systemctl restart docker 4.docker login 192.168.100.17|主机名 #登录私有harbor仓库 docker logout 192.168.100.17|主机名 #退出私有harbor仓库 - 4.制作镜像并测试上传 制作镜像：docker tag httpd:v0.1 192.168.100.17/test/httpd:v1 将之前制作好的镜像改标签再上传上去 docker image build . -t 192.168.100.17/test/httpd:v2.0 也可以通过dockerfile重新制作一个再上传 上传到test仓库中: docker push 192.168.100.17/test/httpd:v1 - 5.测试拉取镜像 在页面上点击复按钮，在命令行中就可以拉取镜像了 - 如何修改配置：[root@linux-host1 harbor]# /usr/local/harbor [root@linux-host1 harbor]# docker-compose stop #先停止服务 [root@linux-host1 harbor]# vim harbor.cfg #编辑配置 [root@linux-host1 harbor]# docker-compose start #重新启动服务]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker网络]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[Docker Network KVM上虚拟桥接式网络类型： 隔离桥：只能与连接到同一个桥上的主机通信，IP地址还需要在同一网段 仅主机桥：可以和连接的桥地址进行通信 路由桥： 1.打开宿主机核心转发功能 2.虚拟机的网关都指向这个桥的地址 就可以与宿主机通信，不能与外网通信 NAT桥：在路由桥的基础上，在宿主机上做SNAT规则，即可访问外网地址 Docker提供的四种网络： 桥网络：bridge，默认就是docker0桥，docker0是SNAT桥 查看网络定义：docker network inspect bridge 大多数的容器还是使用bridge网络 而且这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器 共享桥： 每一个容器都是靠在内核级虚拟资源分配的独立的6种名称空间来支撑的 这6种名称空间是IPC,Net,Mount,UPS,PID,USER 虽然每个容器都有各自独立的名称空间，但是确可以共享，于是就有了这种方式 共享桥的原理： 共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈 而mount user PID还是隔离的，文件系统也是隔离的 这样做的效果就可以构建出一个模型 httpd---&gt;fpm127.0.0.1:9000---&gt;mysql127.0.0.1:3306 那么对于fpm和mysql来说只监听在本地端口上，保证了安全性 host宿主机网络： 既然多个容器可以使用同一个容器的网络名称空间，而且宿主机在内核中也有自己的 网络名称空间，那么容器也理所当然的可以使用宿主机的网络名称空间 容器使用宿主机的网络和DNAT方式有关系 作用：可以做日志收集主机，host一般在特殊环境下使用 none网络：封闭式网络 当容器不需要网络服务时，不创建网卡，只有本地lo网卡 除了bridge桥之外，其他三种网络都是docker所独有的 Docker网络的相关命令docker run 命令中涉及网络的相关命令 --network 启动容器时，指定使用的网络 [bridge|host|none|container:name] --hostname 启动容器时，指定容器的主机名 --add-host list 启动容器时，指定内部的hosts解析文件 如：docker run --add-host c1:192.168.10.1 busybox:latest cat /etc/hosts可以看到添加的解析 --dns 启动容器时，指定DNS地址 如：docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest cat /etc/resolve可以看到指定的DNS地址 --ip string 启动容器时，指定容器的iPv4地址 -p|--publish 因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则 docker network: ls：显示docker内部的全部网络 connect: 让容器连接到某个网络上 disconnect: 把容器从某个网络断开 create: 创建自定义网络，和KVM创建网络类似 inspect:查看某个网络是怎么定义的 prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令 rm: 删除docker内部的网络 Docker network的端口暴露docker run --network [bridge|host|none] -p|--publish 作为一个容器，是要提供web服务的，而docker默认的桥是bridge，而且是个SNAT桥 容器只能访问外网，而不能被外网所访问，那么就失去了web服务器对外提供服务的初衷 而docker提供了一个-p选项来自动生成DNAT规则，来避免每次都手写DNAT规则带来的麻烦 -p选项的用法和使用格式： •-p &lt;containerPort&gt; 将指定的容器端口映射至主机所有地址的一个动态端口 •-p &lt;hostPort&gt;:&lt;containerPort&gt; 将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt; •-p &lt;ip&gt;::&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口 •-p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; “动态端口”指随机端口，具体的映射结果可使用docker port命令查看 不过一般还是要使用第四种方式指定宿主机的端口 指定了映射的端口后，可以使用命令查看映射关系： docker container port [name] 示例： 1.docker run --name c1 -it --rm --network bridge -p 80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 0.0.0.0:32768 2.docker run --name c1 -it --rm --network bridge -p 80:80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 0.0.0.0:80 3.docker run --name c1 -it --rm --network bridge -p 192.168.34.103::80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 192.168.34.103:32768 4.docker run --name c1 -it --rm --network bridge -p 192.168.34.103:80:80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 192.168.34.103:80 Docker的自定义网络docker network create connect:相当于创建一对网卡，一半在桥上，一半在容器中 而且默认创建的网络都是SNAT桥 选项： -d|--driver string 创建时，要指定桥的类型 默认是bridge，当然还有 host macvlan null overlay四种类型 --gateway strings 默认是定义的子网的第一个IP地址 --subnet strings 子网地址 --ip-range strings 地址分配的IP地址范围 修改默认的bridge，docker0桥的子网 自定义docker0桥的网络属性信息：也就是镜像加速的文件 vim /etc/docker/daemon.json文件 { &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;] } 核心选项为bip，即bridge 桥接口的IP地址 ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。 示例： 1.创建一个mybr2的网络，并指定子网地址 docker network create --subnet 10.0.0.0/8 mybr2 2.创建容器c1指定加入到mybr2网络中 docker run --name c1 -it --rm --network mybr2 busybox:latest 3.给容器c1再加入一个bridge网络中 docker network connect bridge c1 此时c1就有了两个网络地址 4.删除容器c1的网卡 docker network disconnect mybr2 c1 Docker指定容器启动的网路类型1.启动为none类型的网络 docker run --name c1 -it --rm --network none busybox:latest 2.启动为bridge类型的网络:docker默认的网络模型 docker run --name c2 -it --rm --network bridge busybox:latest 3.启动为joined类型的网络 启动的c3共享的是c2的Net,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的 因为共享桥只是共享了Net网络，UTS主机名，IPC，此时IP地址和hostname都是一样，就可以通过127.0.0.1进行通信了而mount(文件系统)，user,PID还是隔离的，所以在1上创建一个文件，2上是看不到的这就是共享桥的工作机制 4.启动为host宿主机类型的网络 docker run --name c4 -it --rm --network host busybox:latest 可以看出hostname,Net都是和宿主机是一样的 此时在容器内部启动httpd服务，其他主机是可以通过宿主机提供服务的]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile]]></title>
    <url>%2F2018%2F10%2F18%2FDockerfile%2F</url>
    <content type="text"><![CDATA[DockerFile：构建镜像 前面说过： 1.镜像是分层的，当基于这个镜像创建一个容器时，docker是通过联合挂载机制把镜像层 进行叠加作为容器的只读层，而后又在这个镜像栈上构建了一个可写层作为这个容器的工 作目录. 2.所有的底层数据在第一次发生修改操作时，是通过CoW写时复制机制，把数据复制到读 写层进行修改并保存在读写层，覆盖底层的原始文件；写入新数据时，则直接保存在读写 层，而在读写层看到的数据就是全部的镜像层数据(镜像栈) 3.而Graph Driver则又在构建在本地文件系统之上的二级文件系统(aufs,overlay2) 4.基于Graph Driver这种特有的图形驱动程序，就可以把分成构建的镜像堆积在存储 空间当中，紧邻的镜像是有依赖关系的 5.docker commit可以把当前的读写层及其底层依赖的镜像关系打包成一个镜像层存储 在Graph Driver当中，并且指向底层依赖的镜像层，形成一个新的镜像层，如果基于 同一个镜像commit多个可写层，这些新的镜像层都是指向之前的底层镜像的，这也是 docker镜像不是很大的原因。 6.所以在制作镜像时，完全不必基于某个基础镜像显示启动一个新容器，然后在上面创建 修改可写层并打包成镜像；commit只是一种方式，也可以使用dokcerfile 7.如果再本地将软件源码编译/二进制编译到容器也是可以的 dockerfile基本要求1.dockerfile的工作逻辑： 制作镜像无非就是基于某个基础镜像创建一个可写层修改后再commit成一层新的镜像 这个过程可以由docker自身完成，只需要在dockerfile配置文件中写清楚，基于哪个基础镜像， 按需修改(通过各种指令生成)，而docker build可以读取dockerfile文件，隐 式的执行这些指令集生成一个新的镜像层保存在Graph Driver中 2.工作目录 构建docker镜像时，必须有一个工作目录docker,这个目录下只存在dockerfile和在 dockerfile中定义要复制的文件，是起始目录 3.dockerfile format：语法 dockerfile就是一个纯文本文件; 注释行 dockerfile instruction args:指令要纯大写 第一条指令必须是FROM：基础镜像名称 docker build是按顺序读取执行dockerfile中的指令集的 4.dockerfile中的每一条指令都会生成一个新的镜像层 如果指令比较多，生成的镜像层就比较多，就会造成第一次的CoW从底层读取数据时很慢 但是镜像层比较多又容易被分享和易控，较少又会比较繁琐 所以一般是把做同一个件事的多个操作通过\换行符，用一条指令完成(见下文) 5.镜像内唯一要运行的程序一定必须要运行在前台 dockerfile中的环境变量1.docker为了满足同一镜像在不同环境下的使用场景引入了环境变量的方式 某个容器基于镜像启动时，通过传递环境变量参数，来生成容器内的不同的配置文件 docker container run --name CONTAINER_NAME -e VAR -it IMAGE_NAME COMMAND 这样一来，就可以用基于同一基础镜像，传递不同的环境变量作为参数值，创建适应 于不同环境的容器 2.entrypoint.sh脚本 但是传统的代码不支持传环境变量作为参数，而在docker中又需要传参，这时就有了衔接 层也就是shell脚本，这个脚本作为容器第一个要运行的程序然后运行完退出，再退出去 之前读取用户传的环境变量，将环境变量的值写到程序的配置文件中； 而且很多镜像通过docker image inspect mysql:8.0 |grep entrypoint过滤是可以 看到有这个脚本的 3.环境变量的两类用法： a.在构建dockerfile中使用 b.以dockerfile构建的镜像为基础镜像，启动容器时使用 而dockerfile中的指令的生命周期是有两个阶段的 build：基于基础镜像构建镜像的阶段 run: 启动容器的阶段 dockerfile中的一些指令或者环境变量在不同阶段使用发挥的价值是不一样的 4.环境变量的设定和引用 设置：ENV statement 两种引用方式： 1.${variable:-word} 如果变量variable为空或不存在时，就使用word值 如果设置了variable，就使用该变量值 2.${variable:+word} 如果变量有值，就使用word值，如有没值就是空值 .dockerignore file1.dockerignore是工作目录中专门记录需要忽略的文件列表 2.而且docker build会自动忽略.dockerignore自身和记录在其中的所有文件 Dockerfile基本语法FROM： FROM必须是文件的第一指令 FROM &lt;repository&gt;[:&lt;tag&gt; 镜像的标签 或者&lt;resository&gt;@&lt;digest&gt; 镜像的ID号校验码 推荐使用digest因为校验码是安全的，而且最好不要使用lasted LABLE: authtor&apos;s infomation;提供该镜像的标签信息 语法： maintainer &quot;liu &lt;liu@163.com&gt;&quot; COPY: 从宿主机复制文件至创建的新镜像 COPY &lt;src&gt;... &lt;dest&gt; COPY [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;] &lt;src&gt;：要复制的源文件或目录，支持使用通配符 &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则，COPY指定则以WORKDIR为其起始路径； 注意：在路径中有空白字符时，通常使用第二种格式 注意： 1. src：必须为build上下文中的路径，可使用相对路径 2.如果src是目录，其内部的文件或子目录会自动被递归复制，但src自身不会被复制 等于cp -r /src/* /dest/ 3. src有多个，或者src使用通配符，则dest必须是一个目录，且必须以/结尾 4. 如果dest事先不存在，它将会被自动创建 ADD: 类似于COPY，但是额外支持tar文件和URL路径 ADD &lt;src&gt;... &lt;dest&gt; ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;] 1. 如src为URL时且dest不以/结尾，ADD会自动将指定的文件下载并创建为dest， 如dest以/结尾，则会下载指定的文件并保存为dest/FILENAME 即一个是下载并改名，一个是下载到这个文件目录下 2. 如src是一个本地的tar文件，则会被自动展开为一个目录，但通过URL获取到的文件 则不会自动展开，即在本地的就展开，互联网的就不展开 3. 如src有多个，或使用通配符，则dest必须是目录且以/结尾，如dest不以/结尾， 则被视为一个普通文件，src的内容将被直接追加写入到dest文件中 WORKDIR： 1.用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录 2.WORKDIR指令可出现多次，表示下个指令可以以此目录为父目录，路径可以表示为相对 路径，也可以写成绝对路径 3.WORKDIR的有效范围当前workdir向下，下一个workdir之前的范围 4.另外，WORKDIR也可调用由ENV定义的环境变量的值，如果下次修改环境变量的值，响应生成信息的镜像层 5.而且如果设定了WORKDIR，容器启动时，默认就进入到workdir路径了 VOLUME： 用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷 注意： 1.在dockerfile中定义的卷，启动容器时，是被docker管理的卷与宿主机的某个 路径建立关联关系 2.如果需要定义的卷与宿主机特定的目录建立关联关系，还需要在run container时 指定-v选项 3.如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此 前的所有文件复制到新挂载的卷中 EXPOSE:都是动态端口暴露 用于为容器打开指定要监听的端口以实现与外部通信 EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议 注意： 1.即使在dockerfile中定义了暴露的端口，启动为容器时，端口也不会暴露的 因为是有安全风险的； 但可以用run container时加 -P选项强行暴露端口，但这是个动态端口暴露 用起来极其鸡肋！ ENV： build阶段使用的： 用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令 如ENV、ADD、COPY等）所调用，调用格式为$variable_name或${variable_name} 两种语法： 1.ENV &lt;key&gt; &lt;value&gt; &lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只 能设置一个变量； 2.ENV &lt;key&gt;=&lt;value&gt; ... 可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果 &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另外，反斜线也可用于续行； 定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能 缺点：如果想修改ENV定义的值，只能修改dockerfile中的值，比价麻烦，此时 就可以使用ARG来代替ENV ARG： arg是在build阶段进行传值，替换dockerfile中的值 ARG &lt;name&gt; [=&lt;default&gt;] 可以设置默认值 当build创建镜像时没有传值，则使用在dockerfile中设置的默认值 既可以弥补ENV的缺点也可以和RUN，CMD的ENV传环境变量区别开 如：在build时更改home的值 docker image build --build-arg home=&quot;/webdata/&quot; /data/dockerfile/ -t myimg:v0.4 RUN,CMD,ENTRYPOINT的区别 区别： RUN： 用于指定docker build过程中运行的程序，可以是任何命令 (这就意味着RUN的命令必须是使用的基础镜像支持的命令) 1.是指在docker build过程中通过运行RUN定义的shell命令，以达到在镜像中安装软件等操作 2.RUN可以设定多次，而且每一个都会在build的时执行 语法： RUN &lt;command&gt; 通常运行的是一个shell命令，且以&quot;/bin/sh -c&quot;运行，且/bin/sh是PID为1的进程，command是作为shell的子进程存在 RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] 此种格式指定的命令不会以&quot;/bin/sh -c&quot;，因此无法支持shell的诸多特性，如要依赖于shell特性，可替换成如下格式： RUN [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;] CMD： 1.当把镜像运行容器时，需要指定默认运行的程序，这在dockerfile中需要用CMD命令来 指定，ENTRYPOINT也可以 2.默认运行的程序必须运行在前台 3.由于CMD设定的是容器启动默认运行的程序，所以必须只有一个，如果有多个， 则最后一个CMD生效 语法： CMD &lt;command&gt; 或 CMD [“&lt;executable&gt;”, “&lt;param1&gt;”, “&lt;param2&gt;”] 或 CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;] 前两种语法格式的意义同RUN 第三种则用于为ENTRYPOINT指令提供默认参数 systemctl start httpd启动是运行在systemd的前台上，所以启动就会退出 ENTRYPOINT： 1.CMD和ENTRYPOINT都表示镜像启动为容器时，容器默认运行的程序，而且CMD和ENTRYPOINT有多个，也都是最后一个生效 2.如果CMD和ENTRYPOINT同时存在，CMD和ENTRYPONIT需要组合起来，则CMD指定的内容 都作为ENTRYPOINT所指定内容的参数 语法： ENTRYPOINT &lt;command&gt;或者 ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到 ENTRYPOINT命令最后做为其参数使用 Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效 示例： docker run –name c1 -P -d myimg:v0.1 以后台运行容器]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[Docker Images 1.docker image是docker贡献给容器极具创造性的使用方式！2.分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！3.容器编排技术：—Docker通过镜像机制极富创造性的解决了应用程序打包的根本性难题，它推动了容器技术的快速普及和生产落地—容器本身仅提供托管运行应用的底层逻辑，而容器编排(Orchestration)才是真正产生价值的位置所在； -docker-image和读写机制 1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器 a.docker镜像就像KVM镜像一样，包含了启动容器/虚拟机所依赖的所有文件，文件系统 包括程序文件，库文件，配置文件,数据目录等等 b.dokcer采用分层构建机制，最底层为bootfs，其上是rootfs bootfs：在创建的容器中是看不到的，只是用于系统引导的文件系统，包括 bootloader和kernel，因为在创建启动容器时，其实是用到内核的， 只不过只是启动引导容器启动的，当容器启动完成后会被卸载以节约内存资源; 而且把对应的对容器的管理委托给宿主机的内核，所以容器镜像的内核只 是启动时有用，而且看不到，所以bootfs叫引导文件系统 rootfs:位于bootfs之上，表现为docker容器的根文件系统; 1.在传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只 读&quot;模式，完整性自检完成后将其重新挂载为读写模式；也就是fstab 的最后两项，只有通过自检次序时，才会把根文件系统重新以&quot;读写&quot;方式挂载. 2.但是在docker中，rootfs由内核挂载为&quot;只读&quot;模式，就算容器启动完成 ，rootfs也不会以读写方式重新挂载！也就是说docker容器的用户空 间和根文件系统一直都是只读的！ 3.docker是通过&quot;联合挂载&quot;技术额外挂载一个“可写”层；docker image layer 2.Docker Images Layer 如上图 a.完整的docker镜像包括bootfs,rootfs b.而rootfs又包括Base Image+自定义的镜像层+可写层writable 除了writable是可写层，其他都是只读层 c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加 一个可写层，这个可写层writable是属于容器的 d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的 容器的读写原理：如上图示： 1.对于docker来说有一个专门存放镜像的路径叫Graph Driver，而这个文件系统必须是特殊 格式的(aufs或者overlay2),在linux系统内默认是/var/lib/docker/image/overlay2； overlay2目录就是构建在宿主机(xfs或ext4)的/var/lib/docker/image/目录的二级文件系统 2.前面说镜像数据文件都放在bootfs和rootfs上的，可写层writbale是创建时创建的 那么在可写层上是如何看到底层的数据目录？又是怎么把数据增删改到容器内的？ 默认xfs和ext4是不支持COW机制的 如何看到镜像目录的？ a.在创建容器时，是把镜像内的多层镜像通过联合挂载方式作为可写层的底层，也就是这个容器内部的可访问文件系统接 口 b.所谓联合挂载，是通过把镜像内的多层一层一层叠加上去的，而这个叠加方式的原理是： 第一层上有数据时，而第二层没相同数据，在第二层是可以看到第一层数据的;如果第二层有第一层相同数据， 则会覆盖第一层上的相同数据，在第二层上看到的是第一层和第二层总的文件，以此类推，在可写层上就可以看到 镜像内的数据目录了， 如何修改和写文件？ a.对于修改文件，因为文件是放在只读层的，只能是通过COW写时复制机制，先把文件从只读层复制到可写层上再进行修改 然后保存在可写层,当然是首次修改，第二次再修改因为在可写层有文件了，在可写层修改即可，而只读层的该文件 版本仍然存在，只不过是被读写层中该文件的副本所隐藏了. b.对于写文件，新创建的文件是保存在可写层的，所以最终用户看到的是只读层和可写层的全 部数据文件，这就是镜像的工作逻辑 通过上面的分析可以得出： 1.这就是为什么基于同一镜像创建的两个容器，用户在不同的容器上看到的相同的数据都是只读层的，不同的数据是可写 层上各自独有的，因为可写层是独占的，只读层是共享的 2.这就是为什么镜像背后必须要求特殊文件系统的原因：因为ext4和xfs默认是不支持联合挂载和写时复制机制的 3.因为可写层是可以自定义修改的，把可写层保存为镜像，然后再和原始镜像进行叠加成一个自定义的镜像， 就可以作为基础镜像使用了，不过一般不这么做，而是通过dockerfile自定义镜像 docker imge相关命令docker image 相关命令 docker imges:镜像的管理命令 ls： 查看本地所有的镜像列表 build: import: inspect: 查看下载/创建的镜像详细信息 可以查看下载的某个镜像的具体信息 如：CMD:镜像启动默认运行的命令 Volume: network: 下文中构建docker file时这些都可以自定义 load: prune: pull：从远程仓库拉取镜像到本地 push: 把本地镜像推到远程的Registry rm: docker image rm = docker rmi 删除镜像 tag: 给镜像打标签 save: 2.将当前容器可写层保存为镜像并上传docker hub上 docker container commit [options] container [repository:[tag]] 选项： -a:指定作者 -c:镜像内部默认运行的命名 -p|--pause:因为制作镜像时，容器还在运行，可能制作出的镜像和当前容器不 一致，可以在制作时，暂停容器，保持数据一致 比如： 1.在docker hub上注册用户，并创建镜像仓库 创建的仓库：myimg 2.把centos1容器做成镜像仓库下的myimg：v0.1版本 docker container commit -p -a &quot;liu &lt;liu@163.com&gt;&quot; -c &quot;CMD [&apos;/bin/httpd -f&apos;]&quot; centos1 liukkui/myimg:v0.1 然后新容器就可以基于这个镜像启动了 3.上传docker hub docker login 登录到docker hub 输入账号密码，正常登录后 4.push镜像 docker image push liukkui/myimg:v0.1 正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables之FORWARD和NAT]]></title>
    <url>%2F2018%2F10%2F10%2Fiptables%E4%B9%8BFORWARD%E5%92%8CNAT%2F</url>
    <content type="text"><![CDATA[iptables/netfilter网络防火墙： 在FORWARD链上定义规则，注意以下几个问题： (1) 请求-响应均经由FORWARD链，要注意规则的方向性； (2) 如果可以启用conntrack机制，建议将双方向的状态为ESTABLISHED的报文直接放行； 网络防火墙原理及示例本地通信：两个主机在没有网关或者路由下进行通信，所有的本地通信是通过MAC地址进行通信的 name–&gt;IP–&gt;MAC地址基于广播机制 如果有交换机，交换机会查找MAC地址表(是通过源地址学习得到的), 将数据报文直接发送到连接到交换机的目标主机上网络通信：其实就是多个本地通信实现的，由多个路由器进行中继转发最后到达目标主机的 而把linux服务器扮演成路由器的角色，则这台linux服务器充当是网关，就需要打开核心转发功能 FORWARD链右边是生产环境左边是研发测试环境： 隧道VPN 实验模拟： sysctl -w net.ipv4.ip_forward=1 A: route add -net 192.168.10.10/24 gw 192.168.34.103 B: route add -net 192.168.34.0/24 gw 192.168.10.10 情景一：客户端确定服务端不确定；源地址确定，目标地址不确定 情景二：服务端确定，客户端不确定；源地址不确定，目标地址确定 对于情景一的情况： 客户端确定,服务端不确定；即源地址确定，目标地址不确定示例1: 1.先在FORWARD链上默认为拒绝 如控制客户端只能访问httpd和ping操作，就可以在FORWARD链上添加如下规则 tcp:80端口限制: iptables -A FORWARD 1 -s 192.168.34.0/24 -p tcp –dport 80 -j ACCEPT iptables -I FORWARD 2 -d 192.168.34.0/24 -p tcp –sport 80 -j ACCEPT icmp的ping限制： iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -j ACCEPT iptables -I FORWARD 4 -d 192.168.34.0/24 -p icmp –icmp-type 0 -j ACCEPT 默认拒绝策略： iptables -I FORWARD 5 -j REJECT 2.因为之前介绍过state的状态追踪功能： 就可以简化成这样的规则： iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT iptables -A FORWARD 2 -s 192.168.34.0/24 -p tcp –dport 80 -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -j ACCEPT iptables -I FORWARD 4 -j REJECT 3.情景一因为都是内网的服务器，是不能接收外网的请求的 所以对于ping和tcp只允许从内网出去的，外网是不能进来的，规则如下 iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp –dport 80 -m state –state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp –icmp-type 8 -m state –state NEW -j ACCEPT iptables -I FORWARD 4 -j REJECT 示例2：控制访问ping,httpd：80,vsftp：21,dns：53 规则如下： iptables -I FORWARD 1 -m state –state ESTABLISHED -j ACCEPT iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp -m multiport –dport 80,21,53 -m state –state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p udp –dport 53 -m state –state NEW -j ACCEPT iptables -I FORWARD 4 -s 192.168.34.0/24 -p icmp –icmp-type 8 -m state –state NEW -j ACCEPT iptables -I FORWARD 5 -s 192.168.34.0/24 -p tcp -m state –state RELATED -j ACCEPT iptables -I FORWARD 6 -j REJECT在这里需要指定-s 源，不然外网向内网主动发送报文请求也是可以到达内网的！ 结论： 1.所以说有时服务器ping不通不代表服务不能访问，而且通过内网ping外网时，在外网服务器 进行抓包时，可以看出源地址是内网IP,非网关IP，目标地址是外网IP地址[root@centos7 data]# tcpdump -i ens33 -nn icmptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytes21:10:24.541810 IP 192.168.34.107 &gt; 192.168.10.10: ICMP echo request, id 1764, seq 3, length 6421:10:24.541877 IP 192.168.10.10 &gt; 192.168.34.107: ICMP echo reply, id 1764, seq 3, length 64 2.用linux防火墙做网关网络防火墙，有一个问题，内网的机器是保护了，但是这台linux服务 是没有防护的，所以还需要在这台网络防火墙上在INPUT和OUTPUT链上加上规则，来防护 这台linux网关网络防火墙！所以当用一台linux服务器做网络防火墙时，INPUT,OUTPUT FORWARD链是都需要设置规则的！ 对于情景二的情况：右边的图则控制：源地址不确定，目标地址确定示例3：控制允许互联网的主机访问ping,httpd：80,vsftp：21,dns：53 所以规则应该如下： iptables -I FORWARD 1 -p tcp -m state –state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -d 192.168.10.0/24 -p tcp -m multiport –dports 80,53,21 -m state –state NEW -j ACCEPT iptables -I FORWARD 3 -d 192.168.10.0/24 -p udp –dport 53 -j ACCEPT iptables -I FORWARD 4 -d 192.168.10.0/24 -p icmp –icmp-type 8 -m state –state ESTABLISHED -j ACCEPT iptables -I FORWARD 5 -d 192.168.10.0/24 -m state –state RELATED -j ACCEPT iptables -I 6 FORWARD -j REJECT NAT： 当然NAT规则还是建立在FORWARD的基础上做地址转换，不能转发做NAT也没意义，所以放行和控制限制还是需要在FORWARD链上去做的 NAT: network address translation，地址转换 NAT技术的产生核心原因：隐藏本不需要公开的主机 1.请求报文的源地址地址转换是人为在NAT上加规则实现的 2.响应报文中的目标地址转换，是基于连接追踪功能实现的，不需要人为干预 比如内网的机器要访问互联网，就必然留下IP地址或者端口信息，则有些攻击木马通过真正的 地址来扫描这些内网机器，如果有漏洞，则可能就会被攻击，所以NAT的技术的出现，就 会隐藏我们内网机器访问互联网时的真正IP地址和端口。 实现隐藏的原理： 1.将数据报文中的源地址IP，修改为具有很强防护能力的IP地址，比如网关等,这样的话，互联网上的主机看到的源地址就会是网关的地址，即使被攻击也是攻击网关，而网关一般是具有很高的防护能力的，所以就达到了隐藏源地址的目的. 2.一般来说请求报文经过防火墙时，会拆掉以太网帧首部，看到目标地址不是自己时，会转发出去，但是对于NAT的情况，防火墙会修改数据报文的IP首部的源地址或者目标地址，然后重新封装数据报文，再到达目标主机，这样就会达到保护源主机和目标主机被攻击的风险，在这个过程中，请求报文由手动修改的，响应报文是由NAT连接追踪功能实现的。 NAT的方式：SNAT,DNAT,FullNAT,PortNAT NAT规则可加的链： 支持PREROUTING INPUT OUTPUT POSTROUTING,但是一般只在PREROUTING和 POSTROUTING上做NAT规则，INPUT和OUTPUT只有在特殊情况下才做NAT。 那么在netfilter上是如何实现的？ SNAT的实现 数据报文经过防火墙时，如上图示，只有当数据报文进入防火墙时，才知道目标地址不是 自己，还是需要转发，所以不适合在PREROUTING链上做地址转发，如果目标地址不是当前 主机，就要经由FORWARD链进行转发，而FORWARD链本身确不支持地址转换功能，所以只 有在离开本机再一次进行路由选择，路由完之后才扔给网卡发送队列中，所以只能在POSTROUTING链上加地址转换规则 DNAT的实现 SNAT：POSTROUTING源地址转换 原理： 请求报文发生了源地址修改：人为介入修改 响应报文经过防火墙的NAT规则时，同连接追踪机制自动修改目标地址 所以源地址转换适合隐藏服务端 作用： 1.隐藏内网主机的IP地址，防止被攻击 2.SNAT可以解决IPV4端口不够用的问题： IPV4的地址短缺的问题使得SNAT技术更加流行，因为私网地址使用一个公网地址， 所以通过SNAT地址转换，报文通过公网IP出去的时候，都会把源地址(私网地址)转 换成公网地址，才能与公网通信，响应报文回来的时候是发给公网IP的，则通过连接 追踪功能返回给原来的私网地址。 SNAT实验： 192.168.34.0/24网段SNAT到192.168.10.11上，且只限制80和ping操作能进行 规则如下： NAT的POSTROUTING链规则： iptables -t nat -I POSTROUTING 1 -s 192.168.34.0/24 ! -d 192.168.34.0/24 -j SNAT --to-source 192.168.10.11 注意：这里的source是一个固定的地址，如果这个地址是变动的呢？ 那么可能下次这条规则就不生效了！--&gt; 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 如上图：通过在192.168.10.10上抓icmp包和http日志也可以看出，确实是做了SNAT地址转换的 [root@node7-3 data]#tcpdump -i ens33 -nn icmp 14:56:14.315375 IP 192.168.10.11 &gt; 192.168.10.10: ICMP echo request, id 1373, seq 1, length 64 14:56:14.315473 IP 192.168.10.10 &gt; 192.168.10.11: ICMP echo reply, id 1373, seq 1, length 64 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.10.11 - - [29/Dec/2018:15:20:45 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; DNAT：PREROUTING和OUTPUT目标地址转换 原理: 请求报文的目标地址需要修改成真正的IP地址 响应报文经过防火墙的NAT规则，通过连接追踪机制，自动修改目标地址 作用： 1.隐藏提供服务的服务器的真实IP地址，防止被服务被劫持，如DNS劫持，http服务等 2.DNAT也通过PortNAT方式可以解决IPV4地址不够用的问题 DNAT实验： 访问192.168.10.10的http服务时，只需要访问防火墙NAT服务器的地址即可 即把192.168.10.10DNAT到192.168.34.103上，这里只做简单的DNAT不做portnat 规则如下： NAT的POSTROUTING链规则： ptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 验证：在192.168.34.107上获取192.168.10.10的页面信息：curl 192.168.10.10 因为DNAT是隐藏192.168.10.10的真实地址的，在互联网上只会暴露防火墙的192.168.34.103地址是提供http服务的，真正的地址得以保护，所以这里curl 192.168.34.103即可 [root@node7-2 data]#curl 192.168.34.103 haha 192.168.10.10 而在192.168.10.10查看http日志 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.34.107 - - [29/Dec/2018:17:24:20 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 192.168.34.107 - - [29/Dec/2018:17:26:42 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 从实验也可以看出DNAT的规则生效了，达到了隐藏真正提供服务的192.168.10.10地址 从而保证了服务器被攻击的风险 PortNAT:端口映射端口映射在docker容器中的实现方式更加方便，直接加-p选项即可,而且源端口和目标端口可以指定 进程与进程的通信，实际上就是端口号之间的通信 1.对于SNAT来说，因为访问是互联网的随机端口，所以都转换即可 2.而对于DNAT的情况来说： a.很多情况下，并不是说只要访问防火墙F的地址，都通过DNAT转换成主机A的IPA， 而是当访问主机A的某个服务特定端口时，才进行地址转换 b.而访问F的端口和要转换的IPA的端口不一定需要一样 即IPF：port1--&gt;IPA:port2，port1和port2可以不一样 3.DNAT也可以解决IPV4地址不够用的情况：如下图 那么就可以说地址转换可以发生在网络层，而且借助端口映射也可以发生在传输层首部(端口) DNAT端口映射实验：如上图 访问192.168.10.10：8080的http服务时，只需要访问防火墙NAT服务器的地址即可 即把192.168.10.10:8080DNAT到192.168.34.103:80上,在上面的DAT基础上做修改即可 规则如下： NAT的POSTROUTING链规则： ptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10:8080 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 验证：curl 192.168.34.103:80查看是否能获取到192.168.10.10：8080的页面 [root@node7-2 data]#curl 192.168.34.103 haha 192.168.10.10 [root@node7-2 data]#curl 192.168.10.10:8080 haha 192.168.10.10 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.34.107 - - [29/Dec/2018:17:27:01 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 从实验也可以看出DNAT的端口映射规则生效了，映射的端口不一样也可以访问到页面 1.这里只模拟同一台服务器上的一个服务的DNAT端口映射情景 2.对于同一台服务上的多个服务DNAT端口映射也是同样道理，加上对应的PORTNAT规则即可 3.对于多台服务器上的多个服务DNAT端口映射同样是这样的，只需要在NAT服务器上添加多个地址，然后将对应地址进行多台服务器的服务映射即可 FullNAT：源地址和目标地址都修改既是网关又是NAT fullnat能实现网关和主机不在同一个网段 FullNAT的存在是为了弥补SNAT和DNAT模式下，主机和NAT服务器必须在同一个网段的缺点 SNAT和DNAT都受限于NAT服务器和客户端都在一个网段 1.在SNAT中，主机的网关都是需要指向NAT服务器的，不然如果在主机和防火墙之间存在路由器的话，那么出去的请求报文就不一定经由NAT服务器了，也就达不到地址转换的目的 2.在DNAT中，如果提供服务器的主机和防火墙NAT服务器之间有路由器，那么响应的报文 也不一定经由NAT服务器，也达不到转换目标地址的目的。 3.所以FullNAT的存在就弥补了SNAT和DNAT的缺点 FullNAT的地址转换原理： 如下图示 FullNAT实验： FullNAT的实验原理和SNAT,DNAT,PORTNAT实验方式一样，这里就不做演示了 MASQUERADE只能作用在POSTROUTING链上，对SNAT的缺点弥补 外网地址是动态的就用MASQUERADE,如果是静态的就用SNAT； 因为MASQUERADE会消耗更多的系统资源，能用SNAT就用SNAT，特殊场景才使用MASQUERADE]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables]]></title>
    <url>%2F2018%2F10%2F06%2Fiptables%2F</url>
    <content type="text"><![CDATA[iptables的处理逻辑和命令 对于防火墙而言，原理和设置规则尤其重要，了解原理意味着清楚防火墙是如何在数据报文的必经之路上进行规则限制即iptables的处理逻辑； 规则意味着iptables是如何通过命令和各种选项进行规则编写的 对于防火墙而言，原理和设置规则尤其重要，原理意味着怎么对数据报文的走向进行规则限制，规则 Linux防火墙防火墙的概念iptables的基本认识iptables的组成:iptables的处理逻辑iptables的基本语法iptables之forward的概念iptables之地址转换法则SNAT源地址转换的具体实现DNAT目标地址转换的具体实现 不理解的地方：5个表的优先级和规则的优先级什么是显示扩展和隐式扩展 iptables的处理逻辑和命令 对于防火墙而言，原理和设置规则尤其重要，了解原理意味着清楚防火墙是如何在数据报文的必经之路上进行规则限制即iptables的处理逻辑； 规则意味着iptables是如何通过命令和各种选项进行规则编写的 安全技术：防火墙： 防范非授权网络访问；隔离功能，工作在网络或主机边缘，对进出网络或主机的数据包基 于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一组功能的组件， 基本上的实现都是默认情况下关闭所有的通过型访问，只开放允许访问的策略 入侵检测机制和管理系统： 当病毒或者网络攻击绕过防火墙进入系统后的入侵检测机制，告知管理员采取手段提供有针对性的指导措施和安全决策依据。 杀毒软件：病毒入侵后的防御软件 入侵防御系统： 入侵检测系统检测到网络攻击或者病毒时，通过入侵防御系统进行准确的分析判断， 在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般采用在线部署方式 防火墙作用：作用： 数据报文发到服务器的以太网卡的二种访问行为 1.linux中，数据报文从服务器的以太网卡经过内核空间走一遭，不与用户空间交互，再从网卡出去，穿墙而过 2.或者数据报文达到网卡，到达内核空间，进而与本地用户空间的进程进行通讯，大多数网络通讯发生的目标所在，如httpd的访问，vsftp通讯，ssh通讯 究竟数据报文会以哪种方式怎么选择，会根据主机内部的路由表来选择，内核从网卡拿到请求报文，对linux而言tcp/ip协议栈是在内核中 意味着报文的处理是在内核中处理的，也就是说防火墙必须工作在内核中，防火墙必须在内核中完成tcp/ip报文所流进的位置，用规则取检查，才能真正工作起来； 根据内核的网络协议栈处理逻辑，会先拆除IP层的封装，获取到目标IP，如果是则拆除ip地址的首部封装，获取传输层封装(传输层的tcp的源端口，目标端口，几个标记位等信息；) 这里所说端口是指进程地址，防火墙通常是在这个地方做限制的，只有通过防火墙设置的规则，才能进而与用户空间的应用程序进行数据报文的传输. 这里就要说到网络间的主机通信过程了：如：主机A–&gt;R1路由—&gt;R2路由—&gt;R3路由–&gt;主机B的过程：怎么知道报文是从哪到哪的？在整个网络中，主机A发往主机B的数据报文是一般是经过很多路由转发才到达主机B的而主机A上只会标记出报文的源IP:sipA，目标IP：dipB因为要经过很多路由，所以主机A到达下一个路由设备的时候会在报文的最外层加一层以太网帧首部标记出源MAC(主机A)和目标MAC(R1路由Mac)，将数据报文送到R1，R1会拆除外层的以太网帧头部信息，R1看到目标IP不是自己，则会选择将数据报文继续转发R2，此时数据报文则又被封装源MAC(R1的MAC)和目标MAC(R2的MAC),到达R2，R2则继续拆封以太网帧头部，发现目标IP不是自己，则继续封装以太网帧首部转发出去，最终到达主机B，主机B拆封以太网帧首部，看到目标IP是自己，则继续拆分传输层TCP首部，应用层等进行数据的交换这就是为什么数据报文会从主机A成功发送到主机B上去，在数据报文传输的过程中，IP首部的信息不会变，而MAC层首部会连续换很多次！ 真正通信的不是主机而是主机内的进程，数据报文中还会标识出是从主机A的哪个地址，发往主机B的哪个地址，这里的地址就是端口，而端口(2^16-1=65535,0是)则是动态分配的，当原主机上的端口在进行通信的时候，会临时向内核申请端口：叫端口注册，这个端口叫源端口，而目标端口则是如httpd80;ssh22端口，这些服务的端口是固定的，必须有一端的端口是固定的，否则无法进行通讯，当主机B真正收到数据报文时，拆分IP首部后，则会看到传输层信息，看到端口信息，主机B根据那个服务在内核注册的端口信息，将数据报文交给注册端口的这个服务，即交给用户空间的这个服务对应的进程，比如http继续看到httpd的首部，这个过程是在不是在内核空间处理的，而是在用户空间的进程上处理的 所以这里就会发现在linux内，tcp的五层模型的前四层物理层 数据链路层 网络层 传输层这些都是内核空间处理的，叫传输子网，因为都是在内核中完成的，使用的都是是公共资源模块，为了避免程序员造轮子，把公共资源模块做成了库*.so文件只有应用层是在用户空间处理的，由客户端的浏览器等封装的，叫资源子网的组成部分 而数据报文达到内核中拆分IP头信息后看到目标IP不是自己，因为主机一般不会作为路由器来使用的，所以数据报文则会被丢弃，但是主机都有核心转发功能，如果核心转发功能是开启的forward,则会查本机的路由表，将数据报文转发能到达目标主机的下一个设备，则数据报文在本机的内核中绕一圈被转发出去 主机防火墙和网络防火墙所以防火墙的防火功能则是数据报文的必经之路上放上所谓的墙，其实就是iptables很多规则，只有墙上事先设置的白名单规则，数据报文才允许经过，其他的报文则都被丢弃。 前面说的是单台主机上的防火墙：主机防火墙 然而在一个大的局域网内，通常会有一个大的网络防火墙，因为局域网内的数据报文都是经由 网络防火墙的,负责整个网络的防护机制 硬件防火墙和软件防火墙硬件防火墙：实现逻辑：专业的硬件级防护设备 非通用CPU 一般电脑上的CPU可以处理很多软件，而 使用的专业CPU，只负责管理防火这类的功能 通用CPU：可以完成诸多的功能 软件防火墙： 通过特殊的防火软件来实现 而单纯的硬件防火墙一般是达不到防火目的的，纯软件却可以达到防火目的，一般都是软硬件一起来实现防火目的的 网络防火墙:检测TCP协议的下4层的协议报文(传输层极其以下的层数)应用层防火墙：只是适用于某种服务和协议 linux上的防火墙实现linux的防火墙是模仿OpenBSD实现的防火墙 1.传软件实现 2.内核级实现的，只负责TCP协议的下4层的协议报文(传输层极其以下的层数)中工作和防护 也就是在前文所说的传输子网上进行工作和防护的 内核级的防火机制：在数据报文经过的路径上仔细选择5个钩子：hook，因为是必经之地，所以每个通过的报文都会被hook勾住，然而这里只设置了hook，而没有设置规则，这些规则是由主机的管理员来设置的只有满足设置的规则的数据报文才允许通过当然这个hook不单单是防火功能，有时把经过的数据报文勾起来，修改它的目标地址源地址信息，这个功能叫地址转换，NAT所以对linux而言，防火墙的功能不单单是防火这一个功能，还包括地址转换，报文修改和连接追踪的关闭等几项功能 Netfilter框架的组成和负责的功能Netfilter只是内核级的framework通过系统调用实现：syscall:iptables由5个钩子基本实现了linux的防火墙而这5个hook统称netfilter,只是内核中的一个框架framework，hook只是勾住数据报文，规则则由用户管理员添加，只需要在5个hook的位置上添加相应规则即可 前3个hook是防火功能 input+output+forward 访问本机内部的应用后2个hook:是实现地址转换，报文修改和连接追踪的关闭 prerouting:在进入本机网卡接收队列前的瞬间：路由前 postrouting:由本机发出或者forward转发的离开本机网卡接收队列的瞬间：路由后 而prerouting是不能做过滤的 三种报文流向：流入的报文： prerouting–&gt;路由–&gt;input–&gt;进入用户空间进程流出的报文：这里说的流出报文是指由本机主动发出的请求报文 用户空间进程 –&gt;output–&gt;postrouting转发的报文： prerouting–&gt;forward–&gt;postrouting 而数据报文是有来有往的，有请求报文就应该有响应报文，所以整个通信的过程报文流向应该是 先流入报文：请求报文 prerouting–&gt;路由–&gt;input–&gt;进入用户空间进程 再出去：响应报文 用户空间进程 –&gt;output–&gt;postrouting转发报文：请求 prerouting–&gt;forward–&gt;postrouting转发报文的：响应 也是prerouting–&gt;forward–&gt;postrouting这里要搞清楚，因为客户端和服务端是相对的，进来的都是prerouting出去的都是postrouting 而请求和响应的数据报文，因为方向不同，数据报文内封装的源IP+端口和目标IP+端口是相反的客户端和服务端则是相对的，转发报文也是类似的，也是有来有往的而为了服务器资源来说，如果要阻止报文，控制的是请求报文而非响应报文 什么是iptables？实现规则的工具iptables和firewalld因为Netfilter只是框架，规则由用户来设置，而Netfilter是内核中的，用户是无法直接与内核进行交流的，所以linux创建了一个在用户空间的工具iptables,iptables是一个规则编辑器，能调用内核级的Netfilter的系统调用接口，把写的规则送到内核上的hook上，并立即生效，而内核的数据是保存在内存中的，关机则会丢失定义好的规则，要想规则永久生效，就需要保存在系统reboot时自动加载的文件中，或者由启动的软件间接调用这个规则文件(iptables-server). 而ipfirewall–&gt;ipchains–&gt;iptables–&gt;nfstables iptables是工作在网络层，可以通过隐式扩展工作在传输层，通过显示扩展的string工作在应用层但是不能识别应用层http协议，ftp协议的请求方法，可以识别报文中的字串 iptables的组成iptables由五个表和五个链以及一些规则组成 五个表table：filter、nat、mangle、raw、security filter表：过滤规则表，根据预定义的规则过滤符合条件的数据包 nat表：network address translation 地址转换规则表 mangle：修改数据标记位规则表 raw：关闭NAT表上启用的连接跟踪机制，加快封包穿越防火墙速度 security：用于强制访问控制（MAC）网络规则，由Linux安全模块（如SELinux）实现 优先级由高到低的顺序为:security --&gt;raw--&gt;mangle--&gt;nat--&gt;filter 如果把规则放在input和output上称为主机防火墙，只防护当前主机内部的进程是如何访问的 iptablesnetfilter内核级的框架，内核framework，过滤器syacall：iptables工具，管理规则： centos7上：默认安装firewall 系统内自带的前端工具firewall;默认启用，建议关闭或卸载即可 firewalld:系统守护进程，firewall-cmd 在真正的防火墙管理时，建议用iptables来管理的 iptables： 保存iptabels规则的命令包 iptables-services 需要自己手动安装 用iptables-save restore管理加载事先设定好的防火墙规则即可 Netfilter表和链对应关系 报文流向： * 流入报文路径：到本机内部 * 流出报文路径：由本机发出 * 转发报文路径：转发 tables chains链:在通过iptables引用是是需要大写的 * filter: INPUT,FORWARD,OUTPUT只有3个链 * nat: PREROUTING,INPUT,OUTPUT,POSTROUTING 4个链 * mangle: PREROUTING,INPUT,FORWARD,OUTPUT,POSTROUTING * raw: PREROUTING,OUTPUT 就算filter和nat上都在同一个input链上，因为不属于一个table的，规则是各自生效的那么input上同时有filter和nat表的规则时，则是有优先级的 为了实验，要先关闭firewalld设置开机不启动systemctl stop firewalldsystemctl disabled firewalldsystemctl is-enabled firewalld 规则顺序很重要因为有些规则具有一票否则权比如drop，一旦报文匹配到drop规则，后面的规则都不看因为有些规则具有一票否则权比如accept，一旦报文匹配到drop规则，即使后面有drop也无效从这两条来说把检查条件苛刻的规则放前面规则调用的模块化管理：自定义链，由主链取调用才会生效，删除或更改时方便管理 iptables的命令使用格式获取帮助： CentOS 7：man iptables-extensions CentOS 6：man iptables 规则的编写格式：iptables [-t table] COMMAND chain [rulesnum][-m matchname [per-match-options]] [-j targetname [per-target-options]]表–&gt;命令–&gt;chain–&gt;对链 -t table： 默认为filter；其它可用的有raw, mangle, nat； 子命令COMMAND: 管理链： -P：policy，策略，定义链的默认策略； 一般有两种选择，ACCEPT和DROP； -N：new，新建一条自定义的规则链；被内建链上的规则调用才能生效；[-j chain_name]； -X：drop，删除自定义的、空的、或者引用计数为0的空链； -F：flush，清空指定的链； -E：重命名引用计数和为0的自定义链； -F：flush, 清空整条链 -Z：zero，计数器置零；改为零 iptables的每条规则和每个链都有专用的两个计数器： 每一个规则所匹配到的报文数量个数：pkts 和体积计数器之和：bytes 管理规则：增删改、插入 -A：append，追加，在指定链的尾部追加一条规则； -I：insert，插入，在指定的位置（省略位置时表示链首）插入一条规则； -D：delelte，删除，删除指定的规则； -R：replace，替换，将指定的规则替换为新规则；不能仅修改规则中的部分，而是整条规则完全替换； 查看：链上查看规则的动作，属于action的一种 -L：list，列出表中的链上的规则； -n：numeric，以数值格式显示； -v：verbose，显示详细格式信息； -vv, -vvv -x：exactly，计数器的精确结果； --line-numbers：显示链中的规则行号； 重置规则计数器： -Z：zero，置0； 计数器： 规则，以及默认策略有专用的计数器； 记录被当前规则所匹配到的： (1) 报文个数； (2) 字节总数； chain： (1) 内建链；INPUT OUTPUT FORWARD PREROUTING POSTROUTING (2) 自定义链； 匹配条件：matchname 多重条件：逻辑关系为“与”； 检查报文： TCP或UDP首部：源端口、目标端口、标记为ACK FSM: 有限状态机:TIME_WAIT,监听状态等 IP首部: SIP，DIP MAC首部：MAC地址 将防火墙规则保存下来 iptables-save &gt; /tmp/iptables-rules.v0.1 iptables-restore &lt; /tmp/iptables-rules.v0.1 开机自动加载iptables规则 yum install iptables-services -y 规则的保存和永久生效： 将iptables保存在文件 iptables-save iptables-restore iptables-server的service脚本 保存在/etc/sysconfig/iptables中，开启启动自动加载 firewalld,firewalld-cmd是不能调用iptables定义的规则，用iptables-server 必须先安装，不能并行 匹配条件又分为：通用匹配和扩展匹配 通用匹配条件： 5种检查方式：源 目标 协议 流入 流出 [!] -s, --sip,--source-ip报文源地址 其值可以是单个IP，或者连续IP，可以是网络地址，不能是离散的地址 [!] -d, --destination address[/mask][,...]：检查报文中的目标IP地址是否符合此处指定的地址或范围； [!] -i, --in-interface name：数据报文从哪个网卡接口进入； PREROUTING，INPUT, FORWARD 因为-i是数据报文流入的选项； 所以-i选项只能上面这三个链有关,用在前半部分相关的链上 [!] -o, --out-interface name：数据报文从哪个网卡接口出去； FORWARD, OUTPUT POSTROUTING 同理因为-o是数据报文流出的选项； 所以-o选项只能上面这三个链有关,用在后半部分相关的链上 [!] -p, --protocol protocol：四层协议 tcp|udp|icmp|sctp 这也是为什么iptables叫网络防火墙的原因，正常的工作只能工作在网络层， 检查网络层属性，但是-i -o和网络层属性没关系，和网络层下面的协议有关 正常情况下，网络防火墙是用来检查网络层首部来获得相关信息的 扩展匹配条件：又分为隐式扩展和显示扩展 /lib/modules/$(uname -r)/net/netfilter/下xt开头的就是扩展模块 默认没有载入到内核中，只有当用时才加载的，就叫隐式扩展 netfilter为了做深入的条件检查，通过特定的模块来实现检查功能 隐式扩展：不用-m选项指出matchname即可使用此match的专用选项进行匹配； -p tcp：隐含了-m tcp； [!] --source-port,--sport port[:port] 匹配报文中传输层的源端口； 可以使用单个端口或者连续端口，但是不能使用离散端口 [!] --destination-port,--dport port[:port]、 匹配报文中传输层的目标端口； 可以使用单个端口或者连续端口，但是不能使用离散端口 端口也只有2^16-1=65535个端口 [!] --tcp-flags mask comp SYN，ACK，FIN，RST，URG，PSH； mask：要检查的标志位列表，以逗号分隔； comp：必须为1的标志位列表，余下的出现在mask列表中的标志位则必须为0； --tcp-flags SYN,ACK,FIN,RST SYN 如果只定义SYN则代表tcp握手的第一次，一般只检查第一次 如果定义的是SYN，ACK代表tcp握手的第二次 如果是ACK，则代表tcp的正常通信过程 [!] --syn：因为检查tcp握手的第一次比较常用 所以系统内就设置这个选项代表下面这个选项 相当于--tcp-flags SYN,ACK,FIN,RST SYN -p udp：隐含了-m udp： [!] --source-port,--sport port[:port]：匹配报文中传输层的源端口； [!] --destination-port,--dport port[:port]：匹配报文中传输层的目标端口； -p icmp：隐含了-m icmp:互联控制消息协议 [!] --icmp-type {type[/code]|typename} icmp是有状态的 8：echo-request 0：echo-reply 显式扩展：必须使用-m选项指出matchname，有的match可能存在专用的选项； 显示扩展能帮我们更灵活的设置控制规则 获取帮助： CentOS 7：man iptables-extensions CentOS 6：man iptables 1、multiport扩展 以离散或连续的方式定义多端口匹配条件； 离散最多为15个，以冒号隔开的算一个，所以连续的端口用冒号隔开 [!] --source-ports,--sports port[,port|,port:port]...：指定多个源端口； [!] --destination-ports,--dports port[,port|,port:port]...：指定多个目标端口； [!] --ports port[,port|,port:port]...：指定多个端口； 2、iprange扩展：连续的地址集 以连续的ip地址范围指明连续的多地址匹配条件； [!] --src-range from[-to]：源IP地址； [!] --dst-range from[-to]：目标IP地址； 3、set扩展：定义离散地址集 如果要开放的地址既不是连续的，也不是网络地址就需要使用set了 set依赖于ipset命令行工具；需要用ipset先定义一个地址集， 再用set调用地址集即可；需要先安装ipset安装包 yum install ipset ，重启iptables服务 set存在类型，常用的有两个： hash:net 网络地址的集合：两个网段剧哦多个网段 hash:ip IP地址的集合：离散地址集 使用方式： 先创建集合：ipset create NAME TYPE( hash:ip/hash:net) 向集合添加元素：ipset add NAME ELEMENT set再调用 --match-set NAME src --match-set NAME dst 4、string扩展：字串匹配， 借助string扩展，iptables把触角伸到了应用层 对报文中的应用层数据做字符串匹配检测； [!] --string pattern：要检测字符串模式； [!] --hex-string pattern：要检测的字符串模式，16进制编码； --algo {bm|kmp} 2组比较算法 5、time扩展 根据报文到达的时间与指定的时间范围进行匹配度检测； --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：起始日期时间； --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：结束日期时间； --timestart hh:mm[:ss] --timestop hh:mm[:ss] [!] --monthdays day[,day...] [!] --weekdays day[,day...] --kerneltz：使用内核中配置的时区 ~]# iptables -I INPUT -d 172.16.100.67 -p tcp --dport 23 -m time --timestart 09:00:00 --timestop 18:00:00 --weekdays Tue,Thu,Sat -j ACCEPT 6、connlimit扩展 根据每客户端IP做并发连接数匹配； --connlimit-upto n：连接数数量小于等于n，此时应该允许； --connlimit-above n：连接数数量大于n，此时应该拒绝； ~]# iptables -A INPUT -d 172.16.100.67 -p tcp --dport 23 -m connlimit --connlimit-upto 2 -j ACCEPT 7、limit扩展 基于收发报文的速率进行匹配； --limit rate[/second|/minute|/hour|/day]：平均速率 --limit-burst number：峰值速率 8、state扩展 状态检测；连接追踪机制（conntrack）； INVALID：无法识别的状态； ESTABLISHED：已建立的连接； NEW：新连接； RELATED：相关联的连接； UNTRACKED：未追踪的连接； nf_conntrack内核模块；记忆是由内核空间的conntrack模块实现的 追踪到的连接：/proc/net/nf_conntrack文件中； 能追踪的最大连接数量定义在：/proc/sys/net/nf_conntrack_max 此值可自行定义，建议必要时调整到足够大； 不同的协议的连接追踪的时长： /proc/sys/net/netfilter/ [!] --state STATE 如何开放被模式的ftp服务： (1) 装载追踪ftp协议的模块； # modprobe nf_conntrack_ftp (2) 放行命令连接 ~] # iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT ~] # iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state NEW -j ACCEPT (3) 放行数据连接 ~] iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state RELATED -j ACCEPT 处理动作（目标） -j targetname [per-target-options] targetname： 简单： ACCEPT：接受； DROP：丢弃； 被请求的服务器数据报文丢弃了，请求端需要等待时间会消耗服务端和客户端资源 扩展： REJECT：--reject-with:icmp-port-unreachable默认 拒绝；适用内网，直接弹回报文请求 RETURN:当被调用的自定义链上没有规则则自动返回主链继续匹配; REDIRECT：端口重定向 SNAT：源地址转换 DNAT：目标地址转换 MASQURADE:地址伪装 LOG：日志 自定义链：可以先定义自定义链，再通过主链调用， 当自定义链被引用时，需要先删除引用，再清空自定义链，然后再删除 每个表对应控制的链，各不相同，记住对应关系网络层tcp协议的头部信息 2btye 2^16-1（0表示通用）2个半连接*2这里因为有两个半连接，请求和回应报文，所以防火墙要设置input接收请求和output回应报文，开启接收请求关闭回应报文，对方也是无法接收到回应报文的 生产环境下如何设置防火墙？：1.因为生产环境下，被管理的主机不在本地或者在其他省份，我们是通过ssh远程连接管理的! 2.防火墙规则一般是要设置白名单的，而默认策略是需要设置为DROP或者REJECT，这时，如果 不先把SSH或者VNC先设置白名单，我们就无法管理了！那就是给自己找麻烦了 3.所以要先为SSH服务设置白名单，再设置默认策略为DROP或者REJECT！！！ 4.默认策略可以用-P设置，也可以用自定义策略；自定义策略的好处 5.防火墙的检查机制,是按照顺序从上往下一个个匹配，如果最上面的一旦匹配即使下面有更 严格的条件，也会不生效，所以我们应该把检查严格的条件放到检查宽松的上面 比如：string检查规则(具体看示例)等 iptables的使用规范iptables -F 即清空filter表的所有链，因为默认是filter表 iptables -F INPUT，清空filter表上的INPUT链的所有规则 定义防火墙要设置白名单 极端清空下所有链都是drop的 如果主机有多个网卡，当网关来用的时，forward链就是用来当网络防火墙来用的 规则优化： (1) 注意规则的优先顺序，检查严格的放到前面， (1) 可安全放行所有入站及出站，且状态为ESTABLISHED的连接； (2) 服务于同一类功能的规则，匹配条件严格的放前面，宽松放后面； (3) 服务于不同类功能的规则，匹配报文可能性较大扩前面，较小放后面； (4) 设置默认策略； (a) 最后一条规则设定； (b) 默认策略设定； 隐式扩展示例：隐式扩展示例1：SSH服务 因为是ssh连接的，如果要设置默认策略为DROP，就一定要先开启SSH服务的请求和回应 iptables -A INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 22 -j ACCEPT 再设置默认INPUT链策略为DROP：两种写法：下文会表示自定义链的写法好处 iptables -P INPUT -j REJECT 设置默认策略是拒绝 或者用自定义写法： iptables -t filter -A INPUT -j REJECT，定义流入的默认策略 iptables -A OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 22 -j ACCEPT iptables -t filter -A OUTPUT -j REJECT(代替默认策略的写法) 设置自定义白名单的好处： 必要时，所有规则都可以通过自己明确给定的规则来定义 可以写一个脚本把自定义规则写进去，执行后就可以不受控于默认策略 因为管理的主机不在本地，如果再修改iptables规则时，把ssh也拒绝了，那么就有很大问题 可以把规则写在一个脚本里，在任务计划里创建一个清空防火墙规则的命令 即使脚本里的规则把自己拒绝了，可以等任务计划执行后，就可以登进去了，易于控制 隐式扩展示例2：http服务 在会前基础上开放80端口的访问 iptables -I INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 80 -j ACCEPT iptables -I OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 80 -j ACCEPT 隐式扩展示例3：lo网卡 将127.0.0.1设置不受控 在之前的基础上ping 127.0.0.1是受控的 之前的iptables -t filter -P INPUT DROP，是将0.0.0.0到0.0.0.0都拒绝了 本地127.0.0.1也被拒绝了，所以稍微修改为非lo网卡受控，lo网卡即不受控了 iptables -R INPUT 3 ! -i lo -j REJECT iptables -R OUTPUT 3 ! -o lo -j REJECT 隐式扩展示例4：-p icmp的隐式扩展；ping请求 如何设置当前主机可以ping其他主机，加在最后一条的前面 在之前的基础上此时主机主动ping其他主机也是受控的 icmp是有类型的,见下图，8 echo-request; 0 echo reply iptables -I OUTPUT 3 -p icmp --icmp-type 8 -j ACCEPT iptables -I INPUT 3 -p icmp --icmp-type 0 -j ACCEPT 隐式扩展示例5：DNS -p udp 如何设置开放本机可以通过DNS解析域名 从本机出去，到达互联的DNS服务器，再接收回应的报文 iptables -I OUTPUT -p udp --dport 53 -j ACCEPT 出去的报文 iptables -I INPUT -p udp --sport 53 -j ACCEPT 回来的报文 自定义链的使用示例(-N -E -X -F)以在自定义链中加入samba服务为例 -N：新建一条自定义的规则链 只不过在自定义链上是由计数器的 iptables -N new_rules 新建自定义链 iptables -E new_rules cifs_rules 改自定义链，必须要0引用的，0 references 自定义规则链的创建、调用、删除； 以在自定义链中加入samba服务;然后主链在调用自定义链为例 先设置入栈的规则 iptables -A cifs_rules -p tcp --dport 139 -j ACCEPT iptables -A cifs_rules -p tcp --dport 445 -j ACCEPT iptables -A cifs_rules -p udp --dport 137:138 -j ACCEPT iptables -A cifs_rules -j RETURN 还要加一条RETURN规则表示，当cifs_rules规则被主链调用时，如果自定义链上的规则 没有被匹配到，则return到主链上继续匹配主链上的后续规则. 在INPUT链去调用自定义链cifs_rules iptables -I INPUT 5 -s 192.168.34.0/24 -j cifs_rules 删除自定义链：需要先删除引用 iptables -D INPUT 5 iptables -F cifs_rules iptables -X cifs_rules 显示扩展示例必须使用-m选项指出matchname，有的match可能存在专用的选项 显示扩展示例1：multiport扩展 --多端口匹配 将21 22 80 139 445一起开启允许访问： iptables -I INPUT -p tcp -m multiport --dports 21:22,80,139,445 -j ACCEPT iptables -I OUTPUT -p tcp -m multiport --sports 21,22,80,139,445 -j ACCEPT 显示扩展示例2： ip-range:必须是连续的范围 允许ping的主机为192.168.34.100-192.168.34.106段的IP地址： iptables -I INPUT 3 -p icmp --icmp-type 8 -m iprange --src-range 192.168.34.100-192.168.34.106 -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 0 -m iprange --dst-range 192.168.34.100-192.168.34.106 -j ACCEPT 显示扩展示例3：set扩展 ipset先定义地址集: ipset create allowpinghosts hash:ip --先定义IP地址集 ipset add allowpinghosts 192.168.34.107 --向地址集添加IP地址 set再调用地址集： iptables -I INPUT 4 -p icmp --icmp-type 8 -m set --match-set allowpinghosts src -j ACCEPT iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m set --match-set allowpinghosts dst -j ACCEPT 显示扩展示例4：string扩展：字串匹配 比如：控制httpd服务的报文带有sex字串的都拒绝进入和访问 事先构建一个带有sex字串的html文件，然后设置规则 （因为这个规则比较严格，所以记得要放到允许访问httpd规则的前面！） iptables -I INPUT -p tcp --dport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT iptables -I OUTPUT -p tcp --sport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT 显示扩展示例5：time扩展]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现四层和七层负载均衡]]></title>
    <url>%2F2018%2F03%2F26%2Fnginx%E5%AE%9E%E7%8E%B0%E5%9B%9B%E5%B1%82%E5%92%8C%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[nginx实现七层负载均衡 1.先通过upstream模块将多个后端服务器定义成server服务器组，再使用proxy_pass向后端 代理到这个server组 2.upstream模块实现模块级的负载均衡算法调度 3.upstream模块可以实现对后端服务器集群的健康状态监测，当有服务器down机了自动从这个 组中剔除，服务器恢复正常也会重新加入到这个组中，还支持所有服务器down机，然后由 一台sorry server提供服务 4.session保持的三种方式： session sticky: 1.基于客户端IP做hash将seesion保存在一台服务器上，如果是SNAT网络则IP是 一样的，seesion的颗粒度过于粗糙. 2.cookie机制即使是在通过SNAT网络中，不同的浏览器客户端也会被识别为不同 客户端，seesion的颗粒度精细的多.nginx可以识别应用层的cookie信息， 完全可以基于cookie信息做会话绑定的.但是只有nginx商业版支持. seesion replication: 在同一集群中，session是共享的，但是对内存的消耗比较大 把自己的seesion复制给集群的其他主机 session server: 把用户访问的seesion保存单独的一台服务器，但是session的冗余实现比较麻烦 和cookie ngx_http_upstream_module模块作用于server之外的http上下文 1.upstream name {...} 定义后端服务器组；引入一个新的上下文；只能用于http{}上下文中； 默认调度算法是round robin，也就是加权轮询wrr；默认权重是1 2.server address [parameters]; 定义服务器地址和相关的参数； 地址格式： IP[:PORT] HOSTNAME[:PORT] unix:/PATH/TO/SOME_SOCK_FILE server的修饰参数： weight=number 权重，默认为1； max_fails=number 失败尝试连接的最大次数；默认是1次 fail_timeout=time 设置服务器为不可用状态的超时时长； 失败的默认健康状态检测超时时长，默认10s 备注：max_fails和fail_timeout的乘机算一个周期，比如下面这个例子 backup 把服务器标记为“备用”状态；用于say sorry服务器 down 手动标记其为不可用；手动下线服务器，用于发布更新服务 支持的算法： 3.least_conn; 1.短连接最好使用轮询wrr，长连接最好使用wlc; 2.如果不启用保持连接，即使改成least conn,效果也不是很明显. 3.最少连接调度算法，当server拥有不同的权重时其为wlc，当所有后端主机连接数 相同时，则使用wrr，适用于长连接 4.ip_hash;静态hash算法 对源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server； 1.ip_hash是对源地址进行hash，然后对后端服务器的权重之和取模，模是多少， 就把对应的结果映射到第几台服务器上，如果有服务器down了，那么权重 之和也会变，那么原来的hash结果大概率不能命中，所以ip_hash的调度算法存在很大的缺陷. 2.如果采用ip_hash算法，一旦后端有一台缓存服务器down了，由于是取模法，会造 成后台缓存服务器集群全部不能命中，并发请求数10W时，会把请求压力全部集 中到后端服务器上，造成系统崩溃 3.所以生产环境下一般不用ip_hash，而是采用一致性hash算法. 5.hash key [consistent]; consistent,虚拟主机的一致性hash算法； 此处可以对任意的key进行hash,所选取的key的值不同，hash的结果可以实现不同的 请求调度功能.而且此处的key可以是文本，变量或者二者的组合 例如： hash $remote_addr consistent = ip_hash 即还是对源地址进行hash，但是效果确实一致性hash hash $request_uri consistent 后端服务器是缓存服务器时，对静态内容的请求资源request_uri进行hash， 极有可能在缓存中命中,从而缓解了并加大了服务器的并发访问数. hash $cookie_name consistent 对cookie的hash，首先服务端需要给客户端端强行插入cookie,就需要用到 sticky_cookie_insert,而这个功能只有在nginx plus版本中才能够使用 6.keepalive connections; 可使用长连接的连接数量；每worker与后端服务保持的最大空闲长连接数量； 为每个worker进程保留的空闲的长连接数量，可节约nginx端口，并减少连接管理的消耗 长连接的作用： connections意思代理服务器与后端服务器之前先建立一定数量的始终不断开的长连接数量，当有用户请求时，这些长连接相当于一个一直处于连接状态管道，即一个连接上可以 发N个请求，既可以提升响应速度又可以减少代理服务器的套接字占用，避免了重复建立、断开、再建立的消耗资源的步骤,属于一种优化方式. 示例： upstream staticwebservs { # ip_hash; # hash $remote_addr consistent; hash $request_uri consistent; server 172.17.0.2 weight=2 fail_timeout=2 max_fails=2; server 172.17.0.3 fail_timeout=2 max_fails=2; keepalive 32； } server { listen 8083; location / { proxy_pass http://staticwebservs/; } 这样就可以检测后端服务器集群健康状态的时长，在4s内检测到服务器有问题，就标记为down 而且建立不断开的长连接 总结： 1.对静态资源的请求，因为是短连接，要用weight round robin,加权轮询算法:wrr 2.对动态资源的请求，因为要有会话保持seesion sticky，所以要用ip_hash或者 hash $remote_addr consistent 算法，但是对IP hash的颗粒度较为粗糙，可以 对cookie进行hash,但是nginx社区版不支持. 3.如果网站有缓存层，要用hash $request_uri consistent一致性hash的绑定机制算 法,避免因为后端的一台缓存服务器down机，而影响全局的缓存层! nginx实现四层负载均衡(调度)功能 1.nginx实现四层调度，在nginx和后端服务器集群中建立一个四层的转发通道，对客户端发来 的请求报文不做任何解析，而是对客户端请求的地址和端口转发. 2.如果后端有服务器集群，可以通过upstream模块实现不同算法的负载均衡调度效果. 3.四层负载调度功能，作用于stream上下文，需要单独定义 4.对数据存储等有状态的一类的应用一定不能做负载均衡，而是通过一种数据分发路由机制的 高级组件来完成，比如mysql的读写分离，mysql的分片框架等 5.如上图示，因为只是实现四层调度，不存在什么动静分离资源，只是简单的四层调度功能 ngx_stream_core_moduleThe ngx_stream_core_module module is available since version 1.9.0. This module is not built by default, it should be enabled with the --with-stream configuration parameter. (1) listen address:port [ssl] [udp] [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; 监听的端口； 默认为tcp协议； udp: 监听udp协议的端口； ngx_stream_upstream_module实现四层调度需要在upstream中定义，负载均衡调度的组 upstream name {...}，作用于stream上下文 server address [parmameters] 修饰符： weight=number max_conns=number max_fails=number fail_timeout=time backup down ngx_stream_proxy_module(1) proxy_pass address; (2) proxy_timeout timeout; 默认为10m; (3) proxy_connect_timeout time; 设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s； 示例： stream { upstream sshsrvs { server 192.168.10.130:22; server 192.168.10.131:22; hash $remote_addr consistent; } server { listen 172.16.100.6:22202; proxy_pass sshsrvs; proxy_timeout 60s; proxy_connect_timeout 10s; } } 实现Nginx高并发的Linux入门级内核优化虽然nginx本身就支持高性能的并发访问，除了在配置文件级别的一些性能调优的必要参数之外有时也需要在linux内核级进行简单的调优. 优化说明： 优化是很复杂的一个问题，不是明显的设置缺点的话，不建议对nginx进行优化，因为不确定哪个是导致nginx明显短板的因素，有时也可以通过nginx的二级调度来实现高并发的 访问. 1.由于默认的Linux内核参数考虑的是最通用场景，这明显不符合用于支持高并发访问的 Web服务器的定义，所以需要修改Linux内核参数 2.Nginx可以拥有更高的性能,根据业务特点来进行调整，当Nginx作为静态web内容服务器、反向代理或者提供压缩服务器的服务器时，期内核参数的调整都是不同的，这里针对最通用的、使Nginx支持更多并发请求的TCP网络参数做简单的配置,修改/etc/sysctl.conf来更改内核参数 3.sysctl的用法： sysctl命令： 默认配置文件：/etc/sysctl.conf (1) 设置某参数 sysctl -w parameter=VALUE (2) 通过读取配置文件设置参数 sysctl -p [/path/to/conf_file] (3) 查看所有生效参数 sysctl -a 最好是写在/etc/sysctl.conf中，再通过sysctl -p /etc/sysctl.conf生效即可 比如： 进制本机被ping的设置 sysctl -w net.ipv4.icmp_echo_ignore_all=1 fs.file-max = 999999：单个进程较大可以打开的文件描述符数量 ulimit -n 999999 net.ipv4.tcp_tw_reuse = 1 (必调) 参数设置为1，表示允许将TIME_WAIT状态的socket重新用于新的TCP连接，因为在服务器端有大量的处于TCP中的TIME_WAIT状态的链接存在，能够复用这个socket对于繁忙的服务器来说意义重大. echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse (sysctl) net.ipv4.tcp_keepalive_time = 600 当keepalive启动时，TCP发送keepalive消息的频度，默认为2小时，将其设置10分钟，可以更快的清理无效连接 net.ipv4.tcp_fin_timeout = 30 当服务器主动关闭连接是，socket保持在FIN_WAIT2状态的较大时间 net.ipv4.tcp_max_tw_buckets = 5000 默认是8000，建议调小 允许TIME_WAIT套接字数量的较大值，如果超过这个数字，TIME_WAIT套接字将立刻清除并打印警告信息，默认为8000，过多TIME_WAIT套接字会使web服务器变慢 net.ipv4.ip_local_port_range = 1024 65000 TCP和UDP连接的本地端口取值范围 net.ipv4.tcp_rmem = 1024 87380 12582912 TCP接收缓存的最小值、默认值、最大值 net.ipv4.tcp_wmen = 1024 87380 12582912 TCP发送缓冲的最小值、默认值、最大值 net.core.netdev_max_backlog = 8096 网卡接收队列最大值 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_sync_backlog = 8192 TCP三次握手建立阶段接收SYN请求队列的最大长度，默认为1024 net.ipv4.tcp_tw_recyle = 1 启用timewait的快速回收]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于lnnmp搭建个人博客]]></title>
    <url>%2F2018%2F03%2F22%2F%E5%9F%BA%E4%BA%8Elnnmp%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[基于openstack/docker搭建LNNMP -个人网站基本架构图 环境准备1.所有服务器时间要同步 2.proxysql要和mysql所有服务器在同一个网段，不然会影响mysql的性能 nginx调度服务器：192.168.100.10 nginx+fpm-1服务器：192.168.100.3 nginx+fpm-2服务器：192.168.100.4 proxysql数据库读写分离：192.168.100.30 mysql_1服务器:192.168.100.9 mysql_2服务器:192.168.100.16 mysql_3服务器:192.168.100.17 NFS主：在mysql_2服务器上192.168.100.16 NFS备：在mysql_3服务器上192.168.100.17 软件版本： wordpress: wordpress-5.0-zh_CN.zip (默认安装再升级) wordpress-5.0.2-zh_CN.zip(用于测试升级版本) 依赖于php7.3版本之上和mysql5.6或者mariadb10.0版本之上 mysql:mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz(和一键安装脚本) nginx:nginx-1.12.2.tar.gz php-fpm:php-7.2.14.tar.gz nfs: nfs-utils 1.搭建一主二从数据库二进制安装mysql，此处用事先准备好的脚本进行安装(供参考)； 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@mysql_1 ~]# vim mysql-install.sh #!/bin/bashDIR=`pwd`NAME=&quot;mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz&quot;FULL_NAME=$&#123;DIR&#125;/$&#123;NAME&#125;DATA_DIR=&quot;/data/mysql&quot;yum install vim gcc gcc-c++ wget autoconf net-tools lrzsz iotop lsof iotop bash-completion -yyum install curl policycoreutils openssh-server openssh-clients postfix -yif [ -f $&#123;FULL_NAME&#125; ];then echo &quot;安装文件存在&quot;else echo &quot;安装文件不存在&quot; exit 3fiif [ -h /usr/local/mysql ];then echo &quot;Mysql已经安装&quot; exit 3else tar xvf $&#123;FULL_NAME&#125; -C /usr/local/src ln -sv /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64 /usr/local/mysql if id mysql;then echo &quot;mysql用户已经存在&quot; fi useradd mysql -s /sbin/nologin if id mysql;then chown -R mysql.mysql /usr/local/mysql/* -R if [ ! -d /data/mysql ];then mkdir -pv /data/mysql &amp;&amp; chown -R mysql.mysql /data -R /usr/local/mysql/scripts/mysql_install_db --user=mysql --datadir=/data/mysql --basedir=/usr/local/mysql/ cp /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64/support-files/mysql.server /etc/init.d/mysqld chmod a+x /etc/init.d/mysqld cp $&#123;DIR&#125;/my.cnf /etc/my.cnf ln -sv /usr/local/mysql/bin/mysql /usr/bin/mysql chkconfig --add mysqld service mysqld start else echo &quot;MySQL数据目录已经存在&quot; exit 2 fi fifi 主节点数据库： 1.启用二进制日志和跳过主机名称解析 server-id=1 log_bin=/data/mysql/master-log skip_name_resolve = on 2.授权主从复制账号 grant replication slave on *.* to repluser@&apos;192.168.100.%&apos; identified by &apos;root123&apos;; 3.show master logs; 查看二进制日志位置，准备change master to信息 4.创建wordpress数据库 create database wordpress; 5.创建php连接mysql的用户和proxysql读写分离的用户 grant all on *.* to wordpress@&apos;192.168.100.%&apos; identified by &apos;wordpress123&apos; 此账号既作为php连接数据库的账号，又作为proxysql中读写分离的账户 从节点数据库： 1.每个从节点都需要如下设置，设置只读，启用中继日志 server-id=2|3 read-only relay_log=/data/mysql 2.设置change master to: CHANGE MASTER TO MASTER_HOST=&apos;192.168.100.9&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;root123&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-log.000001&apos;, MASTER_LOG_POS=4, MASTER_CONNECT_RETRY=120; 3.start slave; 启动MySQL主从 service mysqld start 安装配置proxysql读写分离器1.基于YUM仓库安装 vim /etc/yum.repos.d/proxysql.repo [proxysql_repo] name= ProxySQL YUM repository baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever gpgcheck=1 gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key 2.安装启动 yum install proxysql &amp;&amp; systemctl start proxysql 3.向ProxySQL中添加MySQL所有节点，以下操作不需要use main也可成功 MySQL &gt; select * from mysql_servers; MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.9&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.16&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,&apos;192.168.100.17&apos;,3306); MySQL &gt; load mysql servers to runtime; MySQL &gt; save mysql servers to disk; 4.配置监控账号： a.在主节点上，创建监控账号 grant replication client on *.* to monitor@&apos;192.168.100.%&apos; identified by &apos;root123&apos;; 备注：replication client权限是负责监控的，和replication slave是不同的权限 b.Proxysql上配置监控 实际上是保存在global_variables表中，可以查看是否修改成功 MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;; MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;; c.使global_variables表生效 MySQL [mian]&gt; load mysql variables to runtime; MySQL [mian]&gt; save mysql variables to disk; 5.设置分组信息和读写规则 main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20 插入读写组的编号： insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;); 生效和保存： MySQL [monitor]&gt; load mysql servers to runtime; MySQL [monitor]&gt; save mysql servers to disk; 再次查看 select hostgroup_id,hostname,port,status,weight from mysql_servers; 6.创建用于测试读写分离的账号 主节点上创建访问用户： 用上面创建的wordpress账户即可 在ProxySQL配置，将用户wordpress添加到mysql_users表中： insert into mysql_users(username,password,default_hostgroup)values(&apos;wordpress&apos;,&apos;wordpress123&apos;,10); 生效和保存： MySQL [monitor]&gt; load mysql users to runtime; MySQL [monitor]&gt; save mysql users to disk; 7.配置路由规则，实现读写分离 与规则相关的表：mysql_qeury_rules 插入路由规则,实现读写分离的规则 insert into mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply) VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1); 生效和保存到磁盘： load mysql query rules to runtime; save mysql query rules to disk; 8.可以现在本机用wordpress测试是否可以实现读写分离 读：因为是读操作会在2和3上随机选择 mysql -wordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos; 写：事务是非select开头的，所以查询的都是1上 mysql -uwordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos; 编译安装php1.准备环境依赖包： yum -y install wget vim pcre pcre-devel openssl openssl-devel libicu-devel gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel ncurses ncurses-devel curl curl-devel krb5-devel libidn libidn-devel openldap openldap-devel nss_ldap jemalloc-devel cmake boost-devel bison automake libevent libevent-devel gd gd-devel libtool* libmcrypt libmcrypt-devel mcrypt mhash libxslt libxslt-devel readline readline-devel gmp gmp-devel libcurl libcurl-devel openjpeg-devel 2.编译php: ./configure --prefix=/usr/local/php \ --with-config-file-path=/usr/local/php/etc \ --with-config-file-scan-dir=/usr/local/php/etc/conf.d \ --enable-fpm --with-fpm-user=www \ --with-fpm-group=www --with-pear \ --with-curl --with-png-dir --with-freetype-dir \ --with-iconv --with-mhash --with-zlib --with-xmlrpc \ --with-xsl --with-openssl --with-mysqli --with-pdo-mysql \ --disable-debug --enable-zip --enable-sockets \ --enable-soap --enable-inline-optimization --enable-xml \ --enable-ftp --enable-exif --enable-wddx \ --enable-bcmath --enable-calendar --enable-shmop \ --enable-dba --enable-sysvsem --enable-sysvshm --enable-sysvmsg make &amp;&amp; make install 3.创建用户 useradd www 4.准备配置文件 cd /usr/local/php/etc/ cp php-fpm.conf.default php-fpm.conf cp php-fpm.d/www.conf.default php-fpm.d/www.conf 1.修改php-fpm.d/www.conf配置文件，使用dynamic动态模式，并设置最大，最少 空闲进程等信息 2.修改启动php的用户为www 5.准备启动脚本 cp /root/ php-7.2.14/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm chkconfig --add php-fpm chkconfig php-fpm on 也可以使用编译生成的 /usr/local/php/sbin/php-fpm直接启动 编译安装nginx实现web服务因为在上文架构图中nginx既做web服务，又作为前端负载均衡服务器 在这两台服务器上编译安装nginx,实现转发wordpress请求 nginx+fpm-1服务器：192.168.100.3 nginx+fpm-2服务器：192.168.100.4 1.解压并编译 tar xf nginx-1.12.2.tar.gz cd nginx-1.12.2 ./configure \ --prefix=/usr/local/nginx \ --with-pcre \ --with-http_stub_status_module \ --with-http_ssl_module make &amp; make install 2.修改配置文件将php资源请求调度到php-fpm 在server的上下文定义：因为nginx和php在同一台服务器，所以直接写127.0.0.1:9000 location / { root /data/nginx/wordpress; index index.php index.html index.htm; } location ~ \.php$ { root /data/nginx/wordpress;(可不写) fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 如果location中不写root，$document_root就要写/data/nginx/wordpress$fastcgi_script_name; 3.启动服务 /usr/local/nginx/sbin/nginx 部署wordpress-5.0在两台nginxweb服务器上安装同样的wordpress和配置 1.创建存放wordpress目录 mkdir -pv /data/nginx/wordpress 2.解压并将全部文件拷贝到/data/nginx/wordpress下 tar xf wordpress-5.0-zh_CN.zip mv wordpress/* /data/nginx/wordpress/ 3.修改/data/nginx/wordpress的所有者和所属组 chown -R www.www /data/nginx/wordpress 4.准备连接数据库的文件 cp wp-config-sample.php wp-config.php vim wp-config.php /** WordPress数据库的名称 */ define(&apos;DB_NAME&apos;, &apos;wordpress&apos;); /** MySQL数据库用户名 */ define(&apos;DB_USER&apos;, &apos;wordpress&apos;); /** MySQL数据库密码 */ define(&apos;DB_PASSWORD&apos;, &apos;wordpress123&apos;); /** MySQL主机 */ define(&apos;DB_HOST&apos;, &apos;192.168.100.30:6033&apos;); 此处连接的mysql数据库主机是proxysql读写分离的IP和端口 通过NFS共享图片目录准备NFS主备后端存储： 1.这里nfs主备用mysql的两台从服务来实现 yum install nfs-utils -y 一定要安装nfs-utils，实际环境测试不安装utils，访问nfs的速度很慢 准备共享目录： mkdir -pv /nfsdata/images 设置权限nfs共享目录权限 vim /etc/exports /nfsdata/images *(rw,no_root_squash) 2.实现主备NFS的图片同步 rsync -avrlopg /nfsdata/images/* 192.168.100.17:/nfsdata/images/ 在nginx+pfp-fpm的两台服务器挂载nfs的共享目录 showmount -e 192.168.100.16 显示该主机上可以挂载的nfs目录 1.挂载目录并设置开机自动挂载 因为wordpress的图片是保存在/data/nginx/wordpress/wp-content/uploads中的 所以要把该目录用nfs共享 1.vim /etc/fstab 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads/ nfs defaults,_netdev 0 0 写在fstab文件中一定要加_netdev选项,刚开机没有IP地址时，即使挂载不上也可以启动 2.也可以写在/etc/rc.d/rc.local中，因为该文件是系统启动最后加载的文件，此时 已经获取到IP地址了，当然可以实现自动挂载,要设置执行权限 vim /etc/rc.d/rc.local mount -t nfs 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads chmod +x /etc/rc.d/rc.local 3.备注： NFS共享，为了避免IP地址的问题，最好要配置一个DNS服务器来主机名和IP地址 挂载的时候最好使用主机名取挂载，即使IP地址出问题了，也可以临时在DNS服务器上 修改主机名和IP地址的对应关系. 编译安装nginx实现负载均衡nginx调度服务器：192.168.100.10 1.解压并编译 tar xf nginx-1.12.2.tar.gz cd nginx-1.12.2 ./configure \ --prefix=/usr/local/nginx \ --with-pcre \ --with-http_stub_status_module \ --with-http_ssl_module make &amp; make install 2.修改配置文件实现七层调度 在http上下文定义： vim /usr/local/nginx/conf/nginx.conf upstream blogs { server 192.168.100.3:80 weight=1 max_fails=3 fail_timeout=100s; server 192.168.100.4:80 weight=1 max_fails=3 fail_timeout=100s; hash $remote_addr consistent; (做会话保持) } server { listen 80; server_name www.lkblog.net; index index.html index.php; location / { proxy_pass http://blogs; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; add_header X-Via $server_addr; proxy_next_upstream http_502 http_504 error timeout invalid_header; } } 3.启动服务 /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx -t /usr/local/nginx/sbin/nginx -s reload 配置完后重新加载 启动各服务，并测试读写-注册完后生成数据库各表-上传图片测试，在nfs也是可以看到的，说明挂载是成功的 -浏览站点，因为是普通的http请求，用轮询的方式是没问题的 -对于登录页面，如果没有做会话保持是登不上去的，这也是为什么Nginx负载均衡器上做源地址hash的原因. 升级wordpress版本版本更新需要注意最好不要跨大版本进行更新，一般更新也是在大版本下进行小版本的更新 以下以wordpress-5.0--&gt;wordpress-5.0.2 步骤： 1.停止Nginx服务 2.备份元数据或删除 3.升级版本 4.启动服务 简单的以脚本方式实现一台wordpress升级 vim updates.sh ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx -s stop&quot; ssh 192.168.100.4 &quot;rm -rf /data/nginx/wordpress/*&quot; scp wordpress-5.0.2-zh_CN.zip 192.168.100.4:/data ssh 192.168.100.4 &quot;unzip wordpress-5.0.2-zh_CN.zip -d /data/nginx/wordpress/&quot; ssh 192.168.100.4 &quot;chown -R www.www /data/nginx/wordpress/&quot; ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx&quot;]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现反向代理功能]]></title>
    <url>%2F2018%2F03%2F22%2Fnginx%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[Nginx实现反向代理服务器的配置 nginx实现反代的工作原理： 1.代理服务器需要注册监听端口，用来接收用户请求，而监听端口是可以被复用的，且一个端口可以接收N路请求. 2.代理服务器本地没有资源，当请求报文送达时，由于代理服务本身就是个web服务器，所以能够充分理解请求报 文的MIME类型，URL等，差别只是本来是需要通过IO加载本地资源的，但是由于本地没有，则会向后端服务器 去取资源，但是此时请求报文已经被完完整整的拆开了，是不能把请求报文发往后端的 3.所以在nginx中是由一个模块扮演成类似客户端浏览器角色的，把自己模拟成客户端程序，封装一个新的http请求， 向后端服务器发起请求. 4.而后端服务器会把响应报文发送给代理服务器，代理服务器则又会拆掉网络层封装，传输成封装，应用层封装， 看到响应报文的body主体部分，把主体部分拿出来重新封装成一个响应报文发回给客户端》 5.只要是向后端请求必然会再占用一个端口 6.代理服务器要维持两路连接，而且是彼此隔离且独立的 7.那么向后端发送的请求报文要不要带客户端请求中所独有的私有的信息数据？ 如果不传递，后端服务器是无法识别并相应的，必要时要把客户端的属性信息:请求 的url,用户认证信息等等重新封装到向后端发送的请求报文中，还是引用了客户端 发来的数据，而且代理服务器是可以修改请求报文的信息和响应报文中的信息 8.代理服务器可以操纵发往后端的请求和操纵响应给客户端的请求 9.这些也只有工作在应用层并且能识别应用层协议才可以实现的，如果再加一些访问控制 的功能，那么就可以做到四层防火墙做不到的访问控制能力，这也是代理服务器叫做 代理网关的原因，对于iptables和LVS是做不到的 10.面向客户端工作http/https协议，面向后端工作http,tcp,fastCGI,memcache，uwsgi(python的web框架) 等协议，那么这个能模拟客户端的模块就需要是多种专用模块 1.nginx作为代理服务器来说，面向于客户端和服务端可以代理多种协议 代理服务器又叫代理网关，因为工作在应用层可以控制用户访问请求的资源，具有防护功能 面向客户端： 一般是http/https协议：通过http模块实现 mail:简单邮件传输协议等 stream:stream模块实现代理四层协议：tcp/udp (nginx从1.9版本后可以实现四层负载均衡的) 代理后端服务器： nginx内嵌了很多客户端模块来适配不同的后端协议： http协议的服务器：ngx_http_proxy_modules模块 fpm服务器：ngx_http_fastcgi_module模块 memche服务器： 代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx) 1.nginx作为代理服务器是，代理客户端和后端服务器，在数据报文是有两段的： 1.客户端—&gt;代理服务器 2.代理服务器作为客户端—&gt;后端的httpd/fpm/memche服务器 而且代理服务器可以把客户端发来的数据报文进行修改重新封装发给后端服务器， 后端服务器响应给代理服务器的报文也可以被代理服务器修改，再响应给客户端 在设置中，可以通过不能功能体现出数据报文被如何修改的！ 2.作为代理配置和nginx作为web服务器差不多，只不过要把root/alias缓存proxy_pass 如果同时又root和proxy_pass，proxy_pass的优先级高 3.在location中将.php或者.jpg代理到不同的后端服务器上，可以实现资源请求的动静分离 实现了在一台代理服务器上的资源路由. ngx_http_proxy_module模块：1.proxy_pass URL 代理http协议的主要功能，是将客户端的请求代理至后端服务的路径上 Context: location, if in location, limit_except； server { ... server_name HOSTNAME; location / { proxy http://hos[:port]; 优先级高于server的root } location /uri/ { proxy http://host/new_uri/; } location ~|~* /uri/ { proxy http://host; } ... } http://HOSTNAME/uri --&gt; http://host/uri http://HOSTNAME/uri/ --&gt; http://host/new_uri/ http://HOSTNAME/uri/ --&gt; http://host/uri/； 路径映射，前后端的location和proxy_pass是映射关系,必要加/ 如果location是正则表达式路径，proxy_pass的路径必须没有/和URI，因为是正则表达 式，无法判断路径 -前后端路径映射 2.proxy_set_header field value; 前面说过代理服务器可以修改客户端请求数据报文的信息发送给后端服务器，而对于后端 服务器来说看到的请求报文的源IP一直是代理服务器，但是可以通过修改参数是的后端 服务器看到的IP地址是真正的客户端地址而不是代理服务器！ 设定发往后端主机的请求报文的请求首部的值；Context:http,server,location 设置代理服务器： proxy_set_header X-Real-IP $remote_addr; 或者 proxy_set_header X-Real-HOST $host;将 或者 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 然后修改后端服务器的日志格式： LogFormat &quot;%{X-Real-IP}i %l %u %t \&quot;%r\&quot; %&gt;s %b&quot;重启httpd服务即可 此时，后端服务器看到的IP就是客户端的IP了，所以可以设置任何真实的信息传递给后端服务器 Nginx代理Web服务的Proxy缓存功能Nginx是一个高性能的web服务器，尤其在高并发和处理静态页面的时候有先天的优势；很大一部分得益于缓存的开启，缓存的实现逻辑 * 此处是作用于http的上下文，因为每个代理模块都有缓存功能，但是不能混用 * 要想使用proxy的缓存功能，必须先定义再引用 * 定义缓存所以列表：对文件进行hash生成hash串，hash串是16进制数字，如果把hash串的前三位数字，按照数字放在对应的层级生成一个三级索引列表 * 根据实际情况定义缓存层级，每多一次就是对磁盘IO的消耗，灵活定义缓存层级很有必要，比如一层以1个16进制数就是16个目录，2个16进制数就是2^8=256个目录，可以通过增加每次的级数，减小层数，对磁盘的IO消耗就降低了 nginx的缓存功能： 不一定启用nginx缓存，可以使用varnish,或者CDN 只有真正需要启用时，才会启用nginx缓存 3.proxy_cache_path nginx作为代理服务器是可以使用缓存功能的 定义缓存功能键也就是索引，是放在内存中的 定义可用于proxy功能的缓存；Context:http的上下文 proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 4.proxy_cache ksys_zone的name | off; 指明要调用的缓存，或关闭缓存机制；Context:http, server, location 5.proxy_cache_key string; 虽然定义了缓存，还需要定义键，而这个键就是用户访问的地址; 1.为了避免后端有两台server_name有一模一样的URI,造成缓存索引出错，这里引入 了更多的差别数据，把整个访问路径都引入进来进行hash值缓存. 2.然而把整个url都引入进来，也会有问题，比如一个server有两个主机名，路径本 来就应该是相同的，如果引入了全路径则造成缓存不能命中了 3.所以如何定义这个&quot;键&quot;是根据不同场景使用的 默认值：proxy_cache_key $scheme$proxy_host$request_uri; 有时也可以定义为：$request_uri 所以根据不同使用场景proxy_cache_key的值需要修改 6.proxy_cache_valid [code ...] time; 通过定义不同的响应码来定义不同的缓存时长；(也可以统一为一个值) 7.proxy_cache_use_stale 当后端服务器有问题时，是否能够用过期的缓存资源响应客户端请求，默认是关闭的 proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...; 8.proxy_cache_methods GET | HEAD | POST ...; 设置客户端通过什么方法查询时，才调用缓存功能 9.proxy_hide_header field; 隐藏发送给客户端的响应报文的信息；f12中的header中看到的 默认nginx在响应报文中不传递后端服务器的首部字段Date, Server, X-Pad, X-Accel-等，用于隐藏后端服务器特定的响应首部 代理服务器请求后端服务器的几个超时时长： 10.proxy_connect_timeout time; 定义代理服务器后端服务器发请求的三次握手的连接时长 默认为60s，最长75s,不需要调 11.proxy_read_timeout time; 从后端接收响应报文的超时时长 12.proxy_send_timeout time; 连接建立后，向后端发送请求报文的超时时长 示例： 先在http上下文中定义缓存； proxy_cache_path /data/cache/nginx levels=1:1:2；keys_zone webcache:10m max_size=2G; 再在server或者location中调用缓存和设置&quot;键&quot;以及过期时长； location ~* \.(jpg|gif|jpeg)$ { proxy_pass http://172.17.0.2; proxy_cache webcache; proxy_cache_key $request_uri;(这里根据不同场景定义) proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; proxy_cache_methods GET HEAD; proxy_cache_use_stale error timeout http_500 http_502 http_503; 这样就表示把缓存放在/data/cache/nginx中,最好是固态硬盘，磁盘IO越快，索引 查询的速度越快，定义了1:1:2三层路由索引，第一层16个目录，第二层16个子目录 第三次256个子目录 ngx_http_headers_module模块：操纵响应报文首部区别于proxy_set_header： 是代理服务器把客户端请求报文中的某些信息通过修改代理服务器请求报文首部的方式发送给后端服务器 headers： 代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值；达到隐藏 某些信息不发给客户端。 1.add_header name value [always]; 添加自定义首部； add_header X-Via $server_addr; 或者 add_header X-Accel $server_name; 发送给客户端的响应报文时，显示真正的后端服务器IP或者主机名 2.expires [modified] time; expires epoch | max | off; 响应缓存的缓存时长 用于定义Expire或Cache-Control首部的值； Nginx代理后端fastCGI协议 1.fpm其实就是一种类似于httpd的MPM模型中的prefork模型 启用一个fpm主进程，生成n个子进程，由子进程内部的php解释器负责处理并发的多路 请求，再将在本地运行完的php页面程序处理结果响应给请求的调用者 2.fastcgi其实就是简装版的http协议，后端对应的php的fpm就是fastcgi协议的服务器后端 的解析fastcgi协议，而且还能够让fpm的子进程加载磁盘上的php程序文件在php解释器 中运行执行出结果 3.Php并不支持编译成nginx的模块，那么Nginx只能调fastcgi模块与后端的fpm(php)服务器 进行通信，实现LNMP的架构 4.真正与mysql等数据库通信的是php程序代码，即php到mysql的驱动模块，而不是php解释器 5.如上图，因为fpm对进程的管理能力较弱，可以用nginx与全端调度器去连接，而且nginx可 以根据fastcgi处理请求的并发数，在nginx处限制向后端的请求连接数，nginx可以实现 中间件进行流量控制的效果. 6.php管理自己子进程的方式有两种，static和dynamic动态和静态管理方式 7.实现fpm的负载均衡调度，也是需要 ngx_http_fastcgi_module模块：1.fastcgi_pass address; address为fastcgi server的地址； location, if in location； 如：fastcgi_pass localhost:9000; http://www.ilinux.io/admin/index.php --&gt; /admin/index.php (uri) /data/application/admin/index.php 2.fastcgi_index name; fastcgi默认的主页资源; web的是index.html,php应该为index.php 如：fastcgi_index index.php 3.fastcgi_param parameter value [if_not_empty]; 1.由于动态站点在处理请求时，需要取得客户端在连接请求报文中的很多信息(IP,请求 方法,flag,param等)，所以nginx代理必须把保存在变量中与客户端连接状态的 数据，原样的传递给后端的fpm-server或fastcgi. 2.但是保存在nginx的变量名格式和fastcgi的变量名表示格式是不一样的，nginx的 是$+全小写的变量名，fpm是全大写的变量名 3.安装nginx默认就带有/etc/nginx/fastcgi_params,这个文件记录了需要向后端 fpm传递的所有变量. 4.除了传递变量，还需要将请求的uri与后端fpm服务器的路径建立映射关系，即定义 fpm上存放请求页面资源的真正路径. 配置示例： 比如先起一个fpm的容器：并且将动态资源保存在php容器的/data目录下 docker run --name php1 -d -v /data/php1:/data php:7-fpm-alpine 在nginx代理上如下设置： location ~* \.php$ { fastcgi_pass 172.17.0.4:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; include fastcgi_params; } fpm的状态监控4.php的状态监控 1.fpm的进程有static和dynamic两种管理方式，而且为了监控fpm是否正常工作，fpm的 配置文件中内嵌了/pm_status和/ping两个url来监控，status用来输出内嵌信息的 ，而默认是通过fastcgi协议显示的，不能直接看到状态信息，所以可以通过http协 议进行反代来检测fpm的工作状态. 2.可以通过显示监控状态的值，再通过ab,JMeter等工具进行压力测试，调整fpm的实际 场景下的并发访问量 配置示例：通过/pm_status和/ping来获取fpm server状态信息； location ~* ^/(status|ping)$ { fastcgi_pass 172.17.0.2:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; include fastcgi_params; } 测试： 如下图可以通过http://192.168.34.107:8082/status?xml&amp;full 或者html、json格式输出并显示出来，而且还可以通过接口调用加入到zabbix监控中 fastcgi的压力测试和缓存功能a.fastcgi的动态资源缓存意义更大，因为php不用每次都执行代码了 b.要使用缓存就需要先定义缓存； c.因为后端动态资源服务器是有用户认证和用户支付的资源的，为了信息安全对动态资源的缓 存一定不要缓存包含用户信息的资源 定义缓存：和proxy的缓存是不能兼容的，需要单独定义(在server外,http的上下文定义) 4.fastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义； levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE leves=1:2:2 keys_zone=name:size k/v映射的内存空间的名称及大小 inactive=time 非活动时长 max_size=size 磁盘上用于缓存数据的缓存空间上限 调用缓存： 5.fastcgi_cache keys_zone的名称 | off; 调用指定的缓存空间来缓存数据；http, server, location 无定义默认使用的键，需要手动指定 6.fastcgi_cache_key string; 定义用作缓存项的key的字符串； 7.fastcgi_cache_methods GET | HEAD | POST ...; 为哪些请求方法使用缓存； 8.fastcgi_cache_min_uses number; 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； 9.fastcgi_cache_valid [code ...] time; 不同的响应码各自的缓存时长； 10.fastcgi_keep_conn on | off; 默认情况下，fastCGI响应一个请求后会立刻断开，如果是on状态会保持长连接 fastcgi缓存定义示例： http { fastcgi_cache_path /data/cache/fcgi levels=1:2 keys_zone=fcgicache:10m max_size=2G; server { ... location ~* \.php$ { fastcgi_pass 172.17.0.4:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; include fastcgi_params; fastcgi_cache fcgicache; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 301 1h; fastcgi_cache_valid any 1m; fastcgi_cache_methods GET HEAD; } 缓存性能测试： ab -n 1000 -c 50 http://192.168.34.107:8082/index.php 在缓存前和缓存后通过模拟50路并发请求测试响应时间]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现web服务配置]]></title>
    <url>%2F2018%2F03%2F20%2Fnginx%E5%AE%9E%E7%8E%B0web%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[nginx安装和配置文件Nginx下载安装和模块使用说明手册 nginx安装： 源码编译,二进制安装，yum安装，要注意使用次版本为偶数的版本 nginx所说的高度模块化是指静态模块，如果编译安装了很多模块，启动时不管在配 置文件是否使用该模块，默认都是加载的，不过在Nginx的新版本中少量的动态模块 是可以按需加载的 而httpd是可以通过modprobe安装加载模块的 配置文件的组成部分： 主配置文件： /etc/nginx/nginx.conf 还包括 conf.d/*.conf和default.d/*.conf 对于同以功能的配置最好放到一个*.conf中，方便管理 /usr/lib/systemd/system/nginx.service Unit file文件 /usr/sbin/nginx 主程序文件 /usr/share/nginx/html/404.html /usr/share/nginx/html/50x.html /usr/share/nginx/html/index.html 页面文件 fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 启动和配置： yum install nginx -y （编译时按需加载模块即可） systemctl start nginx / nginx 备注： 在生产环境下只要是修改nginx相关的配置文件,一定要nginx -t先进行测试 再nginx -s reload使配置文件生效 配置： 主配置文件的配置指令： 指定生效的范围，三个上下文中 directive value [value2 ...]; 注意： (1) 指令必须以分号结尾； (2) 支持使用配置变量； 内建变量：由Nginx模块引入，可直接引用； 自定义变量：由用户使用set命令定义； set variable_name value; 引用变量：$variable_name 主配置文件结构： main block：主配置段，也即全局配置段；都是顶格写的 event { ... }：事件驱动相关的配置； http { server {} root proxy_pass server {} ... }：http/https 协议相关的配置段； mail { ... } stream { ... } 主配置段都不管是web服务、mail服务还是四层代理是都需要配置的，而且这三个功能一般是 不会一起使用的，至少http和mail功能是不一起使用的 Nginx的全局配置和优化必调参数项配置指令： main配置段常见的配置指令：全局配置 分类： 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置： 1、user，group,是默认运行nginx的用户和组，按需修改 2、pid /PATH/TO/PID_FILE; 指定存储nginx主进程进程号码的文件路径； 3、include file | mask; 指明包含进来的其它配置文件片断； 4、load_module file; 指明要装载的动态模块； 性能优化相关的配置： 1、worker_processes number | auto; worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数； auto：当前主机物理CPU核心数； 2、worker_cpu_affinity cpumask ...; worker_cpu_affinity auto [cpumask]; nginx进程的CPU亲缘性解释； 1.因为CPU有三级缓存，一级和二级是每个CPU所独有的，只有三级缓存是共享的； 2.将worker进程与cpu绑定，这个进程会在cpu本地缓存很多数据和状态信息 3.如果把这个进程调到其他cpu上，那么之前的缓存就失效了，从而影响了性能，而cpu的绑定则起到刚好的负载效果和性能 CPU MASK： 00000000： 0000 0001：0号CPU 0000 0010：1号CPU 0000 0100：2号CPU 0000 1000：3号CPU ... ... 0000 0111：表示0和1号和2号CPU； 3、worker_priority number; 指定worker进程的nice值，设定worker进程优先级；[-20,19] 4、worker_rlimit_nofile number; worker进程所能够打开的文件数量上限； 对于高并发的服务器来说至关重要，每一个连接都需要打开一个套接字，每一个套接 字的维持都需要一个文件描述符，默认情况下linux限制每个用户最多同时打开1024 个文件，所以并发数量很高时，并发数量受限于文件数量，因此对于高并发服务器来 说都需要修改ulimit数量(ulmit -a/-n number) 事件驱动相关的配置: events { ... } 1.worker_connections number; 事件驱动决定了单个worker进程所能够打开的最大并发连接数数量； 所以nginx最大并发连接上限= [worker_processes] * [worker_connections] 在要求高并发的服务器上这两个是必调参数 2.use method; 指明并发连接请求的处理方法； use epoll；是事件驱动模型得以运行的根本 3.accept_mutex on | off;是否打开mutex互斥锁 处理新的连接请求的方法； on意味着由各worker轮流处理新请求，默认为on Off意味着每个新请求的到达都会通知所有的worker进程；会造成进程抢夺请求的情况 调试、定位问题： 1、daemon on|off; 是否以守护进程方式运行Nignx；默认为on 2、master_process on|off; 是否以master/worker模型运行nginx；默认为on； 调试时，把只有主进程处理请求和以前台运行来查找错误原因 3、error_log file [level]; 默认级别 Nginx实现web服务的全局配置和主要模块1.Nginx无论是作为web服务器或者是web服务器的代理服务器，所有配置都在http的上下文 2.location和directory的区别 1.httpd和nginx作为web服务器都可以对用户访问的资源进行限制 2.&lt;Directory &quot;/var/www/html/images/&quot;&gt; 也可以写成 &lt;Location &quot;/images/&quot;&gt; http协议的全局配置匹配检查顺序：server_name和Port–&gt;location–&gt;if in location–&gt;匹配路径(root和alias) ngx_http_core_module:Nginx的核心模块Nginx不管作为什么功能，都要使用core核心模块 http协议上下文的相关配置： http { ... ... 是http的全局配置，共享给多个server使用 server { ... listen server_name root/proxy_pass (root是作为web服务器的，proxy_pass是作为代理服务器使用的) location [OPERATOR] /uri/ (类似于httpd的directory） ... } } server { ... } } 与套接字相关的配置： 1、server { ... } 配置一个虚拟主机； server { listen address[:PORT]|PORT; server_name SERVER_NAME; root /PATH/TO/DOCUMENT_ROOT; } server只能出现在http的上下文中，而且不能嵌套server 2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] 特殊设置：前两个尤为重要 default_server：设定为默认虚拟主机； 如httpd基于主机名配置的多个虚拟主机，访问时是由上而下匹配的 ssl：强制只能通过ssl连接提供服务； backlog=number：后援队列长度； rcvbuf=size：接收缓冲区大小； sndbuf=size：发送缓冲区大小；(默认值足以满足需求) 3、server_name name ...; 必然要使用通配符来设置虚拟主机名和设置优先级 1.支持*通配任意长度的任意字符；server_name *.baidu.com www.baidu.* 2.支持~起始的字符做正则表达式模式匹配；server_name ~^www\d+\.baidu\.com$ (\d匹配单个数字) 匹配机制优先级： (1) 首先是字符串精确匹配; (2) 左侧*通配符； (3) 右侧*通配符； (4) 正则表达式； (并发访问多时，不建议使用正则表达式匹配主机名，对服务器性能有很大消耗) 4、tcp_nodelay on | off; 在keepalived模式下的连接是否启用TCP_NODELAY选项 当为off时，延迟发送，合并多个请求后再发送 默认On时，不延迟发送 可用于：http, server, location 5.tcp_nopush on|off; 在sendfile模式下，是否启用TCP_CORK选项； 5.sendfile on | off; 是否启用sendfile功能； 和定义路径相关的配置： 6.root path; 设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径； root可以作用在http, server, location, if in location上下文中， 如果多有多层级的root，则精确到最内层的root生效 7.location [ = | ^~ | ~ | ~* ] uri { ... } 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置； 用户请求server_name--&gt;server--&gt;Location--&gt;if in Location 会根据正则表达式匹配的优先级匹配到一个最佳的路径 修饰符号： 修饰符匹配优先级：=, ^~, ~/~*，不带符号； 1.=：对URI做精确匹配； 2.^~：对URI的左半部分做匹配检查，不区分字符大小写； 左半部分是指scheme中不包含path和它之后的部分 如https://www.lk.tech/images/1.jpg的左半部分是https://www.lk.tech 3.~：对URI做正则表达式模式匹配，区分字符大小写； 4.~*：对URI做正则表达式模式匹配，不区分字符大小写； 5.不带符号：以URI为前缀的所有uri；通配性最高级location / 还可以在location中定义if这种三级路由选择 root /vhosts/www/htdocs/ http://www.lk.tech/index.html --&gt; /vhosts/www/htdocs/index.html server { root /vhosts/www/htdocs/ location /admin/ { root /webapps/app1/data/ } } –官方示例 8.alias path; 定义路径别名，文档映射的另一种机制；仅能用于location上下文； 注意：location中使用root指令和alias指令的意义不同； (a) root，给定的路径对应于location中的/uri/左侧的/； (b) alias，给定的路径对应于location中的/uri/右侧的/； 如： location /images/ alias &quot;/data/www/&quot;; alias定义的意思是即 /images/* = /data/www/* location /images/ { alias &quot;/data/www/&quot;; root定义的意思就是访问 /data/www/images/* 9、设置默认主页：index file ...; 默认资源；http, server, location； 10、error_page code ... [=[response]] uri; 例如：error_page 404 /404.html; location = /404.html { root &quot;/www/error_pages&quot;; } 11、try_files file ... uri; 定义客户端请求的相关配置 定义客户端请求的相关配置 12、keepalive_timeout timeout [header_timeout]; 设定保持连接的超时时长，0表示禁止长连接；默认为75s； 13、keepalive_requests number; 在一次长连接上所允许请求的资源的最大数量，默认为100; 14、keepalive_disable none | browser ...; 对哪种浏览器禁用长连接； 15、send_timeout time; 向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长； 16、client_body_buffer_size size; 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置； 17、client_body_temp_path path [level1 [level2 [level3]]]; 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量； 16进制的数字； client_body_temp_path /var/tmp/client_body 1 2 2 1：表示用一位16进制数字表示一级子目录；0-f 2：表示用2位16进程数字表示二级子目录：00-ff 2：表示用2位16进程数字表示三级子目录：00-ff 对客户端进行限制的相关配置： 18、limit_rate rate; 限制响应给客户端的传输速率，单位是bytes/second，0表示无限制； 19、limit_except method ... { ... } 限制对指定的请求方法之外的其它方法的使用客户端； limit_except GET { allow 192.168.1.0/24; deny all; } 文件操作优化的配置 访问控制和认证的两个模块ngx_http_access_module模块：实现基于ip的访问控制功能，比httpd的控制更简单 1.allow address | CIDR | unix: | all; 2.deny address | CIDR | unix: | all; http, server, location, limit_except ngx_http_auth_basic_module模块 实现基于用户的访问控制，使用basic机制进行用户认证； 1.auth_basic string | off; 2.auth_basic_user_file file; 需要先生成账号密码，而且htpasswd命令由httpd-tools所提供； htpasswd -c -m /data/.nginxpasswd tom htpasswd -b -m /data/.nginxpasswd haha haha123 如： location /admin/ { auth_basic &quot;需要提供用户密码&quot;;(提示信息) auth_basic_user_file /etc/nginx/.ngxpasswd; } ngx_http_stub_status_module模块：状态监控一般和监控系统一起用，可以在编译安装nginx时加上这个选项 可以通过脚本函数监控这七个数值，纳入到zabbix中进行图形化监控 为了不影响其他location，一般定义专用的location来监控nginx状态，放在server内即可 用于输出nginx的基本状态信息； Active connections: 291 当前的活动连接 server accepts handled requests 连接数，接收并处理的，， 16630948 16630948 31070465 Reading: 6 Writing: 179 Waiting: 106 中间三个是统计数据，其他四个是当前数据； Active connections: 正在处理活动状态的连接数； accepts：已经接受的客户端请求的总数；(tcp建立的连接数) handled：已经处理完成的客户端请求的总数；(客户端发送，nginx处理过的) requests：客户端发来的总的请求数；(建立tcp连接并发送的请求数) Reading：处于读取客户端请求报文首部的连接的连接数；(接收报文) Writing：处于向客户端发送响应报文过程中的连接数；(nginx发送报文) Waiting：处于等待客户端发出请求的空闲连接数； (已经读取未发送的) 用于监控nginx的连接数脚本 1.stub_status; 配置示例： location = /status { stub_status; } ngx_http_log_module模块：日志分析展示nginx官方日志变量说明 1.log_format name string ...; string可以使用nginx核心模块及其它模块内嵌的变量； 日志格式： $remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos; http_x_forward_for 表示被代理服务器的日志记录的访问的IP地址是代理服务器，为了在后端服务器上记录真实的客户端，需要启用这一项 实现：1.为nginx定义使用类似于httpd的combined格式的访问日志； 2.把combined的日志格式定义输出成json格式(KV键值对) 2.access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 访问日志文件路径，格式及相关的缓冲的配置； buffer=size flush=time 3.open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 缓存各日志文件相关的元数据信息； max：缓存的最大文件描述符数量； min_uses：在inactive指定的时长内访问次数低于min_uses就认为是无效的； inactive：非活动时长； valid：验正缓存中各缓存项是否为活动项的时间间隔；检查inactive的间隔 ngx_http_gzip_module：文本资源压缩传输节约带宽在CPU等硬件资源不稀缺的情况下，带宽流量的稀缺使得资源压缩必须启用 启用资源压缩功能，虽然可以大大减小了带宽的消耗，要注意适用的场景； 1.比如当前服务器CPU负载较大，压缩功能本身就会消耗更多的CPU资源，如果启用 对服务器的压力就会更大 2.应该只对文本内容进行压缩，视频、图片、流媒体等本身就已经是有压缩比的资源 3.实现逻辑：先使用压缩过滤器过滤出来有很好压缩比的资源(css,js,html)等文本 再定义压缩规则 1.gzip on | off; 需要先开启gzip压缩功能 2.gzip_comp_level level; 设置压缩比1~9,压缩比越大对CPU的消耗越大 3.gzip_disable regex ...; 过滤User_Agent浏览器类型，禁用较老的浏览器版本不启用压缩功能。 4.gzip_min_length length; 当响应报文大小达到某个值，才压缩，太小就不值得压缩了 比如：低于100k不压缩，高于这个值才进行资源压缩，单位:byte字节 5.gzip_buffers number size; 支持实现压缩功能时为其配置的缓冲区数量(number)及每个缓存区的大小(size)； 在服务器的内存资源充沛时，启用缓冲区可以更快的对资源进行压缩 6、gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...; nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的； off：对代理的请求不启用 no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能； any:任何内容不压缩 7.gzip_types mime-type ...; 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能； 过滤需要压缩的类型，纯文本和html不需要，因为默认就对其压缩 示例： gzip on; gzip_comp_level 6; gzip_min_length 64; gzip_proxied any; gzip_types text/xml text/css application/javascript; ngx_http_ssl_module模块：如上图，代理服务用nginx不采用LVS的一个原因就是LVS不支持SSL的代理，nginx可以实现 面对客户端使用https协议，面对后端服务器集群使用http协议，所以有时nginx反代也叫https的会话卸载器 如果是四层调度，https访问必须是客户端与后端服务器之间建立； 如果两段式连接，对内调度是明文的，把压力放在前端代理服务器上，本身前端调度器 岁CPU资源消耗不是很大 1.ssl on | off; Enables the HTTPS protocol for the given virtual server. 2.ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件； 3.ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件； 4.ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2]; 支持ssl协议版本，默认为后三个； 5.ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; nginx的ssl会话有两种： 1.builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有； 2.[shared:name:size]：在各worker之间使用一个共享的缓存； ssl的session建立是很慢的,所以要启用ssl的缓存，而且还是shared类型的共享缓存方式 6、ssl_session_timeout time; 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长； 实现https加密： 生成私钥和证书： openssl genrsa -out nginx.key 2048 openssl req -new -x509 -key nginx.key -out nginx.crt -days 3650 -subj &quot;/CN=www.lk.tech&quot; 配置https主体： server { listen 443 ssl; server_name www.lk.tech; root /data/lk; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; } ngx_http_rewrite_module模块：实现URL重写 什么是url重写？为什么要用到url重写？ 1.客户端访问URL被重写到另外一个路径了 http://www.lk.tech/photos/1.jpg ---&gt; http://images.lk.tech/1.jpg 2.全站ssl加密时，将用户访问的http://请求全部被重写到https://的虚拟主机上 http://www.lk.tech/images/1.jpg---&gt;https://www.lk.tech/1.jpg rewirte的处理逻辑： 1.将用户请求的URL基于(regex)正则表达式的查找，而后完成替换即可(replacement) 2.如果出现server中两个location互相rewrite，则会出现死循环的现象，所以就引入 了last和break的两个机制 3.last表示接着检查其他rewrite，break表示匹配到当前的rewrite.就不检查其他的 rewrite了这样就避免了死循环。 1.rewrite regex replacement [flag] a.将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement 指定的新的URI； b.rewrite重写的路径可以是相对路径也可以是绝对路径 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制； 如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端 ；用的比较多的是301和302 301：permanent,永久重定向； 302：redirect,临时重定向； [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环； break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环； redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；302 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；301 2.return：类似于重定向的操作 return code [text]; return code URL; return URL; Stops processing and returns the specified code to a client. 3.rewrite_log on | off; 是否开启重写日志；可能出现安全风险，所以没有必要时不用开启 4.if (condition) { ... } 引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令； 一般用于server, location； condition： 比较操作符： == != ~：模式匹配，区分字符大小写； ~*：模式匹配，不区分字符大小写； !~：模式不匹配，区分字符大小写； !~*：模式不匹配，不区分字符大小写； 文件及目录存在性判断： -e, !-e -f, !-f -d, !-d -x, !-x 5.set $variable value; 用户自定义变量； 示例： location ~* ^/(photos|pictures) { ## rewrite ^/photos/(.*)$ /image/$1 last; # rewrite ^/photos/(.*)$ http://images.lk.tech:8081/$1; # rewrite ^/(photos|pictures)/(.*)$ http://images.lk.tech:8081/$2 permanent; # } -redirect和permanent的示例演示 ngx_http_referer_module模块：网站防盗链检查客户端的请求数据报文首部，实际就是防盗链的过滤器，所以在日志中记录referer referer来源： 1. 2. 1.valid_referers none | blocked | server_names | string ...; 定义referer首部的合法有效的值 none：请求报文首部没有referer首部； blocked：请求报文的referer首部没有值； server_names：参数，其可以有值作为主机名或主机名模式； arbitrary_string：直接字符串，但可使用*作通配符； regular expression：被指定的正则表达式模式匹配到的字符串； 要使用~打头，例如 ~.*\.lk.com； 使用说明和示例： 先定义valid_referers的允许连接网站，再通过if判断如果不是在 valid_referers中定义的网站，就返回一张图片或者文字说明 valid_referers none block server_names *.lk.com lk.* ~\.lk\.; if ($invalid_referer) { return http://www.lk.tech/hello.html; }]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible]]></title>
    <url>%2F2018%2F03%2F06%2Fansible%2F</url>
    <content type="text"><![CDATA[运维自动化管理工具之Ansible 内容：1.软件发布环境机制优势对比 和 2.ansible的应用ansible的相关的文档ansible的中文权威指南：ansible中文指南Github上的ansible-galaxy示例：ansible-galaxy 其他相关运维管理工具使用方法：pssh的使用方法参照链接文章：psshsaltstack介绍及使用参照链接文章：saltstackpuppet介绍及使用参照链接文章：puppet 当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric 常用自动化运维工具 PSSH：适用于主机数量很少的环境(基础ssh的key验证) Ansible:python,Agentless,中小型应用环境(自带代理功能) Saltstack:python，一般需部署agent，执行效率更高 Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境 Fabric：python，agentless Chef: ruby,国内应用少 Cfengine func 发布更新环境灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器 而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径 如： 软件路径为:/data/app 正在用的软件版本V1.0：/data/app1.0 更新的软件版本V2.0：/data/app2.0 则需要把删除原来的软链接：/data/app1.0---&gt;/data/app 创建新的软链接：/data/app2.0---&gt;/data/app 10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线 发布步骤： 1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。 2.从负载均衡列表中移除掉「金丝雀」服务器。 3.升级「金丝雀」应用（排掉原有流量并进行部署）。 4.对应用进行自动化测试。 5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。 6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。 A/B Testing A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。 优势与不足： 优势：用户体验影响小，灰度发布过程出现问题只影响少量用户 不足：发布自动化程度不够，发布期间可引发服务中断 预发布验证： 新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器 灰度发布： 可以基于主机，用户或者业务，又细分为地区，VIP和普通用户 蓝绿发布：核心：主备两套环境定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同 时也升级到新版本 主：绿色环境-活动环境：负责对外提供服务，版本：v1.0 备：绿色环境-非活动环境：版本：v2.0 工作机制： 先把备环境升级v1.0---&gt;v2.0版本，然后上线 把主环境的v1.0版本下线，已经升级的备环境进行替换 特点： 蓝绿部署无需停机，并且风险较小. 注意事项： 1.需要提前考虑数据库与应用部署同步迁移/回滚的问题 2.蓝绿部署需要有基础设施支持 3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境 和绿色环境有被摧毁的风险. 优势与不足： 优势：升级切换和回退速度非常快 不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响 滚动发布：在灰度发布的基础上进行进一步优化定义： 一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式. 特点： 1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数. 可以部分部署，例如每次只取出集群的20%进行升级。 2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出 优势和不足: 优势：用户体验影响小，体验较平滑 不足：发布和回退时间比较缓慢。 发布工具比较复杂，LB需要平滑的流量摘除和拉入能力 滚动发布目前成熟型技术组织所采用的主流发布方式 Ansible ansible特性：-最多管理500台主机，更多效率会降低1.模块化：调用特定的模块，完成特定任务 -类似linux中的小命令 2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块 3.支持自定义模块 4.基于Python语言实现 5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务) 6.安全，基于OpenSSH 7.支持playbook编排任务 -类似于脚本功能，多个脚本的集合成为Roles 8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 9.无需代理不依赖PKI（无需ssl） 10.可使用任何编程语言写模块 11.YAML格式，编排任务，支持丰富的数据结构 12.较强大的多层解决方案 Ansible的学习过程：1.ansible基本命令使用 2.ansible常用模块详解，介绍ansible单个命令的使用 3.YAML语法介绍 4.ansible playbook基础：剧本初体验，类似于写脚本 5.playbook中的变量：tags，handlers使用 6.plsybook模板：templates 7.playbook的条件判断：when 8.playbook的字典：with_items 9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合 会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。 ansible命令执行过程ansible命令执行过程 1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg 2. 加载自己对应的模块文件，如command 3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程 服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 4. 给文件+x执行 5. 执行并返回结果 6. 删除临时py文件，sleep 0退出 执行状态：(颜色定义在/etc/ansible/ansible.cfg中) 绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 CMDB作用介绍:CMDB:Configuration Management Database 配置管理数据库 将服务器的配置，网络配置写到数据库里 CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不 断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管 理等流程提供准确的配置信息. 了解更多CMDB可参照文章：CMDB 1.ansible基本命令使用ansible软件安装：多种安装方法1.基于epel源安装： yum install ansible,非服务，只是一个管理工具 2.编译安装： 3.Github方式安装：可以同步安装 4.pip安装：pip是安装Python包的管理器，类似yum ansible的重要&amp;主要文件配置文件： /etc/ansible/ansible.cfg 配置ansible的工作特性 /etc/ansible/hosts 主机清单 /etc/ansible/roles 存放的角色目录 程序文件： /usr/bin/ansible ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 常用命令： ansible all --list 查看ansible管理的主机群 ansible all -m &quot;模块名&quot; -a &apos;执行的命令&apos; 用什么模块执行什么命令 all也可以换成定义的--list中组的名字 ansible-playbook -C &apos;*.yml&apos; 对所有主机执行剧本 ansible-plsybook -C -t &apos;标签&apos; &apos;*.yml&apos; 对所有主机执行哪个标签的剧本 ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)支持不分组，分组，等方式 如： 192.168.34.100 [webservers] 192.168.34.101 192.168.34.102 [dbservers] 192.168.34.[1:6]7 (17,27..67) db[01:100].cenntos.com ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）配置文件只提供默认值，但可以通过playbook的设置进行覆盖 配置文件可以放在/etc/ansible/ansible.cfg中 也可以放到一个工作目录下命名为.ansible.cfg [defaults] inventory = /etc/ansible/hosts - 主机列表配置文件 library = /usr/share/my_modules/ - 库文件存放目录 remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录 local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录 forks = 5 - 默认并发数 sudo_user = root - 默认sudo 用户 ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码 ask_pass = True remote_port = 22 host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 [color] 定义ansible命令的执行结果颜色的 配置文件说明和建议修改的项：local_tmp和remote_tmp： 本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地 家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除. host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 module_name = command -默认使用的命令模块，可以修改成shell module_name = shell 2.ansible常用模块详解，介绍ansible单个命令的使用ansible模块的使用查询方法ansible-doc: 显示模块帮助 ansible-doc [options] [module...] -a 显示所有模块的文档 -l, --list 列出可用模块 -s, --snippet显示指定模块的playbook片段 示例： ansible-doc –l 列出所有功能模块 ansible-doc ping 查看ansible中的ping用法 ansible-doc -s shell 查看shell模块的使用方法 ansible的常用基本选项ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible 端能基于密钥认证的方式联系各被管理节点 ansible语法： ansible &lt;host-pattern&gt; [-m module_name] [-a args] --version 显示版本 -m module 指定模块，默认为command，主要使用选项 -v 详细过程 –vv -vvv更详细 --list-hosts 显示主机列表，可简写 --list -k, --ask-pass 提示输入ssh连接密码，默认Key验证 -K, --ask-become-pass 提示输入sudo时的口令 -C, --check 检查，并不执行 -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s -u, --user=REMOTE_USER 执行远程执行的用户 -b, --become 代替旧版的sudo 切换 ansible的主机清单表示方法:Host-pattern1.All ：表示所有Inventory中的所有主机 如：ansible all -m ping ansible all --list-hosts列出所有主机清单 ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP 2.* :通配符 如：ansible &quot;*&quot; = ansible all ansible 192.168.34.* 表示34网段的所有IP 3.或的关系 如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作 ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作 4.与的关系(且) 如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机 5.非，取反 如：ansible &apos;websrvs:!dbsrvs&apos; 在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号 6.正则表达式 如：ansible &quot;~(web|db).*\.centos\.com&quot; ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项1.Command：在远程主机执行命令，默认模块，可忽略-m选项 可以在ansible.cfg中修改默认模块项 支持：chdir(切换目录) command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现 使用示例： ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh ansible all -a &apos;useradd test&apos; 所有主机上创建test用户 2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项 支持功能：支持$ &lt; &gt; | ; &amp; 等 chdir 执行前，先切换到该文件夹 示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos; 显示appsrvs组的主机名 ansible all -m shell -a &apos;chdir=/data rm -rf *&apos; 先切换到/data目录下，再执行删除命令 3.Script: 批量运行脚本 可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理 功能：creates:远程主机的文件存在，则不运行 removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令 示例：ansible all -m script -a &quot;/data/test.sh&quot; ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot; 因为fstab文件存在，则不执行rm -rf /data/*命令 ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot; 因为fstab文件存在，则执行rm -rf /data/*命令 4.Copy:从服务器复制文件到目标主机 src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户 2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos; 根据自己写的字符串生成文件 5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取 src，dest(抓取到本机目录) 示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos; 将远程主机fstab2文件抓取到本机/data下 如果抓取的是目录，先打包再抓取 打包：ansible all -a &apos;tar cf /root/data.tar /data&apos; 抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos; 6.File：设置文件属性，创建/删除文件 src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos; 创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos; 删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos; 7.Hostname：管理主机名 可以通过后面的变量来实现 a.先在hosts后定义hostname变量名 [centos6] 192.168.34.106 hostname=mini6-2 192.168.34.101 hostname=node6-1 [centos7] 192.168.34.107 hostname=mini7-1 b.再通过hostname模块批量修改 ansible all -m hostname -a &apos;name={{hostname}}&apos; 8.Cron：计划任务 支持：minute，hour，day，month，weekday 示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate 172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务 ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名 ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名 9.Yum：管理包 支持：name,state=(started stopped reloaded restarted),absent 更新缓存：update_cache=yes， 示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包 ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包 10.Service：管理服务(同一systemctl&amp;service) name，state(stopped,started,reloaded,restarted) enable(设置开启启动) 示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务 ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务 ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务 ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动 11.User：管理用户 name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录) 示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos; 创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户 ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录 12.Group：管理组 支持：group,name,gid,system,state=(absent) 示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组 ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 ansible系列的一些模块(用的不多)简单介绍与了解： ansible-galaxy 互联网上的角色分享 ansible-pull 推送命令至远程，效率无限提升，对运维要求较高 Ansible-vault管理yaml文件 功能：管理加密解密yml文件 ansible-vault [create|decrypt|edit|encrypt|rekey|view] ansible-vault encrypt hello.yml 加密 ansible-vault decrypt hello.yml 解密 ansible-vault view hello.yml 查看 ansible-vault edit hello.yml 编辑加密文件 ansible-vault rekey hello.yml 修改口令 ansible-vault create new.yml 创建新文件 Ansible-console ansible重要知识之playbook(上面的各种模块的组合) YAML语言（编写playbook的专门语言）YAML语法： 在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三 个点号( ... )用来表示档案结尾 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 使用#号注释代码 缩进必须是统一的，不能空格和tab混用 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过 缩进结合换行来实现的 YAML文件内容是区别大小写的，k/v的值均需大小写敏感 k/v的值可同行写也可换行写。同行使用:分隔 v可是个字符串，也可是另一个列表 一个完整的代码块功能需最少元素需包括 name: task 一个name只能包括一个task YAML文件扩展名通常为yml或yaml List：列表，其所有元素均使用“-”打头 Dictionary：字典，通常由多个key与value构成 Playbook中的核心元素:1.Hosts 执行的远程主机列表 2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远 程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使 用sudo_user指定sudo时切换的用户 3.Tasks 任务集 4.Varniables 内置变量或自定义变量在playbook中调用 5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件 6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否 则不执行 7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible 具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其 确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可 以通过tags跳过此些代码片断 8.handlers和notify 运行playbook运行playbook的方式 ansible-playbook &lt;filename.yml&gt; ... [options] 常见选项 -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测 --list-hosts 列出运行任务的主机 --limit 主机列表 只针对主机列表中的主机执行 -v 显示过程 -vv -vvv 更详细 备注： 执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误 ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行 执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验将centos7的httpd.conf复制到centos7主机，6上的配置文件不同示例1：写一个安装启动httpd的playbook:install_httpd.yml 包括创建用户，安装httpd包，开启服务，并设置开机启动 - hosts: all remote_user: root tasks: - name: creat user user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd - name: copy config copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf - name: install package yum: name=httpd - name: service service: name=httpd state=started enabled=yes 备注： 执行完通过以下命令判断每个任务都否都执行成功了 1.ansible all -a &apos;getent passwd httpd&apos; 2.ansible all -a &apos;rpm -q httpd&apos; 3..ansible all -a &apos;ss -ntlp|grep 80&apos; 示例2：写一个删除上面的playbook:remove_httpd.yml 包括：删除用户，卸载httpd包 - hosts: all remote_user: root tasks: - name: del user user: name=httpd state=absent remove=yes - name: remove package yum: name=httpd state=absent 备注： 如果只删除特定主机的httpd，而不是全部，需要加--limit选项 ansible-playbook --limit 192.168.34.105 remove_httpd.yml 只限制在192.168.34.105的主机执行 上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。Handlers: 是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生 变化时，才会采取一定的操作 Notify: 此action可用于在每个play的最后被触发，这样可避免多次有改变发生 时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。 在notify中列出的操作称为handler，也即notify中调用handler中定义的操作 示例：示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200） - hosts: all remote_user: root tasks: - name: creat user user: name=memcached shell=/sbin/nologin uid=2345 - name: install package yum: name=memcached - name: copy config copy: src=/data/memcached dest=/etc/sysconfig/memcached notify: restart service 和handlers名称一致 - name: service service: name=memcached state=started enabled=yes handlers: - name: restart service 和notify名称一致 service: name=memcached state=restarted 备注：停止并删除用户和安装包 ansible all -a &apos;service memcached stop&apos; ansible all -a &apos;ss -ntl&apos; ansible all -a &apos;rpm -q memcached&apos; ansible all -a &apos;getent passwd memcached&apos; 可以多个notify对应一个handlers，也可以多个motify对应多个handlers示例4：多个notify对应一个handlers - hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ notify: restart httpd 第一个notify - name: ensure apache is running service: name=httpd state=started enabled=yes notify: restart httpd 第二个notify handlers: - name: restart httpd 对应一个handlers service: name=httpd status=restarted 示例5：多个notify对应多个handlers- hosts: websrvs remote_user: root tasks: - name: config copy: src=/root/config.txt dest=/etc/nginx/nginx.conf notify: - Restart Nginx - Check Nginx Process 多个notify的写法 handlers: - name: Restart Nginx 对应写多个handlers service: name=nginx state=restarted enabled=yes - name: Check Nginx process shell: killall -0 nginx &gt; /tmp/nginx.log tags的用法：作用：挑选某一段的task来执行将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行 然后执行：ansible-plsybook -t ceshi install_memcached.yml 只会触发拷贝文件和handlers的动作 --- #test yaml file - hosts: all remote_user: root tasks: - name: creat user user: name=memcached shell=/sbin/nologin uid=2345 - name: install package yum: name=memcached - name: copy config copy: src=/data/memcached dest=/etc/sysconfig/memcached notify: restart service 和handlers名称一致 tags: ceshi 对拷贝动作加一个标签 - name: service service: name=memcached state=started enabled=yes handlers: - name: restart service 和notify名称一致 service: name=memcached state=restarted Playbook中变量使用:可以多出定义，但是存在优先级优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1 ansible setup facts 远程主机的所有变量都可直接调用 setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的 代码块，然后用代码块当变量 比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的 ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的 2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量 3 通过命令行指定变量，优先级最高 可以对单个变量赋值：ansible-playbook –e varname=value 也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot; 4 在playbook中定义 vars: - var1: value1 - var2: value2 5 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件 很适合在roles中进行单独定义 6 在role中定义（下文中有介绍） 从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作 ansible_fqdn 主机名的变量 ansible_hostname 主机名 ansible_distribution_major_version: “6” 版本名变量 ansible_processor_vcpus 虚拟cpu个数变量 ansible_memtotal_mb 内存的变量 示例： ansible all -m setup -a “filter=ansible_memtotal_mb” 用此命令来查看系统内变量的值 调用不同变量来源的示例：得出变量的优先级顺序示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml - hosts: all remote_user: root tasks: - name: touch file file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量 /etc/ansible/hosts：中定义的变量： [websrvs] 192.168.34.105 port1=80 192.168.34.106 port1=90 -普通变量 [websrvs:vars] -公共组变量 mark=&quot;-&quot; [appsrvs] 192.168.34.101 port1=100 [appsrvs:vars] mark=&quot;=&quot; vars.yml中书写格式： - hosts: all remote_user: root tasks: - name: touch file file: name=/data/app{{mark}}{{ port1 }}.log state=touch 最后生成的文件为： app=100.log，app-80.logapp-90.log 示例3：在示例1的基础上，再通过命令行中定义变量: 在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果： ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml 可以看出，最后新建的文件名为hahaha.log 示例4：在playbook中定义变量 - hosts: all remote_user: root vars: - port1: 200 - mark: +++ tasks: - name: touch file file: name=/data/app{{mark}}{{ port1 }}.log state=touch 生成的文件： app+++200.log 示例5：先写在var.yml中定义变量， 1.先准备cat vars.yml:文件内容格式 var1: httpd var2: nginx 2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义 - hosts: web remote_user: root vars_files: - vars.yml tasks: - name: create httpd log file: name=/app/{{ var1 }}.log state=touch - name: create nginx log file: name=/app/{{ var2 }}.log state=touch 模板templates，作用：文本文件，嵌套有脚本（使用模板编程语言编写） Jinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1, item2, ...] 元组：(item1, item2, ...) 字典：{key1:value1, key2:value2, ...} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;= 逻辑运算：and, or, not 流表达式：For If When templates功能：根据模块文件动态生成对应的配置文件 templates文件必须存放于templates目录下，且命名为 .j2 结尾 yaml/yml 文件需和templates目录平级，目录结构如下： ./ ├── temnginx.yml └── templates └── nginx.conf.j2 示例1：通过templates模板nginx1.先生成nginx.conf.j2模板 cp /etc/nginx/nginx.conf templates/nginx.conf.j2 2.创建playbook - hosts: all remote_user: root tasks: - name: inastll nginx yum: name=nginx - name: template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: service - name: start service service: name=nginx state=started handlers: - name: service service: name=nginx state=restarted when配合templates实现根据不同版本执行不同的功能条件测试: 如果需要根据变量、facts或此前任务的执行结果来做为某task执行与 否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法 格式 when语句 在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 示例： tasks: - name: &quot;shutdown RedHat flavored systems&quot; command: /sbin/shutdown -h now when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值 示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when步骤：涉及到多个notify对应一个handlers,定义端口变量 1.hosts文件配置：修改了4台主机httpd的端口 [centos6] 192.168.34.105 http_port=86 192.168.34.106 http_port=87 192.168.34.101 http_port=88 [centos7] 192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件 httpd_6.conf.j2 httpd_7.conf.j2 3.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的 Listen {{http_port}} 调用hosts列表中的端口变量 4.plsybook如下： --- - hosts: all remote_user: root tasks: - name: install httpd yum: name=httpd - name: templates 6 template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: restart service when: ansible_distribution_major_version == &quot;6&quot; - name: templates 7 template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf when: ansible_distribution_major_version == &quot;7&quot; notify: restart service - name: service service: name=httpd state=started handlers: - name: restart service service: name=httpd state=restarted 迭代：with_items，类似于shell中的for循环迭代：当有需要重复性执行的任务时，可以使用迭代机制 对迭代项的引用，固定变量名为”item“ 要在task中使用with_items给定要迭代的元素列表 列表格式： 字符串 字典 字典构成一个键值对{key:vavul},如示例3 迭代的示例：示例1：比如创建user1.user2.user3个用户 - hosts: all remote_user: root tasks: - name: touch users user: name={{item}} with_items: - haha1 - haha2 - haha3 示例2：拷贝3个文件，file1 file2 file3 - hosts: all remote_user: root tasks: - name: copy files copy: src=/data/playbook/{{item}} dest=/data/ with_items: - file1 - file2 - file3 迭代嵌套子变量:涉及到多个键值对的表达方式示例3：创建3个组，再创建3个用户，指定加入一一对应的组 - hosts: all remote_user: root tasks: - name: creat groups group: name={{item}} with_items: - group1 - group2 - group3 - name: creat users user: name={{item.name}} group={{item.group}} with_items: - { name: &apos;haha1&apos;, group: &apos;group1&apos; } - { name: &apos;haha2&apos;, group: &apos;group2&apos; } - { name: &apos;haha3&apos;, group: &apos;group3&apos; } 备注：注意创建用户时，键值对的表达和使用方法 上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3; Playbook中template结合for循环生成具有重复性的代码段语法: for的写法： {% for vhost in nginx_vhosts %} server { listen {{ vhost.listen | default('80 default_server') }} ### Playbook中template结合for循环生成具有重复性的代码段 if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用 如果没定义，则不执行接下来的代码：示例2 {% if vhost.server_name is defined %} server_name {{ vhost.server_name }}; {% endif %} {% if vhost.root is defined %} root {{ vhost.root }}; {% endif %} ### for和if的示例，帮助理解其要执行语句的含义 示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成 先创建for.j2文件： {% for i in ports %} server{ listen {{i.listen}} name {{i.name}} root {{i.root}} } {% endfor %} 创建playbook:再其中调用for.j2文件 - hosts: all remote_user: root vars: ports: - web1: listen: 81 name: www.baidu.com root: /data/web1 - web2: listen: 82 name: www.baidu1.com root: /data/web2 tasks: - name: test for template: src=for.j2 dest=/data/for1.conf 效果为： server{ listen 81 name www.baidu.com root /data/web1 } server{ listen 82 name www.baidu1.com root /data/web2 } 示例2：template配合if的涵义： 在示例1中的playbook中，把name注释掉，即不定义name的值 - web1: listen: 81 # name: www.baidu.com root: /data/web1 然后playbook:再调用for.j2文件 {% for i in ports %} server{ listen {{i.listen}} {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用 name {{i.name}} {% endif %} root {{i.root}} } {% endfor %} 结果：则web1没有name的值，即可以理解if的用法 server{ listen 81 root /data/web1 少了web1的name的值 } server{ listen 82 name www.baidu1.com root /data/web2 } Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？ansible重要内容之Roles；playbook的集合和拆分 ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles 能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需 要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、 文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一 种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程 等场景中 复杂场景：建议使用roles，代码复用度高 变更指定主机或主机组 如命名不规范维护和传承成本大 某些功能需多个Playbook，通过Includes即可实现 roles的意义和适用场景：角色(roles)：角色集合 适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把 同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了， 当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。 如系统内会存在如下的各类服务，可以先编排好角色 roles/ ├── httpd/ ├── memcached/ ├── mysql/ └── nginx/ roles的目录结构（一般分成以下目录进行存放一类的文件）Roles各目录作用： /roles/project/ :项目名称,有以下子目录 如创建http，memcached，nginx等目录 files/ ：存放由copy或script模块等调用的文件 保存需要拷贝的配置文件 templates/：template模块查找所需要模板文件的目录 保存通过template的jinja2模板调用的配置文件 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此 文件中通过include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要 在此文件中通过include进行包含，可以单独定义变量的目录 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为 main.yml的文件，其它文件需在此文件中通过include进行包含 tasks目录下，组合任务顺序的文件 default/：设定默认变量时使用此目录中的main.yml文件 roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.- hosts: all remote_user: root roles: - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]} - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]} - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]} playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量方法一：把需要调用的角色写在一个playbook里 - hosts: all remote_user: root roles: - role: httpd - role: memcached - role: nginx 弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活 方法二；可以把变量在角色中定义 传递变量给角色 - hosts: remote_user: roles: - mysql - { role: nginx, username: nginx } 键role用于指定角色名称 后续的k/v用于传递变量给角色 调用角色方法3：还可基于条件测试实现角色调用 方法三：还可基于条件测试实现角色调用 roles: - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ } roles示例：以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.ymlroles的目录结构下的httpd&amp;nginxmemcachedroles ├── httpd │ ├── files │ │ ├── index_6.html │ │ └── index_7.html │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ ├── copyhtml_6.yml │ │ ├── copyhtml_7.yml │ │ ├── group.yml │ │ ├── main.yml │ │ ├── package.yml │ │ ├── service.yml │ │ ├── tempconfig_6.yml │ │ ├── tempconfig_7.yml │ │ └── user.yml │ ├── templates │ │ ├── httpd_6.conf.j2 │ │ └── httpd_7.conf.j2 │ └── vars ├── memcached │ ├── files │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ ├── group.yml │ │ ├── main.yml │ │ ├── package.yml │ │ ├── service.yml │ │ ├── tempconfig.yml │ │ └── user.yml │ ├── templates │ │ └── memcached.j2 │ └── vars └── nginx ├── files │ ├── index_6.html │ └── index_7.html ├── handlers │ └── main.yml ├── tasks │ ├── copyhtml_6.yml │ ├── copyhtml_7.yml │ ├── group.yml │ ├── main.yml │ ├── package.yml │ ├── service.yml │ ├── tempconfig.yml │ └── user.yml ├── templates │ └── nginx.conf.j2 └── vars └── main.yml 调用角色的playbook:roles.yml可以通过加变量和标签和条件测试调用更灵活的调用各种角色) vim /data/roles.yml - hosts: all remote_user: root roles: - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“} - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]} - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]} 比如： 1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法 2.ansible-playbook -t httpd roles.yml 只选择安装httpd 3.ansible-playbook -t nginx roles.yml 只选择安装nginx 4.ansible-playbook -t web roles.yml 安装httpd和memcached 5.ansible-playbook -t web1 roles.yml 只选择安装nginx 下图为每个role的各个文件内容：图一：参照roles的httpd的目录各个文件内容 图二：参照roles的nginx的目录各个文件内容 涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有 跨角色调用配置文件写法： - name: copy index6 copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html 图三：参照roles的memcached的目录各个文件内容]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>ansible,运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP三次握手、四次断开与十一种状态]]></title>
    <url>%2F2017%2F10%2F18%2FTCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E3%80%81%E5%9B%9B%E6%AC%A1%E6%96%AD%E5%BC%80%E4%B8%8E%E5%8D%81%E4%B8%80%E7%A7%8D%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[TCP三次握手、四次断开与十一种状态OSI模型由下到上分别为物理层、数据链路层、网络层、传输层、会话层、表示层、应用层 1：第七层：应用层的功能： 为应用软件提供接口，使应用程序能够使用网络服务。常见的应用层协议： http(80)、ftp(20/21)、smtp(25)、pop3(110)、telnet(23)、dns(53)等 2：第六层：表示层的功能： 数据的编码和解码、数据的加密和解密、数据和压缩和解压缩，常见的标准有JPEG/ASCII等 3：第五层：会话层的功能： 建立、管理和终止表示层实体之间的会话连接，在设各或节点之间提供会话控制，它在系统之间协调通信过程,并提供3种 不同的方式来组织它们之间的通信:单工、半双工和全双工 4：第四层：传输层的功能： 负责建立端到端的连接，保证报文在端到端之间的传输。提供可靠TCP及不可靠UDP的传输机制,服务点编址、分段与重组 、连接控制、流量控制、差错控制。 5：第三层：网络层的功能： 定义逻辑地址,逻辑寻址，将数据分组从源传输到目的,路径选择、路由发现、维护路由表，功能是隔离广播域；隔离广播 ,路由选择；维护路由表,寻址及转发,流量管理并连接广域网 6：第二层：数据链路层的功能： 组帧、物理编址，将数据帧从链路上的一个节点传递到另一个节点，流量控制、差错控制、接入控制 7：第一层：物理层的功能： 在介质上传递比特流，定义接口和媒体的物理特性，定义比特的表示、数据传输速率、信号的传输模式（单工、半双工、全 双工），定义网络物理拓扑（网状、星型、环型、总线型等） TCP协议简介：TCP，全称Transfer Control Protocol，中文名为传输控制协议，它工作在OSI的传输层，提供面向连接的可靠传输服务，TCP的工作主要是建立连接，然后从应用层程序中接收数据并进行传输。TCP采用虚电路连接方式进行工作，在发送数据前它需要在发送方和接收方建立一个连接，数据在发送出去后，发送方会等待接收方给出一个确认性的应答，否则发送方将认为此数据丢失，并重新发送此数据。TCP的报文头部结构：-TCP的报文头部结构 TCP三次握手：在建立连接的时候，所谓的客户端与服务端是相对应的，即要看是谁主动连接的谁，如果A主动连接B那么A就是客户端 而B是服务端，如果返过来B主动连接A，那么B就是客户端而A就成了服务端。 1:连接过程： 第一次握手：客户端发送SYN标志位为1的请求到服务端，并随机生成一个seq 序列号x，其中seq是随机产生的数据包的序列号。 第二次握手：服务器收到客户端请求并返回SYN=1，ACK=1，seq=y，ack=x+1，其中ACK=1表示是响应报文，seq=y是 服务器随机产生的数据包序列号，ack=x+1是确认客户端序列号有效并返回给客户端确认。 第三次握手：客户端收到服务器的确认ack=x+1有效的验证信息，即在自己发送的序列号基础之上加了1表示服务器收到 并返回，表示第二次连接有效，然后客户端恢回复ACK=1，seq=x+1，ack=y+1，这是讲服务器发来+1后的序列号当做自 己的seq序列号，确认号ack使用服务器的随机号y再加1即ack=y+1，这样客户端就完成了第三次的验证在讲数据包发给 服务器，服务器收到后验证确认号是在自己的seq之上加了1，表示没有问题就开始传输数据。 注： ACK :TCP协议规定，只有ACK=1时有效，也规定连接建立后所有发送的报文的ACK必须为1 Seq:序号,4字节，范围为0^32—1^32,共4284967296，达到时重新开始计算 在第三次的时候SYN等于0，因为SYN(SYNchronization) 只i在连接建立时用来同步序号,当SYN=1而ACK=0时,表明这 是一个连接请求报文,对方若同意建立连接,则应在响应报文中使SYN=1和ACK=1. 因此, SYN置1就表示这是一个连接请求或连接接受报文，链路建立成功之后就将标志位置为0。 SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急) Sequence number(顺序号码) Acknowledge number(确认号码) -TCP三次握手 TCP的四次断开：TCP断开要四次是因为TCP传输数全双工的，即数据是在同一时间内两条数据链路双向互相传输的，因此每个方向都要单 独关闭一次，断开需要客户端到服务端断开一次，而服务端到客户端也需要断开一次，这样的断开才是完整的断开， 第一次断开：客户方发给服务器一个FIN为1的请求，FIN为1表示是一个断开连接的请求，即表示数据传输完毕请求断开 ，并发送seq序列号和Ack确认号。 第二次断开：服务器收到客户端请求并返回ACK标志位为1，Ack为Seq+1等于201，并将对方的Ack作为自己的Seq序列号 的确认数据包，biao 接收到请求同意断开。 第三次断开：服务器发送ACK=1，FIN=1，Seq等于客户端第一次请求断开的Ack确认号+1，即Seq等于501的断开请求给客户端。 第四次断开：客户端发送ACK=1，Ack在上一步Seq上+1等于502，并使用在第二次断开中服务器发送的Ack确号201作为 本次的序列号发给服务器表示同意断开，服务器收到后验证序列号是第二次的，验证Ack是第三次+1的，确认没有问题后 同意断开，然后将端口置为TIME_WAIT状态，等待2 MSL时间后置为关闭状态，被动方收到主动方的报文确认Ack确认号没有问题后将端口置为CLOSED，至此端口g。 SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急) Sequence number(顺序号码) Acknowledge number(确认号码) 四次断开的图形示意如下： -TCP四次挥手 TCP端口的十一种连接状态：TCP端口一共有十一种状态，CLOSE_WAIT表示是程序y关闭连接，而TIME_WAIT只占用一个socket连接，到时间之后会 释放，因此大量的CLOSE_WAIT是比大量的TIME_WAIT影响更大，另外还有FIN_WAIT1和FIN_WAIT2，如果有 FIN_WAIT2也表示服务有问题，以下是每个端口状态的含义： 1：CLOSED：端口默认是关闭状态。 2：LISTEN： 服务器程序开始监听一个端口，就是LISTEN状态。 3：SYN_RCVD：三次握手的第二次握手后的端口状态，是收到了客户端发送的SYN_SENT数据包之后的状态，这个状态很 短暂，正常在服务器上是很少看到的，除非服务器故意不发送最后一次握手数据包，服务器返回给客户端SYN确认之后就 会将在自己的端口置为SYN_RCVD。 4：SYN_SENT：SYN_SENT状态表示客户端已发送SYN=1的请求连接报文，发送之后客户端就会将自己的端口状态置为SYN_SENT。 5：ESTABLISHED：表示已经连接成功，客户端收到服务器的确认报文会回复服务器，然后就将端口置为ESTABLISHED， 服务器第三次收到客户端的Ack确认就会将端口置为ESTABLISHED并开始传输数据。 6：FIN_WAIT_1：出现在主动关闭方，FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，当任意一方想主动 关闭连接，向对方发送了FIN=1的断开连接请求报文，此时该SOCKET即 进入到FIN_WAIT_1状态。而当对方回应ACK报文 后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马 上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。 7：FIN_WAIT_2：出现在主动关闭方，当被动方回应FIN_WAIT_1的ACK报文后，则进入到FIN_WAIT_2状态 8：TIME_WAIT：出现在主动关闭方，表示收到了对方的FIN请求关闭报文，并发送出了ACK报文，就等2MSL后即可回到 CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到 TIME_WAIT状态，而无须经过FIN_WAIT_2状态。 9：CLOSING： 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送 FIN报文后，按理来说是应该先收到（或同时收到）对方的 ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你 发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什 么情况下会出现此种情况呢？其实细 想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报 文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。 10：CLOSE_WAIT： 表示在等待关闭端口，这种状态存在于被动关闭的一方。 11：LAST_ACK： 是被动关闭方在主动关闭一方在发送FIN报文后，最后等待对方的ACK报文，当再次收到ACK报文后，也即可以进入到CLOSED可用状态了。 12：区分主动断开和被动端口方的端口状态： 主动端口方：SYN_SENT、FIN_WAIT1、FIN_WAIT2、CLOSING、TIME_WAIT 。 被动断开方：LISTEN、SYN_RCVD、CLOSE_WAIT、LAST_ACK 。 都具有的：CLOSED 、ESTABLISHED 。 -TCP的11种状态 关于优化：socket就是一个TCP连接，包括源地址、源端口、目标地址、目标端口和协议(TCP|UDP),0端口是保留不能使用的， 因此服务器的最大端口使用数量为63353个，最大65536个端口是因为TCP报文头部有个端口长度为2^16次方等于 65536，查看当前打开的端口范围# cat /proc/sys/net/ipv4/ip_local_port_range，单个IP地址能接受的最大并 发为六万多，1万个TIME_WAIT大约使用1MB的内存CPU占用更小，因此资源使用很小可以忽略不计，但是会占用一个 socket，可以通过在负载上配置多个公网IP地址以提高高并发的问题， [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_recycle 0 #用于快速回收处于TIME_WAIT状态的socket以便重新分，在负载服务器不能打开，会导致通过nat上网的后续用户 无法打开网页，因为后面的访问用户时间戳小于前面的用户，会导致数据包被负载服务器丢弃，可以在内网使用，但是通常建议关闭。 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_reuse 0 #kernel会复用处于TIME_WAIT状态的socket，即允许将TIME_WAIT状态得socket用于直接新的TCP连接，负载服务器建议打开 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_timestamps 1 #记录数据包的时间戳，判断是新的数据包还是旧的，如果是旧的就丢弃，配合上面两个选项的时候一定要打开才生效。]]></content>
      <categories>
        <category>TCP协议</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建内网yum源]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%90%AD%E5%BB%BA%E5%86%85%E7%BD%91yum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[创建文章的默认模板，可根据实际情况修改 Till I reach the end, then I’ll start again《Try Everything》 1 // 插入音乐 或者 // 表示图片在左边或者右边，中间(left，right，center) // markdown格式测试，就是要测试一下啊啊啊啊a 文本上带一条横线，表示错误 This is an H1 Red Green Blue This is a blockquoteinside a list item. http://example.com/ This is an H2// 插入图片并设置大小两种方法 // 颜色选择 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下双网卡绑定及Bridge]]></title>
    <url>%2F2017%2F10%2F18%2FLinux%E4%B8%8B%E5%8F%8C%E7%BD%91%E5%8D%A1%E7%BB%91%E5%AE%9A%E5%8F%8ABridge%2F</url>
    <content type="text"><![CDATA[Linux的双网卡绑定及Bridge一：linux操作系统下双网卡绑定有七种模式。现在一般的企业都会使用双网卡接入，这样既能添加网络带宽，同时又能做相应的冗余，可以说是好处多多。而一般企业都会使用linux操作系统下自带的网卡绑定模式，当然现在网卡产商也会出一些针对windows操作系统网卡管理软件来做网卡绑定，一共有其中方式，其中比较长用的是0/1/6：二：windows操作系统没有网卡绑定功能需要第三方支持：DELLr720一般都是博科的网卡，Inter网卡，随机光盘和网上 有很多双网卡绑定的软件. 1：网卡绑定案例，先做绑定，然后再把绑定后的网卡配置成桥接： 1.1：第一组配置，将eth1和eth5绑定为bond0： 1.1.1：先创建bond0配置那文件步骤及内容如下： [root@linux-host1 ~]# cd /etc/sysconfig/network-scripts/ [root@linux-host1 network-scripts]# cp ifcfg-eth0 ifcfg-bond0 [root@linux-host1 network-scripts]# cat ifcfg-bond0 #内容如下： BOOTPROTO=static NAME=bond0 DEVICE=bond0 ONBOOT=yes BONDING_MASTER=yes BONDING_OPTS=&quot;mode=1 miimon=100&quot; #指定绑定类型为1及链路状态监测间隔时间 BRIDGE=br0 #桥接到br0 1.1.2：配置br0： TYPE=Bridge BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=br0 DEVICE=br0 ONBOOT=yes IPADDR=X.X.X.X NETMASK=255.255.255.0 GATEWAY=X.X.X.X 1.1.3：eth1配置： [root@linux-host1 network-scripts]# vim ifcfg-eth1 BOOTPROTO=static NAME=eth1 DEVICE=eth1 ONBOOT=yes NM_CONTROLLED=no MASTER=bond0 USERCTL=no SLAVE=yes 1.1.4：eth5的配置： [root@linux-host1 network-scripts]# cp ifcfg-eth1 ifcfg-eth5 [root@linux-host1 network-scripts]# vim ifcfg-eth5 BOOTPROTO=static NAME=eth5 DEVICE=eth5 ONBOOT=yes NM_CONTROLLED=no MASTER=bond0 USERCTL=no SLAVE=yes 1.1.5：重启网络服务： [root@linux-host1 network-scripts]# systemctl restart network 1.1.6：验证网络是否正常： [root@linux-host1 network-scripts]# ping www.baidu.com PING www.a.shifen.com (61.135.169.125) 56(84) bytes of data. 64 bytes from 61.135.169.125: icmp_seq=1 ttl=128 time=6.17 ms 64 bytes from 61.135.169.125: icmp_seq=2 ttl=128 time=10.3 ms 64 bytes from 61.135.169.125: icmp_seq=3 ttl=128 time=5.36 ms 64 bytes from 61.135.169.125: icmp_seq=4 ttl=128 time=6.74 ms 64 bytes from 61.135.169.125: icmp_seq=5 ttl=128 time=5.71 ms 1.1.:6：可以验证当前是绑定在哪一块网卡上的： [root@linux-host1 ~]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011) Bonding Mode: fault-tolerance (active-backup) Primary Slave: None Currently Active Slave: eth1 #备份链路网卡 MII Status: up MII Polling Interval (ms): 100 Up Delay (ms): 0 Down Delay (ms): 0 Slave Interface: eth1 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 18:66:da:f3:34:e5 Slave queue ID: 0 Slave Interface: eth5 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0a:f7:99:ba:d1 Slave queue ID: 0 1.2：第二组配置，将eth2和eth6绑定为bond1： 1.2.1：创建bond1配置文件： [root@linux-host1 network-scripts]# cp ifcfg-bond0 ifcfg-bond1 [root@linux-host1 network-scripts]# vim ifcfg-bond1 BOOTPROTO=static NAME=bond1 DEVICE=bond1 TYPE=Bond BONDING_MASTER=yes BOOTPROTO=static NAME=bond1 ONBOOT=yes BONDING_OPTS=&quot;mode=1 miimon=100&quot; BRIDGE=br1 1.2.2：配置br1： TYPE=Bridge BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=br1 DEVICE=br1 ONBOOT=yes IPADDR=X.X.X.X NETMASK=255.255.255.0 GATEWAY=X.X.X.X DNS1=X.X.X.X 1.2.3：eth2的配置： [root@linux-host1 network-scripts]# vim ifcfg-eth2 BOOTPROTO=static NAME=eth2 DEVICE=eth2 ONBOOT=yes NM_CONTROLLED=no MASTER=bond1 USERCTL=no SLAVE=yes 1.2.4：eth6的配置： [root@linux-host1 network-scripts]# vim ifcfg-eth6 BOOTPROTO=static NAME=eth6 DEVICE=eth6 ONBOOT=yes NM_CONTROLLED=no MASTER=bond1 USERCTL=no SLAVE=yes 1.2.5：重启网络服务： [root@linux-host1 network-scripts]# systemctl restart network 1.2.6：测试内网网络是否正常： [root@linux-host1 network-scripts]# ping 192.168.20.12 PING 192.168.20.12 (192.168.20.12) 56(84) bytes of data. 64 bytes from 192.168.20.12: icmp_seq=1 ttl=64 time=1.86 ms 64 bytes from 192.168.20.12: icmp_seq=2 ttl=64 time=0.570 ms 64 bytes from 192.168.20.12: icmp_seq=3 ttl=64 time=0.410 ms 1.3：设置开机启动： [root@linux-host1 network-scripts]# vim /etc/rc.d/rc.local ifenslave eth1 eth5 ifenslave eth2 eth6 [root@linux-host1 network-scripts]# chmod a+x /etc/rc.d/rc.local 1.4：重启系统后验证网络]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpd]]></title>
    <url>%2F2017%2F10%2F18%2Fhttpd%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. 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]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之awk]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk%2F</url>
    <content type="text"><![CDATA[文本处理三剑客之awk Awk的用户使用指南awk用户指南 相关链接文章：正则表达式： 正则表达式grep文本编辑： grep用法sed文本编辑： sed用法 总结对比一下这三个剑客的特长之处grep、sed、awk被称为linux中的三剑客 grep更适合单纯的查找或匹配文件.sed更适合编辑皮匹配到的文本awk更适合格式化文本，对文本进行比较复杂格式处理 文本三剑客都是默认逐行处理，自带循环sed 可以对文本进行修改，而grep&amp;awk 只是对文本进行过滤,不进行内容修改 awk中的-F后面的分隔符,要用单引号’’,双引号””会产生弱引用,比如特殊符号’\\‘ ‘\\$’关于awk中的单引号和双引号的问题参照：awk中的输入分隔符单引号&amp;双引号 学习awk的一个重要知识点 先举两个例子： awk &apos;/^UUID/&apos; /etc/fstab = awk &apos;/^UUID/{print $0}&apos; /etc/fstab 其实是隐藏了{print $0}的写法 数组中的例子 awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6 实际上是隐藏了{print $0} 学习中遇到的混淆的问题：&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印 而后面的数组里的是加了双括号{}，即用的patter的空模式，即文本中的每一行都处理 Awk基本用法和功能以及各个功能示例：awk介绍awk基本用法awk变量awk格式化-printfawk操作符awk条件判断awk循环awk数组awk函数调用系统命令 awk介绍：whatis awk？ awk：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出，输出成报表格式 linux上默认使用 GNU awk(gawk) [root@centos7 data]which awk /usr/bin/awk [root@centos7 data]ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Sep 19 11:45 /usr/bin/awk -&gt; gawk which awk=/usr/bin/awk 是gawk的软链接 awk基本用法awk [options] &apos;program&apos; var=value file… awk [options] -f programfile var=value file… awk [options] &apos;BEGIN{action;… }pattern{action;… }END{action;… }&apos; file ... awk 程序可由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句 块，共3部分组成 program 通常是被放在单引号中 选项： -F “分隔符” 指明输入时用到的字段分隔符 -v var=value 变量赋值 基本格式：awk [options] &apos;program&apos; file… Program：pattern{action statements;..} 也就是说awk用法：awk [options] &apos;pattern{action statements;..}&apos; file… pattern和action • pattern部分决定动作语句何时触发及触发事件 BEGIN,END • action statements对数据进行处理，放在{}内指明 print, printf 分割符、域和记录 • awk执行时，由分隔符分隔的字段（域）标记$1,$2...$n称为域标识。$0 为所有域，注意：此时和shell中变量$符含义不同 • 文件的每一行称为记录 • 省略action，则默认执行 print $0 的操作 print格式：print item1, item2, ... 要点： (1) 逗号分隔符 (2) 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式 (3) 如省略item，相当于print $0 用法解析及示例：$0=代表处理的整行的内容 $1,$2,$3..代表每一列，也就域 BEGIN，END是为生成一个报表的头和尾准备的，用法通常为： BEGIN：为生成报告模式 添加表头;END:为生成的报告 进行信息汇总 awk &apos;BEGIN{print xxx}{print xxx}END{print xxx}&apos; 注意：BEGIN{print *xxx}处理文本前，打印一遍xxx的内容当成表头 END{print xxx},处理文本后，打印一遍xxx的内容作为表尾 BEGIN&amp;ENDBEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。 END：让用户在最后一条输入记录被读取之后发生的动作。 分隔符：awk默认使用空白符作为字段或列的分隔符；多个空白符被认为是一个，空白符包括空格，tab键/t，回车\n 也可以自定义-F&quot;分隔符&quot;自定义分隔符 print&amp;printf的区别：print命令只是单纯的把特定的内容进行打印，默认换行 printf命令可以把内容以灵活的格式进行显示,如左对齐,右对齐 示例1.awk支持标准输入输出，后面可以不跟文件 [root@centos7 ~]#awk &apos;{print $0}&apos; aaaa aaaa abcabc abcabc 2.打印/etc/passwd：对比几个输出结果 awk &apos;{print $0}&apos; /etc/passwd 把passwd文件全部打印出来 awk &apos;{print &quot;abc&quot;}&apos; /etc/passwd 读入的是passwd文件所有行，打印的是abc awk -v abc=1 &apos;{print abc}&apos; /etc/passwd 读入的是passwd文件所有行，打印的都是1 awk &apos;{print &quot;abc&quot;$0}&apos; /etc/passwd 把passwd文件所有行前都加一个abc,进行输出 所以在awk中不加双引号，abc被识别为变量，如果要引用变量，需要-v先定义值 如果只是想输出abc字符串，需要加双引号 3.awk{}中支持数字运算 awk &apos;{print 1+2}&apos; /etc/passwd 打印多行1+2=3的值 awk &apos;{print &quot;1+2&quot;}&apos; /etc/passwd 加双引号会把1+2当成字符串，输出多行1+2 4.取分区利用率df, df |awk &apos;{print $1,$5}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos; 5.以输入重定向方式，打印 passwd 文件的第1列，即获取当前系统中存在的所有用户和UID awk -F: &apos;{print $1,$3}&apos; &lt; /etc/passwd cat /etc/passwd | awk -F: &apos;{print $1,$3}&apos; awk -F: &apos;{print $1：$3}&apos; /etc/passwd 两列输出时，指定以：进行隔开，默认为空格隔开 awk -F: &apos;{print $1、$3}&apos; /etc/passwd 两列输出时，指定以：进行隔开，默认为空格隔开 cat /etc/passwd | awk -F: &apos;{print $1&quot;\n&quot; $3}&apos; 两列输出时,进行换行 cat /etc/passwd | awk -F: &apos;{print $1&quot;\t&quot; $3}&apos; 两列输出时,以tab键隔开 备注：多行输出时，可以在双引号之间加自定义的分隔符 格式：awk -F: &apos;{print $1&quot;=======&quot;$3}&apos; /etc/passwd Awk中的变量：变量分为：内置变量和自定义变量awk中的内置变量除了$0,$1,$2等，还有以下几种； 如果要使用这些变量需要加-v 选项先进行定义 FS：输入字段分隔符，默认为空白字符 =filed separator=域或列的分隔符 等于-F的选项，-F是选项，而FS是变量，实际作用是相等的 与-F的区别在于：可以下次调用FS变量 awk -v FS=&apos;:&apos; &apos;{print $1,$3}&apos; /etc/passwd = awk -F:&apos;{print $1,$3}&apos; /etc/passwd awk -v FS=&apos;:&apos; &apos;{print $1,FS$3}&apos; /etc/passwd 两列输出时以：做分隔符，调用变量FS awk -v FS=&apos;:&apos; &apos;{print $1,FS FS$3}&apos; /etc/passwd 两列输出时以：：做分隔符，调用2次变量FS 以空格隔开 可以先定义shell中的变量fs=:,awk再进行调用 fs=:;awk -v FS=$fs &apos;{print $1,FS,$3}&apos; /etc/passwd fs=:;awk –F$fs &apos;{print $1,$3,$7}&apos; /etc/passwd OFS：输出字段分隔符，默认为空白字符 =output filed separator 定义输出分隔符，不指定默认空空格做分隔符 awk -v FS=: -v OFS=+++ &apos;{print $1,$3,$7}&apos; /etc/passwd fs=+++;awk -v FS=: -v OFS=$fs &apos;{print $1,$3}&apos; /etc/passwd 调用shell变量做输出分隔符 RS：输入记录分隔符，指定输入时的换行符,自定义行的分隔符 =record记录 默认一行叫记录，行是以\n回车作为切割符的，RS可以自定义不用回车作为分隔符 awk -v RS=&apos; &apos; ‘{print }’ /etc/passwd awk -v RS=&apos;:&apos; &apos;{print NR,$0}&apos;/etc/passwd [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print $0}&apos; aa;xxx bb;bzzzz cc dd eex;zccc xxxx 以RS=：冒号自定义行的分隔符，输出结果如上 [root@centos7 ~]#cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; &apos;{print $1}&apos; aa bb cc dd eex xxxx 自定义FS&amp;RS，输出结果如上 ORS：输出记录分隔符，输出时用指定符号代替换行符 awk -v RS=&apos; &apos; -v ORS=&apos;###&apos;‘{print }’ /etc/passwd [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; -v ORS&quot;===&quot; &apos;{print $1}&apos; aa==bb==cc dd==eex==xxxx == 自定义FS,RS,ORS结果很明显 接下来是一个比较重要的变量 NF：字段数量,也就是域或列的总数量 awk -F: &apos;{print NF}&apos; /etc/passwd 以冒号做分隔符，显示每行的列的总数量 awk -F: &apos;{print $NF}&apos; /etc/passwd 显示以冒号做分隔符，每一行的最后一个字段即bash类型 awk -F：&apos;{print $(NF-1)}&apos; /etc/passwd 显示以冒号做分隔符，每一行的倒数第二个字段 统计光盘中所有安装包适用的cpu架构类型 root@centos7 mnt]#ls /mnt/Packages/*.rpm | awk -F&quot;.&quot; &apos;{print $(NF-1)}&apos;|sort|uniq -c 1371 noarch 2600 x86_64 NR：记录号，可以显示行数，如果有多个文件会合并后再统计总行 awk &apos;{print NR,$0}&apos; /etc/fstab 在每一行前加一个行号 awk BEGIN&apos;{print NR}&apos; /etc/fstab 输出结果为0 awk还没开始处理行，所以记录为0 awk END&apos;{print NR}&apos; /etc/fstab 输出结果为12 可以看出END是统计,awk处理的行数 1.通过加行号，可以很明显看出以冒号作为行的分隔符，每一行的都有什么；可以看出cc dd是一行的 [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print NR$0}&apos; 1aa;xxx 2bb;bzzzz 3cc dd 4eex;zccc 5xxxx 2.备注：如果awk跟两个文件，awk会把两文件合并成一个文件，统计总行数，都取第一个字段的信息 如果需要分开显示统计，则用FNR [root@centos7 ~]awk -F: &apos;{print NR,$1}&apos; /etc/passwd /etc/group 1 root 2 bin 3 daemon 4 adm FNR：各文件分别计数,记录号 1.FNR:多个文件，每个分别统计显示第一个字段并列出来 awk &apos;{print FNR}&apos; /etc/fstab /etc/inittab [root@centos7 ~]awk -F: &apos;{print FNR,$1}&apos; /etc/passwd /etc/group 1 root 2 bin 3 daemon 48 quagga 49 httpd 1 root 2 bin FILENAME：当前文件名 1.统计时，加上变量可以显示文件名 awk &apos;{print FILENAME}&apos; /etc/fstab [root@centos7 ~]awk -F: &apos;{print FILENAME,FNR,$1}&apos; /etc/passwd /etc/passwd 1 root /etc/passwd 2 bin /etc/passwd 3 daemon ARGC：命令行参数的个数 awk &apos;{print ARGC}&apos; /etc/fstab /etc/inittab 结果为3 awk &apos;BEGIN {print ARGC}&apos; /etc/fstab /etc/inittab 结果为3 ARGC统计参数：awk单独算一个参数，后面的每个文件算一个参数,通过下面的数组可以体现出来 ARGV：数组，保存的是命令行所给定的各参数 1.显示awk的每个参数分别是哪个 [root@centos7 ~]awk &apos;{print ARGV[0]}&apos; /etc/fstab /etc/inittab awk [root@centos7 ~]awk &apos;{print ARGV[1]}&apos; /etc/fstab /etc/inittab /etc/fstab 示例：1.统计当前网络连接情况的ip地址是 ss -nt ss -nt | awk &apos;{print $5}&apos; 2.取/var/log/httpd/access_log的时间如下： root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; 分两步取： cat /var/log/httpd/access_log | awk &apos;{print $4}&apos;|awk -F&quot;[&quot; &apos;{print $2}&apos; 一步取： cat /var/log/httpd/access_log | awk -F &quot;[\[ ]&quot; &apos;{print $5}&apos; 原理分析：[\[ ]代表（转义）\[和空格都算是分隔符，正则表达式的写法,或的关系， 而以空格分隔符，时间段为$4,那为什么是$5?在空格的标准里，[算$4,所以时间段为$5 3.取出磁盘分区利用率 -这次只取出利用率 两步取出： df | awk -F% &apos;{print $1}&apos;|awk &apos;{print $5}&apos; 一步取出： df | awk -F&quot;[[:space:]]+|%&quot; &apos;{print $5}&apos; awk用的是扩展的正则表达式 面试题：3-1,取出fstab中挂载的目录 [root@centos7 ~]cat /etc/fstab # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data xfs defaults 0 0 UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap swap defaults 0 0 [root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos; boot data swap 或者 [root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos; boot data swap 4.面试题：将文件f3中的第一个点前的字符串取出再写进去 [root@centos7 ~]cat f3 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4.news.sina.com.cn [root@centos7 ~]cat f3 | awk -F&quot;[ .]&quot; &apos;{print $2}&apos; &gt;&gt; f3 [root@centos7 ~]cat f3 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4.news.sina.com.cn test music sports news 4-1,扩展 前面-F&quot;[ .]&quot;既然是表达或的意思，那么是否可以这么写-F&quot;[ ]|.&quot;？？？ 答案：不可以！ 原因：因为此处用的是正则表达式，在正则表达式中点(.)代表任意单个字符，会把空格后的字母当成分隔符！ 所以是不可以的，那么如何写？ 如果不是点而是%呢？%是可以的，因为在正则表达式中%就是代表%， 但是$,或其他在正则表达式中有特殊含义的不可以作为分隔符，如果一定要做分隔符，需要反斜线转义 如下： 此处用3个反斜线转义 [root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\.&quot; &apos;{print $2}&apos; test music sports news 那如果文本中的第一个点是$呢？ 此处是4个反斜线进行转义 [root@centos7 ~]cat f2 1 test$sina.com.cn 2 music$sina.com.cn 3 sports$sina.com.cn 4 news$sina.com.cn [root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\\$&quot; &apos;{print $2}&apos; test music sports news [root@centos7 ~]cat f2 | awk -F&quot;[ $]&quot; &apos;{print $2}&apos; test music sports news 当用一个空格和具有特殊含义的符号时，最好是写在中括号[]里的 AWK中自定义变量自定义变量(区分字符大小写) (1) -v var=value (2) 在program中直接定义 (2-1)program可以放到一个文本里,awk -f 直接调用即可 示例：自定义变量可以-v var定义，也可以放到program即{}里，变量要先定义，后使用 awk -F: &apos;{name=&quot;magedu&quot;;print $1,name}&apos; /etc/passwd awk -F: -v name=&quot;magedu&quot; &apos;{print $1,name}&apos; /etc/passwd 例如 cat awk.txt {print $1,$2,$6} awk -F： -f awk.txt /etc/passwd =awk -F: &apos;{print $1,$2,$6}&apos; /etc/passwd Awk中的格式化在介绍printf前，先对其进行总结：1.使用printf动作输出的文本不会换行，如果需要换行，可以在对应的格式替换符后加入”\n”进行转义2.使用printf动作时，指定的格式和被格式化的文本之间，需要用”逗号”隔开。3.使用printf动作时，格式中的格式替换符比喻与被格式化的文本一一对应 printf命令-类似于shell里的printfprintf命令可以把内容以灵活的格式进行显示，如左对齐,右对齐 格式化输出：printf &quot;FORMAT&quot;, item1, item2, ... (1) 必须指定FORMAT (2) 不会自动换行，需要显式给出换行控制符，\n (3) FORMAT中需要分别为后面每个item指定格式符 格式符：与item一一对应 %c：显示字符的ASCII码 %d, %i：显示十进制整数 -用的比较多 %e, %E：显示科学计数法数值 %f：显示为浮点数 %g, %G：以科学计数法或浮点形式显示数值 %s：显示字符串 -用的比较多 %u：无符号整数 -用的比较多 %%：显示%自身 修饰符 #[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f + 左对齐（默认右对齐） %-15s * 显示数值的正负符号 %+d printf示例：1.设置对齐格式以及字符数 [root@centos7 ~]awk -F: &apos;{printf &quot;%-20s %-5d\n&quot;,$1,$3}&apos; /etc/passwd root 0 bin 1 pulse 171 gdm 42 gnome-initial-setup 990 $1为字符串，所以设置左对齐为20s个字符，$3为数字所以设置左对齐为5d个字符 printf默认不换行，所以需要加一个换行符 2.打印一个完整的报表格式 root@centos7 ~]awk -F: &apos;BEGIN{print &quot;username |uid\n--------&quot;} {printf &quot;%-10s |%-5d\n&quot;,$1,$3}END{print &quot;-------------&quot;}&apos; /etc/passwd username |uid ----------------------- root |0 bin |1 daemon |2 memcached |987 ceshi |1009 quagga |92 httpd |80 ------------------------- awk生成报表格式大概就是这个样子，所以awk称为报表生成器 3. [root@centos7 ~]awk -F: &apos;{printf &quot;Username: %s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwd Username: root,UID:0 Username: bin,UID:1 Username: daemon,UID:2 Username: adm,UID:3 4. [root@centos7 ~]awk -F: &apos;{printf &quot;Username: %-15s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwd Username: root ,UID:0 Username: bin ,UID:1 Username: daemon ,UID:2 awk操作符a.算术操作符： x+y, x-y, x*y, x/y, x^y, x%y - x：转换为负数 +x：将字符串转换为数值 字符串操作符：没有符号的操作符，字符串连接 赋值操作符： =, +=, -=, *=, /=, %=, ^=，++, --, b.比较操作符： ==, !=, &gt;, &gt;=, &lt;, &lt;= 模式匹配符： ~：左边是否和右边匹配包含 !~：是否不匹配 c.逻辑操作符：与&amp;&amp;，或||，非! d.条件表达式（三目表达式） selector?if-true-expression:if-false-expression 表达式；if-ture-xx:else-xxx eg:x&gt;y?var=x;var=y 操作符用法示例：1.下面两语句有何不同 • awk &apos;BEGIN{i=0;print ++i,i}&apos; 结果 1 1 • awk &apos;BEGIN{i=0;print i++,i}&apos; 结果 0 1 实际上AWK的语法是采用VC语言风格的 2.示例： awk中~&amp;!~是否包含的用法： [root@centos7 ~]awk -F: &apos;$0 ~ /root/{print $1}&apos; /etc/passwd root operator 意思是如果过滤的行中有包含root字符串的，则打印出这行的用户名 用到下文提到的patter模式，在这里是匹配是否包含root字符串 [root@centos7 ~]awk -F: &apos;$0 ~ &quot;/root&quot;{print $1}&apos; /etc/passwd root operator 区别上面的这个写法，在这里是包含/root字符串的行 [root@centos7 ~]awk -F: &apos;$0 !~ /root/{print $1}&apos; /etc/passwd bin daemon adm 和上面的命令刚好相反，如果行不包含字符串root，则打印该行用户名 [root@centos7 ~]awk -F: &apos;$3==0&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 意思：判断UID是否等于0，是则打印该行，判断是否为管理员 [root@centos7 ~]awk &apos;$0~&quot;^root&quot;&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 意思：判断该行是不是以root开头的行，是则打印 3.awk中的与&amp;&amp;，或|| 非!的使用示例： 示例： • awk –F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000 {print $1}&apos; /etc/passwd 如果0&lt;=UID&lt;=1000，则打印出该用户 • awk -F: &apos;$3==0 || $3&gt;=1000 {print $1,$3}&apos; /etc/passwd 打印出UID等于0和UID&gt;=1000的用户名和他的UID • awk -F: &apos;!($3==0) {print $1}&apos; /etc/passwd -要加括号 打印出UID不等于0的用户名 • awk -F: &apos;!($3&gt;=500) {print $3}&apos; /etc/passwd 如果UID&lt;=500,时，打印出该用户的UID 4.AWK中的条件判断表达式 即三目表达式 相当于把shell中的if;then,else,fi的放到awk中 • 示例： [root@centos7 ~]awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd sys root 0 sys bin 1 sys tcpdump 72 common test 1000 common nginx 1008 判断用户是否为系统用户，是则打印并在开头加common,不是也打印在开头加sys awk中的PATTERN和action模式匹配和处理动作=sed的地址定界+修饰符功能：和sed中的pattern一样起到过滤的功能，=sed的地址定界 PATTERN:根据pattern条件，过滤匹配的行，再做处理(1)如果未指定：空模式，匹配每一行 (2) /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来 awk &apos;/^UUID/{print $1}&apos; /etc/fstab awk &apos;!/^UUID/{print $1}&apos; /etc/fstab awk的匹配模式支持的是扩展的正则表达式 注意：不支持直接给出数字格式，但是可以变向的打印输出，详见下面的示例 (3) relational expression: 关系表达式，结果为“真”才会被处理 真：结果为非0值，非空字符串 假：结果为空字符串或0值都是假 字符串为空或者0为假 (4) line ranges：行范围 startline,endline：/pat1/,/pat2/ 不支持直接给出数字格式 awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/{print $1}&apos; /etc/passwd awk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20){print NR,$1}&apos; /etc/passwd NR表示行 (5) BEGIN/END模式 BEGIN{}: 仅在开始处理文件中的文本之前执行一次 END{}：仅在文本处理完成之后执行一次 模式：指定一个行的范围。该语法不能包括BEGIN和END模式。BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。END：让用户在最后一条输入记录被读取之后发生的动作。 patter用法示例：先写一个特殊的用法 1.当在awk命令中使用正则模式时，使用到的正则用法属于&quot;扩展的正则表达式&quot; 2.当使用{x,y}这种次数匹配正则表达式，需要配合--posix或者--re-interval选项 备注：这是网上找到一个示例，文中提到{x,y}必须加这个选项，然而不加选项也是可以过滤的 awk是是支持posix字符集的 [root@centos7 ~]cat f3 seex sex seeex seeeeex [root@centos7 ~]cat f3 | awk &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3 | awk -posix &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3 | awk --re-interval &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3|grep -E &quot;se{2,3}x&quot; seex seeex [root@centos7 ~]cat f3|sed -nr &apos;/se{2,3}x/p&apos; seex seeex 1.取系统磁盘分区空间利用率df,/dev/sd开头的分区(上文中虽然取出来了，但是没过滤) [root@centos7 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &apos;/^\/dev\/sd/{print $1,$5}&apos; /dev/sda2 8 /dev/sda3 1 /dev/sda1 17 2.取当前连接主机的IP地址(上文中虽然取出来了，但是没过滤) [root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $6}&apos; 192.168.34.1 192.168.34.105 或者用NF的表达方式 [root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos; 192.168.34.1 192.168.34.105 3.取登录当前系统失败（lastb）用户的IP [root@centos7 ~]#lastb root ssh:notty 192.168.34.105 Sun Nov 11 17:25 - 17:25 (00:00) root23 ssh:notty 192.168.34.1 Mon Nov 5 15:43 - 15:43 (00:00) btmp begins Fri Nov 2 09:58:52 2018 [root@centos7 ~]#lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c 3 192.168.34.1 1 192.168.34.101 因为最后一行有btmp这样的字样，只能通过包含的功能来过滤掉最后一行 如果要取失败连接次数大于3的扔到防火墙，可以先取出来 root@centos7 ~]lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c| awk &apos;$1 &gt;=3{print $2}&apos; 192.168.34.1 4.patter中为关系表达式的示例 空字符串或0值都是假，其他为真 awk &apos;0{print $0}&apos; /etc/passwd -0为假，结果为空 awk &apos;&quot;&quot;{print $0}&apos; /etc/passwd -空也为假，结果为空 awk &apos;1{print $0}&apos; /etc/passwd -1为真 awk &apos;&quot; &quot;{print $0}&apos; /etc/passwd -空白符也为真 awk -v abc=&quot; &quot; &apos;abc{print $0}&apos; /etc/passwd -abc为空白,不是空字符串,也为真 awk -v abc=&quot; &quot; &apos;! abc{print $0}&apos; /etc/passwd -abc为空白,为真,对真取反，结果为假 5.awk中patter的地址定界 root@centos7 ~]#awk -F: &apos;/^root/,/^adm/{print $0}&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin 打印以root开头的行到以adm开头的行之间的所有行 等于 sed -nr &apos;/^root/,/^adm/p&apos; /etc/passwd 6.如何打印从多少行到多少行之间的行？？ [root@centos7 ~]#awk -F: &apos;NR&gt;=10 &amp;&amp; NR&lt;=12 {print NR,$0}&apos; /etc/passwd 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 通过变量NR变向的打印出行 7.取出/etc/fstab配置文件中以UUID开头的行 [root@centos7 ~]#cat /etc/fstab | awk &apos;/^UUID/{print $0}&apos; UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 效果等于 grep &quot;^UUID&quot; /etc/fstab 效果等于 sed -n &apos;/^UUID/p&apos; /etc/fstab 8. awk &apos;!0&apos; /etc/passwd =awk &apos;!0{print $0}&apos; /etc/passwd 省略了{print $0}的写法 结果为真，即打印全部行 root@centos7 ~]#awk -F: &apos;i=1;j=1{print i,j}&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 1 1 bin:x:1:1:bin:/bin:/sbin/nologin 1 1 ？？？ [root@centos7 ~]#awk -F: &apos;$NF ~ /bash$/{print $1,$NF}&apos; /etc/passwd root /bin/bash test /bin/bash 判断用户shell是否为/bin/bash，是则打印用户名和shell类型，此处用变量NF来实现 效果等于 awk -F: &apos;$NF==&quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd 效果等于 awk -F: &apos;$7 == &quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd 效果等于 awk -F: &apos;$0 ~ /bash$/{print $1,$NF}&apos; /etc/passwd 9.打印奇数行和偶数行 [root@centos7 ~]#seq 6 | awk &apos;i=!i&apos; 打印奇数行 1 3 5 原理：i初始值为空，为假，取反时，则打印第一行，此时i=1 i=1时，为真，取反为假，所以第二行不打印，然后i=0 依次类推所以只打印奇数行 [root@centos7 ~]#seq 6 | awk &apos;!(i=!i)&apos; 打印偶数行 2 4 6 效果等于 seq 10 |awk -v i=1 &apos;i=!i&apos; 原理：同上，只要先定义i=1，为真，第一行就不打印了 或者用sed打印奇数行和偶数行(用sed步进的方式) seq 6 | sed -n &apos;1~2p&apos; 打印奇数行 seq 6 | sed -n &apos;2~2p&apos; 打印偶数行 awk actionaction除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能• (1) Expressions:算术，比较表达式等 • (2) Control statements：if, while等 • (3) Compound statements：组合语句 • (4) input statements • (5) output statements：print等 下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句awk中if-else控制语句的语法及用法语法： 双分支if if(condition){statement;…}(多条语句用;隔开)[else statement] 多分支if if(condition1){statement1}else if(condition2){statement2}else{statement3} 使用场景：对awk取得的整行或某个字段做条件判断 if-else示例：如判断考试分数，写法如下 [root@centos7 ~]awk -v score==80 &apos;BEGIN{if(score &lt;60){print &quot;no pass&quot;} else if(score &lt;=80){print &quot;soso&quot;}else {print good}}&apos; soso awk -F: &apos;{if($3&gt;=1000)print $1,$3}&apos; /etc/passwd 判断UID是否大于1000，是则打印用户名和UID awk -F: &apos;{if($NF==&quot;/bin/bash&quot;) print $1}&apos; /etc/passwd 判断用户shell是否为/bin/bash,是则打印用户名 awk &apos;{if(NF&gt;5) print $0}&apos; /etc/fstab 判断域或列个数是否大于5，是则打印该行 awk -F: &apos;{if($3&gt;=1000) {printf &quot;Common user: %s\n&quot;,$1} else {printf &quot;root or Sysuser: %s\n&quot;,$1}}&apos; /etc/passwd 等于上文中的 awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd 例如：随机生成1000个数字，用awk取出最大值和最小值(可以用shell写法) 1.生成1000个数字 for i in {1..1000};do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f1.txt;else echo -e &quot;,$RANDOM\c&quot; &gt;&gt; f1.txt ;fi;done 2.用awk取出最大值和最小值 awk -F&apos;,&apos; &apos;{i=2;max=$1,while(i&lt;=NF){if($i &gt; max){max=$i}else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; f1.txt 验证用awk是否取出的值为正确的： 方法一：用tr验证 tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | head -n1 tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | tail -n1 方法二：用shell脚本验证 #!/bin/bash for i in {1..1000};do awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理awk中while循环控制语句的语法及用法语法：while(condition){statement;…} 条件“真”，进入循环；条件“假”，退出循环 使用场景： 对一行内的多个字段逐一类似处理时使用 对数组中的各元素逐一处理时使用 此时涉及到系统自带的一个函数length(函数在下面会有介绍) 示例： 1.统计每一行第一个字段的长度 root@centos7 ~]awk -F: &apos;{print length($1),$1}&apos; /etc/passwd 4 root 3 bin 6 daemon 3 adm 2.统计/etc/passwd第一行的每个字段的长度 [root@centos7 ~]awk -F: &apos;NR==1{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/passwd root 4 x 1 0 1 0 1 root 4 /root 5 /bin/bash 9 3.统计grub2.cfg文件中linux16那行的每个字段的长度 [root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/grub2.cfg linux16 7 /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 ro 2 crashkernel=auto 16 rhgb 4 quiet 5 LANG=en_US.UTF-8 16 linux16 7 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 ro 2 crashkernel=auto 16 rhgb 4 quiet 5 4.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用while循环 root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){if(length($i)&gt;=10) {print $i,length($i)};i++}}&apos; /etc/grub2.cfg /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 LANG=en_US.UTF-8 16 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 5.面试题 用awk取出文本f5的最大值和最小值，需要先生成1000个随机数存到f5中 如何做？ 1.不用awk，可以通过脚本实现最大值和最小值 2.用awk如何来做？？ 先生成1000个随机数 [root@centos7 ~]for i in `seq 1000`;do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f5; else echo -e &quot;,$aRANDOM\c&quot; &gt;&gt; f5 ;fi;done 生成了1000随机数，如何取最大值最小值？ [root@centos7 ~]awk -F&quot;,&quot; &apos;{i=2;max=$1;min=$1;while(i&lt;=NF){if($i &gt; max){max=$i} else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; &lt; f5 max=32643 min=60 awk中do-while循环控制语句语法：do {statement;…}while(condition) 意义：无论真假，至少执行一次循环体 do-while使用示例：求1-100正整数的和 [root@centos7 ~]awk &apos;BEGIN{ total=0;i=0;do{ total+=i;i++;}while(i&lt;=100);print total}&apos; 5050 awk中for循环控制语句语法：for(expr1;expr2;expr3) {statement;…} 常见用法： for(variable assignment;condition;iteration process) {for-body} 特殊用法：能够遍历数组中的元素 语法：for(var in array) {for-body} for循环使用示例：1.求1-100正整数的和： [root@centos7 ~]awk &apos;BEGIN{for(i=1;i&lt;=100;i++)sum+=i;print sum}&apos; 5050 2.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用for循环 [root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{for(i=1;i&lt;=NF;i++){if(length($i)&gt;=10){print $i,length($i)}}}&apos; /etc/grub2.cfg /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 LANG=en_US.UTF-8 16 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 awk中的switch控制语句类似于shell中的case语句 语法：switch(expression) {case VALUE1 or /REGEXP/: statement1; caseVALUE2 or /REGEXP2/: statement2; ...; default: statementn} awk中的continue,break，next控制语句break和continuenext:提前结束对本行处理而直接进入下一行处理（awk自身循环） continue的示例求1000以内偶数的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==0)continue;sum+=i}print sum}&apos; 2500 求1000以内奇数的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==1)continue;sum+=i}print sum}&apos; 2550 求1000以内除了66的所有数字的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i==66)continue;sum+=i}print sum}&apos; 4984 break的示例：求1000数字中，当大于100时，跳出循环，即求100以内的和 [root@centos7 ~]#awk &apos;BEGIN{sum=0;for(i=1;i&lt;=1000;i++){if(i&gt;100)break;sum+=i}print sum}&apos; 5050 next的示例：因为提前结束对本行处理而直接进入下一行处理（因为awk本身就是循环行的功能），所以示例 打印/etc/passwd下的奇数行 [root@centos7 ~]awk -F: &apos;{if(NR%2==0)next;print NR,$0}&apos; /etc/passwd 1 root:x:0:0:root:/root:/bin/bash 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 还可以这样写：awk -F: &apos;NR%2==1{print NR,$0}&apos; /etc/passwd awk数组-一个非常使用的功能awk的数组全都是关联数组关联数组：array[index-expression] index-expression: • (1) 可使用任意字符串；字符串要使用双引号括起来 • (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值 初始化为“空串” • (3) 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历 数组的去重的效果示例：awk &apos;!arr[$0]++&apos; dupfile awk &apos;{!arr[$0]++;print $0, arr[$0]}&apos; dupfile echo abc abc ccc bcd ddd ddd abc abc &gt;&gt; f1.txt awk关联数组的遍历：若要遍历数组中的每个元素，要使用for循环:因为关联数组下标是无序性 for(var in array) {for-body} 注意：var会遍历array的每个索引 数组的使用示例：示例1.定义awk数组 [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;; title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]}&apos; zhang 可以用for循环把每一个数组的值都表示出来 [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]; for(i in title){print i,title[i]}}&apos; zhang coo liu ceo zhang cto wang 但输出时数组元素时，是无序的，这就是关联数组的特性 示例2.awk数组中的重要功能 [root@centos7 ~]cat f6 abc abc ddd ccc aaa ccc ccc [root@centos7 ~]awk &apos;!line[$0]++&apos; f6 abc ddd ccc aaa 问题：为什么执行结果是这个？？ 原因： awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6 实际上是隐藏了{print $0}，这个隐藏功能在awk很重要！！！， 但是要和后面patter中的空模式区别开 &apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印 而后面的数组里的是加了双括号{}，{line[$0]++}即用的patter的空模式，即文本中的每一行都处理 这两个写法是不一样的，别混淆了 分析： 基于这个考虑进行分析 &apos;!line[$0]++&apos; = &apos;!line[$0]++{print $0}&apos; 当读取文本f6的第一行时=abc !line[&quot;abc&quot;]++，因为abc没有值，line[&quot;abc&quot;]=0为假，取反！line[&quot;abc&quot;]后为真 所以把第一行的abc打印了一次，打印第一行结束后line[&quot;abc&quot;]=1 当读取文本f6的第二行时=abc !line[&quot;abc&quot;]++，在之前基础上line[&quot;abc&quot;]=1为假，取反！line[&quot;abc&quot;]=0后为假 所以把第二行的abc不打印，结束后line[&quot;abc&quot;]=2 以此类推，发现后续出现abc都不会打印，但是line[&quot;abc&quot;]都会在之前的基础上+1，即达到去重并统计的目的 而处理第三行!line[&quot;ddd&quot;]++时，和上述abc一样，第一次出现则打印，后续也不会打印 所以，命令执行结果为去重的效果 从这个命令执行结果也可以明显看到上述的分析结果 可以看出abc的值是递增的，也就是abc出现的次数 [root@centos7 ~]awk &apos;{!line[$0]++;print $0, line[$0]}&apos; f6 abc 1 abc 2 ddd 1 ccc 1 aaa 1 ccc 2 awk数组中的重要功能之for循环遍历数组，很具有实用性在后面的统计服务的一些日志文件很有作用如果要理解遍历awk数组，需要深刻理解上述的示例2:awk &apos;!line[$0]++&apos; f6是怎么实现的 但还是有些和数组里的，遍历$2,把$2不同的值，当成数组的下标有些区别的 若要遍历数组中的每个元素，要使用for循环for(var in array) {for-body} 注意：var会遍历array的每个索引 为什么要通过特殊写法去遍历awk中的数组？如果是普通数组，用循环0,1,2,3做个循环即可；而awk的数组都是关联数组，[]中括号里的下标都不固定 所以要通过 for(var in array(数组名称)) {for-body}这样的特殊写法，var的值会从array数组元素 取其下标，相当于每次循环var的值是等于array数组的下标的 注意：当我们直接引用一个数组中不存在的元素时，awk会自动创建这个元素，并且为其赋值为&quot;空字符串&quot; for循环遍历数组使用示例：示例1： [root@centos7 ~]awk &apos;BEGIN{print test[&quot;ip&quot;];test[&quot;ip&quot;]++;print test[&quot;ip&quot;]}&apos; 1 第一次输出为空，第二次自动加1 示例2： 1. [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;for(i in title){print title[i]}}&apos; liu zhang wang 分析： for(i in title){print title[i]，i的值来自于title的下标，即i=ceo coo cto,而且是无序打印 示例3： [root@centos7 ~]netstat -tan Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN tcp 0 0 192.168.122.1:53 0.0.0.0:* ESTABLISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN tcp 0 52 192.168.34.103:22 192.168.34.1:8816 ESTABLISHED tcp 0 0 192.168.34.103:22 192.168.34.105:49746 ESTABLISHED tcp6 0 0 :::111 :::* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 ::1:631 :::* LISTEN tcp6 0 0 ::1:25 :::* LISTEN [root@centos7 ~]netstat -tan | awk &apos;/^tcp/{state[$NF]++}END{for(i in state) { print i,state[i]}}&apos; LISTEN 8 ESTABLISHED 3 分析： state[$NF]++以空白做分隔符，统计同一类型的状态有多少个 for(i in state) { print i,state[i]} 即统计了出现状态的多少种以及出现的次数 不明白的可以看上文中的示例2：awk数组中的重要功能 当然，看懂这个命令，需要知道两个知识点 1.空模式，即全文反复提到的{state[$NF]++}={state[$NF]++}{print $0} 2.END模式，END的模式是在前面动作结束之后，最后执行依次END模式中的命令，所以先不用考虑空模式 下面再一次对空模式中的处理过程，做详细的描述 空模式中，我们创建了一个state数组，并将状态值(LISTEN、ESTABLISHED)作为引用下标， 所以执行到第一行时，我们引用的是state[&quot;LISTEN&quot;],很明显，这个元素并不存在，所以，当第一行被空模式的动作处理完毕后 state[&quot;LISTEN&quot;]的值已经被赋值为1了。 这时，空模式中的动作继续处理下一行，而下一行的$NF=ESTABLISTEN；state[&quot;ESTABLISTEN&quot;] 所以，state[&quot;ESTABLISTEN&quot;]第一次参与运算过程与上一个原理相同 直到再次遇到相同的状态时，使用同样一个IP地址作为下标的元素将会再次被自加 直到处理完所有的行，开始执行END模式中的动作。 而END模式中，我们打印出state数组中的所有元素的下标，以及元素对应的值。 此刻，state数组中的下标即为各种状态，元素的值即为对应状态出现的次数， 最终，我们统计出每个状态出现的次数。 3.统计/var/log/httpd/access_log，每个IP链接的次数 root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; &quot;Mozil&quot; 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; 192.168.34.103 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; [root@centos7 ~]awk &apos;{ip[$1]++}END{for(i in ip){print i,ip[i]}}&apos; /var/log/httpd/access_log 192.168.34.101 9 192.168.34.103 13 ::1 4 192.168.34.1 88 效果等于： [root@centos7 ~]awk &apos;{print $1}&apos; /var/log/httpd/access_log |sort|uniq -c 4 ::1 88 192.168.34.1 9 192.168.34.101 13 192.168.34.103 4.统计ss -nt ip链接次数 [root@centos7 ~]ss -nt State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 52 192.168.34.103:22 192.168.34.1:8816 ESTAB 0 0 192.168.34.103:22 192.168.34.105:49746 [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{ip[$(NF-2)]++}END{for(i in ip){print i,ip[i]}}&apos; 192.168.34.105 1 192.168.34.1 1 效果等于： [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;|sort|uniq -c 1 192.168.34.1 1 192.168.34.105 5.统计/etc/fstab文件系统类型分别有多少个 [root@centos7 ~]cat /etc/fstab # /etc/fstab # Created by anaconda on Wed Sep 19 11:44:48 2018 UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data xfs defaults 0 0 UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap swap defaults 0 0 [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos; swap 1 xfs 3 6.求下表中的男生和女生的平均成绩 [root@centos7 ~]cat f9 name sex score a m 90 b f 80 c f 99 d m 88 e m 80 如何利用awk的数组功能来求？ 思路先求男的和和女的和？ 利用两个数组？ [root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3}END{for(i in sum){print i,sum[i]}}&apos; -求男女分的和 m 258 f 179 [root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3;num[$2]++}END{for(i in sum){print i,sum[i]/num[i]}}&apos; m 86 f 89.5 7.统计下面每个名字出现的次数 [root@centos7 ~]cat f1 Allen Phillips Green Lee William Aiden Janmes Lee Angel Jack Jack Thomas Lucas Kevin Tyler Lee William Allen [root@centos7 ~]cat f1 | awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,cuont[j]}}&apos; Tyler Angel Lucas William Thomas Green Jack Phillips Kevin awk函数awk也包括内置函数和自定义函数内置函数包括 rand,length，sub,gsub,split，system数值处理： rand(i)：返回0和1之间一个随机数 awk &apos;BEGIN{srand(); for (i=1;i&lt;=10;i++)print int(rand()*100) }&apos; 字符串处理： • length([s])：返回指定字符串的长度 • sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,“-&quot;,$1)&apos; • gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表 示的内容 echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; • split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所 表示的数组中，第一个索引值为1,第二个索引值为2,… netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}&apos; END{for (i in count) {print i,count[i]} awk内置函数之sub、gsub、split实现搜索替换切割的用法示例1： sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s gsub(r,s,[t])表示全局替换 sub(r,s,[t])不是贪婪模式，默认值替换搜索出来的第一个 [root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,&quot;-&quot;,$1)&apos; 2008-08:08 08:08:08 只替换$1 root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$1)&apos; 2008-08-08 08:08:08 全局替换$0 [root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; 2008-08-08 08-08-08 示例2： 统计字符串中每个字母出现的次数abcdaabbccdd [root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 3 b 3 c 3 d 3 在文章最后会用另外一种写法进行过滤(文章最后会以以空位分隔符的特殊写法来表示) awk内置函数split的切割功能示例1: 统计链接本机的IP和端口号 [root@centos7 ~]#netstat -tn Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 52 192.168.34.103:22 192.168.34.1:8816 ESTABLISHED tcp 0 0 192.168.34.103:22 192.168.34.105:49746 ESTABLISHED [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}END{for (i in count) {print i,count[i]}}&apos; 192.168.34.105 1 192.168.34.1 1 [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[2]]++}END{for (i in count) {print i,count[i]}}&apos; 8816 1 49746 1 分析： split($5,ip,&quot;:&quot;)将192.168.34.1:8816进行切割，数组ip的下标1放IP地址，下标2放端口号 count[ip[1]]++ 把ip下标为1也就是IP地址，把出现的IP个数，又给count当下标，就统计每个IP出现的次数 count[ip[2]]++ 把ip下标为2也就是端口号，把出现的端口号个数，又给count当下标，就统计每个端口号出现的次数 awk中的自定义函数格式：awk自定义函数是用正规开发语言的函数格式 function name ( parameter, parameter, ... ) { statements return expression } awk自定义函数的用法：cat fun.awk,把函数写到文件中 function max(x,y) { x&gt;y?var=x:var=y return var } BEGIN{print max(i,j)} awk -v i=10 -v j=20 -f fun.awk 调用函数即可，和shell中的函数类似 awk中很实用的内置函数system命令system函数作用：在awk可以反过来调用linux里的命令示例： 空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用 空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来 示例1: 显示/boot/grub2下的文件列表；调用命令时要加双引号 [root@centos7 ~]#awk &apos;BEGIN{system(&quot;ls /boot/grub2&quot;)}&apos; device.map fonts grub.cfg grubenv i386-pc locale 或者这么写，先定义变量等于路径，再调用变量 [root@centos7 ~]#awk &apos;BEGIN{dir=&quot;/boot/grub2&quot;;system(&quot;ls &quot;dir)}&apos; device.map fonts grub.cfg grubenv i386-pc locale 调用hostname命令，显示主机名 [root@centos7 ~]#awk &apos;BEGIN{system(&quot;hostname&quot;)}&apos; centos7.localdomain 示例2： 之前处理过lastb中登录失败的IP，如果失败登录次数大于3次，扔到防火墙里， 当时是先取出IP放到文件里，然后iptables再禁用； 现在可以在awk中先取出IP,然后通过system(&quot;iptables &quot; IP)就可以直接扔到防火墙中 具体实现？ awk脚本将awk程序写成脚本，直接调用或执行 awk脚本使用示例： 1.先写文本再调用 cat f1.awk {if($3&gt;=1000)print $1,$3} awk -F: -f f1.awk /etc/passwd 2.也可以写成脚本形式 先写再调用 [root@centos7 ~]vim f2.awk #!/bin/awk -f {if($3 &gt;=1000)print $1,$3} [root@centos7 ~]./f2.awk -F: /etc/passwd nfsnobody 65534 test 1000 gentoo 1007 nginx 1008 ceshi 1009 向awk脚本传递参数格式： awkfile var=value var2=value2... Inputfile 注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通 过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变 量都需要一个-v参数 awk脚本传参使用示例：cat test.awk #!/bin/awk –f {if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3} chmod +x test.awk test.awk -F: min=100 max=200 /etc/passwd 工作中遇到的常用awk文本解决案例：Linux Web服务器网站故障分析常用的命令系统连接状态篇： 1.查看TCP连接状态 netstat -nat |awk &apos;{print $6}&apos;|sort|uniq -c|sort -rn 每出现一被/^tcp/模式匹配到的行，数组S[$NF]就加1，NF为当前匹配到的行的最后一个字段，此处用其值做为数组S的元素索引； netstat -n | awk &apos;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}&apos; 或 netstat -n | awk &apos;/^tcp/ {++state[$NF]}; END {for(key in state) print key,&quot;\t&quot;,state[key]}&apos; netstat -n | awk &apos;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,&quot;t&quot;,arr[k]}&apos; netstat -n |awk &apos;/^tcp/ {print $NF}&apos;|sort|uniq -c|sort -rn netstat -ant | awk &apos;{print $NF}&apos; | grep -v &apos;[a-z]&apos; | sort | uniq -c 2.查找请求数请20个IP（常用于查找攻来源）： 方法一： netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20 方法二： netstat -ant |awk &apos;/:80/{split($5,ip,&quot;:&quot;);++A[ip[1]]}END{for(i in A) print A[i],i}&apos; |sort -rn|head -n20 3.用tcpdump嗅探80端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; ‘{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}’ | sort | uniq -c | sort -nr |head -20 4.查找较多time_wait连接 netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n20 5.找查较多的SYN连接 netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more 6.根据端口列进程 netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1 网站日志分析篇1（Apache）：1.获得访问前10位的ip地址 cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10 cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’ 2.访问次数最多的文件或页面,取前20 cat access.log|awk ‘{print $11}’|sort|uniq -c|sort -nr|head -20 3.列出传输最大的几个exe文件（分析下载站的时候常用） cat access.log |awk ‘($7~/.exe/){print $10 &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -20 4.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数 cat access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -100 5.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面 cat access.log |awk ‘($7~/.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -100 6.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数 cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 7.列出传输时间超过 30 秒的文件 cat access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -20 8.统计网站流量（G) cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’ 9.统计404的连接 awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort 10. 统计http status cat access.log |awk &apos;{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}&apos; cat access.log |awk &apos;{print $9}&apos;|sort|uniq -c|sort -rn 10.蜘蛛分析，查看是哪些蜘蛛在抓取内容。 /usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E &apos;bot|crawler|slurp|spider&apos; 网站日分析2(Squid篇）按域统计流量cat squid_access.log.tar.gz| awk &apos;{print $10,$7}&apos; |awk &apos;BEGIN{FS=&quot;[ /]&quot;}{trfc[$4]+=$1}END{for(domain in trfc){printf &quot;%st%dn&quot;,domain,trfc[domain]}}&apos; 安全篇：(ssh lastb)ssh日志中失败登录的IP，取出来 /var/log/secure awk &apos;/Failed PASSWORD/{IP[$(NF-3)]++}END{for(i in IP){print i,IP[i]}&apos; /var/log/secure 1、文件ip_list.txt如下格式，请提取”.magedu.com”前面的主机名部分并写 入到回到该文件中 1 blog.magedu.com 2 www.magedu.com … 999 study.magedu.com 2、统计/etc/fstab文件中每个文件系统类型出现的次数 [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{print $3}&apos;|sort|uniq -c |sort -nr 3 xfs 1 swap [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos; swap 1 xfs 3 3、统计/etc/fstab文件中每个单词出现的次数 root@centos7 ~]cat /etc/fstab |awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,count[j]}}&apos; man 1 4、提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字 [root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|awk &apos;gsub(/[^0-9]/,&quot;&quot;,$0)&apos; 05973 [root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|tr -dc &quot;[0-9]&quot; 05973 5、有一文件记录了1-100000之间随机的整数共5000个，存储的格式 100,50,35,89…请取出其中最大和最小的整数 6、解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP 并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频 率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT [root@centos7 ~]awk &apos;{access[$1]++}END{for(i in access){if(access[i]&gt;=1){print i,access[i]}}}&apos; /var/log/httpd/access_log 192.168.34.101 9 192.168.34.103 13 只过滤出IP，监控任务可以写到计划任务里， 或者用内置函数system[&quot;iptables&quot;]调用？ 7、将以下文件内容中FQDN取出并根据其进行计数从高到低排序 http://mail.magedu.com/index.html http://www.magedu.com/test.html http://study.magedu.com/index.html http://blog.magedu.com/index.html http://www.magedu.com/images/logo.jpg http://blog.magedu.com/20080102.html [root@centos7 ~]#cat f5|sed -nr &apos;s@.*//([^/]+)/.*@\1@p&apos;|sort|uniq -c|sort -nr 2 www.magedu.com 2 blog.magedu.com 1 study.magedu.com 1 mail.magedu.com [root@centos7 ~]#cat f5|awk -F&quot;/&quot; &apos;{print $3}&apos;|sort|uniq -c|sort -nr 2 www.magedu.com 2 blog.magedu.com 1 study.magedu.com 1 mail.magedu.com 8、将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出 同一inode中，beginnumber的最小值和endnumber的最大值 inode|beginnumber|endnumber|counts| 106|3363120000|3363129999|10000| 106|3368560000|3368579999|20000| 310|3337000000|3337000100|101| 310|3342950000|3342959999|10000| 310|3362120960|3362120961|2| 311|3313460102|3313469999|9898| 311|3313470000|3313499999|30000| 311|3362120962|3362120963|2| 输出的结果格式为： 310|3337000000|3362120961|10103| 311|3313460102|3362120963|39900| 106|3363120000|3368579999|30000| awk -F&apos;|&apos; &apos;NR==1{print;next}{a[$1]?(a[$1]&gt;$2?a[$1]=$2:0):(a[$1]=$2);b[$1]?(b[$1]&lt;$3?b[$1]=$3:0):(b[$1]=$3);c[$1]+=$4} END{l=asorti(a,d);for(i=1;i&lt;=l;i++)print d[i] FS a[d[i]] FS b[d[i]] FS c[d[i]] FS}&apos; file [解析] 第一行直接打印。从第2行开始以$1为下标，建立3个数组，比较出$2的最小值，$3的最大值，然后把$4进行累加，最后进行排序后依次取出各项值。 这其中运用了三目运算的嵌套，跟我们 if(){if(){}}else{} 的使用是一个道理，不要认为复杂，如果觉得模糊不清，仔细读懂流程控制。 9.统计字符串中每个字母出现的次数abcdaabbccdd [root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 3 b 3 c 3 d 3 下面的写法在双引号前一定要加一个空格才能匹配出来 或者用单引号，但是也需要在前面几个空格 [root@centos7 mnt]#echo abcdaabbccdd|awk -F &quot;&quot; &apos;{for(i=1;i&lt;=NF;i++)x[$i]++}END{for(i in x){print i,x[i]}}&apos; a 3 此处一定有个空格 b 3 c 3 d 3 或者用单引号，但是也需要在前面几个空格 [root@mini7-1 ~]#echo abcdaabbccdd |awk -F &apos;&apos; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 2 b 3 c 3 d 2 root@centos7 mnt]#echo abcdaabbccdd | grep -o &quot;[a-z]&quot;|sort|uniq -c 3 a 3 b 3 c 3 d 10.面试题：取出/etc/fstab中的挂载目录 [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos; boot data swap [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos; boot data swap AWK中的输入分隔符我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。要一次指定多个分隔符，需要将分隔符用中括号[]包裹起来，如果多个分隔符中有至少一个特殊字符，那么还需要在中括号外加上双引号或者单引号，并且使用两个或两个以上的\将其进行转义 $、^、(、)、[、]、?、.、| 示例1： [root@node7-1 data]cat b.txt ssh:user1@192.168.1.10 ssh:user2@192.168.1.11 ssh:user3@192.168.1.12 1.取user和IP [root@node7-1 data]awk -F [:@] &apos;{print $2,$3}&apos; b.txt user1 192.168.1.10 user2 192.168.1.11 user3 192.168.1.12 2.上面b.txt中的：和@换成^和|，又该怎么取？ [root@node7-1 data]awk -F &apos;[\\^\\|]&apos; &apos;{print $2,$3}&apos; b.txt user1 192.168.1.10 user2 192.168.1.11 user3 192.168.1.12 示例2： 示例1： george[walker]bush william[jefferson]clinton 如果要打印出由分隔符[和]分隔的三段数据，即可以分别使用两个或两个以上的\对[和]进行转义，如下所示 方法一： awk -F &apos;[\\[\\]]&apos; &apos;{ print $1,$2,$3}&apos; name.txt george walker bush william jefferson clinton 方法二： awk -F &apos;[][]&apos; &apos;{ print $1,$2,$3}&apos; name.txt george walker bush william jefferson clinton 11.取出文本中的姓名和FQDN，awk的方法参照文章最上面的链接文章 [root@node7-1 data]cat a.txt xiaoming\t20\thttp://sougou.com xiaohua\t25\thttp://www.baidu.com xiaodong\t30\thttp://www.jidong.com 方法一：用awk取，以\t做分隔符，但是在表示方法上比较特殊 root@node7-1 data]awk -F&apos;\\\\t&apos; &apos;{print $1,$3}&apos; a.txt xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析： 第一个给第二个转义，第三个给第四个转义，传给awk对就是\\t，awk再将\\解释成\t 方法二：用awk和sed取 [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )t(.*)@\1\2@&apos; xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 12.扩展11题的内容把t换成$,又该如何取？ [root@node7-1 data]cat a.txt xiaoming\$20\$http://sougou.com xiaohua\$25\$http://www.baidu.com xiaodong\$30\$http://www.jidong.com 方法一：还是只用awk来取 [root@node7-1 data]awk -F&apos;\\\\\\$&apos; &apos;{print $1,$3}&apos; a.txt xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析： 1.\\$是转义$的 2.前四个\\\\是转义\的 方法二：awk和sed取 [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )\$(.*)@\1\2@&apos; xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析：先用awk用\做分隔符来取，再用sed取，sed中的$需要转义]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本处理工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[旧事-大好河山]]></title>
    <url>%2F2017%2F10%2F01%2F%E6%97%A7%E4%BA%8B-%E5%A4%A7%E5%A5%BD%E6%B2%B3%E5%B1%B1%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. U2FsdGVkX19min3dSslrd5TyqnlWD6xYkM1vTVceAJqLcteQCu27VEQwqaD/ePWVo8XXRBuaAoQe8j3azPBAHeL1TgD6sj54J8BVW043Dqceu9eu7Vl76YjLD8ZaXrJfod0GDHUdfuFXX9QCl5Rqn6Ts2P1o1Eg8o8+GRNwJx6ynfoUfPdWSejihoyeOTOBSj2ttBnQhFnJRLo6l4OVTsooqBXZaa5XbGrKuyD3FeDjIxCyi7X20WspH7kzlPtGhFpVJE45lGkTYTK8xh/LyPScz53gEjp/pB6pdChSPVPKtgYsvrDE8AGs9u3NYpcqOXjJ8vx2n944frVpL7h40PMwMGr0+/VDbX0LCtXgNg/PT6Q5ReN/cVmVWnxKaaPWX]]></content>
      <categories>
        <category>旧事，杂记</category>
      </categories>
      <tags>
        <tag>旧事，杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP和PXE]]></title>
    <url>%2F2017%2F07%2F06%2FDHCP%E5%92%8CPXE%2F</url>
    <content type="text"><![CDATA[PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobblercobbler实现系统自动化安装cobbler自动化系统安装 DHCP服务&amp;PXE自动化安装系统DHCP服务:(著名的Inter系统协会组织：研发的DHCP和DNS技术)DHCP官方文档：DHCP文档BIND官网文档：BIND文档DNS搭建的相关文档:DNS原理解析&amp;搭建 PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobblercobbler实现系统自动化安装cobbler自动化系统安装 全文只有二个实验：搭建DHCP和在centos7实现基于PXE安装centos7和centos6(centos6上原理类似) 搭建DHCP服务器：基于UDP协议(dhcp服务器端口：67、dhcp客户端端口：68)DHCP: （Dynamic Host Configuration Protocol） 动态主机配置协议 局域网协议，UDP协议(67端口) 主要用途： 用于内部网络和网络服务供应商自动分配IP地址给用户 用于内部网络管理员作为对所有电脑作集中管理的手段 使用场景 自动化安装系统 解决IPV4资源不足问题 DHCP申请网络地址是通过四个过程实现的：四个数据报文DHCP共有八种报文 1.DHCP DISCOVER：客户端到服务器 2.DHCP OFFER ：服务器到客户端 3.DHCP REQUEST：客户端到服务器 4.DHCP ACK ：服务器到客户端 DHCP NAK：服务器到客户端,通知用户无法分配合适的IP 地址 DHCP DECLINE ：客户端到服务器，指示地址已被使用 DHCP RELEASE：客户端到服务器，放弃网络地址和取消 剩余的租约时间 DHCP INFORM：客户端到服务器, 客户端如果需要从DHCP 服务器端获取更为详细的配置信息，则发送Inform报文向 服务器进行请求，极少用到 同网段多DHCP服务 DHCP服务必须基于本地 先到先得的原则 跨网段 RFC 1542 Compliant Routers dhcrelay: 中继 相关协议 Arp rarp DHCP服务器的实现方式：搭建DHCP服务器Linux DHCP协议的实现程序：dhcp, dnsmasq（dhcp,dns） 1.实现DHCP的软件有两个：dnsmasp,这个软件是安装系统是默认的一个 可以同时提供dns和dhcp两种服务，不是很专业 如：ss -ntl 看到的默认就有dnsmasp服务 LISTEN 0 5 192.168.122.1:53 users:((&quot;dnsmasq&quot;,pid=1506,fd=6)) 2.DHCP更专业：下面主要介绍 实验：DHCP服务的搭建实验前提： 1.把vmware虚拟机的主机都设置成仅主机模式，要不然会影响所在的 工作中的DHCP服务器，其他人可能会获取到实验配置的DHCP服务 获取到一个不能上网的IP地址 2.编辑vmware的虚拟网络编辑器，将仅主机的DHCP服务关闭，这样当前 就只有自己配置的DHCP服务器了 Dhcp Server相关配置文件： /etc/dhcp/dhcpd.conf ---&gt;主要配置文件 /usr/lib/systemd/system/dhcpd.service ---&gt;服务名 /usr/sbin/dhcpd ---&gt;dhcp的主程序 /etc/dhcp/dhcpd.conf --&gt; /etc/rc.d/init.d/dhcpd /etc/dhcp/dhcpd6.conf--&gt; /etc/rc.d/init.d/dhcpd6 /var/lib/dhcpd/dhcpd.leases ---&gt;租出去的地址信息库文件 /usr/sbin/dhcrelay /etc/rc.d/init.d/dhcrelay dhcp server:67/udp dhcp client: 68/udp dhcpv6 client:546/udp Dhcp client dhclient 自动获取的IP信息： /var/lib/dhclient dhcp.conf配置文件内容设置：安装DHCP完,默认是启动不了的，因为配置文件dhcpd.conf是空的 1.先通过模板生成新的配置文件 cp /usr/share/doc/dhcp*/dhcpd.conf.example /etc/dhcp/dhcpd.conf 2.模板里的网段地址不对，需要修改，网段和IP范围 question：那么如何修改dhcd.conf配置文件？ answer：根据上面的模板文件中的信息自改自定义的一些值 该文件中定义了： 1.默认续租时间和最长租期 2.DHCP默认分配的网段和分配的IP地址范围 3.DHCP服务提供的默认网关地址和DNS地址 3.前两项设置其他主机只是通过DHCP自动获取地址的需求，如果通过dhcp实现系统的 自动化安装，就不仅仅获取到地址，还需要从DHCP获取能启动计算机的文件，即 dhcp的配置文件中要有配置的地址：类似于grub的文件 其它配置选项： filename: 指明引导文件名称 next-server：提供引导文件的服务器IP地址 示例： filename &quot;pxelinux.0&quot;; next-server 192.168.100.100; 网络中下载文件的主机地址，带有tftp功能 备注：如果网卡有pxe的功能即自带tftp的功能 所以具有完整的功能的dhcp配置文件dhcp.conf内容类似； default-lease-time 600; max-lease-time 7200; subnet 192.168.34.0 netmask 255.255.255.0 { range 192.168.34.20 192.168.34.100; option routers 192.168.34.1; option domain-name-servers 6.6.6.6; ext-server 192.168.34.103; filename &quot;pxelinux.0&quot;; PXE安装相关的配置 } 上面是主要配置内容，在dhcpd.conf中还可以把指定的mac地址与IP绑定 host passacaglia { hardware ethernet 00:0c:29:af:45:f7; fixed-address 192.168.34.80 } 安装tftp服务:(UDP协议：69端口) yum install tftp-server -y [root@node7-1 tftpboot]#rpm -ql tftp-server /etc/xinetd.d/tftp /usr/lib/systemd/system/tftp.service /usr/lib/systemd/system/tftp.socket /usr/sbin/in.tftpd /var/lib/tftpboot 存放下载上传的路径:系统所需要的文件 centos7和centos6上安装tftp是由区别的 centos7上需要安装tftp-server服务--&gt;UDP69端口 yum install tftp-server systemctl start tftp 在centos6上安装和telnet是一个道理，都依赖于xinetd chkconfig tftp on--&gt; /etc/xinetd.d/tftp配置文件 service restart xinted PXE介绍PXE： Preboot Excution Environment 预启动执行环境 Intel公司研发 基于Client/Server的网络模式，支持远程主机通过网络从远端服务器下载 映像，并由此支持通过网络启动操作系统 PXE可以引导和安装Windows,linux等多种操作系统 实验：在centos7实现基于PXE安装centos7和centos6自动化安装步骤： 1.安装前准备：关闭防火墙和SELINUX，DHCP服务器静态IP 2.安装软件包 httpd tftp-server dhcp syslinux system-config-kickstart httpd:实现yum源 tftp-server：实现网络下载的文件 syslinux: 准备pxelinux.0文件 备注：centos6上是安装syslinux-nonlinux system-config-kickstart制作kickstart软件，建议自己制作 3.配置文件共享服务： 准备centos7&amp;centos6的yum源 systemctl enable httpd systemctl start httpd mkdir -pv /var/www/html/centos/{6,7}/os/x86_64 mount /dev/sr0 /var/www/html/centos/7/os/x86_64 mount /dev/sr1 /var/www/html/centos/6/os/x86_64 4.准备kickstart文件 拷贝已经安装机器上的anaconda文件，按照自定义稍微修改，放到http目录下 注意：644权限 cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg ks应答文件的内容可以用system-config-kickstart或者anaconda修改就行了 最好是通过system-config-kickstart做一个应答文件，通过界面更深刻理解 每一项代表的意义 大概内容如下：(最后附件的有详细的ks文件内容) url --url=http://192.168.34.7/centos/7/os/x86_64/ text firewall --disabled selinux --disabled clearpart --all --initlabel zerombr reboot %packages @core %end 5.配置tftp服务 systemctl enable tftp.socket systemctl start tftp.socket 6.配置DHCP服务 cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcpd/dhcpd.conf vim /etc/dhcp/dhcpd.conf option domain-name &quot;example.com&quot;; default-lease-time 600; max-lease-time 7200; subnet 192.168.34.0 netmask 255.255.255.0 { range 192.168.34.20 192.168.34.100; option routers 192.168.34.1; option domain-name-servers 6.6.6.6; next-server 192.168.34.103; filename &quot;pxelinux.0&quot;; } systemctl enable dhcpd systemctl start dhcpd 7.准备PXE相关文件 放pxelinux.0的专用目录，启动菜单 mkdir /var/lib/tftpboot/pxelinux.cfg/ 分别存放6和7的vmliuz和initrd.img文件 mkdir linux{6,7} 拷贝6和7安装必要文件 cp /var/www/html/centos/6/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/linux6/ cp /var/www/html/centos/7/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/linux7/ cp /usr/share/syslinux/{pxelinux.0,menu.c32} /var/lib/tftpboot/ 将光盘里的启动菜单拷贝到并改名为default cp /var/www/html/centos/7/os/x86_64/isolinux.cfg /var/lib/tftpboot/ pxelinux.cfg/default 拷贝完所有文件,文件列表如下： /var/lib/tftpboot/ . ├── linux6 │ ├── initrd.img │ └── vmlinuz ├── linux7 │ ├── initrd.img │ └── vmlinuz ├── menu.c32 ├── pxelinux.0 └── pxelinux.cfg └── default 8.准备启动菜单 菜单项可以自定义多个，如只有mini7和mini6的，还有必须要有本地硬盘启动的菜单项 但是要在文件内把各个的linuz和initrd路径 vim /var/lib/tftpboot/pxelinux.cfg/default default menu.c32 timeout 100 menu title PXE Install CentOS label mini7 menu label ^Auto Install Mini CentOS 7 kernel linux7/vmlinuz append initrd=linux7/initrd.img ks=http://192.168.34.7/ksdir/ks7-mini.cfg label mini6 menu label ^Auto Install Mini CentOS 6 kernel linux6/vmlinuz append initrd=linux6/initrd.img ks=http://192.168.34.7/ksdir/ks6-mini.cfg label local menu default menu label Boot from ^local drive localboot 0xffff. 9.准备完所有的文件和软件后，启动所有的服务，就可以测试PXE安装了。 附带centos7和centos6的ks应答文件模板：建议通过ystem-config-kickstart做一个应答文件，通过界面更深刻理解每一项代表的意义，当然也可以修改anaconda-ks.cfg文件ks6-mini.cfginstall url --url=http://192.168.34.103/centos/6/os/x86_64/ #httpd的yum源路径 lang en_US.UTF-8 keyboard us text #纯文本安装 reboot #安装完重启 network --onboot yes --device eth0 --bootproto dhcp --noipv6 rootpw --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt JjA57WrZO0 firewall --service=ssh 关闭防火墙 authconfig --enableshadow --passalgo=sha512 selinux --enforcing 关闭selinux timezone Asia/Shanghai 时区信息 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work clearpart --all 清空分区信息 zerombr 清空mbr #自定义的分区信息 part /boot --fstype=ext4 --size=1024 part / --fstype=ext4 --size=50000 part /data --fstype=ext4 --size=30000 part swap --size=2048 #自定义的分区信息 %packages @core %end 只安装最基本的核心包，后面也可以加上安装后脚本 ks7-mini.cfg：类似centos6的只是稍微的区别auth --enableshadow --passalgo=sha512 url --url=http://192.168.34.103/centos/7/os/x86_64/ text firstboot --enable ignoredisk --only-use=sda keyboard --vckeymap=us --xlayouts=&apos;us&apos; lang en_US.UTF-8 network --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --activate network --hostname=centos7.localdomain rootpw --iscrypted $6$j2QVLmDO2xasQEW0$xEvr1jyj1mHs0HBtCc7jD73r6u4NrQCxwVoAu.SMXhwm8GiKBHq5ETZ2zFxP4rFsNavYbG0u6Gq13 Igxrn1Ry. firewall --disabled selinux --disabled services --enabled=&quot;chronyd&quot; timezone Asia/Shanghai --isUtc user --name=test --password=$6$Awcwirg.mougtUlL$Yr1a9e2Vfs2k/Nizdn/ZeiunlsU.rJAmI1vhp1iafeccRt48h3PVIlnVwGvKPPt4dVum a/W32jzYIsn1XCrva. --iscrypted --gecos=&quot;test&quot; bootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda clearpart --all --initlabel zerombr reboot part / --fstype=&quot;xfs&quot; --ondisk=sda --size=51200 part /boot --fstype=&quot;xfs&quot; --ondisk=sda --size=1024 part swap --fstype=&quot;swap&quot; --ondisk=sda --size=4096 part /data --fstype=&quot;xfs&quot; --ondisk=sda --size=30720 %packages @core %end]]></content>
      <categories>
        <category>系统安装</category>
      </categories>
      <tags>
        <tag>运维，linux，windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql高可用]]></title>
    <url>%2F2017%2F05%2F20%2Fmysql%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[mysql的高可用 MHA:一主多从架构 1.对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点，基于主从复制实现 2.可以监控多组主从复制集群 MHA工作原理 1.从宕机崩溃的master保存二进制日志事件（binlog events） 2.识别含有最新更新的slave 3.应用差异的中继日志（relay log）到其他的slave 4.应用从master保存的二进制日志事件（binlog events） 5.提升一个slave为新的master 6.使其他的slave连接新的master进行复制 Galera Cluster：多主架构 1.任何一节点都可读写，不需要主从复制，实现多主读写，实现的是多主方案的实现 2.基于wsrep(MySQL extended with the Write Set Replication)通过wsrep协议在全局实现复制 MHA的实现 准备环境： 1.实现主从复制集群，并将忽略名称解析项启用 skip-name-resolv 2.各主机互相基于ssh-key验证 ssh-keygen ssh 10.10.0.5(自己的IP) scp /root/.ssh 10.10.0.3|6|7:/root/即可 3.各主机的时间需要同步 主节点： 1.修改配置文件： vim /etc/my.cnf [mysqld] log-bin server_id=1 skip_name_resolve=1 2.为MHA创建账户，用于管理和提升各节点作为新的主节点 grant all on *.* to mhauser@&apos;10.10.0.%&apos; identified by &apos;mha123&apos;; 从节点： 1.修改配置文件： vim /etc/my.cnf [mysqld] server-id=2|3|4|5 log_bin 启用二进制日志，因为每一台都可能成为一个主 relay_log_purge=0 不清除中继日志，用于补全主节点down机后丢失的信息 read_only skip_name_resolve=ON 安装软件包： 依赖于epel源，需启用 MHA管理节点：Manager工具包和Node工具包 数据库各节点：安装Node工具包 MHA管理节点上配置： vim /etc/mha/mysqlcluster1.cnf [server default] user=mhauser password=mha123 manager_workdir=/etc/mha/cluster1/ manager_log=/etc/mha/cluster1/manager.log remote_workdir=/etc/mha/cluster1/ ssh_user=root repl_user=repluser repl_password=root123 ping_interval=1 [server1] hostname=10.10.0.5 candidate_master=1 [server2] hostname=10.10.0.6 candidate_master=1 [server3] hostname=10.10.0.7 candidate_master=1 测试启动： 测试ssh-key验证是否成功 masterha_check_ssh --conf=/etc/mha/mysqlcluster1.cnf 测试mysqlcluster1配置文件是否能正常连接各个数据库： masterha_check_repl --conf=/etc/mha/mysqlcluster1.cnf 启用cluster masterha_manager --conf=/etc/mha/mysqlcluster1.cnf 故障测试： 1.把主节点down机 2.可以通过查询cat /etc/mha/cluster1/manager.log日志查看故障转移的节点信息 结论： 1.MHAcluster这里是以前台方式运行的，在生产环境下一定要以后台运行的 2.主节点down机后，MHA自动挑选一台从节点当主服务器： 所以show slave status\G和show variables like &apos;read_only&apos;; 都是空的或者是OFF状态，而且其他从节点的slave status看到的主节点 比变成了新的主节点了 3.对于前端的proxysql调度器还需要手动修改主节点信息 4.即使down机的&quot;主节点恢复正常了&quot;，也只是一台单机的服务器，不能再变成主节点 了，需要再进入到集群中，充当从节点 Galera Cluster的实现 Galera Cluster特点： 1.多主架构：真正的多点读写的集群，在任何时候读写数据，都是最新的 2.同步复制：集群不同节点之间数据同步，没有延迟，在数据库挂掉之后，数据 不会丢失 3.并发复制：从节点APPLY数据时，支持并行执行，更好的性能 4.故障切换：在出现数据库故障时，因支持多点写入，切换容易 5.热插拔：在服务期间，如果数据库挂了，只要监控程序发现的够快，不可服务 时间就会非常少。在节点故障期间，节点本身对集群的影响非常小 6.自动节点克隆：在新增节点，或者停机维护时，增量数据或者基础数据不需要 人工手动备份提供，Galera Cluster会自动拉取在线节点数据，最终集群会变为 一致 基于Mariadb Galera Cluster实现1.需要安装Mariadb Galera Cluster特定版本的数据库 配置过程： 1. 配置repo源 cat &gt; /etc/yum.repos.d/galera-cluster &lt;&lt;EOF [galera] name=&quot;galera-cluster&quot; baseurl=https://mirrors.tuna.tsinghua.edu.cn/mariadb//mariadb-10.0.37/yum/centos74-amd64/ enable=1 gpgcheck=0 EOF 2. 使用特定版本的数据库： yum install MariaDB-Galera-server -y 3. 在各节点都需要进行如下配置: vim /etc/my.cnf.d/server.cnf [galera] wsrep_provider=/usr/lib64/galera/libgalera_smm.so wsrep_cluster_address=&quot;gcomm://10.10.0.5,10.10.0.6,10.10.0.7&quot; binlog_format=row default_storage_engine=InnoDB innodb_autoinc_lock_mode=2 bind-address=0.0.0.0 4. 首次启动，需初始集群，在其中一个节点执行以下命令即可 /etc/init.d/mysql start --wsrep-new-cluster 5. 正常启动其它节点 service mysql start 6.查看集群中相关系统变量和状态变量 SHOW VARIABLES LIKE &apos;wsrep_%&apos;; SHOW STATUS LIKE &apos;wsrep_%&apos;; SHOW STATUS LIKE &apos;wsrep_cluster_size&apos;; 7.测试： 因为都是主节点，所以其中任何一个down机，其他节点也都是正常的 这样就实现了Mariadb Galera Cluster数据库集群的搭建 复制的问题和解决方案(1) 数据损坏或丢失 Master： MHA + semi repl 采用MHA+半同步复制的数据库集群 Slave： 重新复制 (2) 混合使用存储引擎 MyISAM：不支持事务 InnoDB： 支持事务 (3) 不惟一的server id 重新复制 (4) 复制延迟 需要额外的监控工具的辅助 一从多主:mariadb10版后支持 多线程复制：对多个数据库复制 Mysql的压力测试数据库服务衡量指标： qps:query per second，每秒钟支持多少个查询 tps:transaction per second，每秒钟支持多少个事务 压力测试工具： 1. Sysbench：功能强大 https://github.com/akopytov/sysbench 2.mysqlslap工具，默认安装mariadb时就会有这个工具 选项： --auto-generate-sql, -a 自动生成测试表和数据，表示用mysqlslap工具自己生成的SQL脚本来测试并发压力 --auto-generate-sql-load-type=type 测试语句的类型。代表要测试的环境是读操作还是写操作还是两者混合的。取值包括：read，key，write，update和mixed(默认) -engines engine_name 代表要测试的引擎，可以有多个，用分隔符隔开。例如：-engines=myisam,innodb --concurrency=N, -c N 表示并发量 --commint=N 如测试MyIsam和InnoDB的速度，虽然MyIsam的速度快，但是InnoDB的保证数据安全性更高，生产环境下一定要用InnoDB存储引擎]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cobbler]]></title>
    <url>%2F2017%2F05%2F06%2FCobbler%2F</url>
    <content type="text"><![CDATA[在服务器很多的情况下，用U盘或者光盘安装时，就显得有点吃力了，虽然可以用PXE进行安装，但是PXE不支持UEFI所以现在更多使用Cobbler来实现自动化部署. Cobbler工作原理 系统自动安装之-cobbler之前写过PXE自动化安装的文档，但是PXE只支持BIOS，不支持UEFI:PXE系统自动化部署Cobbler可以同时支持BIOS和UEFI两种：基于PXE技术为基础的整合 BIOS+MBR：分区最多支持2T的UEFI+GPT：分区可以支持大于2T的分区 在之前的工作中，需要建立大于2T的分区时，PXE安装就不合适了 cobbler:具有图形化管理界面的工具cobbler是什么？ 实际上是把PXE技术用python代码做了封装，形成了相对完整的自动化安装， 但是实现PXE的原有的httpd，DHCP，tftp服务还是需要提前安装的。 Cobbler: 快速网络安装linux操作系统的服务，支持众多的Linux发行版：Red Hat、 Fedora、CentOS、Debian、Ubuntu和SuSE，也可以支持网络安装windows PXE的二次封装，将多种安装参数封装到一个菜单 Python编写 提供了CLI和Web的管理形式 安装cobbler：EPEL源安装包 cobbler 基于EPEL源 cobbler 服务集成 前面说过因为是基于PXE的,安装cobbler因为有依赖性，会自动安装下面的服务 PXE DHCP rsync Httpd DNS Kickstart syslinux tftp-server IPMI 电源管理 启动cobbler:依赖于httpd，要想启动cobbler,必须先启动httpd systemctl start httpd tftp dhcp systemctl start cobblerd 然后再检查cobbler环境 cobbler check cobbler的相关配置文件安装：yum install cobbler dhcp 配置文件目录 /etc/cobbler /etc/cobbler/settings : cobbler 主配置文件(下文会对该文件修改4行) /etc/cobbler/iso/: iso模板配置文件 /etc/cobbler/pxe: pxe模板文件 /etc/cobbler/power: 电源配置文件 /etc/cobbler/user.conf: web服务授权配置文件 /etc/cobbler/users.digest: web访问的用户名密码配置文件 /etc/cobbler/dhcp.template : dhcp服务器的的配置末班 /etc/cobbler/dnsmasq.template : dns服务器的配置模板 /etc/cobbler/tftpd.template : tftp服务的配置模板 /etc/cobbler/modules.conf : 模块的配置文件 数据目录 /var/lib/cobbler/config/: 用于存放distros，system，profiles 等信息配置文件 /var/lib/cobbler/triggers/: 用于存放用户定义的cobbler命令 /var/lib/cobbler/kickstart/: 默认存放kickstart文件 /var/lib/cobbler/loaders/: 存放各种引导程序 镜像目录 /var/www/cobbler/ks_mirror/: 导入的发行版系统的所有数据 /var/www/cobbler/images/ : 导入发行版的kernel和initrd镜像用于远程网络启动 /var/www/cobbler/repo_mirror/: yum 仓库存储目录 日志目录 /var/log/cobbler/installing: 客户端安装日志 /var/log/cobbler/cobbler.log : cobbler日志 cobbler命令介绍cobbler commands介绍 cobbler check 核对当前设置是否有问题 cobbler list 列出所有的cobbler元素 cobbler report 列出元素的详细信息 cobbler sync 同步配置到数据目录,更改配置最好都要执行下 cobbler reposync 同步yum仓库 cobbler distro 查看导入的发行版系统信息 cobbler system 查看添加的系统信息 cobbler profile 查看配置信息 cobbler重要的参数:及下面需要修改的4行内容/etc/cobbler/settings中重要的参数设置 default_password_crypted: &quot;$1$gEc7ilpP$pg5iSOj/mlxTxEslhRvyp/&quot; server: 192.168.34.17 next_server: 192.168.34.17 server：&lt;cobbler服务器的 IP 地址&gt; manage_dhcp: 1 manage_tftpd：1 pxe_just_once：1 cobbler环境检查：先启动cobbler服务再检查1.先启动cobbler服务，再用cobbler check 进行检查 执行Cobbler check命令会报如下异常 1 : The ‘server’ field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it. 2 : For PXE to be functional, the ‘next_server’ field in /etc/cobbler/ settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 3 : some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run ‘cobbler get-loaders’ to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a recent version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The ‘cobbler get-loaders’ command is the easiest way to resolve these requirements. 4 : change ‘disable’ to ‘no’ in /etc/xinetd.d/rsync 5 : comment ‘dists’ on /etc/debmirror.conf for proper debian support 6 : comment ‘arches’ on /etc/debmirror.conf for proper debian support 7 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to ‘cobbler’ and should be changed, try: “openssl passwd -1 -salt ‘random-phrase-here’ ‘your-password-here’” to generate new one 8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them Cobbler的8项报错解决方法错误信息都是在/etc/cobbler/settings文件改了4行，在下文体现 执行Cobbler check报错解决方式 第一个错误解决方法： 1.修改/etc/cobbler/settings文件中的server参数的值为提供cobbler服务的主机相 应的IP地址或主机名：384行，然后重新启动cobbler server: 192.168.34.107 2.修改/etc/cobbler/settings文件中的next_server参数的值为提供PXE服务的主机 相应的IP地址:272行，指定的tftp的服务器地址 next_server: 192.168.34.107 3.执行cobbler get-loaders和cobbler sync； 如果当前节点可以访问互联网，执行&quot;cobbler get-loaders&quot;命令即可； cobbler会自动通过互联网把最小化的系统启动文件下载下来放到 /var/lib/cobbler/loaders/下，再通过&quot;cobbler sync&quot;命令同步到/var/lib/tftpboot/下 4.cobbler认为是在centos6上，tftp服务是依赖于xinetd的，提示启动xinetd,在 这里，由于是在cnetos7上安装的，这项可以忽略 5.执行“chkconfig rsync on”命令即可 4,5,6项如果是在centos7上安装的cobbler是不需要修改也可以启动的 7.第7项是说安装的操作系统密码cobbler事先已经帮忙设置好了，但是不安全，需要自己 去修改一个自定义的密码(通过openssl passwd -1)生成：101行 default_password_crypted：修改成自己设置的密码 备注：在这个提示里，还有一项建议修改，之前用PXE的时候，搭建的DHCP服务，dhcpd.conf 文件时通过模板生成的，但是在cobbler中，可以通过colbber来生成，但是需要改 /etc/cobbler/settings一项配置：242行 manage_dhcp: 0 改成 manage_dhcp: 1 再通过cobbler自带的dhcp模板：/etc/cobbler/dhcp.template，生成dhcpd.conf 只需要把这个模板改一下就行了，而不用想PXE那样通过模板生成dhcpd.conf文件 把dhcp.template里的网段地址改一下 subnet 192.168.34.0 netmask 255.255.255.0 { option subnet-mask 255.255.255.0; range dynamic-bootp 192.168.34.20 192.168.34.100; 再通过cobbler sync重新生成/etc/dhcp/dhcpd.conf,并且会开启DHCP服务 上面的报错全部解决之后，且httpd,tftp，dhcp,cobbler都启动之后，实际上就已经具备了雏形了/var/lib/tftpboot的目录结构:上面的第三步完成后就生成下面的所有文件了[root@mini7-1 tftpboot]#tree /var/lib/tftpboot /var/lib/tftpboot ├── boot │ └── grub │ └── menu.lst ├── etc ├── grub │ ├── efidefault │ ├── grub-x86_64.efi │ ├── grub-x86.efi │ └── images -&gt; ../images ├── images ├── images2 ├── memdisk ├── menu.c32 ├── ppc ├── pxelinux.0 ├── pxelinux.cfg │ └── default ├── s390x │ └── profile_list └── yaboot 接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘(centos6&amp;centos7)cobbler命令的选项： cobbler &lt;distro|profile|system|repo|image|mgmtclass|package|file&gt; ... [add|edit|copy|getks*|list|remove|rename|report] [options|--help] cobbler &lt;aclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink&gt; [options|--help] 这里用import选项将6和7的光盘导入cobbler的主机上 mount /dev/sr0 /mnt/ ---&gt;挂载centos7光盘 mount /dev/sr1 /media ---&gt;挂载centos6光盘 cobbler import --path=/mnt/ --name=Centos-7.5-x86_64 --arch=x86_64 cobbler import --path=/media/ --name=Centos-6.10-x86_64 --arch=x86_64 cobbler会把光盘拷贝到/var/www/cobbler/下分开存放，目录结构如下 [root@mini7-1 cobbler]#tree -d /var/www/cobbler /var/www/cobbler ├── images │ ├── Centos-6.10-x86_64 │ └── Centos-7.5-x86_64 ├── ks_mirror │ ├── Centos-6.10-x86_64 │ │ ├── EFI │ │ │ └── BOOT │ │ ├── images │ │ │ └── pxeboot │ │ ├── isolinux │ │ ├── Packages │ │ └── repodata │ ├── Centos-7.5-x86_64 │ │ ├── EFI │ │ │ └── BOOT │ │ │ └── fonts │ │ ├── images │ │ │ └── pxeboot │ │ ├── isolinux │ │ ├── LiveOS │ │ ├── Packages │ │ └── repodata │ └── config ├── links │ ├── Centos-6.10-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-6.10-x86_64 │ └── Centos-7.5-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-7.5-x86_64 ├── localmirror ├── misc ├── pub ├── rendered ├── repo_mirror └── svc 拷贝完，cobbler sync再同步一次 然后cobbler会把/var/lib/tftpboot/pxelinux.cfg/default文件自动更新，生成新的菜单 DEFAULT menu PROMPT 0 MENU TITLE Cobbler | http://cobbler.github.io/ TIMEOUT 200 TOTALTIMEOUT 6000 ONTIMEOUT local LABEL local MENU LABEL (local) MENU DEFAULT LOCALBOOT -1 LABEL Centos-6.10-x86_64 kernel /images/Centos-6.10-x86_64/vmlinuz MENU LABEL Centos-6.10-x86_64 append initrd=/images/Centos-6.10-x86_64/initrd.img ksdevice=bootif lang= kssendmac text ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-6.10-x86_64 ipappend 2 LABEL Centos-7.5-x86_64 kernel /images/Centos-7.5-x86_64/vmlinuz MENU LABEL Centos-7.5-x86_64 append initrd=/images/Centos-7.5-x86_64/initrd.img ksdevice=bootif lang= kssendmac text ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-7.5-x86_64 ipappend 2 MENU end 此时，就可以用cobbler实现自动化安装了，但是不能自定义ks应答文件安装，下面会讲解如何自定义cobbler的应答文件 Cobbler中自定义应答文件之前在PXE安装时，是自定义的kickstart应答文件，在cobbler中如何实现？ 1.在cobbler中，应答文件是放在/var/lib/cobbler/kickstarts/中 2.把之前制作的ks6-mini.cfg，ks7-mini.cfg拷贝到此目录，但是拷贝完，但cobbler是无 法识别这些应答文件是对应的那个发行版本的，所以要绑定 3.将自定义的应答文件和安装版本进行绑定 4.这两个应答文件有一项需要修改 即url --url=这一项，要改成cobbler的yum源路径，$tree 这里只显示ks6-mini.cfg的详细信息 install url --url=http://192.168.34.103/centos/6/os/x86_64/ (PXE下的源路径) #httpd的yum源路径，要改成$tree 或者改成具体的地址：即光盘拷贝到cobbler的具体路径 http://192.168.34.107/cobbler/ks_mirror/Centos-6.10-x86_64/ lang en_US.UTF-8 keyboard us text #纯文本安装 reboot #安装完重启 network --onboot yes --device eth0 --bootproto dhcp --noipv6 rootpw --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt JjA57WrZO0 firewall --service=ssh 关闭防火墙 authconfig --enableshadow --passalgo=sha512 selinux --enforcing 关闭selinux timezone Asia/Shanghai 时区信息 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work clearpart --all 清空分区信息 zerombr 清空mbr #自定义的分区信息 part /boot --fstype=ext4 --size=1024 part / --fstype=ext4 --size=50000 part /data --fstype=ext4 --size=30000 part swap --size=2048 #自定义的分区信息 %packages @core %end 只安装最基本的核心包，后面也可以加上安装后脚本 将KS和OS关联，生成启动新的菜单自定义的应答文件的绑定、删除、重命名、显示菜单栏对应的ks应答文件信息 在cobberl中 distro中记录的是cobbler中安装的发型版本对应的原文件的 [root@mini7-1 kickstarts]#cobbler distro list Centos-6.10-x86_64 Centos-7.5-x86_64 在cobberl中 profile是对应的各个发型版本的安装方法，就是安装启动界面的选择菜单栏，有多少个 就对应多少个菜单栏：如下图只有两个 [root@mini7-1 kickstarts]#cobbler profile list Centos-6.10-x86_64 Centos-7.5-x86_64 将自定义的应答文件和安装版本进行绑定：cobbler profile命令绑定 将ks6-mini.cfg和centos6进行绑定 cobbler profile add --name=centos-6.10-x86_64_mini --distro=Centos-6.10-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks6-mini.cfg cobbler profile add --name=centos-7.5-x86_64_mini --distro=Centos-7.5-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks7-mini.cfg 也可以删除应答文件： cobbler profile remove --name=Centos-6.10-x86_64 cobbler profile remove --name=Centos-7.5-x86_64 也可以修改带单名 cobbler profile rename --name=Centos-7.5-x86_64 --newname=centos-7.5-x86_64_desktop 查看菜单项对应的具体是哪个应答文件信息 cobbler profile report --name=centos-7.5-x86_64_mini /var/lib/tftpboot/pxelinux.cfg/default会自动生成新的菜单项，从cobbler profile list,也可以看出来 [root@mini7-1 tftpboot]#cobbler profile list Centos-6.10-x86_64 Centos-7.5-x86_64 centos-6.10-x86_64_mini centos-7.5-x86_64_mini cobbler的web管理实现此外cobbler是带有web管理界面的，不过需要安装web界面的包 yum install cobbler-web -y 配置文件： [root@mini7-1 kickstarts]#rpm -qf cobbler-web /etc/httpd/conf.d/cobbler_web.conf cobbler-web是经过http协议的，所以 安装完，需要重启httpd服务 然后看到对应的是443端口启动了 登录界面是，因为cobbler-web是https加密的/etc/cobbler/modules.conf 验证方法;/etc/cobbler/users.digest 记录的用户增加用户]]></content>
      <categories>
        <category>系统安装</category>
      </categories>
      <tags>
        <tag>运维，linux，windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql读写分离]]></title>
    <url>%2F2017%2F03%2F22%2Fmysql%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[Mysql的读写分离 ProxySQL官方网站:ProxySQL&amp;安装手册Mycat:基于Cobar研发的Mycat proxysql是一个高性能的mysql代理服务器，MYSQL中间件 多种方式的的读/写分离 定制基于用户、基于schema、基于语句的规则对SQL语句进行路由 缓存查询结果 后端节点监控 ProxySQL安装基于YUM仓库安装 vim /etc/yum.repos.d/proxysql.repo [proxysql_repo] name= ProxySQL YUM repository baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever gpgcheck=1 gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key 基于RPM下载安装：https://github.com/sysown/proxysql/releases ProxySQL组成 服务脚本：/etc/init.d/proxysql 配置文件：/etc/proxysql.cnf 主程序：/usr/bin/proxysql proxysql使用： proxysql本身是个小型的数据库，启动后在数据库中配置即可 ProxySQL的读写分离实现1.实现读写分离前，先实现主从复制 注意：slave节点需要设置read_only=1 如果不加，proxysql是无法判断该服务器是负责读还是负责写的 2.启动ProxySQL：service proxysql start 启动后会监听两个默认端口 6032：ProxySQL的管理端口，也就是配置端口，在数据库中配置即可 6033：ProxySQL是读写分离的调度服务器发布在外网的端口 使用mysql客户端连接到ProxySQL的管理接口6032，默认管理员用户和密码都 是admin： mysql -uadmin -padmin -P6032 -h127.0.0.1 3.配置proxysql 在main和monitor数据库中的表： 1.runtime_开头的是运行时的配置，不能修改；即生效的表 2.mysql_开头的是配置的表，配置完生效的就是runtime_开头的表了 3.修改mysql_开头的表后必须执行LOAD … TO RUNTIME才能加载到RUNTIME生效； 4.执行save … to disk将配置持久化保存到磁盘 4.向ProxySQL中添加MySQL节点，以下操作不需要use main也可成功 MySQL &gt; select * from mysql_servers; MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;10.10.0.5&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;10.10.0.6&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,&apos;10.10.0.7&apos;,3306); MySQL &gt; load mysql servers to runtime; MySQL &gt; save mysql servers to disk; 意思是先把所有的服务器节点都加入到一个主机组中，然后proxysql会根据my.cnf配置文件中的read-only,自动区分哪些是只读的，哪些是只写的数据库服务器 5.配置监控账号： a.在主节点上，创建监控账号 grant replication client on *.* to monitor@&apos;10.10.0.%&apos; identified by &apos;root123&apos;; 备注：replication client权限是负责监控的，和replication slave是不同的权限 b.Proxysql上配置监控 实际上是保存在global_variables表中，可以查看是否修改成功 MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;; MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;; c.使global_variables表生效 MySQL [mian]&gt; load mysql variables to runtime; MySQL [mian]&gt; save mysql variables to disk; 6.监控模块的指标保存在monitor库的log表中 MySQL [monitor]&gt; use monitor MySQL [monitor]&gt; select * from mysql_server_ping_log; 类似于ping命令，测试所有的数据库是不是连接成功的 mysql&gt; select * from mysql_server_connect_log; mysql&gt; select * from mysql_server_read_only_log; mysql&gt; select * from mysql_server_replication_lag_log; 查看read_only和replication_lag的监控日志 7.设置分组信息和读写规则 main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20 插入读写组的编号： insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;); +------------------+------------------+---------+ | writer_hostgroup | reader_hostgroup | comment | +------------------+------------------+---------+ | 10 | 20 | test | +------------------+------------------+---------+ 生效和保存： MySQL [monitor]&gt; load mysql servers to runtime; MySQL [monitor]&gt; save mysql servers to disk; 再次查看 select hostgroup_id,hostname,port,status,weight from mysql_servers; +--------------+-----------+------+--------+--------+ | hostgroup_id | hostname | port | status | weight | +--------------+-----------+------+--------+--------+ | 10 | 10.10.0.5 | 3306 | ONLINE | 1 | | 20 | 10.10.0.6 | 3306 | ONLINE | 1 | | 20 | 10.10.0.7 | 3306 | ONLINE | 1 | +--------------+-----------+------+--------+--------+ 8.创建用于测试读写分离的账号 主节点上创建访问用户： grant all on *.* to sqluser2@&apos;10.10.0.%&apos; identified by &apos;root1234&apos;; 在ProxySQL配置，将用户sqluser添加到mysql_users表中： insert into mysql_users(username,password,default_hostgroup)values(&apos;sqluser2&apos;,&apos;root1234&apos;,10); 生效和保存： MySQL [monitor]&gt; load mysql users to runtime; MySQL [monitor]&gt; save mysql users to disk; 此时通过mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033可以测试 创建和读取数据库信息，但是读写没有分离出来 9.配置路由规则，实现读写分离 与规则相关的表：mysql_qeury_rules 插入路由规则,实现读写分离的规则 insert into mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply) VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1); 分析： 将select语句分离到20的读组中, 但是在select语句中有一个特殊语句SELECT...FOR UPDATE它会申请写锁，应该属于写 组，所以应该排除在读组之外，放到写组中，放在前面是先匹配到后就放到写组了 (类似于iptables规则，谁在前，谁生效不看接下来的规则) 生效和保存到磁盘： load mysql query rules to runtime; save mysql query rules to disk; 10.用sqluser2测试读写分离效果 读： mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos; 因为是读操作会在2和3上随机选择 写： mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos; 事务是非select开头的，所以查询的都是1上 11.路由的信息：查询stats库中的stats_mysql_query_digest表 MySQL [monitor]&gt; use stats MySQL [stats]&gt; SELECT hostgroup hg,sum_time, count_star, digest_text FROM stats_mysql_query_digest ORDER BY sum_time DESC; +----+----------+------------+-----------------------------------+ | hg | sum_time | count_star | digest_text | +----+----------+------------+-----------------------------------+ | 10 | 100685 | 5 | select @@server_id | | 10 | 39916 | 2 | select @@server_id | | 20 | 25787 | 23 | select @@server_id | +----+----------+------------+-----------------------------------+ 可以看到通过不同的命令具体被调度到哪个数据上的信息 复制的问题和解决方案1. 数据损坏或丢失 Master： MHA + semi repl Slave： 重新复制 2. 混合使用存储引擎 MyISAM：不支持事务 InnoDB： 支持事务 3. 不惟一的server id 重新复制 4. 复制延迟 需要额外的监控工具的辅助 一从多主:mariadb10版后支持 多线程复制：对多个数据库复制]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lvs]]></title>
    <url>%2F2017%2F03%2F22%2Flvs%2F</url>
    <content type="text"><![CDATA[Cluster的集群的概念Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster集群的类型： LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure） MTBF:Mean Time Between Failure 平均无故障时间 MTTR:Mean Time To Restoration（ repair）平均恢复前时间 A=MTBF/（MTBF+MTTR） (0,1)：99%, 99.5%, 99.9%, 99.99%, 99.999% HPC：High-performance computing，高性能 www.top500.org 调度算法： 分布式系统： 作用：因为seesion和cookie的 LB Cluster的实现根据工作的网络层次ISO模型可以分： 通信子网和资源子网 四层调度器：在内核级中，即ISO模型的下四层，完成请求报文的分析 转发，交换 LVS(ipvs),nginx(stream模块),HAProxy(mode tcp) 七层调度器：在用户空间中，即ISO模型的应用层上的 代理：proxy nginx(http_upstream)，HAProxy,ATS,Envoy,Traefik 硬负载：F5,BigIP,Netscaler,Citrix 四层调度的工作过程： 因为tcp/ip协议栈是在内核中的，四层调度是工作在下四层的,四层调度器只需要分析用 户的请求报文中的网络层(目标IP)和传输(目标端口)是什么，就可以做出调度决策，这个 请求报文就不会进入到调度器的用户空间中，而只是在内核空间中分析进而又通过内核进 行转发传输出去了.而用户的请求报文是没有被更改过的，因为调度是在内核中完成的，所以四层调度也叫内核级调度. 四层调度不受限于客户端套接字，最大支持400w个并发 七层调度的工作原理： 详见nginx七层调度工作原理 七层调度因为要与后端服务器进行通信，就需要使用套接字，则最大能使用4W个socket 而绝大多数的网站最多也就4W个并发，即使七层调度最大支持4w个并发，如果是使用短连接，长连接默认60s，所以网站一天也可以有4w*2*86400个请求，弹性计算可以支持峰值 过去之后的服务器资源伸缩. 负载均衡和会话保持只要提到负载均衡那么会话保持也是必然要提到的问题 session保持的三种方式： session sticky:seesion粘性 1.基于客户端IP做hash将seesion保存在一台服务器上，如果是SNAT网络则IP是 一样的，seesion的颗粒度过于粗糙.(SH算法) 2.cookie机制即使是在通过SNAT网络中，不同的浏览器客户端也会被识别为不同 客户端，seesion的颗粒度精细的多.nginx可以识别应用层的cookie信息， 完全可以基于cookie信息做会话绑定的.而cookie是应用层数据，工作在四层的LVS是识别不了的，而七层的nginx只有商业版支持.但是同样是七层的HAproxy可以实现！！！ seesion既损害负载均衡效果，又可能造成seesion丢失(后端服务器down机) seesion replication server(cluster):seesion复制集群 在同一集群中，session是共享的，但是对内存的消耗比较大,但传输是由延迟的 把自己的seesion复制给集群的其他主机，这样seesion集群中的每个主机都会拥有 集群中所有服务器的seesion. 只适合于网站架构初创阶段！！！ session server: 把用户访问的seesion保存单独的一台服务器，通过api调用这个服务器，如redis, memcached，squid等，还是做redis集群保证seesion的安全 但是session的冗余实现比较麻烦和cookie(seesion sticky的另外一种表现) LVS的模型原理:Linux Virtual Server 1.LVS是工作四层，也就是内核中完成调度的,而且源代码也被整合到内核中，就像iptables的 netfilter一样，需要把写的规则送到内核中才能够生效. 2.依赖于内核中的LVS模块和LVS的调度算法模块，需要将集群的定义发送到内核中，并指明 使用哪种调度算法. 3.ipvs在内核中类似netfilter的框架，而ipvsadm是工作在用户空间用来生成规则的命令行 工具，然后送到内核的ipvs上，进而生效的 4.ipvs是工作在INPUT链上的，因为客户端请求的是调度器的VIP地址，必然会被送到INPUT链 而ipvs发现请求的是某个集群服务的，会强行将请求报文送到FORWARD链上，这样就实现 了转发的效果，而不进入LVS的用户空间. 5.所以需要事先在ipvs上放置一些集群的规则，才能实现转发FORWARD或者POSTROUTING链 所以iptables和ipvs在INPUT最好不要同时存在规则. LVS的组成和相关术语LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。 1.ipvs(ip virtual server)：一段代码工作在内核空间，叫ipvs， 是真正生效实现调度的代码。 2. ipvsadm：另外一段是工作在用户空间，叫ipvsadm，负责为ipvs内核框架编写规则， 定义谁是集群服务，而谁是后端真实的服务器(Real Server) 相关术语： 1. DS：Director Server。指的是前端负载均衡器节点。 2. RS：Real Server。后端真实的工作服务器。 3. VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 4. DIP：Director Server IP，主要用于和内部主机通讯的IP地址。 5. RIP：Real Server IP，后端服务器的IP地址。 6. CIP：Client IP，访问客户端的IP地址。 LVS的调度算法WLC是LVS的默认调度算法 在定义调度算法时，要根据实际情况使用合适的调度算法. lsmod | grep ipvs modinfo ip_vs 静态算法和动态算法的区别： 动态算法对系统资源消耗更多，调度效果更慢，但调度效果要好的多.原因在于动态算法 讲究结果公平，静态算法讲究起点公平 静态算法： 区别： 1.仅根据算法本身和请求报文特征进行调度，实现短连接 静态算法的实现： 1.RR:round-robin,是对RS群的轮询，按依次循环的方式将请求调度到不同的服务器上,该算法最大的特点就是实现简单且假设所有的服务器处理请求的能力都一样，调度器会将所有的请求平均分配给每个RS,只关注RS群的个数 2.WRR:weighted rr,权重/加权轮询，加权轮调是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1，服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。短连接 静态算法中的hash算法 对源地址/目标地址进行hash(md5,sha1等)计算然后对后端服务器集群的权重取模，模是 多少，就被调度到哪台后端服务器上. 3.SH: source ip hashing 源地址hash 地址绑定：对访问的源地址进行hash值计算(所谓hash就是IP的MD5或者SHA计算的值)，而只要访问的IP地址不变那么hash的结果对权重之和取模的结果一定也是不变的，如果再次访问时就会再被调度到RS上，所以地址绑定机制实现了session的sticky的会话保持。 缺点： 对于SNAT网络来说，地址绑定的机制会对LVS的工作造成极大的问题在权重模型下的工作逻辑是一样的 适用场景： 在没有使用会话共享的又需要保存会话的环境下（如电子商务网站），建议使用此算法。 4.DH: destination ip hashing 目标地址hash sh是为了追踪并保持会话的，而DH 对访问的解析的地址，进行hash值计算/权重，根据权重分配到某个RS上 动态算法： 区别： 1.不仅根据算法本身和请求报文特征进行调度 2.还要额外考虑后端各RS服务器当前的负载状态，消耗的资源更多 3.动态算法需要对后端服务集群的状态进行采样,考虑到后端每一台服务器的活动连接和非活动连接数以及空闲连接数，统计的值叫overhead=value较小的RS将被调度，这样就实现资源的均衡调度 负载(overhead)的计算公式: overhead=activeconn(服务器当前活动连接数)*256+inactiveconns 正常情况下我们认为活动连接数消耗的资源是非活动连接的256倍，所以要乘以256，这样就可以得出后端服务器的当前负载情况了。 动态算法的实现： 5.LC:least connections 适用于长连接应用 Overhead=activeconns*256+inactiveconns 把新的连接请求分配到当前连接数最小的服务器，通过服务器当前活跃的连接数来估计服务器的情况。调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1；当连接中断或者超时，其连接数减1。 当然实际情况下，后端服务器的权重有可能是不一样的，所以就引入了WLC算法 6.WLC：Weighted LC，LVS的默认调度方法 叫加权最少连接，算法是： Overhead=(activeconns*256+inactiveconns)/weight 加权最少连接数是最小连接调度的优化，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 7.SED：Shortest Expection Delay,初始连接高权重优先，最短期望延迟 Overhead=(activeconns+1)*256/weight WLC算法表面上是合理的，但是当出现计算的overhead值(权重一样)是一样的或者集群刚刚启动时(此时activeconn和inactiveconn都是0， 那么overhead也都是0,那么第一个请求应该发给哪个后端服务器？ 如果权重一样可以自上而下发送给后端服务器即可，如果权重不一样，而且刚好权重最小的在最上面，如果把请求分配给它，那么处理速度就会慢 而我们期望的是由权重大的是处理第一个请求，所有就有了SED算法的出现. SED是如何实现让权重最大的接收处理第一个请求的？ Overhead=(activeconns+1)*256/weight SED算法不再考虑非活动连接状态，把当前活动连接的数目+1除以服务器的权值，此时的计算方法会因为权重大的值反而overhead值越小，这样就实现了让权重大的优先处理请求的目的. 缺点： 如果权重比较大(1:9),那么前8个请求都是让权重为9的服务器来处理的， 如果刚好只有7个请求，那么权重为1的又会闲着，但是我们又不期望有服务器空闲，就有了nq算法. 8.nq:Never Queue，第一轮均匀分配，后续SED,SED的增强版 nq算法是对SED算法的弥补，第一轮都需要处理一个请求，后面再进来的请求再进行权重进行分配，这样所有的服务器都不会空闲,也叫永不排队算法 9.lblc:locality-Base LC，基于本地的最少连接算法，是DH算法的动态版 正向代理情形下的cache server的调度，该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器;若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用“最少链接”的原则选出一个可用的服务器，将请求发送到该服务器｡ 10.lblcr：Locality-Based Least-Connection with Replication 带复制功能的LBLC算法，它与LBLC算法的不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射｡该算法根据请求的目标IP地址找出该目标IP地址对应的服务器组，按”最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器｡同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。]]></content>
      <categories>
        <category>LB</category>
      </categories>
      <tags>
        <tag>LB</tag>
      </tags>
  </entry>
</search>
