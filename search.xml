<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Rook部署Ceph集群]]></title>
    <url>%2F2020%2F05%2F10%2FRook%E9%83%A8%E7%BD%B2Ceph%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"></content>
      <categories>
        <category>k8s</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-部署Redis集群]]></title>
    <url>%2F2019%2F05%2F16%2FKubernetes-%E9%83%A8%E7%BD%B2Redis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[k8s集群部署Redis Cluster更新于：19.6.18 1.redis cluster架构 1.redis高可用可以是主从+Sentinel或redis cluster，这里是部署redis cluster； 2.上图为redis集群的架构图，每个Master都可以拥有多个Slave。当Master下线后，Redis集群会从多个Slave中选举出一个新的Master作 为替代，而旧Master重新上线后变成新Master的Slave； 2.方案 1.这里采用github上的方案，项目地址: https://github.com/zuxqoj/kubernetes-redis-cluster 2.这个项目提供了两种部署Redis集群的方式： 在该项目的README.md中两个方式的部署链接： StatefulSet和 Service&amp;Deployment 3.使用statefulSet方案 在k8s上，对于像Mysql、redis、Mongodb、Zookeeper、es等有状态的服务，使用StatefulSet是首选方式，下面就是通过使用 StatefulSet进行redis集群; 3.StatefulSet控制器的基本要求 1.StatefulSet是为了解决Pod重启、迁移后，Pod的IP、主机名等网络标识会改变而带来的问题的，所以有以下基本要求： 1.每个实例具有唯一的网络标识符(有序的pod名称) 2.每一个Pod必须有唯一的持久存储 3.有序的部署和实例扩展 4.有序的删除和终止 5.有序的自动滚动更新(按照彼此之间的关联关系进行更新) 6.Headless service：ClusterIP=None 为了保证每个pod对象的使用持久且唯一的标识符，稳定的网络标志（包括Pod的hostname和DNS Records），使得Pod重新调度后也保持不变； 7.PVC template 每个Pod用到的存储卷必须使用有storageclass动态供给或由管理员事先创建好的PV 2.部署过程Statefulset based setupredis构建项目参考 前提准备： 1.上面链接是基于StatefulSet的Redis创建步骤： 1.创建NFS存储 2.创建PV 3.创建PVC(PVC由statefulSet自动创建并绑定PV) 4.创建Configmap 5.创建headless服务 6.创建Redis StatefulSet 7.初始化Redis集群 2.备注： 这个项目中的yaml清单中都是创建在default名称空间下，我这里做一下修改都创建在redis-ns名称空间中，下文中的yaml清单和项目 中并不完全一样! 3.项目所需的redis镜像和版本 1.首先redis的版本应该是3.0以后的!!! 2.redis镜像来源： 1.可以下载项目中的kubernetes-redis-cluster/Docker-image/Dockerfile在本地构建redis镜像； 2.也可以在DockerHub上下载最新的redis镜像,这里推荐几个镜像： 官方：redis:lasted 第三方：redis:5.0-rc5-alpine3.8 1.创建NFS存储 内网服务器中192.168.34.118是专门提供NFS服务的主机，导出为redis准备的数据目录即可； ~]# mkdir /data/{redis-pv1,redis-pv2,redis-pv3,redis-pv4,redis-pv5,redis-pv6} #创建6个数据目录给6个redis-pod ~]# chmod 777 /data/redis-pv* -R #修改权限为777,避免权限问题 ~]# vim /etc/exports /data *(rw,no_root_squash) ~]# systemctl start nfs &amp;&amp; systemctl enable nfs #启动NFS 测试： 在k8s的随便一个Node上使用mount挂载然后测试是否可以读写操作 2.创建NFS静态供给PV 1.yaml清单参考项目下的：/persistentvolume/vol-*.yaml 2.提示：如果生产环境下实现了NFS的动态供给，这里创建静态PV的过程是不需要的，只需要在StatefulSet的volumeClaimTemplates中 填写NFS的SC即可，然后NFS会自动创建PV和PVC； 3.每一个Redis Pod都需要一个独立的PV来存储自己的数据，因此可以创建一个pv.yaml文件，包含6个PV： ~]# vim redis-pv.yaml apiVersion: v1 kind: PersistentVolume metadata: name: redis-pv1 labels: app: redis-pv spec: capacity: storage: 500Mi accessModes: - ReadWriteMany nfs: server: 192.168.34.118 path: &quot;/data/redis-pv1&quot; --- 做的修改： 1.下面5个PV省略粘贴， 2.项目中定义存储大小是1Gi大小，这里改成500Mi 3.pv的名称也做了相应修改，并且都加了label:app: redis-pv ~]# kubectl create -f redis-pv.yaml persistentvolume &quot;redis-pv1&quot; created persistentvolume &quot;redis-pv2&quot; created persistentvolume &quot;redis-pv3&quot; created persistentvolume &quot;redis-pv4&quot; created persistentvolume &quot;redis-pv5&quot; created persistentvolume &quot;redis-pv6&quot; created ~]# kubectl get pv 3.StatefuleSet中每个Pod使用的PVC说明： 注意： 1.StatefulSet中是无需管理员事先创建PVC的； 2.因为StatefulSet中的每个Pod的PVC是通过其中的PVC模板volumeClaimTemplates自动为每个Pod创建并关联存储大小合适的PV的! 4.创建Configmap 1.redis.conf配置文件参考：kubernetes-redis-cluster/redis.conf 将Redis的配置文件转化为Configmap，这是一种更方便的配置读取方式。配置文件redis.conf如下： ~]# vim redis.conf appendonly yes cluster-enabled yes cluster-config-file /var/lib/redis/nodes.conf cluster-node-timeout 5000 dir /var/lib/redis port 6379 ~]# kubectl create configmap redis-conf --from-file=redis.conf -n redis-ns #在redis-ns名称空间下创建conifgmap ~]# kubectl describe cm redis-conf -n redis-ns #确认configmap内容是对的 Name: redis-conf Namespace: redis-ns Labels: &lt;none&gt; Annotations: &lt;none&gt; Data ==== redis.conf: ---- appendonly yes cluster-enabled yes cluster-config-file /var/lib/redis/nodes.conf cluster-node-timeout 5000 dir /var/lib/redis port 6379 Events: &lt;none&gt; 5.创建Headless service 1.yaml清单参考项目下的：/statefulset-services/redis-headless.yaml Headless service是StatefulSet实现稳定网络标识的基础，需要管理员手动创建； ~]# vim redis-headless-service.yaml apiVersion: v1 kind: Service metadata: name: redis-headless-service namespace: redis-ns labels: app: redis spec: clusterIP: None ports: - name: redis-port port: 6379 selector: #使用两个标签来关联的后端redis-pod app: redis appCluster: redis-cluster #在redis-ns名称空间下创建此headless-service;service的名称做了一下修改； ~]# kubectl create -f redis-headless-service.yaml ~]# kubectl get svc redis-service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE redis-headless-service ClusterIP None &lt;none&gt; 6379/TCP 20s #可以看到此headless service创建好了； 6.创建6个redis集群节点 1.核心yaml清单参考：/statefulset/redis-statefulset.yaml 2.清单中利用StatefulSet创建6个副本的Redis集群节点，下面列出几处重点内容，完整内容参考该项目的清单： ~]# vim redis-statefulset.yaml ... name: redis-app namespace: redis-ns spec: serviceName: &quot;redis-headless-service&quot; replicas: 6 ... spec: terminationGracePeriodSeconds: 20 affinity: podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: - redis topologyKey: kubernetes.io/hostname ... volumeMounts: - name: &quot;redis-conf&quot; mountPath: &quot;/etc/redis&quot; - name: &quot;redis-data&quot; mountPath: &quot;/var/lib/redis&quot; volumes: - name: &quot;redis-conf&quot; configMap: name: &quot;redis-conf&quot; items: - key: &quot;redis.conf&quot; path: &quot;redis.conf&quot; volumeClaimTemplates: - metadata: name: redis-data spec: accessModes: [ &quot;ReadWriteMany&quot; ] resources: requests: storage: 300Mi yaml清单重要字段说明： 1.和项目中不同的是，把该资源都放在redis-ns名称空间下了； 2.replicas:6：redis的pod数量定义为6个 3.Affinity.podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution #1.使用反亲和性定义使得这6个redis-pod尽量不在一个Node上，从物理节点先保证redis是高可用的； 2.因为yaml中为每个redis都定义了两个label，使用matchExpressions使得如果node上已经有app:redis的pod时，就尽量不要 再向此node上调度，这两条都是保证高可用的方案； 4.volumeMounts:两个mount: 一个是将redis.conf配置文件configmap挂载到/etc/redis下； 一个是使用将redis的数据目录持久化到PVC上； 5.volumeClaimTemplates: StatefulSet需要使用PVC模板来为每个pod提供持久存储 6.serviceName: &quot;redis-headless-service&quot; headless-service的名称之前做过自定义修改，这里也需要改成一致的； ~]# kubectl apply -f redis-statefulset.yaml ~]# kubectl get pods -n redis-ns NAME READY STATUS RESTARTS AGE redis-app-0 1/1 Running 0 1h redis-app-1 1/1 Running 0 1h redis-app-2 1/1 Running 0 1h redis-app-3 1/1 Running 0 1h redis-app-4 1/1 Running 0 1h redis-app-5 1/1 Running 0 1h 备注： 1.如上，可以看到这些Pods在部署时是以StatefulSet的名字+{0..N-1}的顺序依次创建的; 2.而且只有当redis-app-0状态启动后达到Running状态之后，redis-app-1 才开始启动，其他几个pod也同样被依次创建运行的； 每个Pod都会得到集群内的一个DNS域名，格式为$(podname).$(service name).$(namespace).svc.cluster.local，也即是： redis-app-0.redis-headless-service.redis-ns.svc.cre.local redis-app-1.redis-headless-service.redis-ns.svc.cre.local redis-app-2.redis-headless-service.redis-ns.svc.cre.local redis-app-3.redis-headless-service.redis-ns.svc.cre.local redis-app-4.redis-headless-service.redis-ns.svc.cre.local redis-app-5.redis-headless-service.redis-ns.svc.cre.local 其中： cre.local是搭建k8s集群时自定义的集群后缀； ~]# kubectl get pvc -n redis-ns NAME STATUS VOLUME CAPACITY ACCESS MODES redis-data-redis-app-0 Bound redis-pv6 500Mi RWX redis-data-redis-app-1 Bound redis-pv2 500Mi RWX redis-data-redis-app-2 Bound redis-pv3 500Mi RWX redis-data-redis-app-3 Bound redis-pv4 500Mi RWX redis-data-redis-app-4 Bound redis-pv5 500Mi RWX redis-data-redis-app-5 Bound redis-pv1 500Mi RWX 注意： 1.get pvc可以看到6个pvc都被自动创建且绑定到了PV上； 2.而且PVC的名称命名是pvc名字+StatefulSet的名字{0..N-1}顺序创建的； ~]# kubectl get pv #get pv也可以看到每个都被绑定了，而且在CLAIM项中还显示该PV是绑定到哪个PVC上了，这里省略粘贴了； 7.初始化redis集群 1.redis集群初始化逻辑和工具： 1.由于将初始化逻辑写入Statefulset中，则是一件非常复杂而且低效的行为，所以在K8S上创建一个额外的容器，专门用于进行K8S集群内部某些服务的管理控制； 2.redis-trib.rb是官方提供的Redis-Cluster的管理工具,可以对上面6个redis-Pod进行集群初始化； 3.初始化逻辑： 在k8s上创建一个pod然后安装redis-trib.rb工具，redis集群初始化工具就由这个pod完成； 4.方法有两种： 1.k8s上运行一个ubuntu或者Centos基础镜像，然后登陆进去安装redis-trib.rb命令，这也是/zuxqoj/kubernetes-redis-cluster这个项目推荐使用的方式； 2.直接运行一个包含redis-trib.rb命令工具的镜像，这里推荐几个： racccosta/redis镜像 #在其内部已经安装好了redis-trib.rb 两种方式都会在下面介绍 2.创建包含redis-trib.rb工具的Pod 1.项目推荐：参考项目中的README-using-deployment.md ~]# kubectl run -i --tty ubuntu --image=ubuntu --restart=Never /bin/bash / # apt-get update / # apt-get install -y vim wget python2.7 python-pip redis-tools dnsutils / # pip install redis-trib #在Ubuntu容器中安装依赖环境和redis-trib.rb二进制命令，yum源可能会用影响，建议修改yum源； 2.下载redis-trib.rb命令镜像 ~]# docker pull racccosta/redis 3.使用redis-trib创建集群,分两步创建集群 先创建只有master节点的集群，再为每个master分别指定一个slave节点； 3.1.创建只有Master节点的集群： ~]# redis-trib.py create \ `dig +short redis-app-0.redis-headless-service.redis-ns.svc.cre.local`:6379 \ `dig +short redis-app-1.redis-headless-service.redis-ns.svc.cre.local`:6379 \ `dig +short redis-app-0.redis-headless-service.redis-ns.svc.cre.local`:6379 解释： 命令dig +short redis-app-0.redis-headless-service.redis-ns.svc.cre.local用于将Pod的域名转化为IP，这是因为redis-trib不支持域名来创建集群; 3.2.再为每个Master添加Slave： ~]# redis-trib.py replicate \ --master-addr `dig +short redis-app-0.redis-headless-service.redis-ns.svc.cre.local`:6379 \ --slave-addr `dig +short redis-app-3.redis-headless-service.redis-ns.svc.cre.local`:6379 ~]# redis-trib.py replicate \ --master-addr `dig +short redis-app-1.redis-headless-service.redis-ns.svc.cre.local`:6379 \ --slave-addr `dig +short redis-app-4.redis-headless-service.redis-ns.svc.cre.local`:6379 ~]# redis-trib.py replicate \ --master-addr `dig +short redis-app-2.redis-headless-service.redis-ns.svc.cre.local`:6379 --slave-addr `dig +short redis-app-5.redis-headless-service.redis-ns.svc.cre.local`:6379 #为3个master分别指定一个slave节点； 8.验证redis集群是否成功 ~]# kubectl exec -it redis-app-2 /bin/bash #随便连入一个redis-pod进行验证 root@redis-app-2:/data# /usr/local/bin/redis-cli -c 127.0.0.1:6379&gt; cluster nodes #查看集群信息 c15f378a604ee5b200f06cc23e9371cbc04f4559 192.168.169.197:6379@16379 master - 0 1526454835084 1 connected 10923-16383 96689f2018089173e528d3a71c4ef10af68ee462 192.168.169.204:6379@16379 slave d884c4971de9748f99b10d14678d864187a9e5d3 0 1526454836491 4 connected d884c4971de9748f99b10d14678d864187a9e5d3 192.168.169.199:6379@16379 master - 0 1526454835487 4 connected 5462-10922 c3b4ae23c80ffe31b7b34ef29dd6f8d73beaf85f 192.168.169.198:6379@16379 myself,master - 0 1526454835000 3 connected 0-5461 c8a8f70b4c29333de6039c47b2f3453ed11fb5c2 192.168.169.201:6379@16379 slave c3b4ae23c80ffe31b7b34ef29dd6f8d73beaf85f 0 1526454836000 3 connected 237d46046d9b75a6822f02523ab894928e2300e6 192.168.169.200:6379@16379 slave c15f378a604ee5b200f06cc23e9371cbc04f4559 0 1526454835000 1 connected 127.0.0.1:6379&gt; cluster info cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 cluster_size:3 cluster_current_epoch:4 ... 注意： 从cluster nodes的信息看到每个redis节点是使用IP：Port端口通信的，为什么不是使用pod的Name呢，statefulSet的意义何在？在文章最后解释； 9.验证NFS上的redis数据目录是否有数据 ~]# ls /data/redis-pv1 appendonly.aof dump.rdb nodes.conf 10.创建用于访问的redis-cluster的Service 三个service区别： 1.前面Headless-Service只是为StatefulSet控制器为每个Pod提供稳定的网络标记，并不能作为redis-cluster集群的访问入口； 2.所以需要再创建一个Service为这个redis-cluster集群作为其他应用的访问入口和负载均衡； 3.而且这个redis-cluster是为k8s集群内部使用的，所以service只需要是ClusterIP类型的即可； 4.当然也可以再创建一个NodePort类型的service让k8s集群外的应用能够访问redis-cluster，下文会解释这方法搭建的redis集群只能为k8s集群内部使用，不能提供为k8s集群外的服务! ~]# vim redis-access-service.yaml apiVersion: v1 kind: Service metadata: name: redis-access-service namespace: redis-ns labels: app: redis spec: ports: - name: redis-port protocol: &quot;TCP&quot; port: 6379 #此service的端口 targetPort: 6379 #后端代理pod的端口 selector: app: redis appCluster: redis-cluster 解释： 该Service名称为redis-access-service，在k8s集群中暴露6379端口，并且会对labels name为app: redis或appCluster: redis-cluster的pod进行负载均衡 ~]# kubectl apply -f redis-access-service.yml ~]# kubectl get svc redis-access-service -n redis-ns -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR redis-access-service ClusterIP 10.20.101.172 &lt;none&gt; 6379/TCP 41m app=redis,appCluster=redis-cluster #在k8s集群中，所有应用都可以通过10.20.101.172:6379来访问Redis集群,NodePort的service也是同样方式创建即可； 11.测试主从切换 1.将redis集群迁移到k8s集群上，最大的问题就是Redis集群原有的高可用机制是否正常； 2.下文以master节点redis-app-2为例，进行主从切换测试 ~]# kubectl get pods redis-app-2 -o wide NAME READY STATUS RESTARTS AGE IP NODE redis-app-2 1/1 Running 0 20s 192.168.10.20 k8s-node2 #先看一下此时redis-app2的pod的IP地址是192.168.10.20 ~]# kubectl exec -it redis-app-2 /bin/bash #连接到redis-app2 root@redis-app-2:/data# /usr/local/bin/redis-cli -c 127.0.0.1:6379&gt; role 1) &quot;master&quot; 2) (integer) test 3) 1) 1) &quot;192.168.20.131&quot; 2) &quot;6379&quot; 3) &quot;test&quot; #如上可以看到，其为master，slave为192.168.20.131即redis-app-5； 3.手动删除redis-app-2： ~]# kubectl delete pods redis-app-2 pod &quot;redis-app-2&quot; deleted ~]# kubectl get pods redis-app-2 -o wide NAME READY STATUS RESTARTS AGE IP NODE redis-app-2 1/1 Running 0 20s 192.168.10.31 k8s-node2 #可以看到redis-app2重建之后IP地址变为192.168.10.31了； ~]# kubectl exec -it redis-app-2 /bin/bash root@redis-app-2:/data# /usr/local/bin/redis-cli -c 127.0.0.1:6379&gt; role 1) &quot;slave&quot; 2) &quot;192.168.20.131&quot; 3) (integer) 6379 4) &quot;connected&quot; 5) (integer) 8960 127.0.0.1:6379&gt; #redis-app2重建后，角色变成了slave，而它的master是192.168.20.131即redis-app-5； 12.此方法搭建redis-cluster的疑问： 1.在第8步时说过从cluster-nodes的信息看到每个redis节点是使用IP：Port端口通信而不是使用StatefulSet的pod的Name! 那么Pod通信时没有使用稳定的标志，Redis-Pods间又是如何实现正常的故障转移呢？ 2.原因： 1.这是因为Redis本身的机制，在Redis集群中每个节点都有自己的NodeId（保存在自动生成的nodes.conf中），并且该NodeId不会 随着IP的变化和变化，这其实也是一种固定的网络标志。也就是说，就算某个Redis-Pod重启了，该Pod依然会加载保存的NodeId来维持 自己的身份； 3.我们可以在NFS上查看redis-app-1的nodes.conf文件： ~]# vim /data/redis-pv1/nodes.conf 96689f2018089173e528d3a71c4ef10af68ee462 192.168.169.209:6379@16379 slave d884c4971de9748f99b10d14678d864187a9e5d3 0 1526460952651 4 connected ...后文省略 其中： 1.第一列为NodeId，稳定不变；第二列为IP和端口信息，可能会改变； 2.NodeId的两种使用场景： 1.当某个Slave-Pod断线重连后IP改变，但是它的Master发现其NodeId依旧，就认为该Slave还是之前的Slave。 2.当某个Master Pod下线后，集群在其Slave中选举出一个成为Master。待旧Master上线后，集群发现其NodeId依旧，会让旧Master变成新Master的slave； 可以通过上面的方式对这两种情况进行验证，观察redis的日志记录即可验证； 13.搭建redis集群时可能会出现的问题： 如果pip install安装的redis-trib是0.6.1版本的，在执行redis-trib create命令时会报下面这个错误： TypeError: sequence index must be integer, not &apos;slice&apos; 解决方法： 1.pip list | grep redis-trib 2.pip uninstall redis-trib 3.pip install redis-trib==0.5.1 错误解决issues详见： https://github.com/TykTechnologies/tyk-kubernetes/issues/16 14.此方法搭建redis-cluster的局限性： 1.无法为k8s集群外的应用服务； 这个方案只能提供给k8s集群内的应用使用，对集群外的应用根本用不了，因为一旦涉及到move命令，redis节点只会给出内部的pod ip， 这个使得集群外的应用根本连不上，因为这个涉及到redis的源码，redis集群节点的相互通讯使用的redis进程所在的环境的ip， 而这个ip就是pod-ip，相对的节点发送给客户端的move的ip也是pod ip;]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-部署zookeeper集群]]></title>
    <url>%2F2019%2F01%2F28%2FKubernetes-%E9%83%A8%E7%BD%B2zookeeper%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[k8s集群部署zookeeper集群更新于：19.2.18 环境要求： 1.k8s集群至少3个node节点让zk分散调度到3台节点上，zookeeper是有状态应用，需要将数据保存在NFS持久保证数据的安全性； 2.版本： zookeeper版本更新慢，之前使用3.4.5的版本时发现性能比较低还存在一些bug，所以此次在k8s生成环境安装的是3.4.12版本； 1.准备镜像和NFS共享目录 ~]# docker pull elevy/slim_java:8 #这是一个基于alpine构建的java8基础环境 ~]# docker tag elevy/slim_java:8 192.168.1.101/baseimage/elevy_slim_java:8 ~]# docker push 192.168.1.101/baseimage/elevy_slim_java:8 #上传到本地harbor上 2.在192.168.1.117主机的/data下使用NFS共享3个目录 ~]# yum install nfs-utils -y ~]# mkdir /data/{zk-datadir-1,zk-datadir-2,zk-datadir-3} #为3个zookeeper创建其数据目录 ~]# chmod 777 zk-datadir* -R #修改权限为777,避免权限问题 ~]# vim /etc/exports /data *(rw,no_root_squash) ~]# systemctl start nfs &amp;&amp; systemctl enable nfs #启动NFS 1.制作zookeeper镜像zookeeper历史版本下载地址 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491.关于制作zookeeper镜像：自己定制或在dockerHub上下载 1.dockerHub下载 ~]# docker pull zookeeper:3.4.12 #直接拉取使用官方镜像 #官方的zookeeper:3.4.12就是一个可以构建成zk集群的镜像，因为在它的entrypoint脚本中有ZOO_SERVERS用来判断yaml清单是否传入了zk集群的信息，所以如果使用官方镜像，需要在每个zk的depolyment中使用ENV：ZOO_SERVERS指定；如： env: - name: ZOO_SERVERS value: server.1=zk1:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 这一变量和entrypoint.sh下面这段判断有关，将zk集群信息添加到zoo.cfg中 # for server in $ZOO_SERVERS; do # echo &quot;$server&quot; &gt;&gt; &quot;$CONFIG&quot; # done 2.使用Dockerfile自己制作 1.基础镜像可以使用centos、Ubuntu、Alpine等，因为生产中需要使用centos，所以这里以centos为例，下文还会附带使用Alpine linux这个最小镜像制作方法； 2.这里自己构建的zk镜像和官方镜像的区别在于将zk集群信息写入zoo.cfg的方式： env: - name: SERVERS value: &quot;zookeeper1,zookeeper2,zookeeper3&quot; 这一变量和entrypoint.sh下面这段判断有关，将zk集群信息添加到zoo.cfg中 if [ -n &quot;$SERVERS&quot; ]; then IFS=\, read -a servers &lt;&lt;&lt;&quot;$SERVERS&quot; for i in &quot;$&#123;!servers[@]&#125;&quot;; do printf &quot;\nserver.%i=%s:2888:3888&quot; &quot;$((1 + $i))&quot; &quot;$&#123;servers[$i]&#125;&quot; &gt;&gt; $CONFIG done fi2.使用Dockerfile制作zookeeper镜像 ~]# tree zookeeper/ #ZK的Dockerfile目录 zookeeper/ ├── build-command.sh ├── bin │ └── zkReady.sh ├── conf │ ├── log4j.properties │ └── zoo.cfg ├── Dockerfile ├── entrypoint.sh #entrypoint脚本 └── zookeeper-3.4.13.tar.gzz ~]# chmod a+x bin/zkReady.sh &amp;&amp; chmod a+x entrypoint.sh #将脚本提前加权限，避免在容器中运行报权限相关的错误； ~]# vim conf/zoo.cfg #修改好的zoo.cfg文件 tickTime=2000 initLimit=10 syncLimit=5 dataDir=/zookeeper/data dataLogDir=/zookeeper/logs #snapCount=100000 autopurge.purgeInterval=1 clientPort=2181 quorumListenOnAllIPs=true 备注： 这里没准备zk集群的设置，后面需要使用脚本自己生成； ~]# vim conf/log4j.properties #修改好的log4j.properties 文件 zookeeper.root.logger=INFO, CONSOLE, ROLLINGFILE zookeeper.console.threshold=INFO zookeeper.log.dir=/zookeeper/logs zookeeper.log.file=zookeeper.log zookeeper.log.threshold=INFO zookeeper.tracelog.dir=/zookeeper/logs zookeeper.tracelog.file=zookeeper_trace.log ~]# vim entrypoint.sh #!/bin/bash set -e #if [[ &quot;$1&quot; = &apos;zkServer.sh&apos; &amp;&amp; &quot;$(id -u)&quot; = &apos;0&apos; ]]; then # chown -R &quot;$ZOO_USER&quot; &quot;$ZOO_DATA_DIR&quot; &quot;$ZOO_DATA_LOG_DIR&quot; # exec su-exec &quot;$ZOO_USER&quot; &quot;$0&quot; &quot;$@&quot; #fi if [[ ! -f &quot;$ZOO_CONF_DIR/zoo.cfg&quot; ]]; then CONFIG=&quot;$ZOO_CONF_DIR/zoo.cfg&quot; echo &quot;clientPort=$ZOO_PORT&quot; &gt;&gt; &quot;$CONFIG&quot; echo &quot;dataDir=$ZOO_DATA_DIR&quot; &gt;&gt; &quot;$CONFIG&quot; echo &quot;dataLogDir=$ZOO_DATA_LOG_DIR&quot; &gt;&gt; &quot;$CONFIG&quot; echo &quot;tickTime=$ZOO_TICK_TIME&quot; &gt;&gt; &quot;$CONFIG&quot; echo &quot;initLimit=$ZOO_INIT_LIMIT&quot; &gt;&gt; &quot;$CONFIG&quot; echo &quot;syncLimit=$ZOO_SYNC_LIMIT&quot; &gt;&gt; &quot;$CONFIG&quot; echo &quot;maxClientCnxns=$ZOO_MAX_CLIENT_CNXNS&quot; &gt;&gt; &quot;$CONFIG&quot; # for server in $ZOO_SERVERS; do # echo &quot;$server&quot; &gt;&gt; &quot;$CONFIG&quot; # done fi #if [[ ! -f &quot;$ZOO_DATA_DIR/myid&quot; ]]; then # echo &quot;$&#123;MYID:-1&#125;&quot; &gt; &quot;$ZOO_DATA_DIR/myid&quot; #fi echo $&#123;MYID:-1&#125; &gt; &quot;$ZOO_DATA_DIR/myid&quot; if [ -n &quot;$SERVERS&quot; ]; then IFS=\, read -a servers &lt;&lt;&lt;&quot;$SERVERS&quot; for i in &quot;$&#123;!servers[@]&#125;&quot;; do printf &quot;\nserver.%i=%s:2888:3888&quot; &quot;$((1 + $i))&quot; &quot;$&#123;servers[$i]&#125;&quot; &gt;&gt; $CONFIG done fi exec &quot;$@&quot; 作用： 1.entrypoint脚本用来判断是否有zoo.cfg和myid配置文件的，如果没有就自动生成; 2.构建zk集群的myid文件，如果$MYID为空的话，就设置zk的myid为1；MYID是在yaml清单中引用的变量，见下文 3.$SERVERS的作用： SERVERS这一段if判断是为生成zk集群准备的，部署单机zk这个变量没实际作用，主要是为了在k8s中部署yaml使用ENV中SERVERS这个变量然后生成zk集群的zoo.cfg中的信息，如： server.1=zk1:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 4.如果需要使用zookeeper进行zk，可以开启上面脚本中关于创建zookeeper用户的部分； ~]# vim Dockerfile FROM 192.168.1.101/serverbase/centos-jdk-162:v1 MAINTAINER lk &quot;645150765@qq.com&quot; RUN mkdir -p /zookeeper/data &amp;&amp; mkdir /zookeeper/logs ADD zookeeper-3.4.13.tar.gz /usr/local/src/ ADD entrypoint.sh /data/ COPY conf/* /usr/local/src/zookeeper-3.4.13/conf/ COPY bin/* /usr/local/src/zookeeper-3.4.13/bin/ RUN ln -sv /usr/local/src/zookeeper-3.4.13 /usr/local/zookeeper ENV PATH=/usr/local/zookeeper/bin:$&#123;PATH&#125; \ #传递默认变量 ZOO_DATA_DIR=/zookeeper/data \ ZOO_DATA_LOG_DIR=/zookeeper/logs \ ZOO_CONF_DIR=/usr/local/zookeeper/conf \ ZOO_PORT=2181 \ ZOO_TICK_TIME=2000 \ ZOO_INIT_LIMIT=5 \ ZOO_SYNC_LIMIT=5 \ ZOO_MAX_CLIENT_CNXNS=4096 \ JMXPORT=9010 \ # SERVERS=SERVERS=zk1,zk2,zk3 EXPOSE 2181 2888 3888 9010 ENTRYPOINT [&quot;/data/entrypoint.sh&quot;] CMD [&quot;/usr/local/zookeeper/bin/zkServer.sh&quot;,&quot;start-foreground&quot;] ~]# vim build-command.sh # #!/bin/bash tag=$1 docker build -t 192.168.1.101/baseimage/zookeeper:$&#123;tag&#125; . sleep 1 docker push 192.168.1.101/baseimage/zookeeper:$&#123;tag&#125; ~]# bash build-command.sh v1 #执行构建3.测试构建的zk镜像是否可用 ~]# docker run --name zk1 -d -P 192.168.1.101/baseimage/zookeeper:v1 ~]# docker ps -a | grep zk1 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 933826b14002 192.168.1.101/baseimage/zookeeper:v1 &quot;/data/entrypoint.sh…&quot; 13 minutes ago Up 13 minutes 2181/tcp, 2888/tcp, 3888/tcp, 9010/tcp zk1 #可以看到zk正常运行，2181/tcp也暴露出来了； ~]# docker exec -it zk1 /bin/bash / # # ls /zookeeper/data/myid #myid文件自动生成了 # zkReady.sh ZooKeeper JMX enabled by default ZooKeeper remote JMX Port set to 9010 ZooKeeper remote JMX authenticate set to false ZooKeeper remote JMX ssl set to false ZooKeeper remote JMX log4j set to true Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: standalone ]# ss -tnl LISTEN 0 50 *:2181 LISTEN 0 50 *:9010 #因为此时只是单机zk，所以只有2181和JMX监控端口9010开启，zk集群间通信端口2888和syncLimit探测、选举的端口3888此时还没监听； 2.k8s上使用Deployment部署zookeeper集群123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355注意： 1.zk是java语言开发的，如果宿主机上内存资源不足，zk集群是无法正常工作的 2.PV是使用的NFS共享；1.zookeeper的yaml目录结构 ~]# tree zookeeper/ zookeeper/ ├── pv │ ├── zookeeper-persistentvolumeclaim.yaml #PVC模板 │ └── zookeeper-persistentvolume.yaml #PV清单 └── zookeeper.yaml #depolyment-zk集群清单2.创建PV和PVC 2.1.创建PV ~]# vim pv/zookeeper-persistentvolume.yaml #查看PV清单 apiVersion: v1 kind: PersistentVolume metadata: name: zookeeper-datadir-1 spec: capacity: storage: 300Gi accessModes: - ReadWriteOnce nfs: server: 192.168.1.117 path: /data/zk-datadir-1 #nfs共享的zk1目录 --- apiVersion: v1 kind: PersistentVolume metadata: name: zookeeper-datadir-2 spec: capacity: storage: 300Gi accessModes: - ReadWriteOnce nfs: server: 192.168.1.117 path: /data/zk-datadir-2 #nfs共享的zk2目录 --- apiVersion: v1 kind: PersistentVolume metadata: name: zookeeper-datadir-3 spec: capacity: storage: 300Gi accessModes: - ReadWriteOnce nfs: server: 192.168.1.117 path: /data/zk-datadir-3 #nfs共享的zk3目录 ~]# kubectl apply -f zookeeper-persistentvolume.yaml ~]# kubectl get pv NAME CAPACITY ACCESS MODES RECLIAN POLICY STATUS zookeeper-datadir-1 300Gi RWO Retain Available zookeeper-datadir-2 300Gi RWO Retain Available zookeeper-datadir-3 300Gi RWO Retain Available #验证PV创建成功，PV是集群级别的资源不用指定namespace 2.1.创建PVC ~]# vim zookeeper-persistentvolumeclaim.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: zk-pvc-1 namespace: cre spec: accessModes: - ReadWriteOnce resources: requests: storage: 200Gi --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: zk-pvc-2 namespace: cre spec: accessModes: - ReadWriteOnce resources: requests: storage: 200Gi --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: zk-pvc-3 namespace: cre spec: accessModes: - ReadWriteOnce resources: requests: storage: 200Gi ~]# kubectl apply -f zookeeper-persistentvolumeclaim.yaml #创建PVC ~]# kubectl get pvc -n cre NAME STATUS VOLUME CAPACITY ACCESS MODES zk-pvc-1 Bound zookeeper-datadir-1 200Gi RWO zk-pvc-2 Bound zookeeper-datadir-2 200Gi RWO zk-pvc-3 Bound zookeeper-datadir-3 200Gi RWO #确认PVC已经Bound了PV，ZK的数据相对还是较大的，这里指定了200G，而且PVC是namespace级别的资源；3.创建zk集群 ~]# vim zookeeper.yaml apiVersion: v1 kind: Service metadata: name: zookeeper namespace: cre spec: ports: - name: client port: 2181 # clusterIP: None selector: app: zookeeper --- apiVersion: v1 kind: Service metadata: name: zookeeper1 namespace: cre spec: ports: - name: client port: 2181 - name: followers port: 2888 - name: leader-election port: 3888 # clusterIP: None selector: app: zookeeper server-id: &quot;1&quot; --- apiVersion: v1 kind: Service metadata: name: zookeeper2 namespace: cre spec: ports: - name: client port: 2181 - name: followers port: 2888 - name: leader-election port: 3888 # clusterIP: None selector: app: zookeeper server-id: &quot;2&quot; --- apiVersion: v1 kind: Service metadata: name: zookeeper3 namespace: cre spec: ports: - name: client port: 2181 - name: followers port: 2888 - name: leader-election port: 3888 # clusterIP: None selector: app: zookeeper server-id: &quot;3&quot; --- kind: Deployment apiVersion: extensions/v1beta1 metadata: name: zookeeper1 namespace: cre spec: replicas: 1 template: metadata: labels: app: zookeeper server-id: &quot;1&quot; spec: volumes: - name: data emptyDir: &#123;&#125; - name: wal emptyDir: medium: Memory containers: - name: server image: 192.168.1.101/baseimage/zookeeper:v1 imagePullPolicy: Always env: - name: MYID value: &quot;1&quot; - name: SERVERS value: &quot;zookeeper1,zookeeper2,zookeeper3&quot; - name: JVMFLAGS value: &quot;-Xmx2G&quot; ports: - containerPort: 2181 - containerPort: 2888 - containerPort: 3888 volumeMounts: - mountPath: &quot;/zookeeper/data&quot; name: zookeeper-datadir1 volumes: - name: zookeeper-datadir1 persistentVolumeClaim: claimName: zk-pvc-1 --- kind: Deployment apiVersion: extensions/v1beta1 metadata: name: zookeeper2 namespace: cre spec: replicas: 1 template: metadata: labels: app: zookeeper server-id: &quot;2&quot; spec: volumes: - name: data emptyDir: &#123;&#125; - name: wal emptyDir: medium: Memory containers: - name: server image: 192.168.1.101/baseimage/zookeeper:v1 imagePullPolicy: Always env: - name: MYID value: &quot;2&quot; - name: SERVERS value: &quot;zookeeper1,zookeeper2,zookeeper3&quot; - name: JVMFLAGS value: &quot;-Xmx2G&quot; ports: - containerPort: 2181 - containerPort: 2888 - containerPort: 3888 volumeMounts: - mountPath: &quot;/zookeeper/data&quot; name: zookeeper-datadir2 volumes: - name: zookeeper-datadir2 persistentVolumeClaim: claimName: zk-pvc-2 --- kind: Deployment apiVersion: extensions/v1beta1 metadata: name: zookeeper3 namespace: cre spec: replicas: 1 template: metadata: labels: app: zookeeper server-id: &quot;3&quot; spec: volumes: - name: data emptyDir: &#123;&#125; - name: wal emptyDir: medium: Memory containers: - name: server image: 192.168.1.101/baseimage/zookeeper:v1 imagePullPolicy: Always env: - name: MYID value: &quot;3&quot; - name: SERVERS value: &quot;zookeeper1,zookeeper2,zookeeper3&quot; - name: JVMFLAGS value: &quot;-Xmx2G&quot; ports: - containerPort: 2181 - containerPort: 2888 - containerPort: 3888 volumeMounts: - mountPath: &quot;/zookeeper/data&quot; name: zookeeper-datadir3 volumes: - name: zookeeper-datadir3 persistentVolumeClaim: claimName: zk-pvc-3 备注： 1.每个deployment中ENV的第一个变量MYID就是生成每个zk节点的myid文件； 2.第二个变量SERVERS就是在entrypoint脚本中为了生成zoo.cfg配置文件中的zk集群信息的； 3.每个zk节点的数据目录/data都使用volumeMounts挂载PVC； 4.service的问题参考文章最后 ~]# kubectl apply -f zookeeper.yaml4.验证zk集群状态 ~]# kubectl get pods -n cre #确保zk节点的pod都是运行的 NAME READY STATUS zookeeper1-7793b87sw-98ht6 1/1 Running zookeeper2-sk91b87sw-alht6 1/1 Running zookeeper3-2sk3b87sw-28hta 1/1 Running ~]# kubectl exec -it zookeeper1-7793b87sw-98ht6 sh -n cre / # / # df 192.168.1.117:/data/zk-datadir-1 /zookeeper/data / # vim /usr/local/zookeeper/conf/zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/zookeeper/data dataLogDir=/zookeeper/logs #snapCount=100000 autopurge.purgeInterval=1 clientPort=2181 quorumListenOnAllIPs=true server.1=zookeeper1:2888:3888 server.2=zookeeper2:2888:3888 server.3=zookeeper3:2888:3888 / # /usr/local/zookeeper/bin/zkServer.sh status ZooKeeper JMX enabled by default ZooKeeper remote JMX Port set to 9010 ZooKeeper remote JMX authenticate set to false ZooKeeper remote JMX ssl set to false ZooKeeper remote JMX log4j set to true Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: follower ~]# kubectl exec -it zookeeper2-sk91b87sw-alht6 sh -n cre ~]# kubectl exec -it zookeeper3-2sk3b87sw-28hta sh -n cre #一次连接每个zk-pod使用zkServer.sh status验证leader、follwer 备注： 1.使用df查看NFS共享的PVC是否挂载 2.确认每个zk-pod中的zoo.cfg中的zk集群信息是否生成： server.1=zookeeper1:2888:3888 server.2=zookeeper2:2888:3888 server.3=zookeeper3:2888:3888 这三行就是由entrypoint脚本通过调用yaml清单中的MYID和SERVERS两个变量生成的信息，zookeeper&#123;1,2,3&#125;就是yaml清单中3个service的name； 3.使用zkServer.sh status确认这三个pod是一个zk集群； 4.zk是java应用，确保k8s集群有足够的CPU、内存资源才能保证zk集群正常运行； 注意： zookeeper.yaml清单中的service是有要求的： 1.名为zookeeper的service是定义zk集群的svc; 2.名为zookeeper1、zookeeper2、zookeeper3的service是给每个zk节点准备的写在最后： 关于zookeeper.yaml清单中关于service的问题： service是否使用headless类型的?]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ceph存储]]></title>
    <url>%2F2019%2F01%2F18%2FCeph%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-Promethues监控]]></title>
    <url>%2F2019%2F01%2F15%2FKubernetes-Promethues%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[Kubernetes-Promethues更新于：19.1.15 –k8s的prometheus解决方案 1.特点： 1.高性能，数据库的特点 prometheus只作为高性能的数据存储系统，因为其内部自带了时序存储系统，而不像zabbix使用mysql或者Pgsql这样的关系型数据库； 2.promQL的查询接口 prometheus内置了强大的查询接口PromQL,用户可以通过http接口组合非常高级的查询条件从而获取prometheus采集数据； 3.Grafana展示界面 prometheus虽然有它内置的UI展示接口，不过不是聚合型的显示比较混乱所以一般都需要结合Grafana. 4.动态服务发现机制 能支持非常复杂的、高度并行的非常大的集群级别的监控，而且内嵌了弹性监控接口，支持自动发现机制发现每一个可被监控的对象，非常适合k8s这种容器频繁创建、销毁的大规模容器场景； 5.AlterManager:报警系统 prometheus的报警功能需要使用AlterManager来实现，而AlterManager的报警机制需要用户自己定义创建然后才能报警，这和zabbix很像； 2.如上图：prometheus的常用组件有： 这里只介绍prometheus的常见组件，在容器集群和非容器集群中，组件还是有些不同的，见下文：k8s上部署的prometheus组件； 1.Prometheus Server: 用于收集和存储时间序列数据。 2.Client Library: 客户端库，为需要监控的服务生成相应的metrics并暴露给Prometheus-server。当 Prometheus server来pull时，直接返回实时状态的metrics。 3.Push Gateway: 主要用于短期的jobs。由于这类jobs存在时间较短，可能在Prometheus来pull之前就消失了。为此，这次jobs可以直接向Prometheus-server端推送它们的metrics。这种方式主要用于服务层面的metrics，对于机器层面的metrices，需要使用node exporter。 4.Exporters: 用于暴露已有的第三方服务的metrics给Prometheus。 5.Alertmanager: 从Prometheus-server 端接收到alerts后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。常见的接收方式有：电子邮件，pagerduty，OpsGenie, webhook 等。 3.资源指标类型和prometheus获取数据方式 2.1.资源指标类型 1.核心指标：cadvisor/node_exporter 2.程序级指标；如：/metric 1.nginx内部程序级的各种指标数据； 2.Java中JVM内部各种GC的工作逻辑、堆内存当中的新生代、老年代的空间占用比例变动等； 3.业务级数据，如： nginx的并发连接数、接入请求数/s、处理的总的数量等； 2.2.获取数据指标的2种方式 1.主动拉取 prometheus是可以自动拉取数据的，只不过要使用 2.主动推送： 可以借助于推送网关（push gateway），让每一个被监控的系统将数据推送给网关以后，prometheus再由网关获取到数据； 4.prometheus需要在k8s上监控的对象和如何抓取数据？ 1.节点的指标数据： node_exporter： 是专用于节点级监控的程序相当于agent,每一个被监控的主机都需要部署一个node_exporter，它接收prometheus-server的拉取数据； cAdivisor(kubelet的组成部分): 1.可以采集节点和容器级的指标数据 2.prometheus可以把cAdvisor作为指标采集的节点，这样就不需要在节点上部署node_exporter了； 2.API Server 可以使用API Server收集各种性能数据：工作队列性能、etcd缓存性能； 3.etcd etcd有它自己restful风格的api接口，如果不使用k8s的api,就可以使用其自己的不过需要认证到etcd中； 4.Pod： 1.对于pod中程序级和业务级指标的监控只能使用各种exporter采集不同维度的监控指标；比如： mysql的select执行次数、慢查询语句、nginx的并发连接数等等 通过node_exporter和cAdvisor是做不到的，这时就需要依靠程序自身对外输出； 2./metric 1.对于程序级指标是通过程序自身向外输出，输出方式： 有些程序内嵌了允许prometheus抓取的数据接口，这个接口需要通过http协议对外提供服务而且还需要有内嵌的url=/metrics，这个metrics就是用来输出当前内部的各种指标数据； 2.sidecar容器 但是对于类似mysql这种，由于它没有http不能提供/metrics，就需要使用辅助容器了，这个辅助容器可以连接到mysql容器，然后把需要监控的mysql相关指标转为http协议对外输出，然后prometheus就能获取到mysql的程序级指标了； 3.mysqld_exporter、mongodb_exporter、memcached_exporter 1.有些程序就内嵌了/metrics接口，但是有些复杂的应用程序，如mysql、mongodb等，prometheus直接为其提供了exporter程序，如：mysqld_exporter、haproxy_exporter； 2.可以把这些exporter程序直接运行为辅助容器，而不是使用sidecar这种方式，具体事例见mysqld_exporter; annotations: 为了使得使用/metric或者各种exporter获取指标数据的程序，可被prometheus动态抓取，一般来说： 1.如果以pod方式运行，需要在pod字段中添加annotation，作用在于：告诉prometheus-server：类似http://IP+PORT/url是输出指标数据的url； 1.prometheus.io/scrape： 1.如果加上这个annotations，表示当前pod是允许prometheus抓取数据的，如不加这个annotations，prometheus就不会自动把这个pod纳入到监控中； 2.scrape=true：允许抓取；scrape=flase：不允许抓取 2.prometheus.io/path 当scrape=true时，再加此annotation，表示当前Pod能够输出指标数据的Url; 默认：/metric 3.prometheus.io/port 抓取数据时使用的套接字端口，http:80/https:443 5.kube-state-metrics: 1.kube-state-metrics收集k8s集群内资源对象数据; 2.kube-state-metrics主要是用于：派生出k8s的相关的多个指标数据的，这个指标数据主要和计数器有关； 如： kube-system名称空间中pod的总数、整个k8s集群中pod的总数； 3.默认情况下k8s中没有此类指标，所以需要部署kube-state-metrics这个Pod用来： 专门搜集k8s上各种各样的计数数据，搜集完后自己做聚合计算并通过一个api对外输出； 5.其大概的工作流程是： 1.Prometheus-server定期从配置好的jobs或者exporters中拉metrics，或者接收来自 Pushgateway发过来的metrics，或者从其他的Prometheus-server中拉metrics。 2.Prometheus server在本地存储收集到的metrics，并运行已定义好的alert.rules，记录新的时间序列或者向Alertmanager推送警报。 3.Alertmanager根据配置文件，对接收到的警报进行处理，发出告警。 4.在图形界面中，可视化采集数据。 在kubernets上实现cAdvisors/exporter+Prometheus+Grafana部署1.部署注意事项： 1.prometheus是一个有状态应用，因此部署完prometheus以后不能够随意对其进行伸缩，除非使用了statefulSet/Prometheus Operator部署prometheus; 2.Prometheus Operator: prometheus-operator是CoreOS开源的一套用于管理在Kubernetes集群上的Prometheus控制器，它是为了简化在Kubernetes上部署、管理和运行Prometheus和Alertmanager集群。 3.使用kubernetes项目中的addons进行部署 测试时可以使用kubernetes/addons部署，生产环境尽量使用Prometheus Operator部署； 2.K8s上prometheus系统组件:按顺序部署 1.kube-state-metrics: kube-state-metrics可以通过kube-apiserver查询和统计整个k8s集群中需要的计数数据提供给prometheus使用，如 pod总数、处于Running状态的Pod等等； 部署： 通过deployment部署一个kube-state-metrics； 2.node_exporter:监听在9100端口 1.二进制程序： node_exporter是一个守护进程，可以部署为二进制程序使用systemctl/systemd来控制 2.DaemonSet 在k8s上，可以使用DaemonSet运行在每个node节点之上； 3.cAdvisor cAdvisor是内嵌在kubelet中的，不需要单独部署 4.AlterManager AlterManager也需要单独部署，在k8s上表现为一个单独的Pod; 5.Prometheus-Server Prometheus-Server通过exporters、kube-state-metrics、cAdvisor来采集数据，并存处于TSDB当中，内部可以通过报警管理器来评估、分析采集到的数据是否超出了合理区间，超出就触发报警器报警； 6.各种exporters: 对于复杂的应用程序，可以在部署程序时部署相关的exporters，exporter会将数据提交给prometheus； 3.自定义的指标服务器 有了上面5个必要组件它就是一个完整的监控系统，但依然不能作为自定义指标服务器使用，还需要部署下面这个组件： 1.为什么要使用自定义指标服务器，使用prometheus不就可以了？ 1.首先自定义指标采集只能由prometheus完成，其次由于prometheus提供的查询接口是PromQL，管理员如果想查采集到的数据是很困难的； 2.再其次k8s自己也无法对接PromQL接口，只能通过第三方的组件对接PromQL，而且这个第三方组件还有简单的restful风格的api，便于查询； 3.第三：k8s-prometheus-adapter实现pod的HPA(自动伸缩)的基础，HPA需要用到adapter所提供的restful风格的api; 2.k8s-prometheus-adapter: 1.k8s-prometheus-adapter程序也需要部署成一个Pod，它就是一个转换器，它提供restful风格的http协议API，客户端对adapter-api的查询请求会被转换成对prometheus的PromQL的查询请求； 2.k8s-prometheus-adapter就是一个自定义api-service,会被注册到kube-agrrate上，它作为k8s的自定义指标服务器是可以被HPA-v2调度以实现自动规模伸缩； 3.查询过程： 客户端&lt;--&gt;kube-apiserver（aggreation）&lt;--&gt;adapter-api-service&lt;--&gt;prometheus-PromQL 实现此类功能的开源项目还有很多，这里这介绍使用过的k8s-prometheus-adapter； 部署步骤这里使用kubernetes项目中的addons进行部署，地址： https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/prometheus 1.准备各个组件的yml清单 ~]# cd addons/prometheus #为了方便将各个组件yml清单单独存放 ~]# cd addons/prometheus/kube-state-metrics #计数统计相关 kube-state-metrics-rbac.yaml kube-state-metrics-service.yaml ~]# cd addons/prometheus/node-exporter #node_exporter相关 node-exporter-ds.yml #部分清单 hostNetwork: true #共享节点网络名称空间，所以能够监控节点信息 hostPID: true #共享节点的PID volumes: - name: proc hostPath: path: /proc #访问节点proc和sys目录获取监控信息 - name: sys hostPath: path: /sys node-exporter-service.yaml ~]# cd addons/prometheus/alertmanager #alteramanger报警相关 alertmanager-configmap.yamlyear alertmanager-deployment.yaml alertmanager-pvc.yaml alertmanager-service.yaml ~]# cd addons/prometheus/prometheus-server #prometheus-server清单 prometheus-configmap.yaml prometheus-rbac.yaml prometheus-service.yaml prometheus-statefulset.yaml 2.部署kube-state-metric和 node-exporter ~]# kubectl apply -f ../prometheus/kube-state-metric/ ~]# kubectl apply -f ../prometheus/node-exporter/ ~]# kubectl get pods -n kube-system kube-state-metric-7bddaldl-56k56 2/2 Running node-exporter-2ms9z node-exporter-zwrsz node-exporter-vkg4z #可以看到kube-state-metric部署了，每个节点也都部署了node-exporter ~]# kubectl get svc -n kube-system kube-state-metric ClusterIP 10.103.6.3 8080/TCP,8081/TCP node-exporter ClusterIP Node 9100/TCP #通过查看SVC可以看到，kube-state-metric监听在8080端口，node-exporter监听在9100端口； ~]# ss -tnl LISTEN 0 128 :::9100 :::* #node-exporter会监听在每个node节点的9100端口 查看是否获取到指标数据： ~]# curl http://192.168.34.118:9100/metrics #通过curl或者浏览器就访问节点的9100/metrics可以看到node-exporter通过/metrics获取到了数据； ~]# curl 10.103.6.3:8080/metrics #以看到kube-state-metric通过/metrics也获取到了数据 3.部署alertmanager alertmanager部署注意事项： 1.这里如果想在k8s集群外部访问altermanager,需要改一下svc的类型 2.查看alertmanager的PVC清单，实现准备好对应大小的PV； 3.新版的kubelet调用config-reload方式可能不兼容，所以把alertmanager-deployment中关于name: prometheus-alertmanager-configmap-reload这一段全部注释掉； ~]# vim alertmanager-service.yaml spec: ports : - name: http port: 80 protocol: TCP targetPort: 9093 nodePort: 30093 #type: &quot;ClusterIP type: &quot;NodePort&quot; ~]# kubectl apply -f ../prometheus/alertmanager/. ~]# kubectl get svc -n kube-system altermanager NodePort 10.99.170.210 80:30093/TCP #查看altermanager的SVC状态和暴露端口 测试访问： 访问：http://192.168.34.118:30093 #可以在其界面上定义各种alter报警服务； 4.部署prometheus-Server prometheus-Server部署注意事项： 1.这里部署方式是使用statefulSet进行部署的； 2.实现准备好volumeClaimTemplates中storage: &quot;16Gi&quot;大小的PV； 3.同样，想在k8s集群外部访问，也需要改一下prometheus-service.yaml清单中的SVC类型； 4.同样，新版的kubelet调用config-reload方式可能不兼容，所以把prometheus-statefulset.yaml中关于name: prometheus-server-configmap-reload这一段全部注释掉； ~]# cd ../prometheus/prometheus-server/ ~]# vim prometheus-service.yaml spec: ports : - name: http port: 9090 protocol: TCP targetPort: 9090 nodePort: 30090 #可以定义nodeport的端口，也可以随机生成 type: &quot;NodePort&quot; ~]# kubectl apply -f ../prometheus/prometheus-server/. ~]# kubectl get svc -n kube-system prometheus NodePort 10.109.21.102 9090:30090/TCP #查看altermanager的SVC状态和暴露端口 测试访问： 访问：http://192.168.34.118:30090 备注： prometheus-configmap.yaml清单中通过job_name定义了如何自动发现k8s中的： kubernetes-apiservers kubernetes-nodes-kubelet kubernetes-nodes-cadvisor kubernetes-service-endpoints kubernetes-services kubernetes-pods 资源并进行监控 alerting:报警系统也是在这个文件中定义的； –prometheus抓取到的数据–prometheus中已监控的targets 5.部署k8s-prometheus-adapter： 地址： https://github.com/DirectXMan12/k8s-prometheus-adapter 1.如上图中示：Execute下的各个参数是promQL的采集接口，Elament显示的结果就是PromQL的查询语言，而k8s是没办法自己对接这个PromQL，因此还需要部署一个组件：k8s-prometheus-adapter； 2.部署： ~]# git clone https://github.com/DirectXMan12/k8s-prometheus-adapter.git 注意： 1.在custom-metrics-apiserver-deployment.yaml清单中明确说明custom-metrics-apiserver这个自定义api与k8s的kube-apiserver通信是使用证书双向认证的，因此需要使用我们自己搭建的k8s集群中的ca.crt为其签署证书，并做成secret资源； args: - --secure-port=6443 - --tls-cert-file=/var/run/serving-cert/serving.crt - --tls-private-key-file=/var/run/serving-cert/serving.key - --logtostderr=true - --prometheus-url=http://prometheus.prom.svc:9090/ #promethues的svc所在的url，prom是名称空间 volumes: - name: volume-serving-cert secret: secretName: cm-adapter-serving-certs #挂载的secret名称 制作证书： ~]# cd /etc/kubernetes/pki ~]# openssl genrsa -out serving.key 2048 ~]# openssl req -new -key serving.key -out serving.csr -subj &quot;/CN=serving&quot; ~]# openssl x509 -req -in serving.csr -CA ./ca.crt -CAkey ./ca.key -CAcreateserial -out serving.crt -days 3650 转换成secret资源 ~]# kubectl create ns custom-metrics ~]# kubectl create secret generic cm-adapter-serving-certs --from-file=/etc/kubernetes/pki/serving.key -from-file=/etc/kubernetes/pki/serving.crt -n custom-metrics #这里使用generic类型的，因为需要保留它的名字而不是使用tls类型（都被转成tls.key和tls.crt） ~]# kubectl get secret -n custom-metrics cm-adapter-serving-certs Opaque 2 6s #可以看到cm-adapter-serving-certs做好的； 部署： ~]# cd /k8s-prometheus-adapter/deploy/manifests/ ~]# kubectl apply -f . 验证： ~]# kubectl api-versions custom.metrics.k8s.io/vabeta1 #自定义的api群组已经被创建了 ~]# kubectl get pods -n custom-metrics custom-metrics-apiserver-cksaisans-psnasna 1/1 Running #Pod也正常运行 到此通过k8s-prometheus-adapter部署的自定义指标服务器就创建好了； 3.测试： 向custom.metrics.k8s.io/vabeta1群组直接发送请求即可累出其可用的所有自定义指标，例如使用&quot;kubectl get --raw&quot;命令进行测试，并使用jq命令过滤，仅列出指标名称： ~]# kubectl get --raw &quot;/apis/custom.metrics.k8s.io/vabeta1&quot; {&quot;kind&quot;:&quot;APIResourceList&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;groupVersion&quot;:&quot;custom.metrics.k8s.io/vabeta1&quot;,&quot;resources&quot;:[]} #可以看到返回结果中&quot;resources&quot;:[]一直是空的？ 4.故障原因和解决 返回结果&quot;resources&quot;:[]一直是空的，经过查看kubectl logs custom-metrics-apiserver-cksaisans-psnasna -n custom-metrics这个Pod的输出日志，发现：查询api授权没通过？ 解决： 经过层层排查，发现custom-metrics-apiserver-deployment.yaml清单中 - --prometheus-url=http://prometheus.prom.svc:9090/，这里的prometheus是在prom名称空间，而我之前把prometheus部署在kube-system名称空间，所以会出错，将其改为： - --prometheus-url=http://prometheus.kube-system.svc:9090/ 5.再测试 ~]# yum install jq -y #安装json过滤器jsonquery工具 ~]# kubectl get --raw &quot;/apis/custom.metrics.k8s.io/vabeta1&quot; | jq . #这样输出时，就以好看的json格式显示了 或者 ~]# kubectl get --raw &quot;/apis/custom.metrics.k8s.io/vabeta1&quot; | jq &apos;resources[].name&apos; #只显示哪些自定义的资源指标可以使用 6.部署Grafana ~]# cd addons/prometheus/grafana ~]# vim grafana.yaml apiVersion: apps/v1 kind: StatefulSet metadata: name: grafana namespace: kube-system spec: serviceName: &quot;grafana&quot; replicas: 1 selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: containers: - name: grafana image: grafana/grafana resources: limits: cpu: 100m memory: 256Mi requests: cpu: 100m memory: 256Mi volumeMounts: - name: grafana-data mountPath: /var/lib/grafana subPath: grafana securityContext: fsGroup: 472 runAsUser: 472 volumeClaimTemplates: - metadata: name: grafana-data spec: storageClassName: managed-nfs-storage accessModes: - ReadWriteOnce resources: requests: storage: &quot;1Gi&quot; --- apiVersion: v1 kind: Service metadata: name: grafana namespace: kube-system spec: type: NodePort #这里也是nodePort类型，方便在k8s集群外访问 ports: - port: 80 targetPort: 3000 nodePort: 30080 selector: app: grafana ~]# kubectl apply -f grafana.yaml statefulset.apps/grafana created service/grafana created ~]# kubectl get pod,svc -n kube-system | grep grafana pod/grafana-0 1/1 Running 0 45s service/grafana NodePort 10.0.0.78 &lt;none&gt; 80:30080/TCP 44s #pod和svc已经就绪 访问： http://192.168.34.118:30080，接下来就是在grafana做各种设置了 登录：默认账号，密码都是admin 设置： 1.添加Data Soources 2.添加监控面板，这里有几个比较好的模板可以下载导入： 下载地址：https://grafana.com/grafana/download 集群资源监控模板：3119 集群资源监控模板：9276 集群资源监控模板：6417 –1.添加数据源–2.导入后的模板]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpd脚本]]></title>
    <url>%2F2018%2F12%2F30%2Fhttpd%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[httpd服务 httpd服务脚本#!/bin/bash # # httpd Startup script for the Apache HTTP Server # # chkconfig: - 85 15 # description: The Apache HTTP Server is an efficient and extensible \ # server implementing the current HTTP standards. # processname: httpd # config: /etc/httpd/conf/httpd.conf # config: /etc/sysconfig/httpd # pidfile: /var/run/httpd/httpd.pid # ### BEGIN INIT INFO # Provides: httpd # Required-Start: $local_fs $remote_fs $network $named # Required-Stop: $local_fs $remote_fs $network # Should-Start: distcache # Short-Description: start and stop Apache HTTP Server # Description: The Apache HTTP Server is an extensible server # implementing the current HTTP standards. ### END INIT INFO # Source function library. . /etc/rc.d/init.d/functions if [ -f /etc/sysconfig/httpd ]; then . /etc/sysconfig/httpd fi # Start httpd in the C locale by default. HTTPD_LANG=${HTTPD_LANG-&quot;C&quot;} # This will prevent initlog from swallowing up a pass-phrase prompt if # mod_ssl needs a pass-phrase from the user. INITLOG_ARGS=&quot;&quot; # Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server # with the thread-based &quot;worker&quot; MPM; BE WARNED that some modules may not # work correctly with a thread-based MPM; notably PHP will refuse to start. # Path to the apachectl script, server binary, and short-form for messages. apachectl=/usr/sbin/apachectl httpd=${HTTPD-/usr/sbin/httpd} prog=httpd pidfile=${PIDFILE-/var/run/httpd/httpd.pid} lockfile=${LOCKFILE-/var/lock/subsys/httpd} RETVAL=0 STOP_TIMEOUT=${STOP_TIMEOUT-10} # The semantics of these two functions differ from the way apachectl does # things -- attempting to start while running is a failure, and shutdown # when not running is also a failure. So we just do it the way init scripts # are expected to behave here. start() { echo -n $&quot;Starting $prog: &quot; LANG=$HTTPD_LANG daemon --pidfile=${pidfile} $httpd $OPTIONS RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch ${lockfile} return $RETVAL } # When stopping httpd, a delay (of default 10 second) is required # before SIGKILLing the httpd parent; this gives enough time for the # httpd parent to SIGKILL any errant children. stop() { status -p ${pidfile} $httpd &gt; /dev/null if [[ $? = 0 ]]; then echo -n $&quot;Stopping $prog: &quot; killproc -p ${pidfile} -d ${STOP_TIMEOUT} $httpd else echo -n $&quot;Stopping $prog: &quot; success fi RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f ${lockfile} ${pidfile} } reload() { echo -n $&quot;Reloading $prog: &quot; if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then RETVAL=6 echo $&quot;not reloading due to configuration syntax error&quot; failure $&quot;not reloading $httpd due to configuration syntax error&quot; else # Force LSB behaviour from killproc LSB=1 killproc -p ${pidfile} $httpd -HUP RETVAL=$? fi fi echo } # See how we were called. case &quot;$1&quot; in start) start ;; stop) stop ;; status) status -p ${pidfile} $httpd RETVAL=$? ;; restart) stop start ;; condrestart|try-restart) if status -p ${pidfile} $httpd &gt;&amp;/dev/null; then stop start fi ;; force-reload|reload) reload ;; graceful|help|configtest|fullstatus) $apachectl $@ RETVAL=$? ;; *) echo $&quot;Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|reload|status|fullstatus|grace ful|help|configtest}&quot; RETVAL=2 esac exit $RETVAL]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-Helm使用进阶]]></title>
    <url>%2F2018%2F12%2F23%2FKubernetes-Helm%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[Helm使用进阶[Helm基础参照此文] Helm使用进阶—3.Helm Chart结构一.Helm Chart结构 #Chart内部最重要的就是配置清单模板了 1.Chart目录结构 Chart/ Chart.yaml LICENSE README.md requirements.yaml values.yaml charts/ templates/ tamplates/NOTES.txt 2.Chart.yaml文件 name: [必须] Chart的名称 version: [必须] Chart的版本号，版本号必须符合SemVer2：http://semver.org/ description: [可选] Chart的简要描述 engine: gotpl # [可选] 模版引擎，默认值是gotpl home: [可选] 项目地址 icon: [可选] 一个SVG或PNG格式的图片地址URL链接 keywords: - [可选] 关键字列表,K/V格式列表 来说明这个chart是做什么的，search可以通过这个关键词搜索到这个chart sources: - [可选] 当前Chart的下载地址列表，代表这个chart是哪个仓库的哪个位置 maintainers: # [可选] - name: [必须] 名字 email: [可选] 邮箱 #数组列表，-可以写多个 version： [可选] 当前chart的版本，不应用程序的版本 3.requirements.yaml和charts目录 requirements.yaml 文件内容： dependencies: - name: example version: 1.2.3 repository: http://example.com/charts - name: Chart名称 version: Chart版本 repository: 该Chart所在的仓库地址 Chart支持两种方式表示依赖关系: 1.可以使用requirements.yaml定义每一个其他chart的名称、版本、别名等； #此方法可能被废弃了 2.直接使用charts/目录直接把被依赖的chart打包在当前的chart内部使用； 或者直接将依赖的Chart放置到charts目录中 4.templates目录： 1.各类Kubernetes资源的配置模板都放置在这里。Helm会将values.yaml中的参数值注入到模板中生成标准的YAML配置文件。 2.模板是chart最重要的部分，也是Helm最强大的地方。模板增加了应用部署的灵活性，能够适用不同的环境，生成不同配置信息的chart-release; templates/ ├── deployment.yaml ├── _helpers.tpl ├── ingress.yaml ├── NOTES.txt ├── service.yaml └── tests └── test-connection.yaml 3.模版语法扩展了golang/text/template的语法： #这种方式定义的模版，会去除test模版尾部所有的空行 {{- define "test"}} 模版内容 {{- end}} # 去除test模版头部的第一个空行 {{- template "test" }} 4.用于yaml文件前置空格的语法： # 这种方式定义的模版，会去除test模版头部和尾部所有的空行 {{- define "test" -}} 模版内容 {{- end -}} # 可以在test模版每一行的头部增加4个空格，用于yaml文件的对齐 {{ include "test" | indent 4}} 5.templates/NOTES.txt NOTES.txt是chart的简易使用文档，chart安装成功后会显示此文档内容 就是当使用命令： help install chart部署完应用最后那个notes提示信息，可以根据需要自己修改 6.values.yaml 1.values.yaml就是config文件，vaule.yaml中记录的是K/V格式的参数数据； 2.当helm create chart时，这个V就会传递给templates目录下的deployment.yaml、ingress.yaml、service.yaml，然后程序才能正常运行； Helm使用进阶—4.创建自己的chart通过创建自己的chart，可以对chart目录，values.yaml是如何发挥config文件的作用了解的更清楚； 二.创建自己的chart 模板 检查配置和模板是否有效 部署到kubernetes 打包分享 将应用发布到 Repository 依赖 示例：创建一个名为myapp的chart，看一看chart的文件结构 1.创建目录 ~]# helm create myapp #通过helm create创建一个chart ~]# tree myapp/ #chart目录结构是由create时自动生成的 myapp/ ├── charts #被依赖到的其他chart文件下载到此目录 ├── Chart.yaml #Chart本身的版本和配置信息 ├── templates #当前chart的配置模板目录 │ ├── deployment.yaml #deployment文件用于部署应用程序模板 │ ├── _helpers.tpl #用于修改kubernetes objcet配置的模板 │ ├── ingress.yaml #可能需要用到的ingress模板 │ ├── NOTES.txt #helm提示信息 │ ├── service.yaml #部署所需的service文件模板 │ └── tests │ └── test-connection.yaml └── values.yaml #config文件，记录需要传递的K/V值参数 2.templates模板目录 Templates目录下是yaml文件的模板，遵循Go-template语法。使用过Hugo的静态网站生成工具的人应该对此很熟悉； ]# tree templates/ templates/ ├── deployment.yaml ├── _helpers.tpl ├── ingress.yaml ├── NOTES.txt ├── service.yaml └── tests └── test-connection.yaml 备注： deployment.yaml、ingress.yaml、service.yaml都是部署一个chart应用程序必须或者可能需要用到的清单文件， 清单模板内容由helm自动生成，下面简单看一下里面内容； 2.1.deployment.yaml #这里只列出deployment内容，其他yaml文件类似 ]# vim deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: {{ include "myapp.fullname" . }} labels: {{ include "myapp.labels" . | indent 4 }} spec: {{- with .Values.imagePullSecrets }} imagePullSecrets: {{- toYaml . | nindent 8 }} {{- end }} containers: - name: {{ .Chart.Name }} image: &quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}&quot; imagePullPolicy: {{ .Values.image.pullPolicy }} ...下文省略粘贴 解释： 1.可以看出deployment模板中Value都是以变量方式传递进去的，这些变量都放在/myapp/values.yaml这个文件中； 2.比如：container的image镜像的值是{{ .Values.image.repository }}，代表将values.yaml.image.repository的值传递进去，详见values.yaml文件； 2.2.values.yaml文件 ]# vim values.yaml replicaCount: 1 image: repository: nginx #生成时默认是nginx,可以改成myapp tag: stable #myapp镜像的版本，比如：v2 pullPolicy: IfNotPresent #拉取进行策略 imagePullSecrets: [] nameOverride: &quot;&quot; fullnameOverride: &quot;&quot; service: type: ClusterIP #给service.yaml文件中传递的service类型 port: 80 ...下文省略 比如： 1.在Deployment.yaml中定义的容器镜像image: &quot;{{ .Values.image.repository }}:{{ .Values.image.tag }}&quot;其中的： .Values.image.repository就是myapp .Values.image.tag就是stable 以上两个变量值是在create chart的时候由values.yaml传递进去； 3.lint:检查配置和模板是否规范 准备好各种yaml清单后就可以将此chart打包部署了，但是在打包之前可以使用link命令检查我们自己创建的chart是否规范； ~]# helm lint myapp ==&gt; Linting myapp [INFO] Chart.yaml: icon is recommended 1 chart(s) linted, no failures #没有ERROR信息代表成功，如果有错误要么是模板语法错误，要么是一些必选项没有值，按照提示检查即可； 4.基础myapp这个chart部署 ~]# helm install -n myapp ./myapp/ --dry-run NAME: myapp 1.先使用--dry-run选项测试部署一个名为myapp的项目，没有问题再正式部署 2../myapp表示安装本地chart，helm就会找本地路径的chart安装 ~]# helm install -n myapp ./myapp/ #正式部署 ~]# kubectl get pods NAME READY STATUS RESTARTS AGE myapp-72121931-sasjn 1/1 Running 0 20s 5.package:打包分享 我们可以把已经做好了一个chart打包分享出去供别人使用，实现开源精神； package可以把一个chart目录打包成chart归档文件，而不使用tar或者其他工具； ~]# helm package ./myapp/ Successfully packaged chart and saved it to: /root/myapp-0.1.0.tgz #这样就将做好的chart打包好了 6.serve命令：将chart应用发布到Repository helm的server命令表示启动一个本地的web服务器当做本地仓库来使用，并将其加入到 Helm Repo列表中； ~]# helm help serve --address string #默认监听在本地127.0.0.1:8879,可自定义 --repo-path string #repo路径，默认$HOME/.helm/repository/local，可自定义 --url string #对外输出的url ~]# mkdir /data/repo ~]# mv myapp-0.1.0.tgz /data/repo/ ~]# helm serve --address 192.168.34.118:8879 --repo-path /data/repo --url /chart #运行后这个自定义repo就会对外提供服务 ~]# helm search local local/myapp 0.1.0 1.0 myapp web servers #此时就可以搜索出这个chart了 ~]# helm install -n myapp-v2 local/myapp #此时就可以基础这个chart再部署一个release了 7.通过values.yaml部署不同release ~]# cp myapp/values.yaml /data #复制一个新的vaules.yaml文件到data目录 ~]# vim values.yaml #修改values.yaml内容比如，replicas数量、镜像版本等等 ~]# helm install -n myapp-v3 local/myapp -f /data/values.yaml #这样就可以部署一个不同配置的release了 Helm使用进阶—5.Chart升级、回滚过程升级和回滚的原理： helm list输出的结果中我们可以看到有一个Revision（更改历史）字段，该字段用于表示某一个Release被更新的次数，我们可以用该特性对已部署的Release进行回滚； 准备多个版本： 1.修改Chart.yaml文件 将版本号从0.1.0修改为0.2.0, 然后使用helm package命令打包并发布到本地仓库 ~]# cat myapp/Chart.yaml apiVersion: v1 appVersion: &quot;1.0&quot; description: A Helm chart for Kubernetes name: myapp version: 0.2.0 ~]# helm package ./myapp Successfully packaged chart and saved it to: /home/k8s/myapp-0.2.0.tgz 2.查询本地仓库中的Chart信息 ~]# helm search ./myapp -l NAME CHART VERSION APP VERSION DESCRIPTION myapp 0.2.0 1.0 A Helm chart for Kubernetes myapp 0.1.0 1.0 A Helm chart for Kubernetes 1.升级一个应用 先用helm upgrade命令将已部署的myapp升级到新版本。你可以通过--version参数指定需要升级的版本号，如果没有指定版本号，则缺省使用最新版本； ~]# helm upgrade myapp ./myapp Release &quot;myapp&quot; has been upgraded. Happy Helming! ~]# helm list NAME REVISION UPDATED STATUS CHART NAMESPACE myapp 2 10:50:25 DEPLOYED myapp-0.2.0 myapp #可以看到已部署的myapp被升级到0.2.0版本 2.回滚一个应用 1.如果更新后的程序由于某些原因运行有问题，需要回退到旧版本的应用。首先我们可以使用helm history命令查看一个Release的所有变更记录； ~]# helm history myapp REVISION UPDATED STATUS CHART DESCRIPTION 1 Mon Jul 23 10:41:20 SUPERSEDED myapp-0.1.0 Installcomplete 2 Mon Jul 23 10:50:25 DEPLOYED myapp-0.2.0 Upgrade complete 2.其次，我们可以使用下面的命令对指定的应用进行回退 ~]# helm rollback myapp 1 Rollback was a success! Happy Helming! #其中的参数1是helm history查看到Release的历史记录中REVISION对应的值 3.删除一个应用 3.1.如果需要删除一个已部署的Release，可以利用helm-delete命令来完成删除: ~]# helm delete myapp release &quot;myapp&quot; deleted 3.2.确认应用是否删除，该应用已被标记为 DELETED 状态 ~]# helm ls -a myapp NAME REVISION UPDATED STATUS CHART NAMESPACE myapp 3 10:53:42 DELETED myapp-0.1.0 myapp 3.3.也可以使用--deleted 参数来列出已经删除的Release ~]# helm ls --deleted NAME REVISION UPDATED STATUS CHART NAMESPACE myapp 3 10:53:42 DELETED myapp-0.1.0 myapp 3.4.从上面的结果也可以看出，默认情况下已经删除的 Release 只是将状态标识为 DELETED了 ，但该Release的历史信息还是继续被保存的; ~]# helm hist mike-test REVISION UPDATED STATUS CHART DESCRIPTION 1 Mon Jul 23 10:41:20 SUPERSEDED myapp-0.1.0 Install complete 2 Mon Jul 23 10:50:25 SUPERSEDED myapp-0.2.0 Upgrade complete 3 Mon Jul 23 10:53:42 DELETED myapp-0.1.0 Deletion complete 3.5.如果要移除指定Release所有相关的Kubernetes-资源和Release的历史记录，可以用如下命令： ~]# helm delete --purge myapp release &quot;myapp&quot; deleted 3.6.再次查看已删除的 Release，已经无法找到相关信息 ~]# helm hist myapp Error: release: &quot;myapp&quot; not found ~]# helm ls --deleted ~]# helm ls -a myapp #helm ls 命令也已均无查询记录。 6.Helm其它使用技巧1.如何设置helm命令自动补全？ helm有很多子命令和参数，为了提高使用命令行的效率，通常建议安装helm的bash命令补全脚本，方法如下： ~]# helm completion bash &gt; .helmrc ~]# echo &quot;source .helmrc&quot; &gt;&gt; .bashrc ~]# source .bashrc 或者 ~]# source &lt;(helm completion bash) 2.如何使用第三方的Chart存储库？ 随着Helm越来越普及，除了使用预置官方存储库，三方仓库也越来越多了（前提是网络是可达的）。你可以使用如下命令格式添加三方Chart存储库； ~]# helm repo add 存储库名 存储库URL #到helm官方地址https://hub.helm.sh去搜索stable版的仓库，在网页上有helm repo add的项目链接执行即可； ~]# helm repo update 一些三方存储库资源: # Prometheus Operator https://github.com/coreos/prometheus-operator/tree/master/helm # Bitnami Library for Kubernetes https://github.com/bitnami/charts # Openstack-Helm https://github.com/att-comdev/openstack-helm https://github.com/sapcc/openstack-helm # Tick-Charts https://github.com/jackzampolin/tick-charts 3.Helm如何结合CI/CD？ 采用Helm可以把零散的Kubernetes应用配置文件作为一个Chart管理，Chart源码可以和源代码一起放到Git库中管理。 通过把Chart参数化，可以在测试环境和生产环境采用不同的Chart参数配置； –Helm结合CICD 4.Helm如何管理多环境下 (Test、Staging、Production) 的业务配置？ Chart是支持参数替换的，可以把业务配置相关的参数设置为模板变量。使用helm install命令部署的时候指定一个参数值文件，这样就可以把业务参数从Chart中剥离了。 例如： helm install --values=values-production.yaml wordpress 5.Helm如何解决服务依赖？ 在Chart里可以通过requirements.yaml声明对其它Chart的依赖关系。如下面声明表明 Chart依赖Apache和MySQL这两个第三方Chart。 dependencies: - name: mariadb version: 2.1.1 repository: https://kubernetes-charts.storage.googleapis.com/ condition: mariadb.enabled tags: - wordpress-database - name: apache version: 1.4.0 repository: https://kubernetes-charts.storage.googleapis.com/ 6.如何让Helm连接到指定Kubernetes集群？ Helm默认使用和kubectl命令相同的配置访问Kubernetes集群，其配置默认在 ~/.kube/config中。 7.如何在部署时指定命名空间？ helm install默认情况下是部署在default这个命名空间的。如果想部署到指定的命令空间，可以加上--namespace 参数，比如： ~]# helm install ./myapp --name myapp --namespace mynamespace 8.如何查看已部署应用的详细信息？ ~]# helm get myapp 默认情况下会显示最新的版本的相关信息，如果想要查看指定发布版本的信息可加上 --revision参数。 ~]# helm get --revision 1 myapp 9.如何查看已经部署的对应release状态？ ~]# helm status myapp]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议]]></title>
    <url>%2F2018%2F12%2F18%2FHTTP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[HTTP协议和APACHE原理Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等本文说的是HTTP SERVERapacheHTTP2.4的官方文档http2.4文档：安装，模块，指令等说明HTTP2.4官方指令参考文档指令参考文档 http协议:应用层协议,主流http/1.1版本http协议的版本区别http0.9、http1.0、http1.1和http2.0的版本区别 http/0.9: 只有一个GET命令，且只能回应.html文件格式，像.txt等都不支持 http/1.0:效率太低 1.支持cache, MIME(支持各种资源类型), method2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低3.引入了POST命令和HEAD命令，头部信息和4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用 http/1.1:主流使用版本 1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭， 对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性 这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求 2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)4.缺点： 同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象5.解决队头堵塞的办法： 为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度: 不带状态怎么理解？ http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点 http/2.0：解决 HTTP/1.1效率不高的问题 1.头信息和数据体都是二进制，称为头信息帧和数据帧2.和http1.1区别：请求不需要排队，提高效率 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息) HTTP工作机制 工作机制主要分为两步：请求和响应 http请求：http requesthttp响应：http response一次http事务：请求响应 Web资源：web resource一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源的集合 静态页面/文件：无需服务端做出额外处理; 服务器端是什么样传到客户端就是什么样，比如下面这些 比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi 只不过浏览器有时会解析出来以好看的页面展示给用户 动态页面/文件：服务端执行程序，返回执行的结果 服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果 文件后缀：.php, .jsp ,.asp,.sh等 将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户 提高HTTP连接性能 并行连接：通过开多个TCP连接发起并发的HTTP请求持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，管道化连接：通过共享TCP连接发起并发的HTTP请求复用的连接：交替传送请求和响应报文（实验阶段） HTTP协议的其他相关技术 1.URI：一般把URI认为是URLURI: Uniform Resource Identifier 统一资源标识，分为URL和URN 1.URN: Uniform Resource Naming，统一资源命名 如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名 2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置 如输入一个网址，能具体体现出这个资源在互联网上的位置 两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址 URL的组成scheme://user:password@host:port/path;params?query#frag scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等user:用户，某些方案访问资源时需要的用户名password:密码，用户对应的密码，中间用：分隔Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔 网站访问量 1.IP(独立IP)：即Internet Protocol,指独立IP数。 如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个 2.PV(访问量)： 即Page View, 页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数， PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量 一般为了博客为了好看的访问量，都是统计PV量 3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。 网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。 如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1 Web服务请求处理步骤很切合实际生活：比如当我们打开一个浏览器，输入一个www.taobao.com，在互联网后台发生了什么？这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图 当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程每个过程都是一段需要原理详细描述的. 一次完整的http请求处理过程1.建立连接：接收或拒绝连接请求 2.接收请求：接收客户端请求报文中对某资源的一次请求的过程 Web访问响应模型（Web I/O） 单进程I/O模型：访问量不大 启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应 会造成请求排队现象，只适用于访问并发不大的情况 多进程I/O模型： 系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求 如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点 而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的 复用I/O结构： 开启多个进程进程，而一个进程又同时监控N个连接请求 只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗 实现方法：多线程模型和事件驱动 多线程模型：一个进程生成N个线程，每线程响应一个连接请求 事件驱动：一个进程处理N个请求 复用的多进程I/O模型： 启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求 充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的 nginx使用的复用多进程I/O模型 1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程 2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应 避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费 同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题 参考下面的HTTP的MPM三种工作模式 3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理 分析元数据：请求报文首部信息获得method &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt; HEADERS 格式 name:value &lt;request body&gt; 通过method来响应用户请求，比如下载(get)，上传等信息 HTTP常用请求方式，Method GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS 4.访问资源： 服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源 在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件 web服务器资源路径映射方式： (a) docroot (b) alias (c) 虚拟主机docroot (d) 用户家目录docroot 5.构建响应报文： 一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体 1）响应实体 描述了响应主体MIME类型的Content-Type首部 描述了响应主体长度的Content-Length 2）URL重定向 web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径 3）MIME类型 当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文 将构建完的响应报文发送给用户 将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户 用户再层层解封装获得index.html的内容 7.记录日志 最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务 通过在/var/log/httpd/acess_log日志中记录http的响应记录数 方便分析日志统计该网站的IP，PV量等信息 Http协议http协议 http/0.9, http/1.0, http/1.1, http/2.0 http协议：stateless 无状态 服务器无法持续追踪访问者来源 解决http协议无状态方法 cookie 客户端存放 session 服务端存放 http事务：一次访问的过程 请求：request 响应：response Session和Cookie的区别前言: HTTP是一种无状态的协议，为了分辨链接是谁发起的，就需要我们自己去解决这个问题。 不然有些情况下即使是同一个网站我们每打开一个页面也都要登录一下。而Session和 Cookie就是为解决这个问题而提出来的两个机制。 应用场景: 1.日常登录一个网站，今天输入用户名密码登录了，第二天再打开很多情况下就直接打开 了。这个时候用到的一个机制就是cookie。 2.session的一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而 服务器端如何判别呢，所以也需要存储一些信息，这里就用到了session。 Cookie的原理： HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。 也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。 这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设 计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行 保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在 请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服 务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端 保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报 文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后， 会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录， 最后得到之前的状态信息。 通俗讲，Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时 候减少一些步骤。另外一个更准确的说法是：Cookies是服务器在本地机器上存储的小段文 本并随每一个请求发送至同一个服务器，是一种在客户端保持状态的方案。 session的原理： session就是一种保存上下文信息的机制，她是针对每一个用户的，session的内容在服 务器端，通过sessionId来区分不同的客户，session是以cookie或url重写为基础的， 默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie，我们成为session cookie，以区分persistent coookies，注意session cookie是存储于浏览器内存中的 ，并不是写到硬盘上的；我们通常是看不见JSESSIONID的，但是当我们禁用浏览器的 cookie后，web服务器会采用url重写的方式传递sessionid，我们就可以在浏览器看到 sessionid=HJHADKSFHKAJSHFJ之类的字符串；session cookie针对某一次会话而言，会话结束session cookie也就消失了 session与cookie的区别： 1.session保存在服务器，客户端不知道其中的信息；cookie保存在客户端，服务端可以 知道其中的信息 2.session中保存的是对象，cookie中保存的是字符串 3.session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个 地方都可以访问到；而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不道德 session与cookie的联系： session是需要借助cookie才能正常工作的，如果客户端完全禁止cookie，session将失 效 Http应用层的报文头部:又分请求报文和响应报文两种-HTTP请求报文头部 开始行 方法：method GET： 从服务器获取一个资源 HEAD： 只从服务器获取文档的响应首部 POST： 向服务器输入数据，通常会再由网关程序继续处理 PUT： 将请求的主体部分存储在服务器中，如上传文件 DELETE： 请求删除服务器上指定的文档 TRACE： 追踪请求到达服务器中间经过的代理服务器 OPTIONS：请求服务器返回对指定资源支持使用的请求方法 URL:路径 首部行 实体行 -HTTP响应报文头部 开始行 版本：version HTTP/&lt;major&gt;.&lt;minor&gt;1.1/2等等 状态码： 三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况 短语： 状态码所标记的状态的简要描述 首部行 实体行 Http常见的状态码和状态码分类status(状态码)： 1xx：100-101 信息提示 2xx：200-206 成功 3xx：300-305 重定向 4xx：400-415 错误类信息，客户端错误 5xx：500-505 错误类信息，服务器端错误 200： 成功，请求数据通过响应报文的entity-body部分发送;OK 301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资 源现在所处的新位置；Moved Permanently 302： 响应报文Location指明资源临时新位置 Moved Temporarily 304： 如果之前访问一个网站，在本机上有缓存了，当再次访问时，就会出现304的状态码， 提示本地有不需要再去服务器上下载页面 401： 需要输入账号和密码认证方能访问资源；Unauthorized 403： 没有权限访问，请求被禁止了；Forbidden 404： 服务器无法找到客户端请求的资源；要访问的文件不存在 500： 服务器内部错误；Internal Server Error 502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；Bad Gateway 503： 服务不可用，临时服务器维护或过载，服务器无法处理请求 可能是服务器down机了，或者http服务关闭了 504： 网关超时；转给后端服务器时，时间太长 curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因curl是基于URL语法在命令行方式下工作的文件传输工具 1.它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。 2.curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证， HTTP上传，代理服务器，cookies，用户名/密码认证,下载文件断点续传，上载文件断 点续传, http代理服务器管道（ proxy tunneling） 3.还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等 4.curl的强大在于能模拟各种浏览器自定义请求报文头部等信息，来访问某些控制严格的网站 curl [options] [URL...] -A/--user-agent &lt;string&gt; 冒充浏览器类型，实际上在请求报文修改了User-Agent curl -A &apos;IE20&apos; http://192.168.34.103在http日志中可看到 一般用于测试访问网站或者爬虫功能要使用不同浏览器访问 -e/--referer &lt;URL&gt; 来源网址，防盗链相关 比如，伪装从百度跳转的192.168.34.103 curl -e &apos;www.baidu.com&apos; http://192.168.34.103 --cacert &lt;file&gt; CA证书 (SSL) -k/--insecure 允许忽略证书进行 SSL 连接 --compressed 要求返回是压缩的格式 -H/--header &lt;line&gt;自定义首部信息访问网站 -i 显示页面内容，包括报文首部信息 -I/--head 只显示响应报文首部信息 -D/--dump-header &lt;file&gt; 将url的header信息存放在指定文件中，重定向 --basic 使用HTTP基本认证，401认证 -u/--user &lt;user[:password]&gt;设置服务器的用户和密码 -L 如果有3xx响应码，重新发请求到新位置 如果访问的网页被重定向到其他地方时，系统只会提示网页被重定向了，并不会跳转 -L就可以请求到新的页面上 -O 使用URL中默认的文件名保存文件到本地 -o &lt;file&gt; 将网络文件保存为指定的文件中 --limit-rate &lt;rate&gt; 设置传输速度 -0/--http1.0 数字0，使用HTTP 1.0 -v/--verbose 更详细 -C 选项可对文件使用断点续传功能 -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中 -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址 -X/--request &lt;command&gt; 向服务器发送指定请求方法 -U/--proxy-user &lt;user:password&gt; 代理服务器用户和密码 -T 选项可将指定的本地文件上传到FTP服务器上 --data/-d 方式指定使用POST方式传递数据 -b name=data 从服务器响应set-cookie得到值，返回给服务器 elinks工具： 字符界面的浏览器，显示页面内容和源码等 elinks [OPTION]... [URL]... -dump: 非交互式模式，将URL的内容输出至标准输出 比如有些网站是不允许复制的，通过-dump就可以把网站页面文字抓取到本地了 elinks -dump www.baidu.com 不过一般都是用js脚本限制了复制功能，在浏览器关闭js，或查看源码都可以 -source:打印源码 HTTP介绍特性：高度模块化：core + modulesDSO: Dynamic Shared Object 动态加/卸载MPM：multi-processing module多路处理模块 HTTP的三种工作模型：MPM工作模式多用途的处理模块，三种模型分别是，默认使用prefork模型因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型 1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型一个主进程：生成和回收n个子进程，创建套接字，不响应请求 多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过 1024个，消耗比较大内存资源 受限于并发访问控制的内部系统调用机制： select()；内生使用限制最多只能使用1024个描述符，所以最多也就1024个进程 epoll(); Prefork MPM: 预派生模式，有一个主控制进程，然后生成多个子进程，使用select模型，最 大并发1024，每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定 ，可以设置最大和最小进程数，是最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景。 优点：稳定 缺点：慢，占用资源，不适用于高并发场景 配置文件原内容： &lt;IfModule mpm_prefork_module&gt; StartServers 5 #定义apache服务在启动时启动的子进程数量 MinSpareServers 5 #定义最小空闲进程数，空闲进程就是没有处理用户请求的进程数 MaxSpareServers 10 #定义最大空闲进程数 MaxRequestWorkers 250 #定义在prefork模式下的最大并发连接数，表示了apache的最大并发处理能力，超过的连接请求将被排队等候处理。 MaxConnectionsPerChild 0 #进程生命周期内，处理的最大请求数目。达到该数目后，进程将死掉。如果设置 为0，表示没有限制。该参数的意义在于，避免了可能存在的内存泄露带来的系统问题。 &lt;/IfModule&gt; 如果确定合适的MaxRequestWorkers呢？ 首先，通过top命令查看apache进程占用的资源，主要看%CPU和%MEM这两个指标，例如，每个进程的CPU占用率不超过 1%，每个进程的内存占用率不超过2%，考虑内存限制，比较合适的apache进程数量为50个，然后，逐步测试最大值。 通过观测得来的CPU和内存的指标有一定的误差，一般可以适当调节这个数值，例如调到1.5或者2倍，再通过峰值场景下的机器是否卡顿来判断是继续上调还是下调。 2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性 缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！ woker MPM：是一种多进程和多线程混合的模型，有一个控制进程，启动多个子进程，每个子进程里面包含固定的线程 ，使用线程程来处理请求，当线程不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求， 由于其使用了线程处理请求，因此可以承受更高的并发。 优点：相比prefork 占用的内存较少，可以同时处理更多的请求 缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放 。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生） 配置文件原内容详解： &lt;IfModule mpm_worker_module&gt; StartServers 3 # #定义apache服务在启动时启动的子进程数量，默认是3个 MinSpareThreads 75 # 整个控制进程保持最小数的空闲线程数 MaxSpareThreads 250 # 整个控制进程保持最大数的空闲线程数 #ThreadLimit 64 # 每个子进程可以启动的线程数量上限值，默认没有设置 ThreadsPerChild 25 # 每个子进程启动的线程默认数量，开启启动两个子进程每个子进程25个 线程，就是apache 启动后开启25个线程。 MaxRequestWorkers 400 # 所有子进程加起来的线程数量最大值，数量等于最大启动的进程数*ThreadsPerChild(每个进程的线程数) MaxConnectionsPerChild 0 # 每个子进程被请求多少次服务后被kill掉重新生成一个新的子进程，为了解决内存回收方面的问题，0为不设置 &lt;/IfModule&gt; 3.event：事件驱动模型（worker模型的优化,worker模型的变种）event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用 每一个cpu核心生成一个进程； 一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n 注意这里的m*n和work的m*n是不同的机制 相比较worker的有点： 有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许 释放。这样增强了高并发场景下的请求处理能力 event MPM：Apache中最新的模式，属于事件驱动模型(epoll)，每个进程响应多个请求，在现在版本里的已经是稳定 可用的模式。它和worker模式很像，最大的区别在于，它解决了keep-alive场景下，长期被占用的线程的资源浪费问题 （某些线程因为被keep-alive，空挂在哪里等待，中间几乎没有请求过来，甚至等到超时）。event MPM中，会有一个 专门的线程来管理这些keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后， 又允许它释放。这样增强了高并发场景下的请求处理能力。 event只在有数据发送的时候才开始建立连接，连接请求才会触发工作线程，即使用了TCP的一个选项，叫做延迟接受连 接TCP_DEFER_ACCEPT，加了这个选项后，若客户端只进行TCP连接，不发送请求，则不会触发Accept操作，也就不会 触发工作线程去干活，进行了简单的防攻击（TCP连接）,可以使用Telnet进行测试验证： 主机192.168.10.130为客户端机器，192.168.10.131为apache服务器机器使用event模式： 在192.168.10.130上telnet 192.168.10.131 80，然后在192.168.10.130客户端机器上使用netstat查看，发现连 接已经建立，处于ESTABLISHED状态，然后再到apache服务器192.168.10.131使用netstat查看，发现是处于 SYN_RECV状态。 优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程， 当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放 缺点：没有线程安全控制 配置文件内容： &lt;IfModule mpm_event_module&gt; StartServers 3 #apache服务启动的子进程数，默认3个 MinSpareThreads 75 #控制进程保持最小的空闲线程数 MaxSpareThreads 250 #控制进程保持的最大空闲线程数 ThreadsPerChild 25 #每个子进程启动的线程数 MaxRequestWorkers 400 #并发最大请求数，也就是所有子进程加起来的线程数量，woker模式下的 400就是并发400，但是由于是异步处理请求的，因此这里的400比woker模型下的并发处理速度要快很多，因为event省略了工作线程的会话保持。 MaxConnectionsPerChild 0 #每个子进程请求多少次以后被kill掉重新生成一个新的子进程。 &lt;/IfModule&gt; 注意： event模型的强大的I/O机制 httpd从设计上就默认支持prefork 而nginx从设计上就支持event事件驱动模型 进程工作的角色切换 Httpd的功能特性httpd的常见特性： 虚拟主机：在一个物理服务器上搭建多个网站 IP、Port、FQDN CGI：Common Gateway Interface，通用网关接口 通过CGI接口处理动态的程序处理 反向代理 当有用户访问量大时，在前端有一个服务器充当调度器的角色 通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息 看不到后端真正提供服务的服务器群 负载均衡 路径别名 丰富的用户认证机制 basic digest 支持第三方模块 Httpd2.4新特性和安装以及配置新特性 MPM支持运行为DSO机制；以模块形式按需加载 在centos7上的httpd2.4上只有一个二进制程序 /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可 但是在centos6上的httpd2.2版本： 每个MPM模式都有各自对应的二进制程序 /usr/sbin/httpd /usr/sbin/httpd.event /usr/sbin/httpd.worker 如果更改MPM的模式，是需要改对应的二进制程序的 event MPM生产环境可用 异步读写机制 支持每模块及每目录的单独日志级别定义 每请求相关的专用配置 增强版的表达式分析式 毫秒级持久连接时长定义：httpd2.2只能精确到秒级别 上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的 所以在http中是可以定义连接时长(时长和传输请求两种方式)的 基于FQDN的虚拟主机不需要NameVirutalHost指令 httpd2.2创建虚拟主机时还需要NameVirutalHost指令 httpd2.4就不需要了 新指令，AllowOverrideList 支持用户自定义变量 更低的内存消耗 Httpd2.4的具体安装和配置Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了还支持第三方的模块，按需加载模块存放模块的路径：/etc/httpd/modules CentOS7程序环境安装：httpd-2.4 yum install httpd yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档 主要配置文件： /usr/sbin/httpd httpd的主程序文件 /usr/lib/systemd/system/httpd.service httpd的启动单元文件 /etc/httpd/conf/httpd.conf 主要配置文件 配置文件里的路径都是以/etc/httpd/为参考点的 /etc/httpd/conf.d/*.conf /etc/httpd/conf.modules.d/00-mpm.conf mpm相关 /etc/httpd/conf.modules.d/00-proxy.conf 配置代理相关 /etc/httpd/conf.modules.d/00-systemd.conf /etc/httpd/conf.modules.d/01-cgi.conf CGI相关 /var/cache/httpd httpd的缓存目录 /var/log/httpd httpd的日志文件目录 access_log: 访问日志 error_log：错误日志 /etc/httpd/modules httpd的模块存放路径，软件比较复杂 /usr/lib64/httpd/modules 也是httpd的模块存放路径 两个模块的路径实际上是软链接关系 /var/www/html httpd存放网页的目录：默认index.html 帮助文档包：在没有网络时查看帮助文档，建议安装 httpd-manual 检查配置文件语法： httpd –t 类似DNS的rndc语法检查功能 sudo：visudo功能 ansible:ansible -C|--check 执行前检查语法功能 cobbler 也有 httpd的控制和启动命令 systemctl enable|disable httpd.service systemctl {start|stop|restart|status|reload} httpd.service 备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作 有时reload是无效的，只能restart服务 Httpd2.4的常见配置 1.显示服务器版本信息HTTP2.4官方指令参考文档指令参考文档 主要组成: Global Environment 全局配置 Main server configuration 一个服务器上搭建一个网站叫主服务器 virtual host 虚拟主机，一台主机上搭建多个网站 练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)egrep -v ‘^ #.|^$’ /etc/httpd/conf/httpd.conf 常见配置一般都在/etc/httpd/conf/httpd.conf的文件中没有的配置选项可以加在httpd.conf文件最后，也可以放在/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加 1.显示服务器版本信息 访问http://192.168.34.103 打开f12调试模式，可以看到回应头的信息中带有apache的版本信息 也可以通过curl -I http://192.168.34.103来显示头信息 可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全 查看指令参考文档：修改ServerTokens选项建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全 2.修改监听的IP和Port Listen [IP:]PORT (1) 省略IP表示为本机所有IP (2) Listen监听端口至少一个，可以有多个端口 (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口 test.conf添加listen端口： listen 172.18.132.151:6666 6666端口只能通过此IP才能访问 3.持久连接：默认KeepAlive是开启的 Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接 断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级 副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞 折衷：使用较短的持久连接时间 设置： KeepAlive On|Off 设置持久连接开启或者关闭 KeepAliveTimeout 15 设置持久连接为15s 测试：telnet WEB_SERVER_IP PORT GET /index.html HTTP/1.1 Host: WEB_SERVER_IP host可以随便填写，但是在虚拟主机中是有区别的 4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event 默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf 修改mpm的文件 建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的 查看静态编译的模块 httpd -l 查看当前系统中httpd的静态编译及动态装载的加载的模块 httpd –M 动态模块加载：不需重启即生效 动态模块路径 /usr/lib64/httpd/modules/ 切换使用的MPM模块 在/etc/httpd/conf.modules.d/00-mpm.conf中 选择要启用的MPM相关的LoadModule指令即可 prefork的配置： StartServers 8 MinSpareServers 5 保留5个空闲子进程处理新的请求 MaxSpareServers 20 允许的最大空闲进程数 ServerLimit 256 最多进程数,最大20000，并发量建议最多10000 MaxRequestsPerChild 4000 子进程最多能处理的请求数量。在处理 MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进 程占用的内存就会释放(为0时永远不释放） worker和prefork配置类似，只不过会有线程数量的限制 从下面ps auxf的进程图可以看书httpd是使用的prefork模型，而且因为端口是80，开启需要特殊权限，所以父进程是root,子进程是apache 5.DSO： Dynamic Shared Object 加载动态模块配置 /etc/httpd/conf/httpd.conf Include conf.modules.d/*.conf 配置指定实现模块加载格式： LoadModule &lt;mod_name&gt; &lt;mod_path&gt; 模块文件路径可使用相对路径： 相对于ServerRoot（默认/etc/httpd） 6.定义’Main’ server的文档页面路径：存放页面的主目录 主目录是由DocumentRoot指令来设置的 网页文件默认是存在/var/www/html/下的，此处可以自定义 在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html” 如果要自定义主目录，还需要设置该目录为允许访问 在httpd2.2上是不需要设置权限访问的 但是在httpd2.4上是需要设置该目录允许访问的 修改格式如下： #DocumentRoot &quot;/var/www/html&quot; DocumentRoot &quot;/data/www&quot; &lt;directory /data/www&gt; Require all granted &lt;/directory&gt; 7.定义站点默认主页面 访问192.168.34.103默认显示的是index.html的内容， 这一项是由DirectoryIndex指令设置的 在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可 添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件 此处需要了解httpd的权限和访问报错的相关问题和默认主页面：1.访问192.168.34.103跳出的页面默认是index.html页面，如果不存在，则去找conf.d/welcome.conf文件，即报错提示，如果两个都不存在，显示的是/var/www/html目录下的文件列表，因为在httpd.conf配置文件中，定义options indexes选项2.默认页面和默认访问目录都是可以通过指令来指定的3.如果没有index.html文件，没有welcome.conf文件，没有options indexes配置，访问时会报错You don’t have permission to access / on this server.的提示.4.上面三条在下面第12条配置别名时，可以体现的很明显5.所以如果自定义目录和用别名，有时是需要设置目录访问权限、设置目录对应的index.html文件或者跳转的html文件(如果该文件存在就不需要设置了)，设置options indexes选项 8.站点访问控制常见机制 可基于两种机制指明对哪些资源进行何种访问控制 访问控制机制有两种：1.客户端来源地址，2.用户账号 而文件系统路径：可以是 1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配 示例： ‘‘’ 用的是扩展的正则表达式 通配符 &lt;Location /status&gt; 9.中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制 (1) Options：后跟1个或多个以空白字符分隔的选项列 在选项前的+，- 表示增加或删除指定选项 常见选项： Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制 适用于下载网站和镜像网站，不适合电商网站 FollowSymLinks：允许访问符号链接文件所指向的源文件, None：全部禁用 All： 全部允许 Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的 就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站 &lt;directory &quot;/data/www&quot;&gt; options Indexes Require all granted &lt;/directory&gt; FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件 &lt;directory &quot;/data/www&quot;&gt; options Indexes FollowSymLinks Require all granted &lt;/directory&gt; 实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.conf文件，welcome.conf文件就是页面上经常看到的测试123页面，把welcome.conf文件改名或删除，就会显示主目录下的所有列表文件了. (2) AllowOverride allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可 只对语句有效; allowoverride权限时卸载httpd的*.conf配置文件中的 AllowOverride All: .htaccess中所有指令都有效 AllowOverride None： .htaccess 文件无效 AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它 配置allowoverride示例： /etc/httpd/conf.d/test.conf中添加访问控制的目录 &lt;directory /data/www&gt; allowoverride all --&gt;这条必须写，代表.htaccess文件中的options生效 Require all granted &lt;/directory&gt; 在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中 options indexes FollowSymLinks (3) 基于IP的访问控制: 无明确授权的目录，默认拒绝 允许所有主机访问：Require all granted 拒绝所有主机访问：Require all denied 控制特定的IP访问： Require ip IPADDR：授权指定来源的IP访问 Require not ip IPADDR：拒绝特定的IP访问 控制特定的主机访问： Require host HOSTNAME：授权特定主机访问 Require not host HOSTNAME：拒绝 HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机 基于IP的访问控制示例： 如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表 除了/data/www/ceshi文件夹 &lt;directory /data/www&gt; options indexes &lt;RequireAll&gt; Require all granted Require not ip 192.168.34.107 &lt;/RequireAll&gt; &lt;/directory&gt; 2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问 &lt;directory /data/www&gt; options indexes Require all granted &lt;/directory&gt; &lt;directory /data/www/ceshi&gt; &lt;RequireAny&gt; Require all denied Require ip 192.168.34.107 &lt;/RequireAny&gt; &lt;/directory&gt; 10.日志设定：日志默认/var/log/httpd/下format官方说明文档 日志类型：访问日志(access_log)和错误日志(error_log) 日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式 在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义 LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined --&gt;由Logformat指令定义完起一个combined名 CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式 ErrorLog &quot;logs/error_log&quot; 可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径 日志中的格式各个项说明 %h 客户端IP地址 %l 远程用户,启用mod_ident才有效，通常为减号“-” %u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-” %t 服务器收到请求时的时间 %r First line of request，即表示请求报文的首行；记录了此次请求的“方法”， “URL”以及协议版本 %&gt;s 响应状态码 %b 响应报文的大小，单位是字节；不包括响应报文http首部 %{Referer}i 请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页 是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源，所以网站一般要加防盗链，防止资源被盗和占用服务器资源 %{User-Agent}i 指客户端的浏览器版本 11.设定默认字符集 一般不需要设置：基本上使用的是utf-8; AddDefaultCharset UTF-8 此为默认值 如果需要修改字符集，在test.conf或者httpd.conf下添加 AddDefaultCharset gb2312 即可 12.定义路径别名作用：默认访问的文件夹是设置的DocumentRoot文件夹，如果不是在默认文件夹下，而需求要实现把其他路径下的目录共享出来，这就用到了定义路径别名的功能 把一个URL起一个别名不指向真正的目录 在httpd2.4里目录如果没有开启允许时，默认是不允许访问的 例如：访问 /var/www/html/111,111这个目录可有可无，只是充当别名 实际上访问的是/data/www/ceshi目录 directoryindex ceshi.html alias /111 /data/www/ceshi &lt;directory /data/www/ceshi&gt; options indexes Require all granted &lt;/directory&gt; 注意：1.111只是一个别名，在/var/www/html下不需要创建；但是如果/var/www/html下有111的文件夹，如果设置别名后，则访问的是/data/www/ceshi目录，原目录下的111文件夹就失效了。2.在这里和上文第7条设置权限时有联系的，httpd2.4设置路径别名的时候，真正的路径也是需要在test.conf下设置权限的(/data/www/ceshi目录)3.如果/data/www/ceshi/下没有index.html会报权限不允许的错误，所以要设置默认主页面directoryindex，当然可以设置options indexes选项 13.基于虚拟账户的登录访问控制：提示401状态码 认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码 认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源 两种认证方式： basic：用的多，缺点是明文，后面可以用https进行加密 digest：兼容性差，用的少 用户的账号和密码:非linux用户密码 虚拟账号：多种存储方式，只用于httpd服务的，类似vsftp，samba服务的虚拟用户 存储：账号可放在文本文件，SQL数据库，ldap目录存储，nis等 因为basic使用的多，下文以basic认证配置示例 1.提供账号和密码存储（文本文件），如创建一个tom虚拟账户管理httpd htpasswd --&gt;可以指定加密算法 -c 自动创建文件，仅应该在文件不存在时使用 -p 明文密码 -d CRYPT格式加密，默认 -m md5格式加密 -s sha格式加密 -D 删除指定用户 htpasswd -c httpdpass tom :设定密码即可;目录可指定，后面改配置文件即可 htpasswd -s httpdpass jerry 再添加jerry用户，就不需要-c选项了 htpasswd -D httpdpass jerry 从文件中删除jerry用户 修改httpdpass权限，加固安全 chmod 600 httpdpass 或者也可以创建组文件httpdgroup，通过组来管理,组文件组和成员列表 testgroup: tom jerry 2. 在test.conf或者httpd.conf下定义安全域 &lt;directory /var/www/html/ksdir&gt; AuthType Basic ---&gt;使用的认证方式 AuthName &quot;Login&quot; ----&gt;登录提示信息 AuthUserFile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;加密账户文件 AuthGroupFile &quot;/etc/httpd/conf/httpdgroup&quot; --&gt;组账户 Require user tom ---&gt;允许用户访问的列表 Require group testgroup ---&gt;允许访问的组 &lt;/directory&gt; 但是：因为httpd线程是以apache运行的，而httpdpass是600权限，所以默认tom登录是没有权限的，让apache对httpdpass有读权限： setfacl -m u:apache:r httpdpass 即可 14.实现用户家目录的http共享;并实现账户机密访问 实现基础：基于模块mod_userdir.so实现 httpd -M |grep user 可以看出user加密的模块是已经加载的，直接改配置文件即可 在/etc/httpd/conf.d/userdir.conf文件中定义了家目录共享的格式，只需要启用就行了 实现步骤： 1. vim /etc/httpd/conf.d/userdir.conf &lt;IfModule mod_userdir.c&gt; UserDir enabled ---&gt;启用即可；默认不启用 UserDir public_html ---&gt;创建一个public_html文件 &lt;/IfModule&gt; 2.在test家目录下，创建public_html文件夹和public_html文件 su test mkdir public_html/ echo 23333 &gt; /public_html/public_html 3.因为httpd线程是apache身份登录的，所以要允许apache访问test用户的家目录 setfacl -m u:apache:x /home/test 4.设置test家目录访问权限及用户加密 &lt;directory /home/test/public_html&gt; authtype basic authname &quot;test home&quot; authuserfile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;调用之前创建的虚拟账户文件即可 Require user haha &lt;/directory&gt; 5.http访问test家目录方式,即可用加密账户登录 192.168.34.103/~test 15.ServerSignature On|Off|EMail 作用：当用户访问的页面不存在的情况下服务器会产生错误文档，而当ServerSignature选项是打开的情况下，错误文档会将服务器的名字，apahce的版本信息，显示在页面上，某种程度上会对web服务器产生不安全因素，所以一般建议关闭 在配置文件添加一行： ServerSignature off 即可 16.status页面 作用：显示apache的工作状态，有助于判断apache是否正常工作 status页面功能是由下面这个模块实现的：httpd LoadModule status_module modules/mod_status.so 实现步骤：在配置文件添加 &lt;Location &quot;/status&quot;&gt; SetHandler server-status &lt;/Location&gt; ExtendedStatus ON #显示扩展信息 记录的信息包括：启动时间，线程数，等待连接数，cpu，进程，MPM等信息 在实际生产中，由于apache服务器很多，就可以通过curl 192.168.34.103/status来抓取页面，分析apache某个指标是不是正常的； 比如编写简单一个脚本： curl 192.168.34.103/status |grep &quot;Apache Status&quot; || systemctl start httpd 17.实现http的虚拟主机 作用：一个物理服务器上实现多台虚拟主机，至于为什么会用到虚拟主机，有可能是因为要上线的同一网站的有多个域名，却只有一个公网IP地址，也有可能是主机不多啊..，所以虚拟主机的价值就体现出来了… 实现虚拟主机有三种方式 基于ip：为每个虚拟主机准备至少一个ip地址，一个主机可以配多个内网IP地址 基于port：为每个虚拟主机使用至少一个独立的port；80,8081,8082等等 基于FQDN：为每个虚拟主机使用至少一个FQDN 当然这三种方式，基于IP和port的对于用户来说不太现实，一般都是通过输入域名方式来实现虚拟主机搭建. 1.基于IP的虚拟主机搭建：但是这种方式用的比较少 先准备三个网站目录，和在本机上添加三个IP地址 &lt;virtualhost 192.168.34.103&gt; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost 192.168.34.200&gt; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost 192.168.34.210&gt; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; 重启服务即可 通过curl 192.168.34.103 curl 192.168.34.200 curl 192.168.34.210 即可获取到各自的index.html文件内容，对应的日志也都生成了 2.基于port的虚拟主机搭建，监听三个port即可;使用的不多 listen 8081 listen 8082 listen 8083 &lt;virtualhost *:8081&gt; servername &quot;www.a.com&quot; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost *:8082&gt; servername &quot;www.b.cn&quot; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost *:8083&gt; servername &quot;www.c.net&quot; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; 通过本机IP+port获得不同网站的信息 curl 192.168.34.103:8081 curl 192.168.34.103:8082 curl 192.168.34.103:8083 3.基于FQDN的虚拟主机搭建：用的最多 前提：这里就不搭建DNS服务器了，使用本机的hosts文件进行域名解析 &lt;virtualhost *:80&gt; servername &quot;www.a.com&quot; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost *:80&gt; servername &quot;www.b.cn&quot; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost *:80&gt; servername &quot;www.c.net&quot; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_c.log combined &lt;/virtualhost&gt; 测试：curl www.a.com curl www.b.cn curl www.c.net 就可获得各自的主页面信息从这telnet就可以理解出，如果在互联网通过域名访问时(同一IP)，返回的结果是不同网站的信息 [root@node7-1 ~]#telnet 192.168.34.103 80 Trying 192.168.34.103... Connected to 192.168.34.103. Escape character is &apos;^]&apos;. GET /index.html HTTP/1.1 HOST: www.a.com 当访问192.168.34.103时 HOST：即网站的域名，返回的结果就是其对应的页面信息在互联网上，一般是先在本地服务器上通过第三种方式搭建多个网站，然后再通过服务商的智能DNS解析，可以通过访问不同的域名，解析到IP地址，服务器根据输入的HOST：域名判断访问的是哪个网站，进而返回对应网站站点的信息，对于主机较少或者IP有限的环境中，使用http虚拟主机还是很方便的。]]></content>
      <categories>
        <category>web服务</category>
        <category>http</category>
      </categories>
      <tags>
        <tag>Web服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译安装LAMP]]></title>
    <url>%2F2018%2F12%2F10%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85LAMP%2F</url>
    <content type="text"><![CDATA[LAMP Centos7上编译安装LAMP 备注：本文编译PHP是基于fastCGI方式，php-fpm 编译准备： 在192.168.34.105上实现，准备安装包都放在/data/src下 apr-1.6.5.tar.bz2 apr-util-1.6.1.tar.bz2 httpd-2.4.37.tar.bz2 php-7.1.18.tar.bz2 wordpress-5.0-zh_CN.zip mariadb-10.2.19-linux-x86_64.tar.gz 准备开发包组： yum install &apos;develoment tools&apos; -y 1.编译安装httpd和apr 准备依赖包和解压安装包 yum install pcre-devel openssl-devel expat-devel apr-util-devel -y tar xvf apr-1.6.5.tar.bz2 tar xvf apr-util-1.6.1.tar.bz2 tar xvf httpd-2.4.37.tar.bz2 cp -r apr-1.6.5 httpd-2.4.37/srclib/apr cp -r apr-util-1.6.1 httpd-2.4.37/srclib/apr-util a.编译 cd httpd-2.4.37 ./configure \ --prefix=/data/httpd24 \ --enable-so \ --enable-ssl \ --enable-cgi \ --enable-rewrite \ --with-zlib \ --with-pcre \ --with-included-apr \ --enable-modules=most \ --enable-mpms-shared=all \ --with-mpm=prefork make &amp;&amp; make install b.准备环境变量 用自带的服务控制脚本：/app/httpd24/bin/apachectl就需要设置环境变量了 echo &apos;PATH=/mysql/httpd24/bin:$PATH&apos; &gt; /etc/profile.d/httpd24.sh . /etc/profile.d/httpd24.sh c.修改配置文件，为了安全以apache用户运行，并监听在本地 useradd -r -s /sbin/nologin apache vim /data/httpd24/conf/httpd.conf User apache Group apache ServerName localhost:80 2.二进制安装mariadb-10.2.19 a.准备用户和mysql数据库目录 useradd -r -s /sbin/nologin -d /data/mysql mysql mkdir /data/mysql chown mysql.mysql mysql/ b.解压二进制安装包： tar xvf mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local/ cd /usr/local ln -s mariadb-10.2.19-linux-x86_64/ mysql chown -R root.mysql /usr/local/mysql/ c.创建数据库文件:(通过自带脚本工具) cd /usr/local/mysql/ scripts/mysql_install_db --datadir=/mysql/data --user=mysql d.准备配置文件(不修改/etc/my.cnf)拷贝解压完的文件 mkdir /etc/mysql/ cp support-files/my-huge.cnf /etc/mysql/my.cnf 路径优先级高于/etc/my.cnf 根据性能来拷贝配置文件 [mysqld]中添加三个选项：/etc/mysql/my.cnf datadir = /mysql/data innodb_file_per_table = on skip_name_resolve = on 禁止主机名解析，建议使用 e.准备服务脚本，并启动服务 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld service mysqld start f.准备PATH路径 echo &apos;PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh systemctl start mysqld 为wordpress准备数据库和账号密码 mysql -e &apos;create database wordpress&apos; mysql -e &quot;grant all on *.* to php1@&apos;192.168.34.%&apos; identified by &apos;php123&apos;&quot; 3.FastCGI方式编译安装php-7.1.18 tar xf php-7.1.18.tar.bz2 安装依赖包 yum install libxml2-devel bzip2-devel libmcrypt-devel -y a.编译，指定安装数据路劲和配置文件路径 cd php-7.1.18 ./configure --prefix=/data/php \ --enable-mysqlnd \ --with-mysqli=mysqlnd \ --with-openssl \ --with-pdo-mysql=mysqlnd \ --enable-mbstring \ --with-freetype-dir \ --with-jpeg-dir \ --with-png-dir \ --with-zlib \ --with-libxml-dir=/usr \ --enable-xml \ --enable-sockets \ --enable-fpm \ --with-config-file-path=/etc \ --with-config-file-scan-dir=/etc/php.d \ --enable-maintainer-zts \ --disable-fileinfo make &amp;&amp; make install b.准备php配置文件 cd php-7.1.18 cp php.ini-production /etc/php.ini 可以修改当前时区和按照生产环境修改并发连接数等信息 c.创建nginx用户 useradd -s /sbin/nologin nginx d.准备php的conf文件 cd /data/php cp php-fpm.conf.default php-fpm.conf cp php-fpm.d/www.conf.default php-fpm.d/www.conf 修改监听地址和允许连接地址，因为是在一台编译的，监听地址不用改了 vim php-fpm.d/www.conf listen = 127.0.0.1:9000 ;listen.allowed_clients = 127.0.0.1 user = nginx group = nginx e.准备服务脚本: cp /data/src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm chkconfig --add php-fpm chkconfig php-fpm on 4.修改httpd文件，支持php和启用代理 编辑apache配置文件httpd.conf，以使apache支持php,并启用代理 vim /data/httpd24/conf/httpd.conf 1.取消下面两行的注释 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 2.定位至DirectoryIndex index.html 修改为DirectoryIndex index.php index.html 3.最后添加4行 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 重启apache服务，apachectl restart 5.准备wordpress,把wordpress文件全部移动到httpd24/htdocs下 cd /data/src unzip wordpress-5.0-zh_CN.zip cd wordpress mv * /data/httpd24/htdocs 为wordpress准备配置文件和数据库连接 cd /data/httpd24/htdocs mv wp-config-sample.php wp-config.php vim wp-config.php define(&apos;DB_NAME&apos;, &apos;wordpress&apos;); define(&apos;DB_USER&apos;, &apos;php&apos;); define(&apos;DB_PASSWORD&apos;, &apos;php123&apos;); define(&apos;DB_HOST&apos;, &apos;192.168.34.105&apos;); 修改/data/httpd24/htdocs的所有者和所属组 cd /data/httpd24 chown -R nginx.nginx htdocs/ 到此所以的编译安装和准备工作都做完了，把mysql,php-fpm,httpd启动即可 apachectl start systemctl start php-fpm systemctl start mysqld http://192.168.34.105 配置wordpress即可 备注： 创建的文章和账户是放在wordpress数据库中的; 图片是放在/data/httpd24/htdocs/wp-content/uploads下的 然后把这套系统搬到自己的云服务上就可以轻松的实现了,本文是基于LAMP架构实现的不过推荐使用LNMP架构，毕竟Nginx的强大可不是吹出来的.. 安装完成后，开启了一个新的世界，就可以开心的玩耍了,helloworld！]]></content>
      <categories>
        <category>web服务</category>
        <category>个人博客搭建</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GlusterFS存储]]></title>
    <url>%2F2018%2F12%2F06%2FGlusterFS%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TiDB基础]]></title>
    <url>%2F2018%2F12%2F03%2FTiDB%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"></content>
      <categories>
        <category>数据库</category>
        <category>TiDB</category>
      </categories>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ceph存储基础]]></title>
    <url>%2F2018%2F11%2F03%2Fceph%E5%AD%98%E5%82%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[存储基础 存储设备： 1.DAS:IDE，SATA，SCSI，SAS，USB #DAS直接附加存储是直接接到计算机的主板总线上去的； 2.NAS: NFS，CIFS， #1.NAS(Network Attacked Storage)网络附加存储，文件系统级别的存储； #2.把一个文件系统挂载到本地的文件系统树上的某一个挂载点上就可以直接访问，因为 它是通过网络附加到当前主机文件系统之上的一个存储空间就称为网络附加存储； #3.网络附加存储的特点都是文件系统接口(filesystem),本身就是一个做好的文件 系统，通过nfs/cifs接口基于内核级的nfs/cifs模块与远程主机进行通信，把它转 为像本地文件系统一样来使用； #4.对于这种存储设备我们是没办法对它进行再一次的分区格式化等操作的 3.SAN:SCSI #1.SAN(Storage Area Network)称为存储区域局域网络 #2.与NAS不同的是SAN提供给客户端使用的接口是块(block)级别的，所以SAN大多数使用 的是SCSI协议； SCSI协议： SCSI协议也是分层的和tcp/ip协议很像也分数据链路，物理层，传输层，应用层的，不过SCSI只是用来传输数据的存 取，SCSI的物理层早期也是使用并行的线缆传输SCSI信号来实现的，SCSI协议的分层设计意味着某一层是可以被替代的； FC-SAN: 把SCSI的物理层替换成光纤和它对应的协议，就是FC-SAN的形成 ISCSI: 把SCSI的物理层替换成tcp/ip协议和它对应的底层设备(以太网),就是ISCSI 它们其实就是把SCSI协议底层的物理传输接口改换成了另外一种传输信道； 而且SCSI协议本身的传输距离有限，如果是通过以太网传输就大大增加了距离； 所以这种网络提供给客户端的存储接口就称为存储区域网络； 大多数SSD使用如SATA、SAS或光纤通道等接口与计算机接口的总线连接。随着固态硬盘在大众市场上的流行，SATA已成为个人电 脑中连接SSD的最典型方式；但是，SATA的设计主要是作为机械硬盘驱动器（HDD）的接口，并随着时间的推移越来越难满足速度 日益提高的SSD。随着在大众市场的流行，许多固态硬盘的数据速率提升已经放缓。不同于机械硬盘，部分SSD已受到SATA最大吞吐量的限制。 在NVMe出现之前，高端SSD只得以采用PCI Express总线制造，但需使用非标准规范的接口。若使用标准化的SSD接口，操作系统 只需要一个驱动程序就能使用匹配规范的所有SSD。这也意味着每个SSD制造商不必用额外的资源来设计特定接口的驱动程序 HDFS分布式存储(文件系统接口)–HDFS分布式存储 前提： 设计成分布式文件系统的根本目的就是为了能够做到按需扩展 有状态应用： 如果一个服务的第二次访问请求和第一次请求是有关系的，就是有状态的应用 分布式存储： 1.所以分布式存储也是一种有状态应用的一种，如果存储是分布和扩展到多个节点上，以mysql为例，数据第一次写到Storage-A节点, 查的时候在分布式存储内部必须要有一个路由机制使得查询的时候还是到Storage-A节点查询，而不是Storage-B|C|D节点; 2.可能你会想把Storage-A节点的数据同步到B|C|D上，查询数据的时候不就路由到哪个节点都可以了？ 如果是这样每个存储节点都会拥有全部一样的数据了，这样就不符合分布式存储的定义了； 元数据、数据的实现？ 元数据就是负责路由的， 以ext4文件系统为例： inode信息是存储在元数据区的 元数据就是让我们找到所需文件的路由表，但是当我们使用分布式存储时，就不能使用这种传统的在一个分区上来组织 数据和元数据了，而是把数据和元数据分开存放 分布式存储方式： 1.元数据服务器：(NameNode) 分布式存储的元数据和数据不能像ext4那样，但是可以在存储集群中找一个固定的节点存放元数据 2.写数据：(DataNode) 当客户端想要存储2G的数据请求发给元数据节点后，元数据负责将这2G的数据做指定大小规模进行切块，每一块当做独 立的文件进行路由和调度从而达到分散存储的目的，而且还可以并发调度存储到不同的节点充分利用多个节点的磁盘和网络I/O； 3.读数据：(DataNode) 用户读数据时只需要联系元数据服务器，根据在元数据中记录的某一文件切块大小、数量、每一块所在的节点以及块之 间的偏移量然后元数据从各个节点上并行的加载这些数据块然后按照元数据中的逻辑由客户端将其组合起来得到完整的数据； NameNode的高可用： 1.如果只有一台元数据服务器就有单点故障，所以要实现NameNode的高可用； 2.但是文件系统的元数据是一类非常密集但是I/O量非常小的数据，所以为了实现请求元数据时的高效，一般是把它放到内 存当中，但是当服务器down机时会丢失数据的，所以又需要一种机制持久同步存储到磁盘上； 3.但是当文件修改时，元数据也会被修改，因为无法判断哪个文件会被修改，所以就会造成大量的修改操作同步到磁盘上是 随机的，大家都知道随机I/O操作会非常慢； 4.因此为了能够对这些非常密集的文件元数据的修改操作进行高效的同步到磁盘上，一般都不是直接去改那个元数据的，而 是像mysql的binlog一样把每一次的操作请求记下来，而不是真正的去修改元数据，将来想要还原回来只需要把日志重放一 遍就行了，这样就比较像redis的AOF顺序追加记录机制，这样就把随机I/O改成顺序I/O能够快速的进行同步 磁盘进行保存； 5.顺序I/O(AOF)的缺点就是只能通过重放记录在文件中的指令才能把数据还原回来，而不 是复制，所以恢复速度非常慢； 6.为了避免将元数据同步到磁盘上时恢复时比较慢，现在的方案都是持久放在第三方存储上，第三方存储集群使用 zookeeper,这样一来NameNode1宕机了之后，NameNode2就可以快速的从zookeeper中恢复数据； (这样的解决方案就很类似于把有状态的k8s-apiserver放到etcd集群中一样，不过 zookeepr主要作用于java编程领域，etcd作用于go编程领域)； DataNode的高可用： 由于数据文件是被切成很多块分散存储到多个datanode的，当其中任何一个DataNode宕机都会造成此文件的丢失； 数据存储区的两种高可用方案： 1.在DataNode的节点级做冗余，即每个DataNode都有一个从节点，这样代价有点大； 2.分片级的冗余： 1.可以对存在DataNode上的单个数据块做副本，将副本放到存储集群中的其他DataNode节点上，冗余级别取决于每个数据块的副本数量； 2.这样一来，就可以在NameNode中定义任意个数据块都必须有3个副本数量存在，主分片(primary shard)负责数据 复制(replica shard)到事先选择好的其他节点上；把即使任何一个DataNode宕机了也不会影响数据文件的完整性； 3.机架的规划 DataNodeA DataNodeB DataNodeC一般是不在一个机柜的，避免因为一台断电数据 全部丢失； 机柜1：DataNodeA+DataNodeB 机柜2：DataNodeC A--&gt;B-&gt;C #这样一来至少保证以一台数据的安全性，提高冗余级别； TFS(淘宝)&lt;--HDFS&lt;--GFS(谷歌文件系统) 特点： 这种分布式文件系统的特点是读写接口是受限的，可以随机的/顺序的读，但只能顺 序的写，不能随机的写!!! 块级别设备存储–块设备接口逻辑 区别： 1.块级别的存储就是一个裸设备，提供给我们的就是一个没有被组织过的存储空间，而文件系统存储让我们只能以文件形式来存放数据； 2.但是要注意的是&quot;数据并不一定都是文件形式的，也可以是数据流形式的&quot;，只有把数据流组织起来放在一个特定的文件系统上时的一种表现形式； 3.所以文件系统只是数据的组织存放接口，所有数据流存进来以后都表现为我们看到的、所理解的&quot;一种文件&quot;；而文件系统 接口一般是建立在块级别存储接口之上的，我们在一个块级别的存储空间上创建出文件系统来。就可以存放数据流了； 4.像HDFS这种分布式存储最常见的就是文件系统接口，因为在计算机发展中文件系统接口是最经典的接口，因为在计算机中 大量的存储都是以文件形式存放的！ 虽然文件系统接口是最经典最常用的，但有些应用程序确实要求不应该使用文件系统接口，比如KVM,VMware虚拟机启动时使用的 磁盘镜像文件，如果提供给它的是文件系统接口它还需要再将文件虚拟成磁盘进行挂载就会影响它的性能，如果是直接提供块设 备作为磁盘，它启动时直接加载磁盘不是更好吗; 对象存储–对象存储的存储方式 如上图示： 和文件系统中把数据和元数据分开存放的不同在于：对象存储中每一个数据流都自带数据data和元数据metadata，每一个这样的数据流都被叫做一个对象； 1.这样一来只要找到这个对象就可以知道它的元数据信息不需要再访问元数据区了； 2.这样一来每一个数据对象内部都应该有自己的管理格式用来标记它的数据和元数据所在的位置 3.因此对象是直接放到磁盘之上的，而不是像文件系统那样分开存放； –对象的组织格式 每一个object是如何被存下来的？ 如上图对象是自带数据data和元数据metadata被统一存储的 ID用于集群内部引用 元数据是K/V类型的 –filestore和bluestore FileStore存储方式： 1.将对象转换成文件进行存储，转换成的文件的元数据放在元数据区 2.原来对象自己的元数据都被放在levelDB中 #levelDB也是高性能的K/V类型数据库是直接放在xfs文件系统上 3.对象数据直接存在文件系统上 非标准的文件系统键入元数据 BlueStore存储方式： 1.BlueStore=BlueFS+RocksDB #因为此时OSD是一个裸设备，而RocksDB数据库必须运行在一个文件系统之上，所以在其下也必须有文件系统叫做 BlueFS支撑RocksDB数据库运行； 2.此时对象本身就直接存放在OSD裸设备磁盘内，对象的元数据放在RocksDB内 3.而RocksDB为了实现它的安全性需要进行数据持久化保存，使用WAL的方式来写日志； 所以在BlueStore上存储的数据分为三类： 1.数据 2.元数据 3.元数据的元数据，就像redis的AOF文件一样 鉴于以上因素，BlueStore支持三种不同的存储设备，然后就有了这种方案 1.BlueFS和RocksDB放在固态硬盘上 2.对象数据放在机械硬盘上 3.RocksDB的持久化数据放在NVMe上 Ceph–ceph微型架构 1.Ceph是什么？ Ceph也是分布式存储的一种解决方案，但是和HDFS还是有一点区别的： 1.Ceph是一个软件定义的存储SDS(software-defined storage),而且是一个开源的高 度可伸缩的平台； 2.Ceph是一个&quot;对象（object）&quot;式存储系统，它把每一个待管理的数据流（例如一个文件） 切分为一到多个&quot;固定大小&quot;的对象数据shard，并以其为&quot;原子单元&quot;完成数据存取； 默认的&quot;固定大小&quot;是4M，但可以自定义； 3.对象数据的底层存储服务是由多个主机（host）组成的存储集群，该集群也被称之为 RADOS（Reliable Automatic Distributed Object Store）存储集群，即可靠、 自动化、 分布式对象存储系统； 4.librados是RADOS存储集群的API（库接口），它支持C、C++、Java、Python、Ruby和PHP等编程 语言； 5.Ceph从设计上就是为了解决分布式存储所面临的元数据服务器很容易称为瓶颈的缺点； 备注： 要注意的是每一个固定大小的对象(每一个数据流)都自带数据data和元数据 metadata,这样每一个数据流都被叫做一个对象 2.Ceph是如何解决元数据服务器瓶颈的问题的？ Ceph在存数据的时候，为了避免有一个元数据中心服务器成为整个系统的瓶颈所在，它也采用了计算方式来解决问题； Ceph是没有文件元数据中心服务器的，因为它的所有数据访问都是通过CRUSH算法实时计算路由的，而且计算所需的资源量 很小而且是无状态的可以按需无限制扩展； Crush组件： 1.即当存储一个文件时它要对文件做hash计算，然后映射到对应的存储节点上去，查和读的时候也是做计算去查的，这是依靠Crush算法来实现的. 2.CRUSH算法就是ceph内部通过计算方式用来完成对象路由的一个非常重要的算法； Ceph Architecture：ceph架构–ceph的架构 由于从根本上来讲，Ceph存储在底层是一个由多节点组成的RADOS存储集群，而这个存储集群服务是librados的API; 1.而服务是一个API就意味着是无法挂载的，如果想要存一个文件必须自己写一个对接这个api的程序才行； 2.所以为了让用户使用方便，Ceph在其存储接口api之上开发提供了三种抽象接口以便用户能够像传统意义上的存储功能一样使用Ceph. 三个接口： 1.CephFS 1.就像NFS,CIFS一样是一个做好的文件系统，可以挂在到客户端 2.CephFS其实是不依赖于librados的，因为它自身就集成在rados cluster之上的 3.CephFS是最早出现的，也是最后(J版本)投入生产使用的； 4.Cephfs因为是文件系统接口可以直接在客户端进行挂载，而且还可以再次抽象成NFS/CIFS接口来使用； 5.CephFS是依靠ceph-mds服务对外提供服务的； 2.RBD #将ceph提供的存储空间模拟成一个个独立的块设备使用，每一个块设备叫做一个image磁盘,可以对这个磁盘做分区/格式然后挂载使用； 1.RBD是使用最广泛的接口； 2.RBD是块接口的需要映射到内核才能被使用，所以要基于内核模块(librbd),由客户端主机基于librbd与RBD接口进行交互完之后，再由客户端主机对其进行分区格式化进行挂载使用； 3.如果是KVM的virt可以直接使用RBD块存储； 4.RBD是不需要守护进程的，而是使用内核模块librbd对外提供服务； 3.RadosGW #更加抽象的、能够跨互联网使用的对象(object)存储 区别： 1.这个所谓的对象不是指ceph内部的对象，ceph内部的对象是固定大小的存储块，而且通常只在ceph集群中使用，它是基于rpc接口调用的； 2.而互联网上的OSS对象存储是基于restful接口提供的存储，每一个文件都是一个对象，而且文件大小各不相同； RadosGW提供的是http/https协议的接口； RadosGW是依靠ceph-radosgw对外提供服务的 注意： 1.RBD/RadosGW都是为了与librados-api交互写的创建，而且CephFS/RBD/RadosGW都是RADOS的客户端，他们底层都以rados作为存储后台，他们只是这个存储后台的一种抽象层而已； 2.任何一个客户端要想接入rados cluster服务，就必须经过pool存储池来实现； 3.而且这三种客户端都有各自的专用存储池，且所需的存储池个数都不一样； Ceph存储底层的工作逻辑基础–ceph存储的组成和逻辑 RADOS的组成： rados最为最底层，是应该由很多主机host组织成一个rados cluster存储集群 Rados Cluster 1.rados-cluster是ceph的核心组件，它以对象化的方式把每一个文件切分成固定大小的对象，然后基于对象进行管理的； 2.每一个对象都必须经过CRUSH算法实时计算后映射到集群中的某个osd上； Host: 1.每个主机上都应该运行一些守护进行来确保每个host能够提供存储空间； 2.Host主机本地的存储空间是以什么形式供给的？ FileStore: 我们都知道ceph是对象存储，每个对象存储自带数据和元数据的，而在早期的ceph上每个host中都是由已经格式化成 xfs系统的磁盘组成，如果把对象存进来，那么又回到了将数据和元数据分开存放的形式，它一定会降低存储性能的,这就是FileStore：文件管理引擎； BlueStore: 在后来的ceph的Host内部是直接使用磁盘来存储对象了，而这个磁盘内部有自己的裸设备管理逻辑，这种形式叫做 BlueStore，BlueStore是Ceph的新存储引擎，是社区版的默认配置； 因此RADOS才是把多个节点组织为一个集群，并利用对方的存储空间整合成一个更大的存储空间，从而提供分布式的存储服务的 一个非常重要的底层存储机制； OSD: 1.每一个主机host上有多个OSD(Object Storage Device),每一个OSD可以认为是一个 磁盘(FileStore意味着它是一个目录，BlueStore意味着它是一个磁盘)； 2.OSD叫做对象存储设备，每一个磁盘叫做一个OSD； MON：集群元数据监视器 在RADOS cluster中除了Host之外，还有一类节点叫做Mon 1.mon是集群元数据节点，而在前面说过ceph为了实现没有性能瓶颈是没有元数据服务器的，这里的所说的元数据节点是指 它是用来管理整个集群的元数据； 2.mon有整个集群的运行图：host节点的数量和状态、每个host上的osd数量和健康状态，每个PG的健康状态等等； 3.所以mon需要做高可用，而且mon的高可用是内部直接使用Paxos协议来实现数据冗余，任何一个节点都有完整的副本， 为了使各节点上的数据冗余是强一致的，所以使用Paxos分布式协作协议实现； (类似etcd使用Raft协议实现高可用一样)； [Monitor and Paxos参考文章](https://www.jianshu.com/p/53dd30054c0f) Mgr: 因为mon对集群元数据采集是实时的查询的，这种实时查询的代价是很高的，因为在Ceph的新版本(从L版开始)中引用了一个新组件mgr； 1.mgr:manager专门维护查询的操作，根据内部的逻辑将查询操作缓存下来然后再响应给客户端； Pool:存储池 类似于k8s中的namspace思想一样，将Rados cluster所提供的存储空间切成多个pool 原因： 这里说一下存储在ceph中的所有对象都是在一个平面当中的，因为ceph中没有文件系统，没有目录，是没有分层管理 的概念的，这样一来所有对象都放一起了，代来的麻烦就是管理、分类、迁移就难！ 1.基于以上的原因，rados把它的存储空间切成了类似于分区大小的磁盘方便管理； 2.每一个分区叫做一个存储池pool,每个pool的大小是取决于底层rados-cluster所提供的存储空间的； 3.存储池pool必须先创建才能使用,对象只需要向这个pool请求存储就行了； 4.pool存储池的类型： 所谓存储池类型就是如何做数据冗余的:前面说过数据冗余有节点级冗余和分片级冗余； 1.而pool的存储池类型就是分片级冗余，不过这里不叫主分片/副本分片； 2.pool是以PG为单位来管理的，所以它叫做主PG和副本PG； 5.ceph还支持纠正删码池存储池 纠删码池也会选择足量的osd来，不过多个osd不是用来存副本的，而是每一个osd存一部分，另外一份存的是校验码， 必要时可以通过校验码计算出来完整数据，这样做的好处就是存储空间的利用率高了； PG：归置组 1.每一个pool的空间如果太大了，当把1亿个对象(4M大小)存进pool之后，以对象为颗粒 度进行副本管理太过于精细，代价高且维护起来太麻烦；所以还可以进一步的切分成多个PG； 2.PG就是将对象映射到OSD之间的一个虚拟中间层，是不能被创建的; 3.放到一个PG内的所有对象是被统一管理的，而且是放到同一个OSD上的；以PG为颗粒度的管理就变得简单多了； 4.pool--&gt;PG 将放在pool中的对象名字做一致性hash计算，hash的结果映射到hash环上，而这个hash环上遍布着PG，再通过顺时针找到最近的PG，然后将对象归置到这个PG上； 这只是CRUSH算法的第一步实现； 5.PG--&gt;OSD 1.这是CRUSH算法的第二步实现：需要把PG根据pool的类型和冗余副本数量找到足量的osd来动态映射； 2.而PG的主、副本是由CURSH算法来区分的； 那么外部文件是如何存储到rados cluster中OSD上的？ 客户端接入(CephFS/RBD/RadosGW)-&gt;切分固定大小的存储对象-&gt;pool-&gt;PG-&gt;osd 究竟要放到哪个OSD上，这中间是依靠cursh来完成的； 总结： 从上面的基础概念可以概括出Ceph存储的基本组件包括： 1.OSDs 2.Monitors #一般是3~5~7个监视器 3.Managers #2个以上的管理器 4.MdSs #如果要用到CephFS文件系统的话，还需要有MDSs文件系统元数据服务器，而且为了实现元数据安全MDS是要做高可用的； #从严格意义上来说，MDS只能算是构建在RADOS存储集群之上的文件存取接口，它同RBD/RadosGW属于同一级别，而非Ceph必要组件，使用CephFS接口时才是需要的；]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-ELK收集日志]]></title>
    <url>%2F2018%2F11%2F03%2FKubernetes-ELK%E6%94%B6%E9%9B%86%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[使用EL/FK收集k8s容器日志更新于：19.01.19 1.日志收集方式及其架构 前言： 1.由于运行在k8s中业务pod的IP不固定、业务A的pod不只一个来回切换查看日志太麻烦，而且生产中制作的业务镜像是不安装SSH 服务的，所以需要将一类pod中的日志收集到一起放到es中通过kibana去查看更方便； 2.kubernetes官方插件使用EFK来处理容器日志,其中F指代Fluentd（Fluentd属于CNCF项目）,用于收集容器的日志。但是由于 Fluentd用起来的确不怎么舒服（Ruby风格配置文件）,而Logstash又过于重量级(光启动就需要消耗大约500M内存), 而Elatic家族的Beats系列中的Filebeat既轻量又无依赖，因此filebeat是无二选择； 1.官方日志方案 Kubernetes官方提供了EFK的日志收集解决方案，但是这种方案并不适合所有的业务场景，它本身就有一些局限性，例如： 1.所有日志都必须是out前台输出，真实业务场景中无法保证所有日志都在前台输出 2.只能有一个日志输出文件，而真实业务场景中往往有多个日志输出文件 3.Fluentd并不是常用的日志收集工具，我们更习惯用logstash，现使用filebeat替代； 4.我们已经有自己的ELK集群且有专人维护，没有必要再在kubernetes上做一个日志收集服务 2.Kubernetes集群中的日志收集解决方案 1.每个app的镜像中都集成日志收集组件： 优点： 部署方便，kubernetes的yaml文件无须特别配置，可以为每个app自定义日志收集配置 缺点： 强耦合，不方便应用和日志收集组件升级和维护且会导致镜像过大 2.单独创建一个日志收集组件跟app的容器一起运行在同一个pod中： 优点： 低耦合，扩展性强，方便维护和升级 缺点： 需要对kubernetes的yaml文件进行单独配置，略显繁琐 3：将所有的Pod的日志都挂载到宿主机上，每台主机上单独起一个日志收集Pod： 优点： 完全解耦，性能最高，管理起来最方便 缺点： 需要统一日志收集规则，目录和输出方式 3.方案选择 1.综合以上方案，由于filebeat不大放在每个容器中镜像也不会很大，虽然后期filebeat版本升级有点繁琐，但这样不需要在 yaml清单中对日志收集进行定义，所以选择了第一种方式； 虽然在进行日志收集的过程中,我们首先想到的是使用Logstash,它用于日志的原始数据的分析和转换(grok)；但是在k8s容器 时代，更为轻量级的方案中首选Beats系列,上面就是基于ELK改造过后的基于Filebeat的容器日志处理方案； 2.filebeat部署： 1.Filebeat可以使用DaemonSet的方式部署在每个k8s节点上，它会将Docker容器的日志 目录(/var/lib/docker/containers)挂载进去开启一个prospector来进行处理； 2.将filebeat构建在每个业务镜像中，作为业务容器中的一个进程对外发送日志； 4.最终日志收集流程 由于第二种方式更简单所以选择第二种方式收集日志，收集流程： 业务A-filebeat将pod日志--&gt;redis--&gt;logstach--&gt;elasticsearch--&gt;kibana展示 #当然也可以使用zookeeper+kafka代替redis集群 2.使用filebeat收集kubernetes容器日志部署方式： 1.elasticsaerch、logstash、redis、kibana都部署在k8s集群外 2.docker镜像中都安装filebeat客户端 1.安装elasticsearch集群 对ES添加添加一些我们需要的插件： ~]# cd /usr/share/elasticsearch ~]# bin/elasticsearch-plugin install ingest-geoip ~]# bin/elasticsearch-plugin install x-pack ~]# systemctl restart elasticsearch #ES的地图需要使用GEOIP来解索IP的经纬度, 所以ES还需要安装一个GEOIP的插件 2.安装logstach 3.安装zk+kafka或者redis 此处使用redis，安装redis,设置密码等；redis服务器地址是192.168.1.118 zk+kafka部署参考：k8s中的文章 4.安装kibana #以上步骤全部省略 5.制作包含filebeat的tomcat8基础镜像 生产环境下我们会将filebeat程序制作成系统基础镜像，然后业务镜像再基于这个镜像构建成业务镜像，就能够收集日志了； ~]# tree tomcat8/ #以centos为基础镜像 tomcat8/ ├── build-command.sh #build脚本 └── Dockerfile #centos的Dockerfile文件 └── filebeat-6.4.2-x86_64.rpm #准备日志服务filebeat ├── apache-tomcat-8.0.38.tar.gz #tomcat8 ├── jdk-8u162-linux-x64.tar.gz #jdk8 └── profile #jdk的profile文件 ~]# vim Dockerfile #Centos Base Image FROM 192.168.1.101/baseimage/centos:7.6 #基于官方镜像构建 MAINTAINER lk &quot;645150765@qq.com&quot; #author ADD filebeat-6.4.2-x86_64.rpm /tmp/ RUN yum install -y epel-release vim wget tree pcre pcre-devel gcc gcc-c++ zlib zlib-devel openssl openssl-devel net-tools iotop unzip zip iproute ntpdate nfs-utils tcpdump telnet traceroute /tmp/filebeat-6.4.2-x86_64.rpm &amp;&amp; rm -rf /tmp/ RUN rm -rf /etc/localtime &amp;&amp; ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #安装了常用的基础命令、上传安装filebeat、修改镜像默认时区 ADD jdk-8u162-linux-x64.tar.gz /usr/local/src/ RUN ln -sv /usr/local/src/jdk1.8.0_162 /usr/local/jdk ADD profile /etc/profile RUN mkdir /data/tomcat/webapps -pv ENV JAVA_HOME /usr/local/jdk ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/:$JRE_HOME/lib/ ENV PATH $PATH:$JAVA_HOME/bin ADD apache-tomcat-8.0.38.tar.gz /apps RUN ln -sv /apps/apache-tomcat-8.0.38 /apps/tomcat RUN useradd tomcat -u 2001 ~]# bash build-command.sh #构建镜像 #!/bin/bash docker build -t 192.168.1.101/serverbase/tomcat-base:v1 . sleep 1 docker push 192.168.1.101/serverbase/tomcat-base:v1 6.构建业务镜像 ~]# tree cre-app1/ cre-app1/ ├── cre-app1.tar.gz ├── build-command.sh ├── catalina.sh ├── Dockerfile ├── filebeat.yml ├── cre-app1 │ └── index.html ├── run_tomcat.sh └── server.xml ~]# vim filebeat.yml #修改filebeat文件 filebeat.prospectors: - type: log enabled: true paths: - /apps/tomcat/logs/catalina.out fields: log_type: web-test-creapp1-catalina-outlog filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 3 output.redis: hosts: [&quot;192.168.1.118:6379&quot;] key: &quot;web-test&quot; db: 1 timeout: 5 password: &quot;123456&quot; 备注： 1.paths：指定要收集当前pod的哪个日志文件； 2.fields： log_type:在logstach中做if判断它是哪个业务的哪个日志 3.output.redis: 先输出到redis,logstach再从redis取数据 hosts：redis的地址，这里使用单机redis key： 一个业务只有一个key即可，无论这个业务里有多少nginx或tomcat都写到这个key中即可，如果key太多的话，那么logstach的input就需要写很多个； ~]# vim Dockerfile #tomcat cre-app1 FROM 192.168.1.101/serverbase/tomcat-base:v1 ADD catalina.sh /apps/tomcat/bin/catalina.sh ADD server.xml /apps/tomcat/conf/server.xml ADD cre-app1.tar.gz /data/tomcat/webapps/myapp/ ADD run_tomcat.sh /apps/tomcat/bin/run_tomcat.sh ADD filebeat.yml /etc/filebeat/filebeat.yml RUN chown -R tomcat.tomcat /data/ /apps/ &amp;&amp; chmod a+x /apps/tomcat/bin/*.sh EXPOSE 8080 8443 CMD [&quot;/apps/tomcat/bin/run_tomcat.sh&quot;] ~]# vim run_tomcat.sh #!/bin/bash echo &quot;192.168.1.248 k8s-vip.example.com&quot; &gt;&gt; /etc/hosts /usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat &amp; su - tomcat -c &quot;/apps/tomcat/bin/catalina.sh start&quot; tail -f /etc/hosts 备注： filebeat在容器启动方式如上，这种方式是在物理机上安装启动后按照实际路径修改的,让filebeat在容器中以进程的方式运行，&amp;表示放到run_tomcat.sh这个shell的后台去； ~]# bash build-command.sh 2018-10-20 192.168.1.101/cre/cre-app1:2018-10-20 测试镜像： ~]# docker run --name app1 -d 192.168.1.101/cre/cre-app1:2018-10-20 ~]# docker exec -it app1 /bin/bash [root@488da447ab60 /]# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 11684 1400 ? Ss 14:01 0:00 /bin/bash /apps/tomcat/bin/run_tomcat.sh root 6 0.1 0.7 288584 13304 ? Sl 14:01 0:00 /usr/share/filebeat/bin/filebeat... tomcat 32 6.2 6.9 3049932 129176 ? Sl 14:01 0:02 /usr/local/jdk/bin/java 确保tomcat、filebeat都是运行的即可 7.部署cre-app1项目并收集其日志 1.部署cre-app1项目 ~]# tree cre-app1/ cre-app1/ └── cre-app1.yaml ~]# kubectl apply -f cre-app1.yaml ~]# kubectl get pods -n cre #1.确保cre-app1的svc、pod等正常运行 #2.启动cre-app1-pod时，filebeat会先运行起来然后检测tomcat的运行日志； 2.确认redis中有数据 ~]# redis-cli -h192.168.1.118 -p123456 192.168.1.118&gt; SELECT 1 192.168.1.118&gt; KEYS * 1) &quot;web-test&quot; #确认filebeat中指定的key传进来了 192.168.1.118&gt; LPOP web-test &quot;{\&quot;@timestamp\&quot;:\&quot;2018-1020T04:16:02.103z\&quot;,\&quot;@metadata\&quot;:{\&quot;beat&quot;}...,\&quot;fileds\&quot;:{\&quot;log_type\&quot;:\&quot;web-test-creapp1-catalina-outlog\&quot;}...:&quot;/apps/tomcat/logs/catalina.out\&quot;}&quot; #确保key中filebeat定义的fields.log_type:web-test-creapp1-catalina-outlog是否存在，logstach会过滤这个log_type； 3.logstash从redis取数据传给elasticsearch ~]# cd /etc/logstash/conf.d/ ~]# vim redis-logstash-es.conf input { redis { host =&gt; &quot;192.168.1.118&quot; port =&gt; &quot;6379&quot; db =&gt; &quot;1&quot; key =&gt; &quot;web-test&quot; data_type =&gt; &quot;list&quot; password =&gt; &quot;123456&quot; } } output { if [filed][log_type] == &quot;web-test-creapp1-catalina-outlog&quot; { elasticsearch { hosts =&gt; [&quot;192.168.1.116:9200&quot;] index =&gt; &quot;web-test-container-creapp1-catalina-outlog-%{+YYYY.MM.dd}&quot; }} } ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis-logstash-es.conf 4.像catalina.out追加信息 ~]# kubectl exec -it web-test-cre-deployment-sa9nsha-m7mga bash -n cre # # echo &quot;tomcat log test&quot; &gt;&gt; /apps/tomcat/logs/catalina.out 5.在kibana上验证 –收集的日志 参考使用filebeat收集kubernetes容器日志Getting Started With Beats and the Elatic StackElasticsearch 安装X-PackDeploy filebeat as daemonset in kubernetes clusteFilebeat 模块列表应用日志收集]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-CNI和网络插件]]></title>
    <url>%2F2018%2F10%2F23%2FKubernetes-CNI%E5%92%8C%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Kubernetes-CNI和网络插件更新于：18.11.20 1.k8s集群上的通信需求1.docker时代和k8s时代的网络区别： 1.在docker时代,同一个docker服务器上的多个container是通过docker0(SNAT桥)进行通信的，而docker0是使用172.17.0.0/16这个私网网段地址的. 2.在不同的docker服务器上运行的两个container必须通过SNAT-&gt;DNAT互相访问的，在容器众多的场景下这样手动配置规则显然是不合理的。 3.而k8s集群又是由有多个docker网络的node节点组成的，如果都是用DNAT,SNAT方式通信是不现实的. 2.k8s上常见的通信需求： 1.pod内的container-&gt;container之间是通过lo接口通信的； 2.pod--&gt;pod之间相互访问 k8s规定不同node上的pod必须是PodIP---&gt;PodIP的直接通信，而不能经过NAT方式进行通信！ 3.pod--&gt;service service是当前节点的iptables\ipvs规则，pod的请求报文还没离开本机就被iptables\ipvs所捕获. 4.pod--&gt;外部k8s集群外部的客户端间的通信 nodeport,hostport,hostnetwork方式 5.从k8s集群外部访问Pod网络 3.从第2条的通信需要可以理解K8S在网络设计时，在选择、配置集群网络插件类型或者实践K8S应用/服务部署时应该想到以下原则： 1.每个Pod都拥有一个独立IP地址，Pod内所有容器共享一个网络命名空间 2.集群内所有Pod都在一个直接连通的扁平网络中，可通过IP直接访问 2.1.所有容器之间无需NAT就可以直接互相访问 2.2.所有Node和所有容器之间无需NAT就可以直接互相访问 2.3.容器自己看到的IP跟其他容器看到的一样 3.Service-cluster-IP尽可在集群内部访问，外部请求需要通过NodePort、LoadBalance或者Ingress来访问； 2.CNI：Container Network Interface–CNI 1.为什么会有CNI？ CNI是Container Network Interface的缩写，简单地说，就是一个标准的，通用的接口。已知我们现在有各种各样的容器平台：docker，kubernetes， mesos，我们也有各种各样的容器网络解决方案：flannel，calico，weave，并且还有各种新的解决方案在不断涌现。如果每出现一个新的解决方案，我们 都需要对两者进行适配，那么由此带来的工作量必然是巨大的，而且也是重复和不必要的。事实上，我们只要提供一个标准的接口，更准确的说是一种协议， 就能完美地解决上述问题。一旦有新的网络方案出现，只要它能满足这个标准的协议，那么它就能为同样满足该协议的所有容器平台提供网络功能，而CNI正 是这样的一个标准接口协议； 2.什么是CNI？ 1.CNI是一个接口协议，用于连接容器管理系统和网络插件。它们之间通过JSON格式的文件进行通信，实现容器的网络功能。具体的事情都是插件来实现的，包括： 1.CNI Plugin负责创建容器网络空间，它包括两个基本的接口: 1.1.配置网络: AddNetwork(net *NetworkConfig, rt *RuntimeConf) (types.Result, error) 1.2.清理网络: DelNetwork(net *NetworkConfig, rt *RuntimeConf) error 提供一个容器所在的network namespace（从网络的角度来看，network namespace和容器是完全等价的）； 2.IPAM Plugin负责给容器分配IP地址 负责将network interface插入该network namespace中（比如veth的一端），并且在宿主机做一些必要的配置 （例如将veth的另一端加入bridge中），给网络接口分配IP，最后对namespace中的interface进行IP和路由的配置。 那么CNI的工作其实主要是从容器管理系统处获取运行时信息，包括network namespace的路径，容器ID以及network interface name，再从容器 网络的配置文件中加载网络配置信息，再将这些信息传递给对应的插件，由插件进行具体的网络配置工作，并将配置的结果再返回到容器管理系统中； 2.最后，需要注意的是，在之前的CNI版本中，网络配置文件只能描述一个network，这也就表明了一个容器只能加入一个容器网络。但是在后来的CNI版本 中，我们可以在配置文件中定义一个所谓的NetworkList，事实上就是定义一个network序列，CNI会依次调用各个network的插件对容器进行相应的配置， 从而允许一个容器能够加入多个容器网络。 3.跨主机的网络间通信原理 1.在没有k8s集群之前，运行在不同docker主机上的container也需要彼此通信，当时就有很多种跨主机的网络通信解决方案，而k8s-node本质上就是多个 dockerdocker网络的节点，因此网络解决方案本质上是没什么区别的，下面简单说一下跨主机的容器之间的通信解决方案、以及网络实现原理： 1.大二层网络 1.通过桥接网络模式让容器可以直接与外部主机通信，只需要让其在不同的网段地址不冲突即可； 2.如果一台主机上的pod众多时，广播包会严重影响通信，所以需要将每台主机都划分一个Vlan 3.如果主机节点众多时，手动管理网络是一件麻烦的事. 2.叠加网络 1.叠加网络是在节点的物理网卡间加了一个Vxlan二层隧道，当节点访问的IP不是本机内部的时候，就会通过vxlan隧道进行封装转发到另外一个节点； 2.而Vxlan是需要外部存储记录各个节点内部的子网网段，从而每次封装转发时查询目标IP所在的节点完成报文的发送. 2.两种网络模型的对比： 1.大二层网络(物理桥网络)是较大规模的网络中实现网络虚拟化的重要基础技术之一而且 是由BGP协议(边界网关协议)实现，但是要求机房支持BGP协议； 2.叠加网络也是在较大规模的网络中实现网络虚拟化的重要基础技术，而且在众多实现叠加网络协议中，vxLan协议以性能高，协议开放著名； 3.区别： 1.大二层网络的性能更高，因为是直接通信的 2.Vxlan还需要再封装一层隧道，所以MTU是小于1500的,但是在网络管理上Vxlan是不低于大二层网络的. 4.k8s集群的CNI网络插件及其原理Kubernetes本身没有提供网络组件，在部署Kubernetes的时候需要安装第三方CNI插件来支持Kubernetes中的网络。Kubernetes可支持CNI网络的插件也有 很多，比如：flannel，calico，canel等，早期k8s版本是用kubenet来对接外部网络的！ 1.在k8s中启用CNI网络插件 1.如果是kubeadm部署的k8s是不需要手动启用cni接口的； 2.二进制部署k8s时，需要为kubelet添加下面3个参数： --network-plugin=cni \ --cni-conf-dir=/etc/cni/net.d(默认路径) \ --cni-bin-dir=/opt/cni/bin(默认路径) \ 注意： 上面的路径是默认的，如果更改，则需要修改对应参数的值为正确路径； 2.kubernetes使用了CNI网络插件之后，工作过程是这样的：（Pod的网络的创建过程） 1.首先必须有pause基础容器，每个Pod除了创建时指定的业务容器外，都有一个kubelet启动时指定的基础容器，比如： mirrorgooglecontainers/pause-amd64 #所以需要在node节点先下载此镜像 2.首先由kubelet创建pause容器并生成network namespace 3.然后kubelet调用网络CNI driver，由它根据配置调用具体的CNI插件（因为配置的是CNI，所以会调用CNI相关代码） 4.CNI driver根据配置调用具体的cni插件给pause容器配置正确的网络 5.Pod中其他的容器都是用pause的网络 3.CNI插件类型种类： 1.常用CNI插件有flannel、calico、weave等等，这些插件各有优势，也在互相借鉴学习优点,比如： 在所有node节点都在一个二层网络时候，flannel提供hostgw实现，避免vxlan实现的udp封装开销，估计是目前最高效的；calico也针对 L3 Fabric，推出了IPinIP的选项，利用了GRE隧道封装；因此这些插件都能适合很多实际应用场景。 5.Flannel、Caclio、Canel的区别和选择1.Flannel 简单易用，但不支持网络管理，没有网络策略管理功能，后端默认使用vxlan通信。默认情况下vxlan会对数据包进行封装和拆包，这样会影响中一定的网络 传输的性能。但可以通过directrouting选项来开启直接路由模式，也就是不封装和拆包，默认值为false，改为true即可。通过开启directrouting虽然提 高网络性能，但是这种模式只支持所有node节点在同一网段下才有效，也就是不需要路由就可以到达的网络。如果node节点在不同网络下会被自己降低为 需要封装和拆包的模式。另外同样可以不使用vxlan通讯，可将其改为host-gw这种模式就是指定使用直接通讯模式，但如果集群内有不同网段的node节点， 那么就会导致网络无法正常通讯，由coreOS研发的轻量级的网络实现方案，默认使用10.244.0.0/16网段； 1.Flannel网络原理： 1.cni0桥 cni0是flannel为了自己管理网络，没有使用docker0桥而创建的 2.flannel.1 是flannel的隧道接口桥，他是专门封装隧道协议的专用接口，隧道协议默认是VxLan； 3.A节点上的pod会分配cni0网桥(10.244.1.0/24)上的地址,如果通信地址是10.244.10.244.2.0/24的地址，会通过内核级的路由送到flannel.1 上，然后由flannel.1打上隧道报文进行跨节点的隧道间协议转发； 2.flannel.1接口的报文封装转发方式：和backend选择 1.VxLAN 1.vxlan虽然是二层协议隧道；但是可以降级为host-gw类型，实现当k8s所有节点在同一物理网络中可以使用host-gw类型提高性能，如果不在同一个物理网络中则工作于VxLAN模型; 2.即如果节点不是一个二层（不是同网段）网络，只有三层可达，请选用vxlan类型 2.UDP 四层UDP协议隧道，性能较差 3.host-gw 通过物理网桥直接接入到物理网络中，性能虽好但是所有物理节点必须在同一个物理网络中（意味着是通过MAC地址通信）不能跨路由器，范围和 数量就会有很大局限性，特别是很多k8s集群是构建在公有云上的，哪些ECS肯定不是在一台交换机上，如果要使用flannel插件必然要使用VxLan方式； 3.缺点： 1.不支持网络策略 2.flannel实现方案是基于VxLAN技术,也就是叠加网络 3.flannel也支持隧道网络，而且是三层隧道:IPIP； 4.网络信息存储： 因为flannel也是通过etcd来保存分配出去的网段和节点IP的映射关系的 1.如果是以pod运行可以通过apiserver间接共享k8s集群的etcd存储 2.如果不以pod形式部署，一般还要额外搭建一套etcd存储,或者手动将flannel分配信息存到k8s-etcd集群中去，如下文使用脚本保存信息： ~]# vim save_to_etcd.sh #!/bin/bash etcdctl --endpoints=&quot;https://etcd01.cre.com:6379&quot; --ca-file=ca.pem --cert-file=flanneld.pem --key-file=flanneld-key.pem set /kubernetes/network/config &apos;{&quot;Network&quot;:&quot;10.244.0.0/16&quot;, &quot;SubnetLen&quot;: 24, &quot;Backend&quot;: {&quot;Type&quot;: &quot;host-gw&quot;}}&apos; 2.Calico: 1.支持网络配置与网络策略管理，基于BGP路由协议，性能上高于Flannel。支持很细的ACL规则控制，从而对网络隔离有了更好的隔离性。因为是基于BGP 路由，所以当worker节点是不同网段的情况下是直接使用BGP通讯，从而网络性能较高,默认使用192.168.0.0./16网络； 2.Calico利用Linux内核原生的路由和iptables防火墙功能。进出各个容器，虚拟机和主机的所有流量都会在路由到目标之前遍历这些内核规则。 3.caclio组件： 1.Felix：Calico agent：(calico/node) 1.运行在每台node上，为容器设置网络信息：IP,路由规则，iptable规则等; 2.每个主机上运行，​​从键\值存储中读取相关的策略和网络配置信息，并在Linux内核中实现它。 2.etcd:calico后端存储、用来保存Calico的策略和网络配置状态； 3.BIRD:BGP Client： 1.负责把Felix在各node上设置的路由信息广播到Calico网络( 通过BGP协议)。 2.IPIP：IPIP是一种将各Node的路由之间做一个tunnel，再把两个网络连接起来的模式，启用IPIP模式时，Calico将在各Node上创建一个名为&quot;tunl0&quot;的虚拟网络接口； 注意： 1.当k8s的node节点都在同一个网络中，可以关闭IPIP功能来提供网络性能； 2.当node节点不在一个网络中时，IPIP功能是必须要开的；如何开启和关闭IPIP功能，见下文部署caclio; 4.BGP Route Reflector：大规模集群的分级路由分发。 5.calicoctl： calico命令行管理工具、允许您从简单的命令行界面实现高级策略和网络。 6.orchestrator插件：提供与各种流行协调器的紧密集成和同步。 7.Dikastes/Envoy： 可选的Kubernetes组件，通过相互TLS身份验证保护工作负载到工作负载的通信，并实施应用层策略。 3.Canel: caclio+flannel即flannel的网络功能+caclio的网络策略功能； 4.Calico与flannel的不同之处 1.Calico与flannel都是需要访问etcd集群，来存储数据 1.1.flannel在etcd需要创建虚拟网络，在后续从这个虚拟网段中分配node的IP网段； 1.2.Calico则无需在etcd提前创建虚拟网络，直接启用即可，因为网段会直接写在linux的路由表上; 2.Calico有什么flannel没有的缺点？ 2.1.Calico自动分配pod的IP地址是存储在etcd的，如果kubernetes需要更新版本，那么就要停某个node节点的服务；在停服务之间，如果没有将该node节点的pod删除掉，残留部分，这个时候残留的pod IP也会在etcd数据中残留，当你再启动的时候，很可能由于etcd还有残留的数据，导致这些残留的pod数据无法启动。 2.2.flannel目前使用上没有发现这种情况 3.Calico与flannel转发的协议区别： Calico是基于BGP协议进行转发的，而flannel是通过封装数据帧进行转发的。 5.如何选择网络插件？ 1.生产环境中最开始是使用flannel作为集群的docker容器之间的网络转发服务的，其实在使用的过程也没感觉有很大的不妥，但是在考虑了flannel与 calico网络的性能差异之后，就决定转用calico的网络集成方式了； 2.至于后面选择caclio是因为生产环境的原因： 1.我们的生产环境都是centos7裸机的环境，或者在阿里云、腾讯云直接购买多台centos7系统的服务器。 2.还有就是客户方提供的私有云，使用刀片服务器基于vsphere等集群构建的几台centos7虚拟机： 通常这种情况下客户方的私有云可能存在比较频繁的网络波动，，默默排查一下集群异常的原因，最后通过etcd的心跳日志一看，存在很大的网络延迟，导致etcd集群服务出现异常，从而影响了整个kubernetes的集群服务； 3.不使用flannel的原因： 1.基于第2条知道，所以如果在将k8s集群构建在阿里云、腾讯云等云平台，你就肯定要用VxLan的方式了，因为这些虚拟机大部分情况肯定不是在一台 交换机的，host-gw的方式经过验证是用不成的； 2.同时flannel的转发过程中是很占用服务器的CPU性能的，而且转发的效率也比较低； 当然是相对而言的啦，我在生产环境运行了一年多，感觉要求不是很高的话也还行 3.而且flannel还带有一个缺点： flannel是非常依赖防火墙的转发规则的，而calico并不依赖 4.网络策略 如果想在k8s中使用网络策略功能，那么必然是caclio了； 6.Flannel网络原理和部署flannel项目–flannel原理图–flannel是怎么工作的–Flannel下的Pod间的通信过程 1.Flannel网络原理 关于Flannel使用的原理这里不做深入的探讨，只讲解Pod同一node节点与不同Worker节点的通讯原理，如上图示： 1.Flannel网络插件只负责Pod间的网络通讯问题，那么一般Flannel会被部署在node节点上面，但如果Master节点也是使用容器部署的，那么Flannel也会被部署到Master节点; 2.部署成功Flannel网络插件后会在当前节点上创建两张网卡，一张为cni0的虚拟交换机，另一张为flannel1.1的虚拟网卡，如上图所示： 可以将docker0理解为cni0。通过下面Flannel的部署我们知道Pod的使用的总网段被划分为了多个不同的小网段，这些网段的信息被存入了k8s的后端 存储etcd集群中。当加入一个node节点的时候，集群会从这里小的网段里面分配一个给当前的node节点。一般当前分配的网段的第一个可用IP会被分配 到cni0的虚拟交换机，这个IP也相当于是一个网关，而剩下的可用IP会被当前node节点的Pod所使用; 3.Pod同k8s-node节点通讯: 同node节点的比较简单，数据包到达cni0虚拟交换机后就转发到了目标的Pod; 4.Pod跨node节点通讯过程：通信逻辑如上图 1.数据包首先会到达cni0虚拟交换机； 2.数据包到达虚拟交换机后，发现不是发送到本交换机下的数据包。这时候会通过对应的路由将数据包转发至flannel1.1。这里的路由信息由本机； 3.数据包到达flannel1.1的时候会对数据包进行第一次封装，然后再将数据包c通过eth0发送到node节点的网卡上。因为flannel是通过eth0的网卡 进行了隧道封装，可以在eth0上进行抓包（抓包信息：外层是eth0之间的通信，内层是pod-pod的通信）； 4.经过flannel1.1封装过的数据包还不可以直接在网络上面进行传输，所以这时候还会再对数据包进行第二次封装，再将数据包发送到对应的node 节点。在这封装的信息里面包含了要发往的目标node节点，目标节点的信息是从Etcd集群中获取的; 5.知道了目标node节点的信息，目标节点的路由信息是系统自己维护，根据路由信息，数据包将由flannel.1转发出去，最终到达目标node节点的flannl.1的接口。 6.这时候目标node节点接收到来自其它节点的数据，然后将数据经过解包后发往了flannel1.1虚拟网卡，再到达cni0虚拟交换机，最后到达了目标Pod。 5.详细的通讯报文传输过程： 参考下面的抓包测试截图； 6.创建容器网络的流程就是：kubelet——&gt;flannel——&gt;flanneld。如果宿主机上并发创建Pod，则你会看到有多个flannel进程在后台，不过正常几秒钟就会结束，而flanneld是常驻进程; 2.部署方式： 1.以pod形式部署 flannel会共享节点的网络名称空间，在节点上自动创建cni0和flannel.1接口； 这样就类似于节点上的运行了一个flannel系统级守护进程. 2.在节点上以安装包方式安装 手动部署，手动修改配置文件，通过systemctl控制启动. 备注： 以pod形式运行更易于升级 3.提供CNI插件 注意：flannel需要提前准备CNI插件，calico会由内部的install-cni：calico\cniv3.1.3镜像来完成的； 下载地址：https://github.com/containernetworking/plugins/releases ~]# 上传CNI插件到k8s的所有node节点上； ~]# mkdir -p /opt/cni/bin #创建展开路径，因为这是默认的加载路径 ~]# tar xf cni-plugins-amd64-v0.7.4.tgz -C /opt/cni/bin/ #展开到这个特定的目录 ~]# ls /opt/cni/bin/ bridge dhcp flannel host-device host-local ipvlan loopback macvlan portmap ptp sample tuning vlan #确保这些二进制程序文件都生成了，后面安装flannel或者caclio时，会自动在此目录下查找对应网络插件的可执行文件，用于容器IP地址的分配； 其中：flannel用到的插件 - bridge - flannel - host-local - loopback - portmap #可以只复制这5个插件到bin目录下即可 Flannel-CNI插件的配置文件可以包含多个plugin或由其调用其他plugin；Flannel-DaemonSet Pod运行以后会生成/run/flannel/subnet.env 文件，例如： FLANNEL_NETWORK=10.244.0.0/16 FLANNEL_SUBNET=10.244.10.1/24 FLANNEL_MTU=1472 FLANNEL_IPMASQ=true 然后它利用这个文件信息去配置和调用`bridge`插件来生成容器网络，调用host-local来管理IP地址，例如： { &quot;name&quot;: &quot;mynet&quot;, &quot;type&quot;: &quot;bridge&quot;, &quot;mtu&quot;: 1472, &quot;ipMasq&quot;: false, &quot;isGateway&quot;: true, &quot;ipam&quot;: { &quot;type&quot;: &quot;host-local&quot;, &quot;subnet&quot;: &quot;10.244.10.1/24&quot; } } 4.以pod方式部署flannel； ~]# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml #直接使用上面flannel项目的配置清单部署即可 配置清单文件内容如下: kind: ConfigMap apiVersion: v1 metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flannel data: cni-conf.json: | { &quot;name&quot;: &quot;cbr0&quot;, &quot;plugins&quot;: [ { &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: { &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true } }, { &quot;type&quot;: &quot;portmap&quot;, &quot;capabilities&quot;: { &quot;portMappings&quot;: true } } ] } net-conf.json: | { &quot;Network&quot;: &quot;10.244.0.0/16&quot;, &quot;Backend&quot;: { &quot;Type&quot;: &quot;vxlan&quot; } } 5.选项说明、修改为host-gw模式 1.关于Flannel网络部署配置清单文件关键配置项说明: 1.Network：Pod使用的网络。 2.Backend：后端使用协议，默认为vxlan，默认没有开启Directrouting，如果需要开始的话在backend里面再加一个选项，如下所示。 &quot;Backend&quot;: { &quot;Type&quot;: &quot;vxlan&quot;, &quot;Directrouting&quot;: true } 2.如果需要使用host-gw模式的话，直接将Type的值改为host-gw即可。 &quot;Backend&quot;: { &quot;Type&quot;: &quot;host-gw&quot;, } 3.关于net-conf.json里面还可以定义以下一些配置，如: 1.SubnetLen：定义每个子网的掩码长度，默认为24。如果为24，那么10.244.0.0/16就会被分成255个子网，其中每个Worker节点会使用一个子网。 每个子网里有多少个地址可用就意味着每个Worker节点可以运行多少个Pod。 2.SubnetMin：定义Pod网络的起始，默认是从10.244.0.0/24开始，也可以定义从10.244.10.0/24开始，也不一定要使用10开始的网络。 3.SubnetMax：与上面相反，定义Pod网络的结束。 4.其他信息： 另外，你还会发现每个Node都被打上了很多flannel开头的Annotation，这些Annotation会在每次flanneld启动时RegisterNetwork的时候进行更新。这些Annotation主要用于Node Lease。 flannel.alpha.coreos.com/backend-data: &quot;null&quot; flannel.alpha.coreos.com/backend-type: host-gw flannel.alpha.coreos.com/kube-subnet-manager: &quot;true&quot; flannel.alpha.coreos.com/public-ip: xx.xx.xx.xx flannel.alpha.coreos.com/public-ip-overwrite:yy.yy.yy.yy (ps:optional) 5.host-gw模式原理 1.flannel不仅提供基于封装类型的互联技术，也提供基于路由技术的互联技术，那就是host-gw模式; 2.host-gw模式通过建立主机IP到主机上对应flannel子网的mapping，以直接路由的方式联通flannel的各个子网; 3.这种互联方式没有vxlan等封装方式带来的负担，通过路由机制，实现flannel网络数据包在主机之间的转发; 4.缺点： 所有节点之间都要相互有点对点的路由覆盖，并且所有加入flannel网络的主机需要在同一个LAN里面；所以每个节点上有 n-1个路由，而n个节点一共有n(n-1)/2个路由以保证flannel的flat网络能力； 6.~]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE kube-flannel-ds-amd64-csa29l 1/1 Running 0 10s kube-flannel-ds-amd64-vskspz 1/1 Running 0 20s kube-flannel-ds-amd64-x38cks 1/1 Running 0 30s #因为只是pod-pod间通信，所以flannel网络插件只会运行在node节点上 6.1.kube-flannel容器 在kube-flannel容器里面运行的是我们的主角flanneld，我们需要关注的这个容器里面的目录/文件： /etc/kube-flannel/cni-conf.json /etc/kube-flannel/net-conf.json /run/flannel/subnet.env /opt/bin/flanneld ~]# kubectl exec -it kube-flannel-ds-amd64-csa29l -n kube-system /bin/sh /run/flannel # cat /etc/kube-flannel/cni-conf.json { &quot;name&quot;: &quot;cbr0&quot;, &quot;plugins&quot;: [ { &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: { &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true } } ] } /run/flannel # cat /etc/kube-flannel/net-conf.json { &quot;Network&quot;: &quot;10.244.0.0/16&quot;, &quot;Backend&quot;: { &quot;Type&quot;: &quot;vxlan&quot; } } /run/flannel # cat /run/flannel/subnet.env FLANNEL_NETWORK=10.244.0.0/16 FLANNEL_SUBNET=10.244.26.1/24 FLANNEL_MTU=1500 FLANNEL_IPMASQ=true 6.2.initContainers:：install-cni辅助容器 install-cni容器顾名思义就是负责安装cni插件的，把镜像里的flannel等二进制文件复制到宿主机的/etc/cni/net.d，注意这个目录要匹配 kubelet对应的cni配置项，如果你没改kubelet默认配置，那么kubelet默认也是配置的这个cni目录。我们需要关注install-cni容器内的目录/文件： /host/etc/cni/net.d/ /host/opt/cni/bin/ /host/etc/cni/net.d/10-flannel.conflist ~]# kubectl exec -it kube-flannel-ds-amd64-csa29l -c install-cni -n kube-system /bin/sh #连接到同一个pod内的sidecar容器内 /host/etc/cni/net.d # ls 10-flannel.conflist dhcp ipvlan noop tuning bridge flannel loopback portmap vlan cnitool host-local macvlan ptp /host/etc/cni/net.d # cd /host/opt/cni/bin/ /host/opt/cni/bin # ls 10-flannel.conflist dhcp ipvlan noop tuning bridge flannel loopback portmap vlan cnitool host-local macvlan ptp /opt/cni/bin # ls bridge dhcp host-local loopback noop ptp vlan cnitool flannel ipvlan macvlan portmap tuning /opt/cni/bin # cat /host/etc/cni/net.d/10-flannel.conflist { &quot;name&quot;: &quot;cbr0&quot;, &quot;plugins&quot;: [ { &quot;type&quot;: &quot;flannel&quot;, &quot;delegate&quot;: { &quot;hairpinMode&quot;: true, &quot;isDefaultGateway&quot;: true } } ] } 7.验证flannel网络 在集群创建几个测试pod: ~]# kubectl run test --image=busybox --replicas=3 sleep 30000` ~]# kubectl get pod --all-namespaces -o wide|head -n 4 NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE default busy-5956b54c8b-ld4gb 1/1 Running 0 9m 172.20.2.7 192.168.1.20 default busy-5956b54c8b-lj9l9 1/1 Running 0 9m 172.20.1.5 192.168.1.21 default busy-5956b54c8b-wwpkz 1/1 Running 0 9m 172.20.0.6 192.168.1.22 查看路由 ~]# ip route default via 192.168.1.254 dev ens3 onlink 192.168.1.0/24 dev ens3 proto kernel scope link src 192.168.1.20 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 172.20.0.0/24 via 192.168.1.22 dev ens3 172.20.1.0/24 via 192.168.1.21 dev ens3 172.20.2.0/24 dev cni0 proto kernel scope link src 172.20.2.1 在各节点上分别 ping 这三个POD IP地址，确保能通： ~]# ping 172.20.2.7 ~]# ping 172.20.1.5 ~]# ping 172.20.0.6 8.Flannel部署及使用时的排错帮助 https://github.com/coreos/flannel/blob/master/Documentation/troubleshooting.md 官方列出了flannel常见的报错信息，可以参考此文章！ –抓包测试 7.部署Cacliocaclio官方安装介绍–caclio原理图 环境要求： 1.Calico 是一个基于BGP协议的网络互联解决方案。它是一个纯3层的方法，使用路由来实现报文寻址和传输。； 2.相比flannel,ovs等SDN解决方案，Calico避免了层叠网络带来的性能损耗。将节点当做router，位于节点上的container被当做router 的直连设备。利用Kernel来实现高效的路由转发。 节点间的路由信息通过BGP协议在整个Calico网络中传播。 具有以下特点： 1.在calico中的数据包不需要进行封包和解封。 2.基于三层网络通信，troubleshoot会更方便。 3.网络安全策略使用ACL定义，基于iptables实现，比起overlay方案中的复杂机制更只管和容易操作。 3.Calico会使用DaemonSet在每一个node节点上部署一个calico容器，使用BGP网络会自动学习主机上的路由，当网络环境很大，需要在 跨机房部署k8s集群时，需要在交换机设备上开启BGP，否则跨机房时就访问不了； 4.calico学习路由的方式： calico会自己学习路由，它出去的源地址网络就是容器本身，不像flannel使用宿主机的网卡出去；比如： node1:上各运行3个pod:node1-pod1、node1-pod2、node1-pod3 node2:上运行3个pod:node2-pod1、node2-pod2、node2-pod3 对于flannel来说的报文流程： node1-pod1访问node2-pod2是使用overlay方式，流程： node1-pod1-&gt;cni0-&gt;flannel.1-&gt;node1-eth0&lt;--------&gt;node02-eth0-flannel.1-&gt;cni0-&gt;node2-pod2，必须依赖宿主机物理网卡通信； 对于Calico来说的报文流程： calico会在node1主机上自动学习静态路由，这个静态路由指的是：calico会学习到我们事先规划好的每个node节点上的pod网络，比如： node1的pod网段：10.244.20.0/255.255.255.192,它有64个主机位，然后node1就会加一条静态路由，然后通告给其他节点； node2的pod网段：10.244.30.0/255.255.255.192,那么node2到达node1节点的静态路由就是： route add 10.244.20.0/255.255.192.0 gw node1-ip,通信时不需要经过flannel的flannel.1、物理网络eth0等报文封装带来的性能损耗，而是直接通过物理网卡通信； 具体路由信息可以看下文安装好calico后的route路由信息； 1.安装方式： 1.Calico有多种托管方式，因为我们使用的二进制部署方式，所以首先可以抛开kubeadm这种不适合生产环境的方式； 2.标准托管方式与kubernetes数据存储区分的方式有什么区别呢？ 1.标准托管方式： Calico与kubernetes共用一套etcd集群存储数据 2.kubernetes数据存储区分：Calico与kubernetes分别单独各自使用一套etcd集群存储数据； 在线上一般是使用标准托管方式，因为维护一套etcd集群便于管理 3.caclio版本： 根据安装的k8s版本依赖的或者推荐的caclio版本安装即可； 4.安装前注意事项： 1.安装前检查主机名不能有大写字母，只能由小写字母、-、.组成 (regex: [a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*))(calico-node v3.0.6以上已经解决主机大写字母问题)； 2.安装前必须确保各节点主机名不重复： calico node name由节点主机名决定，如果重复，那么重复节点在etcd中只存储一份配置，BGP邻居也不会建立。 3.安装之前必须确保kube-master和kube-node节点已经成功部署； 4.等待15s后（视网络拉取calico相关镜像速度），calico网络插件安装完成，删除之前kube-node安装时默认cni网络配置 2.提供CNI插件 下载地址：https://github.com/containernetworking/plugins/releases ~]# 上传CNI插件到k8s的所有node节点上； ~]# mkdir -p /opt/cni/bin #创建展开路径，因为这是默认的加载路径 ~]# tar xf cni-plugins-amd64-v0.7.4.tgz -C /opt/cni/bin/ #展开到这个特定的目录 ~]# ls /opt/cni/bin/ bridge dhcp flannel host-device host-local ipvlan loopback macvlan portmap ptp sample tuning vlan #确保这些二进制程序文件都生成了，后面安装flannel或者caclio时，会自动在此目录下查找对应网络插件的可执行文件，用于容器IP地址的分配； 备注： 在caclio.yaml部署时，CNI插件的安装是由内部的install-cni：calico/cniv3.1.3镜像来完成的； 3.标准托管方式安装caclio 1.RBAC： 如果在启用RBAC的群集上部署Calico，则应首先应用ClusterRole和ClusterRoleBinding规范,下载清单，如需修改清单，可以修改后再部署； ~]# kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/rbac.yaml clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created clusterrole.rbac.authorization.k8s.io/calico-node created clusterrolebinding.rbac.authorization.k8s.io/calico-node created 2.生成caclio-etcd-secret的secret资源 A.在caclio.yaml清单中需要用到caclio需要通过apiserver间接访问etcd集群，所以需要提前为caclio生成etcd客户端的证书和私钥，并转为secret资源进行挂载使用； B.这里手动创建caclio-etcd-secrets资源，而不使用caclio.yaml清单中方式，需要下文还会标注怎么把那段注释掉； 1.创建calico证书请求 ~]# vim calico-csr.json.j2 { &quot;CN&quot;: &quot;calico&quot;, &quot;hosts&quot;: [], &quot;key&quot;: { &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 }, &quot;names&quot;: [ { &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;HangZhou&quot;, &quot;L&quot;: &quot;XS&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; } ] } 2.生成calico证书和私钥 ~]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes calico-csr.json | cfssljson -bare calico caclio.pem caclio-key.pem 3.生成calico-etcd-secrets的secret资源（在kube-system名称空间中） ~]# kubectl create secret generic -n kube-system calico-etcd-secrets --from-file=etcd-ca=ca.pem --from-file=etcd-key=calico-key.pem --from-file=etcd-cert=calico.pem #因为caclio.yaml中挂载的secret资源名称就是calico-etcd-secrets并放在kube-system名称空间中； 4.准备caclioTLS目录 ~]# mkdir /etc/calico/caclioTLS/ #该目录是为caclio.yaml清单中的configmap启用TLS认证准备的 ~]# ls /etc/calico/caclioTLS/ caclio.pem caclio-key.pem #将caclio的证书和私钥放到此目录下 3.下载caclio部署清单 ~]# wget https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/calico.yaml #这里下载caclio-v3.3版本的 在部署前需要修改几项： 1.修改镜像拉取地址； caclio.yaml文件中有依赖三个镜像，如下： image: quay.io/calico/node:v3.3.6 image: quay.io/calico/cni:v3.3.6 image: quay.io/calico/kube-controllers:v3.1.6 因为quay.io访问很慢，一般是先下载下来上传到本地harbor上，再从本地拉取 image: harbor1.cre.io/calico-node:v3.3.6 image: harbor1.cre.io/calico-cni:v3.3.6 image: harbor1.cre.io/calico-kube-controllers:v3.3.6 2.注释掉caclio.yaml清单中关于secret的信息 apiVersion: v1 kind: Secret type: Opaque metadata: name: calico-etcd-secrets namespace: kube-system data: # etcd-key: null # etcd-cert: null # etcd-ca: null --- #将此三项注释掉，因为上文已手动创建了calico-etcd-secrets资源； 3.修改caclio.yaml清单中ConfigMap的部分主要参数如下，按需修改： kind: ConfigMap apiVersion: v1 metadata: name: calico-config namespace: kube-system data: etcd_endpoints: &quot;http://127.0.0.1:2379&quot; calico_backend: &quot;bird&quot; cni_network_config: |- { &quot;name&quot;: &quot;k8s-pod-network&quot;, &quot;cniVersion&quot;: &quot;0.3.0&quot;, &quot;plugins&quot;: [ { &quot;type&quot;: &quot;calico&quot;, &quot;etcd_endpoints&quot;: &quot;__ETCD_ENDPOINTS__&quot;, &quot;etcd_key_file&quot;: &quot;/etc/calico/ssl/calico-key.pem&quot;, &quot;etcd_cert_file&quot;: &quot;/etc/calico/caclioTLS/calico.pem&quot;, &quot;etcd_ca_cert_file&quot;: &quot;/etc/kubernetes/ssl/ca.pem&quot;, &quot;log_level&quot;: &quot;info&quot;, &quot;mtu&quot;: 1500, &quot;ipam&quot;: { &quot;type&quot;: &quot;calico-ipam&quot; }, &quot;policy&quot;: { &quot;type&quot;: &quot;k8s&quot; }, &quot;kubernetes&quot;: { &quot;kubeconfig&quot;: &quot;/root/.kube/config&quot; } }, { &quot;type&quot;: &quot;portmap&quot;, &quot;snat&quot;: true, &quot;capabilities&quot;: {&quot;portMappings&quot;: true} } ] } #如果etcd集群启用了TLS证书认证，需要将下面三项都启用 etcd_ca: &quot;/calico-secrets/etcd-ca&quot; #etcd的CA证书 etcd_cert: &quot;/calico-secrets/etcd-cert&quot; #etcd的证书 etcd_key: &quot;/calico-secrets/etcd-key&quot; #etcd的私钥 #这三个路径是etcd访问TLS文件的容器中的路径，默认的，不需要修改 ############################################################### 1.etcd_endpoints：Calico使用etcd来保存网络拓扑和状态，该参数指定etcd的地址，可以使用K8S Master所用的etcd，也可以另外搭建； 改为：etcd_endpoints: &quot;https://etcd01.cre.io:2379,https://etcd02.cre.io:2379,https://etcd03.cre.io:2379&quot; 2.calico_backend：Calico的后端，默认为bird； 3.修改cni_network_config中的信息 type=calico： Kubelet从CNI_PATH（默认为/opt/cni/bin）找名为calico的可执行文件，用于容器IP地址的分配； etcd_endpoints：etcd集群地址，同上 &quot;etcd_key_file&quot;: &quot;/etc/calico/caclioTLS/calico-key.pem&quot;, &quot;etcd_cert_file&quot;: &quot;/etc/calico/caclioTLS/calico.pem&quot;, &quot;etcd_ca_cert_file&quot;: &quot;/etc/kubernetes/ssl/ca.pem&quot;, #caclio证书的本地路径 &quot;kubernetes&quot;: { &quot;kubeconfig&quot;: &quot;/root/.kube/config&quot; #使用的kubeconfig文件 4.修改calico.yaml清单关于通过DaemonSet部署的calico-node服务的主要参数： 1.该POD中主包括如下两个容器： 1.calico-node：calico服务程序，用于设置Pod的网络资源，保证pod的网络与各Node互联互通，它还需要以HostNetwork模式运行，直接使用宿主机网络。 2.install-cni：在各Node上安装CNI二进制文件到/opt/cni/bin目录下，并安装相应的网络配置文件到/etc/cni/net.d目录下。 2.calico-node服务的主要参数： CALICO_IPV4POOL_CIDR：&quot;192.168.0.0/16&quot; Calico IPAM（IP分配）的IP地址池，Pod的IP地址将从该池中进行分配,默认是192.168.0.0/16，如果是规划的其他网络，需要修改正确； FELIX_LOGSEVERITYSCREEN：info #日志级别,可以改为warning FELIX_IPV6SUPPORT：flase #是否启用IPV6，默认不启用 FELIX_DEFAULTENDPOINTTOHOSTACTION:ACCEPT #默认允许Pod到Node的网络流量 CALICO_IPV4POOL_IPIP： 是否启用IPIP模式：启用IPIP模式时，Calico将在node上创建一个tunl0的虚拟隧道；你启用IPIP时，路由规则直接使用物理机网卡作为路由器转发。 备注： IP Pool可以使用两种模式：BGP或IPIP。 启用IPIP模式时，设置CALICO_IPV4POOL_IPIP=&quot;always&quot;，不使用IPIP模式时，设置为&quot;off&quot;，此时将使用BGP模式，当k8s的node 节点在同一网络时可以关闭IPIP功能来提高网络性能，当不在一个网络或者运行在公有云上需一定要开启IPIP功能，所以设置默认开启就行了； 5.查看挂载的secret资源 volumes: - name: etcd-certs secret: secretName: calico-etcd-secrets defaultMode: 0400 #calico-node和calico-kube-controllers都是通过这种方式挂载的； 6.部署 ~]# kubectl apply -f calico.yaml configmap/calico-config created secret/calico-etcd-secrets created daemonset.extensions/calico-node created deployment.extensions/calico-kube-controllers created serviceaccount/calico-kube-controllers created serviceaccount/calico-node created #部署完成 4.验证caclio和集群状态 ~]# calicoctl version #执行客户端命令，验证caclico版本是否安装正确 ~]# calicoctl node status #验证calico网络是否正常 Calico process is running IPv4 BGP status +--------------+-------------------+-------+-------+-------------+ | PEER ADDRESS | PEER TYPE | STATE | SINCE | INFO | +--------------+-------------------+-------+-------+-------------+ | 192.168.1.20 | node-to-mode mesh | up | 10:20 | Established | | 192.168.1.21 | node-to-mode mesh | up | 10:20 | Established | | 192.168.1.22 | node-to-mode mesh | up | 10:20 | Established | +--------------+-------------------+-------+-------+-------------+ IPv6 BGP status No IPv6 peer found. #使用calicoctl node status验证，每个node节点都是Established就是正常的,这里因为是3台节点所以是3条信息； 查看路由 ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.1.1 0.0.0.0 UG 0 0 0 ens3 10.20.161.192 192.168.1.20 255.255.255.192 UG 0 0 0 tunl0 10.20.218.0 192.168.1.21 255.255.255.192 UG 0 0 0 tunl0 10.20.167.130 192.168.1.22 255.255.255.192 UG 0 0 0 tunl0 10.20.222.190 0.0.0.0 255.255.255.192 UG 0 0 0 * 192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 ens3 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 其中： 1.在Destination中10.20.*.*/255.255.255.192的就是calico为node节点分配的pod网段 2.比如10.20.161.192 192.168.1.20 255.255.255.192 UG 0 0 0 tunl0就是一条静态路由，即： route add 10.20.161.192/255.255.255.192 gw 192.168.1.20,当前主机到达node节点IP为192.168.1.20的静态路由； BGP协议信息： 1.calico是使用BGP协议，会自动学习node节点上的路由条目（route -n）; 2.BGP协议是通过TCP连接来建立邻居的，因此可以用netstat命令验证BGP Peer ~]# netstat -antlp|grep ESTABLISHED|grep 179 tcp 0 0 192.168.1.10:179 192.168.1.20:42316 ESTABLISHED 28479/bird tcp 0 0 192.168.1.10:179 192.168.1.21:40320 ESTABLISHED 28479/bird tcp 0 0 192.168.1.10:179 192.168.1.22:49330 ESTABLISHED 28479/bird ~]# kubectl get pod -n kube-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-795885ddbd-dr8t7 1/1 Running 0 1m calico-node-26brb 0/2 ContainerCreating 0 1m calico-node-w2ntg 0/2 ContainerCreating 0 1m calico-node-zk8ch 2/2 Running 0 1m ~]# kubectl get node NAME STATUS ROLES AGE VERSION k8s-master01 Ready,SchedulingDisabled master 1h20m v1.13.4 k8s-master02 Ready,SchedulingDisabled master 2h10m v1.13.4 k8s-master03 Ready,SchedulingDisabled master 3h30m v1.13.4 k8s-node01 Ready node 23m v1.13.4 k8s-node02 Ready node 33m v1.13.4 k8s-node03 Ready node 43m v1.13.4 5.查看etcd中calico相关信息： 因为这里calico网络使用etcd存储数据，所以可以在etcd集群中查看数据，calico-3.x版本默认使用etcd v3存储，登陆集群的任意一个etcd节点查看即可； ~]# ETCDCTL_API=3 etcdctl --endpoints=http://127.0.0.1:2379 --ca-file=/etc/kubernetes/ssl/ca.pem ls /calico #查看所有保存在etcd集群中的calico相关数据 ~]# ETCDCTL_API=3 etcdctl --endpoints=&quot;http://127.0.0.1:2379&quot; get --prefix /calico/ipam/v2/host #查看calico网络为各节点分配的网段 calico 2.x版本默认使用etcd v2存储，登陆集群的一个etcd 节点，查看命令： ~]# etcdctl --endpoints=http://127.0.0.1:2379 --ca-file=/etc/kubernetes/ssl/ca.pem ls /calico 6.部署pod测试网络是否正常 ~]# kubectl run net-test --image=alpine --replicas=4 sleep 36000 deployment.apps/net-test created #部署4个pod实例是为了使其运行在不同的node上，然后使用位于不同node的pod进行ping操作来验证网络正常与否； ~]# kubectl get pods -o wide NAME READY STATUS IP NODE net-test-cd766cb69-cb6x9 1/1 Running 10.20.218.2 k8s-node01 net-test-cd766cb69-fv9s8 1/1 Running 10.20.151.194 k8s-node02 net-test-cd766cb69-ssffz 1/1 Running 10.20.151.193 k8s-node02 net-test-cd766cb69-vfksm 1/1 Running 10.20.218.1 k8s-node03 #选择两个位于不同的NODE上的pod进行验证 ~]# kubectl exec -it net-test-cd766cb69-cb6x9 sh #登录位于node01上的pod / # / # ping 10.20.218.1 #ping位于k8s-node03上的Pod PING 10.20.218.1 (10.20.218.1) 56(84) bytes of data. 64 bytes from 10.20.218.1: icmp_seq=1 ttl=64 time=0.346 ms 64 bytes from 10.20.218.1: icmp_seq=2 ttl=64 time=0.670 ms / # ping 10.20.218.1 #ping位于k8s-node02上的Pod PING 10.20.151.193 (10.20.151.193) 56(84) bytes of data. 64 bytes from 10.20.151.193: icmp_seq=1 ttl=64 time=0.376 ms 64 bytes from 10.20.151.193: icmp_seq=2 ttl=64 time=0.620 ms #测试结果看到网络部署是正常的 8.网络策略：NetworkPolicy 1.为什么flannel不用vxlan来做网络策略实现网络隔离？ 1.尽管vlan可以做到设置网络策略达到访问限制，但是对于k8s集群来说这样做太鸡肋了； 2.因为kubernetes的网络概念中都是一种大网的模式，也就是所有pod是在同一个网络中的，当需要隔离性时采用Network Policy来解决，就是通过一些 声明的方式表示访问的权限和关系，类似于微服务的治理，而不是通过vxlan或者vlan这种传统的分区的方式。 2.网络策略就是各pod之间的网络通信的控制！ 1.因为namespace只是隔离名称的，而不能隔离网络通信，不同名称空间的Pod也是可以直接通信的. 2.如果有两个公司在公有云上使用同一个k8s集群，pod之间是可以通信的那么就没有安全性可言了，所以必须通过网络策略实现跨pod的网络通信之间的隔离. 3.网络策略可以 3.NetworkPolicy: 1.k8s为了实现跨组织的安全通信和安全隔离引入了标准的k8s资源允许用户在自己的名称 空间定义同一名称空间下的pod之间如何通信和跨名称空间的pod之间如何通信. 2.用户可以根据networkpolicy内部的逻辑自定义Pod间的访问控制规则； 3.netpol中的规则生效则是由k8s转为对应节点上的iptables或者ipvs规则. 4.netpol实际是k8s将不同操作系统的底层抽象出来的一种资源，通过对这种资源的定义进而又根据不同的操作系统在内核级完成的网络流量访问控制的控制逻辑转换成各自的规则. 4.定义networkpolicy: 1.应用于某一名称空间下的一组或一个pod施加访问控制的，如果没指定默认是所有的Pod，当然也可以selector选择特定的pod. 2.egress to:出站 egress定义了pod主动可访问的pod集群和如何访问的规则. 3.Igress from：入站 Ingress定义了pod能被哪些pod所访问和访问规则. 4.egress和ingress可以同时定义，也可以只定义其中之一. 标准对端的方法： 1.某个名称空间下的所有pod 2.某个名称空间下能被selector所匹配的pod 3.来自哪个IP客户端的 5.如何定义networkpolicies(netpol) ~]# kubectl explain networkpolicies(netpol) apiVersion: networking/v1(V1.9版本之后的群组) metadata: name namespace: #定义为哪个名称空间设置访问控制规则 kind: spec: podSelector: #通过便签选择器选择控制当前名称空间的哪些pod matchLabels matchExpressions # {}代表当前名称空间的所有pod policyTypes: Ingress/Egress/Ingress,Egress #policyTypes就是定义egress和ingress是否同时生效还是只生效其中之一,就是说上文即使都定义了规则，只有在此项中明确写出才会真正生效. egress: #定义出栈规则 to #对端的地址列表 - namespaceSelector #指定名称空间中的所有pod matchLabels matchExpressions #这里的匹配是指namespace标签不是pod podSelector #指定名称空间中的指定pod？？？ {} #为空代表当前规则所在名称空间的所有pod ipBlock #指定ip地址或网络地址 ports #对端是server端，应该是对端的端口 port #定义端口 protocol #定义协议 ingress: #定义入栈规则 from #对端的地址 - namespaceSelector #指定名称空间中的所有pod matchLabels matchExpressions #这里的匹配是指namespace标签不是pod podSelector #指定名称空间中的指定pod？？？ ipBlock #指定ip地址或网络地址 ports #自己时server端，应该是自己的端口 port #定义端口 protocol #定义协议 注意： 1.to和from表示都有三种方式，如果同时定义三种方式只要满足其一就可以了； 2.但是from中的from.namespaceSelector和from.podSelector是隐藏着一个逻辑: 2.1.如果podSelector不作为from的列表项和namespaceSelector是并关系 2.2.如果podSelector是from的列表项和namespaceSelector是或关系. 3.在k8s上必须显示定义，即被控制匹配到才能够被运行，如果没有被规则所匹配到默认就是拒绝的. 备注： 如果再定义networkpolicy之前两个pod之间已经做了通信测试，然后再设置拒绝策略或者允许策略，这写策略都是不生效的，所以应该先定义好netpol再进行通信. 6.网络策略示例： 示例1：默认拒绝所有名称空间的pod对test-1名称空间的访问 apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: deny-all-ingress namespace: test-1 spec: podSelector: {} # ingress: #如果加上ingress {}则表示允许所有外部的访问 # - {} policyTypes: - Ingress 示例2：在示例一的基础上允许只允许test-3名称空间对test-1的访问 apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-test-3-ingress namespace: test2 spec: podSelector: {} ingress: - from: - namespaceSelector: #通过namespace标签选择允许的名称空间 matchLabels: name: test3 policyTypes: - Ingress 示例3: 定义允许test2内部通信和来自test-3对test2的访问 apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-test-1-ingress namespace: test2 spec: podSelector: {} ingress: - from: - namespaceSelector: matchExpressions: - key: name operator: In value: [&quot;test3&quot;,&quot;test2&quot;] policyTypes: - Ingress 9.替换k8s集群的网络插件在测试环境的k8s集群中希望试用多种网络插件（calico/flannel/kube-router）,可以使用如下方式清理之前安装的网络插件 1.WARNNING：重新安装k8s网络插件会短暂中断已有运行在k8s上的服务 2.如果k8s集群已经运行庞大业务pod，重装网络插件时会引起所有pod的删除、重建，短时间内将给apiserver带来压力，可能引起master节点夯住; 3.确保没有裸pod运行（因为最后需要删除所有pod重建，裸pod不会重建），即所有pod 都是由deploy/daemonset/statefulset等创建； 1.替换流程 如果使用标准cni方式安装k8s集群的网络插件；cni负载创建容器网卡和IP分配（IPAM），不同的网络插件（calico,flannel等）创建容器网卡和IP分配方式不一样，所以在替换网络插件时候需要现有pod全部删除，然后自动按照新网络插件的方式重建pod网络； 2.替换操作： 大致流程为： a.根据实际运行情况，删除现有网络组件的daemonset pod b.如果现有组件是kube-router需要进行一些额外清理 c.暂停node相关服务，后面才可以进一步清理iptables等 d.执行旧网络插件相关清理 e.重新开启node相关服务 f.安装新网络插件 g.删除所有运行pod，然后等待自动重建 3.实例操作： 1.删除原network插件部署 ~]# kubectl delete -f flannel.yaml/calico.yaml #根据实际情况使用yaml清单删除之前部署的网络插件 2.停止k8s-node相关服务 ~]# systemctl stop kubelet kube-proxy 3.清理calico残留路由 如果需要清理calico，还需做此步骤 ~]# for rt in `ip route|grep bird|sed &apos;s/blackhole//&apos;|awk &apos;{print $1}&apos;`;do ip route del $rt;done; 4.清理kube-proxy产生的iptables规则 ~]# kube-proxy --cleanup 5.清理目录和文件 ~]# rm -rf ${dir} 需要清理的目录有下面这些 - &quot;/etc/cni/&quot; - &quot;/run/flannel/&quot; - &quot;/etc/calico/&quot; - &quot;/var/run/calico/&quot; - &quot;/var/lib/calico/&quot; - &quot;/var/log/calico/&quot; - &quot;/etc/cilium/&quot; - &quot;/var/run/cilium/&quot; - &quot;/sys/fs/bpf/tc/&quot; - &quot;/var/lib/cni/&quot; - &quot;/var/lib/kube-router/&quot; - &quot;/opt/kube/kube-system/&quot; 6.清理网络 ~]# &quot;ip link del tunl0; \ ip link del flannel.1; \ ip link del cni0; \ ip link del mynet0; \ ip link del kube-bridge; \ ip link del dummy0; \ ip link del kube-ipvs0; \ ip link del cilium_net; \ ip link del cilium_vxlan; \ systemctl restart networking; \ systemctl restart network&quot; 7.重启k8s-node服务 ~]# systemctl start kubelet kube-proxy 8.重新安装新的网络插件 ~]# kubectl apply -f flannel.yaml/calico.yaml 9.删除所有运行pod，由controller自动重建 ~]# vim restart_all_pod.sh #!/bin/bash for NS in $(kubectl get ns|awk &apos;NR&gt;1{print $1}&apos;);do kubectl delete pod --all -n $NS done;]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile]]></title>
    <url>%2F2018%2F10%2F18%2FDockerfile%2F</url>
    <content type="text"><![CDATA[DockerFile：构建镜像 前面说过： 1.镜像是分层的，当基于这个镜像创建一个容器时，docker是通过联合挂载机制把镜像层进行叠加作为容器的只读层，而后又在这个镜像栈 上构建了一个可写层作为这个容器的工作目录. 2.所有的底层数据在第一次发生修改操作时，是通过CoW写时复制机制，把数据复制到读写层进行修改并保存在读写层，覆盖底层的原始文件； 写入新数据时，则直接保存在读写层，而在读写层看到的数据就是全部的镜像层数据(镜像栈) 3.而Graph Driver则又在构建在本地文件系统之上的二级文件系统(aufs,overlay2) 4.基于Graph Driver这种特有的图形驱动程序，就可以把分成构建的镜像堆积在存储空间当中，紧邻的镜像是有依赖关系的 5.docker commit可以把当前的读写层及其底层依赖的镜像关系打包成一个镜像层存储在Graph Driver当中，并且指向底层依赖的镜像层， 形成一个新的镜像层，如果基于同一个镜像commit多个可写层，这些新的镜像层都是指向之前的底层镜像的，这也是docker镜像不是很大的原因。 6.所以在制作镜像时，完全不必基于某个基础镜像显示启动一个新容器，然后在上面创建修改可写层并打包成镜像；commit只是一种方式， 也可以使用dokcerfile 7.如果再本地将软件源码编译/二进制编译到容器也是可以的 dockerfile基本要求1.dockerfile的工作逻辑： 制作镜像无非就是基于某个基础镜像创建一个可写层修改后再commit成一层新的镜像这个过程可以由docker自身完成，只需要在 dockerfile配置文件中写清楚，基于哪个基础镜像，按需修改(通过各种指令生成)，而docker build可以读取dockerfile文件， 隐式的执行这些指令集生成一个新的镜像层保存在Graph Driver中 2.工作目录 构建docker镜像时，必须有一个工作目录docker,这个目录下只存在dockerfile和在dockerfile中定义要复制的文件，是起始目录 3.dockerfile format：语法 dockerfile就是一个纯文本文件; 注释行 dockerfile instruction args:指令要纯大写 第一条指令必须是FROM：基础镜像名称 docker build是按顺序读取执行dockerfile中的指令集的 4.dockerfile中的每一条指令都会生成一个新的镜像层 如果指令比较多，生成的镜像层就比较多，就会造成第一次的CoW从底层读取数据时很慢但是镜像层比较多又容易被分享和易控，较少又会 比较繁琐所以一般是把做同一个件事的多个操作通过\换行符，用一条指令完成(见下文) 5.镜像内唯一要运行的程序一定必须要运行在前台 dockerfile中的环境变量1.docker为了满足同一镜像在不同环境下的使用场景引入了环境变量的方式 某个容器基于镜像启动时，通过传递环境变量参数，来生成容器内的不同的配置文件 docker container run --name CONTAINER_NAME -e VAR -it IMAGE_NAME COMMAND 这样一来，就可以用基于同一基础镜像，传递不同的环境变量作为参数值，创建适应 于不同环境的容器 2.entrypoint.sh脚本 但是传统的代码不支持传环境变量作为参数，而在docker中又需要传参，这时就有了衔接层也就是shell脚本，这个脚本作为容器第一个要 运行的程序然后运行完退出，再退出去之前读取用户传的环境变量，将环境变量的值写到程序的配置文件中； 而且很多镜像通过docker image inspect mysql:8.0 |grep entrypoint过滤是可以看到有这个脚本的 3.环境变量的两类用法： a.在构建dockerfile中使用 b.以dockerfile构建的镜像为基础镜像，启动容器时使用 而dockerfile中的指令的生命周期是有两个阶段的 build：基于基础镜像构建镜像的阶段 run: 启动容器的阶段 dockerfile中的一些指令或者环境变量在不同阶段使用发挥的价值是不一样的 4.环境变量的设定和引用 设置：ENV statement 两种引用方式： 1.${variable:-word} 如果变量variable为空或不存在时，就使用word值 如果设置了variable，就使用该变量值 2.${variable:+word} 如果变量有值，就使用word值，如有没值就是空值 .dockerignore file1.dockerignore是工作目录中专门记录需要忽略的文件列表 2.而且docker build会自动忽略.dockerignore自身和记录在其中的所有文件 Dockerfile基本语法FROM： FROM必须是文件的第一指令 FROM &lt;repository&gt;[:&lt;tag&gt; 镜像的标签 或者&lt;resository&gt;@&lt;digest&gt; 镜像的ID号校验码 推荐使用digest因为校验码是安全的，而且最好不要使用lasted LABLE: authtor&apos;s infomation;提供该镜像的标签信息 语法： maintainer &quot;liu &lt;liu@163.com&gt;&quot; COPY: 从宿主机复制文件至创建的新镜像 COPY &lt;src&gt;... &lt;dest&gt; COPY [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;] &lt;src&gt;：要复制的源文件或目录，支持使用通配符 &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则，COPY指定则以WORKDIR为其起始路径； 注意：在路径中有空白字符时，通常使用第二种格式 注意： 1. src：必须为build上下文中的路径，可使用相对路径 2.如果src是目录，其内部的文件或子目录会自动被递归复制，但src自身不会被复制 等于cp -r /src/* /dest/ 3. src有多个，或者src使用通配符，则dest必须是一个目录，且必须以/结尾 4. 如果dest事先不存在，它将会被自动创建，包括其父目录； ADD: 类似于COPY，但是额外支持tar文件和URL路径 ADD &lt;src&gt;... &lt;dest&gt; ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;] 1. 如src为URL时且dest不以/结尾，ADD会自动将指定的文件下载并创建为dest， 如dest以/结尾，则会下载指定的文件并保存为dest/FILENAME 即一个是下载并改名，一个是下载到这个文件目录下 2. 如src是一个本地的tar文件，则会被自动展开为一个目录，但通过URL获取到的文件 则不会自动展开，即在本地的就展开，互联网的就不展开 3. 如src有多个，或使用通配符，则dest必须是目录且以/结尾，如dest不以/结尾， 则被视为一个普通文件，src的内容将被直接追加写入到dest文件中 WORKDIR： 1.用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录 2.WORKDIR指令可出现多次，表示下个指令可以以此目录为父目录，路径可以表示为相对 路径，也可以写成绝对路径 3.WORKDIR的有效范围当前workdir向下，下一个workdir之前的范围 4.另外，WORKDIR也可调用由ENV定义的环境变量的值，如果下次修改环境变量的值，响应生成信息的镜像层 5.而且如果设定了WORKDIR，容器启动时，默认就进入到workdir路径了 VOLUME： 用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷 注意： 1.在dockerfile中定义的卷，启动容器时，是被docker管理的卷与宿主机的某个 路径建立关联关系 2.如果需要定义的卷与宿主机特定的目录建立关联关系，还需要在run container时 指定-v选项 3.如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此 前的所有文件复制到新挂载的卷中 EXPOSE:都是动态端口暴露 用于为容器打开指定要监听的端口以实现与外部通信 EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议 注意： 1.即使在dockerfile中定义了暴露的端口，启动为容器时，端口也不会暴露的 因为是有安全风险的； 但可以用run container时加 -P选项强行暴露端口，但这是个动态端口暴露 用起来极其鸡肋！ ENV： build阶段使用的： 用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令 如ENV、ADD、COPY等）所调用，调用格式为$variable_name或${variable_name} 两种语法： 1.ENV &lt;key&gt; &lt;value&gt; &lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只 能设置一个变量； 2.ENV &lt;key&gt;=&lt;value&gt; ... 可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果 &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另外，反斜线也可用于续行； 定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能 缺点：如果想修改ENV定义的值，只能修改dockerfile中的值，比价麻烦，此时 就可以使用ARG来代替ENV 注意： 1.在build阶段和run阶段都可以传环境变量，不过为了区别两个阶段，build阶段的 ENV现在都用ARG来代替了(build阶段的ENV命令也比较老了) 2.在run阶段传的环境变量是给容器启动时所使用的 ARG： arg是在build阶段进行传值，替换dockerfile中的值 ARG &lt;name&gt; [=&lt;default&gt;] 可以设置默认值 当build创建镜像时没有传值，则使用在dockerfile中设置的默认值 既可以弥补ENV的缺点也可以和RUN，CMD的ENV传环境变量区别开 如：在build时更改home的值 docker image build --build-arg home=&quot;/webdata/&quot; /data/dockerfile/ -t myimg:v0.4 Healthcheck:容器健康状态监测，支持docker17版本之后的 1.--interval=DURATION(default 30s) 每隔多久检测一次 2.--timeout=DURATION(default 30s) 单次请求的等待应答时长 3.--start-period=DURATION(default 5s) 容器启动多久后，开始检测程序是否正常，根据不同程序时间不同 4.--reties=N (default 3) 重试次数 0表示成功，1表示不健康，2表示docker内部的健康检测返回值 虽然能检测容器是否为健康状态，但是容器本身是不能重启的，需要借助容器编排工具 一旦发现容器不健康，编排工具会自动重启容器 ONBUILD 用于在dockerfile中定义一个触发器 具体用法： 1.在dockerfile中定义ONBUILD指令后，build镜像时，是不执行ONBUILD指令的！ 而当别人在基于这个有ONBUILD的镜像，又做一个dockerfile，build镜像时， 被引用的镜像中的ONBUILD才执行 2.所以叫做指令的延迟执行，而且OBUILD指令后跟的命令一般是ADD一个互联网的 网址，因为COPY/ADD文件，可能别人的电脑上并没有这个文件 shell和RUN,CMD,ENTRYPOINT的区别1.先解释shell： 比如：[root@node02 ~]# 它是我们通过ssh连接的命令行接口而且是由一个shell进程打印出来的，如果我们运行一个ls,那么ls就是 当前这个shell的子进程，同理在这个接口下运行httpd呢，httpd当然也就是这个shell的子进程，所以说我们平时在命令行中启动的进程 都是shell的子进程!!! 2.进程管理和进程控制： 1.在进程管理中一定遇到过这个问题： 如果在ssh远程连接的shell中启动一个进程(比如就是httpd)，当这个ssh进程因为网络原因断开了那么这个SSH进程的所有子 进程(子子进程)都会终止，(ssh进程-&gt;shell进程-&gt;ls(httpd)进程); 2.进程控制 因此为了能够把某一进程运行为守护进程而且不会因为某一个shell终止而终止，就需要用进程控制，比如： &amp;:使用&amp;符号将当前进程送到后台去，但是依然和当前shell剥离不了关系； nohup:使用nohup剥离与当前终端的关系 比如： nohup httpd &amp;：就表示将httpd运行在后台并剥离与当前终端的关系，即当前的shell终止了，httpd进程不会终止，这就是守护进程的意义和价值； 3.所以说我们正常在shell命令行终端中启动的进程其实都是shell的子进程，而这个问题在容器中就不是问题了，因为在容器中进程必须 运行在前台且不能送到后台去； 3.shell的特性： 在shell中有很多特性：输入输出重定向、管道、globaling文件名通配、*等等； 因此在linux中，程序启动的方式有两种： 1.由shell解释运行 2.不使用shell来运行，而是直接把它作为由内核控制的进程就启动起来了； 可以理解为是init.d的直接子进程 比如： 1.~]# ls *: 之所以能运行并不是ls能够接收*作为参数，而是在ls执行之前*已经被shell解释过了，然后由shell再让ls去运行;那么ls是否 可以不是shell的子进程？ （ls好像一直都是运行在shell接口上的，但是crontab确是我们经常遇到的，而且有可能不是运行为shell的子进程；） 2.crontab crontab是可以不使用shell来启动的，不使用shell启动就意味着直接把它作为由内核控制的进程就启动起来了和shell没关系，它是内核上init的子进程； (正常应该是init-shell进程-command都是shell子进程) 所以说： 如果ls不是运行在shell接口下，而是由内核直接控制的进程，那么执行ls *命令就会出错的，因为*是shell的特性内核是无法解释*的； 我们只是习惯了在shell接口中执行命令了，这就是为什么我们平时的操作都是正常的，只是没有认识到shell的存在而已； 4.因此： CMD [&quot;/usr/sbin/httpd&quot;,&quot;-DFOREGROUND&quot;] #这意味着这个进程是直接运行为init的子进程的和shell没关系 CMD [&quot;/bin/bash&quot;,&quot;-c&quot;,&quot;/usr/sbin/httpd&quot;,&quot;-DFOREGROUND&quot;] #如果想运行为shell的子进程，就需要加上&quot;/bin/bash&quot;,&quot;-c&quot;，通过shell解释运行httpd命名 这种运行方式在下文介绍RUN、CMD、ENTRYPONIT命令中是否运行为shell子进程都是可以通过不同语法来控制的!!! RUN,CMD,ENTRYPOINT的区别： RUN： 用于指定docker build过程中运行的程序，可以是任何命令 (这意味着RUN的命令必须是我们使用的基础镜像存在且支持的命令) 1.是指在docker build过程中通过运行RUN定义的shell命令，以达到在镜像中安装软件等操作 2.RUN可以设定多次，而且每一个都会在build的时执行 3.语法： 1.RUN &lt;command&gt; 第一种格式中command通常是一个shell命令，docker build会自动专门启动一个&quot;/bin/sh -c&quot;进程来运行这个这个command， 而且/bin/sh是docker中PID为1的进程，command只是作为shell的子进程存在的 2.RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] 1.第二种格式中的参数是一个JSON格式的数组，此种格式指定的命令不会以&quot;/bin/sh -c&quot;，不是作为shell的子进程来运行的因此无法支持shell的诸多特性； 2.如果想使用第二种格式支持shell的特性的话，需要使用下面这种语法： RUN [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;] 3.所以RUN、CMD、ENTRYPONIT命令是在[]中括号内的，都不会作为shell的子进程运行，除非使用[&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;]这种语法!!! CMD： 1.当把镜像运行容器时，需要指定默认运行的程序，这在dockerfile中需要用CMD命令来 指定，当然使用ENTRYPOINT也可以； 2.和RUN的区别在于： RUN指令运行在映像文件构建过程中，而CMD指令运行于Dockerfile构建出的新映像文件启动一个容器时； 3.默认运行的程序必须运行在前台 4.由于CMD设定的是容器启动默认运行的程序，所以必须只有一个，如果有多个，则最后一个CMD生效 5.基于镜像运行的容器启动时，是可以运行指定的命令来覆盖容器内默认的程序的，如果 不想让其覆盖，可以使用ENTRYPOINT进行定义默认程序做成镜像 如： CMD [&quot;/usr/sbin/httpd&quot;,&quot;-DFOREGROUND&quot;] #当run时如果指定了/bin/bash，那么httpd就不会运行了 ENTRYPOINT [&quot;/usr/sbin/httpd&quot;,&quot;-DFOREGROUND&quot;] #当run时如果指定了/bin/bash，那么httpd就不会运行了 语法(三种)： 1.CMD &lt;command&gt;：表示运行为shell的子进程 2.CMD [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] 表示不以shell解释运行，不支持shell的特性 3.CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;] 前两种语法格式的意义同RUN 第三种则用于为ENTRYPOINT指令提供默认参数 注意： 1.在分析docker时提到过任何命令要作为容器的默认运行的命令时，它必须运行在前台； 2.而以往我们用systemctl start httpd启动一个程序时他代表是运行在后台的，而且事实上它是托管在systemd的前台上； 3.但是我们现在不打算用systemd来启动，就是手动启动，即便是以shell的子进程来启动他也是手动启动的，而不是使用systemd来控制，因为可能这里并没有systemd; ENTRYPOINT： 1.ENTRYPOINT存在的主要意义是给容器传递变量、文件、做一些启动容器前的准备工作的，所以： 1.当只有CMD命令时，可以使用CMD以前台方式运行一个进程来支撑容器不退出； 如：CMD [&quot;/usr/sbin/httpd&quot;,&quot;-DFOREGROUND&quot;] 2.当只有entrypoint脚本是，那么entrypoint.sh中，可以有一些准备工作+需要运行的进程和一个前台进程；如： CMD [&quot;/apps/tomcat/bin/run_tomcat.sh&quot;] 或者 ENTRYPOINT [&quot;/apps/tomcat/bin/run_tomcat.sh&quot;] 这里可以是CMD也可以是ENTRYPOINT ~]# vim run_tomcat.sh #!/bin/bash su - tomcat -c &quot;/apps/tomcat/bin/catalina.sh start&quot; tail -f /etc/hosts 3.当CMD和ENTRYPOINT同时存在时，这个时候有些特殊，需使用特殊方法； 1.前提：CMD和ENTRYPOINT同时存在时的逻辑是： CMD中的命令都将作为ENTRYPOINT脚本的参数运行，而我们知道shell脚本运行时会再开启一个shell进程，那么CMD命令就会 是这个新的shell进程下的子进程，而shell进程是不能作为容器的前台进程运行的，所以必须让这个ENTRYPOINT的shell进程 强行退出，让CMD命令作为前台进程运行保证容器不退出，所以就可以在ENTRYPOINT中使用exec&quot;$@&quot;来实现这个目的； 2.这种方法是使用Dockerfile构建镜像时的常用方法，示例详见下文：制作httpd镜像； 2.CMD和ENTRYPOINT都表示镜像启动为容器时，容器默认运行的程序，而且CMD和ENTRYPOINT有多个，也都是最后一个生效； 3.基于镜像运行的容器启动时，是可以运行指定的命令来覆盖容器内CMD定义的默认的程序的，如果不想让其覆盖，可以在ENTRYPOINT中 定义默认程序，因为ENTRYPOINT中定义的默认运行命令在run时是不允许覆盖的!!! 但是如果再run时，通过选项--entrypoint &quot;/bin/bash&quot; 还是可以被覆盖的 4.ENTRYPOINT语法： ENTRYPOINT &lt;command&gt;或者 ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] CMD和ENTRYPONIT同时存在的意义？ 1.可以把CMD /usr/sbin/httpd -DFOREGROUND写成 CMD [&quot;/usr/sbin/httpd&quot;,&quot;-DFOREGROUND&quot;] ENTRYPONIT [&quot;/bin/bash&quot;,&quot;-c&quot;] 当然这只是一种表达方式，不过通常是在ENTRYPONIT写脚本 2.entryponit脚本作为传统应用程序与容器化运行程序的中间层，来处理不同环境下的 应用程序所依赖的不同配置文件的，而且脚本可以接受环境变量传参数来设置配置文件的 脚本自己先执行脚本内定义的一些功能，运行完之后，再转为将CMD作为entrypoint的参数 ，还替换脚本进程，CMD的PID号也会变为1 注意： 在run阶段也是可以传环境变量的，只不过这个变量是给容器启动时所使用的，在这里是 给entrypoint中的变量赋值的 总结： 1.基于同一个镜像启动容器时，希望能有不同的配置，要么程序能接受读环境变量来设定 自定义信息，要么通过entrypoint脚本创建镜像，基于镜像创建容器时，为entrypoint脚本中的变量传值来设置不同的配置文件. 2.自己制作或者从网上下载的image可以先通过docker image inspect name查看是否 entrypoint脚本，再查看脚本中定义的内容和变量，可以根据不同的环境，run时， -e 传递不同的变量值生成不同配置文件的容器 Dockerfile示例：基于centos:7制作httpd镜像~]# vim Dockerfile #httpd的dockerfile FROM centos:7 LABEL maintainer=&quot;liu &lt;liu@163.com&gt;&quot; ENV home=&quot;/data/test&quot; RUN yum repolist &amp;&amp; \ yum install iproute vim -y &amp;&amp; \ yum install httpd php php-mysql iproute vim -y &amp;&amp; \ yum clean all ADD entrypoint.sh /bin/ #将entrypoint.sh放到bin目录下 EXPOSE 80 8080 CMD [&quot;/usr/sbin/httpd&quot;,&quot;-DFOREGROUND&quot;] #表示不以shell解释运行； ENTRYPOINT [&quot;/bin/entrypoint.sh&quot;] ~]# vim entrypoint.sh #!/bin/bash # listen_port=${LISTEN_PORT:-80} #变量赋值用法，设置默认值 server_name=${SERVER_NAME:-localhost} #如上 doc_root=${DOC_ROOT:-/var/www/html} #如上 cat &gt; /etc/httpd/conf.d/virtual.conf &lt;&lt;EOF #定义httpd的配置文件 listen $listen_port &lt;VirtualHost *:${listen_port}&gt; ServerName &quot;$server_name&quot; DocumentRoot &quot;$doc_root&quot; &lt;Directory &quot;$doc_root&quot;&gt; Options none AllowOverride none Required all granted &lt;/Directory&gt; &lt;/VirtualHost&gt; EOF exec &quot;$@&quot; 备注：重点解释exec &quot;$@&quot;的作用： exec是指用目标进程替换当前shell进程，让当前entrypoint开启的shell进程终止退出 1.前提: 可以看到Dockerfile中CMD和ENTRYPOINT是同时存在的，那么就意味着&quot;/usr/sbin/httpd&quot;,&quot;-DFOREGROUND&quot;就将作为这个entrypoint.sh的两个参数$1,$2运行,而根据shell的特性：运行脚本时会开启一个新的shell进程，这样一来CMD的命令就会运行为新的shell进程下的子进程，此时通过dockerfile制作的镜像就会以entrypoint.sh开启的shell进程作为前台进程运行，而我们知道shell是不能作为容器的前台进程运行的，所以需要有一种办法：关闭entrypoint.sh的shell进程，让CMD的命令代替作为容器中唯一的进程且PID=1并且运行在前台； 2.exec &quot;$@&quot; 首先CMD中的内容都将传递给entrypoint作为参数运行，而在脚本中规定引用一个脚本的所有参数要使用$@符号，而使用exec替换命令来运行所有传递给entrypoint的参数（即CMD中的命令），表示用目标进程（$@）替换当前entrypoint开启的shell进程，让entrypoint开启的shell进程（entrypoint）终止退出，这样的话CMD用来运行前台程序进程的目的就达到了； 3.所以这才是ENTRYPOINT和CMD同时存在时的正确使用方法，ENTRYPOINT准备一些容器运行CMD命令前的文件存在性判断、准备配置文件等功能，虽然此时有CMD命令，但可以使用exec&quot;$@&quot;来让CMD命令退出entrypoint的shell进程，成为容器中唯一的进程； 附录： 如果不了解shell中exec的作用，可参考：4.shell中exec解析.txt 简单来说就是： exec命令在执行时会把当前的shell_process关闭，然后换到后面的命令继续执行； ~]# chmod +x entrypoint.sh #记得要设置执行权限,防止运行制作好的镜像时报错：permission deniey ~]# docker build -t httpd:v1 . #制作镜像 ~]# docker run --name c1 -P -d httpd:v1 #基于制作好的镜像运行，测试容器是否正常运行 ~]# docker save httpd:v1 -o httpd.tar #打包制作好的镜像，可以基于FTP、NFS共享]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker存储卷]]></title>
    <url>%2F2018%2F10%2F18%2Fdocker%E5%AD%98%E5%82%A8%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[Docker Data Volume：docker存储卷 存储卷是什么： 存储卷是容器上一个或者多个“目录”，并将此“目录”与宿主机上的某目录建立关联关系， 存储卷在容器初始化之时会被创建，由baseimage提供的卷中的数据数据会在此时完成复制 为什么需要用到存储卷: docker启动一个容器是基于镜像的只读层，并在其上添加一个读写层，而镜像是由多个只读层叠加而来。如果运行中 的容器修改了现有一个已存在的文件，那该文件将会从只读层复制到读写层，而该文件的只读版本仍然存在，只是 被读写层中该文件的副本所隐藏而已，而此时关闭该容器，该容器所修改的文件的将会丢失且不能被其它容器共享、复用，因而需要一个存储卷。 如何实现容器内的路径与容器外的存储建立关联关系？ 实际应用场景： 1.通常在可写层上只保存临时数据，有效数据保存在和宿主机关联的目录下，这样就 剥离了程序和产生的数据间紧密的耦合关系，即程序在容器的名称空间上，数据在 宿主机或存储上，数据就独立于容器的生命周期之外 2.当容器down后，再启动一个新容器，指定数据路径为宿主机或存储上的路径，则 又恢复了数据，这就叫做Docker的存储卷 存储卷存在的问题： 存在的问题 •存储于联合文件系统中，不易于宿主机访问； •容器间数据共享不便 •删除容器其数据会丢失 解决方案：“卷(volume)” •“卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机 上的某目录“绑定(关联)” •Volume于容器初始化之时即会创建，由base image提供的卷中的数据会于此期间 完成复制 •Volume的初衷是独立于容器的生命周期实现数据持久化，因此删除容器之时既不会 删除卷，也不会对哪怕未被引用的卷做垃圾回收操作； 存储卷的type: 1. Bind mount volume 绑定挂载卷，永久生效 容器内目录和宿主机中的目录都是由用户自己指定的， 2. Docker-managed volume： 称为docker自己指定的卷 容器中的卷是用户自己指定的，而宿主机上的目录是由docker-daemon进程自行 决定与宿主机的哪个目录建立 关联关系的存储卷，只能用于临时挂载。 存储卷的相关命令: docker run -v 运行时，指定存储卷 --volumes-from list 复制其他容器的卷，达到共享卷的目的 --sorkdir string docker volume ls：列出当前已和宿主建立关联关系的存储卷 create： inspect name:查看一个卷的详细信息 prune rm: 因为docker container inspect c1看到的容器内的详细信息是JSON格式的 所以就可以通过过滤特殊字段显示查询的信息 docker container inspect CONTAINER_NAME -f {{.JSON_VALUE}} Docker-managed volume • ~]# docker run -it -name c1 –v /data busybox • ~]# docker inspect -f {{.Mounts}} c1 • 查看c1容器的卷、卷标识符及挂载的主机目录 和docker container inspect c1的过滤效果一样 Bind-mount Volume • ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name c1 busybox • ~]# docker inspect -f {{.Mounts}} c1 如图以过滤IP地址为例，其他信息类似 示例1.Docker-managed volume 临时创建挂载一个mydata卷 docker run --name c1 -it --rm -v /mydata busybox:latest 并通过docker container inspect c1 探测 mydata被docker指定与宿主机的哪个目录建立了关联关系 从上图看mydata是被docker-manager指定与该容器目录下的_data建立了关系注意：创建容器的时候加–rm选项时，停止容器后，宿主机上的卷也会被删除的不加–rm选项，停止容器，并rm容器，宿主机上的卷是不会被删除的缺点是对应的宿主机上的目录难查找 示例2.Bind mount volume 现在宿主机上创建卷的目录 mkdir /data/volume/c1 docker run --name c1 -it --rm -v /data/volumes/c1:/mydata busybox:latest 并通过docker container inspect c1 可以看出宿主机的/data/volumes/c1与容器内的/mydata是建立的bind类型的卷即使容器被删除，数据还在存在的而且如果/data/volume/c1是在NFS网络文件系统上的话，即使宿主机down了，数据也是无损的 示例3：多容器之间的数据共享 1.先创建容器c1 docker run --name c1 -it --rm -v /data/volumes/c1:/mydata busybox:latest 2.创建容器c2时，共享容器c1的卷 docker run --name c2 -it --rm --volumes-from c1 busybox:latest 此时c1和c2上看到的mydata卷看的数据都是一样的，达到共享卷的目的 示例4.用docker实现类似于k8s上的pod组件机制 要求： 1.c1上挂载多个NFS存储上的卷和bridge桥 2.c3和c4使用c1的网络名称空间和c1上的卷 实现： c1: docker run --name c1 -v /data/volumes/c1:/mydata -v /data/volume2:/mydata2 busybox:latest c3. docker run --name c3 -it --rm --network container:c1 --volumes-from c1 busybox:latest c4. docker run --name c4 -it --rm --network container:c1 --volumes-from c1 busybox:latest]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-基于SSL的Harbor双向复制]]></title>
    <url>%2F2018%2F10%2F18%2FDocker-%E5%9F%BA%E4%BA%8ESSL%E7%9A%84Harbor%E5%8F%8C%E5%90%91%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Docker仓库管理工具Harbor HARBORgithub上的harbor harbor官方功能介绍： 1.基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可 以对多个镜像仓库在同一命名空间（project）里有不同的权限。 2.镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡， 高可用，混合云和多云的场景。 3.图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库， 管理项目和命名空间. 4.Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。 5.AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。 6.审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。 依赖环境和使用介绍： 1.harbor是基于distribution二次开发的企业级私有仓库，云原生registry，多租户机制，允许用户创建自己的名称空间 2.因为harbor内置了mysql,nginx等服务才能构建一个harbor,所以依赖于docker-compose进行容器编排和依赖于至少docker-17.03.0版本 3.harbor为了安全，也需要以https运行，需要在harbor服务器提供证书，而且也需要为 其他客户端提供证书，为harbor验证使用，当然可以关闭https功能 4.因为需要实时下载镜像，提供了离线安装和在线安装，也可以安装到vSphere平台(OVA方式)虚拟设备。 1.基于Http的Harbor双向复制harbor离线安装包下载离线版安装部署文档 1.版本和服务器要求 1.版本 新版本的harbor测试时发现有点问题，所以公司一般用v1.2.2版本的. 这里使用harbor-offline-installer-v1.2.2离线版的v1.2.2版本进行安装 2.服务器要求： 1.磁盘空间： harbor作为存放镜像的仓库，磁盘空间要足够大，最好使用NFS或者商业存储保证数据安全；所以镜像目录/var/lib/docker需要使用NFS挂载 2.网络要求：万兆或网卡绑定 千兆网卡带宽也就100多M，很多业务同时使用时很容易就打满了，所以最好使用万兆网卡、光纤或者做网卡绑定升级为2000M的； 3.环境 192.168.1.101 harbor1 192.168.1.102 harbor2 2.先安装docker-compose，docker-ce并修改配置文件 ~]# yum install docker-compose docker-ce -y #两个harbor节点都安装 ~]# vim /usr/lib/systemd/system/docker.service ... ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --insecure-registry 192.168.1.101 --insecure-registry 192.168.1.107 ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT ... #1.使用--insecure-registry添加两个harbor的地址； #2.将iptables的FORWARD默认策略为DROP改成ACCEPT； 或者 使用daemon.json方式添加两个harbor地址： ~]# vim /etc/docker/daemon.json { &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.101&quot;，&quot;192.168.1.107&quot;] } 这种方式测试过有时不能同时登录两台harbor，会报错： 443:connect:connection refused的情况，好像是只生效了一个地址，所以推荐使用上面第一种方式添加； 3.使用NFS挂载docker镜像目录：/var/lib/docker 这里NFS共享的是192.168.1.100的/data/imagedata目录 ~]# yum install nfs-utils -y ~]# mount -t nfs 192.168.1.100:/data/dockerimage /mnt #先挂载到mnt下测试nfs是否可用 ~]# vim /etc/fstab ... 192.168.1.100:/data/dockerimage /var/lib/docker nfs default,_netdev 0 0 注意： 参数项要使用_netdev声明它是一个网络设备，这样开机时如果nfs服务挂了，不会影响当前主机启动，否则服务器会一直卡在那； ~]# mount -a &amp;&amp; df -TH #验证nfs挂载生效了 ~]# systemctl start docker #启动docker 4.安装harbor ~]# tar xf harbor-offline-installer-v1.4.0.tgz -C /usr/local/ ~]# cd /usr/local/harbor ~]# grep &quot;^[a-Z]&quot; harbor.cfg #配置harbor hostname = 192.168.1.101 #设置主机名/IP ui_url_protocol = http #访问协议，支持http和https max_job_workers = 10 #最大进程连接数 #####设置使用https协议的证书和路径##### customize_crt = on #是否使用自定义证书 ssl_cert = /data/cert/server.crt ssl_cert_key = /data/cert/server.key secretkey_path = /data log_rotate_count = 50 #本地最多保存50次日志滚动 log_rotate_size = 200M #当日志达到200M时滚动一次 http_proxy = #是否使用代理 https_proxy = no_proxy = 127.0.0.1,localhost,core,registry ####设置用户上下载镜像时，是否启用发邮件功能######### email_identity = email_server = smtp.mydomain.com email_server_port = 25 email_username = sample_admin@mydomain.com email_password = abc email_from = admin &lt;sample_admin@mydomain.com&gt; email_ssl = false email_insecure = false ####使用互联网上的邮箱############## harbor_admin_password = Harbor12345 #harbor默认的管理员密码 auth_mode = db_auth #默认使用的数据库类型 db_host = mysql #设置连接mysql的端口和用户密码 db_password = root123 db_port = 3306 db_user = root #这里还支持 ldap 以及 本地文件存储方式。 #####修改数据库类型和用户和密码######### ~]# ./install.sh #执行安装 [Step 0]: checking installation environment ... Note: docker version: 18.09.0 Note: docker-compose version: 1.18.0 [Step 1]: loading Harbor images ... ... #因为是离线安装包，会从tar文件中装入所需的镜像文件并启动，启动时会检查docker-ce和docker-compose的版本开始加载 镜像(mysql,redis,nginx等等)； 5.登录harbor http://192.168.1.101 #habor1 http://192.168.1.102 #habor2 #用户和密码admin/harbor12345 创建两个镜像仓库： 1.项目--&gt;+项目--&gt;baseimage--&gt;设置仓库为公开 2.项目--&gt;+项目--&gt;cre--&gt;设置仓库为公开 创建这两个仓库是为了下文做harbor镜像同步用的 2.配置harbor双向复制、删除注意事项 1.首先复制是针对项目下的某个仓库而言的，不是对整个harbor内的所有仓库，所以需要先创建复制规则，某个仓库再去使用这个规则才行； 2.复制是双向的： 1.在harbor1上需要建立对应harbor2的某个仓库的规则 2.同样早harbor2上也需要建立对应harbor1上的某个仓库规则； 需要注意的是如果只配置了harbor1-A--&gt;harbor2-A的规则，则harbor1-A仓库会将镜像都复制到harbor2-A上，但是 harbor2-A的镜像不会复制到harbor1-A上； 3.下文以上面创建的baseimage仓库为例，添加双向复制规则； 1.先配置harbor1-baseimage--&gt;harbor2-baseimage的复制规则 步骤： 1.先创建baseimage仓库的复制规则 系统管理--&gt;编复制管理--&gt;编+目标--&gt;编辑目标--&gt;见下图1 2.再为baseimage添加复制规则 项目--&gt;baseimage--&gt;复制--&gt;+复制规则--&gt;见下图2 截图如下： – 2.再配置harbor2-baseimage--&gt;harbor1-baseimage的复制规则 步骤： 1.先创建baseimage仓库的复制规则 系统管理--&gt;编复制管理--&gt;编+目标--&gt;编辑目标--&gt;见下图1 2.再为baseimage添加复制规则 项目--&gt;baseimage--&gt;复制--&gt;+复制规则--&gt;见下图2 截图如下： – 3.测试双向同步复制、删除效果 1.先验证harbor1-&gt;harbor2的复制、删除效果 1.在harbor1上上传一个新的镜像 ~]# docker push 192.168.1.101/baseimage/cre:v1 2.验证harbor2上是否同步 登录查看，harbor2的baseimage同步了一个新的镜像cre:v1 3.在harbor1上删除baseimage/cre:v1镜像 直接在harbor1页面上删除即可 4.验证harbor2上是否还有/cre:v1镜像 harbor2上也被删除了 2.再验证harbor2-&gt;harbor1的复制、删除效果 1.在harbor2上上传一个新的镜像 ~]# docker push 192.168.1.107/baseimage/cre:v2 2.验证harbor1上是否同步 登录查看，harbor1的baseimage同步了一个新的镜像cre:v2 3.在harbor2上删除baseimage/cre:v2镜像 直接在harbor2页面上删除即可 4.验证harbor1上是否还有/cre:v2镜像 harbor1上也被删除了 总结： 1.可以看到双向复制、删除镜像是没问题的 2.在harbor1和harbor2上，镜像的前缀都会自动变成各自的IP地址； 3.配置基于https的Harbor仓库和上面没什么区别，只要就是自己制作证书； 1.时间 两台主机的时间必须准确且一致 2.制作证书 ~]# mkdir /usr/local/harbor/certs #创建证书目录 ~]# cd /usr/local/harbor/certs ~]# openssl genrsa -out /usr/local/harbor/certs/server.key 2048 #生成私钥 ~]# openssl req -x509 -new -nodes -key /usr/local/harbor/certs/server.key -subj &quot;/CN=harbor1.cre.com&quot; -days 7120 -out /usr/local/harbor/certs/server.crt #1.生成自签证书，CN名称必须和harbor.cfg中的hostname保持一致； #2.证书有效期建议设置长一点，这里设置20年有效期； 备注：如果需要为多个https的harbor申请证书，安按照上面申请证书即可 ~]# openssl req -x509 -new -nodes -key /usr/local/harbor/certs/server.key -subj &quot;/CN=harbor2.cre.com&quot; -days 7120 -out /usr/local/harbor/certs/server.crt #比如为harbor2.cre.com主机也申请一个证书，公钥一套私钥即可 3.修改harbor.cfg文件 ~]# vim /usr/local/harbor/harbor.cfg hostname = harbor1.cre.com ssl_cert = /usr/local/harbor/certs/server.crt ssl_cert_key = /usr/local/harbor/certs/server.key #主要修改这三项即可 4.安装 ~]# ./install.sh #安装即可 5.登录验证 本机直接在host文件解析即可；windows修改hosts文件 https://harbor1.cre.com 6.配置其他docker服务器使用https的harbor镜像服务器 1.在每个docker主机上创建存放harbor证书的第一级目录：certs.d ~]# mkdir /etc/docker/certs.d #必须是叫这个目录 2.在certs.d再创建二级目录：harbor1.cre.com ~]# mkdir /etc/docker/certs.d/harbor1.cre.com 注意： #1.二级目录名必须和这个harbor的hostname一样,即证书中的CN名称； #2.如果有多个https的harbor，按同样方式创建与其hostname一样的目录，如： mkdir /etc/docker/certs.d/harbor2.cre.com mkdir /etc/docker/certs.d/harbor3.cre.com 然后把对应的证书放在对应的目录下即可 3.拷贝crt文件到二级目录下 ~]# scp usr/local/harbor/certs/server.crt 192.168.1.200:/etc/docker/certs.d/harbor1.cre.com #拷贝crt文件到每个需要登录https的harbor的主机上 4.重启docker 如果daemon.json和docker.service之前设置了非安全登录方式，删除即可，此时有证书了就需要设置非安全登录了； ~]# systemctl restart docker 5.登录https-harbor ~]# docker login harbor1.cre.com #直接使用域名登录即可，确保hosts文件或者内网DNS有解析记录； 6.测试上传镜像 ~]# docker tag 192.168.1.101/cre/cre:v1 harbor1.cre.com/cre/cre:v1 #该tag号 ~]# docker push harbor1.cre.com/cre/cre:v1 #上传 7.其他主机登录harbor 1.由于公司内单机服务器和k8s-node节点都需要登录到harbor上，不可能每次都使用docker login登录一次，通常的做法是： 1.将daemon.json、docker.service、/root/.docker/config.json文件先在一台服务器上设置好，然后使用ansible将这3个文件统一分发到其他需要登录harbor的服务器上；]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker网络]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[Docker Network KVM上虚拟桥接式网络类型： 隔离桥：只能与连接到同一个桥上的主机通信，IP地址还需要在同一网段 仅主机桥：可以和连接的桥地址进行通信 路由桥： 1.打开宿主机核心转发功能 2.虚拟机的网关都指向这个桥的地址 就可以与宿主机通信，不能与外网通信 NAT桥：在路由桥的基础上，在宿主机上做SNAT规则，即可访问外网地址 Docker提供的四种网络： 桥网络：桥接网络 bridge，默认就是docker0桥，docker0是SNAT桥 查看网络定义：docker network inspect bridge 大多数的容器还是使用bridge网络 而且这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器 共享桥：联盟式网络 每一个容器都是靠在内核级虚拟资源分配的独立的6种名称空间来支撑的 这6种名称空间是IPC,Net,Mount,UTS,PID,USER 虽然每个容器都有各自独立的名称空间，但是确可以共享，于是就有了这种方式 共享桥的原理： 共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈 而mount user PID还是隔离的，文件系统也是隔离的 这样做的效果就可以构建出一个模型 httpd---&gt;fpm127.0.0.1:9000---&gt;mysql127.0.0.1:3306 那么对于fpm和mysql来说只监听在本地端口上，保证了安全性 host宿主机网络：共享宿主机网络 既然多个容器可以使用同一个容器的网络名称空间，而且宿主机在内核中也有自己的 网络名称空间，那么容器也理所当然的可以使用宿主机的网络名称空间 容器使用宿主机的网络和DNAT方式有关系 作用：可以做日志收集主机，host一般在特殊环境下使用 none网络：封闭式网络 当容器不需要网络服务时，不创建网卡，只有本地lo网卡 除了bridge桥之外，其他三种网络都是docker所独有的 Docker网络的相关命令docker run 命令中涉及网络的相关命令 --network 启动容器时，指定使用的网络 [bridge|host|none|container:name] --hostname 启动容器时，指定容器的主机名 --add-host list 启动容器时，指定内部的hosts解析文件 如：docker run --add-host c1:192.168.10.1 busybox:latest cat /etc/hosts可以看到添加的解析 --dns 启动容器时，指定DNS地址 如：docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest cat /etc/resolve可以看到指定的DNS地址 --ip string 启动容器时，指定容器的iPv4地址 -p|--publish 因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则 docker network: ls：显示docker内部的全部网络 connect: 让容器连接到某个网络上 disconnect: 把容器从某个网络断开 create: 创建自定义网络，和KVM创建网络类似 inspect:查看某个网络是怎么定义的 prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令 rm: 删除docker内部的网络 Docker network的端口暴露docker run --network [bridge|host|none] -p|--publish 作为一个容器，是要提供web服务的，而docker默认的桥是bridge，而且是个SNAT桥 容器只能访问外网，而不能被外网所访问，那么就失去了web服务器对外提供服务的初衷 而docker提供了一个-p选项来自动生成DNAT规则，来避免每次都手写DNAT规则带来的麻烦 -p选项的用法和使用格式： •-p &lt;containerPort&gt; 将指定的容器端口映射至主机所有地址的一个动态端口 •-p &lt;hostPort&gt;:&lt;containerPort&gt; 将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt; •-p &lt;ip&gt;::&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口 •-p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; “动态端口”指随机端口，具体的映射结果可使用docker port命令查看 不过一般还是要使用第四种方式指定宿主机的端口 指定了映射的端口后，可以使用命令查看映射关系： docker container port [name] 示例： 1.docker run --name c1 -it --rm --network bridge -p 80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 0.0.0.0:32768 2.docker run --name c1 -it --rm --network bridge -p 80:80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 0.0.0.0:80 3.docker run --name c1 -it --rm --network bridge -p 192.168.34.103::80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 192.168.34.103:32768 4.docker run --name c1 -it --rm --network bridge -p 192.168.34.103:80:80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 192.168.34.103:80 Docker的自定义网络docker network create connect:相当于创建一对网卡，一半在桥上，一半在容器中 而且默认创建的网络都是SNAT桥 选项： -d|--driver string 创建时，要指定桥的类型 默认是bridge，当然还有 host macvlan null overlay四种类型 --gateway strings 默认是定义的子网的第一个IP地址 --subnet strings 子网地址 --ip-range strings 地址分配的IP地址范围 修改默认的bridge，docker0桥的子网 自定义docker0桥的网络属性信息：也就是镜像加速的文件 vim /etc/docker/daemon.json文件 { &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;] } 核心选项为bip，即bridge 桥接口的IP地址 ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。 示例： 1.创建一个mybr2的网络，并指定子网地址 docker network create --subnet 10.0.0.0/8 mybr2 2.创建容器c1指定加入到mybr2网络中 docker run --name c1 -it --rm --network mybr2 busybox:latest 3.给容器c1再加入一个bridge网络中 docker network connect bridge c1 此时c1就有了两个网络地址 4.删除容器c1的网卡 docker network disconnect mybr2 c1 Docker指定容器启动的网路类型1.启动为none类型的网络 docker run --name c1 -it --rm --network none busybox:latest 2.启动为bridge类型的网络:docker默认的网络模型 docker run --name c2 -it --rm --network bridge busybox:latest 3.启动为joined类型的网络 启动的c3共享的是c2的Net,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的 因为共享桥只是共享了Net网络，UTS主机名，IPC，此时IP地址和hostname都是一样，就可以通过127.0.0.1进行通信了而mount(文件系统)，user,PID还是隔离的，所以在1上创建一个文件，2上是看不到的这就是共享桥的工作机制 4.启动为host宿主机类型的网络 docker run --name c4 -it --rm --network host busybox:latest 可以看出hostname,Net都是和宿主机是一样的 此时在容器内部启动httpd服务，其他主机是可以通过宿主机提供服务的]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker的资源限制]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E7%9A%84%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Docker资源限制 docker容器得以实现的三个组件： Namespace:内核中的名称空间是实现容器技术非常重要的组件 CGroups：实现容器的资源配额 1.如果没有资源配额的限定，比如恶意代码会占用宿主机上的很多资源，会造成其他容器无法运行的情况， 默认是宿主机上的所有资源. 2.cgroup允许将宿主机上的所有技术资源(CPU,内存等)做资源分割,以指定方式进行分配，而CPU和内存又分别支持两种不同的配额方式 3.CPU属于可压缩型资源，如果程序运行的cpu不够，只需要等待cpu资源即可，不会造成容器崩溃。 4.内存属于不可压缩型资源，如果一个进程依赖于3g内存来运行，宿主机只分配给它1g，则会造成OOM，这个进程就会因为内存耗尽而被终止. 内存的限制方式： -m|--memory= 限制容器的最大内存使用量，进程并不是一启动就占用最大内存的，而是 运行一段时间慢慢增长的，所以要分配给进程运行的最大内存. --memory-swap * 当前容器所允许使用的交换分区大小(生产环境是禁止启用交换内存 的，因为性能会急剧下降.) --memory-swappiness 使用交换分区的倾向性：因为使用交换分区会极大影响性能， 只有到万不得已才使用交换分区，数值越小,越会较晚使用交换分区，所以一般这个 值建议调小，默认是0-100 --memory-reservation 为系统保留多的内存空间，保证系统的正常运行 --kernel-memory 为内核保留多少内存空间 --oom-kill-disable 一旦某个容器发生OOM是否立刻kill这个容器，建议设置，因为 会造成整个宿主机的崩溃，也可以事先设定好内核和系统的内存空间，然后手动处理 发生OOM的容器，以便分析发生OOM的原因. 注意： 1.在容器内使用free命令可以看到的swap空间并不具有其所展现的空间指示意义. 2.-m|--memory=和 --memory-swap *一般是结合起来生效的 CPU的限制方式： 主流的分两种：共享式和CPU绑定式 --cpu-shares 共享方式是基于权重分配的，而且是根据容器的数量和CPU的权重动态 分配调整的.如果只有一个容器在运行，那么这个容器也会尽可能的占用宿主机的CPU资源，这种分配方式依然会有可能造成系统崩溃. --cpus &lt;value&gt; 定义容器最多跑满宿主机的几个核心数，例如宿主机有8核，限制容器 最多跑满2个核心数，而且这个2核可以跑在8个核心上加起来是2个核心数，也可以是 在2个核心上跑满.真正限制了容器使用的最大核心数. docker的1.13版以后都使用这个选项来定义. --cpuset-cpus 定义容器只能跑在宿主机核心的几号核心上，例如只允许跑在1号和3号核心上，那么 这个容器最多也就只能跑满这两个核心,也叫CPU绑定. 所以在创建启动容器一定要做资源限制，即使不清楚容器中某个程序要占用多大的资源时，也应该设置只允许占用宿主机一半的资源. 资源限制压测在docker hub上的lorel/docker-stress-ng镜像 -c N 启动几个进程对CPU进行压测 -vm N 启动几个进程对内存做压测 示例：通过该镜像进行压测 限制只能跑在cpu的0号和3号上，最多只能跑满2个核心数 限制最多占用512m的内存大小 docker run --name stress --cpus 2 --cpuset-cpus 0,3 -m 512m --rm lorel/docker-stress-ng -c 2 -vm 2 -docker stats命令查看结果 -top命令显示宿主机资源(安装1显示全部的CPU核心数信息)]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[Docker Images 1.docker image是docker贡献给容器极具创造性的使用方式！2.分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！3.容器编排技术：—Docker通过镜像机制极富创造性的解决了应用程序打包的根本性难题，它推动了容器技术的快速普及和生产落地—容器本身仅提供托管运行应用的底层逻辑，而容器编排(Orchestration)才是真正产生价值的位置所在； -docker-image和读写机制 1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器 a.docker镜像就像KVM镜像一样，包含了启动容器/虚拟机所依赖的所有文件，文件系统 包括程序文件，库文件，配置文件,数据目录等等 b.dokcer采用分层构建机制，最底层为bootfs，其上是rootfs bootfs：在创建的容器中是看不到的，只是用于系统引导的文件系统，包括 bootloader和kernel，因为在创建启动容器时，其实是用到内核的， 只不过只是启动引导容器启动的，当容器启动完成后会被卸载以节约内存资源; 而且把对应的对容器的管理委托给宿主机的内核，所以容器镜像的内核只 是启动时有用，而且看不到，所以bootfs叫引导文件系统 rootfs:位于bootfs之上，表现为docker容器的根文件系统; 1.在传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只 读&quot;模式，完整性自检完成后将其重新挂载为读写模式；也就是fstab 的最后两项，只有通过自检次序时，才会把根文件系统重新以&quot;读写&quot;方式挂载. 2.但是在docker中，rootfs由内核挂载为&quot;只读&quot;模式，就算容器启动完成 ，rootfs也不会以读写方式重新挂载！也就是说docker容器的用户空 间和根文件系统一直都是只读的！ 3.docker是通过&quot;联合挂载&quot;技术额外挂载一个“可写”层；docker image layer 2.Docker Images Layer 如上图 a.完整的docker镜像包括bootfs,rootfs b.而rootfs又包括Base Image+自定义的镜像层+可写层writable 除了writable是可写层，其他都是只读层 c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加 一个可写层，这个可写层writable是属于容器的 d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的 容器的读写原理：如上图示： 1.对于docker来说有一个专门存放镜像的路径叫Graph Driver，而这个文件系统必须是特殊 格式的(aufs或者overlay2),在linux系统内默认是/var/lib/docker/image/overlay2； overlay2目录就是构建在宿主机(xfs或ext4)的/var/lib/docker/image/目录的二级文件系统 2.前面说镜像数据文件都放在bootfs和rootfs上的，可写层writbale是创建时创建的 那么在可写层上是如何看到底层的数据目录？又是怎么把数据增删改到容器内的？ 默认xfs和ext4是不支持COW机制的 如何看到镜像目录的？ a.在创建容器时，是把镜像内的多层镜像通过联合挂载方式作为可写层的底层，也就是这个容器内部的可访问文件系统接 口 b.所谓联合挂载，是通过把镜像内的多层一层一层叠加上去的，而这个叠加方式的原理是： 第一层上有数据时，而第二层没相同数据，在第二层是可以看到第一层数据的;如果第二层有第一层相同数据， 则会覆盖第一层上的相同数据，在第二层上看到的是第一层和第二层总的文件，以此类推，在可写层上就可以看到 镜像内的数据目录了， 如何修改和写文件？ a.对于修改文件，因为文件是放在只读层的，只能是通过COW写时复制机制，先把文件从只读层复制到可写层上再进行修改 然后保存在可写层,当然是首次修改，第二次再修改因为在可写层有文件了，在可写层修改即可，而只读层的该文件 版本仍然存在，只不过是被读写层中该文件的副本所隐藏了. b.对于写文件，新创建的文件是保存在可写层的，所以最终用户看到的是只读层和可写层的全 部数据文件，这就是镜像的工作逻辑 通过上面的分析可以得出： 1.这就是为什么基于同一镜像创建的两个容器，用户在不同的容器上看到的相同的数据都是只读层的，不同的数据是可写 层上各自独有的，因为可写层是独占的，只读层是共享的 2.这就是为什么镜像背后必须要求特殊文件系统的原因：因为ext4和xfs默认是不支持联合挂载和写时复制机制的 3.因为可写层是可以自定义修改的，把可写层保存为镜像，然后再和原始镜像进行叠加成一个自定义的镜像， 就可以作为基础镜像使用了，不过一般不这么做，而是通过dockerfile自定义镜像 docker imge相关命令docker image 相关命令 docker imges:镜像的管理命令 ls： 查看本地所有的镜像列表 build: import: inspect: 查看下载/创建的镜像详细信息 可以查看下载的某个镜像的具体信息 如：CMD:镜像启动默认运行的命令 Volume: network: 下文中构建docker file时这些都可以自定义 load: prune: pull：从远程仓库拉取镜像到本地 push: 把本地镜像推到远程的Registry rm: docker image rm = docker rmi 删除镜像 tag: 给镜像打标签 save: 2.将当前容器可写层保存为镜像并上传docker hub上 docker container commit [options] container [repository:[tag]] 选项： -a:指定作者 -c:镜像内部默认运行的命名 -p|--pause:因为制作镜像时，容器还在运行，可能制作出的镜像和当前容器不 一致，可以在制作时，暂停容器，保持数据一致 比如： 1.在docker hub上注册用户，并创建镜像仓库 创建的仓库：myimg 2.把centos1容器做成镜像仓库下的myimg：v0.1版本 docker container commit -p -a &quot;liu &lt;liu@163.com&gt;&quot; -c &quot;CMD [&apos;/bin/httpd -f&apos;]&quot; centos1 liukkui/myimg:v0.1 然后新容器就可以基于这个镜像启动了 3.上传docker hub docker login 登录到docker hub 输入账号密码，正常登录后 4.push镜像 docker image push liukkui/myimg:v0.1 正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-容器监控Metrics-Server]]></title>
    <url>%2F2018%2F09%2F28%2FKubernetes-%E5%AE%B9%E5%99%A8%E7%9B%91%E6%8E%A7Metrics-Server%2F</url>
    <content type="text"><![CDATA[kubernetes容器监控-Metrics-Server更新于：18.12.02 1.前提： 1.在上篇文章中说过新版本的k8s监控系统演变：从v1.8开始，资源使用情况的监控可以通过Metrics API的形式获取，具体的组件为Metrics-Server， 用来替换之前的heapster，heapster从1.11开始逐渐被废弃，在1.13版之后正式被废弃； 2.Metrics-Server是集群核心监控数据的聚合器（聚合的概念也在上篇文章说过），从Kubernetes1.8开始，它作为一个Deployment对象默认部署在 由kube-up.sh脚本创建的集群中; 3.注意： kubernetes的新监控体系中，metrics-server属于Core metrics(核心指标)，提供API-metrics.k8s.io，仅提供Node和Pod的CPU和内存使用 情况。而其他Custom Metrics(自定义指标)由Prometheus等组件来完成; 2.在介绍Metrics-Server之前，必须要提一下Metrics API的概念: 1.Metrics API相比于之前的监控采集方式(hepaster)是一种新的思路，官方希望核心指标的监控应该是稳定的，版本可控的，且可以直接被用户 访问(例如通过使用 kubectl top 命令)，或由集群中的控制器使用(如HPA)，和其他的Kubernetes APIs一样。 2.官方废弃heapster项目，就是为了将核心资源监控作为一等公民对待，即像pod、service那样直接通过api-server或者client直接访问，不再是 安装一个hepater来汇聚且由heapster单独管理; 3.假设每个pod和node我们收集10个指标，从k8s的1.6开始，支持5000节点，每个节点30个pod，假设采集粒度为1分钟一次，则： 10 x 5000 x 30 / 60 = 25000 平均每分钟2万多个采集指标 4.因为k8s的api-server将所有的数据持久化到了etcd中，显然k8s本身不能处理这种频率的采集，而且这种监控数据变化快且都是临时数据，因此需要 有一个组件单独处理他们，k8s版本只存放部分在内存中，于是metric-server的概念诞生了; 5.其实hepaster已经有暴露了api，但是用户和Kubernetes的其他组件必须通过master proxy的方式才能访问到，且heapster的接口不像api-server 一样，有完整的鉴权以及client集成。这个api现在还在alpha阶段（18年8月），希望能到GA阶段。类api-server风格的写法：generic apiserver 6.有了Metrics Server组件，也采集到了该有的数据，也暴露了api，但因为api要统一，如何将请求到api-server的/apis/metrics请求转发给 Metrics-Server呢，解决方案就是：kube-aggregator,在k8s的1.7中已经完成，之前Metrics-Server一直没有面世，就是耽误在了kube-aggregator这一步； kube-aggregator（聚合api）主要提供： 1.Provide an API for registering API servers. 2.Summarize discovery information from all the servers. 3.Proxy client requests to individual servers. 7.metric api的使用： 1.Metrics API只可以查询当前的度量数据，并不保存历史数据 2.Metrics API URI为/apis/metrics.k8s.io/，在k8s.io/metrics维护 3.必须部署metrics-server才能使用该 API，metrics-server通过调用Kubelet Summary API获取数据； 如： http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes/&lt;node-name&gt; http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/namespace/&lt;namespace-name&gt;/pods/&lt;pod-name&gt; 1.Metrics-Server在k8s监控体系中的位置–k8s最新的监控体系 1.Metrics server定时从Kubelet的Summary API（类似/ap1/v1/nodes/nodename/stats/summary）采集指标信息，这些聚合过的数据将存储在内存中， 且以metric-api的形式暴露出去; 即metrics-server通过调用Kubelet Summary API获取采集核心指标数据，给k8s集群内的kubectl,hpa,scheduler等组件使用； 2.Metrics server复用了api-server的库来实现自己的功能，比如鉴权、版本等，为了实现将数据存放在内存中，去掉了默认的etcd存储，引入了内存 存储（即实现Storage interface)。因为存放在内存中，因此监控数据是没有持久化的，可以通过第三方存储来拓展，这个和heapster是一致的； Metrics-server负责采集的核心指标数据，虽然是放在内存中但也是需要缓存的，所以使用emptyDIr存储卷，当然也可以使用持久存储卷. 3.如上图： Metrics server出现后，新的​Kubernetes 监控架构将变成上图的样子： 1.核心流程（黑色部分）：这是Kubernetes正常工作所需要的核心度量，从Kubelet、cAdvisor等获取度量数据，再由metrics-server提供Dashboard、HPA控制器等使用; 2.监控流程（蓝色部分）：基于核心度量构建的监控流程，比如Prometheus可以从metrics-server获取核心度量，从其他数据源 （如Node_Exporter等）获取非核心度量，再基于它们构建监控告警系统; 4.Metric-Server属于kubenetes处于孵化的项目；它有两个组件： Metrics API #提供resource定义，即自定义apiserver Metrics server #定义背后resource资源定义是否合法 2.Metric-Server部署实现metric-server项目k8s项目中的metric-servermetrics指南-官方指导文档 1.部署前注意事项： 1.开启apiserver聚合层: 上文提到的，metric-server是扩展的apiserver，依赖于kube-aggregator，因此需要在kube-apiserver的配置文件或unitfile中开启相关参数。 --requestheader-client-ca-file=/etc/kubernetes/certs/proxy-ca.crt \ --proxy-client-cert-file=/etc/kubernetes/certs/metrics-server.pem \ --proxy-client-key-file=/etc/kubernetes/certs/metrics-server-key.pem \ --requestheader-allowed-names=aggregator \ --requestheader-extra-headers-prefix=X-Remote-Extra- \ --requestheader-group-headers=X-Remote-Group \ --requestheader-username-headers=X-Remote-User \ --enable-aggregator-routing=true 由上到下启用的参数项解释： 1.ca证书： kube-aggregator的前端代理front-proxy-ca证书，因为这里etcd、apiserver、aggregator是用的同一套CA，即ca.pem（front-proxy-ca.crt）; 2.metrics-server证书 用于证明aggregator或kube-apiserver在请求期间发出呼叫的身份的客户端证书； 3.2.metrics-server私钥 于证明聚合器或kube-apiserver的身份的客户端证书的私钥，当它必须在请求期间调用时使用。包括将请求代理给用户api-server和调用webhook-admission插件； 4.metrics-server证书中的CN名称； 通用名称列表（CN）。如果设置，则在检查请求头中的用户名之前，必须呈递具有列表中指定名字的客户端证书。如果为空，则允许由 --requestheader-client-ca-file中的权限验证的任何客户端证书； 5.kube-apiserver的aggregatorlayer相关的配置参数,可选，不区分大小写。 建议使用&quot;X-Remote-Extra-&quot;; 6.kube-apiserver的aggregatorlayer相关的配置参数,可选，不区分大小写。建议使用&quot;X-Remote-Group&quot;; 7.kube-apiserver的aggregatorlayer相关的配置参数,必需，不区分大小写。按顺序检查头名字用于识别用户身份。第一个包含的值用作用户名，建议使用&quot;X-Remote-User&quot;; 8.打开aggregator路由请求到endpoints IP，而不是集群IP; 2.准备metrics-server证书文件 1.使用cfssl工具生成证书 ~]# vim metrics-server-csr.json { &quot;CN&quot;: &quot;aggregator&quot;, &quot;hosts&quot;: [], &quot;key&quot;: { &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 }, &quot;names&quot;: [ { &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; } ] } 备注：证书中的CN：&quot;aggregator&quot;,就是requestheader-allowed-names的名称，要保持一致； 2.签发证书： ~]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes metrics-server-csr.json | cfssljson -bare metrics-server metrics-server.pem metrics-server-key.pem 3.拷贝证书： 将生成的证书(metrics-server*.pem) 拷贝到集群各个节点的证书目录中: ~]# scp metrics-server*.pem {{ $IP }}:/etc/kubernetes/ssl/ 4.备注： 如果没有配置--proxy-client-cert-file和--proxy-client-key-file就会出现下面这个报错； Error from server (Forbidden): nodes.metrics.k8s.io is forbidden: User &quot;system:anonymous&quot; cannot list nodes.metrics.k8s.io at the cluster scope: no RBAC policy matched 2.部署方式和版本选择 1.部署方式 metrics-server既有单独项目又在kubernetes项目的addons附件中有，使用哪个地方的清单部署都可以，但是清单中是有错误的，需要修改，详见下文； 2.版本选择 Metrics Server Metrics API group/version Supported Kubernetes version 0.3.x metrics.k8s.io/v1beta1 1.8+ 0.2.x metrics.k8s.io/v1beta1 1.8+ 0.1.x metrics/v1alpha1 1.7 注意： metric-server的0.2和0.3版本在部署时还是有区别的，有些参数在0.3版被废弃了，具体见下文部署前注意事项; 3.修改metrics-Server的清单文件 ~]# git clone https://github.com/kubernetes-incubator/metrics-server.git #下载项目到本地 ~]# cd metrics-server/deploy/1.8+/ aggregated-metrics-reader.yaml #定义ClusterRole和其权限 auth-delegator.yaml #ClusterRoleBinding auth-reader.yaml #RoleBinding metrics-apiservice.yaml #自定义apiservice metrics-server-deployment.yaml metrics-server-service.yaml #SVC resource-reader.yaml #两个auth适合RBAC权限相关的，专门定义了ServiceAccount并授权才能采集数据； 1.kubernetes/kubernetes/tree/master/cluster/addons/metrics-server 1.如果使用kubernetes项目中附件addons中的部署清单，需要修改清单中kubelet的端口10255--&gt;10250; 2.同时还要添加和metrics-server一样的参数选项； 2.metric-server 如果通过metric-server项目部署时也会出错，因为metrics-server-deployment清单中metric-server使用的是0.3版的镜像，而0.3版之后的 metrics-server启用时不支持-source选项了，需要修改部署清单： command: - /metrics-server - --kubelet-insecure-tls #不使用metric-server的tls证书 - --kubelet-preferred-address-types=InternalIP 或者： args: #给metric-server传递两个参数 - --kubelet-insecure-tls - --kubelet-preferred-address-types=InternalIP 选项解释： 1.--kubelet-insecure-tls：表示 1.metric-server是需要连接kubelet获取聚合指标数据，而kubelet是有自己的API的，metric-server作为客户端连接也是需要kubelet颁发的证书的； 2.上面做好的证书和这里是没有关系的，它是给k8s-apiserver启用聚合层用的，这里就表示不使用证书连接kubelet; 3.简单来说就是不验证kubelet的ca证书，暂时开启。（不推荐用于生产环境） 2.kubelet-preferred-address-types=InternalIP 1.首先metric-server是作为pod部署在k8s中的，在k8s内部服务间通信是通过CoreDNS或者kubeDNS解析的； 2.其次物理节点Node的主机名解析记录是不在coredns中的，而metrics默认使用hostname来通信的，那么它通过CoreDNS解析是肯定出错的； 3.解决办法有两种： 1.打通内网DNS和CoreDNS间的解析关系（详见K8S-DNS部署）： 即搭建一个内部的DNS服务器或者在pod的deployment的yaml手动添加主机解析记录； 2.改参数为InternalIP，让metrics-server直接连接物理节点Node的IP地址即可； 4.部署并验证自定义的apiserver ~]# kubectl apply -f deploy/1.8+/ #运行此目录下的所有yaml清单 ~]# kubectl get pods -n kube-system | grep metrics-server metrics-server-fc6d2228d-644ck 1/1 Running 0 20s #metrics-server的Pod正常运行,稍等一会就会采集到数据 ~]# kubectl get svc -n kube-system | grep metrics-server metric-server ClusterIP 10.96.0.10 &lt;none&gt; 443/TCP 20s #metric-server的SVC已经创建 ~]# kubectl api-versions metrics.k8s.io/v1beta1 1.部署完后，自定义的metrics.k8s.io/v1beta1群组就会有了 2.用户对kube-apiserver中的agregator的metrics.k8s.io/v1beta1访问就被代理至metric-server这个SVC在的pod上了； 5.测试数据采集 ~]# kubectl get apiservice v1beta1.metrics.k8s.io -o yaml apiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {&quot;apiVersion&quot;:&quot;apiregistration.k8s.io/v1beta1&quot;,&quot;kind&quot;:&quot;APIService&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{}, &quot;name&quot;:&quot;v1beta1.metrics.k8s.io&quot;},&quot;spec&quot;:{&quot;group&quot;:&quot;metrics.k8s.io&quot;,&quot;groupPriorityMinimum&quot;:100, &quot;insecureSkipTLSVerify&quot;:true,&quot;service&quot;:{&quot;name&quot;:&quot;metrics-server&quot;,&quot;namespace&quot;:&quot;kube-system&quot;},&quot;version&quot;:&quot;v1beta1&quot;, &quot;versionPriority&quot;:100}} creationTimestamp: 2018-10-10T08:36:10Z ~]# kubectl get --raw &quot;/apis/metrics.k8s.io/v1beta1/nodes&quot; | jq . { &quot;kind&quot;: &quot;NodeMetricsList&quot; &quot;apiVersion&quot;: &quot;metrics.k8s.io/v1beta1&quot;, &quot;metadata&quot;: { &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/nodes&quot; } &quot;items&quot;: [ { &quot;metadata&quot;: { &quot;name&quot;: &quot;192.20.10.2&quot; &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/nodes/192.20.10.2&quot; &quot;creationTimestamp&quot;: &quot;2018-10-10T08:36:10Z&quot; } } ] } 6.查看k8s集群的资源使用情况 ~]# kubectl top nodes NAME CPU(cores) CPU% MEMORY(byte) MEMORY% master.cre.com 334m 8% 1179Mi 68% node01.cre.com 112m 2% 672Mi 29% node02.cre.com 90m 2% 425Mi 20% node03.cre.com 200m 6% 298Mi 29% ~]# kubectl top pods -n cre NAME CPU(cores) MEMORY(bytes) cre-test-2mvql 32m 63Mi cre-test-3mdox 19m 53Mi cre-test-2aspq 27m 24Mi 7.备注1：修改metrics-server清单中的资源使用率 - name: metrics-server image: k8s.gcr.io/metrics-server-amd64:v0.3.1 imagePullPolicy: IfNotPresent command: - /metrics-server - --kubelet-insecure-tls - --kubelet-preferred-address-types=InternalIP ports: - containerPort: 443 name: https protocol: TCP - name: metrics-server-nanny image: k8s.gcr.io/addon-resizer:1.8.3 imagePullPolicy: IfNotPresent resources: limits: cpu: 100m memory: 300Mi requests: cpu: 5m memory: 50Mi env: - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: MY_POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: metrics-server-config-volume mountPath: /etc/config command: #添加此段配置 - /pod_nanny - --config-dir=/etc/config - --cpu=100m - --extra-cpu=0.5m - --memory=100MI - --extra-memory=10Mi - --threshold=5 - --deployment=metrics-server-v0.3.1 - --container=metrics-server - --poll-period=300000 - --estimator=exponential]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-DNS部署]]></title>
    <url>%2F2018%2F09%2F20%2FKubernetes-DNS%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[kubernetes-DNS部署(KubeDNS/CoreDNS) 为什么要部署dns? 因为kuberntes中的所有pod都是基于service域名解析后，再负载均衡分发到service后端的各个pod服务中，那么如果没有DNS解析，则无法查到各个 服务对应的service服务; 1.部署KubeDNSkube-dns项目 1.准备镜像 kubeDNS部署需要3个镜像文件 ~]# ls /images k8s-dns-dnsmasq-nanny-amd64_1.14.13.tar.gz #dnsmasq k8s-dns-kube-dns-amd64_1.14.13.tar.gz #kube-dns程序 k8s-dns-sidecar-amd64_1.14.13.tar.gz #辅助容器 #sidecar是一个监控健康模块，同时向外暴露metrics记录。 ~]# docker load -i k8s-dns-dnsmasq-nanny-amd64_1.14.13.tar.gz ~]# docker load -i k8s-dns-kube-dns-amd64_1.14.13.tar.gz ~]# docker load -i k8s-dns-sidecar-amd64_1.14.13.tar.gz ~]# docker tag gcr.io/google-containers/k8s-dns-dnsmasq-nanny-amd64:1.14.13 192.168.1.101/baseimage/k8s-dns-dnsmasq-nanny-amd64:1.14.13 #重新打tag标签，其他两个镜像一样操作 ~]# docker push 192.168.1.101/baseimage/k8s-dns-dnsmasq-nanny-amd64:1.14.13 #上传到本地的harbor的baseimage仓库中 2.修改kube-dns.yaml清单 清单中有几个需要根据实际规划的IP和域名要更改 ~]# vim kube-dns.yaml #修改yaml清单，只显示需要修改的，没有修改的使用...代替 apiVersion: v1 kind: Service ... spec: selector: k8s-app: kube-dns clusterIP: 172.31.254.254 #和kubelet的cluster-dns参数的值一样 ...... --- apiVersion: extensions/v1beta1 kind: Deployment ... - name: kubedns image: 192.168.1.101/baseimages/k8s-dns-kube-dns-amd64:1.14.13 resources: limits: memory: 4096Mi #建议内存限制修改为大于4G； requests: cpu: 100m memory: 70Mi args: - --domain=cre.local. #和kubelet的cluster-domain参数的值一样 - --dns-port=10053 #在集群内部dns服务的端口 - --config-dir=/kube-dns-config ... - name: dnsmasq image: 192.168.1.101/baseimages/k8s-dns-dnsmasq-nanny-amd64:1.14.13 args: - --server=/cre.local./127.0.0.1#10053 #修改k8s的搜索域 - --server=/creonline.local./192.168.1.160#53 - --server=/creonline.local./192.168.1.180#53 ... - name: sidecar image: 192.168.1.101/baseimages/k8s-dns-sidecar-amd64:1.14.13 args: - --v=2 - --logtostderr - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cre.local.,5,SRV - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cre.local.,5,SRV ... ################################################################### 需要修改的地方： 1.clusterIP: 172.31.254.254 #和kubelet的cluster-dns参数的值一样,一般为service网络靠后的一个IP地址 2.kubedns、dnsmasq、sidecar使用的镜像 #修改为本地harbor镜像的地址 3.kubedns容器的内存限制 limits: memory: 4096Mi #内存限制一定要修改成大于4G，不然dns解析会很慢； 4.kubedns、dnsmasq、sidecar的args中解析的域名： #都修改为k8s集群事先定义好的集群后缀名：cre.local. 5.dnsmasq容器的args中添加解析k8s集群外的DNS服务器地址； 原因： 1.cre.local.是k8s集群内部的DNS后缀，但是公司内部还有内网的DNS服务器，比如： 内网DNS服务器域名后缀是：online.local. 支付业务使用的域名： bj-cre-zhifu-vip.creonline.local （生产环境的支付域名） bj-cre-zhifu-vip.crepre.local （测试环境的支付域名） bj-cre-zhifu-vip.cretest.local (开发环境的支付域名) 2.由于通常开发在代码中写的支付业务的域名是写的内网DNS服务器的记录，而k8s是解析不了的，因此在部署kube-dns时需要在dnsmasq中 加--server来指定内网DNS服务器的地址和端口； --server=/creonline.local./192.168.1.160#53 --server=/crepre.local./192.168.1.170#53 --server=/cretest.local./192.168.1.180#53 #1.当需要解析集群外的生产环境后缀为creonline.local.的域名时，就解析到192.168.1.160这台DNS服务器去查询； #1.当需要解析集群外的测试环境后缀为crepre.local.的域名时，就解析到192.168.1.170这台DNS服务器去查询； #1.当需要解析集群外的开发环境后缀为cretest.local.的域名时，就解析到192.168.1.180这台DNS服务器去查询； 3.部署kube-dns ~]# kubectl apply -f kube-dns.yaml #部署 service/kube-dns created serviceaccount/kube-dns created configmap/kube-dns created deployment.extensions/kube-dns created ~]# kubectl get pods -n kube-system | grep kube-dns NAME READY STATUS RESTARTS AGE kube-dns-5b9b99d8bc-4wrpt 3/3 Running 0 10s #可以看到3个kube-dns-pod都正常运行了 4.测试DNS功能 ~]# kubectl create busybox --image=busybox sleep 36000 pod/busybox created ~]# kubectl get pods busybox 1/1 Running 0 20s ~]# kubectl get services --all-namespaces NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) default kubernetes CLUSTERIP 10.96.0.1 &lt;none&gt; 443/TCP kube-system kube-dns CLUSTERIP 10.96.254.254 &lt;none&gt; 53/UDP,53/TCP #1.kubernetes这个svc就是k8s-apiserver在内部的访问接口 #2.kube-dns的svc; ~]# kubectl exec busybox nslookup kubernetes #解析kubernetes这个svc Server: 10.96.254.254 Address 1: 10.96.254.254 kube-dns.kube-system.svc.cre.local Name: kubernetes Address 1: 10.96.0.1 kubernetes.default.svc.cre.local #因为busybox和kubernetes都在default名称空间，只写svc的name也是可以解析出来的； ~]# kubectl exec busybox nslookup kube-dns #kube-dns这个svc nslookup: cant&apos;t resolve &apos;kube-dns&apos; Server: 10.96.254.254 Address 1: 10.96.254.254 kube-dns.kube-system.svc.cre.local command terminated with exit code 1 #此时解析和busybox不在同一namespace的kube-dns就不能解析了； ~]# kubectl exec busybox nslookup kube-dns.kube-system.svc.cre.local Server: 10.96.254.254 Address 1: 10.96.254.254 kube-dns.kube-system.svc.cre.local Name: kube-dns.kube-system.svc.cre.local Address 1: 10.96.254.254 kube-dns.kube-system.svc.cre.local #使用完成格式的svc名称解析就可以解析出来了,所以在生产环境中规定都是写service的全称，而不是这些svc的名字； 5.域名解析原理： 1.k8s是基于pod的service-name相互调用、解析的，不是deployment也不是pod 2.在k8s内部是有namespace的概念的，不同的ns之间的域名等信息是隔离的，不同ns中可以有相同的pod、service、controller等资源，如果 两个pod不在同一ns中是不能解析出其svc的（不是不能而是写全称）； 3.k8s为了解决第2条的问题，规定业务相互调用时必须写svc的全称,即指定解析的svc是在哪个名称空间下； 全称格式： 业务svc-name.所在名称空间.svc.cre.local 如： tomcat1-svc.cre.svc.cre.local #cre名称空间下的tomcat1业务 比如： nginx的upstream中调用tomcat时，server后填的的这个tomcat的全称:8080 upstream creonline { hash $remote_addr consistent; server tomcat1.cre.svc.cre.local:8080 weight=2 max_fails=0; server tomcat2.cre.svc.cre.local:8080 weight=3max_fails=0; server tomcat3.cre.svc.cre.local:8080 max_fails=0; keepalive 32； } 2.部署CoreDNScoredns项目deployment部署项目kubernetes-addons中的coredns项目 部署方式： 1.coredns在github上是需要使用GO编译安装的，但是在deployment分支中的模板；项目上有人做好了coredns.yaml的模板和修改脚本，可以根据实际 情况修改成自己使用的coredns.yaml部署清单文件； deploy.sh脚本： 其实就是输入自己定义的DNS-IP和service-CIDR网段，传递参数生成新的coredns.yaml清单； 2.在kubernetes项目中的附件addons中也可以下载coredns.yaml.sed模板清单，在使用deploy.sh脚本处理； 3.两个地方下载的coredns.yaml.sed清单内容还是有差别的，差别在于： 是否使用运行在K8s-Master节点上附加组件管理器（Addon-manager）管理附加组件（Addons）的服务，它管理着 $ADDON_PATH （默认是 /etc/kubernetes/addons/）目录中的所有扩展，保证它们始终运行在期望状态； 4.Addon-manager支持两种标签： 1.addonmanager.kubernetes.io/mode=Reconcile： 表示无法通过API来修改，即： 1.如果通过API修改了，则会自动回滚到/etc/kubernetes/addons/中的配置； 2.如果通过API删除了，则会通过/etc/kubernetes/addons/中的配置自动重新创建； 3.如果从/etc/kubernetes/addons/中删除配置，则Kubernetes资源也会删除； 简而言之就是说只能通过修改/etc/kubernetes/addons/中的配置来修改； 2.addonmanager.kubernetes.io/mode=EnsureExists： 表示仅检查扩展是否存在而不检查配置是否更改，即： 1.可以通过API来修改配置，不会自动回滚 2.如果通过API删除了，则会通过/etc/kubernetes/addons/中的配置自动重新创建 3.如果从/etc/kubernetes/addons/中删除配置，则Kubernetes资源不会删除； 当然yaml模板中还有其他参数的差别，具体使用哪一个模板都可以，下文使用的是deployment分支中的模板； 5.部署的coredns副本数量是1 在coredns.yaml清单中coredns的replicas副本数量默认都是1个，但是如果开启了coredns的HPA功能，replicas的数量会自动伸缩； 1.下载镜像并上传 coredns只需一个镜像即可，不像kubedns需要3个镜像 ~]# docker load -i coredns_1.2.2.tar #使用1.2.2版本（查看k8s依赖版本部署） ~]# docker tag coredns/coredns:1.2.2 192.168.1.101/baseimage/coredns:1.2.2 #更改tag后上传到本地harbor上 ~]# docker push 192.168.1.101/baseimage/coredns:1.2.2 2.下载coredns.yaml.sed的模板清单和处理脚本 ~]# wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed #在deployment分支上下载coredns的模板清单 ~]# wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh #下载处理脚本 3.生成core.yaml清单，并修改拉取镜像地址 1.生成新的yaml清单 ~]# bash deploy.sh -i 10.96.254.254 -r &quot;10.96.0.0/12&quot; -s -t coredns.yaml.sed -d cre.local &gt; coredns.yaml #1.向脚本传递DNS服务的地址是10.96.254.254，service的网段时10.96.0.0/12，然后生成实际的coredns.yaml清单文件； #2.DNS地址就是kubelet配置的--cluster-dns参数的地址，在node节点上使用ps -ef | grep dns即可看到kubelet的信息； #3.-d cre.local:指定部署的k8s集群真正的域后缀名称，代替模板中默认的cluster.local; 2.修改yaml清单 ~]# vim coredns.yaml ... --- apiVersion: v1 kind: ConfigMap ... data: Corefile: | .:53 { errors health kubernetes cre.local. in-addr.arpa ip6.arpa #修改为实际域名后缀 ... containers: - name: coredns image: 192.168.1.101/baseimages/coredns:1.2.6 #从harbor拉取镜像 ... 备注： 修改k8s的域后缀，当然也可以在deploy.sh通过-d传递和从本地拉取镜像 4.部署 ~]# kubectl apply -f coredns.yaml serviceaccount/coredns created clusterrole.rbac.authorization.k8s.io/system:coredns created clusterrolebinding.rbac.authorization.k8s.io/system:coredns created configmap/coredns created deployment.extensions/coredns created service/kube-dns created ~]# kubectl get pods -n kube-system | grep coredns NAME READY STATUS RESTARTS AGE coredns-5457cf5965-l6rkq 1/1 Running 0 20s #正常运行 5.测试DNS服务 和上文kube-dns测试步骤相同； 部署dnsmasq实现统一管理k8s-dns和内网DNS原因： 在经过上面的一系列部署之后，kuberntes的虚拟集群网络的DNS解析的确是可以的了。但是kubernetes之外的物理机节点也是需要DNS解析的，那么该 怎么去管理呢？ 比如，在上文部署kube-dns时提到过代码中写的是内网DNS中的域名，而对于k8s中的服务来说也是需要解析内网DNS的，上文只是提出对于使用 kube-dns的一个解决方案，但是对于coredns来说如何解决？ 方法：使用Dnsmasq: dnsmasq部署于物理服务器上，而CoreDNS的上游DNS服务器默认会选择物理机网卡上设置的DNS，只要将dnsmasq作为物理机网卡设置的DNS，那么就可 以直接设置为CoreDNS的上游DNS服务器了。 Dnsmasq工作原理: 1.Dnsmasq提供DNS缓存和DHCP服务、Tftp服务功能。当接受到一个DNS请求时，Dnsmasq首先会查找/etc/hosts这个文件，然后查找/etc/resolv.conf 中定义的外部DNS。所以说Dnsmasq是一个很不错的外部DNS中继。 2.配置Dnsmasq为DNS缓存服务器，同时在/etc/hosts文件中加入本地内网解析，这样一来每当内网机器查询时就会优先查询hosts文件，这就等于 将/etc/hosts共享给全内网机器使用，从而解决内网机器互相识别的问题; 1.部署Dnsmasq服务 ~]# getenforce 0 #关闭selinux以及配置防火墙放行53端口号 ~]# systemctl stop firewalld.service #停止firewall ~]# systemctl disable firewalld.service #禁止firewall开机启动 关闭防火墙： ~]# yum install -y dnsmasq ~]# systemctl start dnsmasq #安装并启动Dnsmasq ~]# systemctl status dnsmasq ● dnsmasq.service - DNS caching server. Loaded: loaded (/usr/lib/systemd/system/dnsmasq.service; disabled; vendor preset: disabled) Active: active (running) since Sun 2018-07-14 23:06:36 CST; 11s ago Main PID: 5895 (dnsmasq) Tasks: 1 Memory: 396.0K CGroup: /system.slice/dnsmasq.service └─5895 /usr/sbin/dnsmasq -k Jul 14 23:06:36 master01 dnsmasq[5895]: reading /etc/resolv.conf Jul 14 23:06:36 master01 dnsmasq[5895]: using nameserver 45.113.201.35#53 Jul 14 23:06:36 master01 dnsmasq[5895]: using nameserver 114.114.114.114#53 Jul 14 23:06:36 master01 dnsmasq[5895]: read /etc/hosts - 5 addresses #Dnsmasq启动后，会自动读取当前主机的网卡的DNS以及hosts文件 2.Dnsmasq配置文件解析： Dnsmasq的配置文件在/etc/dnsmasq.conf，默认情况下dnsmasq.conf中只开启了最后include项，可以在/etc/dnsmasq.d中自己写任意名字的配置文件。 重要部分配置文件说明： resolv-file=/etc/resolv.dnsmasq.conf #定义dnsmasq从哪里获取上游DNS服务器的地址，默认是从/etc/resolv.conf获取 strict-order #严格按照resolv-file文件中的顺序从上到下进行DNS解析，直到第一个解析成功为止。一般需要开启strict-order listen-address=127.0.0.1 #定义dnsmasq监听的地址，默认是监控本机的所有网卡上。局域网内主机若要使用dnsmasq服务时，指定本机的IP地址 address=/19.76.10.in-addr.arpa/10.20.10.10 #设置一个反向解析，即所有的地址都解析到特定dns去解析 address=/double-click.net/127.0.0.1 #增加一个域名，强制解析到你指定的地址上 cache-size=150 #设置dns缓存大小,默认为150条 log-queries log-facility=/usr/log/dnsmasq.log 设置DNS的日志及日志路径 3.配置Dnsmasq ~]# grep -v &quot;^#&quot; /etc/dnsmasq.conf | grep -v &quot;^$&quot; #Dnsmasq的配置文件 resolv-file=/etc/resolv.dnsmasq.conf #dnsmasq会从这个文件中寻找上游dns服务器 strict-order addn-hosts=/etc/dnsmasq.hosts listen-address=127.0.0.1,192.168.1.160 #dnsmasq部署在192.168.1.160上 4.修改本机/etc/resolv.conf指向部署的dnsmasq服务器 ~]# vim /etc/resolv.conf nameserver 192.168.1.160 #dnsmasq服务器的地址 5.创建resolv.dnsmasq.conf文件并添加上游DNS服务器地址 ~]# vim /etc/resolv.dnsmasq.conf nameserver 202.96.134.133 nameserver 114.114.114.114 备注： resolv.dnsmasq.conf中设置的真正能访问互联网的DNS服务器地址（如电信、联通、腾讯、阿里） 6.创建dnsmasq.hosts文件 ~]# cp /etc/hosts /etc/dnsmasq.hosts ~]# vim /etc/dnsmasq.hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 kube-master01 192.168.1.101 kube-master02 192.168.1.102 kube-master03 192.168.1.103 kube-node01 192.168.1.104 kube-node02 192.168.1.105 kube-node03 192.168.1.106 #添加内网需要解析的DNS地址和域名 7.启动Dnsmasq ~]# systemctl start dnsmasq &amp;&amp; systemctl enable dnsmasq ]# ss -tnlp | grep 53 LISTEN 0 5 *:53 *:* users:((&quot;dnsmasq&quot;,pid=4581,fd=5)) LISTEN 0 5 :::53 :::* users:((&quot;dnsmasq&quot;,pid=4581,fd=7)) 8.重启Coredns CoreDNS在启动的时候已经设置好了上游DNS服务器了，重启一下可以让CoreDNS重新设置上游服务器。 9.测试 ~]# ping k8s-master01 #在物理节点测试 PING k8s-master01 (192.168.1.101) 56(84) bytes of data. 64 bytes from k8s-master01 (192.168.1.101): icmp_seq=1 ttl=64 time=0.036 ms 64 bytes from k8s-master01 (192.168.1.101): icmp_seq=2 ttl=64 time=0.056 ms ~]# kubectl exec busybox ping k8s-master01 PING k8s-master01 (192.168.1.101) 56(84) bytes of data. 64 bytes from k8s-master01 (192.168.1.101): icmp_seq=1 ttl=64 time=0.033 ms #可以看到容器内的pod也可以解析内网的服务器地址了； 总结： 从上面的结果来看，Dnsmasq已经成为了CoreDNS的上游DNS服务器了，这样只要管理好dnsmasq的域名配置，就可以统一管理各台物理机以及 kubernetes所有服务的DNS解析了；]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Etcd集群搭建和维护]]></title>
    <url>%2F2018%2F09%2F06%2FEtcd%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E5%92%8C%E7%BB%B4%E6%8A%A4%2F</url>
    <content type="text"><![CDATA[Etcd原理 etcd官网Raft协议和它的三个子问题 1.什么是etcd？ 1.1.etcd是一个强大一致的分布式键值存储，它提供了一种可靠的方式来存储需要由分布式系统或机器群访问的数据。它优雅地处理网络分区 期间的领导者选举，并且可以容忍机器故障，即使在领导者节点中也是如此。 1.2.etcd主要用来作为共享的服务配置及服务发现，使用的是raft协议来保证在分布式系统下的数据一致性，而raft算法那么容易理解， 对于每个过程也是很好处理的； 1.3.etcd基于raft协议来完成leader选举、完成数据强一致性协作等，每一节点都可以读写，任何节点写入的数据都会同步到集群中其他节点； 1.4.raft协议是简装版的paxos协议，比paxos更轻量化更适用于轻量式的分布式协作的应用场景中； 2.etcd集群的节点数量？ 1.在etcd的集群中会选举出一位leader，其他etcd服务节点就会成为follower，在此过程其他follower会同步leader的数据。由于etcd 集群必须能够选举出leader才能正常工作，为了避免当集群发生网络分区时的脑裂行为，所以部署的服务器数量必须是奇数， 例如： 1，3，5，7，9 的etcd节点数量。 2.etcd集群数量必须为奇数 2.1.在组建集群的时候，我们总是可以看到使用奇数个节点，例如，3，5，7，9等节点的数量。 2.2.要是在选主leader的时候，不会发生脑裂的情况。一般情况是如果有3个，那么可以容许一个挂掉；如果有五个，那么容许2个挂掉； 也就是N/2+1个活着就行。 3.etcd的节点数量为奇数，需要部署多少个节点最合适呢？ 在考虑etcd读写效率以及稳定性的情况下，基本可以选型如下： 只有单台或者两台服务器做kubernetes的服务集群，只需要部署一台etcd节点即可； 只有三台或者四台服务器做kubernetes的服务集群，只需要部署三台etcd节点即可； 只有五台或者六台服务器做kubernetes的服务集群，只需要部署五台etcd节点即可； 4.etcd节点数量不易太多； 1.三台和五台服务器作为etcd的节点已经比较稳定的了； 2.因为etcd的集群所有的follower都需要从leader同步完数据之后，leader才能继续写入新的数据，所以如果etcd的节点数量过多， 则会导致同步的时间变长、导致leader的写入效率降低； 3.数量过多时，当出现网络抖动，延时、不稳定的情况，那么需要管理、维护、修复故障的服务器数量就多； Etcd集群搭建1.如何搭建高可用etcd集群？ 1.etcd内置了高可用组件，只要激活这个组件就可以激活raft协议让etcd节点彼此之间能够协作，称为一个强一致性的etcd集群； 2.etcd集群的每一节点都可以读写，都会把数据同步给集群中的其他节点； 3.因为etcd本身是强一致性的，它其实是BASE（ACID）理论的一种实践，当集群发生网络分区（Partition-tolerance）时，为了避免脑裂， 它的法定票数quorum必须大于半数才能避免分区（奇数）； 2.etcd版本注意： 1.特别注意，k8s v1.9用的是v3.10版本的etcd，现在最新的v1.14版本k8s支持的etcd最低版本为3.12.x，因此这里etcd的版本替换成了 3.13版本的; 2.centos的extra源自带3.3.11版本的etcd，这里直接使用这个版本安装 3.设置主机名解析 ~]# vim /etc/hosts 192.168.0.101 k8s-master01.cre.io k8s-master01 etcd01.cre.io etcd01 192.168.0.102 k8s-master02.cre.io k8s-master02 etcd02.cre.io etcd02 192.168.0.103 k8s-master03.cre.io k8s-master03 etcd03.cre.io etcd03 #内部要使用DNS服务器 4.安装etcd ~]# yum install epel-release -y #安装epel源 ~]# yum install etcd -y ~]# rpm -ql etcd /etc/etcd /etc/etcd/etcd.conf #主配置文件，被etcd.service作为变量使用 /usr/bin/etcd #服务端程序 /usr/bin/etcdctl #客户端程序 /usr/lib/systemd/system/etcd.service #Unitfile /var/lib/etcd #默认的数据存储目录，可使用nfs等存储 ~]# grep -v &quot;^#&quot; /etc/etcd/etcd.conf #配置成etcd集群 ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot; ETCD_LISTEN_PEER_URLS=&quot;http://192.168.0.101:2380&quot; ETCD_LISTEN_CLIENT_URLS=&quot;http://192.168.0.101:2379&quot; ETCD_NAME=&quot;etcd01.cre.io&quot; ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://etcd01.cre.io:2380&quot; ETCD_ADVERTISE_CLIENT_URLS=&quot;http://etcd01.cre.io:2379&quot; ETCD_INITIAL_CLUSTER=&quot;etcd01.cre.io=http://etcd01.cre.io:2380,etcd02.cre.io=http://etcd02.cre.io:2380,etcd03.cre.io=http://etcd03.cre.io:2380&quot; #这里先不配置证书，参数意义和格式参照下文附录1中说明 ~]# scp /etc/etcd/etcd.conf etcd02.cre.io:/etc/etcd/ ~]# scp /etc/etcd/etcd.conf etcd03.cre.io:/etc/etcd/ #将配置文件复制给etcd其他节点，在其他节点上修改各自的主机名和IP即可； 5.启动集群 ~]# systemctl start etcd #将3个节点的etcd都启动 ~]# systemctl enable etcd #设置开机自启etcd服务 ~]# ss -tnl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 192.168.0.101:2379 *:* LISTEN 0 128 192.168.0.101:2380 *:* #确保3个节点上etcd的2379、2380端口都是处于监听的 6.测试etcd集群是否正常 测试的时候，最简单的方式就是使用命令客户端etcdctl来测试，如下： ~]# etcdctl --endpoints=&apos;http://etcd01.cre.io:2379&apos; member list b3504381e8ba3cb: name=etcd02.cre.io peerURLs=http://etcd02.cre.io:2380 clientURLs=http://etcd02.cre.io:2379 isLeader=false b8b747c74aaea686: name=etcd01.cre.io peerURLs=http://etcd01.cre.io:2380 clientURLs=http://etcd01.cre.io:2379 isLeader=true f572fdfc5cb68406: name=etcd03.cre.io peerURLs=http://etcd03.cre.io:2380 clientURLs=http://etcd03.cre.io:2379 isLeader=false 备注： 1.通过--endpoints选项连接任何节点的2379可以列出集群中所有成员 2.isLeader=true是集群内部leader选举出的leader节点；false表示备用节点 扩展： 1.~]# etcdctl member list error #0: dial tcp 127.0.0.1:4001: connect: connection refused error #1: dial tcp 127.0.0.1:2379: connect: connection refused #不加--endpoints使用会出错是因为etcd.conf配置文件中没监听127.0.0.1 修改成ETCD_LISTEN_CLIENT_URLS=&quot;http://192.168.0.101:2379，http://127.0.0.1:2379&quot;即可 2.etcdctl还有其他命令都可以探测集群是否正常，如cluster-health、mkdir、set等，有需要可以自己测试； 3.为了确保数据安全，可以使用etcdctl backup进行周期性数据备份； 7.etcd API 虽然这里安装的是etcd 3.x版本，但是etcd的环境变量中的API默认是etcd_v2，如果要使用etcd_v3_API，需要设置环境变量； ~]# export ETCDCTL_API=3 ~]# etcdctl help #etcd_v2和etcd_v3的API还是有区别的，而且使用etcdctl命令也可以看出来； 这样一个高可用的基于http通信的etcd集群就搭建好了!!! 配置etcd集群基于https通信（等于重新生成一个新的etcd集群）首先etcd中的数据是很重要的一般需要将etcd集群是基于证书认证的https通信，其次其实这篇etcd集群部署是和k8s集群有关的，因此无论出于 何种目的都需要配置成https通信； 制作证书工具： 1.CFSSL 2.openssl #本文以openssl工具为例 证书要求： CA证书: 服务端和peer对等证书共用的CA证书 server证书： 服务端证书和私钥 peer对等证书： 每一个证书既是当客户端证书用，又当服务端证书用，只用在2380各节点间通信，因此证书中的CN必须一致； apiserver证书： 用于kube-apiserver作为etcd的客户端连接至etcd集群各节点 客户端证书： etcd集群本地要连接到etcd也需要一个方便测试使用的证书：client.crt 1.制作证书 在github有人做好了制作证书的脚本，下载即可使用 ]# git clone https://github.com/iKubernetes/k8s-certs-generator.git ~]# cd k8s-certs-generator/ ~]# ls etcd-certs-gen.sh gencerts.sh k8s-certs-gen.sh openssl.conf #gencerts.sh可以做k8s和etcd证书，也可以用另外单独两个做证书 ~]# bash gencerts.sh etcd Enter Domain Name [ilinux.io]: cre.io #填写为哪个域名申请证书即可由脚本生产，最后会生成一个etcd目录 比如使用cre.io和在/etc/hosts文件中保持一致 ~]# tree etcd #生成的etcd证书目录 etcd ├── patches │ └── etcd-client-cert.patch └── pki ├── apiserver-etcd-client.crt #apiserver作为客户端的证书 ├── apiserver-etcd-client.key #apiserver作为客户端的私钥 ├── ca.crt #ca的证书 ├── ca.key #ca的私钥 ├── client.crt #本地连接测试使用证书 ├── client.key #本地连接测试使用私钥 ├── peer.crt #对等通信的证书 ├── peer.key #对等通信的私钥 ├── server.crt #服务端证书 └── server.key #服务端私钥 ~]# cp pki/ /etc/etcd/ -a ~]# scp -rp pki/ etcd02.cre.io:/etc/etcd/ ~]# scp -rp pki/ etcd03.cre.io:/etc/etcd/ #每一个etcd节点都需要一样的证书，将pki目录复制过去都放到/etc/etcd/目录下 2.修改etcd.conf配置文件 ~]# grep -v &quot;^#&quot; /etc/etcd/etcd.conf ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot; ETCD_LISTEN_PEER_URLS=&quot;https://192.168.0.101:2380&quot; #修改成https ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.0.101:2379&quot; #修改成https ETCD_NAME=&quot;etcd02.cre.io&quot; #和hosts、证书中的域名保持一致 ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://etcd02.cre.io:2380&quot; ETCD_ADVERTISE_CLIENT_URLS=&quot;https://etcd02.cre.io:2379&quot; ETCD_INITIAL_CLUSTER=&quot;etcd01.cre.io=https://etcd01.cre.io:2380,etcd02.cre.io=https://etcd02.cre.io:2380,etcd03.cre.io=https://etcd03.cre.io:2380&quot; ETCD_CERT_FILE=&quot;/etc/etcd/pki/server.crt&quot; #etcd作为服务端的证书 ETCD_KEY_FILE=&quot;/etc/etcd/pki/server.key&quot; #etcd作为服务端的私钥 ETCD_CLIENT_CERT_AUTH=&quot;true&quot; #客户端连接etcd要使用证书认证 ETCD_TRUSTED_CA_FILE=&quot;/etc/etcd/pki/ca.crt&quot; #etcd所信任的CA证书 ETCD_AUTO_TLS=&quot;false&quot; #不自动生成证书和私钥 ETCD_PEER_CERT_FILE=&quot;/etc/etcd/pki/peer.crt&quot; #使用的对等证书文件 ETCD_PEER_KEY_FILE=&quot;/etc/etcd/pki/peer.key&quot; #使用的对等私钥文件 ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot; #集群中各节点通信时要互相验证对方的证书 ETCD_PEER_TRUSTED_CA_FILE=&quot;/etc/etcd/pki/ca.crt&quot;#对等证书信任的CA证书 ETCD_PEER_AUTO_TLS=&quot;false&quot; #不开启自动生成对等证书和私钥 3.启动集群 ~]# rm -rf /var/lib/etcd/* #先将之前生成的文件删除，因为这等于配置了一个新集群避免问题干扰 ~]# systemctl start etcd #3个节点都启用etcd 4.测试 ~]# etcdctl --endpoints=&apos;https://etcd01.cre.io:2379&apos; --cert-file=/etc/etcd/pki/client.crt --key-file=/etc/etcd/pki/client.key --ca-file=/etc/etcd/pki/ca.crt cluster-health member 78f1359abb4e38df is healthy: got healthy result from https://etcd03.cre.io:2379 member 82a31133d997d8c1 is healthy: got healthy result from https://etcd02.cre.io:2379 member d5b7e59a90e92a8f is healthy: got healthy result from https://etcd01.cre.io:2379 cluster is healthy #使用client.crt客户端证书连接并验证基于https通信的etcd集群搭建好了； ETCD_CLIENT_CERT_AUTH=&quot;true&quot; 的作用就是客户端连接etcd必须使用证书； 备注： 从menber的ID看出这是一个新的集群了，所以最好要把数据目录/var/lib/etcd/进行清空，重新自动生成； 5.重要说明 配置成基于https通信的etcd集群就等于在上面的基础上重新配置一个新集群，那么上面已有集群信息必然会影响这次的重新部署，因此需要清理一些文件； ~]# vim /etc/etcd/etcd.conf ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot; #启用此项并重新设置不同的etcd集群初始化的token名字 ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot; #修改etcd的数据存储目录 ~]# rm -rf &quot;/var/lib/etcd/* #将之前的数据全部删除，重新自动创建 附录1：配置etcd集群需要设置的参数项etcd的主配置为/etc/etcd/etcd.conf，各节点上使用的个别配置参数的取值会有不同，主要是需要分别根据节点自身的环境进行取值。需要配置的各参数说明如下： ETCD_DATA_DIR=&quot;/var/lib/etcd/k8s.etcd&quot; 集群数据目录，可保持默认或按需取值；建议各节点保持一致； ETCD_LISTEN_PEER_URLS 当前节点用于集群内的节点间通信监听的URL，需要以IP地址格式给出当前节点用于etcd集群通信的接口的IP地址，例如&quot;https://172.29.3.6:2380&quot;； ETCD_LISTEN_CLIENT_URLS 当前节点向客户端提供服务所监听的URL，需要以IP地址格式给出当前节点用于向客户端提供服务的接口的IP地址，例如&quot;https://172.29.3.6:2379&quot;； ETCD_NAME 当前节点的主机名称，例如&quot;k8s-master01.ilinux.io&quot;； ETCD_INITIAL_ADVERTISE_PEER_URLS 此成员节点向etcd集群通告的URL，例如&quot;https://k8s-master01.ilinux.io:2380&quot;； ETCD_ADVERTISE_CLIENT_URLS 此节点通告的用于向客户端提供服务的URL，例如&quot;https://k8s-master01.ilinux.io:2379&quot;； ETCD_INITIAL_CLUSTER=&quot;k8s-master01.ilinux.io&quot; 用于引导并启动集群的配置信息，由集群的全部成员节点向集群通告的URL组成的列表，例如&quot;k8s-master01.ilinux.io=https://k8s-master01.ilinux.io:2380,k8s-master02.ilinux.io=https://k8s-master02.ilinux.io:2380,k8s-master03.ilinux.io=https://k8s-master03.ilinux.io:2380&quot;； ETCD_CERT_FILE 用于同客户端通信时使用的服务器证书文件路径，例如&quot;/etc/etcd/pki/server.crt&quot; ETCD_KEY_FILE 用于同客户端通信时使用的服务器证书匹配的私钥文件，例如&quot;/etc/etcd/pki/server.key&quot; ETCD_CLIENT_CERT_AUTH 是否需要认证客户端，安全通信的场景需要启用，其值需要为&quot;true&quot; ETCD_TRUSTED_CA_FILE 指定信任的CA的数字证书，例如&quot;/etc/etcd/pki/ca.crt&quot; ETCD_PEER_CERT_FILE etcd集群成员间通信时用于认证的peer格式的数字证书，例如&quot;/etc/etcd/pki/peer.crt&quot; ETCD_PEER_KEY_FILE etcd集群成员通信时所用证书所配对的私钥，例如&quot;/etc/etcd/pki/peer.key&quot; ETCD_PEER_CLIENT_CERT_AUTH 是否验正集群成员节点的客户端证书，安全通信的场景需要启用，其值为&quot;true&quot; ETCD_PEER_TRUSTED_CA_FILE 用于为成员安全通信签署证书的CA的证书，例如&quot;/etc/etcd/pki/ca.crt&quot; etcd集群数据备份、基本管理和故障维护1.管理etcd集群 Etcd集群支持在线改变集群成员节点，可以增加、修改、删除成员节点；不过改变成员数量仍旧需要满足集群成员多数同意原则（quorum）， 另外请记住集群成员数量变化的影响： 1.增加etcd集群节点, 提高集群稳定性 2.增加etcd集群节点,提高集群读性能（所有节点数据一致，客户端可以从任意节点读取数据）； 3.增加etcd集群节点,降低集群写性能（所有节点数据一致，每一次写入会需要所有节点数据同步）； 2.关于etcd数据存储的说明 首先etcd对数据的持久化采用的是binlog日志，也称WAL，即Write-Ahead-Log+Snapshot快照的方式，即数据目录是由snap+wal （binlog）两个目录组成的； 1.如下：是etcd数据目录的树结构和两个目录的作用： ~]# tree /var/lib/etcd/ /var/lib/etcd/ └── default.etcd └── member ├── snap │ └── db └── wal ├── 0000000000000000-0000000000000000.wal └── 0.tmp snap: 用于存放快照数据，etcd为防止WAL文件过多会创建快照，snap用于存储etcd的快照数据状态； wal： 1.用于存放预写式日志，其最大的作用是记录整个数据变化的全部历程。 2.在etcd中，所有数据的修改在提交前，都要先写入WAL中，使用WAL进行数据的存储使得etcd拥有故障快速回复和数据回滚这两个重要功能； 2.故障恢复： 1.如果你的数据遭到破坏，就可以通过执行所有WAL中记录的修改操作，快速从最原始的数据恢复到数据损坏之前的状态； 2.etcd会把启动的配置信息存储到--datadir参数指定的数据目录中，配置信息包括本地节点的ID、集群ID和初始化时的集群信息， 当一个节点有数据损坏或丢失时，就应该把这个节点从集群中删除，然后加入一个不带数据目录的新节点； 3.数据回滚undo/重做redo： 因为所有的修改操作都被记录在WAL中，所以进行回滚或重做时，只需要反向或正向执行日志中的操作即可； 4.为什么还要做快照？ 虽然有了wal实时存储所有的变更，但为了防止磁盘很快爆满，etcd默认每10000条记录做一次快照，做过快照后的wal文件就可以删除了，而且通过API可以查询的历史etcd操作默认为1000条； 在备份中的文件目录如下所示： ~]# tree /data/etcdbak/ /data/etcdbak/ └── back_20190628 └── member ├── snap │ └── db └── wal └── 0000000000000000-0000000000000000.wal #从上面可以看到，备份会默认丢弃tmp文件，而tmp文件主要是未提交的数据记录 3.备份、恢复etcd数据: etcd_API有v2、v3版本，所以备份时还是有区别的，下文分别阐述： 区别： 做快照的时候etcd_v2是把内存中的数据库序列化成JSON，然后持久化到磁盘，而etcd_v3是读取磁盘里的数据库的当前版本（从BoltDB在读取，然后序列化到磁盘）； 1.etcd v2版本的备份和恢复 etcd v2是一个纯内存数据库，写操作先通过Raft协议复制binlog,复制成功后将数据写入内存，整个数据库在内存中就是一个简单的 树结构，其并未将数据实时写入磁盘，持久化是靠binlog和定期做快照来实现的，etcd_v2做快照的方法是将内存中的整个数据库复制 一份出来，然后序列化成JSON，写入磁盘中成为一个快照；而且做快照时使用的是复制出来的数据库，客户端的读写请求依旧会落在原 始的数据库上，所以做快照的操作不会阻塞客户端的读写请求； 1.1.备份方式： ~]# export ETCDCTL_API=2 #配置etcd v2的API环境变量 #因为etcdctl backup命令是etcd v2的API的子命令； ~]# vim /script/backup_etcd.sh #备份脚本 #!/bin/bash date_time=`date +%Y%m%d` etcdctl backup --data-dir /var/lib/etcd/default.etcd/ --backup-dir /data/etcdbak/back_${date_time} find /data/etcdbak/ -ctime +7 -exec rm -r {} \; ~]# crontab -e #设置定时任务 #backup etcd everyday at 2:00 0 2 * * * /usr/bin/bash /script/backup_etcd.sh &amp;&gt; /dev/null #将错误输出和正常输出都重定向掉，是为了防止发送邮件，造成inode数量增大； #备份数据时，可以在任意节点执行backup命令即可； 1.2.数据恢复的步骤 1.打包备份数据，发送到要恢复的etcd主机 ~]# rm -rf /var/lib/etcd/default.etcd/* #先删除本机上原来的数据目录下的所有文件 ~]# tar -zcvf etcdbak.tar.gz etcdbak/ etcdbak/ etcdbak/20181220/ etcdbak/20181220/member/ etcdbak/20181220/member/snap/ etcdbak/20181220/member/wal/ etcdbak/20181220/member/wal/0000000000-000000000000.wal ~]# cp -rf etcdbak/20181220/member /var/lib/etcd/default.etcd/ #只需要将member目录复制到default.etcd下即可； 2.etcd v3版本的备份和恢复 在一个基线上为etcd集群做快照能够实现etcd数据的冗余备份，通过定期的为etcd节点后端数据库做快照，etcd集群就能从一个已知的 良好状态时间点进行恢复； 2.1.备份方式： ~]# mkdir /etcd_back &amp;&amp; cd /etcd_back #创建快照的备份目录，并且执行备份命令也是在此目录； ~]# ETCDCTL_API=3 etcdctl --endpoinits $ENDPOINT snapshot save backup.db #指定一个正在运行的etcd节点使用snapshot-save备份,然后集群就可以通过复制etcd节点数据目录的member/snap/db文件来获得快照了； ~]# ETCDCTL_API=3 etcdctl --write-out=table snapshot status backup.db +-----------+----------+------------+-------------+ | HASH | REVISION | TOTAL KEYS | TOTAL SIZE | +-----------+----------+------------+-------------+ | fe01cf57 | 10 | 230 | 10.2M | +-----------+----------+------------+-------------+ #查看备份，而且快照文件的完整性校验会在恢复时进行，使用backup.db中的HASH值就是用于snapshot restore时进行校验； 扩展： 备份方式还可以直接从etcd的数据目录中进行复制，但复制过来的数据是没有一致性Hash值的，在恢复时需要使用&quot;--skip-hash-check&quot;选项跳过，下文有直接复制数据目录恢复的方式 2.2.恢复步骤： 1.etcd v3提供了快照和恢复机制重建一个新的etcd集群，只要一个快照文件就能恢复etcd集群，使用snapshot restore命令 创建一个新的etcd数据目录（m1.etcd,m2.etcd,m3.etcd），所有节点都将从同一个快照文件进行恢复，恢复时会覆写快照文件 中的一些元数据，如：member ID和cluster ID,这些节点也就丢失它们之前的身份信息，抹掉元数据就是为了防止新节点不小心加入别的etcd集群； 2.恢复操作会初始化一个新的etcd节点，该节点保留了之前的数据，并且配置将通过启动参数传入，步骤如下： 1.停止ectd集群服务 ~]# systemctl stop etcd #停止所有etcd节点服务 2.清除etcd数据目录 ~]# rm -rf /var/lib/etcd/default.etcd/* #清除所有etcd节点之前生成default.etcd数据目录下的所有文件，有的人可能没有default.etcd这个目录，按照实际情况的数据目录删除即可； 3.生成备份目录和准备最新的备份快照文件 ~]# mkdir etcd_back #创建恢复数据时的目录，将快照复制到此目录 #因为执行snapshot_restore时会生成新的etcd数据目录，需要将这些目录拷贝到/var/lib/etcd/下； ~]# cd /etcd_back &amp;&amp; mv backup.db /etcd_back ~]# ls /etcd_back backup.db #确保这是恢复时需要的快照文件 4.etcd数据恢复 etcd01.cre.io、etcd02.cre.io、etcd03.cre.io是3台etcd节点的主机名 ~]# export ETCDCTL_API=3 #导出etcd v3的API环境变量 #snapshot_restore是etcd_v3_API的子命令，默认是etcd_2的环境变量； ~]# ETCDCTL_API=3 etcdctl snapshot restore backup.db \ --name etcd01.cre.io \ --initial-cluster etcd01.cre.io=https://etcd01.cre.io:2380,etcd02.cre.io=https://etcd02.cre.io:2380,etcd03.cre.io=https://etcd03.cre.io:2380 \ --initial-cluster-token etcd-cluster-0 \ --initial-advertise-peer-urls https://etcd01.cre.io:2380 ~]# ETCDCTL_API=3 etcdctl snapshot restore backup.db \ --name etcd02.cre.io \ --initial-cluster etcd01.cre.io=https://etcd01.cre.io:2380,etcd02.cre.io=https://etcd02.cre.io:2380,etcd03.cre.io=https://etcd03.cre.io:2380 \ --initial-cluster-token etcd-cluster-0 \ --initial-advertise-peer-urls https://etcd02.cre.io:2380 ~]# ETCDCTL_API=3 etcdctl snapshot restore backup.db \ --name etcd03.cre.io \ --initial-cluster etcd01.cre.io=https://etcd01.cre.io:2380,etcd02.cre.io=https://etcd02.cre.io:2380,etcd03.cre.io=https://etcd03.cre.io:2380 \ --initial-cluster-token etcd-cluster-0 \ --initial-advertise-peer-urls https://etcd03.cre.io:2380 ~]# ls /etcd_back backup.db etcd01.cre.io.etcd etcd02.cre.io.etcd etcd03.cre.io.etcd #上面每执行一次命令就会生成etcd节点对应的数据目录，所以这里生成了3个数据目录 5.拷贝恢复的数据目录到etcd数据目录 由于etcd的配置文件中指定的数据目录是--datadir=/var/lib/etcd/default.etcd，所以这里需要把对应目录下的member目录复制即可,或者复制时将目录改成default.etcd即可； ~]# cp -rf /etcd_back/etcd01.cre.io.etcd/member /var/lib/etcd/default.etcd ~]# cp -rf /etcd_back/etcd02.cre.io.etcd/member /var/lib/etcd/default.etcd ~]# cp -rf /etcd_back/etcd03.cre.io.etcd/member /var/lib/etcd/default.etcd #将3台etcd使用snapshot_restore生成的对应数据拷贝到对应的etcd节点即可； 6.启动etcd ~]# systemctl start etcd #拷贝确认无误后启动3台etcd节点 7.验证所有etcd节点服务状态和日志 ~]# systemctl status etcd ~]# journalctl -u etcd -f #验证三个etcd进程都启动没有报错后，etcd集群就能在快照数据的基础上对外提供服务了； 3.让k8s集群能够识别新的etcd集群： 如果前端是k8s集群，当确认新etcd集群工作正常后，可以重新配置运行apiserver，让k8s集群能够识别新的etcd集群； ~]# systemctl daemon-reload ~]# systemctl restart kube-apiserver &amp;&amp; systemctl restart kube-controller-manager &amp;&amp; systemctl restart kube-scheduler&quot; #重启k8s-master上的组件； 4.关闭其中一台etcd [root@etcd02 ~]# systemctl stop etcd #关闭etcd ~]# etcdctl --endpoints=&apos;https://etcd02.cre.io:2379&apos; --cert-file=/etc/etcd/pki/client.crt --key-file=/etc/etcd/pki/client.key --ca-file=/etc/etcd/pki/ca.crt member list 78f1359abb4e38df: name=etcd03.cre.io peerURLs=https://etcd03.cre.io:2380 clientURLs=https://etcd03.cre.io:2379 isLeader=false 82a31133d997d8c1: name=etcd02.cre.io peerURLs=https://etcd02.cre.io:2380 clientURLs=https://etcd02.cre.io:2379 isLeader=true d5b7e59a90e92a8f: name=etcd01.cre.io peerURLs=https://etcd01.cre.io:2380 clientURLs=https://etcd01.cre.io:2379 isLeader=false ~]# etcdctl --endpoints=&apos;https://etcd02.cre.io:2379&apos; --cert-file=/etc/etcd/pki/client.crt --key-file=/etc/etcd/pki/client.key --ca-file=/etc/etcd/pki/ca.crt cluster-health member 78f1359abb4e38df is healthy: got healthy result from https://etcd03.cre.io:2379 member 82a31133d997d8c1 is healthy: got healthy result from https://etcd02.cre.io:2379 failed to check the health of member d5b7e59a90e92a8f on https://etcd01.cre.io:2379: Get https://etcd01.cre.io:2379/health: dial tcp 192.168.0.102:2379: connect: connection refused member d5b7e59a90e92a8f is unreachable: [https://etcd01.cre.io:2379] are all unreachable cluster is degraded #cluster is degraded表示etcd集群被降级了，而且短时间内重新选举etcd02为leader;仍然可以对外提供服务； 5.主机迁移 有的时候，物理机需要下线维修，从而需要将数据拷贝到其他的机器上，从而在这里使用第三台机器来进行迁移； 在这里进行恢复的时候，必须按照步骤进行恢复，首先停止需要停止的机器的etcd进程，然后将数据拷贝到新机器的数据目录中: ~]# scp -r /etcd/ 192.168.34.117:/etcd/ #拷贝数据 ~]# systemctl start etcd #启动这台服务器的etcd ~]# etcdctl member list #先找出被替换掉的etcd的编号 ~]# etcdctl member update 此处写上面找到的etcd编号 ~]# etcdctl member list #update后，就会把被替换掉的etcd的IP改成新的etcd服务器的IP； 备注： 假设运行很久的etcd集群的binlog里有20万条操作记录，某一节点down且无法恢复，需要在集群中重新添加一台新的节点，这个时候master就需要把整个数据库复制到新加入的节点，master通过raft协议将整个binlog复制给slave节点，slave再将binlog在本地重放，这样做会非常耗时，因此一般的做法是： 对整个数据库定期打快照，先将快照复制到新节点上，然后剩下的数据再使用binlog方式由master-&gt;slave上复制； 6.扩容-etcd集群运行时重配置 出于安全考虑。etcd所有运行时的重配置都必须经过两个阶段：广播新的配置和启动新的集群： 1.通知集群新的配置 要向etcd集群增加一个member，需要调用一次用于向集群增加member的API，这是增加节点的必经之路，只有当集群同意该配置更新之后，该API才能正确返回； 2.启动新集群 --initial-cluster-state需要启用选项； 为了加etcd节点加入一个现有集群，需要指定正确的initial-cluster,并将initial-cluster-state设置成existing，待新节点启动后，首先它会连一次现有集群，并验证当前集群的配置是否与启动参数initial-cluster指定的匹配，在新节点成功启动后，集群就会实现期望的配置； 原理： --initial-cluster-state的含义是：初始化集群状态，它有两个值： 1.new，默认值 2.existing 意义： 当静态启动或当DNS服务发现所有member都存在时设置成new;设置成existing时，etcd会尝试加入一个已经存在的集群； ~]# 先做好证书并上传 ~]# etcdctl member add etcd04 https://etcd03.cre.io:2380&quot; ~]# etcdctl member list #此时就可以看到新的etcd了 7.缩容 当集群需要缩小规模的时候，主要直接移除节点，那么节点上etcd进程会被停止。 ~]# etcdctl member list #先查看需要移除的etcd节点的编号 ~]# etcdctl member remove etcd节点的编号 Etcd集群和常见问题1.时钟不同步 时钟不同的时候，出现错误如下： 2018-12-20 05:45:37.636506 W | rafthttp: the clock difference against peer 5d951def1d1ebd99 is too high [8h0m2.595609129s &gt; 1s] 2018-12-20 05:45:37.717527 W | rafthttp: the clock difference against peer f83aa3ff91a96c2f is too high [8h0m2.52274509s &gt; 1s] 将时间进行同步即可。 2.集群id不匹配 主要是因为数据目录没有删除，然后导致集群的id不匹配，删除数据目录，然后重新加入即可 3.删除的时候数据目录报错 2018-02-07 22:05:58.539721 I | raft: e0f5fe608dbc732d became follower at term 11 2018-02-07 22:05:58.539833 C | raft: tocommit(25) is out of range [lastIndex(0)]. Was the raft log corrupted, truncated, or lost? panic: tocommit(25) is out of range [lastIndex(0)]. Was the raft log corrupted, truncated, or lost? goroutine 59 [running]: github.com/coreos/pkg/capnslog.(*PackageLogger).Panicf(0xc4201730e0, 0x559ecf0e5ebc, 0x5d, 0xc420121400, 0x2, 0x2) /builddir/build/BUILD/etcd-1e1dbb23924672c6cd72c62ee0db2b45f778da71/Godeps/_workspace/src/github.com/coreos/pkg/capnslog/pkg_logger.go:75 +0x15e github.com/coreos/etcd/raft.(*raftLog).commitTo(0xc42021a380, 0x19) /builddir/build/BUILD/etcd-1e1dbb23924672c6cd72c62ee0db2b45f778da71/src/github.com/coreos/etcd/raft/log.go:191 +0x15e github.com/coreos/etcd/raft.(*raft).handleHeartbeat(0xc42022c1e0, 0x8, 0xe0f5fe608dbc732d, 0x5d951def1d1ebd99, 0xb, 0x0, 0x0, 0x0, 0x0, 0x0, ...) /builddir/build/BUILD/etcd-1e1dbb23924672c6cd72c62ee0db2b45f778da71/src/github.com/coreos/etcd/raft/raft.go:1100 +0x56 github.com/coreos/etcd/raft.stepFollower(0xc42022c1e0, 0x8, 0xe0f5fe608dbc732d, 0x5d951def1d1ebd99, 0xb, 0x0, 0x0, 0x0, 0x0, 0x0, ...) /builddir/build/BUILD/etcd-1e1dbb23924672c6cd72c62ee0db2b45f778da71/src/github.com/coreos/etcd/raft/raft.go:1046 +0x2b5 github.com/coreos/etcd/raft.(*raft).Step(0xc42022c1e0, 0x8, 0xe0f5fe608dbc732d, 0x5d951def1d1ebd99, 0xb, 0x0, 0x0, 0x0, 0x0, 0x0, ...) /builddir/build/BUILD/etcd-1e1dbb23924672c6cd72c62ee0db2b45f778da71/src/github.com/coreos/etcd/raft/raft.go:778 +0x10f9 github.com/coreos/etcd/raft.(*node).run(0xc420354000, 0xc42022c1e0) /builddir/build/BUILD/etcd-1e1dbb23924672c6cd72c62ee0db2b45f778da71/src/github.com/coreos/etcd/raft/node.go:323 +0x67d created by github.com/coreos/etcd/raft.RestartNode /builddir/build/BUILD/etcd-1e1dbb23924672c6cd72c62ee0db2b45f778da71/src/github.com/coreos/etcd/raft/node.go:223 +0x340 原因： 这种主要是需要将节点作为一个新的节点加入到集群中，直接启动的话由于找不到集群的文件和日志文件，从而报错]]></content>
      <categories>
        <category>分布式存储</category>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>分布式存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s-volumes]]></title>
    <url>%2F2018%2F08%2F10%2Fk8s-volumes%2F</url>
    <content type="text"><![CDATA[Kubernetes Volumes k8s上的volumes和docker中的volumes都是为了保存数据，但还是有区别的： 1.docker上因为是在单机上运行容器的，删除容器只要加载本地之前挂载的卷就可以了。 2.在k8s集群上，如果删除一个Pod,则这个pod的卷数据会保存在之前的这个node节点上了，而scheduler的调度是随机的， 有可能不会运行在之前的node上，那么之前保存的数据是无意义，不能利用的. 3.k8s是分布式集群，如果所有节点都挂载网络文件系统，那么数据就可以跨节点使用了. 数据冗余实现方式： 1.存储设备做镜像，主备模式 2.分布式存储 不会对存储节点设备做冗余，而是在软件数据管理级别上对每个数据对象做冗余； 根据调度规则和冗余级别在当前集群的多个节点上都存放一份数据 还支持向外扩展 如何挂载： 1.pod中是有个基础容器pause的,同一个pod中是共享pause容器的UTS(主机名),Network(网络名称空间),IPC(进程间通信，网络协议栈). 2.因为在节点上的pod是共享节点内核的，驱动也是在内核，所以节点本身需要先识别适配外部的各种存储系统. 3.节点是可以挂载多种外部存储系统的，所以pause挂载存储时，需要指明挂载的是哪种文件系统类型的存储并有相应的存储插件驱动. 4.同一Pod中的其他容器要想使用pause中的volumes,需要先通过volumes定义pause中定义卷，pod再通过volumeMounts复制并挂载pause定义的卷. CSI: Container Storage interface，通过容器存储接口自定义存储卷 k8s中内置的存储卷类型 kubectl explain pod.spec.volumes 定义存储卷 详见：kubectl explain pod.spec.volumes #如何定义挂载卷 要用存储卷需要现在pod.spec字段定义挂载卷类型和目录等信息 挂载存储： 详见： kubectl explain pod.spec.containers.volumeMounts #定义如何挂载卷 是使用挂载卷，需要在pod.spec.containers中挂载上去才能用 spec中的详细定义说明： spec: volumes: #先定义pause中的挂载卷 - name #必须定义存储卷名称,以便挂载时引用 下面根据存储类型不同定义方式也不同，按需修改 hostPath/nfs #必须指定存储类型 - path #定义宿主机或者网络存储的路径 type #指定的目录/文件不存在时，应该怎么创建 DirectoryOrCreate #不存在则创建 Directory #目录必须事先存在 File #文件可以挂载，但是必须事先存在 FileOrCreate #文件不存在则自动创建 Socket #必须是套接字文件，必须事先存在 CharDevice #字符设备文件，必须事先存在 BlockDevice #块设备文件，必须事先存在 containers: - name: image: volumeMounts: #复制并挂载pause中定义的卷 - name: #引用volumes中定义的1个或多个卷的卷名 mountPath #挂载在容器的哪个路径(应用程序的文件路径) readOnly：true|false #挂载的路径是否只读，默认是读写权限 mountPropagation # 本地存储：hostPath和local示例1：hostPath类型 #节点级的目录 vim myapp-hostpath-volumes.yaml apiVersion: v1 kind: Pod metadata: name: myapp namespace: volumes-test spec: containers: - name: myapp image: ikubernetes/myapp:v1 volumeMounts: - name: website mountPath: /usr/share/nginx/html readOnly: true volumes: - name: website hostPath: path: /volumes/myapp type: DirectoryOrCreate 示例2：local类型 k8s1.10版本之后的类型，且是节点级的设备或者节点级目录 临时存储：emptyDir临时存储作用： 1.为容器提供缓存存储空间 1.支持在节点的内存中切分一部分空间作为缓存来用 2.为没有持久存储必要的同一Pod中的两个容器共享数据 3.临时存储随着Pod的删除自动删除 用法： kubectl explain pod.spec.volumes.emptyDir medium #默认是disk磁盘，还可以是Memory内存 sizeLimit #当medium是memory时，则必须进行限制 简单示例： volumes: - name: ceshi # emptyDir: {} #如果medium和sizelimit都不定义，则为磁盘的任意空间 emptyDir: medium: Memeory #使用内存当空间 sizeLimit: 200Mi #使用内存空间为200M 网络存储：NFS用法： kubectl explain pods.spec.volumes.nfs path： #nfs的共享目录：如/vols/v1 readOnly：true|false #是否只读，默认读写 server: #nfs服务IP或者主机名 缺点： 1.需要事先知道nfs服务器的地址 2.nfs导出的存储空间目录 示例： 先准备nfs的共享目录:在10.10.0.29上测试 vim /etc/exports /vols/v1 10.10.0.0/8(rw,no_root_squash) [root@master01 manifsets]# vim redis-nfs-volumes.yaml apiVersion: v1 kind: Pod metadata: name: redis namespace: volumes-test spec: nodeName: node03 containers: - name: redis image: redis:alpine ports: - name: redis containerPort: 6379 volumeMounts: - name: redisdata mountPath: /data readOnly: false volumes: - name: redisdata nfs: path: /vols/v1 #nfs导出的共享目录 server: 10.10.0.29 #nfs服务器的地址 持久卷申请存储：PV&amp;PVC为了使用存储方便，为volumeMounts和后端存储设备加加了两个中间层 在spec.volumes和存储间加了一个persistentVolume中间层 把存储系统的所提供的存储能力抽象成k8s上的标准资源：persistentVolume持久存储卷 persistentVolume： 1.PV和存储系统之间不是一一对应关系，而是与对应后端存储系统上可被单独访问的逻辑单元； 2.一个PV对应nfs的一个导出目录、ceph的一个image、云存储的一个云盘; 3.把后端存储的一个个逻辑单元映射为k8s上的一个个PV; 4.PV是集群级别的资源，不属于任何名称空间; PV的lifecycle: provisioning: #PV的动态供给 bingding #PV被绑定 using #PV被使用 reclaiming #PV被回收 PV的供给方式： 动态供给： 1.存储系统上需要事先有逻辑存储单元，根据PVC的空间需求，在底层存储上选择适合空间需求的存储单元动态得创建为PV. 2.底层存储的逻辑单元不存在，只有存储空间 1.PVC向SC请求调用存储系统的API存储接口，临时创建需求空间大小的逻辑存储单元. 2.然后在SC内部把此存储单元创建为PV，与PVC进行binding. 3.动态供给是创建SC，而不是PV 静态供给： 存储系统上事先有存储，手动创建PV，再手动创建PVC与之绑定. PV的回收策略：reclaim Pod删除时，PVC也可以删除，则引用的PV就处于回收状态，PV删除有二种策略 Delete: #PVC删除时连带PV一起删除 Retain #PV和PV上的数据都保留 备注： 1.如果是retain的，PV上仍然会有数据，但是不能被其他PVC所绑定了 2.可以手动删除PV，并手动删除存储上逻辑单元下的数据 persistentVolumeClaim 1.PV属于集群级别资源，Pod属于名称空间级别资源，如果pod想使用PV就需要把PV注册到名称空间中; 2.Pod是通过PVC请求占用PV，来使用PV的，一旦名称空间A占用PV1，其他名称空间就不能再用PV1了; 3.PVC占用PV称为binding;为被PVC占用的PV称为avaiable(可用的PV); 4.Pod通过volumes.persistentVolumeClaim使用PVC，进而间接使用PVC所占用的PV的. 5.PVC是属于某个名称空间，可以由管理员手动创建的. PVC和存储系统的多路访问模型： 1.单路读写： RW0:ReadWriteOnce iscsi 2.多路读写: RWX:ReadWriteMany 3.多路只读: ROX:ReadOnlyMany 作用： PV是与后端存储的逻辑单元做映射的，存储系统是否支持多路读写应该体现在PV的定义上，才能避免PVC关联PV是否能多路读写出现存储故障. PV和PVC的删除保护： 当PVC和PV被Pod使用时，在k8s的1.10版本之后，即使PVC和PV被删除，此时也不会真的被删除，只有Pod被删除时， PVC和PV才会被允许删除，这就是PVC和PV的删除保护. 定义PV： pv.spec和pod.spec.volumes是一样的，这样在创建pod时就不要再定义volumes了直接在containers.volumeMounts进行复制挂载就行了. kubectl explain persistentVolume.spec spec: accessModes #定义存储系统的访问模型的字符串列表 RW0/RWZ/ROX capacity: #定义存储容量 storage #单位是Ki Mi Gi等等 volumeMode: #存储设备的访问接口(文件系统接口和块设备接口) Fileystem|block persistentVolumeReclaimPolicy #定义PV的回收策略 Delete|Retain storageClassName: #定义使用哪种存储类 mountOptions: #自定义挂载选项,下面这两项是默认的 - hard - nfsvers=4.1 nfs/ceph: #定义PV关联的存储类型 下面选项根据不同存储系统定义不同的属性值 server: path: 定义PVC： kubectl explain pvc.spec accessModes #访问权限必须要要绑定的PV权限的子集 volumeMode #存储设备的访问接口(文件系统接口和块设备接口) resources #资源请求 requests: #资源需求 storage: #具体的需求存储空间大小 limit #资源上限 storageClassName #存储类(PVC和PV必须在同一存储类中) selector #通过标签选择器去选PV 不定义选择器，则从所有PV中选择合适的PV volumeName # dataSource # 存储类SC：StorageClass SC:Storageclass是k8s上的标准资源 SC是实现PVC动态创建存储单元PV的基础 1.SC上定义了如何连接外部存储API管理接口的方式 2.PVC只能向同一个SC中的PV请求绑定，不能跨SC. 定义SC： 详见：kubectl explain sc apiVersion kind metadata parameters #对接外部存储时的参数 reclaimPolicy #在此SC中的PV回收策略 provisioner #指明后端存储设备-----必须项 volumeBindingMode #后端存储支持的访问模型(RWX,ROX,RWO) allowVolumeExpansion #后端存储系统是否支持空间拉伸 官方示例： glusterfs类型的SC apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: slow provisioner: kubernetes.io/glusterfs parameters: resturl: &quot;http://127.0.0.1:8081&quot; clusterid: &quot;630372ccdc720a92c681fb928f27b53f&quot; restauthenabled: &quot;true&quot; restuser: &quot;admin&quot; secretNamespace: &quot;default&quot; secretName: &quot;heketi-secret&quot; gidMin: &quot;40000&quot; gidMax: &quot;50000&quot; volumetype: &quot;replicate:3&quot; ceph-rbd类型的SC: kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: fast provisioner: kubernetes.io/rbd parameters: monitors: 10.16.153.105:6789 adminId: kube adminSecretName: ceph-secret adminSecretNamespace: kube-system pool: kube userId: kube userSecretName: ceph-secret-user userSecretNamespace: default fsType: ext4 imageFormat: &quot;2&quot; imageFeatures: &quot;layering&quot; 示例-创建静态供给PV和PVC以nfs为例定义一个PV： [root@master01 manifsets]# vim pv-test.yaml apiVersion: v1 kind: PersistentVolume metadata: name: pv-nfs-v1 labels: storagefs: nfs spec: # accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;] accessModes: - ReadWriteMany - ReadWriteOnce - ReadOnlyMany capacity: storage: 1Gi #定义PV能提供多大存储空间 volumeMode: Filesystem persistentVolumeReclaimPolicy: Retain #定义PV回收策略 nfs: path: /vols/v2 server: 10.10.0.29 创建PVC： apiVersion: v1 kind: PersistentVolumeClaim metadata: name: redis-pvc #定义PVC的名称，以便Pod中引用 namespace: volumes-test spec: selector: #定义关联到哪个PV，不指定则根据需求空间找相近空间大小的PV matchLabels: storagefs: nfs2 accessModes: - ReadWriteMany volumeMode: Filesystem resources: requests: storage: 500Mi #根据PV的存储空间定义PVC有多少空间 创建Pod挂载PVC apiVersion: v1 kind: Pod metadata: name: redis namespace: volumes-test spec: nodeName: node03 containers: - name: redis image: redis:alpine ports: - name: redis containerPort: 6379 volumeMounts: #容器复制挂载volumes - name: redisdata mountPath: /data readOnly: false volumes: - name: redisdata persistentVolumeClaim: claimName: redis-pvc #挂载PVC 测试： [root@master01 ~]# kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pv-nfs-v1 1Gi RWO,ROX,RWX Retain Available 8m14s pv-nfs-v2 2Gi RWO,ROX,RWX Retain Released volumes-test/redis-pvc-1 8m14s pv-nfs-v3 3Gi RWO,ROX,RWX Retain Bound volumes-test/redis-pvc 8m14s [root@master01 ~]# kubectl get pvc -n volumes-test NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE redis-pvc Bound pv-nfs-v3 3Gi RWO,ROX,RWX 5m55s 特殊存储：ConfigMap和Secret都是为pod中的容器提供配置变更，扮演了k8s系统上一组控制器控制的pod的配置中心 docker中的应用程序根据不同的环境配置不同的配置文件是依靠两种方式： 1.应用程序镜像是云原生或者支持通过enterpoint脚本可以传递环境变量来适应不同的场景使用. 缺点是：要修改传的值需要删除容器重新创建 2.先配置好不同的配置文件，通过挂载卷将文件传递到容器中. 缺点是：在本地映射的路径下修改了配置文件，容器是不会自动加载新的配置文件的. k8s上面临相同的问题，为了解决修改配置文件或参数值能够使Pod自动重载配置信息，就将配置文件做成了k8s上的configMap资源. ConfigMap和Secret 1.Pod中的容器提供配置信息 2.配置中心：配置发生变更，测试完成后，通知方式(灰度) 区别： configMap用来保存非敏感数据，Secret用来保存敏感数据的 configMap和Secret是如何将配置传递至Pod中的？ 先定义configMap和secret类型的资源，而这种资源时K/V键值对存在的 1.如果是环境变量，则定义这两种资源时，指定key和value 2.如果是配置文件，则文件名为Key,文件内容为值value 创建pod时，只需要引用此资源的Key即可： 1.把configmap和secret资源的key映射给pod容器中的环境变量或者文件名 2.给环境变量传key的名称，通过k/v替换，获得v的值，如果想变更配置，只需要修改pod外部configmap中的value的值即可 ，pod会在一段时间内自动传递新的value值，进行配置更新. ConfigMap注意： 1.命令行创建configmap比资源清单更简单，但是配置清单更易维护. 2.通过资源清单配置的configMap中嵌套的是K/V数值还比较简单如果嵌套的是文件内容 的话，配置格式还是有些麻烦的. 创建ConfigMap的两种方式 1.基于命令行的 kubectl create configmap -h --from-literal #手动指定K/V值，定义多个K/V值需要有多个--from-literal --from-file #从文件中读取创建 2.配置清单(比命令行麻烦，但是更易维护) kubectl explain configmap data: #只有data字段，而没有spec字段 两种引用configMap的方式: pod和configMap必须在同一名称空间 1.基于环境变量方式引用configMap (用于传递环境变量) [root@master01 ~]#pod.spec.containers.env env #直接手动给变量 - name #镜像中所能接收的变量名 value #手动给值(一般用valuefrom) valuefrom #从其他位置引用值 configMapKeyRef #引用一个configMap的键key name #configMap的名称 key #configMap中的一个键名 optional #被引用的configMap资源存在就可以，不存在则报错 true|false #默认是必须存在 secretKeyRef #引用一个Secret的键key,用于敏感数据传输 envfrom #从其他地方加载环境变量 缺点： 1.如果修改configmap中的环境变量的值，pod是不会更新环境变量的，除非删除重建pod，新的环境变量才会生效. 2.基于存储卷方式引用configMap (用于传递文件) 是把configmap资源当成存储卷来用的 kubectl explain pods.spec.volumes.configMap volumes: - name #定义存储卷名称以便挂载时使用 configMap: name #configMap资源的名称 items #要引用configmap中的那些键映射为本地的文件 - key #configmap中的键名 mode #映射的文件权限时多少，没定义则使用外部的defaultMode path #映射到pod中叫什么文件名(可以和key一样，也可以随意更改) 必须是相对路径，而且是相对于挂载点而言 defaultMode #映射到本地的文件权限为多少 默认是0644读写权限，可以自己指定 optional #引用的configMap资源或者引用的键不存在是否报错 注意： 1.相对于环境变量方式引用configmap，存储卷方式的pod会根据configmap内容的变化而更新自己pod中的配置信息. 2.如果一个deploy控制的多个pod，并定义挂载了configMap类型的存储，如果修改configMap文件中的内容，这些pod一般会在一分钟之内都更新到最新configmap中新的值. 3.在deploy控制的后端pod众多的情况下，需要借助互联网上的配置中心组件实现pod的滚动更新或者金丝雀更新. 4.后端pod较少的情况下，可以用ansible或者puppet进行灰度更新. 创建并引用ConfigMap示例1.基于命令行的--from-literal创建 kubectl create configmap filebeat-cfg -n config-ns --from-literal=redis_host=&quot;filebeat.defalut.svc.cluster.local&quot; --from-literal=log_level=&quot;Info&quot; 创建名为filebeat-cfg的cm,并设定两个key和他的值 2.基于命令行的--from-file创建 kubectl create cm nginx-cfg --from-file=nginx-./server1.conf --from-file=server-zhihui.conf=./nginx-server2.conf -n config-ns 引用示例： 1.基于环境变量引用configMap 此处手动创建一个Pod，用来演示使用env属性值引用configMap：filebeat-cfg apiVersion: v1 kind: Pod metadata: name: filebeat namespace: config-ns #pod和configMap必须在同一名称空间 spec: containers: - name: filebeat image: ikubernetes/filebeat:5.6.5-alpine env: - name: REDIS_HOST valueFrom: configMapKeyRef: name: filebeat-cfg key: redis_host - name: LOG_LEVEL valueFrom: configMapKeyRef: name: filebeat-cfg key: log_level 2.基于存储卷方式引用configMap 此处手动创建一个Pod，用来演示挂载configMap类型的存储 apiVersion: v1 kind: Pod metadata: name: nginx namespace: config-ns #pod和configMap必须在同一名称空间 spec: containers: - name: nginx image: ikubernetes/myapp:v1 volumeMounts: - name: config mountPath: /etc/nginx/conf.d #挂载的目录 volumes: - name: config configMap: name: nginx-cfg items: - key: nginx-server1.conf #本地文件名 path: server1.conf #映射到pod中的文件名 - key: server-zhihui.conf #本地文件名 path: server2.conf #映射到pod中的文件名 测试： 通过手动修改configmap的值，查看pod中的文件是否也会发生改变 kubectl edit cm/nginx-cfg -n config-ns 测试看出基于存储卷方式引用configMap的pod的文件内容也会自动更新. Secret1.Secret和configMap在功能上是一样的，只不过Secret是保存敏感数据的. 2.Secret的数据是通过base64编码处理过的，不是真正意义上的加密，可以通过base64进行解码. 3.Secret资源一般是通过命令行创建，而不是配置清单，因为如果通过配置清单配置时，需要 手动将敏感数据(密码)进行base64编码，是很麻烦的，而命令行创建，会自动把敏感数据进行 base64编码后保存到secret中. Secret的三种类型： 详见：kubectl create secret -h 1.docker-registry 私有镜像仓库需要登录才能够访问，docker-registry就是将账号密码进行加密认证，以便kubelet可以认证到镜像仓库服务器上. 认证方式有两种： 1.kubectl explain pod.spec.imagePullSecrets name:可以定义多个列表用于认证 缺点：如果想使用不同的账户时，是不易修改Secret的 2.kubectl explain pod.spec.serviceAccountName 服务账号：可以使用pod之外的系统认证方式 即使修改账号只需要修改serviceAccountName就可以了. 2.generic 非证书的私有敏感信息都用generic类型,通用型 3.tls #tls是专用于把ssl的tls中的x509格式的证书和私钥打包到一个secret中 而且不管原来的*.key和*.crt都被转成名为tls.key和tls.crt 创建secret-generic资源: 1.命令行创建，类似于configmap kubectl create secret [secret类型] secret名称 --from-literal= --from-file=[key=]source 2.资源清单创建，要注意将密码进行base64编码后填到data资源中的key:value中 kubectl explain secret 创建secret-tls资源: 1.命令行创建： kubectl create secret tls NAME --cert=path/to/cert/file --key=path/to/key/file -n namespace #需要先创建证书和私钥，再在创建secret-tls时引用即可. 创建docker-registry资源: 1.命令行创建： kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL # 创建docker-registry类型的资源时，要指定连接的私有docker仓库的IP/域名，用户名，密码，注册时使用的账号 引用secret的方式 1.通过env环境变量引用 kubectl explain pod.spec.containers.env env: - name #Pod镜像中的存在的变量名 valueFrom: secretKeyRef: #表示从secret类型资源引用键 name: #引用的Secret资源的名称 key #secret资源中的键名 optional: #secret资源或者引用的key不存在时报错 true|false 2.通过存储卷引用Secret资源 kubectl explain pod.spec.volumes.secret volumes: - name: #定义存储卷名称以便挂载时使用 secret: secretName #引用的secret资源名称 items: #引用的多个键对象 - key #引用的secret资源中的键名 mode: #文件权限，私密数据建议600权限，不指定则使用外部默认的 path: #映射到pod中叫什么文件名(可以和key一样，也可以随意更改) defaultMode #引用资源的默认权限，0644 optional 注意： 1.tls类型的证书和私钥一般要用存储卷方式进行引用，不然value的值太长的. 示例： 1.generic类型的secret引用示例 apiVersion: v1 kind: Pod metadata: name: mysql namespace: config-ns spec: containers: - name: mysql image: mysql:5.6 env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql-root-password key: passwd optional: true 2.tls类型secret引用示例 apiVersion: v1 kind: Pod metadata: name: nginx namespace: config-ns spec: containers: - name: nginx image: nginx:1.14-alpine volumeMounts: - name: tls mountPath: /etc/nginx/ssl volumes: - name: tls secret: - secretName: nginx-tls items: - key: nginx.crt #原来的证书名 path: nginx-server.crt #映射到pod中的证书名 - key: nginx.key #原来的私钥名 path: nginx-server.key #映射到pod中的私钥名 mode: 0600]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-cluster集群]]></title>
    <url>%2F2018%2F07%2F20%2Fredis-cluster%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[Redis cluster 1.redis主从架构的缺点： 1.当master出现redis服务异常、主机断电、磁盘损坏等问题导致master无法使用，而redis高可用无法实现自故障 转移(将slave提升为master)，需要手动执行slave noone将slave切换成master,而且时间很长; 2.不管是主从模式还是sentinel机制都只是保证了数据跨主机备份的安全性，并没有提升Redis服务的并行写入性能； 3.所以当单台Redis服务器性能无法满足业务写入需求的时候就必须需要一种方式解决以上的两个核心问题. 1.master和slave角色的无缝切换，让业务无感知从而不影响业务使用; 2.可以横向动态扩展Redis服务器，从而实现多台服务器并行写入以实现更高并发的目的; 2.Redis cluster集群实现方式：客户端分片、代理分片、Redis Cluster，但是各有区别； 1.客户端分区： 由客户端程序决定key写分配和写入的redis node，但是需要客户端自己处理写入 分配、高可用管理和故障转移等； 2.代理方案： 基于三方软件实现redis proxy，客户端先连接之代理层，由代理层实现key的写入分配，对客户端来说是有 比较简单，但是对于集群管节点增减相对比较麻烦，而且代理本身也是单点和性能瓶颈； 3.redis cluster Redis cluster主从实现原理为了解决单机的redis写入性能受限于单机的内存大小、并发数量、网卡速率等因素，因此redis官方在redis 3.0版本之后推出了无中心架构的redis cluster机制，在无中心的redis集群汇中，其每个节点保存当前节点数据和 整个集群状态,每个节点都和其他所有节点连接，特点如下： 1：所有Redis节点使用(PING-PING机制)互联 2：集群中某个节点的实效是整个集群中超过半数的节点监测都实效才算真正的实效 3：客户端不需要proxy即可直接连接redis，且客户端不需要连接集群中的所有节点，只要连接集群中的任何一个节点即可。 4：redis cluster把所有的redisnode映射到 0-16383个槽位(slot)上，读写需要到指定的redis node上 进行操作，因此有多少个reids node相当于redis 并发扩展了多少倍。 5：Redis集群预先分配16384个(slot)槽位，当需要在redis集群中写入一个key -value的时候， 会使用CRC16(key) mod 16384之后的值，决定将key写入值哪一个槽位从而决定写入哪一个Redis节点上， 从而有效解决单机瓶颈。 1.假设三个主节点分别是：A, B, C 三个节点，采用哈希槽 (hash slot)的方式来分配16384个slot的话，它们三个节点分别承担的slot 区间是： 节点A覆盖0－5460 节点B覆盖5461－10922 节点C覆盖10923－16383 2.Redis cluster的架构虽然解决了并发的问题，但是又引入了一个新的问题，因为每个 Redis master上数据都是不一样的，所以为了保证数据的安全，每个master都需要一个slave来实现数据的高可用. Redis cluster主从架构部署 1.环境准备： 1.每个redis node节点采用相同的硬件配置、相同的密码 2.每个节点必须开启参数 cluster-enabled yes #必须开启集群状态，开启后redis 进程会有cluster显示 cluster-config-file nodes-6380.conf #此文件有redis cluster集群自动创建和维护，不需要任何手动操作 2.为了实验方便，slave都是在master上以6380端口启动，使用不同的Unitfile和配置文件 只列出 redis node master A的操作，其他两台master一样即可 准备配置文件： [root@node02 ~]# vim /usr/local/redis/etc/redis.conf cluster-enabled yes cluster-config-file nodes-6379.conf #启用创建cluster集群的两项 [root@node02 ~]# cp /usr/local/redis/etc/redis /usr/local/redis/etc/redis-6380.conf [root@node02 ~]# vim /usr/local/redis/etc/redis-6380.conf ：%s/6379/6380/g #将6379端口全部替换成6380端口(此端口作为slave的端口) 准备启动服务： [root@node02 ~]# cd /usr/lib/systemd/system/ [root@node02 ~]# cp redis.service redis-6380.service [root@node02 ~]# vim redis-6380.service #修改slave的Unitfile中加载的配置文件redis-6380.conf [root@node02 ~]# systemctl start redis redis-6380 #将一台服务器上的master和slave都启动 #其他两台Redis Node Master{B,C}一样配置即可； –每一台redis上应该有一主一从 3.创建集群 redis-cli --cluster help #客户端命令可以创建管理集群 [root@node01 ~]# redis-cli -a root --cluster create 192.168.34.121:6379 192.168.34.121:6380 192.168.34.124:6379 192.168.34.124:6380 192.168.34.123:6379 192.168.34.123:6380 --cluster-replicas 1 – 4.检查集群状态 #Cluster info可以查看当前集群的状态，集群规模和是否有master节点出现故障以及槽位分配是否是完整且连续的. [root@node01 ~]# redis-cli -h 192.168.34.121 -p 6379 -a root 192.168.34.121:6379&gt; CLUSTER INFO cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 cluster_size:3 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:1474 cluster_stats_messages_pong_sent:1507 cluster_stats_messages_sent:2981 cluster_stats_messages_ping_received:1502 cluster_stats_messages_pong_received:1474 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:2981 5.查看集群node对应关系 #通过cluster nodes可以看到集群中的主从对应关系 [root@node01 ~]# redis-cli -h 192.168.34.121 -p 6380 -a root 192.168.34.121:6380&gt; cluster nodes 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545659135000 4 connected 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 myself,slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545659135000 6 conne ctedf4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545659135000 1 connected 0-5460 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545659136000 3 connected 5461-10922 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545659134000 5 connected 10923-16383 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545659135946 5 connected –cluster nodes 6.查看集群槽位和主从的具体关系 使用redis-cli -a root --cluster check 192.168.34.101:6379 随机一个master的IP和端口可以看到对应关系 –查看集群对应关系![查看集群对应关系]redis-cluster集群/(查看集群对应关系.png) 7.验证集群写入key 192.168.7.101:6379&gt; SET k1 v1 #经过算法计算，当前key的槽位需要写入指定的node (error) MOVED 9189 192.168.7.103:6379 #因为槽位不在当前node所以无法写入 192.168.7.102:6379&gt; SET k1 v1 (error) MOVED 9189 192.168.7.102:6379 192.168.7.103:6379&gt; SET k1 v1 #指定的node就可以写入 OK 192.168.7.103:6379&gt; KEYS * 1) &quot;k1&quot; 192.168.7.101:6379&gt; KEYS * (empty list or set) 192.168.7.102:6379&gt; KEYS * (empty list or set) 8.故障动态转移测试； 上一步已经将数据写入到192.168.7.103:6379的master上了现在关闭192.168.7.103上的master 6379的redis进程，测试192.168.7.103:6379的slave192.168.7.103:6380 是否能成为master，数据是否能查到. –103的slave–103的slave会切换成master 9.集群状态监控 # redis-cli -a 123456 --cluster check 192.168.7.101:6379 –集群状态监控 Redis cluster集群管理维护集群运行时间长久之后，难免由于硬件故障、网络规划、业务增长等原因对已有集群进行相应的调整， 比如增加Redis node节点、减少节点、节点迁移、更换服务器等。增加节点和删除节点会涉及到已有的槽位重新分配及数据迁移。 1.集群维护之动态添加节点1.增加Redis node节点，需要与之前的Redis node版本相同、配置一致，然后分别启动两台Redis node，因为一主一从;2.现有的三主三从redis cluster架构可能无法满足现有业务的并发写入需求，新增一台服务器192.168.34.122，需要将其动态添加到集群当中其不能影响业务使用和数据丢失，则添加过程如下: 1.同步配置文件 同步之前Redis node的配置文件到192.168.7.104 Redis编译安装目录， 注意配置文件的监听IP，这是在一台服务器上模拟一主一从redis； # scp redis.conf 192.168.34.104:/usr/local/redis/etc/ # scp redis_6380.conf 192.168.34.104:/usr/local/redis/etc/ 分别启动redis服务： # systemctl daemon-reload # systemctl restart redis # /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis_6380.conf 2.新增新节点到集群(先新增一台master节点) 使用命令：redis-cli -a 123456 --cluster add-node 192.168.34.104:6379 192.168.7.101:6379 #注意： 前面是新增加的的redis节点IP和端口后面是已经存在的集群中的master IP:端口(可以是任意一个master的IP和端口) 注意： 增加到集群很快，但是新加的节点是没有数据的，需要对集群进行槽位重新分片，数据重新划分； –添加新节点到集群 3.分配槽位 添加主机之后需要对添加至集群种的新主机重新分片否则其没有分片；将现有的三主三从上的数据重新分配到四主四从上； 重新分片机制： 将集群中的每个master抽出一部分给新增的节点使用； 命令： [root@redis ~]# redis-cli -a 123456 --cluster reshard 192.168.7.104:6379 –重新分配槽位 4.查看当前集群状态 查看重新划分之后集群是否是正常的. 此时因为只加入了一个master,没有把新的slave节点加进来，所以会有一个master没有slave –重新分配完成 5.将新的slave也加入集群 [root@node01 ~]# redis-cli -a 123456 --cluster add-node 192.168.34.104:6380 192.168.7.101:6379 #新的节点加入集群默认都是master节点，需要把它变成一个192.168.34.104:6379的slave 6.为新增的master192.168.34.104:6379添加slave192.168.34.104:6380节点 将新加slave192.168.34.104:6380，作为master192.168.34.104:6379的slave, 登录到192.168.34.104:6380上通过CLUSTER REPLICATE ID更改新节点状态为slave 1.需要先登录到要成为slave的节点上； 2.取出要成为master的ID(cluster nodes命令查看) –添加slave 7.验证当前集群状态 –当前集群状态 2.集群维护之动态删除节点添加节点的时候是先添加node节点到集群，然后分配槽位，删除节点的操作与添加节点的操作正好相反，是先将被删除的Redis node上的槽位迁移到集群中的其他Redis node节点上，然后再将其删除。 1.迁移master192.168.7.102:6379的槽位之其他master [root@redis-s1 ~]# redis-cli -a root --cluster reshard 192.168.7.102:6379 #指定要删除的master节点的IP+端口 –迁移节点 2.验证槽位迁移完成 –验证槽位迁移完成 3.从集群删除服务器 虽然槽位已经迁移完成，但是服务器IP信息还在集群当中，因此还需要将IP信息从集群删除 命令格式:redis-cli -a root --cluster del-node IP:Port ID 删除master： [root@redis1~]# redis-cli -a root --cluster del-node 192.168.7.101:6379 f4cfc5cf821c0d855016488d6fbfb62c03a14fda Warning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe. &gt;&gt;&gt; Removing node f4cfc5cf821c0d855016488d6fbfb62c03a14fda from cluster 192.168.7.101:6379 &gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster... &gt;&gt;&gt; SHUTDOWN the node. 删除slave： 该节点上如果还有其他节点上master 的slave，但是由于服务器下架也要一并删除，因此要提前把保证每个master至少有一个slave [root@redis-s1 ~]# redis-cli -a root --cluster del-node 192.168.7.101:6380 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 Warning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe. &gt;&gt;&gt; Removing node 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 from cluster 192.168.7.101:6380 &gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster... &gt;&gt;&gt; SHUTDOWN the node. 4.验证node是否删除 发现192.168.7.101已经被删除，但是由于192.168.7.101:6380之前是192.168.7.103:6379的slave，所以删除 后会导致相应的master缺少slave，需要重新为没有slave的master分配slave。 可以发现下图的192.168.7.104有两个slave，分别是192.168.7.102:6380和192.168.7.104:6380，因此需要将 其中一个slave转移为192.168.7.103的slave。 –验证node是否删除 5.重新分配slave 将192.168.7.104:6380 转移为192.168.7.103的slave –重新分配slave 6.重新验证集群Master与Slave对应关系 Redis Slave节点一定不能和master在一个服务器，必须为跨主机交叉备份模式，避免主机故障后主备全部挂掉，如果出现Redis Slave与Redis master在同一台Redis node的情况，则需要安装以上步骤重新进行slave分配，直到不相互交叉备份为止。 –master和slave对应关系 3.集群维护之导入现有Redis数据将redis cluster部署完成之后，需要将之前的数据导入到Redis cluster集群，但是由于Redis cluster使用的分片保存key的机制，因此使用传统的AOF文件或RDB快照无法满足需求，因此需要使用集群数据导入命令完成。 注意： 导入数据需要redis cluster不能与被导入的数据有重复的key名称，否则导入不成功或中断。 1.环境准备： 1.导入数据之前需要关闭各redis 服务器的密码，包括集群中的各node和源Redis server，避免认证带来的 环境不一致从而无法导入，但是可以加参数--cluster-replace 强制替换Redis cluster已有的key 2.执行数据导入 将源Redis server的数据直接导入之redis cluster。 命令格式：#redis-cli --cluster import 集群服务器IP:PORT --cluster-from 外部Redis node-IP:PORT --cluster-copy --cluster-replace –数据导入]]></content>
      <categories>
        <category>Nosql</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis高可用]]></title>
    <url>%2F2018%2F07%2F15%2Fredis%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Redis高可用 虽然Redis可以实现单机的数据持久化，但无论是RDB也好或者AOF也好，都解决不了单点宕机问题，即一旦redis服务器本身出现系统故障、硬件故障等问题后，就会直接造成数据的丢失，因此需要使用高可用和集群技术来解决单点问题. Redis主从实现主从复制过程 Redis支持主从复制分为全量同步和增量同步，首次同步是全量同步，主从同步可以让从服务器从主服务器备份数据，而且从 服务器还可与有从服务器，即另外一台redis服务器可以从一台从服务器进行数据同步，redis 的主从同步是非阻塞的， 其收到从服务器的sync(2.8版本之前是PSYNC)命令会fork一个子进程在后台执行bgsave命令，并将新写入的数据写入到 一个缓冲区里面，bgsave执行完成之后并生成的将RDB文件发送给客户端，客户端将收到后的RDB文件载入自己的内存， 然后主redis将缓冲区的内容在全部发送给从redis，之后的同步从服务器会发送一个offset的位置(等同于MySQL的binlog 的位置)给主服务器，主服务器检查后位置没有错误将此位置之后的数据包括写在缓冲区的积压数据发送给redis从服务 器，从服务器将主服务器发送的挤压数据写入内存，这样一次完整的数据同步，再之后再同步的时候从服务器只要发送 当前的offset位 置给主服务器，然后主服务器根据响应的位置将之后的数据发送给从服务器保存到其内存即可。 Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 1）从服务器连接主服务器，发送SYNC命令； 2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB快照文件并使用缓冲区记录此后执行的所有写命令； 3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 7）后期同步会先发送自己slave_repl_offset位置，只同步新增加的数据，不再全量同步。 总结： redis的主从复制比mysql的主从要简单的多了 当从节点接入主节点，由主节点直接做一快照RDB，并通过网络直接传给从节点，所以主节点边做快照边传输，从节点边 接收边恢复到本地内存中，等传输完成，从节点就拿到了完整了数据； 随后主节点每记录一个写操作语句，会同时把这个写操作发送给从节点一份，从节点接收后直接在本地重放(也不基于 二进制文件或者aof文件进行主从复制)而是把所有的写操作通过网络传输发送给每一个从节点； 一旦从节点长时间没接入主节点造成数据差异过大，从节点会放弃本地所有数据，然后从主节点进行完整数据复制，这个主从复制过程完全不需要管理员介入 主从配置参数及优化：Redis在2.8版本之前没有提供增量部分复制的功能，当网络闪断或者slave Redis重启之后会导致主从之间的全量同步，即从2.8版本开始增加了部分复制的功能。 repl-diskless-sync no #yes为支持disk，master将RDB文件先保存到磁盘在发送给slave，no为maste直接将RDB文件发送给slave，默认即为使用no，Master RDB文件不需要与磁盘交互。 repl-diskless-sync-delay 5 #Master准备好RDB文件后等等待传输时间 repl-ping-slave-period 10 #slave端向server端发送pings的时间区间设置，默认为10秒 repl-timeout 60 #设置超时时间 repl-disable-tcp-nodelay no #是否启用TCP_NODELAY，如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms），造成master与slave数据不一致，假如设置成no，则redis master会立即发送同步数据，没有延迟，前者关注性能，后者关注一致性 repl-backlog-size 1mb #master的写入数据缓冲区，用于记录自上一次同步后到下一次同步过程中间的写入命令，计算公式：b repl-backlog-size = 允许从节点最大中断时长 * 主实例offset每秒写入量，比如master每秒最大写入64mb，最大允许60秒，那么就要设置为64mb*60秒=3840mb(3.8G)= repl-backlog-ttl 3600 #如果一段时间后没有slave连接到master，则backlog size的内存将会被释放。如果值为0则表示永远不释放这部份内存。 slave-priority 100 #slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端进行恢复，如果值设置为0，则表示该slave永远不会被选择。 #min-slaves-to-write 0 #min-slaves-max-lag 10 #设置当一个master端的可用slave少于N个，延迟时间大于M秒时，不接收写操作。 Master的重启会导致master_replid发生变化，slave之前的master_replid就和master不一致从而会引发所有slave的全量同步。 套接字文件的产生： 我们的互联网本身是包转发的概念，包和包之间是没有关系的，所说的tcp是有连接的，那么tcp是怎么实现连接的？ 在报文当中内置了一下能够判定此前前后状态数据的syn、ack，我们的服务器是根据客户端是否请求断开 根据客户端请求时的clientip+port,serverip+port信息创建成一个文件保存在内存中，当客户端再来时如果能查到这个文件说明此前连接过，而客户端关闭了连接，也会自动删除这个已连接的套接字文件，而如果是10w并发也会占用太大的资源，这就是为什么要断开空闲进程的原因； 配置redis一主二从–主从架构 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980实现主从的两种方式： 1.通过CONFIG和SLAVEOF命令配置 127.0.0.1:6379[1]&gt; SLAVEOF 192.168.34.118 6379 #master的IP+port OK 127.0.0.1:6379[1]&gt; CONFIG SET masterauth root #master密码 OK 127.0.0.1:6379[1]&gt; CONFIG REWRITE #保存在配置文件中 OK [root@node03 ~]# tail /usr/local/redis/etc/redis.conf replicaof 192.168.34.118 6379 masterauth &quot;root&quot; #可以看到主从配置信息被写在配置文件的最后面了 2.修改配置文件 详见下文客户端连接redis: 1.主备模式，可以实现Redis数据的跨主机备份； 2.程序端连接到高可用负载的VIP，然后连接到负载服务器设置的Redis后端real server ，此模式不需要在程序里面配置Redis服务器的真实IP地址，当后期Redis服务器IP 地址发生变更只需要更改redis 相应的后端real server即可，可避免更改程序中的 IP地址设置.1.配置2台slave： 1.Redis Slave也要开启数据持久化(RDB/AOF)并设置和master同样的连接密码， 因为后期slave会有提升为master的可能,Slave端切换master同步后会丢失之前的所有数据。 2.一旦某个Slave成为一个master的slave,Redis Slave服务会清空当前redis服务器上的所有数据并将master的数据导入到自己的内存，但是断开同步关系后不会删除当前已经同步过的数据； redis早期的时候都是全量同步，后期支持增量同步2.修改两台从redis服务器的redis.conf配置文件 [root@node02 redis]# vim etc/redis.conf replicaof 192.168.34.118 6379 #master的IP和端口 #注意：master的IP必须和master的bind监听的地址是一致的，如果有两个地址，而bind只监听在内网IP上，此处只能写内网的IP，写外网的IP也不会同步成功的. masterauth root #master的验证密码 requirepass root #每个redis数据库的验证密码都要和master一样3.重启从redis： 127.0.0.1:6379&gt; INFO # Replication role:slave #显示是从节点 master_host:192.168.34.118 #显示master的IP master_port:6379 #显示master的端口 master_link_status:up #显示是否为up状态，在此状态下才是正常的 master_last_io_seconds_ago:9 master_sync_in_progress:0 slave_repl_offset:462 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:1f0cd49a266eaacc5c6bdd14f5c793d065207166 #master的ID master_replid2:0000000000000000000000000000000000000000 #如果有主从故障转移，master_replid2就成了master_replid的编号 #而master_replid会重新生成一个编号 master_repl_offset:462 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:4624.验证master上的信息 Replication role:master connected_slaves:2 #显示当前有几个slave和IP及是否正常 slave0:ip=192.168.34.126,port=6379,state=online,offset=630,lag=0 slave1:ip=192.168.34.117,port=6379,state=online,offset=630,lag=0 master_replid:1f0cd49a266eaacc5c6bdd14f5c793d065207166 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:630 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:6305.验证Slave从节点上的数据 127.0.0.1:6379&gt; keys * 1) &quot;myeky&quot; 2) &quot;mykey1&quot; #显示已经从master上将数据同步成功了，如果slave上原来有数据，则会被清空！6.master和slave上的日志 在master和slave上的日志可以显示出是否同步成功，如果没有同步成功会显示原因，有时原因不会很清楚，需要将redis.conf下的loglevel日志级别调整为debug模式. 主从复制常见问题汇总1.master和slave的防火墙要关闭 2.master密码不对 即配置的master密码不对，导致验证不通过而无法建立主从同步关系。 3.Redis版本不一致 不同的redis 版本之间存在兼容性问题，因此各master和slave之间必须保持版本一致 4.无法远程连接 在开启了安全模式情况下，没有设置bind地址和密码 应用程序如何连接redis？：1.java客户端连接redis是通过jedis来实现的，java代码用的时候只要创建jedis对象就可以建多个jedis连接池来连接 redis，应用程序再直接调用连接池即可连接Redis。 2.而Redis为了保障高可用,服务一般都是Sentinel部署方式，当Redis服务中的主服务挂掉之后,会仲裁出另外一台Slaves 服务充当Master。这个时候,我们的应用即使使用了Jedis连接池,Master服务挂了,我们的应用将还是无法连接新的Master服务 3.为了解决这个问题,Jedis也提供了相应的Sentinel实现,能够在Redis Sentinel主从切换时候,通知我们的应用, 把我们的应用连接到新的Master服务。 4.Jedis Sentinel的使用也是十分简单的,只是在JedisPool中添加了Sentinel和MasterName参数，Jedis Sentinel 底层基于Redis订阅实现Redis主从服务的切换通知，当Reids发生主从切换时，Sentinel会发送通知主动通知Jedis进行 连接的切换，JedisSentinelPool在每次 从连接池中获取链接对象的时候,都要对连接对象进行检测,如果此链接和Sentinel的Master 服务连接参数不一致,则会关闭此连接,重新获取新的Jedis连接对象。 redis Sentinel(哨兵)机制实现–sentinel监控架构 redis sentinel的作用： 主要完成三个功能：监控、通知、自动故障转移 选举：流言协议、投票协议 1.redis主从架构中，master宕机之后，是需要人为执行slave noone将slave切换成 master的； 2.而sentinel进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用； 3.master切换后，sentinel进程会通知给JAVA程序上一个与redis通信的jar包，java程序就会与新的master建立连接池进而正常工作. 4.sentinel可以监控1-N个redis主从集群； sentinel工作原理： 1.哨兵(Sentinel) 是一个分布式系统，你可以在一个架构中运行多个哨兵(sentinel) 进程，这些进程使用流言协议(gossipprotocols)来接收关于Master主服务器 是否下线的信息，并使用投票协议(Agreement Protocols)来决定是否执行自动 故障迁移,以及选择哪个Slave作为新的Master； 2.每个哨兵(Sentinel)进程会向其它哨兵(Sentinel)、Master、Slave定时发送消息， 以确认对方是否&quot;活&quot;着，如果发现对方在指定配置时间(可配置的)内未得到回应 ，则暂时认为对方已掉线，也就是所谓的”主观认为宕机” 简称SDOWN; 3.当&quot;哨兵群&quot;中的多数Sentinel进程在对Master主服务器做出SDOWN 的判断，并且 通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master Server下线判断，这种方式就是“客观宕机”，简称 ODOWN。 4.然后通过一定的vote算法，从剩下的slave从服务器节点中，选一台提升为Master服务 器节点，然后自动修改相关配置，并开启故障转移(failover); redis集群变动： 1.sentinel是分布式集群，只有满足quorum数量判定主节点故障时，才会选举出新的从节点作为master主节点； 2.一旦主的redis宕机之后，sentinel集群会根据每个从节点的replica-priority优先级选择，如果优先级都一样再通过其他方式选择新的master; 3.一旦一个slave--&gt;变成master,数据则以这个slave为准，而其他的从节点都会清空自己的所有数据，重新从这个新的master上同步数据； 配置项详解： port 26379 sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; sentinel auth-pass &lt;master-name&gt; &lt;password&gt; &lt;quorum&gt;表示sentinel集群的quorum机制，即至少有quorum个sentinel节点同时判定主节点故障时，才认为其真的故障； s_down: subjectively down o_down: objectively down sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt; 监控到指定的集群的主节点异常状态持续多久方才将标记为&quot;故障&quot;； sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt; 指在failover过程中，能够被sentinel并行配置的从节点的数量； #意思是：当slave成为master时，其他slave都要重新从master上复制数据， 当数据量和节点数量较大时，可以设置一次复制几个slave;即复制的并行度 sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt; sentinel必须在此指定的时长内完成故障转移操作，否则，将视为故障转移操作失败； sentinel notification-script &lt;master-name&gt; &lt;script-path&gt; 通知脚本，此脚本被自动传递多个参数，类似于keepalived； 配置和连接： sentinel只需要配置监控在主节点上即可,因为sentinel知道这个主从集群中都有哪些从节点； redis-cli -h SENTINEL_HOST -p SENTINEL_PORT redis-cli&gt; SENTINEL masters SENTINEL slaves &lt;MASTER_NAME&gt; SENTINEL failover &lt;MASTER_NAME&gt; SENTINEL get-master-addr-by-name &lt;MASTER_NAME&gt; 注意： 哨兵只是解决了人为介入master和slave角色的切换问题，在Redis服务的并行写入性能上并没有任何作用. Sentinel实现(在上面配置的一主二从上实现sentinel)哨兵可以不和Redis服务器部署在一起,因为sentinel在生产环境下应该是独立的节点，这里是 实验环境，三台sentinel都配置在redis上，生产环境下，redis集群可能是一主八从，可以挑选任意三台部署sentinel； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061.准备Sentinel的配置文件 [root@node01 redis]# cp /usr/local/src/redis-5.0.3/sentinel.conf /usr/local/redis/etc/2.编辑sentinel.conf配置文件 [root@node03 ~]# grep -v &quot;^$&quot; /usr/local/redis/etc/sentinel.conf | grep -v &quot;^#&quot; bind 0.0.0.0 #修改监听的地址为0.0.0.0 port 26379 #sentinel的端口 daemonize no #修改为以守护进程方式运行 pidfile &quot;/usr/local/redis/redis-sentinel.pid&quot; #pid路径 logfile &quot;/usr/local/redis/logs/redis-sentinel.log&quot; #log日志路径 dir &quot;/tmp&quot; #sentinel临时文件目录 sentinel monitor mymaster 192.168.34.126 6379 2 #监控的redis集群名字(可自定义)，master的IP和端口 2是代表3台中的2台sentinel认为master是down的就进行重新选举master sentinel auth-pass mymaster root #redis的密码 sentinel down-after-milliseconds mymaster 15000 #检测时长 sentinel parallel-syncs mymaster 2 #新的slave的复制的并行度 sentinel failover-timeout mymaster 1800003.将此配置文件复制给其他sentinel节点 [root@redis etc]# scp sentinel.conf 192.168.34.126:/usr/local/redis/etc/ [root@redis etc]# scp sentinel.conf 192.168.34.117:/usr/local/redis/etc/4.启动每一台上的哨兵sentinel [root@node01 redis]# redis-sentinel /usr/local/redis/etc/sentinel.conf #因为没有sentinel的Unitfile,所以启动时指定配置文件路径即可;5.验证： [root@node01 ~]# redis-cli -h 192.168.34.118 -a root 192.168.34.118:6379&gt; INFO replication # Replication role:master connected_slaves:2 slave0:ip=192.168.34.117,port=6379,state=online,offset=393121,lag=1 slave1:ip=192.168.34.126,port=6379,state=online,offset=393407,lag=0 master_replid:42cbfee5a816a2cd95d002efed47878cda1fd351 master_replid2:ffac7a2cd6147d781c4fae196266b96dfa1cd9c4 #可以看到192.168.34.118有两个正常的slave; 在每一台哨兵sentinel都启动后，会在sentinel.conf文件中生成 1.所监控的mymaster，redis集群中的主从信息 2.sentinel集群的信息 [root@node01 ~]# tail /usr/local/redis/etc/sentinel.conf protected-mode no sentinel known-replica mymaster 192.168.34.118 6379 sentinel known-replica mymaster 192.168.34.117 6379 #上面两项是mymaster集群中的主从信息 sentinel known-sentinel mymaster 192.168.34.126 26379 7064908b82b7f81d820e1428e813efbf64b222b5 sentinel known-sentinel mymaster 192.168.34.118 26379 e9f530c38fe22f1c76d2cf5f8e52e048d946ec3a #下面两项是sentinel集群中各sentinel的信息 sentinel current-epoch 0 #current-epoch 0表示是刚配置，redis集群没有故障转移，如果redis集群进行过 故障转移，current-epoch的值就会自动加16.通过sentinel客户端命令验证 [root@node01 ~]# redis-cli -p 26379 127.0.0.1:26379&gt; SENTINEL masters 1) 1) &quot;name&quot; 2) &quot;mymaster&quot; 3) &quot;ip&quot; 4) &quot;192.168.34.118&quot; 5) &quot;port&quot; 6) &quot;6379&quot; #此命令会显示集群中的master的信息 127.0.0.1:26379&gt; SENTINEL slaves mymaster 1) 1) &quot;name&quot; 2) &quot;192.168.34.118:6379&quot; 3) &quot;ip&quot; 4) &quot;192.168.34.118&quot; #SENTINEL slaves mymaster会显示名为mymaster的redis集群中的主从信息7.故障转移模拟 1.关闭192.168.34.118这个redis主节点 2.再次查看名为mymaster的redis集群中的master是哪个节点 [root@node01 ~]# redis-cli -p 26379 127.0.0.1:26379&gt; SENTINEL masters 1) 1) &quot;name&quot; 2) &quot;mymaster&quot; 3) &quot;ip&quot; 4) &quot;192.168.34.126&quot; 5) &quot;port&quot; 6) &quot;6379&quot; #此时看到新的master是192.168.34.126节点 [root@node01 ~]# tail /usr/local/redis/etc/sentinel.conf protected-mode no sentinel known-replica mymaster 192.168.34.118 6379 sentinel known-replica mymaster 192.168.34.117 6379 sentinel known-sentinel mymaster 192.168.34.126 26379 7064908b82b7f81d820e1428e813efbf64b222b5 sentinel known-sentinel mymaster 192.168.34.118 26379 e9f530c38fe22f1c76d2cf5f8e52e048d946ec3a sentinel current-epoch 1 #此时sentinel文件中也会记录进行了一次故障转移； 3.修改原来的master节点重新加入redis集群 如果故障的master被修复了，想要再次加入这个集群，就需要在redis.conf文件中设置主从同步信息就可以了； [root@node01 ~]# vim /usr/local/redis/etc/redis.conf replicaof 192.168.34.126 6379 masterauth &quot;root&quot; 启动redis: [root@node01 ~]# systemctl start redis 4.验证： [root@node01 ~]# redis-cli -h 192.168.34.126 -a root 192.168.34.126:6379&gt; INFO replication # Replication role:master connected_slaves:2 slave0:ip=192.168.34.117,port=6379,state=online,offset=393121,lag=1 slave1:ip=192.168.34.118,port=6379,state=online,offset=393407,lag=0 master_replid:42cbfee5a816a2cd95d002efed47878cda1fd351 master_replid2:ffac7a2cd6147d781c4fae196266b96dfa1cd9c4 #可以看到新的master192.168.34.126有两个正常的slave; –当前redis状态–故障转移时sentinel信息–故障转移后的redis配置文件]]></content>
      <categories>
        <category>Nosql</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-监控Heapster和Dashboard]]></title>
    <url>%2F2018%2F06%2F28%2FKubernetes-%E7%9B%91%E6%8E%A7Heapster%E5%92%8CDashboard%2F</url>
    <content type="text"><![CDATA[Heapster和Dashboard 1.前提： 1.现阶段dashboar获取metrics仍旧依赖于heapster，因此也需要安装heapster 2.在未部署Heapster插件前，当前dashboard不能展示Pod、Nodes的CPU、内存等metric图形，后续部署heapster后自然能够看到； 2.准备镜像文件 dashboard的镜像是在k8s.gcr.io需要科学上网，这里已经下载并上传到本地harbor上了； ~]# 下载并上传两个镜像文件到本地 ~]# docker tag k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1 192.168.1.101/baseimage/kubernetes-dashboard-amd64:v1.10.1 ]# docker tag mirrorgooglecontainers/heapster-amd64:v1.5.4 192.168.1.101/baseimage/heapster-amd64:v1.5.4 #将两个镜像重新打tag ~]# docker push 192.168.1.101/baseimage/heapster-amd64:v1.5.4 ]# docker push 192.168.1.101/baseimage/kubernetes-dashboard-amd64:v1.10.1 #上传到本地harbor上 1.Heapster部署Heapster项目地址 备注： 1.部署heapster只是为了Dashboard显示metrics数据，不是为了监控不需要部署influxdb+kabana; 2.heapster内部是使用域名调用其他组件的，所以需要依赖于CoreDNS/kubeDNS； 1.heapster.yaml部署清单 [root@k8s-master heapster-only]# vim heapster.yaml --- apiVersion: v1 kind: ServiceAccount metadata: name: heapster namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: heapster subjects: - kind: ServiceAccount name: heapster namespace: kube-system roleRef: kind: ClusterRole name: system:heapster apiGroup: rbac.authorization.k8s.io --- apiVersion: apps/v1beta1 kind: Deployment metadata: name: heapster namespace: kube-system spec: replicas: 1 selector: matchLabels: k8s-app: heapster template: metadata: labels: spec: replicas: 1 selector: matchLabels: k8s-app: heapster template: metadata: labels: task: monitoring k8s-app: heapster spec: serviceAccountName: heapster containers: - name: heapster #image: gcr.io/google_containers/heapster-amd64:v1.5.4 image: mirrorgooglecontainers/heapster-amd64:v1.5.4 imagePullPolicy: IfNotPresent command: - /heapster #- --source=kubernetes:https://kubernetes.default - --source=kubernetes.summary_api:&apos;&apos; #- --sink=influxdb:http://monitoring-influxdb.kube-system.svc:8086 livenessProbe: httpGet: path: /healthz port: 8082 scheme: HTTP initialDelaySeconds: 180 timeoutSeconds: 5 --- apiVersion: v1 kind: Service metadata: labels: task: monitoring # For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons) # If you are NOT using this as an addon, you should comment out this line. #kubernetes.io/cluster-service: &apos;true&apos; kubernetes.io/name: Heapster name: heapster namespace: kube-system spec: ports: - port: 80 targetPort: 8082 selector: k8s-app: heapster 2.部署 ~]# kubectl apply -f heapster.yaml 2.Dashboard部署github链接dashboard官方重要说明 dashboard: 1.DashBoard是k8s的Web UI:用户的访问界面，可以看到查看pod,svc等等资源;必要时可以先写好yaml格式的资源清单直接粘贴到文本框中就 可以创建资源了. 2.dashboard是不支持创建用户的，用户是k8s内的用户，权限也是有RBAC授权的，所以不同权限的用户登录看到的是RBAC授权看到的资源. 3.Dashboard是以pod形式运行在k8s之上的，即是一个系统服务，系统服务使用的是service Account类型的账户而不是user类型的. 4.dashboard是需要在集群外部访问的，所以通过svc.nodeport或者ingress代理出去. 5.登录dashboard的用户必须是sa用户. 1.下载yaml清单 ~]# wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml 2.准备dashboard的证书文件和secret文件 1.github上下载的dashboard资源部署清单是需要secret的generic类型的资源，这个secret资源名为kubernetes-dashboard-certs,且在 kube-system名称空间. 2.这里使用openssl来制作证书，使用cfssl方式类似； ~]# openssl genrsa -out dashboard.key 2048 #生成dashboard的私钥 ~]# openssl req -new -key dashboard.key -out dashboard.csr -subj &quot;/O=cre/CN=www.cre.io&quot; #指定登录dashboard的域名是www.cre.com，向k8s的CA申请签署 ~]# openssl x509 -req -in dashboard.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out dashboard.crt -days 3650 #使用k8s的CA证书进行签署 ~]# kubectl create secret generic kubernetes-dashboard-certs --from-file=dashboard.crt --from-file=dashboard.key -n kube-system #转换成secret资源,kubernetes-dashboard-certs是dashboard.yaml中事先规定好的secret名字； 3.修改dashboard.yaml清单中的service类型 Dashboard需要在k8s集群外部访问，所以需要修改其service类型为NodePort类型，而不是默认的ClusterIP类型； ~]# vim dashboard.yaml #修改清单中关于service的信息 ... kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard kubernetes.io/cluster-service: &quot;true&quot; addonmanager.kubernetes.io/mode: Reconcile name: kubernetes-dashboard namespace: kube-system spec: ports: - port: 443 targetPort: 8443 nodePort: 30443 #手动指定使用30443的端口 selector: k8s-app: kubernetes-dashboard type: NodePort #修改为NodePort类型 修改部分解释： 1.如果不写nodePort则由apiserver从service-node-port-range=30000-65000中自动分配端口，当然也可以手动指定nodeport范围内的端口； 2.type: NodePort：指定为NodePort类型的service; 4.修改dashboard.yaml清单中镜像地址和args参数 ~]# vim dashboard.yaml #修改清单中关于deployment的信息 spec: containers: - name: kubernetes-dashboard image: 192.168.1.101/baseimage/kubernetes-dashboard-amd64:v1.10.1 ports: - containerPort: 8443 protocol: TCP args: - --auto-generate-certificates - --token-ttl=43200 修改部分解释： 1.从本地harbor上拉取dashboard的镜像； 2.auto-generate-certificates默认设置，需要挂载生成的dashboard证书了，已经使用创建并挂载secret资源代替了； 3.token-ttl=43200：默认的token有效时间是900s，当然这里可以设置自己想要的有效时长，这里设置了12小时； 5.部署Dashboard: ~]# kubectl apply -f kubernetes-dashboard.yaml #部署 secret/kubernetes-dashbaord-certs created serviceaccount/kubernetes-dashboard created role.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created deployment.apps/kubernetes-dashboard created service/kubernetes-dashboard created ~]# kubectl cluster-info kubernetes master is running at https://192.168.1.100:6443 CoreDNS is running at https://10.96.254.254:6443/api/v1/namesapces/kube-system/services/kube-dns:dns/proxy kubernetes-dashboard is running at https://192.168.1.100:6443/api/v1/namesapces/kube-system/services/https:kubernetes-dashboard:/proxy #可以看到部署成功的dashboard访问地址，或者直接访问证书中的dashboard域名； 6.准备admin权限和read只读权限的kubeconfig文件或Token信息； 1.登录dashboard是有两种方式的：令牌和kubeconfig文件 2.关于权限： Dashboard是给开发和运维用的，但是登录看到的权限不同，所以这里准备了一个管理员权限admin，和只读权限的read; 6.1.准备admin权限的ServiceAccount用户：admin-user ~]# vim admin-user-sa-rbac.yaml #写好一个admin-user的清单文件 apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kube-system ~]# kubectl apply -f admin-user-sa-rbac.yaml #通过yaml清单创建admin-user并绑定到ClusterRole上获取admin权限 获取admin-user的Token信息： ~]# kubectl -n kube-system describe secret $(kubectl get secret -n kube-system | grep admin-user | awk &apos;{print $1}&apos;) #1.获取到刚刚创建的admin-user账号的Token信息，然后可以粘贴到登录页面的地方即可； #2.Token太长每次复制粘贴Token是比较麻烦的，所以一般是做成kubeconfig文件； 生成admin-user的kubeconfig文件： 1.设置添加一个集群： kubectl config set-cluster crek8s --server=&quot;http://192.168.1.100:6443&quot; --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true --kubeconfig=/tmp/creadminconfig 2.添加用户信息 kubectl config set-credentials admin-user --token=[此处粘贴上面获得Token] --kubeconfig=/tmp/creadminconfig 3.将添加的用户和集群设置上下文： kubectl config set-context admin-user@crek8s --cluster=crekube --user=admin-user --kubeconfig=/tmp/creadminconfig 4.设置当前上下文： kubectl config use-context admin-user@crek8s --kubeconfig=/tmp/creadminconfig 5.导出/tmp/creadminconfig文件，在登录界面使用kubeconfig方式登录即可. 6.2.准备read权限的ServiceAccount用户：dashboard-read-user 因为k8s没有内置的只读权限的用户，所以这里自己写了一个 ~]# vim read-user-sa-rbac.yaml apiVersion: v1 kind: ServiceAccount metadata: name: dashboard-read-user namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: dashboard-read-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: dashboard-read-clusterrole subjects: - kind: ServiceAccount name: dashboard-read-user namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: dashboard-read-clusterrole rules: - apiGroups: - &quot;&quot; resources: - configmaps - endpoints - persistentvolumeclaims - pods - replicationcontrollers - replicationcontrollers/scale - serviceaccounts - services - nodes - persistentvolumeclaims - persistentvolumes verbs: - get - list - watch - apiGroups: - &quot;&quot; resources: - bindings - events - limitranges - namespaces/status - pods/log - pods/status - replicationcontrollers/status - resourcequotas - resourcequotas/status verbs: - get - list - watch - apiGroups: - &quot;&quot; resources: - namespaces verbs: - get - list - watch - apiGroups: - apps resources: - daemonsets - deployments - deployments/scale - replicasets - replicasets/scale - statefulsets verbs: - get - list - watch - apiGroups: - autoscaling resources: - horizontalpodautoscalers verbs: - get - list - watch - apiGroups: - batch resources: - cronjobs - jobs verbs: - get - list - watch - apiGroups: - extensions resources: - daemonsets - deployments - deployments/scale - ingresses - networkpolicies - replicasets - replicasets/scale - replicationcontrollers/scale verbs: - get - list - watch - apiGroups: - policy resources: - poddisruptionbudgets verbs: - get - list - watch - apiGroups: - networking.k8s.io resources: - networkpolicies verbs: - get - list - watch - apiGroups: - storage.k8s.io resources: - storageclasses - volumeattachments verbs: - get - list - watch - apiGroups: - rbac.authorization.k8s.io resources: - clusterrolebindings - clusterroles - roles - rolebindings verbs: - get - list - watch ~]# kubectl apply -f read-user-sa-rbac.yaml #通过yaml清单部署read用户和名为dashboard-read-clusterrole的clusterrole 获取read-user的Token信息: 同上，省略 生成read-user的kubeconfig文件： 同上，省略 7.访问Dashboard： 根据官方文档，目前访问Dashboard有四种方式： 1.NodePort 2.API Server 3.kubectl proxy 4.Ingress 测试了前三种，目前只有NodePort和kubectl proxy可用，API Server暂时没有解决 1.使用NodeIP+NodePort方式访问 因为配置了tls证书，需要使用https登录 https://192.168.1.20:30443登录即可 或者使用证书中的域名加NodePort访问 https://www.cre.com:30443 #最好使用NodeIP+port方式不会出错 2.使用API Server 1.使用kubectl cluster-info命令显示的dashboard的apiserver地址登录 注意： API Server方式登录会出现403、401,具体报错和解决办法见下文附录; 3.使用kubectl proxy 在主节点上执行kubectl proxy --address=192.168.34.117 --disable-filter=true 其中： address表示外界可以使用192.168.34.117来访问Dashboard，我们也可以使用0.0.0.0 disable-filter=true表示禁用请求过滤功能，否则我们的请求会被拒绝，并提示 Forbidden (403) Unauthorized。 当然也可以指定端口，具体请查看kubectl proxy --help –Dashboard登录页面 3.安装报错问题汇总1.system:anonymous，code:403问题 访问dashboard网页时，可能出现下面这种报错： { &quot;kind&quot;: &quot;Status&quot;, &quot;apiVersion&quot;: &quot;v1&quot;, &quot;metadata&quot;: { }, &quot;status&quot;: &quot;Failure&quot;, &quot;message&quot;: &quot;services \&quot;https:kubernetes-dashboard:\&quot; is forbidden: User \&quot;system:anonymous\&quot; cannot get services/proxy in the namespace \&quot;kube-system\&quot;&quot;, &quot;reason&quot;: &quot;Forbidden&quot;, &quot;details&quot;: { &quot;name&quot;: &quot;https:kubernetes-dashboard:&quot;, &quot;kind&quot;: &quot;services&quot; }, &quot;code&quot;: 403 } 原因: 1.出现system:anonymous，403的原因是Kubernetes API Server新增了–anonymous-auth选项，允许匿名请求访问 secure-port。没有被其他authentication方法拒绝的请求即Anonymous-requests，这样的匿名请求的username为 system:anonymous,归属的组为system:unauthenticated。并且该选线是默认的。这样一来，当采用chrome浏览器访问 dashboard UI时很可能无法弹出用户名、密码输入对话框，导致后续authorization失败。为了保证用户名、密码输入对话框的弹出，需要将–anonymous-auth设置为false; 2.或者可以这么理解： 使用API-Server方式访问dashboard相当于当前主机是apiserver的客户端，由于主机作为客户端没有证书所以认证失败了， 但官方提供的解决方法是将kubelet的证书转化为浏览器可用的证书，然后导入进浏览器就行了；或者也可以使用下面这种方法； 解决办法： 在api-server配置文件中启用--anonymous-auth=false ~]# vim /usr/lib/systemd/system/kube-apiserver.service [Service] User=root ExecStart=/usr/local/bin/kube-apiserver \ --anonymous-auth=false \ #不接受匿名访问，若为true，则表示接受，此处设置为false，便于dashboard访问 2.Unauthorized，code:401问题 有时虽然设置了--anonymous-auth=false，但访问dashboard时，还会出现如下报错： { &quot;kind&quot;: &quot;Status&quot;, &quot;apiVersion&quot;: &quot;v1&quot;, &quot;metadata&quot;: { }, &quot;status&quot;: &quot;Failure&quot;, &quot;message&quot;: &quot;Unauthorized&quot;, &quot;reason&quot;: &quot;Unauthorized&quot;, &quot;code&quot;: 401 } 原因： 解决办法1： 在api-server配置文件中启用-basic-auth-file基于用户名密码认证 ~]# vim /usr/lib/systemd/system/kube-apiserver.service [Service] User=root ExecStart=/usr/local/bin/kube-apiserver \ --basic-auth-file=/etc/kubernetes/pki/basic-auth.csv \ basic-auth.csv制作方法： 格式为password，username，uid ~]# vim basic-auth.csv cre123456，admin，1 readonly，readonly，2 #这里设置两个用户 授权admin用户权限： ~]# kubectl create clusterrolebinding login-dashboard-admin --clusterrole=cluster-admin --user=admin #将admin与k8s内部的clusterrole：cluster-admin获得权限； 解决办法2： 方法1可能对低版本k8s-apiserver配置后就无法启动了，所以推荐使用kubectl proxy方案； 在主节点上，我们执行kubectl proxy --address=192.168.56.101 --disable-filter=true开启代理。 其中： address表示外界可以使用192.168.56.101来访问Dashboard，我们也可以使用0.0.0.0 disable-filter=true表示禁用请求过滤功能，否则我们的请求会被拒绝，并提示 Forbidden (403) Unauthorized。 3.getsockopt: connection timed out问题 果安装的docker版本为1.13及以上，并且网络畅通，flannel、etcd都正常，但还是会出现getsockopt: connection timed out&apos;的错误，则可能是iptables配置问题。具体问题： Error: &apos;dial tcp 10.233.50.3:8443: getsockopt: connection timed out 原因： docker从1.13版本开始，可能将iptables FORWARD chain的默认策略设置为DROP，从而导致ping其他Node上的Pod IP失败，遇到这种问题时，需要手动设置策略为ACCEPT： 解决办法： ~]# vim /usr/lib/systemd/system/docker.service [Service] Type=notify ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPT #将Forward的默认策略改为ACCEPT; ~]# systemctl restart dcoker #重启Docker即可； 4.getsockopt: no route to host问题 出现这个问题大概为三种情况： 一种是权限问题，node节点与master节点之间因为权限问题无法访问； 二是防火墙、iptable，这块如果开启了iptalbe的话需要配置一些端口的访问，比如6443； 三就是节点之间的内部网络不通导致无法访问到内部的8443端口，可以尝试ping一下看网络是否通畅；]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis基础]]></title>
    <url>%2F2018%2F06%2F26%2Fredis%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[缓存基础介绍 1.系统缓存：buffer与cachecentos6是分开的，centos7放到一起了. buffer： 缓冲也叫写缓冲，一般用于写操作，可以将数据先写入内存再写入磁盘，buffer 一般用于写缓冲，用于解决不同介质 的速度不一致的缓冲，先将数据临时写入到里自己最近的地方，以提高写入速度，CPU会把数据线写到内存的磁盘缓冲 区，然后就认为数据已经写入完成看，然后内核的线程在后面的时间在写入磁盘，所以服务器突然断电会丢失内存中的 部分数据。 buffer是在内存中还没写到磁盘上，即将写到磁盘上的数据！ cache： 缓存也叫读缓存，一般用于读操作，CPU读文件从内存读，如果内存没有就先从硬盘读到内存再读到CPU，将需要频繁读 取的数据放在里自己最近的缓存区域，下次读取的时候即可快速读取。 cache是vim/cat等打开的文件信息放到内存中的称为cache,是为了下次访问时加速的！ cache的保存位置： 客户端：浏览器(每个浏览器的默认过期时间不一样) 内存：本地服务器、远程服务器 硬盘：本机硬盘、远程服务器硬盘 速度对比： 客户端浏览器-CPU-内存-远程内存-硬盘-远程硬盘。 cache的特性: 1.过期时间 2.强制过期，源网站更新图片后CDN是不会更新的，需要强制是图片缓存过期 3.命中率，即缓存的读取命中率 在memcached中可以看到有多少缓存和缓存的命中率; Cache（缓存）位于CPU与内存之间的临时存储器，缓存容量比内存小的多但交换速度比内存要快得多。Cache通过缓存文件 数据块，解决CPU运算速度与内存读写速度不匹配的矛盾，提高CPU和内存之间的数据交换速度。Cache缓存越大，CPU处理速 度越快。 Buffer（缓冲）高速缓冲存储器，通过缓存磁盘（I/O设备）数据块，加快对磁盘上数据的访问，减少 I/O，提高内存和硬盘（或其他I/O设备）之间的数据交换速度。Buffer是即将要被写入磁盘的， 而Cache是被从磁盘中读出来的。 2.CDN缓存 CDN内容分发网络（Content Delivery Network），通过将服务内容分发至全网加速节点，利用全球调度系统使用户能够 就近获取，有效降低访问延迟，提升服务可用性. 1.CDN第一降低机房的使用带宽，因为很多资源通过CDN就直接返回用户了; 2.第二解决不同运营商之间的互联，因为可以让联通的网络访问联通让电信的网络访问电信，起到加速用户访问的目的; 3.第三解决用户访问的地域问题，就近返回用户资源; 关于302调度： 如用的是是联通的网络，但是设置了一个电信的DNS，或者电信的用户设置了一个联通的DNS，在刚建立连接的时候CDN法获 取到用户的真实IP，而是只能获取到用户的local DNS而判定用户是联通还是电信的网络，假如设置了错误的运营商DNS会 被调度到错误的CDN 边缘节点，当和边缘节点连接之后就可以获取到用户的真实IP从而判断用户是联通还是电信的网络，如 果是电信的网络被调度到了联通的CDN边缘节点或者是电信的网络被调度到了联通的CND边缘节点，那么可以给用户再发送一 个302重定向的回复，用户的浏览器再根据新的地址进行连接，即可访问到正确的CND 边缘节点。 用户请求CDN的流程： 提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根 据访问的热度不同而进行不同级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA， 再其次的放在云存储，这样兼顾了速度与成本。 内容分发与分层： 提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根 据访问的热度不通而进行不通级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA， 再其次的放在云存储，这样兼顾了速度与成本 CDN的主要优势： 1.提前对静态内容进行预缓存，避免当地用户大量的请求回源，导致主站网络带宽被打满而导致数据无法更新,变向的 减小了存储、Web服务器、数据库的压力； 2.CDN还可以将数据根据访问的热度不通而进行不通级别的缓存，例如访问量最高的资源访问CDN边缘节点的内存，其次 的放在SSD(经常访问的数据放到SSD)或者SATA(不经常访问的放到SATA)，再其次的放在云存储，这样兼顾了速度与成 本。缓存-缓存到最快的地方如内存，缓存的数据准确命中率高，访问速度就快 3.将用户准确调度到最近的边缘节点性能优化，加快访问速度; 4.CDN还可以进行安全相关-抵御攻击 5.最主要的还是节省带宽； 自建CDN优缺点： nginx+squid、nginx+varnish、nginx+ATS等方式可以自建 优点： 自建CDN 比较灵活，可以在访问用户较多的地方多部署服务器 成本比较容易控制 缺点： 费用高 团队技术要求高 问题不变排查，出问题不容易搞的定 3.应用层缓存Nginx、PHP、tomcat等web服务可以设置应用缓存以加速响应用户请求，另外有些解释性语言比如PHP/Python不能直接运行 ，需要先编译成字节码，但字节码需要解释器解释为机器码之后才能执行，因此字节码也是一种缓存，有时候会出现程序代 码上线后字节码没有更新的现象。 动态页面静态化： 将java的动态页面静态化，比如将每个具体产品的web页面静态化为html文件，然后通过nginx 的rewrite功能发布， 即用户最终访问到的某个产品的web 页面是静态的页面，静态页面的访问速度是比较快的，生成的静态页面可以通过nfs、 rsync、分布式存储等方式推送到各web服务器，如果静态页面生成的信息是错误的，可以将信息更改后通过推送平台重新生 成新的web页面并同步到各web服务器，平时可以通过每间隔几个小时自动生成静态页面，比如每6小时生成一次动态页面并同步到各web服务器; 4.其他缓存CPU缓存(L1的数据缓存和L1的指令缓存)、二级缓存、三级缓存 磁盘缓存 RAID卡缓存 分布式缓存：redis、memcache # MegaCli64 -LDinfo -Lall -aAll 此命令可以监控到物理机的raid、磁盘等信息 Redis和Memcached 1.Redis和Memcached是非关系型数据库也称为NoSQL， 2.redis是一个开源的、遵循BSD协议的、基于内存的而且目前比较流行的键值数据库(key-value database)，是一个非关 系型数据库，redis提供将内存通过网络远程共享的一种服务，提供类似功能的还有memcache，但相比memcache，redis还 提供了易扩展、高性能、具备数据持久性等功能； 3.redis是单线程的，在高并发、低延迟环境要求比较高的环境使用量非常广泛，memcached是多进程的. redis和memcached的对比： 1.支持两种方式进行数据的持久化：可以将内存中的数据保持在磁盘中，重启redis服务或者服务器之后可以从备份文 件中恢复数据到内存继续使用。 2.支持更多的数据类型：支持string(字符串)、hash(哈希数据)、list(列表)、set(集合)、zet(有序集合) 3.支持数据的备份：可以实现类似于数据的master-slave模式的数据备份，另外也支持使用快照+AOF； 4.支持更大的value数据：memcache单个key value最大只支持1MB，而redis最大支持 512MB； 5.Redis 是单线程，而memcache是多线程，所以单机情况下没有memcache并发高，但redis 支持分布式集群以实现更高的并发，单Redis实例可以实现数万并发。 6.支持集群横向扩展：基于redis cluster的横向扩展，可以实现分布式集群，大幅提 升性能和数据安全性。 7.都是基于C语言开发。 redis的典型应用场景： Session共享：常见于web集群中的Tomcat或者PHP中多web服务器session共享 详见：tomcat的session cluster/server共享 消息队列：ELK的日志缓存、部分业务的订阅发布系统 计数器：访问排行榜、商品浏览数等和次数相关的场景 缓存：数据查询、电商网站商品信息、新闻内容 微博/微信社交场合：共同好友、点赞评论等 redis的主要功能： 1.Redis支持多种数据结构，包括字符串、哈希表、链表、集合、有序集合、位图、Hyperloglogs等; 2.Redis具备LRU淘汰、事务实现、以及不同级别的硬盘持久化等能力，并且支持副本集和 通过Redis Sentinel实现的高可用方案，同时还支持通过Redis Cluster实现的数 据自动分片能力; 3.Redis的主要功能都基于单线程模型实现，也就是说Redis使用一个线程来服务所有的 客户端请求，同时Redis采用了非阻塞式IO，并精细地优化各种命令的算法时间复杂度， 这些信息意味着： 1.Redis是线程安全的（因为只有一个线程），其所有操作都是原子的，不会因并发产生数据异常; 2.Redis的速度非常快（因为使用非阻塞式IO，且大部分命令的算法时间复杂度都是O(1)); 3.使用高耗时的Redis命令是很危险的，会占用唯一的一个线程的大量处理时间，导致所有的请求都被拖慢。 （例如时间复杂度为O(N)的KEYS命令，严格禁止在生产环境 中使用); Redis安装版本： 公司现在一般用的是3.X 4.X版本的，最新是5.3版本了 http://download.redis.io/releases/ epel源上的redis版本是3.2.12，这里进行编译安装redis-5.0.3版本； 编译安装： [root@node01 ~]# cd /usr/local/src [root@node01 src]# tar xf redis-5.0.3.tar.gz [root@node01 src]# cd redis-5.0.3 [root@node01 redis-5.0.3]# make PREFIX=/usr/local/redis install #将二进制命令放到/usr/local/redis下 编译安装的就不能使用systemctl进行启动了，可以根据yum安装的程序路径进行修改； [root@node01 redis]# mkdir /usr/local/redis/etc/ #创建配置文件目录 [root@node01 redis]# mkdir /usr/local/redis/data/ #创建数据目录 [root@node01 redis]# mkdir /usr/local/redis/logs/ #创建日志存放目录 [root@node01 redis]# mkdir /usr/local/redis/run/ ##创建pid目录 [root@node01 redis]# cp /usr/local/src/redis-5.0.3/redis.conf /usr/local/redis/etc/ #将原来目录下的redis.conf文件拷贝到二进制命令的目录下 redis相关命令: [root@node01 bin]# ll total 32672 -rwxr-xr-x. 1 root root 4366608 Mar 10 03:28 redis-benchmark -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-check-aof #用于检查aof文件异常状态 -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-check-rdb #用于检查rbd文件异常状态 -rwxr-xr-x. 1 root root 4801864 Mar 10 03:28 redis-cli #redis客户端命令 lrwxrwxrwx. 1 root root 12 Mar 10 03:28 redis-sentinel -&gt; redis-server #哨兵命令 -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-server #redis主程序用于启动redis 启动： [root@node01 redis]# pwd /usr/local/redis [root@node01 redis]# /usr/local/redis/bin/redis-server etc/redis.conf #启动后会有三个警告信息一定要修改，不然运行后期会有错误 解决启动时三个报警信息： 1.backlog参数控制的是三次握手的时候server端收到client ack确认号之后的队列值。 net.core.somaxconn = 512 2.vm.overcommit_memory： 0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存 申请失败，并把错误返回给应用进程。 1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 2 表示内核允许分配超过所有物理内存和交换空间总和的内存 vm.overcommit_memory = 1 #因为memcached和redis是直接操作内存的，内存的参数不需要使用内核的参数来调了; 3.transparent hugepage： 开启大页内存动态分配，需要关闭让redis 负责内存管理。 echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled #如果是虚拟化的情况下，需要打开； 修改配置文件并开机自动生效： [root@node01 etc]# vim /etc/rc.d/rc.local echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled [root@node01 etc]# chmod +x /etc/rc.d/rc.local [root@node01 etc]# vim /etc/sysctl.conf net.core.somaxconn = 512 vm.overcommit_memory = 1 创建用户： [root@node01 redis]# useradd redis -s /sbin/nologin 设置目录权限： [root@node01 redis]# chown redis.redis /usr/local/redis/ -R #redis用户要对编译的路径有权限 创建软链接： [root@node01 bin]# ln -sv /usr/local/redis/bin/redis-* /usr/sbin/ 编辑redis服务启动脚本: # cat /usr/lib/systemd/system/redis.service [Unit] Description=Redis persistent key-value database After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf --supervised systemd ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target 启动： systemctl start redis Redis配置文件详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151登录： [root@node01 bin]# redis-cli -h host (设置了bind就需要指定IP地址) info #查看redis信息 select #切换数据库，默认是16个库(编号0-15)redis配置文件主要配置项：######################## 网络配置项 #####################################bind 0.0.0.0 #监听地址，可以用空格隔开后多个监听IP #一般只监听在redis服务器的内网IP上,redis强烈建议内网使用protected-mode yes redis的保护模式 #redis3.2之后加入的新特性，在没有设置bind IP和密码的时候只允许访问 127.0.0.1:6379port 6379 #监听端口tcp-backlog 511 #三次握手的时候server端收到client ack确认号被占满后的等待队列 长度；timeout 0 #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时，生产环境下是600。 tcp-keepalive 300 #tcp会话保持超时时间########################### 通用配置项 ################################daemonize no #默认情况下redis不是作为守护进程运行的，如果你想让它在后台 运行，你就把它改成yes,当redis作为守护进程运行的时候，它会写一个pid 到/var/run/redis.pid文件里面； 在centos6上是yes，在centos7上都是nosupervised no #和操作系统相关参数，可以设置通过upstart和systemd管理Redis守护进程， centos 7以后都使用systemdpidfile /usr/local/redis/redis_6379.pid #pid文件路径 #一般习惯放在编译的路径下(但是redis用户需要对此目录有读权限)loglevel notice #日志级别#loglevel debug #如果日志显示不详细，可以开启debug模式，但是debug的日志会很大；logfile &quot;/usr/local/redis/redis_6379.log&quot; #日志路径 #一般习惯放在编译的路径下(但是redis用户需要对此目录有读权限)databases 16 #设置db库数量，默认16个库，名称编号0-15 改成-1,表示支持无限个库####################### 和快照相关的参数/RBD ##################################快照时从redis主进程复制出一个专门的进程做快照，不会影响redis的读写always-show-logo yes #在启动redis 时是否显示logsave 900 1 #在900秒内有一个键内容发生更改就出就快照机制save 300 10save 60 10000 #也可以通过BGSAVE命令手工触发RDB快照保存。 #注意这是逆向生效的，启动一次全量备份 表示：三个策略满足其中任意一个均会触发SNAPSHOTTING操作；60s内至少有1W次key发生变化才触发备份，300s内至少 有10次key有变化才触发备份，900s内至少有一次key有变化，所以最迟是900s/15min分钟会做一次快照全量备份；stop-writes-on-bgsave-error no #快照创建出错时是否禁止redis写入操作 #重要配置，一定要改成no,避免快照因为磁盘空间满了快照写不进去，使得redis 无法登陆；rdbcompression yes #持久化到RDB文件时，是否压缩，&quot;yes&quot;为压缩，&quot;no&quot;则反之 #启用压缩功能有时还是有必要的rdbchecksum yes #是否开启RC64校验，默认是开启dbfilename dump.rdb #快照生成的文件名，一般给称redis_6379.rdbdir ./ #快照文件保存路径;一般放在二进制编译路径下/usr/loca/redis #一般这个路径不会放在系统盘的而是放在数据盘/挂载存储 #像k8s中这个盘可能是放在ceph/nfs/glusterfs上的,即使云服务down， 也会自动启动一个容器/pod加载到这个盘和文件进行数据恢复##################### REPLICATION主从复制相关的参数####################replicaof &lt;masterip&gt; &lt;masterport&gt; #修改为master的IP和端口 如：replicaof 192.168.34.118 6379masterauth &lt;master-password&gt; #master的密码replica-serve-stale-data yes #当主节点down了，是否使用过期数据提供给主节点replica-read-only yes #作为从服务器必须要是只读的repl-diskless-sync no no, Disk-backed, Diskless 新的从节点或某较长时间未能与主节点进行同步的从节点重新与主节点通信，需要做&quot;full synchronization&quot;，此时其同步方式有两种style： Disk-backend：主节点新创建快照文件于磁盘中，而后将其发送给从节点； Diskless：主节占新创建快照后直接通过网络套接字文件发送给从节点；为了实现并行复制，通常需要在复制启动前延迟一个时间段；repl-diskless-sync-delay 5 #Diskless模式下复制启动前延迟一个时间 #在第一个从节点连进来后等待5s，在这5s内其他从节点都连进来之后 主节点主做一次复制同时传给N个从节点，加快效率repl-ping-replica-period 10 #默认不开启 #slave端向server端发送ping的时间区间设置，默认为10秒repl-timeout 60 #设置复制的超时时长，60s,超过这个时间，从节点再连到主节点就需要重新复制了；repl-disable-tcp-nodelay no #不禁止tcp nodelay，也就是启用tcp nodelayreplica-priority 100 #从节点的优先级 复制集群中，主节点故障时，sentinel应用场景中的主节点选举时使用的优先级；数字越小优先级越高，但0表示不参与选举； #类似于keepalived的主从prioritymin-slaves-to-write 3 #主节点仅允许其能够通信的从节点数量大于等于此处的值时接受写操作；min-slaves-max-lag 10 #从节点延迟时长超出此处指定的时长时，主节点会拒绝写入操作；10s####################和安全相关的参数配置####################################requirepass root123456 #设置redis的登录密码 登录后，需要AUTH root23456验证后，才能set key 如果不设置密码，通过telnet就可以登录到redis进行删除等操作，所以生产环境下建议一定要设置密码.################# 和客户端相关的参数配置/limits #############################maxclients 10000 #最大的客户端并发连接数 #默认值就可以了，毕竟redis是面向应用程序服务器的，而不是客户端############### 内存管理与数据淘汰机制/极其重要 ##############################maxmemory 8589934592 #单位是字节(8g*1024*1024*1024) #一旦设置了最大使用内存空间，当使用空间耗尽时，就需要定义策略了； #注意一定要设置最大内存，如果不设置可能会启用swap交换内存,交换内存会降低 redis的性能，而且swap也使用完后就会导致OOM，内核会kill掉redis进程；maxmemory-policy noeviction #默认使用的淘汰策略 1.volatile-lru #对设置了过期时间的key使用LRU算法进行淘汰 2.allkeys-lru #对所有键key使用LRU算法进行淘汰 3.volatile-random #对过期的key进行随机算法进行淘汰 4.allkeys-random #对所有键key基于随机算法进行淘汰 5.volatile-ttl #比较设置了过期时间的key，越短的先被淘汰 6.noeviction #不淘汰任何现有的数据项 #redis作为database时，一定要使用noeviction #redis作为缓存时，应该使用volatile-lru或者noeviction，具体使用哪种策略取决于业务中的具体情况；配置解析： 1.默认情况下，在32位OS中，Redis最大使用3GB的内存，在64位OS中则没有限制。 2.在使用Redis时，应该对数据占用的最大空间有一个基本准确的预估，并为Redis设定最大使用的内存。否则在64位OS中 Redis会无限制地占用内存（当物理内存被占满后会使用swap空间），容易引发各种各样的问题； 3.在内存占用达到了maxmemory后，再向Redis写入数据时，Redis会： 1.根据配置的数据淘汰策略尝试淘汰数据，释放空间 2.如果没有数据可以淘汰，或者没有配置数据淘汰策略，那么Redis会对所有写请求返回错误，但读请求仍然可以正常执行 4.在为Redis设置maxmemory时，需要注意： 1.如果采用了Redis的主从同步，主节点向从节点同步数据时，会占用掉一部分内存空间，如果maxmemory过于接近 主机的可用内存，导致数据同步时内存不足。所以设置的maxmemory不要过于接近主机可用的内存，留出一部分预留用作主从同步。maxmemory-samples 5 #淘汰算法运行时的采样样本数；######################### AOF相关配置 #################################appendonly yes #启用aof日志，类似于mysql的bin-log,一定要改成yes #登录redis的select、Set等操作就会被记录在此日志中appendfilename &quot;appendonly.aof&quot; #aof日志的路径和名称 #注意这个路径是以上面的dir路径为根的 #如果要保存在一个后端存储上，最好写成绝对路径 -----------------------------------------------------------#AOF提供了三种fsync配置，always/everysec/no，通过配置项[appendfsync]指定：#appendfsync always #每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢 appendfsync everysec #折中的做法，交由后台线程每秒fsync一次#appendfsync no #不进行fsync，将flush文件的时机交给OS决定，速度最快 ----------------------------------------------------------#随着AOF不断地记录写操作日志，必定会出现一些无用的日志，例如某个时间点执行了命令SET key1 “abc”，在之后某个时间点又执行了SET key1 “bcd”，那么第一条命令很显然是没有用的。大量的无用日志会让AOF文件过大，也会让数据恢复的时间过长。auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb #触发aof日志rewrite #上面两行配置的含义是，Redis在每次AOF rewrite时，会记录完成rewrite后的AOF日志大小，当AOF日志大小在该基础 上增长了100%后，自动进行AOF rewrite。同时如果增长的大小没有达到64mb，则不会进行rewrite。############################# 慢日志查询相关配置 ##########################Slow log是Redis用来记录查询执行时间的日志系统，slow log保存在内存里面，读写速度非常快，因此你可以放心地使用它，不必担心因为开启slow log而损害Redis的速度。slowlog-log-slower-than 10000(10毫秒10的负6次方) #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作slowlog-max-len 128 #记录多少条慢日志保存在队列，超出后会删除最早的，以此滚动删除####################### REDIS CLUSTER集群相关 ##############################cluster-enabled yescluster-config-file nodes-6379.conf #集群节点集群信息配置文件,每个节点都有一个,由redis生成和更新,配置时避免名称冲突 #直接指一个文件名即可，文件内容自动生成不需要填入任何配置参数cluster-node-timeout 15000 集群节点互连超时的阈值，单位毫秒cluster-slave-validity-factor 10 进行故障转移时,salve会申请成为master。有时slave会和master失联很久导致数据较旧，这样的slave不应该成为 master。这个配置用来判断slave是否和master失联时间过长。########################################################################### Redis的数据结构和常用命令Key: 1.Redis采用Key-Value型的基本数据结构，任何二进制序列都可以作为Redis的Key使用（例如普通的字符串或一张JPEG图片） 2.关于Key的一些注意事项： 1.不要使用过长的Key。例如使用一个1024字节的key就不是一个好主意，不仅会消耗更多的内存，还会导致查找的效率降低 2.Key短到缺失了可读性也是不好的，例如”u1000flw”比起”user:1000:followers”来说，节省了寥寥的存储空间，却引发了可读性和可维护性上的麻烦 3.最好使用统一的规范来设计Key，比如”object-type:id:attr”，以这一规范设计出的Key可能是”user:1000″或 ”comment:1234:reply-to” 4.Redis允许的最大Key长度是512MB（对Value的长度限制也是512MB） 1.字符串:String1.String是Redis的基础数据类型，Redis没有Int、Float、Boolean等数据类型的概念，所有的基本类型在Redis中都以String体现; SET：为一个key设置value，可以配合EX/PX参数指定key的有效期，通过NX/XX参数针对 key是否存在的情况进行区别操作，时间复杂度O(1) GET：获取某个key对应的value，时间复杂度O(1) GETSET：为一个key设置value，并返回该key的原value，时间复杂度O(1) MSET：为多个key设置value，时间复杂度O(N) MSETNX：同MSET，如果指定的key中有任意一个已存在，则不进行任何操作，时间复杂度O(N) MGET：获取多个key对应的value，时间复杂度O(N) 2.redis的基本数据类型只有String，但Redis可以把String作为整型或浮点型数字来使用，主要体现在INCR、DECR类的命令上： 1.INCR：将key对应的value值自增1，并返回自增后的值。只对可以转换为整型的String 数据起作用。时间复杂度O(1) 2.INCRBY：将key对应的value值自增指定的整型数值，并返回自增后的值。只对可以转换 为整型的String数据起作用。时间复杂度O(1) 3.DECR/DECRBY：同INCR/INCRBY，自增改为自减。 备注： 1.INCR/DECR系列命令要求操作的value类型为String，并可以转换为64位带符号的整型 数字，否则会返回错误。 2.也就是说，进行INCR/DECR系列命令的value，必须在[-2^63 ~ 2^63 – 1]范围内。 3.前文提到过，Redis采用单线程模型，天然是线程安全的，这使得INCR/DECR命令可以 非常便利的实现高并发场景下的精确控制。 例1：库存控制 在高并发场景下实现库存余量的精准校验，确保不出现超卖的情况。 设置库存总量： SET inv:remain &quot;100&quot; 库存扣减+余量校验： DECR inv:remain 当DECR命令返回值大于等于0时，说明库存余量校验通过，如果返回小于0的值，则说明库存已耗尽。 假设同时有300个并发请求进行库存扣减，Redis能够确保这300个请求分别得到99到-200的返回值，每个请求得到的 返回值都是唯一的，绝对不会找出现两个请求得到一样的返回值的情况。 例2：自增序列生成 实现类似于RDBMS的Sequence功能，生成一系列唯一的序列号 设置序列起始值： SET sequence &quot;10000&quot; 获取一个序列值： INCR sequence 直接将返回值作为序列使用即可； 获取一批（如100个）序列值： INCRBY sequence 100 假设返回值为N，那么[N – 99 ~ N]的数值都是可用的序列值。 当多个客户端同时向Redis申请自增序列时，Redis能够确保每个客户端得到的序列值或序 列范围都是全局唯一的，绝对不会出现不同客户端得到了重复的序列值的情况。 2.列表：和ELK相关，基于管道插入多个数据Redis的List是链表型的数据结构，可以使用LPUSH/RPUSH/LPOP/RPOP等命令在List的两端执行插入元素和弹出元素的 操作。虽然List也支持在特定index上插入和读取元素的功能，但其时间复杂度较高（O(N)），应小心使用； 1.LPUSH：向指定List的左侧（即头部）插入1个或多个元素，返回插入后的List长度。 时间复杂度O(N)，N为插入元素的数量 2.RPUSH：同LPUSH，向指定List的右侧（即尾部）插入1或多个元素 3.LPOP：从指定List的左侧（即头部）移除一个元素并返回，时间复杂度O(1) 4.RPOP：同LPOP，从指定List的右侧（即尾部）移除1个元素并返回 5.LPUSHX/RPUSHX：与LPUSH/RPUSH类似，区别在于，LPUSHX/RPUSHX操作的key 如果不存在，则不会进行任何操作 6.LLEN：返回指定List的长度，时间复杂度O(1) 7.LRANGE：返回指定List中指定范围的元素（双端包含，即LRANGE key 0 10会返回 11个元素），时间复杂度O(N)。应尽可能控制一次获取的元素数量，一次获取过大范 围的List元素会导致延迟，同时对长度不可预知的List，避免使用LRANGE key 0 -1这样的完整遍历操作。 应谨慎使用的List相关命令： 1.LINDEX：返回指定List指定index上的元素，如果index越界，返回nil。index数值是 回环的，即-1代表List最后一个位置，-2代表List倒数第二个位置。时间复杂度O(N) 2.LSET：将指定List指定index上的元素设置为value，如果index越界则返回错误， 时间复杂度O(N)，如果操作的是头/尾部的元素，则时间复杂度为O(1) 3.LINSERT：向指定List中指定元素之前/之后插入一个新元素，并返回操作后的List长 度。如果指定的元素不存在，返回-1。如果指定key不存在，不会进行任何操作，时间复杂度O(N) 由于Redis的List是链表结构的，上述的三个命令的算法效率较低，需要对List进行遍历， 命令的耗时无法预估，在List长度大的情况下耗时会明显增加，应谨慎使用。 换句话说，Redis的List实际是设计来用于实现队列，而不是用于实现类似ArrayList这样的 列表的。如果你不是想要实现一个双端出入的队列，那么请尽量不要使用Redis的List数据结构 3.集合:SetRedis Set是无序的，集合成员是唯一的，不可重复的String集合. 与Set相关的常用命令： 1.SADD：向指定Set中添加1个或多个member，如果指定Set不存在，会自动创建一个。 时间复杂度O(N)，N为添加的member个数 2.SREM：从指定Set中移除1个或多个member，时间复杂度O(N)，N为移除的member个数 3.SRANDMEMBER：从指定Set中随机返回1个或多个member，时间复杂度O(N)，N为返回的 member个数; 4.SPOP：从指定Set中随机移除并返回count个member，时间复杂度O(N)，N为移除的 member个数; 5.SCARD：返回指定Set中的member个数，时间复杂度O(1) 6.SISMEMBER：判断指定的value是否存在于指定Set中，时间复杂度O(1) 7.SMOVE：将指定member从一个Set移至另一个Set SADD set1 v1 #生成集合key TYPE set1 #查询集合key SADD set1 v2 v3 v4 #追加数值，追加的时候不能追加已经存在的数值 SMEMBERS set1 #查看集合的所有数据 SDIFF set1 set2 #获取集合的差集 #差集：已属于A而不属于B的元素称为A与B的差（集） SINTER set1 set2 #获取集合的交集 #交集：已属于A且属于B的元素称为A与B的交（集） SUNION set1 set2 #获取集合的并集 #并集：已属于A或属于B的元素为称为A与B的并（集） 慎用的Set相关命令： 1.SMEMBERS：返回指定Hash中所有的member，时间复杂度O(N) 2.SUNION/SUNIONSTORE：计算多个Set的并集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数 3.SINTER/SINTERSTORE：计算多个Set的交集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数 4.SDIFF/SDIFFSTORE：计算1个Set与1或多个Set的差集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数 上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的Set尺寸不可知的情况下，应严格避免使用 4.有序集合：sorted set1.Sorted Set非常适合用于实现排名。 2.Redis Sorted Set和Set一样也是string类型元素的集合,且不允许重复的成员，不同的是 Sorted Set中的每个元素都会关联一个double(双精度浮点型)类型的分数(score)，Sorted Set会根据score对元素 进行升序排序。如果多个member拥有相同的score，则以字典序进行升序排序;序集合的成员是唯一的,但分数(score) 却可以重复，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)，集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员); Sorted Set的主要命令： 1.ZADD：向指定Sorted Set中添加1个或多个member，时间复杂度O(Mlog(N))，M为添加的member数量，N为Sorted Set中的member数量 2.ZREM：从指定Sorted Set中删除1个或多个member，时间复杂度O(Mlog(N))，M为删除的member数量，N为Sorted Set中的member数量 3.ZCOUNT：返回指定Sorted Set中指定score范围内的member数量，时间复杂度：O(log(N)) 4.ZCARD：返回指定Sorted Set中的member数量，时间复杂度O(1) 5.ZSCORE：返回指定Sorted Set中指定member的score，时间复杂度O(1) 6.ZRANK/ZREVRANK：返回指定member在Sorted Set中的排名，ZRANK返回按升序排序的排名，ZREVRANK则 返回按降序排序的排名。时间复杂度O(log(N)) 7.ZINCRBY：同INCRBY，对指定Sorted Set中的指定member的score进行自增， 时间复杂度O(log(N)); 慎用的Sorted Set相关命令： 1.ZRANGE/ZREVRANGE：返回指定Sorted Set中指定排名范围内的所有member，ZRANGE为按score升序排序， ZREVRANGE为按score降序排序，时间复杂度O(log(N)+M)，M为本次返回的member数 2.ZRANGEBYSCORE/ZREVRANGEBYSCORE：返回指定Sorted Set中指定score范围内的所有member，返回结果以 升序/降序排序，min和max可以指定为-inf和+inf，代表返回所有的member。时间复杂度O(log(N)+M) 3.ZREMRANGEBYRANK/ZREMRANGEBYSCORE：移除Sorted Set中指定排名范围/指定 score范围内的所有member。时间复杂度O(log(N)+M) 上述几个命令，应尽量避免传递[0 -1]或[-inf +inf]这样的参数，来对Sorted Set做 一次性的完整遍历，特别是在Sorted Set的尺寸不可预知的情况下。可以通过ZSCAN命令 来进行游标式的遍历. 5.Hash1.Hash即哈希表，Redis的Hash和传统的哈希表一样，是一种field-value型的数据结构，可以理解成将HashMap搬入Redis； 2.Hash非常适合用于表现对象类型的数据，用Hash中的field对应对象的field即可，hash特别适合用于存储对象, Redis 中每个hash可以存储 232-1键值对(40多亿). 1.HSET：将key对应的Hash中的field设置为value。如果该Hash不存在，会自动创建一个。时间复杂度O(1) 2.HGET：返回指定Hash中field字段的值，时间复杂度O(1) 3.HMSET/HMGET：同HSET和HGET，可以批量操作同一个key下的多个field，时间 复杂度：O(N)，N为一次操作的field数量 4.HSETNX：同HSET，但如field已经存在，HSETNX不会进行任何操作，时间复杂度O(1) 5.HEXISTS：判断指定Hash中field是否存在，存在返回1，不存在返回0，时间复杂度O (1)HDEL：删除指定Hash中的field（1个或多个），时间复杂度：O(N)，N为操作的field数量 6.HINCRBY：同INCRBY命令，对指定Hash中的一个field进行INCRBY，时间复杂度O(1) 应谨慎使用的Hash相关命令： 1.HGETALL：返回指定Hash中所有的field-value对。返回结果为数组，数组中field和value交替出现。时间复杂度O(N) 2.HKEYS/HVALS：返回指定Hash中所有的field/value，时间复杂度O(N) 上述三个命令都会对Hash进行完整遍历，Hash中的field数量与命令的耗时线性相关，对于尺寸不可预知的Hash， 应严格避免使用上面三个命令，而改为使用HSCAN命令进行游标式的遍历 消息队列redis除了支持数据类型之外还支持消息队列：生产者消费者模式和发布者订阅者模式. 生产者消费者模式: 1.微服务架构是将比如多个war包分开部署作为独立的小服务，这些服务之间存在着相互 调用的关系，他们是通过特殊的管道发送消息，其他服务也会监听这个管道，当有消息过 来时会读取处理完后再发送到管道给其他服务去完成整个过程，然后再返回给用户. 2.常用的软件还有RabbitMQ、Kafka、RocketMQ、ActiveMQ等. redis实现生产者消费者模式： 1.生产者发布消息 192.168.34.117:6379&gt; LPUSH channel1 msg1 #从管道的左侧写入 (integer) 1 192.168.34.117:6379&gt; LPUSH channel1 msg2 (integer) 2 192.168.34.117:6379&gt; LPUSH channel1 msg3 (integer) 3 2.查看队列所有消息 192.168.34.117:6379&gt; LRANGE channel1 0 -1 1) &quot;msg3&quot; 2) &quot;msg2&quot; 3) &quot;msg1&quot; 3.消费者消费消息 192.168.34.117:6379&gt; RPOP channel1 #从管道的右侧消费 &quot;msg1&quot; 4.再次验证队列消息 192.168.34.117:6379&gt; LRANGE channel1 0 -1 1) &quot;msg3&quot; 2) &quot;msg2&quot; #队列中的msg1消息已经被消费了，只剩两条消息了. 发布者订阅模式： 在发布者订阅者模式下，发布者将消息发布到指定的channel里面，凡是监听该channel的消费者都会收到 同样的一份消息，这种模式类似于是收音机模式，即凡是收听某个频道的听众都会收到主持人发布的相同的消息内容 redis实现发布者订阅模式： 1.订阅者监听频道 192.168.34.117:6379&gt; SUBSCRIBE channel2 #订阅消息 Reading messages... (press Ctrl-C to quit) 1) &quot;subscribe&quot; 2) &quot;channel2&quot; 3) (integer) 1 2.发布者发布消息 192.168.34.117:6379&gt; PUBLISH channel2 test1 #发布消息 (integer) 1 3.各订阅者得到验证消息 192.168.34.117:6379&gt; SUBSCRIBE channel2 Reading messages... (press Ctrl-C to quit) 1) &quot;subscribe&quot; 2) &quot;channel2&quot; 3) (integer) 1 1) &quot;message&quot; 2) &quot;channel2&quot; 3) &quot;test1&quot; #此时订阅此频道的就可以看到消息了 Redis常用命令1.CONFIG： config命令用于查看当前redis配置、以及不重启更改redis配置等。config可以完成绝大多数的redis.config文件中的配置. 示例：直接更改最大内存，而且是立即生效的 192.168.34.117:6379&gt; CONFIG set maxmemory 8589934592 OK 127.0.0.1:6379&gt; CONFIG get maxmemory 1) &quot;maxmemory&quot; 2) &quot;8589934592&quot; 示例：查看redis的配置信息 192.168.34.117:6379&gt; CONFIG GET * 1) &quot;dbfilename&quot; 2) &quot;redis_6379.rdb&quot; 3) &quot;requirepass&quot; 4) &quot;&quot; 5) &quot;masterauth&quot; 213) &quot;bind&quot; 214) &quot;192.168.34.117&quot; #ONFIG GET *看到的奇数行是配置，偶数行是它的值 示例:更改密码 192.168.34.117:6379&gt; CONFIG SET requirepass 123456 OK 2.INFO 显示当前节点redis运行状态信息 # Server #server端配置信息 # Clients #client端配置信息 # Memory #Memory配置信息 # Persistence #rbd和aof持久化配置信息 # Stats #当前状态 # Replication #集群相关信息(配置完集群查看是否正常) # CPU #CPU配置信息 # Cluster #集群信息 # Keyspace #redis的键时间通知 3.SELECT 切换数据库 192.168.34.117:6379&gt; SELECT 6 OK #redis是基于库做的隔离，不同的库是为了存放不同类型的key 4.keys 查看当前库下的所有key 注意： 在redis数据量大的时候，禁止使用keys *命令，严重情况下回造成redis服务器的 IO爆满而出现故障！可以先用DBSIZE看一下有多少个key! 5.BGSAVE：非阻塞 手动在后台执行RDB持久化操作，会立即启动一个后台进程做快照 192.168.34.117:6379[6]&gt; BGSAVE Background saving started 6.SAVE：阻塞 执行SAVE时，数据量比较大时，需要几秒甚至更长的时间将数据保存到磁盘上，如果再SAVE过程中，写入请求会中断 的，可能会造成数据丢失，所以一般用BGSAVE. 7.DBSIZE 显示当前库下的所有key数量 192.168.34.117:6379&gt; DBSIZE (integer) 2 8.FLUSHDB 强制清空当前库中的所有key,慎重使用！ 9.FLUSHALL 强制清空当前redis服务器所有数据库中的所有key，即删除所有数据,慎重使用！ 10.CLIENT命令 127.0.0.1:6379[1]&gt; CLIENT LIST #显示连进来的客户端 127.0.0.1:6379[1]&gt; CLIENT KILL #关闭客户端+id或者ip+port 11.redis的事务 1.事务操作是原子性的就是要么都执行要么都不执行，为了保证事务本身的特性，还可以撤销事务之前所做的操作； 2.redis也是支持事务的，虽然不支持撤销功能，但可以保证将多个命令打包成一个然后一次性的按顺序执行多个命令的机 制，并且在事务执行期间服务器不会中断事务而改变去执行其他客户端命令的请求，它会将事务中的所有命令执行完毕然后 才会处理其他命令请求； 3.redis通过MULTI,EXEC,WATCH等命令实现事务功能，但是仅仅是实现了将多个命令打包然后一次性的按顺序执行多个命令的机制； Redis数据持久化redis虽然是一个内存级别的缓存程序，即redis是使用内存进行数据的缓存的，但是其可以将内存的数据按照一定的策略保存到 硬盘上，从而实现数据持久保存的目的，redis支持两种不同方式的数据持久化保存机制，分别是RDB和AOF. 必须使用数据持久化吗？ 但通常来说，仍然建议至少开启RDB方式的数据持久化，因为： 1.RDB方式的持久化几乎不损耗Redis本身的性能，在进行RDB持久化时，Redis主进 程唯一需要做的事情就是fork出一个子进程，所有持久化工作都由子进程完成 2.Redis无论因为什么原因crash掉之后，重启时能够自动恢复到上一次RDB快照中记 录的数据。这省去了手工从其他数据源（如DB）同步数据的过程，而且要比其他任何的数据恢复方式都要快 3.现在硬盘那么大，真的不缺那一点地方. Redis的持久化: RDB：snapshotting, 二进制格式；按事先定制的策略，周期性地将数据从内存同步至磁盘；数据文件默认为dump.rdb； 客户端显式使用SAVE或BGSAVE命令来手动启动快照保存机制； SAVE：同步，即在主线程中保存快照，此时会阻塞所有客户端请求； BGSAVE：异步；backgroud RDB是完全备份，所以可能会丢失数据； AOF：Append Only File, fsync 记录每次写操作至指定的文件尾部实现的持久化；当redis重启时，可通过重新执行文件中的命令在内存中重建出数据库； BGREWRITEAOF：AOF文件重写； 不会读取正在使用AOF文件，而是通过将内存中的数据以命令的方式保存至临时文件中，完成之后替换原来的AOF文件； RBD:基于时间的快照技术，在save 900 1，在900秒内有一个键内容发生更改就快照机制； 在同时开启AOF和RBD时，因为AOF的级别比RBD高会使用AOF模式. AOF：类似于数据库的binlog，将文件拷贝走，放到另外一台redis的数据目录，自动恢复 AOF中记录的是每次在redis的操作，和mysql的bin-log类似; 生产环境： 1.生产环境下，一般在Slave服务器上同时开启AOF和RDB，Master上只开启RBD.但是生产环境下是需要做集群来解决数据高可用的问题. 2.不建议同时开启RBD和AOF，会对I/O性能影响很高 3.如果一定要同时开启两种持久化方式，最好是把他们放在两个不同的后端存储系统上； 4.如果同时启用时，当出现故障时一定要用AOF恢复，因为它恢复的数据量更多； RDB模式：snapshottingredis的RDB的快照机制是直接把redis放在内存中的数据所占用的内存空间直接原样不动的复刻一份放到磁盘上,它是一个二进制文件; 即把在内存中的数据和它的结构通通转为文件格式放到磁盘上,恢复时会从文件中读取，读取到内存中恢复为在内存空间中的空间结构和数据； RDB：基于时间的快照，默认只保留当前最新的一次快照(会把上一次的快照切换掉)，特点 是执行速度比较快，缺点是可能会丢失从上次快照到当前快照未完成之间的数据(即在两次快照时间之间redis服务可能出现故障，数据会丢失);如果是AOF模式，则不会发生此问题. RDB实现的具体过程： 1.Redis从主进程先fork出一个子进程，使用写时复制(COW)机制，子进程将内存的数据保存为一个临时文件，比如 dump.rdb.temp，当数据保存完成之后再将上一次保存的RDB文件替换掉，然后关闭子进程，这样可以保存每一次做RDB快照 的时候保存的数据都是完整的，因为直接替换RDB文件的时候可能会出现突然断电等问题而导致RDB文件还没有保存完整就突 然关机停止保存而导致数据丢失的情况，可以手动将每次生成的RDB文件进程备份，这样可以最大化保存历史数据。 2.因为会单独开一个子进程负责做快照，所以不影响redis的读写请求. 3.Redis是先将数据写入到一个临时文件中，并且写成功了才会保存到打算要存的文件中，所以一般来讲只要备份下来rdb文件总是可用的； 4.当然也可以连到redis之后，执行SAVE或者BGSAVE命令启动快照保存机制，每隔多长时间执行一次手动RBD数据备份； 但是： SAVE: 是在主线程保存快照，这就意味着在SAVE保存完成之前，此时会阻塞所有客户端请求，因为它是同步保存而且在主线程中实现； 都是完整(全量)的将内存中的数据写入到磁盘当中，而不是增量方式，如果内存中数据量比较大时，必然会影响性能； BGSAVE: 异步方式实现，当我们启动BGSAVE以后，他将立即返回结果告诉已经启动了，然后自动在后台实现保存操作，所以客户端主进程是不会被阻塞的！ 所以一般是通过在脚本中使用BGSAVE命令执行手动RBD数据备份操作!!! RDB模式的优缺点： 优点： 1.RDB快照保存了某个时间点的数据，可以通过脚本执行bgsave(非阻塞)或者save(阻塞)命令自定义时间点备份，可以保留多个备份，当出现问题可以恢复到不同时间点的版本。 2.可以最大化o的性能，因为父进程在保存RDB 文件的时候唯一要做的是fork出一个子进程，然后的-操作都会有这个子进程操作，父进程无需任何的IO操作; 3.RDB在大量数据比如几个G的数据，恢复的速度比AOF的快； 因为RDB是直接将几个G的文件导入到内存中，AOF中记录的是几千上万行的操作命令， 在数据恢复时，需要逐行执行. 缺点： 1-不能实时的保存数据，会丢失自上一次执行RDB备份到当前的内存数据； 2-数据量非常大的时候，从父进程fork的时候需要一点时间，可能是毫秒或者秒； 生产环境下遇到的坑：redis RDB持久化模式有坑,因为我们使用的服务器是机械硬盘，读写性能和SSD固态硬盘相差很大，服务器内存是128G，当时给 redis分了最大内存是120G，每fork一次就出来一个新的进程，但是在此触发持久化的条件后又会fork一个进程出来，前一个还 未写到硬盘中，后一个fork已经出现孙子辈的了，甚至重孙辈的，导致服务器资源耗尽，宕机。还有个redis强烈建议内网使用， 程序调用也是内网，程序调用也是内网，程序调用也是内网。因为有一次被黑就是redis在公网上跑，还没有设置密码,导致将近 20台服务器被黑。 AOF模式:append only file1.AOF日志的全称是Append Only File，从名字上我们就能看出来，它就是把redis的每个操作命令都以追加的方式写入的日志文件尾部； 2.与一般数据库不同的是，AOF文件是可识别的纯文本，它的内容就是一个个的Redis标准命令 3.类似于mysql的bin-log日志； AOF:按照用户或Web服务器的操作顺序依次将操作添加到指定的日志文件当中，特点是数据安全性相对较高，缺点是即使有些操作是重复的也会全部记录. AOF有二个显著缺陷： 1.用fsync来解决数据同步不及时的问题 1.因为linux内核写数据的时候，其实不是直接写磁盘的，而是先把写操作放到内存完成，然后同步到磁盘中的； 2.内核将内存中的数据同步到磁盘的时间是不确定的，因为在内核中有个脏页数据同步策略，写数据-&gt;内存-&gt;由内核 同步到内核内存-&gt;磁盘，由于同步时间的不确定，在断电之前的内核内存中需要同步的数据就丢失了,所以为了避免出 现这种问题就使用fsync; 3.在内核有一个库调用叫fsync(文件同步)，它的工作逻辑是当需要把数据祈请给内核中，内核不但要把数据保存到内核内存中，还要立即同步到磁盘文件中去； 4.而我们只需要调用了fsync，就不会按照内核自己的管理调用方式待会再同步到磁盘，而是立即同步到磁盘，确保了数据一定是保存在磁盘上了； 5.由于内核之所以会使用脏页数据同步策略，就是为了提高IO性能的，而我们却通过 fsync强行同步到磁盘中了，这样一来每秒钟同步的次数就相当多了，而机械硬盘1s也就100个I/O，像SSD能有500IO/s,而PCIE这样的硬盘能达到上万的IO，但价格是 相当昂贵的； 2.AOF的rewrite 1.在redis中一个key以counter来计数通过INCR使得数据增长，如果INCR了20w次，在AOF中也会记录20w行 INCR-counter，不但造成AOF文件过大而且恢复时也会很慢； 2.而这种情况无非就是将counter直接变成20w次，所以为了避免AOF文件过大，必要每隔一段时间对这个key重写一遍 N个合并成一个即可，这叫做AOF的rewrite;这样一来文件的体积就很小，恢复时重放也不会很慢了； AOF实现的具体过程: AOF和RDB一样使用了写时复制机制，AOF默认为每秒钟fsync一次，即将执行的命令保存到AOF文件当中，这样即使redis 服务器发生故障的话顶多也就丢失1秒钟之内的数据，也可以设置不同的fsync策略，或者设置每次执行命令的时候执行 fsync，fsync会在后台执行线程，所以主线程可以继续处理用户的正常请求而不受到写入AOF文件的IO影响 AOF的优点： 1.最安全，在启用appendfsync always时(fsync是同步内存中redis所有已经修改 的文件到存储设备)，任何已写入的数据都不会丢失，使用在启用appendfsync everysec也至多只会丢失1秒的数据。 2.AOF文件在发生断电等问题时也不会损坏，即使出现了某条日志只写入了一半的情况， 也可以使用redis-check-aof工具轻松修复。 3.AOF文件易读，可修改，在进行了某些错误的数据清除操作后，只要AOF文件没有 rewrite，就可以把AOF文件备份出来，把错误的命令删除，然后恢复数据。 AOF模式缺点: 1.AOF文件通常比RDB文件更大 2.磁盘IO性能消耗比RDB高(fsync机制的原因) 3.数据恢复速度比RDB慢 redis一键安装脚本和启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158[root@redis-node ~]# cd /usr/local/src/[root@redis-node src]# ll redis-4.0.1.tar.gz-rw-rw-r-- 1 root root 1711660 Aug 27 16:19 redis-5.0.3.tar.gz[root@redis-node src]# cat redis_install.sh#!/usr/bin/env bash# It&apos;s Used to be install redis.# Created on 2018/03/06 .# author: lk.# Version: 1.0 function install_redis () &#123;########################################################################### cd /usr/local/src tar -zxvf /usr/local/src/redis-5.0.3.tar.gz cd redis-5.0.3 make PREFIX=/usr/local/redis install mkdir -p /usr/local/redis/&#123;etc,var&#125; rsync -avz redis.conf /usr/local/redis/etc/ sed -i &apos;s@pidfile.*@pidfile /var/run/redis-server.pid@&apos; /usr/local/redis/etc/redis.conf sed -i &quot;s@logfile.*@logfile /usr/local/redis/var/redis.log@&quot; /usr/local/redis/etc/redis.conf sed -i &quot;s@^dir.*@dir /usr/local/redis/var@&quot; /usr/local/redis/etc/redis.conf sed -i &apos;s/daemonize no/daemonize yes/g&apos; /usr/local/redis/etc/redis.conf sed -i &apos;s/^# bind 127.0.0.1/bind 0.0.0.0/g&apos; /usr/local/redis/etc/redis.conf ##########################################################################&#125;install_redis赋予脚本执行权限,并进行安装[root@redis-node src]# chmod 755 /usr/local/src/redis_install.sh[root@redis-node src]# /bin/bash -x /usr/local/src/redis_install.sh 编写redis-server启动脚本[root@redis-node src]# cat /etc/init.d/redis-server#!/bin/bash## redis - this script starts and stops the redis-server daemon## chkconfig: - 85 15# description: Redis is a persistent key-value database# processname: redis-server# config: /usr/local/redis/etc/redis.conf# config: /etc/sysconfig/redis# pidfile: /usr/local/redis/var/redis-server.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ &quot;$NETWORKING&quot; = &quot;no&quot; ] &amp;&amp; exit 0 redis=&quot;/usr/local/redis/bin/redis-server&quot;prog=$(basename $redis) REDIS_CONF_FILE=&quot;/usr/local/redis/etc/redis.conf&quot; [ -f /etc/sysconfig/redis ] &amp;&amp; . /etc/sysconfig/redis lockfile=/var/lock/subsys/redis-server start() &#123; [ -x $redis ] || exit 5 [ -f $REDIS_CONF_FILE ] || exit 6 echo -n $&quot;Starting $prog: &quot; daemon $redis $REDIS_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; stop start&#125; reload() &#123; echo -n $&quot;Reloading $prog: &quot; killproc $redis -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload&#125;&quot; exit 2esac赋予脚本执行权限,并启动redis-server[root@redis-node src]# /etc/init.d/redis-server start[root@redis-node src]# lsof -i:6379COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEredis-ser 24439 root 6u IPv4 24642923 0t0 TCP dns02.kevin.cn:6379 (LISTEN) 温馨提示:需要将redis.conf文件中的bind改为本机ip.不能使用默认的127.0.0.1,否则远程连接该redis就会失败[root@redis-node src]# vim /usr/local/redis/etc/redis.conf.....bind 192.168.34.118 重启redis-server服务[root@redis-node src]# /etc/init.d/redis-server restartStopping redis-server: [ OK ]Starting redis-server: [ OK ][root@redis-node src]# lsof -i:6379COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEredis-ser 8184 root 6u IPv4 24688720 0t0 TCP dns02.kevin.cn:6379 (LISTEN) 最好在tomcat两个节点上使用&quot;telnet 192.168.34.118 6379&quot;验证下redis是否能成功连接]]></content>
      <categories>
        <category>Nosql</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式存储系统数据分布方法]]></title>
    <url>%2F2018%2F05%2F10%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[分布式存储系统数据分布方法 分布式存储系统中面临着的首要问题就是如何将大量的数据分布在不同的存储节点上，无论上层接口是KV存储、对象存储、块存储、 亦或是列存储，在这个问题上大体是一致的； 而分布式存储系统中做数据分布目标及可选的方案一般分为下面几种： 假设目标数据是以key标识的数据块或对象，在一个包含多个存储节点的集群中，数据分布算法需要为每一个给定的key指定一个 或多个对应的存储节点负责，数据分布算法有两个基本目标： 1.均匀性(Uniformity) ：不同存储节点的负载应该均衡； 2.稳定性(Consistency)：每次一个key通过数据分布算法得到的分布结果应该保持基本稳定，即使再有存储节点发生变化的情况下。 可以看出，这两个目标在一定程度上是相互矛盾的，当有存储节点增加或删除时，为了保持稳定应该尽量少的进行数据的移 动和重新分配，而这样又势必会带来负载不均。同样追求极致均匀也会导致较多的数据迁移。所以我们希望在这两个极端之间 找到一个点以获得合适的均匀性和稳定性。除了上述两个基本目标外，工程中还需要从以下几个方面考虑数据分布算法的优劣： 3.性能可扩展性，这个主要考虑的是算法相对于存储节点规模的时间复杂度，为了整个系统的可扩展性，数据分布算法不应该在集 群规模扩大后显著的增加运行时间。 4.考虑节点异构，实际工程中，不同存储节点之间可能会有很大的性能或容量差异，好的数据分布算法应该能很好的应对这种异构 ，提供加权的数据均匀。 5.隔离故障域，为了数据的高可用，数据分布算法应该为每个key找到一组存储节点，这些节点可能提供的是数据的镜像副本，也 可能是类似擦除码的副本方式。数据分布算法应该尽量隔离这些副本的故障域，如不同机房、不同机架、不同交换机、不同机器。 算法实现：分析完分布算法的评价指标后，接下来介绍一些可能的方案演进，并分析他们的优劣。这里假设key的值足够分散； 1.Hash1.一个简单直观的想法是直接用Hash来计算，简单的以Key做哈希后对节点数取模。可以看出，在key足够分散的情况下 ，均匀性可以获得，但一旦有节点加入或退出，所有的原有节点都会受到影响，稳定性无从谈起； 2.这和负载均衡的调度算法以及后端缓存服务器的调度情况很类似，单纯的hash取模法是无法保证稳定性的； 3.hash原理：对对象(文件/IP地址)的名称做hash计算，对后端的节点数量进行取模，模是几就落到第几个节点上进 行数据存储； 2.一致性Hash–Consistent hash 一致性Hash可以很好的解决稳定问题，可以将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺 时针找到先遇到的一组存储节点存放。而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将 数据从该节点接收或者给予。但这有带来均匀性的问题，即使可以将存储节点等距排列，也会在存储节点个数变化时带 来数据的不均匀。而这种可能成倍数的不均匀在实际工程中是不可接受的; 3.带负载上限的一致性Hash–带负载上限的一致性Hash 1.一致性Hash有节点变化时不均匀的问题，Google在2017年提出了Consistent Hashing with Bounded Loads来 控制这种不均匀的程度。简单的说，该算法给Hash环上的每个节点一个负载上限为1 + e倍的平均负载，这个e可以自定 义，当key在Hash环上顺时针找到合适的节点后，会判断这个节点的负载是否已经到达上限，如果已达上限，则需要继 续找之后的节点进行分配; 2.如上图所示，假设每个桶当前上限是2，红色的小球按序号访问，当编号为6的红色小球到达时，发现顺时针首先遇到 的B（3，4），C（1，5）都已经达到上限，因此最终放置在桶A。这个算法最吸引人的地方在于当有节点变化时，需要 迁移的数据量是1/e^2相关，而与节点数或数据数均无关，也就是说当集群规模扩大时，数据迁移量并不会随着显著增 加。另外，使用者可以通过调整e的值来控制均匀性和稳定性之间的权衡。无论是一致性Hash还是带负载限制的一致性Hash都无法解决节点异构的问题 4.带虚拟节点的一致性Hash–带虚拟节点的一致性Hash 1.为了解决负载不均匀和异构的问题，可以在一致性Hash的基础上引入虚拟节点，即hash环上的每个节点并不是实际 的存储节点，而是一个虚拟节点。实际的存储节点根据其不同的权重，对应一个或多个虚拟节点，所有落到相应虚拟节 点上的key都由该存储节点负责。如下图所示，存储节点A负责(1,3]，(4,8]，(10, 14]，存储节点B负责(14,1]，(8,10]; 2.这个算法的问题在于，一个实际存储节点的加入或退出，会影响多个虚拟节点的重新分配，进而影响很多节点参与到 数据迁移中来；另外，实践中将一个虚拟节点重新分配给新的实际节点时需要将这部分数据遍历出来发送给新节点。我 们需要一个跟合适的虚拟节点切分和分配方式，那就是分片 5.分片 1.分片将哈希环切割为相同大小的分片，然后将这些分片交给不同的节点负责。注意这里跟上面提到的虚拟节点有着很 本质的区别，分片的划分和分片的分配被解耦，一个节点退出时，其所负责的分片并不需要顺时针合并给之后节点，而 是可以更灵活的将整个分片作为一个整体交给任意节点，实践中，一个分片多作为最小的数据迁移和备份单位; 2.而也正是由于上面提到的解耦，相当于将原先的key到节点的映射拆成两层，需要一个新的机制来进行分片到存储节 点的映射，由于分片数相对key空间已经很小并且数量确定，可以更精确地初始设置，并引入中心目录服务来根据节点 存活修改分片的映射关系，同时将这个映射信息通知给所有的存储节点和客户端 ; 3.上图是我们的分布式KV存储Zeppelin中的分片方式，Key Space通过Hash到分片，分片极其副本又通过一层映射 到最终的存储节点Node Server 6.CRUSH算法 CRUSH算法本质上也是一种分片的数据分布方式，其试图在以下几个方面进行优化： 1.分片映射信息量：避免中心目录服务和存储节点及客户端之间需要交互大量的分片映射信息，而改由存储节点或客户端自 己根据少量且稳定的集群节点拓扑和确定的规则自己计算分片映射。 2.完善的故障域划分：支持层级的故障域控制，将同一分片的不同副本按照配置划分到不同层级的故障域中。 客户端或存储节点利用key、存储节点的拓扑结构和分配算法，独立进行分片位置的计算，得到一组负责对应分片及副本的存 储位置。如下图所示是一次定位的过程，最终选择了一个row下的cab21，cab23，cab24三个机柜下的三个存储节点; 当节点变化时，由于节点拓扑的变化，会影响少量分片数据进行迁移，如下图新节点加入是引起的数据迁移，通过良好的分 配算法，可以得到很好的负载均衡和稳定性，CRUSH提供了Uniform、List、Tree、Straw四种分配算法 常见的存储系统大多采用类似于分片的数据分布和定位方式： * Dynamo及Cassandra采用分片的方式并通过Gossip在对等节点间同； * Redis Cluster将key space划分为slots，同样利用Gossip通信； * Zeppelin将数据分片为Partition，通过Meta集群提供中心目录服务； * Bigtable将数据切割为Tablet，类似于可变的分片，Tablet Server可以进行分片的切割，最终分片信息记录在Chubby中； * Ceph采用CRUSH方式，由中心集群Monitor维护并提供集群拓扑的变化 原文引用于:浅谈分布式存储系统数据分布方法]]></content>
      <categories>
        <category>分布式系统</category>
        <category>分布式存储</category>
      </categories>
      <tags>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现四层和七层负载均衡]]></title>
    <url>%2F2018%2F03%2F26%2Fnginx%E5%AE%9E%E7%8E%B0%E5%9B%9B%E5%B1%82%E5%92%8C%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. 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]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程管理与计划任务]]></title>
    <url>%2F2018%2F03%2F22%2F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E4%B8%8E%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[进程管理与计划任务 进程运行程序的一个副本 进程优先级系统优先级：数字越小，优先级越高 0-139（Centos4,5) 0-98，99(Centos6) 实时优先级：99-0 值越大优先级最高 nice优先级 -20-19，对应系统优先级100-139或99 Big O：时间复杂度，用时和规模的关系O(1)，O(logn), O(n)线性, O(n^2)抛物线, O(2^n) 进程内存：Page Frame，页框，存储页面数据，最小页框大小4k LRU：Least Recently Used 近期最少使用算法，释放内存物理地址空间和线性地址空间 如内存中有长期不使用的数据，则被调出内存空间，当内存中有一数据被调用，则把其从内存的空间中移到首位，与当前内存空间的首位数据，调换位置，并将其它数据依次后推 MMU：Memory Management Unit 负责转换线性和物理地址 TLB：Translation Lookaside Buffer IPC，进程间通信同一主机： signal，信号 shm，共享内存 semaphore，信号量 不同主机： socket，IP和端口号 PRC，远程过程调用 MQ，消息队列 进程的状态进程类型： 守护进程，deamon，与终端无关，系统启动时启动 前台进程，跟终端相关，通过终端启动 进程状态： 运行态，running 就绪态，ready 睡眠态，sleep 可中断睡眠，interruptable 不可中断睡眠，uninterruptable 停止态，stopped 僵死态，zombie 进程的分类CPU-Bond：CPU密集型 IO-Bond：IO密集型 pstree 进程间的树形结构-p，显示详细的树形结构 psLinux各进程的信息保存在/proc/PID ps [option] [option] ps a，与终端相关所有进程 ps x，与终端无关的进程 ps u，与用户相关的进程 ps f，显示进程树形结构 ps o，显示指定的指定字段pid，%cpu，%mem，...常用于ax选项一起使用 L，显示可指定所有字段 ps -C，只显示cmdlist中的进程 ps -e，显示所有进程，常用于f选项一起使用 ps -u，显示有效用户 ps -U，显示真正用户 ps -g，显示有效组名称 ps -G，显示真正组名称 user，当前运行该进程所有者 PID，当前运行进程调度父进程 CPU，当前进程的cpu负载 mem，当前进程的mem负载 VSZ，虚拟内存集 RSS，常驻内存集 TTY，当前进程所关联的终端 stat，当前进程的运行的状态 START，当前进程启动的时间 TIME，当前进程所用占用cpu的时间片 COMMAND，当前进程运行的命令 示例 ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%men | head，当前系统men使用最多的进程 ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head ，当前系统cpu使用最多的进程 taskset 绑定进程至指定的CPUtaskset -cp CPUID PID renice 调整进程优先级pgrep-u，显示有效用户 -U，显示真正用户 -t termimal 显示与终端相关的进程 -l，显示进程名 pidof 显示进程的进程编号 uptime 显示系统启动的时间 top 动态监测系统 -p，显示指定的pid -u，显示指定用户的pid -n，最多显示几次就退出 top -p pids -u|User -n max -o field freefree -h，已易读的方式显示 vmstat 虚拟内存状态 si，从swap写入数据到内存 so，从内存写出数据到swap iostat 显示io的负载情况，在sysstat pmap 显示进程的内存占用情况 dstat 显示系统的占用，替代vmstat，iostatiotop 显示进程的io占用的情况iotop -p pid 指定pid iotop -u user 指定的用户 iotop -n NUM 指定显示多少次后退出 lsof 查看进程打开的文件lsof -p，查看指定pid打开的文件 lsof -i，查看指定端口是那个进程 恢复删除的文件，前提此文件正在打开 lsof | grep /var/log/message rm -f /var/log/message lsof | grep /var/log/message cat /proc/PID/fd/NUM &gt; FILE kill-l，显示信号列表 kill -1 PID 重读配置文件 kill -2 PID 中止某PID，相当于ctrl+C kill -3 PID 相当于ctrl+\ kill -9 PID 强制杀死正在运行的进程 kill -15 PID 终止正在运行的进程 kill -0 PID 安全检查PID kill -18 PID 前端运行 kill -19 PID 后端运行 作业控制ctrl+z，将前端运行的程序挂起到后端 fg，将程序放在前端运行 bg，将程序在后端运行 command &amp; ，将还未运行的命令在后端运行 nohup command &amp;&gt; /dev/null ，将进程与终端剥离 并行执行{ command1&amp; command2&amp; } { command1 command2 }&amp; { command1 command2 }&amp; 示例： { ping -c2 127.0.0.1 ping 127.0.0.2 }&amp; { ping -c2 127.0.0.3 ping 127.0.0.4 }&amp; 计划任务at，在指定的时间执行一次任务,适合执行一次性任务的 at -l，显示计划任务的列表 at -c，查看具体作业任务 at now+TIME，从现在起多少TIME后执行计划任务 /etc/at.{allow,deny}控制用户是否能执行at任务 白名单：/etc/at.allow，默认不存在，只有该文件的用户才执行at命令 黑名单：/etc/at.deny，默认存在，拒绝该文件的用户才执行at命令 周期性任务计划cron 相关的程序包： cronie：主程序包，提供crond守护进程及相关辅助工具 [root@node02 ~]# rpm -ql cronie /usr/bin/crontab #创建任务计划的工具 /usr/sbin/crond #计划任务主程序 /usr/lib/systemd/system/crond.service #此服务必须启动才能确保任务能够周期性执行 cronie-anacron：cronie的补充程序，用于监控cronie任务执行状况 #对服务器用处不大 crontabs：包含CentOS提供系统维护任务 [root@node02 ~]# rpm -ql crontabs /etc/sysconfig/run-parts #将某个目录下的计划任务全部执行一次 计划周期性执行的任务提交给crond，到指定时间会自动运行 系统cron任务：系统维护作业 /etc/crontab 格式书写： [root@node02 ~]# vim /etc/crontab SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59)分 # | .------------- hour (0 - 23)时 # | | .---------- day of month (1 - 31)日 # | | | .------- month (1 - 12) OR jan,feb,mar,apr ...月 # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat周 # | | | | | # * * * * * user-name command to be executed 分 时 日 月 周 用户 执行的命令/脚本 30 2 * 3-6,12 0 root /bin/tar /data/etc.tar /etc/ &amp;&gt; /dev/null #3-6月和12月的周日2:30备份/data/etc目录 30 2 1,10,20 * 0 root /bin/tar /data/etc.tar /etc/ &amp;&gt; /dev/null #注意：当month和week同时设定时是或的关系 即每个月的1,10,20号和每周日都执行备份操作 30 2 1,10,20 * * root /bin/tar /data/etc.tar /etc/ &amp;&gt; /dev/null #注意：每个月的1,10,20号并且是的周日情况下才执行？ 思路：只需要在脚本里通过date +%w判断一下是不是周日即可，不是就退出脚本即可； */10 * * * * root /bin/chekdisk.sh #每十分钟执行一次磁盘检查 10 21 * * * wang /bin/echo &quot;Howdy!&quot; #晚上9点10分运行echo命令 #当然在/etc/crontab创建计划任务只能通过root用户，这样对普通用户来说就不方便了，所以更多的还是 使用crontab命令 用户cron任务： crontab命令 日志：/var/log/cron crontab命令 基本语法，以普通用户执行crontab命令 crontab -e 编辑计划任务列表 */10 * * * * root /bin/chekdisk.sh 默认文件保存路径：/var/spool/cron/编辑计划任务的用户名 #而且不管是哪个用户，只要通过crontab -e创建自己的计划任务就会在此目录下创建同名的文件 改变crontab默认的编辑器为vi，可修改为VIM 如果想修改之前编辑的任务 crontab -e -u test #以test用户修改之前创建的任务计划 01 * * * * root /bin/chekdisk.sh #每个小时的第一分钟执行一次检查 删除计划任务： crontab -r -u test #删除test用户的计划任务 crontab -l 列出所有任务 示例： 如何在秒级别运行任务？ * * * * * for min in 0 1 2;do echo &quot;hi&quot;; sleep 20; done 每秒执行任务 如何实现每7分钟运行一次任务? 1、每周的工作日1：30，将/etc备份至/backup目录中，保存的文件名称格式 为&quot;etcbak-yyyy-mm-dd-HH.tar.xz&quot;，其中日期是前一天的时间 [root@node02 ~]# vim /root/bakcup.sh #!/bin/bash tar Hcf /backup/etcbak-`date -d &apos;-1 day&apos; +%Y-%m-%d-%H`.tar.xz /etc/ &amp;&gt; /dev/null [root@node02 ~]# chmod +x /root/bakcup.sh [root@node02 ~]#crontab -e 30 1 * * 1-5 /root/bakcup.sh 2、每两小时取出当前系统/proc/meminfo文件中以S或M开头的信息追加至 /tmp/meminfo.txt文件中 [root@node02 ~]# vim /root/test.sh #!/bin/bash cat /proc/meminfo | grep -o &quot;^[M|S].*&quot; &gt;&gt; /tmp/meminfo.txt [root@node02 ~]# chmod +x /root/test.sh [root@node02 ~]# crontab -e 0 */2 * * * /root/test.sh 3、工作日时间，每10分钟执行一次磁盘空间检查，一旦发现任何分区利用率高于80%，就执行wall警报 [root@node02 ~]# vim /root/diskspce.sh #!/bin/bash [ `df |sed -nr &apos;/^\/dev\/sd/s/.*([0-9]+)%.*/\1/p&apos;|sort -nr|head -n1` -gt 80 ] &amp;&amp; wall disk will be full [ `df -i |sed -nr &apos;/^\/dev\/sd/s/.*([0-9]+)%.*/\1/p&apos;|sort -nr|head -n1` -gt 80 ] &amp;&amp; wall disk will be full [root@node02 ~]# chmod +x /root/diskspce.sh [root@node02 ~]#crontab -e */10 * * * * /root/diskspce.sh 系统自带的计划任务： /etc/cron.d /etc/cron.hourly /etc/cron.daily /etc/cron.daily/tmpwatch 定期执行清除临时文件 /etc/cron.weekly /etc/cron.monthly 附录：crontab作为应用守护时，如何避免出现环境变量未加载的情况？如何避免crontab导致僵尸进程的出现1. crontab与环境变量 不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点： 1）脚本中涉及文件路径时写全局路径； 2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如： cat start_cbp.sh #!/bin/sh source /etc/profile export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf /usr/local/jboss-4.0.5/bin/run.sh -c mev &amp; 3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如： 0 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh 2. 其他应该注意的问题 1）新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。 2）每条 JOB 执行完毕之后，系统会自动将输出发送邮件给当前系统用户。日积月累，非常的多，甚至会撑爆整个系统。所以每条 JOB 命令后面进行重定向处理是非常必要的： &gt;/dev/null 2&gt;&amp;1 。前提是对 Job 中的命令需要正常输出已经作了一定的处理, 比如追加到某个特定日志文件。 3）当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。 4）千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。 5）在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\%Y\%m\%d’`。 3.最近遇到了一些sh不能在crontab定时任务中自动执行的问题 期间由于不太了解，故走了一点弯路，现在总结下来可能第一次 进行设置遇到的问题。以绝后患！我所用过的操作系统为HP-unix&amp;linux&amp;sco-unix，均测试通过 1，首先确保sh脚本具有可执行属性 即chmod +x ***.sh 或chmod +777 ***.sh 2，确保sh脚本手工执行正常 即在当前系统内手工执行sh脚本以后能收到自己期望得到的结果 3，加载环境变量 这个问题是经常容易被忽略的问题，通常我们在第二步的时候手动执行脚本能得到自己想要的结果，可是设置好crontab之后，总不能得到自己想要的结果，总感觉脚本没有被执行。或者执行后没有得到正常的结果。很多均是由于没有加载所在用户的环境变量所引起的。因此最好在自己的脚本首两行添加环境变量的导入。如下：其中telstar是我在操作系统下所在的用户。在该目录下执行ls -a可以查看到.cshrc文件。我们在自己的sh脚本中增加source 该文件，将本用户的环境变量加载，那么以下的内容就能正常被执行了 #!/bin/csh#source /telstar/.cshrc 下面贴出我的定时重启tomcat的一个例子 #!/bin/csh#source /telstar/.cshrckill -9 `ps -ef | grep Djava.uti | grep -v tail | grep -v vi | grep -v grep | awk &apos;{print $2}&apos;`cd /telstar/tomcat/binsleep 15./startup.sh &amp; 4.cron输出导致僵尸进程案例及解决 案例： 登录到主机发现服务器上有2个名称为[sh] &lt;defunct&gt;的进程 Ps –ef 带进程号查 发现是僵尸进程是restartTomcat.sh这类进程 杀掉这些僵尸进程 单纯使用kill -9 进程号是无法杀掉，需要kill -9 父进程号，子进程会自动被init进程接管，释放。 查询父进程是cron，root下有cron任务 [root@server mail]# crontab -l 50 23 * * * /bin/bash restartTomcat.sh 造成这些现象的原因是crontab中的程序执行，导致输出大量信息到标准设备上。 crontab 计划内容中定义命令，如果有大量输出信息，将会造成僵尸进程(defunct)；这时候应该在定义的命令后边加上 &quot;&gt; /dev/null 2&gt;&amp;1&quot; 解决办法: 把cron任务的输出定向到空设备上 即将crontab里面的每行命令后面加上 &gt; /dev/null 2&gt;&amp;1]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈mysql优化]]></title>
    <url>%2F2018%2F03%2F22%2F%E6%B5%85%E8%B0%88mysql%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[浅谈mysql优化 一、影响mysql性能的因素 sql语句查询速度 服务器硬件 网卡流量 磁盘IO 二、优化mysql的性能方法 优化sql语句，索引 使用缓存，把经常使用的数据放到缓存中，能节省磁盘IO 优化硬件，使用SSD硬盘 主从分离读写，采用主从复制把数据库的读操作和写操作分离开来 不采用全文索引 三：拒绝使用默认设置 下面是三个MySQL性能优化设置 1.innodb_ buffer_ pool_size: 缓冲池用于存放缓存数据和索引。这是使用具有大容量RAM的系统作为数据库服务器的主要原因。如果只运行InnoDB存储 引擎，通常会将80%的内存分配给缓冲池。如果您正在运行非常复杂的查询，或者有大量的并发数据库连接，或大量的表 ，可能需要将此值降低一个档次，以便为其他操作分配更多的内存。 在设置InnoDB缓冲池大小时，需要确保不要设置得太大，否则会导致交换。这绝对会影响数据库性能。一种简单的检查方 法是查看Percona Monitoring and Management中的系统概述图中的交换活动 2.innodb_log_file_size： 这是单个InnoDB日志文件的大小。默认情况下，InnoDB使用两个值，这样您就可以将这个数字加倍，从而获得InnoDB用 于确保事务持久的循环重做日志空间的大小。这也优化了将更改应用到数据库。设置innodb_ log_ file_ size是一个 权衡的问题。分配的重做空间越大，对于写密集型工作负载而言，性能就越好，但是如果系统断电或出现其他问题，崩溃恢复的时间就越长 3.MAX_Connections： 大型应用程序连接数通常需高于默认值。不同于其它变量，如果没有正确设置它，就不会有性能问题(本身)。相反， 如果连接的数量不足以满足您的应用程序的需要，那么您的应用程序将无法连接到数据库(在您的用户看来，这就 像是停机时间)。所以正确处理这个变量很重要 四：将数据库保存在内存中 一、SQL查询语句优化 1.使用索引，创建正确的索引 建立索引可以使查询速度得到提升，我们首先应该考虑在where及order by，group by涉及的列上建立索引。 分析： 索引通过减少查询必须扫描的数据库中的数据量来提高查询效率。MySQL中的索引用于加速数据库中的访问，并帮助执 行数据库约束(如 UNIQUE和FOREIGN KEY )。 数据库索引很像图书索引。它们被保存在自己的位置，并且包含主数据库中已经存在的信息。它们是指向数据所在位置的参考方法 或映射。索引不会更改数据库中的任何数据。它们只是指向数据的位置。 没有完全适用于任何工作负载的索引。而应该始终在系统运行的查询上下文中查看索引。 索引良好的数据库不仅运行得更快，而且即使缺少一个索引也会使数据库慢如蜗牛。使用EXPLAIN(如前所述)查找缺少的索引 并添加它们。但是要小心：不要添加你不需要的索引！不必要的索引会降低数据库的速度 2.借助explain（查询优化神器）选择更好的索引和优化查询语句 SQL 的 Explain 通过图形化或基于文本的方式详细说明了 SQL 语句的每个部分是如何执行以及何时执行的，以及执行效果。通过 对选择更好的索引列，或者对耗时久的SQL语句进行优化达到对查询速度的优化。 3、任何地方都不要使用SELECT * FROM语句。 4、不要在索引列做运算或者使用函数 5、查询尽可能使用limit来减少返回的行数 6、使用查询缓存，并将尽量多的内存分配给MYSQL做缓存 二、主从复制，读写分离，负载均衡 目前大多数的主流关系型数据库都提供了主从复制的功能，通过配置两台（或多台）数据库的主从关系，可以将一台数据库 服务器的数据更新同步到另一台服务器上。网站可以利用数据库这一功能，实现数据库的读写分离，从而改善数据库的负载 压力。一个系统的读操作远远多于写操作，因此写操作发向master，读操作发向slaves进行操作（简单的轮询算法来决定使用哪个slave）。 利用数据库的读写分离，Web服务器在写数据的时候，访问主数据库（master），主数据库通过主从复制将数据更新同步到 从数据库（slave），这样当Web服务器读数据的时候，就可以通过从数据库获得数据。这一方案使得在大量读操作的Web应用 可以轻松地读取数据，而主数据库也只会承受少量的写入操作，还可以实现数据热备份，可谓是一举两得。 三、数据库分表、分区、分库 1、分表 通过分表可以提高表的访问效率。有两种拆分方法： 垂直拆分 在主键和一些列放在一个表中，然后把主键和另外的列放在另一个表中。如果一个表中某些列常用，而另外一些不常用，则可以采用垂直拆分。 水平拆分 根据一列或者多列数据的值把数据行放到两个独立的表中。 2、分区 分区就是把一张表的数据分成多个区块，这些区块可以在一个磁盘上，也可以在不同的磁盘上，分区后，表面上还是一张 表，但是数据散列在多个位置，这样一来，多块硬盘同时处理不同的请求，从而提高磁盘I/O读写性能。实现比较简单， 包括水平分区和垂直分区。 3、分库 分库是根据业务不同把相关的表切分到不同的数据库中，比如web、bbs、blog等库。 分库解决的是数据库端 并发量的问题。分库和分表并不一定两个都要上，比如数据量很大，但是访问的用户很少，我们就可以只 使用分表不使用分库。如果数据量只有1万，而访问用户有一千，那就只使用分库 注意：分库分表最难解决的问题是统计，还有跨表的连接（比如这个表的订单在另外一张表），解决这个的方法就是使用中间件， 比如大名鼎鼎的MyCat，用它来做路由，管理整个分库分表，乃至跨库跨表的连接 生产环境my.cnf硬件：内存32G innodb_file_per_table = 1 打开独立表空间 max_connections = 8000 MySQL 服务所允许的同时会话数的上限，经常出现Too Many Connections的错误提 示，则需要增大此值 back_log = 300 back_log 是操作系统在监听队列中所能保持的连接数 max_connect_errors = 1000 每个客户端连接最大的错误允许数量，当超过该次数，MYSQL服务器将禁止此主机的连 接请求，直到MYSQL服务器重启或通过flush hosts命令清空此主机的相关信息 open_files_limit = 10240 #所有线程所打开表的数量 max_allowed_packet = 32M #每个连接传输数据大小.最大1G，须是1024的倍数，一般设为最大的BLOB的值 wait_timeout = 10 #指定一个请求的最大连接时间 sort_buffer_size = 16M #排序缓冲被用来处理类似ORDER BY以及GROUP BY队列所引起的排序 join_buffer_size = 16M #不带索引的全表扫描.使用的buffer的最小值 query_cache_size = 128M #查询缓冲大小 query_cache_limit = 4M #指定单个查询能够使用的缓冲区大小，缺省为1M transaction_isolation = REPEATABLE-READ 设定默认的事务隔离级别 thread_stack = 512K # 线程使用的堆大小. 此值限制内存中能处理的存储过程的递归深度和SQL语句复杂性， 此容量的内存在每次连接时被预留. log-bin #二进制日志功能 binlog_format=row #二进制日志格式 innodb_buffer_pool_size = 24G #InnoDB使用一个缓冲池来保存索引和原始数据, 可设置这个变量到服务器物理内存大小 的80% innodb_file_io_threads = 4 #用来同步IO操作的IO线程的数量 innodb_thread_concurrency = 16 #在InnoDb核心内的允许线程数量，建议的设置是CPU数量加上磁盘数量的两倍 innodb_log_buffer_size = 16M # 用来缓冲日志数据的缓冲区的大小 innodb_log_file_size = 512M 在日志组中每个日志文件的大小 innodb_log_files_in_group = 3 # 在日志组中的文件总数 innodb_lock_wait_timeout = 120 # SQL语句在被回滚前,InnoDB事务等待InnoDB行锁的时间 long_query_time = 2 #慢查询时长 log-queries-not-using-indexes #将没有使用索引的查询也记录下来]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于lnnmp搭建个人博客]]></title>
    <url>%2F2018%2F03%2F22%2F%E5%9F%BA%E4%BA%8Elnnmp%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[基于openstack/docker搭建LNNMP -个人网站基本架构图 环境准备1.所有服务器时间要同步 2.proxysql要和mysql所有服务器在同一个网段，不然会影响mysql的性能 nginx调度服务器：192.168.100.10 nginx+fpm-1服务器：192.168.100.3 nginx+fpm-2服务器：192.168.100.4 proxysql数据库读写分离：192.168.100.30 mysql_1服务器:192.168.100.9 mysql_2服务器:192.168.100.16 mysql_3服务器:192.168.100.17 NFS主：在mysql_2服务器上192.168.100.16 NFS备：在mysql_3服务器上192.168.100.17 软件版本： wordpress: wordpress-5.0-zh_CN.zip (默认安装再升级) wordpress-5.0.2-zh_CN.zip(用于测试升级版本) 依赖于php7.3版本之上和mysql5.6或者mariadb10.0版本之上 mysql:mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz(和一键安装脚本) nginx:nginx-1.12.2.tar.gz php-fpm:php-7.2.14.tar.gz nfs: nfs-utils 1.搭建一主二从数据库二进制安装mysql，此处用事先准备好的脚本进行安装(供参考)； 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@mysql_1 ~]# vim mysql-install.sh #!/bin/bashDIR=`pwd`NAME=&quot;mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz&quot;FULL_NAME=$&#123;DIR&#125;/$&#123;NAME&#125;DATA_DIR=&quot;/data/mysql&quot;yum install vim gcc gcc-c++ wget autoconf net-tools lrzsz iotop lsof iotop bash-completion -yyum install curl policycoreutils openssh-server openssh-clients postfix -yif [ -f $&#123;FULL_NAME&#125; ];then echo &quot;安装文件存在&quot;else echo &quot;安装文件不存在&quot; exit 3fiif [ -h /usr/local/mysql ];then echo &quot;Mysql已经安装&quot; exit 3else tar xvf $&#123;FULL_NAME&#125; -C /usr/local/src ln -sv /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64 /usr/local/mysql if id mysql;then echo &quot;mysql用户已经存在&quot; fi useradd mysql -s /sbin/nologin if id mysql;then chown -R mysql.mysql /usr/local/mysql/* -R if [ ! -d /data/mysql ];then mkdir -pv /data/mysql &amp;&amp; chown -R mysql.mysql /data -R /usr/local/mysql/scripts/mysql_install_db --user=mysql --datadir=/data/mysql --basedir=/usr/local/mysql/ cp /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64/support-files/mysql.server /etc/init.d/mysqld chmod a+x /etc/init.d/mysqld cp $&#123;DIR&#125;/my.cnf /etc/my.cnf ln -sv /usr/local/mysql/bin/mysql /usr/bin/mysql chkconfig --add mysqld service mysqld start else echo &quot;MySQL数据目录已经存在&quot; exit 2 fi fifi 主节点数据库： 1.启用二进制日志和跳过主机名称解析 server-id=1 log_bin=/data/mysql/master-log skip_name_resolve = on 2.授权主从复制账号 grant replication slave on *.* to repluser@&apos;192.168.100.%&apos; identified by &apos;root123&apos;; 3.show master logs; 查看二进制日志位置，准备change master to信息 4.创建wordpress数据库 create database wordpress; 5.创建php连接mysql的用户和proxysql读写分离的用户 grant all on *.* to wordpress@&apos;192.168.100.%&apos; identified by &apos;wordpress123&apos; 此账号既作为php连接数据库的账号，又作为proxysql中读写分离的账户 从节点数据库： 1.每个从节点都需要如下设置，设置只读，启用中继日志 server-id=2|3 read-only relay_log=/data/mysql 2.设置change master to: CHANGE MASTER TO MASTER_HOST=&apos;192.168.100.9&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;root123&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-log.000001&apos;, MASTER_LOG_POS=4, MASTER_CONNECT_RETRY=120; 3.start slave; 启动MySQL主从 service mysqld start 安装配置proxysql读写分离器1.基于YUM仓库安装 vim /etc/yum.repos.d/proxysql.repo [proxysql_repo] name= ProxySQL YUM repository baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever gpgcheck=1 gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key 2.安装启动 yum install proxysql &amp;&amp; systemctl start proxysql 3.向ProxySQL中添加MySQL所有节点，以下操作不需要use main也可成功 MySQL &gt; select * from mysql_servers; MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.9&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.16&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,&apos;192.168.100.17&apos;,3306); MySQL &gt; load mysql servers to runtime; MySQL &gt; save mysql servers to disk; 4.配置监控账号： a.在主节点上，创建监控账号 grant replication client on *.* to monitor@&apos;192.168.100.%&apos; identified by &apos;root123&apos;; 备注：replication client权限是负责监控的，和replication slave是不同的权限 b.Proxysql上配置监控 实际上是保存在global_variables表中，可以查看是否修改成功 MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;; MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;; c.使global_variables表生效 MySQL [mian]&gt; load mysql variables to runtime; MySQL [mian]&gt; save mysql variables to disk; 5.设置分组信息和读写规则 main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20 插入读写组的编号： insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;); 生效和保存： MySQL [monitor]&gt; load mysql servers to runtime; MySQL [monitor]&gt; save mysql servers to disk; 再次查看 select hostgroup_id,hostname,port,status,weight from mysql_servers; 6.创建用于测试读写分离的账号 主节点上创建访问用户： 用上面创建的wordpress账户即可 在ProxySQL配置，将用户wordpress添加到mysql_users表中： insert into mysql_users(username,password,default_hostgroup)values(&apos;wordpress&apos;,&apos;wordpress123&apos;,10); 生效和保存： MySQL [monitor]&gt; load mysql users to runtime; MySQL [monitor]&gt; save mysql users to disk; 7.配置路由规则，实现读写分离 与规则相关的表：mysql_qeury_rules 插入路由规则,实现读写分离的规则 insert into mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply) VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1); 生效和保存到磁盘： load mysql query rules to runtime; save mysql query rules to disk; 8.可以现在本机用wordpress测试是否可以实现读写分离 读：因为是读操作会在2和3上随机选择 mysql -wordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos; 写：事务是非select开头的，所以查询的都是1上 mysql -uwordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos; 编译安装php1.准备环境依赖包： yum -y install wget vim pcre pcre-devel openssl openssl-devel libicu-devel gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel ncurses ncurses-devel curl curl-devel krb5-devel libidn libidn-devel openldap openldap-devel nss_ldap jemalloc-devel cmake boost-devel bison automake libevent libevent-devel gd gd-devel libtool* libmcrypt libmcrypt-devel mcrypt mhash libxslt libxslt-devel readline readline-devel gmp gmp-devel libcurl libcurl-devel openjpeg-devel 2.编译php: ./configure --prefix=/usr/local/php \ --with-config-file-path=/usr/local/php/etc \ --with-config-file-scan-dir=/usr/local/php/etc/conf.d \ --enable-fpm --with-fpm-user=www \ --with-fpm-group=www --with-pear \ --with-curl --with-png-dir --with-freetype-dir \ --with-iconv --with-mhash --with-zlib --with-xmlrpc \ --with-xsl --with-openssl --with-mysqli --with-pdo-mysql \ --disable-debug --enable-zip --enable-sockets \ --enable-soap --enable-inline-optimization --enable-xml \ --enable-ftp --enable-exif --enable-wddx \ --enable-bcmath --enable-calendar --enable-shmop \ --enable-dba --enable-sysvsem --enable-sysvshm --enable-sysvmsg make &amp;&amp; make install 3.创建用户 useradd www 4.准备配置文件 cd /usr/local/php/etc/ cp php-fpm.conf.default php-fpm.conf cp php-fpm.d/www.conf.default php-fpm.d/www.conf 1.修改php-fpm.d/www.conf配置文件，使用dynamic动态模式，并设置最大，最少 空闲进程等信息 2.修改启动php的用户为www 5.准备启动脚本 cp /root/ php-7.2.14/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm chkconfig --add php-fpm chkconfig php-fpm on 也可以使用编译生成的 /usr/local/php/sbin/php-fpm直接启动 编译安装nginx实现web服务因为在上文架构图中nginx既做web服务，又作为前端负载均衡服务器 在这两台服务器上编译安装nginx,实现转发wordpress请求 nginx+fpm-1服务器：192.168.100.3 nginx+fpm-2服务器：192.168.100.4 1.解压并编译 tar xf nginx-1.12.2.tar.gz cd nginx-1.12.2 ./configure \ --prefix=/usr/local/nginx \ --with-pcre \ --with-http_stub_status_module \ --with-http_ssl_module make &amp; make install 2.修改配置文件将php资源请求调度到php-fpm 在server的上下文定义：因为nginx和php在同一台服务器，所以直接写127.0.0.1:9000 location / { root /data/nginx/wordpress; index index.php index.html index.htm; } location ~ \.php$ { root /data/nginx/wordpress;(可不写) fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 如果location中不写root，$document_root就要写/data/nginx/wordpress$fastcgi_script_name; 3.启动服务 /usr/local/nginx/sbin/nginx 部署wordpress-5.0在两台nginxweb服务器上安装同样的wordpress和配置 1.创建存放wordpress目录 mkdir -pv /data/nginx/wordpress 2.解压并将全部文件拷贝到/data/nginx/wordpress下 tar xf wordpress-5.0-zh_CN.zip mv wordpress/* /data/nginx/wordpress/ 3.修改/data/nginx/wordpress的所有者和所属组 chown -R www.www /data/nginx/wordpress 4.准备连接数据库的文件 cp wp-config-sample.php wp-config.php vim wp-config.php /** WordPress数据库的名称 */ define(&apos;DB_NAME&apos;, &apos;wordpress&apos;); /** MySQL数据库用户名 */ define(&apos;DB_USER&apos;, &apos;wordpress&apos;); /** MySQL数据库密码 */ define(&apos;DB_PASSWORD&apos;, &apos;wordpress123&apos;); /** MySQL主机 */ define(&apos;DB_HOST&apos;, &apos;192.168.100.30:6033&apos;); 此处连接的mysql数据库主机是proxysql读写分离的IP和端口 通过NFS共享图片目录准备NFS主备后端存储： 1.这里nfs主备用mysql的两台从服务来实现 yum install nfs-utils -y 一定要安装nfs-utils，实际环境测试不安装utils，访问nfs的速度很慢 准备共享目录： mkdir -pv /nfsdata/images 设置权限nfs共享目录权限 vim /etc/exports /nfsdata/images *(rw,no_root_squash) 2.实现主备NFS的图片同步 rsync -avrlopg /nfsdata/images/* 192.168.100.17:/nfsdata/images/ 在nginx+pfp-fpm的两台服务器挂载nfs的共享目录 showmount -e 192.168.100.16 显示该主机上可以挂载的nfs目录 1.挂载目录并设置开机自动挂载 因为wordpress的图片是保存在/data/nginx/wordpress/wp-content/uploads中的 所以要把该目录用nfs共享 1.vim /etc/fstab 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads/ nfs defaults,_netdev 0 0 写在fstab文件中一定要加_netdev选项,刚开机没有IP地址时，即使挂载不上也可以启动 2.也可以写在/etc/rc.d/rc.local中，因为该文件是系统启动最后加载的文件，此时 已经获取到IP地址了，当然可以实现自动挂载,要设置执行权限 vim /etc/rc.d/rc.local mount -t nfs 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads chmod +x /etc/rc.d/rc.local 3.备注： NFS共享，为了避免IP地址的问题，最好要配置一个DNS服务器来主机名和IP地址 挂载的时候最好使用主机名取挂载，即使IP地址出问题了，也可以临时在DNS服务器上 修改主机名和IP地址的对应关系. 编译安装nginx实现负载均衡nginx调度服务器：192.168.100.10 1.解压并编译 tar xf nginx-1.12.2.tar.gz cd nginx-1.12.2 ./configure \ --prefix=/usr/local/nginx \ --with-pcre \ --with-http_stub_status_module \ --with-http_ssl_module make &amp; make install 2.修改配置文件实现七层调度 在http上下文定义： vim /usr/local/nginx/conf/nginx.conf upstream blogs { server 192.168.100.3:80 weight=1 max_fails=3 fail_timeout=100s; server 192.168.100.4:80 weight=1 max_fails=3 fail_timeout=100s; hash $remote_addr consistent; (做会话保持) } server { listen 80; server_name www.lkblog.net; index index.html index.php; location / { proxy_pass http://blogs; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; add_header X-Via $server_addr; proxy_next_upstream http_502 http_504 error timeout invalid_header; } } 3.启动服务 /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx -t /usr/local/nginx/sbin/nginx -s reload 配置完后重新加载 启动各服务，并测试读写-注册完后生成数据库各表-上传图片测试，在nfs也是可以看到的，说明挂载是成功的 -浏览站点，因为是普通的http请求，用轮询的方式是没问题的 -对于登录页面，如果没有做会话保持是登不上去的，这也是为什么Nginx负载均衡器上做源地址hash的原因. 升级wordpress版本版本更新需要注意最好不要跨大版本进行更新，一般更新也是在大版本下进行小版本的更新 以下以wordpress-5.0--&gt;wordpress-5.0.2 步骤： 1.停止Nginx服务 2.备份元数据或删除 3.升级版本 4.启动服务 简单的以脚本方式实现一台wordpress升级 vim updates.sh ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx -s stop&quot; ssh 192.168.100.4 &quot;rm -rf /data/nginx/wordpress/*&quot; scp wordpress-5.0.2-zh_CN.zip 192.168.100.4:/data ssh 192.168.100.4 &quot;unzip wordpress-5.0.2-zh_CN.zip -d /data/nginx/wordpress/&quot; ssh 192.168.100.4 &quot;chown -R www.www /data/nginx/wordpress/&quot; ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx&quot;]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK和搜索引擎]]></title>
    <url>%2F2018%2F03%2F22%2FELK%E5%92%8C%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[搜索引擎和ELK日志分析平台 –网站架构 1.网站架构中的日志分析的作用： 如上图示：有两个个问题： 1.如果需要记录日志来分析用户行为的话，这个日志是在接入层（haproxy）?缓存层（varnish）? 后端服务器层（nginx+tomcat）?的哪个层级去收集？ 其实都是可以的，但在在哪个层级去收集还是有很大区别的!!! 2.很大站点前端一般都是有CDN负责响应用户80%的请求时，那么由CDN负责响应的请求我们也是收集不到的，但好在有一个根本性问题： 作为一个动态站点几乎所有原始资源的表现都为动态的，在动态内容当中键入了很多URL，这些url引用了静态内容； PV的统计： 首先统计PV时不是把每个资源都统计一次，而是第一次访问这些资源的入口称为一次页面访问PV,因为一个页面中包含很多 资源的链接，因此统计一个网站的PV量是打开一个站点的主页面和对这个主页面下每一个入口的访问； PV就是指网站有多少个用户可尝试访问的入口，只需要分析日志中用户请求的URL即可，统计时做模式匹配把那些可以认为 是访问入口的过滤出来即可； UV的统计： UV是指接入的IP，只需要过滤日志中的不同IP即可； 3.通过日志分析用户行为形成推荐系统： 除了统计PV、UV这些，对于电商站点来说：比如在1W件商品中统计出哪些商品在哪个季节是受用户欢迎的、甚至可以统计出不同区域 性对不同商品的喜好程度作分析后在前端就可以对用户进行商品推送； 2.分布式日志分析平台： 日志分析平台的压力分析： 小规模场景： 因为对web应用来说因为它是不能通过rsyslog来收集的，但是实现日志分析平台也是很容易的，只需要在每一个待收集日志的服务器上 监控它的日志文件，当它产生新的日志数据时把它的数据流读出来通过一些协议（如文件共享协议、http协议等）发送到一个专门的服务 器上即可，在较小规模的场景中这样做是没问题的； 大规模场景： 如果每秒钟需要收集的日志量达到近万条，那么本地硬盘的IO是无法承载的，更重要的是我们收集日志的目的是对日志做分析那就涉及 更大的读写，因此一旦单个节点承载不了就需要使用分布式系统； 分布式存储和分布式系统： 1.首先分布式存储很多是不支持创建完修改、不支持追加式写入的、不支持随机访问，但对于日志来说它是流式化数据、不断的产生， 因为分布式存储不适用于日志分析平台； 2.因此不同的存储特性决定着它能够存储的数据有哪些，但mysql支持存储流式化数据、随时可以insert数据；再比如Nosql中的 mongoDB、elasticsearch也支持随时insert数据； 3.像这种存储系统和文件系统是两种不同业务、应用场景中的不同的存储解决方案； 4.但是对于关系型数据库mysql来说它本身的并发能力有限，因为它对事务有要求的情况下数据的插入、检索是非常慢的，在日志分析 存储平台这种高并发场景下是不适合的；虽然mongoDB天生支持分布式shard功能，但是在高并发场景的查询场景下它 自带的sql查询接口能力也是很有限的； –搜索引擎工作原理 3.搜索引擎 1.全文搜索 因此这时就需要一个搜索引擎来完成，只需要建立关键字他就可以完成全文搜索；所谓全文搜索是指可以针对整个文档中的任何一个 单词进行搜索（而对于mysql而言如果要搜索的字段出现在中间那左侧就只能使用通配就无法用到索引了），而在海量数据中没有索引也就没有意义了； 2.程序=算法+数据结构 1.因此搜索引擎它一定能够完成全文搜索、实现任何一个关键字搜索、更智能化的模糊匹配的工具，这种工具就是搜索引擎，它必须 是一个建立在它已有的数据模型之上来完成这种功能； 2.这就是为什么说程序=算法+数据结构组成的： 1.对于mysql的存储结构来讲：它的程序称为sql引擎、底层的存储机制为一种数据结构； 2.几乎每一种存储系统都是由两种层次组成：内部的存储结构+前端的访问接口 如文件系统只提供访问接口不提供程序 3.搜索引擎的组成： 1.索引链：能够让数据存下来并构建索引，这时搜索引擎的根本 索引链如何生成索引？ 1.收集数据后先检索原始内容 2.根据原始内容创建成文档： 对网页很容易构建成文档，但是对图片、PDF等是无法构建成文档的 3.对文档进行分析切词后构建出倒排索引 2.搜索组件： 通过索引链将数据存储构建索引后，用户可以通过前端的搜索组件来进行关键词 1.构建查询 搜索组件需要在构建查询时也是需要将用户提交的标签移除，然后再做切词，切词的过程是一个复杂的过程涉及很多 逻辑关系，然后再运行查询； 2.运行查询 3.数据的来源： 1.数据可以是拉取（pull）和推送（push）两种方式； 爬虫属于pull方式，而像日志收集只需要在web服务器上部署agent监控日志文件推送过来即可； 2.数据队列 如果数据量较大时可以在前端做一个缓存队列或者分布式队列，然后服务器再从这个队列上取出数据并构建索引即可； 4.切词和倒排索引 对文档分析最重要的就是做切词，切词的结果无非就是让搜索变得更容易，但是如何切词、切词方式、如何做语法修正等等这就 需要一个很强大的分析引擎! 4.开源软件实现搜索引擎功能的 1.Lucene 1.lucene是apache开源项目，但是lucene只是实现了索引链它没有提供前端的可用界面和不能自己获取原始内容； 2.lucene可以把获取到的原始内容做分析构建出文档、做文档分析、创建出索引，因此lucene只是一个开发库需要开发出接入 lucene的API进行搜索和展示给用户； 2.Elasticsearch elasticsearch仅仅是搜索引擎中的一部分，它的核心是Lucene 5.数据获取组件： solr,Nutch,Grub Lucene：搜索引擎中的索引链组件搜索引擎之所以能搜索，关键就是后台的索引构建组件Lucene,elasticsearch是在lucene基础上建立的搜索组件； 1.文档：Document 1.文档是Lucene中最重要的，文档是索引和搜索的最原子单位，它是包含了一个或多个域的容器； filed:也就是键值对中的value,真正搜索时是对value进行搜索的 2.lucene提供类似关系型数据库的存储和查询能力，但是lucene没有确定的全局模式 全局模式意思是lucene不像sql数据库中的表一样，它内部是无schme的，每一个文档结构都无需事先定义好结构的，这和MongoDB是一样的； 3.域 1.创建域时可以为域指定多个选项来控制lucene在将文档添加进域索引后对该域可以执行哪些操作，这个过程通常称为域的分析过程； 2.域本身的选项可以分为几种独立类型：比如：索引选项、存储选项、域向量使用选项等等，这些都是涉及到搜索引擎底层的复杂概念； 索引选项： 索引选项主要用于通过倒排索引来控制文本是否可以被搜索，意思是每一个文档中的内容只有称为索引中的项它才能被搜索； 1.Index:ANYLYZED 表示使用分析器对某一个filed上加一个Index:ANYLYZED选项，那么这个field中的value要被切词并放在倒排索引中去， 那么这个filed中的每一个分词都可以被搜索； 2.Index:Not_ANYLYZED 表示对filed仍然做索引但不做分析（不切词），即把这个filed的vaule当作一个词而不做切词了； 3.Index:ANYLYZED_NORMS 类似Index:ANYLYZED，因为Value中每个词的出现是有权值的，ANYLYZED_NORMS就表示虽然也会会value做切词，但不会 在索引中存储token的NORMS（加权基准）信息； 4.Index:Not_ANYLYZED_NORMS 类似于Index:Not_ANYLYZED，表示不对value切词，也不存储token的NORMS（加权基准）信息； 5.Index:NO: 表示不对此域的值进行索引，因为不能被搜索 lucene就是通过这5个索引选项来决定一个域是否可被搜索的!!! 存储选项: 定义是否需要存储域的真实值； 表示是否存储这个filed分析前的真实值 store:YES 存储真实值 意味着原始字符串还要保存在索引中需要占用额外空间 store:NO 不存储真实值 域向量使用选项： 用于在搜索期间该文档所有的唯一项都能完全从文档中检索时使用； 4.文档和域的加权操作 加权操作是指搜索时多个文档都出现某一值，哪一个文档应该排在前面就称为加权值； 默认情况下所有文档都没有加权值或者加权值都为1，加权计算标准： 5.搜索： 1.查询lucene索引时，它返回的是一个有序的scoreDOC对象，因为lucene是JAVA语言开发的是纯对象的编语言，因此他返回的每一个东西都是对象； 2.有序的scoreDOC对象？ 查询时，lucene会根据加权标准等为每一个文档计算一个score，并根据分值进行排序，因此它是一个是根据评分返回的有序的对象； 3.API Lucene要想完成查询，它提供了大量的API,因为lucene只是一个库他需要API对外输出； IndexSearcher:搜索索引入口 Query及其子类： QueryParser:查询分析器 TopDocs: lucene每一个返回的结果为一个scoreDOC对象，这个scoreDOC对象会放在TopDocs数组中，因此它是用来保存某一次查询 操作当中分值较高的前10个； scoreDOC： 4.因此键入搜索的过程是： 通过IndexSearcher和Query及其子类build一个搜索，通过QueryParser来完成搜索分析，搜索结果会通过scoreDOC来返回， 而scoreDOC是放在TopDocs中评分最高的前10个结果； 6.lucene的多样化查询： 1.因为lucene查询最终都是调用IndexSearcher这个API来完成搜索的，而在IndexSearcher中有一个search方法，这个search方法 是一个类，而且完成搜索时还需要传入Query实例作为参数来进行； 2.而search方法又有很多种： 1.TermQuery：对索引中的特定项进行搜索 a.因为在倒排索引中有两个字段：项和文档出现的编号，因此TermQuery就是对索引中的特定项进行搜索的； b.Term是索引中的最小索引片段，每个Term包含了一个域名和一个文本值； 2.TermRangQuery: 在索引中的多个特定项中进行搜索，能搜索指定的多个域 3.NumericRangeQuery:数值范围搜索 搜索时指定数据类型是必要的，NumericRangeQuery就是指是做数值范围搜索的； 比如： 20、30abc、40sbc、60这个4个字串，当搜索20~60这个范围时使用NumericRangeQuery这个搜索方法就会把30abc、40sbc排除； 4.PrefixQuery: 前缀搜索，用来搜索特定字串开头的文档 5.BooleanQuery:用于实现组合查询 BooleanQuery不是专门做搜索的，而是为了实现组合搜索，它的组合逻辑有三种：AND,OR,NOT 6.PhraseQuery:词语搜索 能够根据位置信息定义对应文档 7.WildcardQuery：通配符 可以结合？或*来完成通配符查询的 8.FuzzyQuery:模糊查询 Elasticsearch：搜索引擎中的搜索组件–elasticsearch elasticsearch弹性搜索，是借助于apache的lucene的API在lucene之外又重新封装了一层实现搜索引擎当中的搜索组件； 1.功能增强： 1.ES除了实现搜索引擎当中的搜索组件功能之外，还额外新增了很多更强大的功能，因为如果仅是调用lucene来完成搜索组件的话它可能 只是一个简单的展示界面； 2.ES在lucene所提供的API基础之上，还把自己构建成分布式的将Lucene所提供的索引组建成shard形式分片分布于多个节点上，从而构建 成分布式实时查询的组件； 1.和sql中多个行组成表的概念不同的是：在lucene中很多文档（相当于行）组成的索引（相当于表）； 2.索引是怎么存到磁盘上的？ 1.在mysql中表只是逻辑组件上的概念，它最终还是需要存到磁盘上表现为物理文件，对于Innodb来说它放在表空间当中而且多 张表的索引数据都放在ibdata1中，对于MyISAM表来说它放在*.MYD中； 2.同样对于lucene也是一个索引也应该有对应物理文件，而且对lucene而言最关键的搜索组件是索引（它不像sql中需要单独存 储的数据组件），整个可被搜索的文档都存储在索引中，而索引本身是基础倒排机制来定义的； 3.ES为了使得lucene支持非常强大的并行存储和搜索能力，在一个es节点上是满足不了的，因此es在lucene基础上借助于lucene的功能进行了扩展： 它支持把lucene的索引自动切割成N片shard,每一个es节点上放一个shard,而且为了保证shard数据的高可用，es采用副本分片 的主从机制，当一个shard故障时会自动在底层进行补全，因此es是一个分布式的数据索引存储搜索引擎； 3.如何构建多个节点的es集群？ ES可以工作为单个节点，在高并发场景多节点集群性能更高，只需要在配置文件中定义cluster.name和node.name，集群中的成员就 可以自己通信、传递心跳信息探测决定集群中的节点个数； 4.ES是一个基于Lucene实现的开源、分布式、Restful的全文本搜索引擎； 5.此外它还是一个分布式实时文档存储，其中每个文档的每个filed会被自动加上Index:ANYLYZED，因此每个filed均是被索引的数据， 且可被搜索，也是一个带实时分析功能的分布式搜索引擎，能够扩展至数以百计的节点实时处理PB级别的数据； 2.ES的基本逻辑组件： 1.索引(index): 1.索引是文档的集合,索引是具有类似属性的文档的集合，类似于sql中的表; 2.在ES中索引名必须使用全小写字母，在ES中可以创建数量的索引，每一个索引的引用都是一依靠其名字来引用的，如kibana选择的 就是索引的名字； 3.一般来说，一个索引内部只存储一类文档，否则处理起来是极为不便的； 2.类型(type): 1.类型是索引内部的逻辑分区，它是根据用户的需求来定义的，一个索引内部可定义一个或多个类型； 2.类型其实就是那些拥有相同域的文档的预定义，相当于sql中表的表结构（即都有哪些字段和其字段名称）； 3.文档(document): 1.文档是Lucene索引和搜索的原子单位，它包含了一个或多个域filed,是域的容器；域就是指字段，文档要基于JSON格式存储； 2.每个域的组成部分：一个名字，一个或多个值；拥有多个值的域通常称为多值域，而且文档是可以嵌套的，这一点和mongoDB相似； 4.映射(mapping): 1.每一个原始数据需要先分析以后才能存储为文档再构建成索引，因此映射是指这个分析机制应该如何实现，分析过程涉及： 如何切词、过滤掉某些词等等； 2.除此之外ES还为映射提供了诸如将域中的内容排序等功能 3.因此类型是用来定义格式的，映射是用来定义原始数据应该如何被分析的!!! 3.ES的集群组件： Cluster:ES的集群标识为集群名称，默认为&quot;elasticsearch&quot; 节点就是靠此名字来决定加入到哪个ES集群中，一个几点只能属于一个集群； Node:运行了单个ES示例的主机即为节点 用于存储数据、参与集群索引及搜索操作，节点的标识依靠节点名：node.name Shard: 1.ES就是一把物理的Lucene大索引文件切成N个片shard分散分布的存储到多个ES节点上；每一个shard是一个独立且完整的索引； 2.创建索引时，ES默认将其分为5个分片shard,用于可以按需自定义； 3.Shard有两种类型： primary shard：主shard 1.主shard用于文档存储，每一个新的索引都会自动创建出5个主shard； 2.一旦新的索引创建出主shard后，数量是不能更改的除非删除重新创建； replica shard 1.replica shard是为主shard提供数据冗余的、查询时的负载均衡以提高搜索性能； 2.每一个主shard的副本数量可以动态修改，不够时可以按需增加副本shard; 4.ES Cluster的工作过程： 1.启动时，通过多播（默认）或单播方式在tcp/9300端口查找同一集群中的其他节点，并与之建立通信，依靠的是cluster.name判断是否 属于同一集群； 2.集群中的所有节点会选举出一个主节点负责管理整个集群状态，以及在集群范围内决定各shards的分布方式； 注意：在用户角度是没有主节点的，每一个节点都可以接受并响应用户请求； 3.集群是有状态的： green:正常状态 red:不可用 yellow:修复状态 1.如果集群中某一节点故障了，主节点会读取集群状态信息并启动修复过程进入修复模式，在此过程中主节点会检查所有 可用shard并确定各primary-shard及其对应的副本shard数量是否完整，此时集群处于yellow状态； 2.在yellow状态下，各副本shard均处于未分配模式，即此时只能使用主shard，副本shard是不可用的无法负载均衡读请求了； 4.ES集群工作过程中主节点会周期性检查各节点是否处于可用状态，当有节点处于不可用时都会启动修复模式，然后ES会自动将shard进行重新均衡， 5.ES的默认端口 参与集群的事务：tcp/9300 transport.tcp.port 接收请求：tcp/9200 http.port 6.Restful API 四类API： 1.检查集群、节点、索引等健康与否，以及获取其相应状态 2.管理集群、节点、索引及元数据 3.执行CRUD操作 4.执行高级操作，如：paping,filtering等 ES访问接口：tcp/9200 curl -X&lt;VERB&gt; &apos;&lt;PROTOCOL&gt;://HOST:PORT/&lt;PATH&gt;?&lt;Query_STRING&gt;&apos; -d &apos;&lt;BODY&gt;&apos; VERB:请求方法,GET,PUT,DELETE PROTOCOL:协议 http,https Query_STRING:查询参数 例如?pretty表示易读的JSON格式输出,做任何查询都可以加上此参数 BODY：请求的主体 比如： 1.查看ES工作是否正常 curl -X GET &apos;http://192.168.34.118:9200/?pretty&apos; 2.定期删除某个超过三个月的index DATE=`date -d &quot;2 days ago&quot; +%Y.%m.%d` LOG_NAME=&quot;logstash-redis-systemlog&quot; FILE_NAME=${LOG_NAME}-${DATE} curl -XDELETE http://172.20.103.29:9200/${FILE_NAME} 7.ES中几个重要的运维相关的API 1.Cluster APIs: health: curl -X GET &apos;http://192.168.34.118:9200/_cluster/health?pretty&apos; state:状态查看命令 curl -X GET &apos;http://192.168.34.118:9200/_cluster/state/{metrics}?pretty&apos; version:显示和集群相关的版本号，集群状态发生改变版本号自动加一； master_node：查询集群中的主节点是哪个 nodes：查看集群中的所有nodes及其ID号 stats:统计数据相关 curl -X GET &apos;http://192.168.34.118:9200/_cluster/stats/{metrics}?pretty&apos; reroute:重新路由，对某一次查询重新路由一次分开到其他节点上去实现 update settings:更新集群中的某一设定 curl -XPUT &apos;http://192.168.34.118:9200/_cluster/settings -d cluster.routing.allocation.awareness.attributes cluster.routing.allocation.awareness.force node stats:节点状态信息 curl -XGET &apos;&apos;http://192.168.34.118:9200/_nodes/stats&apos; 8.ES相关的插件Plugins 插件是ES很重要的部分，用户可以开发插件来扩展ES的功能，和ES相关的插件有近百种之多 下面列出和展示集群状态、探索集群内shard、index相关信息的几个常见的站点插件： 添加自定义的映射类型、自定义分析器、本地脚本、自定义发现方式 安装插件： 1.直接将插件放置于plugins目录中即可； src]# rpm -qpl elasticsearch-5.6.13.rpm /usr/share/elasticsearch/plugins #插件目录 2.使用plugins命令进行安装 站点插件： http://192.168.34.118:9200/_plugin/plugin_name 常见的plugins有：head、marvel、bigdesk、kopf等 9.CRUD操作相关的API ES中的索引会自动创建的，只需要像这个索引中插入文档即可 1.创建文档 curl -XPUT &apos;http://192.168.34.118:9200/students/class1/2?pretty&apos; -d &apos; &gt; { &gt; &quot;first_name&quot;: &quot;san&quot;, &gt; &quot;last_anme&quot;: &quot;zhang&quot;, &gt; &quot;age&quot;: &quot;20&quot; &gt; }&apos; { &quot;_index&quot; : &quot;students&quot;, &quot;_type&quot; : &quot;class1&quot;, &quot;_id&quot; : &quot;2&quot; &quot;_version&quot; : 1, &quot;created&quot; : true } 2.获取文档 curl -XGET &apos;http://192.168.34.118:9200/students/class1/2?pretty&apos; 3.更新文档 PUT方法会覆盖原有文档 如果只更新文档中部分内容，需要使用_update API curl -XPOST &apos;http://192.168.34.118:9200/students/class1/2/_update?pretty&apos; -d &apos; &gt;{ &gt; &quot;doc&quot;: {&quot;age&quot;: &quot;30&quot;} &gt;}&apos; 4.删除文档 DELETE curl -XDELETE &apos;http://192.168.34.118:9200/students/class1/2&apos; 5.查看所有索引 curl -XGET &apos;http://192.168.34.118:9200/_cat/indices?v&apos; 6.删除索引 删除索引，那么索引中的文档也会一并被删除 curl -XDELETE &apos;http://192.168.34.118:9200/students&apos; 10.查询数据 查询数据需要使用ES中的Query API,也是ES中最重要的API Query DSL:基于JSON用于构建复杂查询语言、诸多类型的查询操作 比如term query、phrase、range query、boolean query、fuzzy等； ES的查询操作执行分为两个阶段： 分散阶段： 将查询操作分散到shard所在节点上去，向所查询的索引中的所有shard发起查询的过程 合并阶段： 将所有shard返回的结果合并起来并返回给查询者； 查询方式： 向ES发起查询请求的方式有两种： 1.通过Restful request API查询，也成为query string; 2.通过发送Rest request body进行； 多索引、多类型查询 /_search:所有索引 #不建议用，因为数据量很大 /INDEX_NAME/_search:但索引 #不建议用，因为数据量很大 /INDEX_NAME1,INDEX_NAME2/_search:多索引 11.ES如何搜索？ 1.Mapping和Analusis: 1.如何搜索，要想理解搜索就需要理解映射（mapping）和分析（Analusis），才能够真正理解它是如何搜索的! 2.ES:对每一个文档，会取得其所有域的所有值，生成一个名为&quot;_all&quot;的域；执行查询时，如果在query_string未指定查询的域， 则在_all域上执行查询操作； GET /_search?q=&apos;Zhang San&apos; GET /_search?q=&apos;Zhang%20Sanfeng&apos; GET /_search?q=name:&apos;Zhang%20Sanfeng&apos; GET /_search?q=name:&apos;Zhang San&apos; 前两个：表示在_all域搜索 后两个：在制定的域上搜索 3.文档中的每个域可能存储为特定类型而非字符串string，因为all域和特定域的运行方式可能并不一样，在文档中域的数值存储支持的数据类型有： string、numbers、boolean、dates,这每一种在解析时可能并不完全一样； 查看指定类型的mapping示例： curl &apos;http://192.168.34.118:9200/students/_mapping/class1?pretty&apos; #可以查看class1这个类别内部字段mapping是如何定义的 2.ES中搜索的数据广义上可被理解为两类： types:exect：指定类型上做精确搜索 full-text:全文搜索 精确值：是指未经加工的原始值；在搜索时做精确匹配 全文搜索：用于引用文本中数据； 判断文档在多大程度上匹配查询请求：即评估文档与用户请求查询的相关度； 为了完成full-text搜索，ES必须首先分析文本，并创建出倒排索引，而且倒排索引中的数据还需要进行&quot;正规化&quot;为标准格式； 分词--&gt;正规化（=分析）--&gt;构建成倒排索引 12.分析器 分词+正规化=分析,而分析的这两步都需要由分析器进行：analyzer 分析器通常由三个组件组成： 1.字符过滤器 2.分词器 3.分词过滤器 这三个组件每一个都有N种方法实现，而且Lucene还内置了很多这种组件 ES内置的分析器： Standard analyzer:标准分析器 适用于各种语言的通用分析器，根据Unicode的标准进行分词的，也是ES默认的分析器； Simple analyzer：简单分析器 根据所有的非字母进行分词，只要不是字母就会被当成分词边界； Whitespace analyzer:空白文本分析器 只把空白字符当做分词的分隔符； Language analyzer:语言分析器 为多种语言分别提供不同的分析器 注意： 1.分析器不仅在创建索引时用到，在构建查询时也会用到，在搜索组件中将搜索请求提交给索引之前也需要先经过分析器： 把html标签去掉+切词+正规化 2.而且构建索引用的分析器类型必须和构建查询用的是同一种，不然是无法匹配查询的； logstachlogstach的输入输出插件 1.ES本身提供了分布式文档存储功能，同时又提供了非常具有弹性的搜索接口，这个搜索接口是基于lucene所提供的倒排索引等级制实现的； 2.logstach是做数据收集的,日志数据，logstach是高度插件化的，主要有四类： input：使用input插件去获取数据 codec:做编码的 filter：使用filter筛选过滤数据 output：将过滤处理后的数据输出到指定位置 input和output的插件有很多种，输出到ES集群只是它的一种方式而已，也可以是mysql; 3.logstach的工作流程： input--&gt;filter--&gt;output 如无需对数据进行额外处理，filter是可以省略的 4.input插件： 1.File:从指定的文件中读取事件流；类似tail -f test.txt 1.它是按行做区分的，每一行都被识别为一个事件，如果期望将多行识别为一个事件就需要使用multicodec这个编码器将多行编辑为 一行再对外输出； 2.logstach是使用linux内核中的FileWatch（Ruby Gem库）来监视文件是否变化的，支持以glogbing的方式去展开文件名因此可以监听多个文件； 3..sincedb FileWatch会把每一个文件读取的位置状态信息保存在隐藏的.sincedb数据库中，即使重启logstach它也不会重新读一次文件， 而是接着sincedb库中记录的位置往下读取； sincedb记录每个被监听文件的inode、major、number、minor number、pos、路径是在启用logstach进程用户的家目录的； 4.file插件还能自动识别日志的滚动操作， 2.udp： 1.通过udp协议从网络连接来读取message，其必备参数为port,用于执行自己监听的端口，host则指明自己监听的地址,可以使用0.0.0.0； 2.其他主机指向要此主机UDP：port发送数据即可 3.redis: 从redis获取数据，支持redis channel和lists两种方式； 5.filter插件： 用于在将event事件通过output发出之前对其实现某些处理功能，logstach也有很多filter插件，主要的有一个： 1.grok:文本格式化插件 1.grok是我们从web服务器的日志当中读取到日志事件并需要处理时必然用到的插件 2.grok是logstach最重要的插件之一，它主要用于分析并结构化文本数据，是logstach中将非结构化日志数据转化为结构化的可查询数据的不二之选； 支持处理syslog、apache、nginx日志； 如：它会把读取的行，每个字段都拆解开并命名转换成结构化的，使得logstach随后对日志分析能够进行； 3.默认情况下grok提供了120种模式，所谓的模式是指将大段文本拆解成结构化的文本数据，定义的路径在如下这个文件中，它里面 已经预定义了很多模式： patters都定义在grok-patterns这个文件中 ~]# rpm -qpl logstash-5.6.13.rpm | grep grok-patterns /usr/share/logstash/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-4.1.2/patterns/grok-patterns #patterns模式都被定义在这个文件中，具体信息查看该文本内容即可 #其实grok-patterns就是正则表达式的匹配模式 4.logstach格式中的grok语法格式： %{SYNTAX:SEMANTIC} SYNTAX:预定义模式名称 这个名称肯定是grok-patterns文件中已经定义好的模式名称，如果没有就需要自己自定义grok的模式了(见下文)； SEMANTIC：匹配到的文本的自定义标识符，管理员可以随便定义 5.grok应用示例： 原文：2.2.2.2 GET /index.html 10 0.01 结构化模式： %{IP:clientip} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:responsetime} 备注： 1.IP、WORD、URIPATHPARAM、NUMBER、NUMBER都是在grok-patterns已经存在正则表达式的模式名称，直接套用即可； 2.clientip、method、request、bytes、responsetime相当于是别名方便管理员知道此字段是什么意义； 3.当然了，具体每一段要使用grok-patterns中哪个预定义模式就需要理解清楚grok每一个默认模式是代表什么意思； 定义文件： ]# vim groksimple.conf input { stdin {} } filter { grok { match =&gt; { &quot;message&quot; =&gt; &quot;%{IP:clientip} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:responsetime}&quot; } } } output { stdout { codec =&gt; rubydebug } } 启动并测试： ]# /usr/share/logstash/bin/logstash -f groksimple.conf The stdin plugin is now waiting for input: 2.2.2.2 GET /index.html 10 0.01 #粘贴要测试的文本内容 { &quot;request&quot; =&gt; &quot;/index.html&quot;, &quot;@timestamp&quot; =&gt; 2018-03-10T05:40:46.116Z, &quot;method&quot; =&gt; &quot;GET&quot;, &quot;bytes&quot; =&gt; &quot;10&quot;, &quot;clientip&quot; =&gt; &quot;2.2.2.2&quot;, &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;node02&quot;, &quot;responsetime&quot; =&gt; &quot;0.01&quot;, &quot;message&quot; =&gt; &quot;2.2.2.2 GET /index.html 10 0.01&quot; } #根据自定义模式输出的格式 6.自定义grok的预定义模式的两种方法： grok的模式是基于正则表达式编写，其元字符与其它用到的正则表达式的工具awk/sed/grep差别不大； 1.直接使用模式文本定义标识符，如上述示例中 2.自己创建patterns目录，然后再filetr中通过patterns_dir指明目录加载即可； 自定义patterns中的模式的语法： Pattern_Name (?正则表达式) 7.匹配apahce和nginx日志 1.匹配apahce日志：这里只写filter filter { grok { match =&gt; {&quot;message&quot; =&gt; &quot;%{COMBINEDAPACHELOG}&quot;} } } %{COMBINEDAPACHELOG}是在grok_patterns中定义好的，直接引用即可 2.匹配nginx日志 NGUSERNAME [a-zA-Z\.\@\-\+_%]+ NGUSER %{NGUSERNAME} NGINXACCESS %{IPORHOST:clientip} - %{NOTSPACE:remote_user} \[%{HTTPDATE:timestamp}\] \&quot;(?:%{WORD:verb} %{NOTSPACE:request}(?:HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\&quot; %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} %{NOTSPACE:http_x_forwarded_for} #将上面信息添加到grok-patterns文件中即可 filter { grok { match =&gt; {&quot;message&quot; =&gt; &quot;%{NGINXACCESS}&quot;} } } #调用上面添加到grok_patterns的nginx的模式即可 2.当然也可以不用grok 1.因为在新版本的logstach的grok-patterns中，apahce、nginx、tomcat等是没有定义该日志模式的，如果想要收集它们的日志可以 在里面定义即可； 而web日志也无非就是combined、common、nginx、tomcat格式的!!! 2.当然我们有也可以把apahce、nginx、tomcat它们原有的非结构化日志格式先转换成Json格式，这样就需要在logstach通过grok来定义了； 方法：详见ELK日志收集实现文章 6.output插件 input的是实现数据获取的，经过filter过滤处理后就需要将结果保存到指定的存储中即可；而每一种output插件都是存储实现方案; 1.stdout：标准输出 2.elasticsearch：输出到ES集群，常用参数： hosts：ES主机集群列表，它是一个数组 index：索引，存储在ES集群的哪个索引中， 默认是&quot;logstach-%(+YYYY.MM.dd)&quot;,每天的日志信息都是单独存放的，会生成一个索引序列； 3.redis:输出到redis，常用参数 batch:true|false true表示一次可以压多个事件进去，false表示一次只能一个，默认是false host：redis服务器的IP列表，它是一个数组 port：redis服务器的端口，默认是6379 db:存储到redis的哪个库中，默认是0号库 data_type:数据类型：[&quot;list&quot;, &quot;channel&quot;] logstach使用redis做输入输出插件时有两种数据类型来保存logstach的数据 channel：频道，发布订阅 list:列表格式保存数据，一般使用list数据类型即可 key:channel或者list的名字 当然也可以使用动态名称，引用的是input中的type即可；]]></content>
      <categories>
        <category>日志分析平台</category>
        <category>elk</category>
      </categories>
      <tags>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现反向代理功能]]></title>
    <url>%2F2018%2F03%2F22%2Fnginx%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[Nginx实现反向代理服务器的配置 nginx实现反代的工作原理： 1.代理服务器需要注册监听端口，用来接收用户请求，而监听端口是可以被复用的，且一个端口可以接收N路请求. 2.代理服务器本地没有资源，当请求报文送达时，由于代理服务本身就是个web服务器，所以能够充分理解请求报 文的MIME类型，URL等，差别只是本来是需要通过IO加载本地资源的，但是由于本地没有，则会向后端服务器 去取资源，但是此时请求报文已经被完完整整的拆开了，是不能把请求报文发往后端的 3.所以在nginx中是由一个模块扮演成类似客户端浏览器角色的，把自己模拟成客户端程序，封装一个新的http请求， 向后端服务器发起请求. 4.而后端服务器会把响应报文发送给代理服务器，代理服务器则又会拆掉网络层封装，传输成封装，应用层封装， 看到响应报文的body主体部分，把主体部分拿出来重新封装成一个响应报文发回给客户端》 5.只要是向后端请求必然会再占用一个端口 6.代理服务器要维持两路连接，而且是彼此隔离且独立的 7.那么向后端发送的请求报文要不要带客户端请求中所独有的私有的信息数据？ 如果不传递，后端服务器是无法识别并相应的，必要时要把客户端的属性信息:请求 的url,用户认证信息等等重新封装到向后端发送的请求报文中，还是引用了客户端 发来的数据，而且代理服务器是可以修改请求报文的信息和响应报文中的信息 8.代理服务器可以操纵发往后端的请求和操纵响应给客户端的请求 9.这些也只有工作在应用层并且能识别应用层协议才可以实现的，如果再加一些访问控制 的功能，那么就可以做到四层防火墙做不到的访问控制能力，这也是代理服务器叫做 代理网关的原因，对于iptables和LVS是做不到的 10.面向客户端工作http/https协议，面向后端工作http,tcp,fastCGI,memcache，uwsgi(python的web框架) 等协议，那么这个能模拟客户端的模块就需要是多种专用模块 1.nginx作为代理服务器来说，面向于客户端和服务端可以代理多种协议 代理服务器又叫代理网关，因为工作在应用层可以控制用户访问请求的资源，具有防护功能 面向客户端： 一般是http/https协议：通过http模块实现 mail:简单邮件传输协议等 stream:stream模块实现代理四层协议：tcp/udp (nginx从1.9版本后可以实现四层负载均衡的) 代理后端服务器： nginx内嵌了很多客户端模块来适配不同的后端协议： http协议的服务器：ngx_http_proxy_modules模块 fpm服务器：ngx_http_fastcgi_module模块 memche服务器： 代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx) 1.nginx作为代理服务器是，代理客户端和后端服务器，在数据报文是有两段的： 1.客户端—&gt;代理服务器 2.代理服务器作为客户端—&gt;后端的httpd/fpm/memche服务器 而且代理服务器可以把客户端发来的数据报文进行修改重新封装发给后端服务器， 后端服务器响应给代理服务器的报文也可以被代理服务器修改，再响应给客户端 在设置中，可以通过不能功能体现出数据报文被如何修改的！ 2.作为代理配置和nginx作为web服务器差不多，只不过要把root/alias缓存proxy_pass 如果同时又root和proxy_pass，proxy_pass的优先级高 3.在location中将.php或者.jpg代理到不同的后端服务器上，可以实现资源请求的动静分离 实现了在一台代理服务器上的资源路由. ngx_http_proxy_module模块：1.Syntax: proxy_pass URL; Default: — Context: location, if in location, limit_except 代理http协议的主要功能，是将客户端的请求代理至后端服务的路径上 server { ... server_name HOSTNAME; location / { proxy http://host[:port]; 优先级高于server的root } #此处后面的/可加可不加 location /uri/ { proxy http://host/new_uri/; } location ~|~* /uri/ { proxy http://host; #此处最后不能加/ } ... } 特别注意1： http://HOSTNAME/uri --&gt; http://host/uri http://HOSTNAME/uri/ --&gt; http://host/new_uri/ http://HOSTNAME/uri/ --&gt; http://host/uri/； 路径映射，前后端的location和proxy_pass是映射关系,必要加/ 如果location是正则表达式路径，proxy_pass的路径必须没有/和URI，因为是正则表达 式，无法判断路径 1.加/就是映射，不加就会把前面用户请求时的路径补回来 2.前后端不一样时必定要加，一样时可加可不加 3.但如果localtion中使用了正则表达式模式，就一定不能加/，不加/的意思是指： 把用户请求的URL中除了地址的路径原样不动的补到host后面，客户端请求什么就补什么! 4.具体区别看下文示例 特别注意2： nginx中有两个模块都有proxy_pass指令。一个是ngx_http_proxy_module 模块，一个是ngx_stream_proxy_module模块。 1.ngx_http_proxy_module 中的 proxy_pass 用法如下： 语法: proxy_pass URL; 场景: location, if in location, limit_except 说明: 1.设置后端代理服务器的协议(protocol)和地址(address),以及location中可以匹配的一个可选的URI。 2.协议可以是&quot;http&quot;或&quot;https&quot;。地址可以是一个域名或ip地址和端口，或者一个unix-domain socket 路径。 2.ngx_stream_proxy_module 中的proxy_pass用法如下： 语法: proxy_pass address; 场景: server 说明: 1.设置后端代理服务器的地址。 2.这个地址(address)可以是一个域名或ip地址和端口，或者一个 unix-domain socket路径。 3.关系和区别： 在两个模块中，两个proxy_pass都是用来做后端代理的指令。 1.ngx_http_proxy_module模块的proxy_pass指令作用于http上下文需要在location、location中的if、limit_except段中使用， 它是proxy_pass URL，需要提供域名或ip地址和端口外，还需要提供协议，如&quot;http&quot;或&quot;https&quot;，还有一个可选的uri可以配置； 2.ngx_stream_proxy_module模块的proxy_pass指令只能在server段使用,只需要提供域名或ip地址和端口。可以理解为端口转发， 可以是tcp端口，也可以是udp端口，不需要写protocol协议!! 路径映射示例： 前端请求：http://www.blog.com/images/logo.jpg 在nginz中/images/logo.jpg就URI，而在location中配置的也都是URI 第一种情况： location / { proxy_pass http://192.168.34.118; #此处不加/ } location /images/ { proxy_pass http://192.168.34.118; #此处不加/ } 发送到后端都是：http://192.168.34.118/images/logo.jpg 分析： 这两个例子中proxy_pass都不加/时，客户端请求中的URI是/images/logo.jpg就把这个URI补到proxy_pass后，此时和location中的路径无关! 第二种情况： 2.1.location / { proxy_pass http://192.168.34.118/; #此处加/ } 发送到后端：http://192.168.34.118/images/logo.jpg 2.2.location /images/ { proxy_pass http://192.168.34.118/; #此处不加/ } 发送到后端：http://192.168.34.118/logo.jpg 分析： 首先proxy_pass的uri和location的路径是映射关系的，映射是指： 需要分析客户端请求的URI时，要把location的这部分在客户端请求的URI中去掉，然后把余下的部分补到proxy_pass的/后!! 1.2.1中的映射关系是：/=/,所以把images/logo.jpg补到proxy_pass的/后就是：http://192.168.34.118/images/logo.jpg 2.2.2中的映射关系时：/images/=/,所以把logo.jpg补到proxy_pass的/后就是：http://192.168.34.118/logo.jpg 2.从上面四个例子可以明显看到映射关系和带不带/是有着重要关系的!再看下面两个例子； 第三种情况： location / { proxy_pass http://192.168.34.118/bbs/; } 发送到后端：http://192.168.34.118/bbs/images/logo.jpg 分析： 此时的映射关系是：/=/bbs/,所以要把images/logo.jpg补到proxy_pass的/bbs/后就是：http://192.168.34.118/bbs/images/logo.jpg 第四种情况： location /images/ { proxy_pass http://192.168.34.118/bbs; #此处bbs后没有/ } 发送到后端：http://192.168.34.118/bbslogo.jpg 分析： 此时的映射关系是：/images/=bbs,所以把logo.jpg补到proxy_pass的/bbs后就是：http://192.168.34.118/bbslogo.jpg!! 这样的话，那么客户端请求时肯定会报错了!! 第五种情况： location ~* \.(jpg)$ { proxy_pass http://192.168.34.118; } 发送到后端：http://192.168.34.118/*****.jpg 分析： 这时由于location中是正则表达式，无法判断客户端请求的路径，所以需要都加到proxy_pass的后面，所以proxy_pass后不能带任何路径!! 总结： 1.location中的路径和proxy_pass中的路径是映射关系! 2.当proxy_pass后没有带任何路径时（没有/|/bbs/|/bbs），只需要把客户端请求的URI全部补到proxy_pass即可； 3.当proxy_pass后不管只有/还是/abac[ |/]时，这里的location中的路径和proxy_pass中的路径是映射关系，这时就需要location中路径和proxy_pass路径是否一样了!! 4.当location中是正则表达式时,这个路径是无法映射的！这时只能客户端请求什么，然后在proxy_pass后补什么！因此location是 正则表达式时，proxy_pass后一定不要写任何Uri,否则nginx -t就会报语法错误！ -前后端路径映射 2.proxy_set_header field value; 前面说过代理服务器可以修改客户端请求数据报文的信息发送给后端服务器，而对于后端 服务器来说看到的请求报文的源IP一直是代理服务器，但是可以通过修改参数是的后端 服务器看到的IP地址是真正的客户端地址而不是代理服务器！ 设定发往后端主机的请求报文的请求首部的值；Context:http,server,location 设置代理服务器： proxy_set_header X-Real-IP $remote_addr; 或者 proxy_set_header X-Real-HOST $host;将 或者 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 然后修改后端服务器的日志格式： LogFormat &quot;%{X-Real-IP}i %l %u %t \&quot;%r\&quot; %&gt;s %b&quot;重启httpd服务即可 此时，后端服务器看到的IP就是客户端的IP了，所以可以设置任何真实的信息传递给后端服务器 Nginx代理Web服务的Proxy缓存功能Nginx是一个高性能的web服务器，尤其在高并发和处理静态页面的时候有先天的优势；很大一部分得益于缓存的开启，缓存的实现逻辑 * 此处是作用于http的上下文，因为每个代理模块都有缓存功能，但是不能混用 * 要想使用proxy的缓存功能，必须先在nginx中定义出一个缓存空间出来，然后再引用！ * 定义缓存所以列表：对文件进行hash生成hash串，hash串是16进制数字，如果把hash串的前三位数字，按照数字放在对应的层级生成一个三级索引列表 * 根据实际情况定义缓存层级，每多一次就是对磁盘IO的消耗，灵活定义缓存层级很有必要，比如一层以1个16进制数就是16个目录，2个16进制数就是2^8=256个目录，可以通过增加每次的级数，减小层数，对磁盘的IO消耗就降低了 nginx的缓存功能： 不一定启用nginx缓存，可以使用varnish,或者CDN 只有真正需要启用时，才会启用nginx缓存 3.proxy_cache_path nginx作为代理服务器是可以使用缓存功能的 定义缓存功能键也就是索引，是放在内存中的 定义可用于proxy功能的缓存；Context:http的上下文 proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 4.proxy_cache ksys_zone的name | off; 指明要调用的缓存，或关闭缓存机制；Context:http, server, location 5.proxy_cache_key string; 虽然定义了缓存，还需要定义键，而这个键就是用户访问的地址; 1.为了避免后端有两台server_name有一模一样的URI,造成缓存索引出错，这里引入 了更多的差别数据，把整个访问路径都引入进来进行hash值缓存. 2.然而把整个url都引入进来，也会有问题，比如一个server有两个主机名，路径本 来就应该是相同的，如果引入了全路径则造成缓存不能命中了 3.所以如何定义这个&quot;键&quot;是根据不同场景使用的 默认值：proxy_cache_key $scheme$proxy_host$request_uri; 有时也可以定义为：$request_uri 所以根据不同使用场景proxy_cache_key的值需要修改 6.proxy_cache_valid [code ...] time; 通过定义不同的响应码来定义不同的缓存时长；(也可以统一为一个值) 7.proxy_cache_use_stale 当后端服务器有问题时，是否能够用过期的缓存资源响应客户端请求，默认是关闭的 proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...; 8.proxy_cache_methods GET | HEAD | POST ...; 设置客户端通过什么方法查询时，才调用缓存功能 9.proxy_hide_header field; 隐藏发送给客户端的响应报文的信息；f12中的header中看到的 默认nginx在响应报文中不传递后端服务器的首部字段Date, Server, X-Pad, X-Accel-等，用于隐藏后端服务器特定的响应首部 代理服务器请求后端服务器的几个超时时长： 10.proxy_connect_timeout time; 定义代理服务器后端服务器发请求的三次握手的连接时长 默认为60s，最长75s,不需要调 11.proxy_read_timeout time; 从后端接收响应报文的超时时长 12.proxy_send_timeout time; 连接建立后，向后端发送请求报文的超时时长 示例： 先在http上下文中定义缓存； proxy_cache_path /data/cache/nginx levels=1:1:2；keys_zone webcache:10m max_size=2G; 再在server或者location中调用缓存和设置&quot;键&quot;以及过期时长； location ~* \.(jpg|gif|jpeg)$ { proxy_pass http://172.17.0.2; proxy_cache webcache; proxy_cache_key $request_uri;(这里根据不同场景定义) proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; proxy_cache_methods GET HEAD; proxy_cache_use_stale error timeout http_500 http_502 http_503; 这样就表示把缓存放在/data/cache/nginx中,最好是固态硬盘，磁盘IO越快，索引 查询的速度越快，定义了1:1:2三层路由索引，第一层16个目录，第二层16个子目录 第三次256个子目录 ngx_http_headers_module模块：操纵响应报文首部nginx中的内嵌变量 区别于proxy_set_header： 是代理服务器把客户端请求报文中的某些信息通过修改代理服务器请求报文首部的方式发送给后端服务器 headers： 代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值；达到隐藏 某些信息不发给客户端。 1.add_header name value [always]; 添加自定义首部； add_header X-Via $server_addr; 或者 add_header X-Accel $server_name; 发送给客户端的响应报文时，显示真正的后端服务器IP或者主机名 2.expires [modified] time; expires epoch | max | off; 响应缓存的缓存时长 用于定义Expire或Cache-Control首部的值； 示例： 可以在server或者location中定义 server { listen 80; server_name www.blog.com; root /data/html proxy_set_header X-Real-IP $remote_addr; location /bbs/ { proxy_pass http://172.17.0.2/; proxy_cache webcache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; proxy_cache_methons GET HEAD; add_header X-Via $server_addr; add_header X-Accel $server_name; } } Nginx代理后端fastCGI协议 1.fpm其实就是一种类似于httpd的MPM模型中的prefork模型 启用一个fpm主进程，生成n个子进程，由子进程内部的php解释器负责处理并发的多路 请求，再将在本地运行完的php页面程序处理结果响应给请求的调用者 2.fastcgi其实就是简装版的http协议，后端对应的php的fpm就是fastcgi协议的服务器后端 的解析fastcgi协议，而且还能够让fpm的子进程加载磁盘上的php程序文件在php解释器 中运行执行出结果 3.Php并不支持编译成nginx的模块，那么Nginx只能调fastcgi模块与后端的fpm(php)服务器 进行通信，实现LNMP的架构 4.真正与mysql等数据库通信的是php程序代码，即php到mysql的驱动模块，而不是php解释器 5.如上图，因为fpm对进程的管理能力较弱，可以用nginx与全端调度器去连接，而且nginx可 以根据fastcgi处理请求的并发数，在nginx处限制向后端的请求连接数，nginx可以实现 中间件进行流量控制的效果. 6.php管理自己子进程的方式有两种，static和dynamic动态和静态管理方式 7.实现fpm的负载均衡调度，也是需要 ngx_http_fastcgi_module模块：1.fastcgi_pass address; address为fastcgi server的地址； location, if in location； 如：fastcgi_pass localhost:9000; http://www.ilinux.io/admin/index.php --&gt; /admin/index.php (uri) /data/application/admin/index.php 2.fastcgi_index name; fastcgi默认的主页资源; web的是index.html,php应该为index.php 如：fastcgi_index index.php 3.fastcgi_param parameter value [if_not_empty]; 1.由于动态站点在处理请求时，需要取得客户端在连接请求报文中的很多信息(IP,请求 方法,flag,param等)，所以nginx代理必须把保存在变量中与客户端连接状态的 数据，原样的传递给后端的fpm-server或fastcgi. 2.但是保存在nginx的变量名格式和fastcgi的变量名表示格式是不一样的，nginx的 是$+全小写的变量名，fpm是全大写的变量名 3.安装nginx默认就带有/etc/nginx/fastcgi_params,这个文件记录了需要向后端 fpm传递的所有变量. 4.除了传递变量，还需要将请求的uri与后端fpm服务器的路径建立映射关系，即定义 fpm上存放请求页面资源的真正路径. 配置示例： 比如先起一个fpm的容器：并且将动态资源保存在php容器的/data目录下 docker run --name php1 -d -v /data/php1:/data php:7-fpm-alpine 在nginx代理上如下设置： location ~* \.php$ { fastcgi_pass 172.17.0.4:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; include fastcgi_params; } fpm的状态监控4.php的状态监控 1.fpm的进程有static和dynamic两种管理方式，而且为了监控fpm是否正常工作，fpm的 配置文件中内嵌了/pm_status和/ping两个url来监控，status用来输出内嵌信息的 ，而默认是通过fastcgi协议显示的，不能直接看到状态信息，所以可以通过http协 议进行反代来检测fpm的工作状态. 2.可以通过显示监控状态的值，再通过ab,JMeter等工具进行压力测试，调整fpm的实际 场景下的并发访问量 配置示例：通过/pm_status和/ping来获取fpm server状态信息； location ~* ^/(status|ping)$ { fastcgi_pass 172.17.0.2:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; include fastcgi_params; } 测试： 如下图可以通过http://192.168.34.107:8082/status?xml&amp;full 或者html、json格式输出并显示出来，而且还可以通过接口调用加入到zabbix监控中 fastcgi的压力测试和缓存功能a.fastcgi的动态资源缓存意义更大，因为php不用每次都执行代码了 b.要使用缓存就需要先定义缓存； c.因为后端动态资源服务器是有用户认证和用户支付的资源的，为了信息安全对动态资源的缓 存一定不要缓存包含用户信息的资源 定义缓存：和proxy的缓存是不能兼容的，需要单独定义(在server外,http的上下文定义) 4.fastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义； levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE leves=1:2:2 keys_zone=name:size k/v映射的内存空间的名称及大小 inactive=time 非活动时长 max_size=size 磁盘上用于缓存数据的缓存空间上限 调用缓存： 5.fastcgi_cache keys_zone的名称 | off; 调用指定的缓存空间来缓存数据；http, server, location 无定义默认使用的键，需要手动指定 6.fastcgi_cache_key string; 定义用作缓存项的key的字符串； 7.fastcgi_cache_methods GET | HEAD | POST ...; 为哪些请求方法使用缓存； 8.fastcgi_cache_min_uses number; 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； 9.fastcgi_cache_valid [code ...] time; 不同的响应码各自的缓存时长； 10.fastcgi_keep_conn on | off; 默认情况下，fastCGI响应一个请求后会立刻断开，如果是on状态会保持长连接 fastcgi缓存定义示例： http { fastcgi_cache_path /data/cache/fcgi levels=1:2 keys_zone=fcgicache:10m max_size=2G; server { ... location ~* \.php$ { fastcgi_pass 172.17.0.4:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; include fastcgi_params; fastcgi_cache fcgicache; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 301 1h; fastcgi_cache_valid any 1m; fastcgi_cache_methods GET HEAD; } 缓存性能测试： ab -n 1000 -c 50 http://192.168.34.107:8082/index.php 在缓存前和缓存后通过模拟50路并发请求测试响应时间]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix基础]]></title>
    <url>%2F2018%2F03%2F20%2Fzabbix%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[zabbix介绍 监控主要工作： 1.解决生产和测试环境遇到的问题 2.部署业务； 3.查看监控系统 查看服务是否出现问题和即将出现瓶颈等问题 如：mysql连接达到1500~2000时就变慢了；最近三个月的趋势 web服务的并发数达到一定值，就要考虑扩容了 实时监控服务是否down机，服务是否不可用，比如java服务内存溢出，tomcat由于内存溢出，导致访问异常，出现503，500等异常服务代码，如果zabbix对其做了监控，就可以实时及时的看到报警和展示，及时进行修复 4.监控系统是随着业务增加和服务器增加，在监控上不能出现瓶颈，不能因为监控系统的资源不够，导致监控项采集不完整和出故障时报警不及时等问题 2.如何规划监控 在大规模集群中是通过不同的群组来管理： 1.根据不同业务分组 2.根据虚拟机/物理机分组 3.虚拟机内部又根据业务划分很多组 Zabbix核心任务主流监控系统功能介绍： 数据采集：周期性时序数据 1.主机/对象：服务器、路由器、交换机、存储、防火墙、IP、URL、自定义监控对象... 2.采集目标：监控项，指标数据（metrics data） 数据存储： 存储系统： SQL: MySQL、PostgreSQL NoSQL：MongoDB、HBase、InfluxDB、Prometheus、redis ... rrd: Round Robin Database 数据： 历史数据: 每个监控项采集到的每个监控值 趋势数据: 趋势表里主要保留某个监控项一个小时内历史数据的最大值、最小值和平均值以及该监控项一个小时内所采集到的数据个数。 阈值：severity，可按照等级实现层级报警 告警：通过email, 短信, 微信,语音,故障自治愈 通过脚本将报警信息发送到公众号上 Zabbix四大核心任务： 采集：zabbix-server, zabbix-proxy,zabbix-agent 1.agentless SNMP、Telnet、ssh、IPMI、JMX(监控tomcat) #不能安装agent客户端的只能通过特殊协议来采集 #IPMI:服务器上的特殊接口，用来采集CPU温度和风扇转速等硬件进行监控 2.zabbix-server 核心组件，负责数据的存储、管理、查看 3.zabbix-agent 负责各节点的数据采集发送给server 4.zabbix-proxy 用于非常庞大的环境下是需要的：超过几百台服务器 多个agent--&gt;proxy--server #可以有效减少server端的端口和CPU性能消耗; 存储: zabbix database--&gt;mysql 展示： zabbix web：支持图形聚合 graph -&gt; screen -&gt; slideshow(将多个screen以幻灯片的方式进行轮流展示) 告警： host (host groups) &lt;---templates host --&gt; items --&gt; triggers --&gt; action (conditions, operations) #先创建模板，在模板里设置告警，然后把模板关联到某个主机上，使用模板的好处 是不需要在每个主机上都设置告警信息了. 1.安装Zabbix-server和数据库源码安装：zabbix-4.0.3.tar.gz版本 1.环境准备： 安装常用命令： [root@zabbix-server ~]# yum install vim iotop bc gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel zip unzip zlib-devel net-tools lrzsz tree ntpdate telnet lsof tcpdump wget libevent libevent-devel 安装依赖包： [root@zabbix-server ~]# yum install gcc libxml2-devel net-snmp net-snmp-devel libevent-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel –y [root@zabbix-server ~]# yum install /root/jdk-8u191-linux-x64.rpm #安装java-jdk 2.安装mariadb数据库 [root@mysql ~]# yum install mariadb-server mariadb -y [root@mysql ~]# systemctl start mariadb [root@mysql ~]# systemctl enable mariadb [root@mysql ~]# mysql -proot123 [root@mysql ~]# MariaDB [(none)]&gt; create database zabbix character set utf8 collate utf8_bin; #创建一个zabbix库，专门存放监控数据 [root@mysql ~]# MariaDB [(none)]&gt; grant all privileges on zabbix.* to zabbix@&quot;192.168.34.%&quot; identified by &apos;zabbix123&apos;; #授权zabbix用户有权限访问zabbix库任何操作 3.编译安装zabbix-server端 [root@zabbix-server ~]# cd /usr/local/src/ [root@zabbix-server src]# tar xf zabbix-4.0.3.tar.gz [root@zabbix-server src]# cd zabbix-4.0.3 [root@zabbix-server zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java [root@zabbix-server zabbix-4.0.3]# make &amp;&amp; make install [root@zabbix-server zabbix-4.0.3]# cd /usr/local/zabbix/ [root@zabbix-server zabbix]# cd etc/ 修改配置文件： [root@zabbix-server etc]# grep &quot;^[a-Z]&quot; zabbix_server.conf LogFile=/usr/local/zabbix//zabbix_server.log #日志路径 DebugLevel=3 #日志级别 PidFile=/usr/local/zabbix/zabbix_server.pid #pid路径 SocketDir=/usr/local/zabbix #zabbix目录 DBHost=192.168.34.126 #mysql的IP地址 DBName=zabbix #连接的数据名 DBUser=zabbix #连接数据的用户 DBPassword=zabbix123 #连接数据库的密码 DBPort=3306 #数据库的端口 Timeout=4 # LogSlowQueries=3000 # 准备启动脚本： [root@node02 zabbix-4.0.3]# cp misc/init.d/fedora/core/zabbix_* /etc/init.d/ [root@node02 zabbix-4.0.3]# cd /etc/init.d/ [root@node02 zabbix-4.0.3]# vim zabbix_server BASEDIR=/usr/local/zabbix PIDFILE=/usr/local/zabbix/$BINARY_NAME.pid #将启动脚本里的zabbix的目录修改为编译安装的路径 #将pid路径修改和配置文件的路径一致(编译目录) 创建用户： [root@node02 init.d]# useradd zabbix -s /sbin/nologin 修改zabbix编译目录权限： [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R 初始化zabbix数据库： [root@node02 ~]# cd /usr/local/src/zabbix-4.0.3 [root@node02 zabbix-4.0.3]# cd database/mysql/ [root@node02 mysql]# mysql -uzabbix -pzabbix123 -h192.168.34.126 zabbix &lt; schema.sql 启动zabbix: [root@node02 zabbix]# /usr/local/zabbix/sbin/zabbix_server -c /usr/local/zabbix/etc/zabbix_server.conf #通过编译生成目录下的二进制命令指定配置文件启动zabbix 查看端口： [root@node02 zabbix]# ss -tnl LISTEN 0 128 *:10051 #zabbix-server启动后监听在10051端口 2.安装zabbix-web页面zabbix的前端服务是PHP程序，需要安装httpd [root@node02 zabbix]# yum install php httpd #安装php和httpd [root@node02 zabbix-4.0.3]# mkdir /var/www/html/zabbix #创建zabbix目录 [root@node02 zabbix]# cd /usr/local/src/zabbix-4.0.3 [root@node02 zabbix-4.0.3]# cp -a frontends/php/* /var/www/html/zabbix/ #因为zabbix的前端程序都在解压的目录下，所以把其拷贝到httpd下的目录 启动httpd: [root@node02 zabbix]# systemctl start httpd 访问： http://192.168.34.118/zabbix –启动报错 解决报错信息： 1.安装依赖包： [root@node02 zabbix]# yum install php-gettext php-session php-ctype php-xmlreader php-xmlwriter php-xml php-net-socket php-gd php-mysql 2.更改vim /etc/php.ini参数： post_max_size = 8M 改为 post_max_size = 16M max_execution_time = 30 改为 max_execution_time = 300 max_input_time = 60 改为 max_input_time = 300 date.timezone = 改为 date.timezone = date.timezone = Asia/Shanghai 3.重启httpd,进入zabbix配置 注意： 如果在页面上连接mysql时出错，可以检查一下httpd_can_network_connect的值是不是on的； [root@node02 conf]# getsebool -a | grep httpd_can_network_connect httpd_can_network_connect --&gt; off 如果是off，需要修改成on [root@node02 conf]# setsebool httpd_can_network_connect 1 上述状态改变只是暂时性的，一旦系统重启，该变量状态将改变回初始状态，因此，可以使用如下命令永久性改变状态： [root@node02 conf]# setsebool -P httpd_can_network_connect_db on 4.配置完成后将zabbix.conf.php放到/var/www/html/zabbix/conf下 zabbix.conf.php保存了刚才在页面上填写的信息，可以修改 5.登录 账户：Admin 密码：zabbix 6.登录后： 1.确认zabbix server是running状态； 2.默认会有一个报警，因为zabbix-server上的zabbix-agent进程没启动; 3.在Administartion-Users-ADMIN模板中修改语言和默认账户密码 7.启动zabbix-server的agent服务 [root@node02 etc]# vim zabbix_agentd.conf Server=127.0.0.1 #被动模式下的Server的IP StartAgents=3 #agent进程起来之后，启动几个子进程收集日志 #需要启动起来 ServerActive=127.0.0.1 #主动模式下的Server的IP Hostname=Zabbix server #当前主机的IP地址 #hostname是zabbix中用于区分监控主机的有效值，必须保留且不能重复 即一定要与web页面上的配置--&gt;主机--&gt;模板--&gt;主机名称保持一致，基于设置的hostname来监控，一般是改成IP地址 8.启动zabbix-agent [root@node02 etc]# /etc/init.d/zabbix_agentd start #监听在10050端口 然后再web页面就可以看到主机zabbix server的ZBX为绿色正常状态了. 9.字体优化 将windows下或者网上下载合适的字体上传到zabbix上 [root@node02 ~]# cd /var/www/html/zabbix/fonts/ DejaVuSans.ttf root@node02 fonts]# grep &quot;DejaVuSans&quot; ../* -R Binary file ../fonts/DejaVuSans.ttf matches ../include/defines.inc.php:define(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;DejaVuSans&apos;); // font file name ../include/defines.inc.php:define(&apos;ZBX_FONT_NAME&apos;, &apos;DejaVuSans&apos;); 修改方式： 1.将上传的字体改成DejaVuSans.ttf把原来的字体删除 2.将上面两个文件中调用的字体修改为上传的字体名 在需要监控的主机上部署zabbix-agent1.环境准备： [root@zabbix-server ~]# yum install gcc libxml2-devel net-snmp net-snmp-devel libevent-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel –y [root@zabbix-server ~]# yum install /root/jdk-8u191-linux-x64.rpm #安装java-jdk 2.安装zabbix-agent [root@node01 src]# tar xf zabbix-4.0.3.tar.gz [root@node01 src]# cd zabbix-4.0.3 [root@node01 zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-agent [root@node01 zabbix-4.0.3]# make &amp;&amp; make install [root@node01 zabbix-4.0.3]# cd /usr/local/zabbix/ 3.配置zabbix-agent [root@node01 zabbix]# cd etc/ [root@node03 etc]# vim zabbix_agentd.conf PidFile=/usr/local/zabbix/zabbix_agentd.pid LogFile=/usr/local/zabbix/zabbix_agentd.log DebugLevel=3 Server=172.18.140.5 #被动模式下的server的IP ListenPort=10050 #agent的端口 ListenIP=0.0.0.0 #agent本机监听的地址 StartAgents=3 #启用几个agent子进程用于收集数据 ServerActive=127.0.0.1 #主动模式的IP(可以是server或者proxy) Timeout=30 #收集数据的超时时长，一定要设置成最长的30s ##上面的选项都是agent客户端的通用配置 Hostname=192.168.34.107 ##一定要写成每个agent客户端自己的IP地址 #因为server是依靠Hostname来区分客户端的 #AllowRoot=0 # User=zabbix # Include=/usr/local/etc/zabbix_agentd.userparams.conf # Include=/usr/local/etc/zabbix_agentd.conf.d/ # Include=/usr/local/etc/zabbix_agentd.conf.d/*.conf #用于存放自定义监控项和脚本的 UnsafeUserParameters=1 #需要改成1即启用特殊字符，因为脚本里需要特殊字符 # UserParameter= #自定义监控项(启用) 4.准备启动脚本并修改 ##此处在公司是通过ansible推送到各个主机上的 ##安装的zabbix路径都是/usr/local/zabbix的，所以启动脚本也都一样 ###创建用户也是通过ansible来管理的 [root@node03 etc]# cp /usr/local/src/zabbix-4.0.3/misc/init.d/fedora/core/zabbix_agentd /etc/init.d/ ##此处在公司是通过ansible推送到各个主机上的 5.创建用户 [root@node03 init.d]# useradd zabbix -s /sbin/nologin 6.修改zabbix目录权限 [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R 7.启动zabbix-agent [root@node03 init.d]# /etc/init.d/zabbix_agentd start 测试相关命令： 当把主机加入server时没有数据，可以先通过zabbix-get进行测试 [root@node02 bin]# cp /usr/local/zabbix/bin/zabbix_get /usr/bin/ [root@node02 bin]# zabbix_get -s 172.18.140.7 -p10050 -k &quot;agent.ping&quot; 1 #1表示172.18.140.7客户端时正常的 1.监控tomcat注意： 1.java gateway如果要监控的后端java程序比较多，最好部署在一台单独的服务器上； 2.使用阿里云上的java-gateway安装包，直接yum安装即可 https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-java-gateway-4.0.1-1.el7.x86_64.rpm1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071721.要想监控java-tomcat,需要先在编译安装zabbix-server时加--enable-java选项;2.监控逻辑： zabbix监控java服务的时候很特殊，并不是有agent和server直接监控的，而是在中间加 了一个代理层叫做java gateway，需要在tomcat服务中开启JMX服务(监听在TCP：12345 端口)，然后java gateway连接到JMX：12345端口，将监控项发给JMX，再将采集的数据发给zabbix-server.3.修改启动java-getway服务： [root@node02 ~]# cd /usr/local/zabbix/sbin/zabbix_java/ [root@node02 zabbix_java]# vim settings.sh LISTEN_IP=&quot;0.0.0.0&quot; #java-gateway监听的地址 LISTEN_PORT=10052 #java-gateway端口 PID_FILE=&quot;/usr/local/zabbix/zabbix_java.pid&quot; START_POLLERS=5 #启动多少线程数 #因为如果有后端100个java(tomcat)程序，最好设置20个线程，那就采集5次， 避免采集的很慢，根据实际情况修改 TIMEOUT=30 ##采集数据的超时时长，一定要设置成最长的30s 启动： [root@node02 zabbix_java]# /usr/local/zabbix/sbin/zabbix_java/startup.sh #监听在10052端口 备注： 如果是以单独的服务安装的java-gateway,可以通过systemctl来控制启动关闭！4.在zabbix-server上配置java-getway服务的地址和端口 [root@node02 etc]# vim zabbix_server.conf JavaGateway=172.18.140.5 #Java-gate的IP地址 JavaGatewayPort=10052 #Java-gate的端口 StartJavaPollers=5 #启动多少线程数要和java-gate配置文件中一致5.配置JDK环境： [root@node01 ~]# tar xf jdk-8u191-linux-x64.tar.gz -C /usr/local/src/ [root@node01 src]# ln -sv /usr/local/src/jdk1.8.0_191/ /usr/local/jdk #为了JDK升级方便，将其创建一个软链接，后期只要创建一个新的软链接即可 [root@node01 local]# vim /etc/profile export JAVA_HOME=/usr/local/jdk export TOMCAT_HOME=/apps/tomcat export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$TOMCAT_HOME/bin:$PATH export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar [root@node01 local]# source /etc/profile #是配置生效 [root@node01 local]# java -version #查看是否为安装的JDK版本6.配置tomcat [root@node01]# tar xf apache-tomcat-8.5.37.tar.gz -C /usr/local/src/ [root@node01]# cd /usr/local/src/apache-tomcat-8.5.37/ [root@node01 apache-tomcat-8.5.37]# cd webapps/ [root@node01 apache-tomcat-8.5.37]# bin/startup.sh #启动tomcat服务7.配置tomcat监控参数 #修改catalina.sh启动脚本，放在第一个非注释行的前面 [root@node01 apache-tomcat-8.5.37]# vim bin/catalina.sh CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote #启用远程监控JMX -Dcom.sun.management.jmxremote.port=12345 #默认启动的JMX端口号，要和zabbix添加主机时候的端口一致即可 -Dcom.sun.management.jmxremote.authenticate=false #不使用用户名密码认证 -Dcom.sun.management.jmxremote.ssl=false #不使用ssl认证 -Djava.rmi.server.hostname=172.18.140.6&quot; #tomcat主机自己的IP地址，不要写zabbix服务器的地址8.重新启动tomcat即可 [root@node01 etc]# /usr/local/tomcat/bin/startup.sh9.在zabbix监控页面配置 1.填写JMX的IP和端口 2.关联tomcat监控模板 3.导入制作好的tomcat模板，然后将主机关联到此模板即可.10.测试 如果window上安装了JDK，可以使用jconsole.exe进行登录测试JMX服务是否采集到数据 C:\Program Files\Java\jdk1.8.0_191\bin\jconsole.exe11.监控java排错方法 测试能否获取到java 当前已经分配的 线程数 # java -jar cmdline-jmxclient-0.10.3.jar - 192.168.15.203:12345 &apos;Catalina:name=&quot;http-bio-8080&quot;,type=ThreadPool&apos; currentThreadCount12.自制tomcat监控模板 busy-nio #nio线程达到某个值时，通知给管理员 –正常的tomcat的JMX状态 2.zabbix的主动模式和被动模式–zabbix监控架构 1.主动与被动 这是对于zabbix agent来说的工作模式 1.被动模式就是由zabbix server向zabbix agent发出指令获取数据，即zabbix agent被动的去获取数据并返回给zabbix server，zabbix server周期性的向agent 索取数据，这种模式的最大问题就是会加大zabbix server的工作量，在数百台服务器的 环境下zabbix server不能及时获取到最新数据，但这也是默认的工作方式; 而且在server上回打开很多随机端口； 2.主动模式是有zabbix agent主动向server索取监控项，根据拿到的监控项再去采集数据然后返回给zabbix server，不再需要zabbix serve进行干预，因此主动模式在一定程度上可减轻zabbix server的压力； 主动模式下，只会向zabbix server的10051端口发出请求连接，就不会有随机端口 3.基于zabbix-proxy代理实现监控–zabbix主动模式 1.zabbix_proxy zabbix 是一个分布式的监控系统，支持通过代理服务器zabbix proxy收集zabbix agent的数据，然后把收集保存在本地数据库并发送给zabbix server进行统一存储和展示； 2.优点： 1.更轻量，无图形化界面 2.临时保存在本地 可以独立采集数据并存储，临时的 3.易维护：配置完成后基本无需管理 4.报警通知： 代理服务器不发送邮件通知 5.独立数据库 保留少量最近数据 3.编译安装zabbix-proxy 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 1.环境准备： [root@node01]#yum install gcc libxml2-devel net-snmp net-snmp-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel java-1.8.0-openjdk-devel 2.创建数据库 MariaDB [(none)]&gt; create database zabbix_proxy character set utf8 collate utf8_bin; MariaDB [(none)]&gt; grant all privileges on zabbix_proxy.* to proxy@&apos;172.18.140.%&apos; identified by &apos;zabbix123&apos;; 3.安装zabbix-proxy [root@node04 zabbix-4.0.3]# useradd zabbix -s /sbin/nologin [root@node04 src]# tar xf zabbix-4.0.3.tar.gz [root@node04 src]# c zabbix-4.0.3 [root@node04 zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-proxy --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java [root@node04 zabbix-4.0.3]# make &amp;&amp; make install 4.初始化数据库 [root@node02 mysql]# mysql -uproxy -pzabbix123 -h172.18.140.7 zabbix_proxy &lt; schema.sql4.修改zabbix-proxy配置文件 ProxyMode=1 #0为主动，1为被动 Server=172.18.140.5 #被动模式下zabbix server服务器的地址或主机名 #如果proxyMode是0，就不需要填此地址 Hostname=zabbix-proxy-active #代理服务器名称，需要与zabbix server添加代理时候的proxy name是一致的！ LogFile=/tmp/zabbix_proxy.log DBHost=172.18.140.7 #数据库服务器地址 DBName=zabbix_proxy #使用的数据库名称 DBUser=proxy #连接数据库的用户名称 DBPassword=zabbix123 #数据库用户密码 DBPort=3306 #数据库端口 ################################################################### 框中的配置只会在主动模式下生效，被动模式不生效 ################################################################### ProxyLocalBuffer=3 #已经提交到zabbix server的数据保留时间(单位小时，最大720) ProxyOfflineBuffer=24 #未提交到zabbix server的时间保留时间(单位小时，最大720) HeartbeatFrequency=60 #心跳间隔检测时间，默认60秒，范围0-3600秒，被动模式不使用 ConfigFrequency=5 #建议时间短一点 #间隔多久从zabbix server索取获取监控信息 DataSenderFrequency=5 #需要改长 #数据发送时间间隔，默认为1秒，范围为1-3600秒，被动模式不使用 ################################################################### StartPollers=20 #启动的数据采集器线程数量(生产环境下尽量多点) StartHTTPPollers=5 #启动多少线程响应http的请求 JavaGateway=172.18.140.5 #java gateway服务器地址,当需要监控java的时候必须配置否则监控不到数据 JavaGatewayPort=10052 #Javagatewa服务端口 StartJavaPollers=5 #启动多少个线程采集数据和java-gate一致 ################################################################### !!!和性能相关的非常重要的两项优化!!! !!!zabbix-server和zabbix-proxy都需要优化这两项!!! zabbix保存监控项是放在内存中的，所以CacheSize默认的8M内存空间是不够的 在zabbix-proxy服务器内存较大时，一定要把这个值调大(2G/4G)！！ ################################################################### CacheSize=2G #保存所有主机的监控项而占用的最大内存 HistoryCacheSize=2G #保存监控历史数据占用的最大内存 HistoryIndexCacheSize=4M #建议改成128M TrendCacheSize=128M #建议改成128M ValueCacheSize=128M #建议改成128M ################################################################### HistoryCacheSize默认才16M，建议一定要改成做大的2G内存 ################################################################### Timeout=30 #监控项超时时间，单位为秒 LogSlowQueries=3000 #毫秒，多久的数据库查询会被记录到日志5.授权并启动： [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R [root@node04 zabbix]# /usr/local/zabbix/sbin/zabbix_proxy -c /usr/local/zabbix/etc/zabbix_proxy.conf #这里直接使用二进制命令指定配置文件启动了 或者 将yum安装的zabbix-proxy的启动脚本拷贝过来，修改里面的配置文件路径和二进制命令的路径即可启动. zabbix自动注册和自动发现1.自动发现：zabbix Server 主动发现所有客户端，然后将客户端登记自己的小本本上，缺点 zabbix server压力山大 （网段大，客户端多），时间消耗多。 自动注册：zabbix agent 主动到 zabbix Server 上报到，登记；缺点 agent 有可能找不到 Server（配置出错） 被动模式：默认，都是站在 agent 的立场上说话，agent 被 server 抓取数据 主动模式：都是站在 agent 的立场上说话，agent 主动的将数据发送给 Server 两种模式都是在 agent 上的配置文件配置的 1.1 自动发现（被动模式） 第一步：zabbix Server 安装完毕 （完成） 第二步：zabbix agent 安装完毕，Server=172.16.1.61 （完毕） 第三步：网页上配置自动发现规则 1.2 自动注册（主动模式） 第一步：zabbix Server 安装完毕 （完成） 第二步：zabbix agent 安装完毕，需要额外增加的配置 [root@node04 zabbix]# vim /etc/zabbix/zabbix_agentd.conf ServerActive=172.16.1.61 # Hostname=Zabbix server HostnameItem=system.hostname [root@node04 zabbix]# systemctl restart zabbix-agent.service –自动发现–自动发现规则–自动发现动作–自动发现1–自动发现条件–自动发现操作]]></content>
      <categories>
        <category>监控</category>
        <category>zabbix监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现web服务配置]]></title>
    <url>%2F2018%2F03%2F20%2Fnginx%E5%AE%9E%E7%8E%B0web%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[nginx安装和配置文件Nginx下载安装和模块使用说明手册 nginx安装： 源码编译,二进制安装，yum安装，要注意使用次版本为偶数的版本 nginx所说的高度模块化是指静态模块，如果编译安装了很多模块，启动时不管在配 置文件是否使用该模块，默认都是加载的，不过在Nginx的新版本中少量的动态模块 是可以按需加载的 而httpd是可以通过modprobe安装加载模块的 配置文件的组成部分： 主配置文件： /etc/nginx/nginx.conf 还包括 conf.d/*.conf和default.d/*.conf 对于同以功能的配置最好放到一个*.conf中，方便管理 /usr/lib/systemd/system/nginx.service Unit file文件 /usr/sbin/nginx 主程序文件 /usr/share/nginx/html/404.html /usr/share/nginx/html/50x.html /usr/share/nginx/html/index.html 页面文件 fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 启动和配置： yum install nginx -y （编译时按需加载模块即可） systemctl start nginx / nginx 备注： 在生产环境下只要是修改nginx相关的配置文件,一定要nginx -t先进行测试 再nginx -s reload使配置文件生效 配置： 主配置文件的配置指令： 指定生效的范围，三个上下文中 directive value [value2 ...]; 注意： (1) 指令必须以分号结尾； (2) 支持使用配置变量； 内建变量：由Nginx模块引入，可直接引用； 自定义变量：由用户使用set命令定义； set variable_name value; 引用变量：$variable_name 主配置文件结构： main block：主配置段，也即全局配置段；都是顶格写的 event { ... }：事件驱动相关的配置； http { server {} root proxy_pass server {} ... }：http/https 协议相关的配置段； mail { ... } stream { ... } 主配置段都不管是web服务、mail服务还是四层代理是都需要配置的，而且这三个功能一般是 不会一起使用的，至少http和mail功能是不一起使用的 Nginx的全局配置和优化必调参数项配置指令： main配置段常见的配置指令：全局配置 分类： 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置： 1、user，group,是默认运行nginx的用户和组，按需修改 2、pid /PATH/TO/PID_FILE; 指定存储nginx主进程进程号码的文件路径； 3、include file | mask; 指明包含进来的其它配置文件片断； 4、load_module file; 指明要装载的动态模块； 性能优化相关的配置： 1、worker_processes number | auto; worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数； auto：当前主机物理CPU核心数； 2、worker_cpu_affinity cpumask ...; worker_cpu_affinity auto [cpumask]; nginx进程的CPU亲缘性解释； 1.因为CPU有三级缓存，一级和二级是每个CPU所独有的，只有三级缓存是共享的； 2.将worker进程与cpu绑定，这个进程会在cpu本地缓存很多数据和状态信息 3.如果把这个进程调到其他cpu上，那么之前的缓存就失效了，从而影响了性能，而cpu的绑定则起到刚好的负载效果和性能 CPU MASK： 00000000： 0000 0001：0号CPU 0000 0010：1号CPU 0000 0100：2号CPU 0000 1000：3号CPU ... ... 0000 0111：表示0和1号和2号CPU； 3、worker_priority number; 指定worker进程的nice值，设定worker进程优先级；[-20,19] 4、worker_rlimit_nofile number; worker进程所能够打开的文件数量上限； 对于高并发的服务器来说至关重要，每一个连接都需要打开一个套接字，每一个套接 字的维持都需要一个文件描述符，默认情况下linux限制每个用户最多同时打开1024 个文件，所以并发数量很高时，并发数量受限于文件数量，因此对于高并发服务器来 说都需要修改ulimit数量(ulmit -a/-n number) 事件驱动相关的配置: events { ... } 1.worker_connections number; 事件驱动决定了单个worker进程所能够打开的最大并发连接数数量； 所以nginx最大并发连接上限= [worker_processes] * [worker_connections] 在要求高并发的服务器上这两个是必调参数 2.use method; 指明并发连接请求的处理方法； use epoll；是事件驱动模型得以运行的根本 3.accept_mutex on | off;是否打开mutex互斥锁 处理新的连接请求的方法； on意味着由各worker轮流处理新请求，默认为on Off意味着每个新请求的到达都会通知所有的worker进程；会造成进程抢夺请求的情况 调试、定位问题： 1、daemon on|off; 是否以守护进程方式运行Nignx；默认为on 2、master_process on|off; 是否以master/worker模型运行nginx；默认为on； 调试时，把只有主进程处理请求和以前台运行来查找错误原因 3、error_log file [level]; 默认级别 Nginx实现web服务的全局配置和主要模块1.Nginx无论是作为web服务器或者是web服务器的代理服务器，所有配置都在http的上下文 2.location和directory的区别 1.httpd和nginx作为web服务器都可以对用户访问的资源进行限制 2.&lt;Directory &quot;/var/www/html/images/&quot;&gt; 也可以写成 &lt;Location &quot;/images/&quot;&gt; http协议的全局配置匹配检查顺序：server_name和Port–&gt;location–&gt;if in location–&gt;匹配路径(root和alias) ngx_http_core_module:Nginx的核心模块Nginx不管作为什么功能，都要使用core核心模块 http协议上下文的相关配置： http { ... ... 是http的全局配置，共享给多个server使用 server { ... listen server_name root/proxy_pass (root是作为web服务器的，proxy_pass是作为代理服务器使用的) location [OPERATOR] /uri/ (类似于httpd的directory） ... } } server { ... } } 与套接字相关的配置： 1、server { ... } 配置一个虚拟主机； server { listen address[:PORT]|PORT; server_name SERVER_NAME; root /PATH/TO/DOCUMENT_ROOT; } server只能出现在http的上下文中，而且不能嵌套server 2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] 特殊设置：前两个尤为重要 default_server：设定为默认虚拟主机； 如httpd基于主机名配置的多个虚拟主机，访问时是由上而下匹配的 ssl：强制只能通过ssl连接提供服务； backlog=number：后援队列长度； rcvbuf=size：接收缓冲区大小； sndbuf=size：发送缓冲区大小；(默认值足以满足需求) 3、server_name name ...; 必然要使用通配符来设置虚拟主机名和设置优先级 1.支持*通配任意长度的任意字符；server_name *.baidu.com www.baidu.* 2.支持~起始的字符做正则表达式模式匹配；server_name ~^www\d+\.baidu\.com$ (\d匹配单个数字) 匹配机制优先级： (1) 首先是字符串精确匹配; (2) 左侧*通配符； (3) 右侧*通配符； (4) 正则表达式； (并发访问多时，不建议使用正则表达式匹配主机名，对服务器性能有很大消耗) 4、tcp_nodelay on | off; 在keepalived模式下的连接是否启用TCP_NODELAY选项 当为off时，延迟发送，合并多个请求后再发送 默认On时，不延迟发送 可用于：http, server, location 5.tcp_nopush on|off; 在sendfile模式下，是否启用TCP_CORK选项； 5.sendfile on | off; 是否启用sendfile功能； 和定义路径相关的配置： 6.root path; 设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径； root可以作用在http, server, location, if in location上下文中， 如果多有多层级的root，则精确到最内层的root生效 7.location [ = | ^~ | ~ | ~* ] uri { ... } 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置； 用户请求server_name--&gt;server--&gt;Location--&gt;if in Location 会根据正则表达式匹配的优先级匹配到一个最佳的路径 修饰符号： 修饰符匹配优先级：=, ^~, ~/~*，不带符号； 1.=：对URI做精确匹配； 2.^~：对URI的左半部分做匹配检查，不区分字符大小写； 左半部分是指scheme中不包含path和它之后的部分 如https://www.lk.tech/images/1.jpg的左半部分是https://www.lk.tech 3.~：对URI做正则表达式模式匹配，区分字符大小写； 4.~*：对URI做正则表达式模式匹配，不区分字符大小写； 5.不带符号：以URI为前缀的所有uri；通配性最高级location / 还可以在location中定义if这种三级路由选择 root /vhosts/www/htdocs/ http://www.lk.tech/index.html --&gt; /vhosts/www/htdocs/index.html server { root /vhosts/www/htdocs/ location /admin/ { root /webapps/app1/data/ } } –官方示例 8.alias path; 定义路径别名，文档映射的另一种机制；仅能用于location上下文； 注意：location中使用root指令和alias指令的意义不同； (a) root，给定的路径对应于location中的/uri/左侧的/； (b) alias，给定的路径对应于location中的/uri/右侧的/； 如： location /images/ alias &quot;/data/www/&quot;; alias定义的意思是即 /images/* = /data/www/* location /images/ { alias &quot;/data/www/&quot;; root定义的意思就是访问 /data/www/images/* 9、设置默认主页：index file ...; 默认资源；http, server, location； 10、error_page code ... [=[response]] uri; 例如：error_page 404 /404.html; location = /404.html { root &quot;/www/error_pages&quot;; } 11、try_files file ... uri; 定义客户端请求的相关配置 定义客户端请求的相关配置 12、keepalive_timeout timeout [header_timeout]; 设定保持连接的超时时长，0表示禁止长连接；默认为75s； 13、keepalive_requests number; 在一次长连接上所允许请求的资源的最大数量，默认为100; 14、keepalive_disable none | browser ...; 对哪种浏览器禁用长连接； 15、send_timeout time; 向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长； 16、client_body_buffer_size size; 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置； 17、client_body_temp_path path [level1 [level2 [level3]]]; 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量； 16进制的数字； client_body_temp_path /var/tmp/client_body 1 2 2 1：表示用一位16进制数字表示一级子目录；0-f 2：表示用2位16进程数字表示二级子目录：00-ff 2：表示用2位16进程数字表示三级子目录：00-ff 对客户端进行限制的相关配置： 18、limit_rate rate; 限制响应给客户端的传输速率，单位是bytes/second，0表示无限制； 19、limit_except method ... { ... } 限制对指定的请求方法之外的其它方法的使用客户端； limit_except GET { allow 192.168.1.0/24; deny all; } 文件操作优化的配置 访问控制和认证的两个模块ngx_http_access_module模块：实现基于ip的访问控制功能，比httpd的控制更简单 1.allow address | CIDR | unix: | all; 2.deny address | CIDR | unix: | all; http, server, location, limit_except ngx_http_auth_basic_module模块 实现基于用户的访问控制，使用basic机制进行用户认证； 1.auth_basic string | off; 2.auth_basic_user_file file; 需要先生成账号密码，而且htpasswd命令由httpd-tools所提供； htpasswd -c -m /data/.nginxpasswd tom htpasswd -b -m /data/.nginxpasswd haha haha123 如： location /admin/ { auth_basic &quot;需要提供用户密码&quot;;(提示信息) auth_basic_user_file /etc/nginx/.ngxpasswd; } ngx_http_stub_status_module模块：状态监控一般和监控系统一起用，可以在编译安装nginx时加上这个选项 可以通过脚本函数监控这七个数值，纳入到zabbix中进行图形化监控 为了不影响其他location，一般定义专用的location来监控nginx状态，放在server内即可 用于输出nginx的基本状态信息； Active connections: 291 当前的活动连接 server accepts handled requests 连接数，接收并处理的，， 16630948 16630948 31070465 Reading: 6 Writing: 179 Waiting: 106 中间三个是统计数据，其他四个是当前数据； Active connections: 正在处理活动状态的连接数； accepts：已经接受的客户端请求的总数；(tcp建立的连接数) handled：已经处理完成的客户端请求的总数；(客户端发送，nginx处理过的) requests：客户端发来的总的请求数；(建立tcp连接并发送的请求数) Reading：处于读取客户端请求报文首部的连接的连接数；(接收报文) Writing：处于向客户端发送响应报文过程中的连接数；(nginx发送报文) Waiting：处于等待客户端发出请求的空闲连接数； (已经读取未发送的) 用于监控nginx的连接数脚本 1.stub_status; 配置示例： location = /status { stub_status; } ngx_http_log_module模块：日志分析展示nginx官方日志变量说明 1.log_format name string ...; string可以使用nginx核心模块及其它模块内嵌的变量； 日志格式： $remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos; http_x_forward_for 表示被代理服务器的日志记录的访问的IP地址是代理服务器，为了在后端服务器上记录真实的客户端，需要启用这一项 实现：1.为nginx定义使用类似于httpd的combined格式的访问日志； 2.把combined的日志格式定义输出成json格式(KV键值对) 2.access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 访问日志文件路径，格式及相关的缓冲的配置； buffer=size flush=time 3.open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 缓存各日志文件相关的元数据信息； max：缓存的最大文件描述符数量； min_uses：在inactive指定的时长内访问次数低于min_uses就认为是无效的； inactive：非活动时长； valid：验正缓存中各缓存项是否为活动项的时间间隔；检查inactive的间隔 ngx_http_gzip_module：文本资源压缩传输节约带宽在CPU等硬件资源不稀缺的情况下，带宽流量的稀缺使得资源压缩必须启用 启用资源压缩功能，虽然可以大大减小了带宽的消耗，要注意适用的场景； 1.比如当前服务器CPU负载较大，压缩功能本身就会消耗更多的CPU资源，如果启用 对服务器的压力就会更大 2.应该只对文本内容进行压缩，视频、图片、流媒体等本身就已经是有压缩比的资源 3.实现逻辑：先使用压缩过滤器过滤出来有很好压缩比的资源(css,js,html)等文本 再定义压缩规则 1.gzip on | off; 需要先开启gzip压缩功能 2.gzip_comp_level level; 设置压缩比1~9,压缩比越大对CPU的消耗越大 3.gzip_disable regex ...; 过滤User_Agent浏览器类型，禁用较老的浏览器版本不启用压缩功能。 4.gzip_min_length length; 当响应报文大小达到某个值，才压缩，太小就不值得压缩了 比如：低于100k不压缩，高于这个值才进行资源压缩，单位:byte字节 5.gzip_buffers number size; 支持实现压缩功能时为其配置的缓冲区数量(number)及每个缓存区的大小(size)； 在服务器的内存资源充沛时，启用缓冲区可以更快的对资源进行压缩 6、gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...; nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的； off：对代理的请求不启用 no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能； any:任何内容不压缩 7.gzip_types mime-type ...; 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能； 过滤需要压缩的类型，纯文本和html不需要，因为默认就对其压缩 示例： ~]# vim /usr/local/nginx/conf/nginx.conf #将以下配置放到nginx.conf的http{ ... }节点中 gzip on; #开启gzip压缩功能 gzip_buffers 4 16k; #设置压缩缓冲区大小，此处设置为4个16K内存作为压缩结果流缓存 gzip_comp_level 6; #设置压缩比率，最小为1 gzip_min_length 64; #设置允许压缩的页面最小字节数; gzip_http_version 1.1; #压缩版本 gzip_disable &quot;MSIE [1-6]\.&quot;; #配置禁用gzip条件，支持正则。此处表示ie6及以下不启用gzip（因为ie低版本不支持） gzip_proxied any; gzip_types text/plain application/x-javascript text/css application/xml \ text/javascript application/x-httpd-php application/javascript application/json; #制定压缩的类型,线上配置时尽可能配置多的压缩类型!上面是生成线上配置 注意： Nginx的Gzip压缩功能虽然好用，但是下面两类文件资源不太建议启用此压缩功能。 1.图片类型资源 (还有视频文件) 原因：图片如jpg、png文件本身就会有压缩，所以就算开启gzip后，压缩前和压缩后大小没有多大区别，所以开启 了反而会白白的浪费资源。（可以试试将一张jpg图片压缩为zip，观察大小并没有多大的变化。虽然zip和gzip算法 不一样，但是可以看出压缩图片的价值并不大） 2.大文件资源 原因：会消耗大量的cpu资源，且不一定有明显的效果 ngx_http_ssl_module模块：如上图，代理服务用nginx不采用LVS的一个原因就是LVS不支持SSL的代理，nginx可以实现 面对客户端使用https协议，面对后端服务器集群使用http协议，所以有时nginx反代也叫https的会话卸载器 如果是四层调度，https访问必须是客户端与后端服务器之间建立； 如果两段式连接，对内调度是明文的，把压力放在前端代理服务器上，本身前端调度器 岁CPU资源消耗不是很大 1.ssl on | off; Enables the HTTPS protocol for the given virtual server. 2.ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件； 3.ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件； 4.ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2]; 支持ssl协议版本，默认为后三个； 5.ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; nginx的ssl会话有两种： 1.builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有； 2.[shared:name:size]：在各worker之间使用一个共享的缓存； ssl的session建立是很慢的,所以要启用ssl的缓存，而且还是shared类型的共享缓存方式 6、ssl_session_timeout time; 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长； 实现https加密： 生成私钥和证书： openssl genrsa -out nginx.key 2048 openssl req -new -x509 -key nginx.key -out nginx.crt -days 3650 -subj &quot;/CN=www.lk.tech&quot; 配置https主体： server { listen 443 ssl; server_name www.lk.tech; root /data/lk; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; } ngx_http_rewrite_module模块：实现URL重写 什么是url重写？为什么要用到url重写？ 1.客户端访问URL被重写到另外一个路径了 http://www.lk.tech/photos/1.jpg ---&gt; http://images.lk.tech/1.jpg 2.全站ssl加密时，将用户访问的http://请求全部被重写到https://的虚拟主机上 http://www.lk.tech/images/1.jpg---&gt;https://www.lk.tech/1.jpg rewirte的处理逻辑： 1.将用户请求的URL基于(regex)正则表达式的查找，而后完成替换即可(replacement) 2.如果出现server中两个location互相rewrite，则会出现死循环的现象，所以就引入 了last和break的两个机制 3.last表示接着检查其他rewrite，break表示匹配到当前的rewrite.就不检查其他的 rewrite了这样就避免了死循环。 1.rewrite regex replacement [flag] a.将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement 指定的新的URI； b.rewrite重写的路径可以是相对路径也可以是绝对路径 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制； 如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端 ；用的比较多的是301和302 301：permanent,永久重定向； 302：redirect,临时重定向； [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环； break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环； redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；302 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；301 2.return：类似于重定向的操作 return code [text]; return code URL; return URL; Stops processing and returns the specified code to a client. 3.rewrite_log on | off; 是否开启重写日志；可能出现安全风险，所以没有必要时不用开启 4.if (condition) { ... } 引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令； 一般用于server, location； condition： 比较操作符： == != ~：模式匹配，区分字符大小写； ~*：模式匹配，不区分字符大小写； !~：模式不匹配，区分字符大小写； !~*：模式不匹配，不区分字符大小写； 文件及目录存在性判断： -e, !-e -f, !-f -d, !-d -x, !-x 5.set $variable value; 用户自定义变量； 示例： location ~* ^/(photos|pictures) { ## rewrite ^/photos/(.*)$ /image/$1 last; # rewrite ^/photos/(.*)$ http://images.lk.tech:8081/$1; # rewrite ^/(photos|pictures)/(.*)$ http://images.lk.tech:8081/$2 permanent; # } -redirect和permanent的示例演示 ngx_http_referer_module模块：网站防盗链检查客户端的请求数据报文首部，实际就是防盗链的过滤器，所以在日志中记录referer referer来源： 1. 2. 1.valid_referers none | blocked | server_names | string ...; 定义referer首部的合法有效的值 none：请求报文首部没有referer首部； blocked：请求报文的referer首部没有值； server_names：参数，其可以有值作为主机名或主机名模式； arbitrary_string：直接字符串，但可使用*作通配符； regular expression：被指定的正则表达式模式匹配到的字符串； 要使用~打头，例如 ~.*\.lk.com； 使用说明和示例： 先定义valid_referers的允许连接网站，再通过if判断如果不是在 valid_referers中定义的网站，就返回一张图片或者文字说明 valid_referers none block server_names *.lk.com lk.* ~\.lk\.; if ($invalid_referer) { return http://www.lk.tech/hello.html; }]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins实现自动发布回滚]]></title>
    <url>%2F2018%2F03%2F06%2Fjenkins%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83%E5%9B%9E%E6%BB%9A%2F</url>
    <content type="text"><![CDATA[脚本部署实现自动代码流水线扫描上线 –自动代码扫描过程 1.jenkins怎么实现脚本传递参数的 在构建任务时，在参数化构建过程中添加选项参数、字符参数等用于给脚本传参； 2.多版本保存，有利于版本回滚 在shell脚本中，scp时加上&apos;DATE&apos;选项，即可根据时间后缀记录发布的版本； 3.发布时不建议同时升级，服务会断开 在生产环境下我们是先在group1中设置一台升级测试，但是这一台在脚本中会明确不加入 到负载均衡中，只作为开发和测试对线上服务器升级后的测试，如果确认这台没问题后再对group2进行版本升级； 这就是为了会分group1,group2,group3,group-all了 前端负载： 1.如果是haproxy,使用socat命令即可对server进行下线； 2.如果是nginx,需要jenkins服务器ssh到nginx服务器上在配置文件中的upstream指定的server前加个#注释掉即可，然后再将#后取消就可以实现上线了！ –任务中给shell脚本传参数1–任务中给shell脚本传参数2–任务中给shell脚本传参数3 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129脚本：[root@jenkins deploy]# vim cre-deploy.sh #!/bin/bashDATE=`date +%Y-%m-%d_%H-%M-%S` #生成脚本执行的时间，便于版本回滚METHOD=$1 #上图中的第一个参数BRANCH=$2 #上图中的第二个参数GROUP_LIST=$3 #上图中的第三个参数function IP_list()&#123; if [[ $&#123;GROUP_LIST&#125; == &quot;online-group1&quot; ]];then #只对group1中的后端web进行上线,实现金丝雀/灰度发布 Server_IP=&quot;172.20.141.44&quot; echo $&#123;Server_IP&#125; elif [[ $&#123;GROUP_LIST&#125; == &quot;online-group2&quot; ]];then #只对group2中的后端web进行上线,实现金丝雀/灰度发布 Server_IP=&quot;172.20.141.45&quot; echo $&#123;Server_IP&#125; ssh root@172.20.141.44 &quot;echo &quot;enable server web-port-80-listen/172.20.141.44&quot; | socat stdio /var/lib/haproxy/haproxy.sock&quot; ssh root@172.20.141.45 &quot;echo &quot;enable server web-port-80-listen/172.20.141.44&quot; | socat stdio /var/lib/haproxy/haproxy.sock&quot; #对group1升级后，再执行group2，确保group1中的服务器也加入到负载中 elif [[ $&#123;GROUP_LIST&#125; == &quot;online-all&quot; ]];then #对所有的后端web进行上线 Server_IP=&quot;172.20.141.44 172.20.141.45&quot; echo $&#123;Server_IP&#125; fi&#125;function clone_code()&#123; rm -rf /data/gitdir/cre-app cd /data/gitdir/ git clone -b $&#123;BRANCH&#125; git@172.20.103.39:cre/cre-app.git&#125;function scanner_code()&#123; cd /data/gitdir/cre-app /usr/local/sonar-scanner/bin/sonar-scanner&#125;function make_zip()&#123; cd /data/gitdir/cre-app &amp;&amp; zip -r code.zip ./*&#125;function down_node()&#123; for node in $&#123;Server_IP&#125;;do ssh root@172.20.141.45 &quot;echo &quot;disable server web-port-80-listen/$&#123;node&#125;&quot; | socat stdio /var/lib/haproxy/haproxy.sock&quot; ssh root@172.20.141.44 &quot;echo &quot;disable server web-port-80-listen/$&#123;node&#125;&quot; | socat stdio /var/lib/haproxy/haproxy.sock&quot; done&#125;function scp_zipfile()&#123; for node in $&#123;Server_IP&#125;;do scp /data/gitdir/cre-app/code.zip $&#123;node&#125;:/data/tomcat_appdir/code-$&#123;DATE&#125;.zip ssh $&#123;node&#125; &quot;unzip /data/tomcat_appdir/code-$&#123;DATE&#125;.zip -d /data/tomcat_webapps/code-$&#123;DATE&#125;&quot; ssh $&#123;node&#125; &quot;rm -rf /data/tomcat_webdir/myapp &amp;&amp; ln -sv /data/tomcat_webapps/code-$&#123;DATE&#125; /data/tomcat_webdir/myapp&quot; done&#125;function stop_tomcat()&#123; for node in $&#123;Server_IP&#125;;do ssh $&#123;node&#125; &quot;/etc/init.d/tomcat stop&quot; done&#125;function start_tomcat()&#123; for node in $&#123;Server_IP&#125;;do ssh $&#123;node&#125; &quot;/etc/init.d/tomcat start&quot; #sleep 5 done&#125;function web_test()&#123; #sleep 30 for node in $&#123;Server_IP&#125;;do NUM=`curl -s -I -m 10 -o /dev/null -w %&#123;http_code&#125; http://$&#123;node&#125;:8080/myapp/index.html` if [[ $&#123;NUM&#125; -eq 200 ]];then echo &quot;$&#123;node&#125; 测试通过,即将添加到负载&quot; add_node $&#123;node&#125; else echo &quot;$&#123;node&#125; 测试失败,请检查该服务器是否成功启动tomcat&quot; fi done&#125;function add_node()&#123; #添加到负载 node=$1 echo $&#123;node&#125;.&quot;-----&gt;&quot; if [ $&#123;node&#125; == &quot;172.20.141.44&quot; ];then echo &quot;172.20.141.44 部署完毕，请进行代码测试！&quot; #这一台就是为了先测试升级准备的，而且最初是不加入到负载上的； else ssh root@172.20.141.45 &quot;echo &quot;enable server web-port-80-listen/$&#123;node&#125;&quot; | socat stdio /var/lib/haproxy/haproxy.sock&quot; ssh root@172.20.141.44 &quot;echo &quot;enable server web-port-80-listen/$&#123;node&#125;&quot; | socat stdio /var/lib/haproxy/haproxy.sock&quot; fi&#125;function rollback_last_version()&#123; #回滚 for node in $&#123;Server_IP&#125;;do NOW_VERSION=`ssh $&#123;node&#125; &quot;&quot;/bin/ls -l -rt /data/tomcat_webdir/ | awk -F&quot;-&gt;&quot; &apos;&#123;print $2&#125;&apos; | tail -n1&quot;&quot;` NOW_VERSION=`basename $&#123;NOW_VERSION&#125;` echo $NOW_VERSIONG NAME=`ssh $&#123;node&#125; &quot;&quot; ls -l -rt /data/tomcat_webapps/ | grep -B 1 $&#123;NOW_VERSION&#125; | head -n1 | awk &apos;&#123;print $9&#125;&apos;&quot;&quot;` ssh $&#123;node&#125; &quot;rm -rf /data/tomcat_webdir/myapp &amp;&amp; ln -sv /data/tomcat_webapps/$&#123;NAME&#125; /data/tomcat_webdir/myapp&quot; done&#125;main()&#123; case $1 in deploy) IP_list; clone_code; scanner_code; make_zip; down_node; stop_tomcat; scp_zipfile; start_tomcat; web_test; ;; rollback_last_version) IP_list; echo $&#123;Server_IP&#125;; down_node; stop_tomcat; rollback_last_version; start_tomcat; web_test; ;; esac&#125;main $1 $2 $3 脚本中注意事项： 1.jenkins服务器的公钥要配置到gitlab上 2.jenkins要对后端web和负载均衡都要ssh免秘钥 3.每个tomcat上都要创建/data/tomcat_webapps用于保存加压后的apps应用程序 4.根据脚本中设置的，要先执行group1，再执行group2,这样做是为了在整个版本发布先 进行一台测试，然后内部测试没问题再对其他的web服务器升级； 5.因为tomcat是由tomcat用户启动的，所以tomcat需要对/data/整个目录有权限，而且 在脚本中ssh时要使用tomcat@IP方式，而且jenkins的ssh免秘钥是拷贝到tomcat用户目录下的； 回滚回滚是默认的当前版本的上一个版本或者指定版本的 版本回滚方式有两种： 1.git reset --hard HEAD^ 2.通过在脚本过滤/data/tomcat_webdir/下现有版本过滤出上一版本的code+DATE,然后再重新创建软链接即可 版本发布测试和版本回退测试 备注： 在版本回滚时可以看到即使tomcat下/data/tomcat_webdir/下因为执行时间而产生的版本时间不一致， 在脚本中也会根据各自的当前版本进行发布和回滚! –目录下版本回退示例]]></content>
      <categories>
        <category>CI/CD</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>CI/CD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible]]></title>
    <url>%2F2018%2F03%2F06%2Fansible%2F</url>
    <content type="text"><![CDATA[运维自动化管理工具之Ansible 内容：1.软件发布环境机制优势对比 和 2.ansible的应用ansible的相关的文档ansible的中文权威指南：ansible中文指南Github上的ansible-galaxy示例：ansible-galaxy 其他相关运维管理工具使用方法：pssh的使用方法参照链接文章：psshsaltstack介绍及使用参照链接文章：saltstackpuppet介绍及使用参照链接文章：puppet 当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric 常用自动化运维工具 PSSH：适用于主机数量很少的环境(基础ssh的key验证) Ansible:python,Agentless,中小型应用环境(自带代理功能) Saltstack:python，一般需部署agent，执行效率更高 Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境 Fabric：python，agentless Chef: ruby,国内应用少 Cfengine func 发布更新环境灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器 而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径 如： 软件路径为:/data/app 正在用的软件版本V1.0：/data/app1.0 更新的软件版本V2.0：/data/app2.0 则需要把删除原来的软链接：/data/app1.0---&gt;/data/app 创建新的软链接：/data/app2.0---&gt;/data/app 10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线 发布步骤： 1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。 2.从负载均衡列表中移除掉「金丝雀」服务器。 3.升级「金丝雀」应用（排掉原有流量并进行部署）。 4.对应用进行自动化测试。 5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。 6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。 A/B Testing A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。 优势与不足： 优势：用户体验影响小，灰度发布过程出现问题只影响少量用户 不足：发布自动化程度不够，发布期间可引发服务中断 预发布验证： 新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器 灰度发布： 可以基于主机，用户或者业务，又细分为地区，VIP和普通用户 蓝绿发布：核心：主备两套环境定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同 时也升级到新版本 主：绿色环境-活动环境：负责对外提供服务，版本：v1.0 备：绿色环境-非活动环境：版本：v2.0 工作机制： 先把备环境升级v1.0---&gt;v2.0版本，然后上线 把主环境的v1.0版本下线，已经升级的备环境进行替换 特点： 蓝绿部署无需停机，并且风险较小. 注意事项： 1.需要提前考虑数据库与应用部署同步迁移/回滚的问题 2.蓝绿部署需要有基础设施支持 3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境 和绿色环境有被摧毁的风险. 优势与不足： 优势：升级切换和回退速度非常快 不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响 滚动发布：在灰度发布的基础上进行进一步优化定义： 一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式. 特点： 1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数. 可以部分部署，例如每次只取出集群的20%进行升级。 2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出 优势和不足: 优势：用户体验影响小，体验较平滑 不足：发布和回退时间比较缓慢。 发布工具比较复杂，LB需要平滑的流量摘除和拉入能力 滚动发布目前成熟型技术组织所采用的主流发布方式 Ansible ansible特性：-最多管理500台主机，更多效率会降低1.模块化：调用特定的模块，完成特定任务 -类似linux中的小命令 2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块 3.支持自定义模块 4.基于Python语言实现 5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务) 6.安全，基于OpenSSH 7.支持playbook编排任务 -类似于脚本功能，多个脚本的集合成为Roles 8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 9.无需代理不依赖PKI（无需ssl） 10.可使用任何编程语言写模块 11.YAML格式，编排任务，支持丰富的数据结构 12.较强大的多层解决方案 Ansible的学习过程：1.ansible基本命令使用 2.ansible常用模块详解，介绍ansible单个命令的使用 3.YAML语法介绍 4.ansible playbook基础：剧本初体验，类似于写脚本 5.playbook中的变量：tags，handlers使用 6.plsybook模板：templates 7.playbook的条件判断：when 8.playbook的字典：with_items 9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合 会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。 ansible命令执行过程ansible命令执行过程 1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg 2. 加载自己对应的模块文件，如command 3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程 服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 4. 给文件+x执行 5. 执行并返回结果 6. 删除临时py文件，sleep 0退出 执行状态：(颜色定义在/etc/ansible/ansible.cfg中) 绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 CMDB作用介绍:CMDB:Configuration Management Database 配置管理数据库 将服务器的配置，网络配置写到数据库里 CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不 断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管 理等流程提供准确的配置信息. 了解更多CMDB可参照文章：CMDB 1.ansible基本命令使用ansible软件安装：多种安装方法1.基于epel源安装： yum install ansible,非服务，只是一个管理工具 2.编译安装： 3.Github方式安装：可以同步安装 4.pip安装：pip是安装Python包的管理器，类似yum ansible的重要&amp;主要文件配置文件： /etc/ansible/ansible.cfg 配置ansible的工作特性 /etc/ansible/hosts 主机清单 /etc/ansible/roles 存放的角色目录 程序文件： /usr/bin/ansible ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 常用命令： ansible all --list 查看ansible管理的主机群 ansible all -m &quot;模块名&quot; -a &apos;执行的命令&apos; 用什么模块执行什么命令 all也可以换成定义的--list中组的名字 ansible-playbook -C &apos;*.yml&apos; 对所有主机执行剧本 ansible-plsybook -C -t &apos;标签&apos; &apos;*.yml&apos; 对所有主机执行哪个标签的剧本 ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)支持不分组，分组，等方式 如： 192.168.34.100 [webservers] 192.168.34.101 192.168.34.102 [dbservers] 192.168.34.[1:6]7 (17,27..67) db[01:100].cenntos.com ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）配置文件只提供默认值，但可以通过playbook的设置进行覆盖 配置文件可以放在/etc/ansible/ansible.cfg中 也可以放到一个工作目录下命名为.ansible.cfg [defaults] inventory = /etc/ansible/hosts - 主机列表配置文件 library = /usr/share/my_modules/ - 库文件存放目录 remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录 local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录 forks = 5 - 默认并发数 sudo_user = root - 默认sudo 用户 ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码 ask_pass = True remote_port = 22 host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 [color] 定义ansible命令的执行结果颜色的 配置文件说明和建议修改的项：local_tmp和remote_tmp： 本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地 家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除. host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 module_name = command -默认使用的命令模块，可以修改成shell module_name = shell 2.ansible常用模块详解，介绍ansible单个命令的使用ansible模块的使用查询方法ansible-doc: 显示模块帮助 ansible-doc [options] [module...] -a 显示所有模块的文档 -l, --list 列出可用模块 -s, --snippet显示指定模块的playbook片段 示例： ansible-doc –l 列出所有功能模块 ansible-doc ping 查看ansible中的ping用法 ansible-doc -s shell 查看shell模块的使用方法 ansible的常用基本选项ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible 端能基于密钥认证的方式联系各被管理节点 ansible语法： ansible &lt;host-pattern&gt; [-m module_name] [-a args] --version 显示版本 -m module 指定模块，默认为command，主要使用选项 -v 详细过程 –vv -vvv更详细 --list-hosts 显示主机列表，可简写 --list -k, --ask-pass 提示输入ssh连接密码，默认Key验证 -K, --ask-become-pass 提示输入sudo时的口令 -C, --check 检查，并不执行 -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s -u, --user=REMOTE_USER 执行远程执行的用户 -b, --become 代替旧版的sudo 切换 ansible的主机清单表示方法:Host-pattern1.All ：表示所有Inventory中的所有主机 如：ansible all -m ping ansible all --list-hosts列出所有主机清单 ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP 2.* :通配符 如：ansible &quot;*&quot; = ansible all ansible 192.168.34.* 表示34网段的所有IP 3.或的关系 如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作 ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作 4.与的关系(且) 如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机 5.非，取反 如：ansible &apos;websrvs:!dbsrvs&apos; 在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号 6.正则表达式 如：ansible &quot;~(web|db).*\.centos\.com&quot; ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项1.Command：在远程主机执行命令，默认模块，可忽略-m选项 可以在ansible.cfg中修改默认模块项 支持：chdir(切换目录) command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现 使用示例： ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh ansible all -a &apos;useradd test&apos; 所有主机上创建test用户 2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项 支持功能：支持$ &lt; &gt; | ; &amp; 等 chdir 执行前，先切换到该文件夹 示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos; 显示appsrvs组的主机名 ansible all -m shell -a &apos;chdir=/data rm -rf *&apos; 先切换到/data目录下，再执行删除命令 3.Script: 批量运行脚本 可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理 功能：creates:远程主机的文件存在，则不运行 removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令 示例：ansible all -m script -a &quot;/data/test.sh&quot; ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot; 因为fstab文件存在，则不执行rm -rf /data/*命令 ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot; 因为fstab文件存在，则执行rm -rf /data/*命令 4.Copy:从服务器复制文件到目标主机 src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户 2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos; 根据自己写的字符串生成文件 5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取 src，dest(抓取到本机目录) 示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos; 将远程主机fstab2文件抓取到本机/data下 如果抓取的是目录，先打包再抓取 打包：ansible all -a &apos;tar cf /root/data.tar /data&apos; 抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos; 6.File：设置文件属性，创建/删除文件 src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos; 创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos; 删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos; 7.Hostname：管理主机名 可以通过后面的变量来实现 a.先在hosts后定义hostname变量名 [centos6] 192.168.34.106 hostname=mini6-2 192.168.34.101 hostname=node6-1 [centos7] 192.168.34.107 hostname=mini7-1 b.再通过hostname模块批量修改 ansible all -m hostname -a &apos;name={{hostname}}&apos; 8.Cron：计划任务 支持：minute，hour，day，month，weekday 示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate 172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务 ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名 ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名 9.Yum：管理包 支持：name,state=(started stopped reloaded restarted),absent 更新缓存：update_cache=yes， 示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包 ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包 10.Service：管理服务(同一systemctl&amp;service) name，state(stopped,started,reloaded,restarted) enable(设置开启启动) 示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务 ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务 ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务 ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动 11.User：管理用户 name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录) 示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos; 创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户 ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录 12.Group：管理组 支持：group,name,gid,system,state=(absent) 示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组 ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 ansible系列的一些模块(用的不多)简单介绍与了解： ansible-galaxy 互联网上的角色分享 ansible-pull 推送命令至远程，效率无限提升，对运维要求较高 Ansible-vault管理yaml文件 功能：管理加密解密yml文件 ansible-vault [create|decrypt|edit|encrypt|rekey|view] ansible-vault encrypt hello.yml 加密 ansible-vault decrypt hello.yml 解密 ansible-vault view hello.yml 查看 ansible-vault edit hello.yml 编辑加密文件 ansible-vault rekey hello.yml 修改口令 ansible-vault create new.yml 创建新文件 Ansible-console ansible重要知识之playbook(上面的各种模块的组合) YAML语言（编写playbook的专门语言）YAML语法： 在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三 个点号( ... )用来表示档案结尾 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 使用#号注释代码 缩进必须是统一的，不能空格和tab混用 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过 缩进结合换行来实现的 YAML文件内容是区别大小写的，k/v的值均需大小写敏感 k/v的值可同行写也可换行写。同行使用:分隔 v可是个字符串，也可是另一个列表 一个完整的代码块功能需最少元素需包括 name: task 一个name只能包括一个task YAML文件扩展名通常为yml或yaml List：列表，其所有元素均使用“-”打头 Dictionary：字典，通常由多个key与value构成 Playbook中的核心元素:1.Hosts 执行的远程主机列表 2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远 程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使 用sudo_user指定sudo时切换的用户 3.Tasks 任务集 4.Varniables 内置变量或自定义变量在playbook中调用 5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件 6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否 则不执行 7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible 具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其 确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可 以通过tags跳过此些代码片断 8.handlers和notify 运行playbook运行playbook的方式 ansible-playbook &lt;filename.yml&gt; ... [options] 常见选项 -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测 --list-hosts 列出运行任务的主机 --limit 主机列表 只针对主机列表中的主机执行 -v 显示过程 -vv -vvv 更详细 备注： 执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误 ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行 执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验将centos7的httpd.conf复制到centos7主机，6上的配置文件不同示例1：写一个安装启动httpd的playbook:install_httpd.yml 包括创建用户，安装httpd包，开启服务，并设置开机启动 - hosts: all remote_user: root tasks: - name: creat user user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd - name: copy config copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf - name: install package yum: name=httpd - name: service service: name=httpd state=started enabled=yes 备注： 执行完通过以下命令判断每个任务都否都执行成功了 1.ansible all -a &apos;getent passwd httpd&apos; 2.ansible all -a &apos;rpm -q httpd&apos; 3..ansible all -a &apos;ss -ntlp|grep 80&apos; 示例2：写一个删除上面的playbook:remove_httpd.yml 包括：删除用户，卸载httpd包 - hosts: all remote_user: root tasks: - name: del user user: name=httpd state=absent remove=yes - name: remove package yum: name=httpd state=absent 备注： 如果只删除特定主机的httpd，而不是全部，需要加--limit选项 ansible-playbook --limit 192.168.34.105 remove_httpd.yml 只限制在192.168.34.105的主机执行 上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。Handlers: 是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生 变化时，才会采取一定的操作 Notify: 此action可用于在每个play的最后被触发，这样可避免多次有改变发生 时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。 在notify中列出的操作称为handler，也即notify中调用handler中定义的操作 示例：示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200） - hosts: all remote_user: root tasks: - name: creat user user: name=memcached shell=/sbin/nologin uid=2345 - name: install package yum: name=memcached - name: copy config copy: src=/data/memcached dest=/etc/sysconfig/memcached notify: restart service 和handlers名称一致 - name: service service: name=memcached state=started enabled=yes handlers: - name: restart service 和notify名称一致 service: name=memcached state=restarted 备注：停止并删除用户和安装包 ansible all -a &apos;service memcached stop&apos; ansible all -a &apos;ss -ntl&apos; ansible all -a &apos;rpm -q memcached&apos; ansible all -a &apos;getent passwd memcached&apos; 可以多个notify对应一个handlers，也可以多个motify对应多个handlers示例4：多个notify对应一个handlers - hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ notify: restart httpd 第一个notify - name: ensure apache is running service: name=httpd state=started enabled=yes notify: restart httpd 第二个notify handlers: - name: restart httpd 对应一个handlers service: name=httpd status=restarted 示例5：多个notify对应多个handlers- hosts: websrvs remote_user: root tasks: - name: config copy: src=/root/config.txt dest=/etc/nginx/nginx.conf notify: - Restart Nginx - Check Nginx Process 多个notify的写法 handlers: - name: Restart Nginx 对应写多个handlers service: name=nginx state=restarted enabled=yes - name: Check Nginx process shell: killall -0 nginx &gt; /tmp/nginx.log tags的用法：作用：挑选某一段的task来执行将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行 然后执行：ansible-plsybook -t ceshi install_memcached.yml 只会触发拷贝文件和handlers的动作 --- #test yaml file - hosts: all remote_user: root tasks: - name: creat user user: name=memcached shell=/sbin/nologin uid=2345 - name: install package yum: name=memcached - name: copy config copy: src=/data/memcached dest=/etc/sysconfig/memcached notify: restart service 和handlers名称一致 tags: ceshi 对拷贝动作加一个标签 - name: service service: name=memcached state=started enabled=yes handlers: - name: restart service 和notify名称一致 service: name=memcached state=restarted Playbook中变量使用:可以多出定义，但是存在优先级优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1 ansible setup facts 远程主机的所有变量都可直接调用 setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的 代码块，然后用代码块当变量 比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的 ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的 2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量 3 通过命令行指定变量，优先级最高 可以对单个变量赋值：ansible-playbook –e varname=value 也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot; 4 在playbook中定义 vars: - var1: value1 - var2: value2 5 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件 很适合在roles中进行单独定义 6 在role中定义（下文中有介绍） 从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作 ansible_fqdn 主机名的变量 ansible_hostname 主机名 ansible_distribution_major_version: “6” 版本名变量 ansible_processor_vcpus 虚拟cpu个数变量 ansible_memtotal_mb 内存的变量 示例： ansible all -m setup -a “filter=ansible_memtotal_mb” 用此命令来查看系统内变量的值 调用不同变量来源的示例：得出变量的优先级顺序示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml - hosts: all remote_user: root tasks: - name: touch file file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量 /etc/ansible/hosts：中定义的变量： [websrvs] 192.168.34.105 port1=80 192.168.34.106 port1=90 -普通变量 [websrvs:vars] -公共组变量 mark=&quot;-&quot; [appsrvs] 192.168.34.101 port1=100 [appsrvs:vars] mark=&quot;=&quot; vars.yml中书写格式： - hosts: all remote_user: root tasks: - name: touch file file: name=/data/app{{mark}}{{ port1 }}.log state=touch 最后生成的文件为： app=100.log，app-80.logapp-90.log 示例3：在示例1的基础上，再通过命令行中定义变量: 在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果： ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml 可以看出，最后新建的文件名为hahaha.log 示例4：在playbook中定义变量 - hosts: all remote_user: root vars: - port1: 200 - mark: +++ tasks: - name: touch file file: name=/data/app{{mark}}{{ port1 }}.log state=touch 生成的文件： app+++200.log 示例5：先写在var.yml中定义变量， 1.先准备cat vars.yml:文件内容格式 var1: httpd var2: nginx 2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义 - hosts: web remote_user: root vars_files: - vars.yml tasks: - name: create httpd log file: name=/app/{{ var1 }}.log state=touch - name: create nginx log file: name=/app/{{ var2 }}.log state=touch 模板templates，作用：文本文件，嵌套有脚本（使用模板编程语言编写） Jinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1, item2, ...] 元组：(item1, item2, ...) 字典：{key1:value1, key2:value2, ...} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;= 逻辑运算：and, or, not 流表达式：For If When templates功能：根据模块文件动态生成对应的配置文件 templates文件必须存放于templates目录下，且命名为 .j2 结尾 yaml/yml 文件需和templates目录平级，目录结构如下： ./ ├── temnginx.yml └── templates └── nginx.conf.j2 示例1：通过templates模板nginx1.先生成nginx.conf.j2模板 cp /etc/nginx/nginx.conf templates/nginx.conf.j2 2.创建playbook - hosts: all remote_user: root tasks: - name: inastll nginx yum: name=nginx - name: template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: service - name: start service service: name=nginx state=started handlers: - name: service service: name=nginx state=restarted when配合templates实现根据不同版本执行不同的功能条件测试: 如果需要根据变量、facts或此前任务的执行结果来做为某task执行与 否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法 格式 when语句 在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 示例： tasks: - name: &quot;shutdown RedHat flavored systems&quot; command: /sbin/shutdown -h now when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值 示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when步骤：涉及到多个notify对应一个handlers,定义端口变量 1.hosts文件配置：修改了4台主机httpd的端口 [centos6] 192.168.34.105 http_port=86 192.168.34.106 http_port=87 192.168.34.101 http_port=88 [centos7] 192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件 httpd_6.conf.j2 httpd_7.conf.j2 3.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的 Listen {{http_port}} 调用hosts列表中的端口变量 4.plsybook如下： --- - hosts: all remote_user: root tasks: - name: install httpd yum: name=httpd - name: templates 6 template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: restart service when: ansible_distribution_major_version == &quot;6&quot; - name: templates 7 template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf when: ansible_distribution_major_version == &quot;7&quot; notify: restart service - name: service service: name=httpd state=started handlers: - name: restart service service: name=httpd state=restarted 迭代：with_items，类似于shell中的for循环迭代：当有需要重复性执行的任务时，可以使用迭代机制 对迭代项的引用，固定变量名为”item“ 要在task中使用with_items给定要迭代的元素列表 列表格式： 字符串 字典 字典构成一个键值对{key:vavul},如示例3 迭代的示例：示例1：比如创建user1.user2.user3个用户 - hosts: all remote_user: root tasks: - name: touch users user: name={{item}} with_items: - haha1 - haha2 - haha3 示例2：拷贝3个文件，file1 file2 file3 - hosts: all remote_user: root tasks: - name: copy files copy: src=/data/playbook/{{item}} dest=/data/ with_items: - file1 - file2 - file3 迭代嵌套子变量:涉及到多个键值对的表达方式示例3：创建3个组，再创建3个用户，指定加入一一对应的组 - hosts: all remote_user: root tasks: - name: creat groups group: name={{item}} with_items: - group1 - group2 - group3 - name: creat users user: name={{item.name}} group={{item.group}} with_items: - { name: &apos;haha1&apos;, group: &apos;group1&apos; } - { name: &apos;haha2&apos;, group: &apos;group2&apos; } - { name: &apos;haha3&apos;, group: &apos;group3&apos; } 备注：注意创建用户时，键值对的表达和使用方法 上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3; Playbook中template结合for循环生成具有重复性的代码段语法: for的写法： {% for vhost in nginx_vhosts %} server { listen {{ vhost.listen | default('80 default_server') }} ### Playbook中template结合for循环生成具有重复性的代码段 if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用 如果没定义，则不执行接下来的代码：示例2 {% if vhost.server_name is defined %} server_name {{ vhost.server_name }}; {% endif %} {% if vhost.root is defined %} root {{ vhost.root }}; {% endif %} ### for和if的示例，帮助理解其要执行语句的含义 示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成 先创建for.j2文件： {% for i in ports %} server{ listen {{i.listen}} name {{i.name}} root {{i.root}} } {% endfor %} 创建playbook:再其中调用for.j2文件 - hosts: all remote_user: root vars: ports: - web1: listen: 81 name: www.baidu.com root: /data/web1 - web2: listen: 82 name: www.baidu1.com root: /data/web2 tasks: - name: test for template: src=for.j2 dest=/data/for1.conf 效果为： server{ listen 81 name www.baidu.com root /data/web1 } server{ listen 82 name www.baidu1.com root /data/web2 } 示例2：template配合if的涵义： 在示例1中的playbook中，把name注释掉，即不定义name的值 - web1: listen: 81 # name: www.baidu.com root: /data/web1 然后playbook:再调用for.j2文件 {% for i in ports %} server{ listen {{i.listen}} {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用 name {{i.name}} {% endif %} root {{i.root}} } {% endfor %} 结果：则web1没有name的值，即可以理解if的用法 server{ listen 81 root /data/web1 少了web1的name的值 } server{ listen 82 name www.baidu1.com root /data/web2 } Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？ansible重要内容之Roles；playbook的集合和拆分 ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles 能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需 要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、 文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一 种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程 等场景中 复杂场景：建议使用roles，代码复用度高 变更指定主机或主机组 如命名不规范维护和传承成本大 某些功能需多个Playbook，通过Includes即可实现 roles的意义和适用场景：角色(roles)：角色集合 适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把 同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了， 当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。 如系统内会存在如下的各类服务，可以先编排好角色 roles/ ├── httpd/ ├── memcached/ ├── mysql/ └── nginx/ roles的目录结构（一般分成以下目录进行存放一类的文件）Roles各目录作用： /roles/project/ :项目名称,有以下子目录 如创建http，memcached，nginx等目录 files/ ：存放由copy或script模块等调用的文件 保存需要拷贝的配置文件 templates/：template模块查找所需要模板文件的目录 保存通过template的jinja2模板调用的配置文件 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此 文件中通过include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要 在此文件中通过include进行包含，可以单独定义变量的目录 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为 main.yml的文件，其它文件需在此文件中通过include进行包含 tasks目录下，组合任务顺序的文件 default/：设定默认变量时使用此目录中的main.yml文件 roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.- hosts: all remote_user: root roles: - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]} - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]} - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]} playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量方法一：把需要调用的角色写在一个playbook里 - hosts: all remote_user: root roles: - role: httpd - role: memcached - role: nginx 弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活 方法二；可以把变量在角色中定义 传递变量给角色 - hosts: remote_user: roles: - mysql - { role: nginx, username: nginx } 键role用于指定角色名称 后续的k/v用于传递变量给角色 调用角色方法3：还可基于条件测试实现角色调用 方法三：还可基于条件测试实现角色调用 roles: - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ } roles示例：以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.ymlroles的目录结构下的httpd&amp;nginxmemcachedroles ├── httpd │ ├── files │ │ ├── index_6.html │ │ └── index_7.html │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ ├── copyhtml_6.yml │ │ ├── copyhtml_7.yml │ │ ├── group.yml │ │ ├── main.yml │ │ ├── package.yml │ │ ├── service.yml │ │ ├── tempconfig_6.yml │ │ ├── tempconfig_7.yml │ │ └── user.yml │ ├── templates │ │ ├── httpd_6.conf.j2 │ │ └── httpd_7.conf.j2 │ └── vars ├── memcached │ ├── files │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ ├── group.yml │ │ ├── main.yml │ │ ├── package.yml │ │ ├── service.yml │ │ ├── tempconfig.yml │ │ └── user.yml │ ├── templates │ │ └── memcached.j2 │ └── vars └── nginx ├── files │ ├── index_6.html │ └── index_7.html ├── handlers │ └── main.yml ├── tasks │ ├── copyhtml_6.yml │ ├── copyhtml_7.yml │ ├── group.yml │ ├── main.yml │ ├── package.yml │ ├── service.yml │ ├── tempconfig.yml │ └── user.yml ├── templates │ └── nginx.conf.j2 └── vars └── main.yml 调用角色的playbook:roles.yml可以通过加变量和标签和条件测试调用更灵活的调用各种角色) vim /data/roles.yml - hosts: all remote_user: root roles: - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“} - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]} - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]} 比如： 1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法 2.ansible-playbook -t httpd roles.yml 只选择安装httpd 3.ansible-playbook -t nginx roles.yml 只选择安装nginx 4.ansible-playbook -t web roles.yml 安装httpd和memcached 5.ansible-playbook -t web1 roles.yml 只选择安装nginx 下图为每个role的各个文件内容：图一：参照roles的httpd的目录各个文件内容 图二：参照roles的nginx的目录各个文件内容 涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有 跨角色调用配置文件写法： - name: copy index6 copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html 图三：参照roles的memcached的目录各个文件内容]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>ansible,运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控系统]]></title>
    <url>%2F2018%2F02%2F05%2Fzabbix%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. 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]]></content>
      <categories>
        <category>监控</category>
        <category>zabbix监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx+tomcat+redis/memcached]]></title>
    <url>%2F2018%2F01%2F20%2Fnginx-tomcat-redis-memcached%2F</url>
    <content type="text"><![CDATA[对tomcat实现负载均衡和seesion保持 提到负载均衡就必然又要提到seesion保持的问题： session sticky:seesion粘性 sticky是需要调度器用调度算法来解决问题的； 这样带来的问题就是： 既损害负载均衡效果，又可能造成seesion丢失(后端服务器down机) 1.基于客户端IP做hash将seesion保存在一台服务器上，如果是SNAT网络则IP是 一样的，seesion的颗粒度过于粗糙. 2.cookie机制即使是在通过SNAT网络中，不同的浏览器客户端也会被识别为不同 客户端，seesion的颗粒度精细的多.nginx可以识别应用层的cookie信息， 完全可以基于cookie信息做会话绑定的.但是只有nginx商业版支持. haproxy可以实现！！！ seesion replication:seesion复制会话集群 将后端服务器组织成一个会话集群； 在同一集群中，session是共享的，但是对内存的消耗比较大,但传输是由延迟的 把自己的seesion复制给集群的其他主机，这样seesion集群中的每个主机都会拥有 集群中所有服务器的seesion. 工作原理： 基于多播、单播、广播方式将自己获取的seesion同步给同一集群的其他server； 缺点： 对内存的消耗比较大,而且网络资源传输是有延迟的，且集群规模不能太大 适用场景： 只适合于网站架构初创阶段！！！ session server: 保存后端服务器之后的存储服务器上； 把用户访问的seesion保存单独的一台服务器，通过api调用这个服务器，如redis, memcached，squid等，还是做redis集群保证seesion的安全 但是session的冗余实现比较麻烦和cookie(seesion sticky的另外一种表现) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354环境： nginx：192.168.34.117 两台tomcat：192.168.34.118,192.168.34.126 1.为tomcat创建一个app [root@tomcat ~]# mkdir /webapps/myapp/&#123;WEB-INF,class,META-INF,lib&#125; [root@tomcat ~]# cd /webapps/myapp/ [root@tomcat ~]# vim index.jsp #准备不同的页面，验证负载均衡效果 &lt;%@ page language=&quot;java&quot; %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatB&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color=&quot;black&quot;&gt;TomcatA.lk.com&lt;/font&gt;&lt;/h1&gt; &lt;table align=&quot;centre&quot; border=&quot;1&quot;&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute(&quot;lk.com&quot;,&quot;lk.com&quot;); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; 2.修改server.xml文件，增加一个app定义 [root@tomcat ~]# vim conf/server.xml &lt;Context path=&quot;/myapp&quot; docBase=&quot;/webapps/myapp&quot; reloadable=&quot;&quot; /&gt; #通过context定义app 3.先验证两台tomcat访问是否正常 http://192.168.34.118:8080/myapp http://192.168.34.126:8080/myapp 4.安装nginx并修改配置文件实现负载均衡 [root@nginx ~]# yum install nginx -y [root@nginx ~]# vim nginx.conf upstream tcsrvs &#123; hash $remote_addr consistent; #使用源地址一致性hash算法 server 192.168.34.118:8080; server 192.168.34.126:8080; &#125; #要注意的是server后写IP地址还是主机名，取决于后端tomcat是不是有多个 虚拟主机，如果想要代理至特定的虚拟主机上，这里就要写虚拟主机名了，而不 是IP地址(详见上面的nginx+tomcat中的分析) location / &#123; proxy_pass http://tcsrvs/; &#125; #要注意的是tcsrvs后的/要不要写，取决于location的/和tcsrvs的/是不是 一致的(详见nginx篇的proxy_pass路径映射分析) 5.测试访问 http://192.168.34.117/myapp #可以看出由于是使用源地址hash，来自同一客户端的请求都代理至一个tomcat上了； 6.缺点： 这样是通过前端负载均衡的调度算法来实现会话粘性(session sticky)的，但是 这样有一个缺点就是，如果tomcatA down机了，那么要不要重新调度就取决于现场解决问题的速度了；如果能够尽快修复上线，那就不要再进行调度； 1.tomcat Session Replication Clustertomcat8-cluster实现文档 –cluster实现原理 用tomcat内嵌的cluster功能，每一个server得到会话就自动传给其他server 1.多播机制 单播：如果使用单播机制，每一个主机都需要1：N-1份单播，效率不高 广播：如果是广播机制，在同一个二层网络中所有主机都能接收到广播信息，因此广播 波及面太广，其他主机就会收到干扰； 组播/多播：如果同一集群共同使用同一个多播地址(多播域)，只需要向这个多播地址 发送信息，只有同一多播地址上的主机才能接收到信息，这样就避免了单播和多播的 缺点了； 2.session manager： 当客户端访问tomcat的实例时，tomcat都会保存用户行为来追踪用户信息，这个会话需要专用的类来实例化出对象来管理，在tomcat上会话管理的组件称为session manager; 而默认使用的是持久会话管理器； 3.持久会话管理器： 1.会话来了之后是保存在内存中的，再周期性的同步到磁盘上，如果关闭tomcat再启动，会话也不会丢失； 2.但是如果要实现session cluster,每一个tomcat节点就不能再用默认的持久会话管理 器，而是Delta会话管理器； 4.Delta session manager Delta会把每一个节点后来生成的变化增量信息，只把变动信息通过多播机制发送到多播 域内，同一多播域的其他主机再通过Delta-manager接收变动的信息并且合并到本地的 session当中； 5.缺点： 这样一来每一个节点都有整个session信息，当有大量客户端访问时，就会生成大量的 session信息，不仅造成磁盘/网络I/O性能下降，也无法扩展session集群规模； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768tomcat的Session Replication Cluster就是通过Delta manager来实现的具体配置实现： (1)配置启用集群，将下列配置放置于&lt;engine&gt;或&lt;host&gt;中； 1.修改两台tomcat的server.xml文件 [root@tomcat1 ~]# vim /usr/local/tomcat/conf/server.xml &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot; jvmRoute=&quot;tcA&quot;&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot; channelSendOptions=&quot;8&quot;&gt; &lt;Manager className=&quot;org.apache.catalina.ha.session.DeltaManager&quot; expireSessionsOnShutdown=&quot;false&quot; notifyListenersOnReplication=&quot;true&quot;/&gt; &lt;Channel className=&quot;org.apache.catalina.tribes.group.GroupChannel&quot;&gt; &lt;Membership className=&quot;org.apache.catalina.tribes.membership.McastService&quot; address=&quot;228.0.19.4&quot; port=&quot;45564&quot; frequency=&quot;500&quot; dropTime=&quot;3000&quot;/&gt; &lt;Receiver className=&quot;org.apache.catalina.tribes.transport.nio.NioReceiver&quot; address=&quot;192.168.34.118&quot; #绑定的IP地址 port=&quot;4000&quot; autoBind=&quot;100&quot; selectorTimeout=&quot;5000&quot; maxThreads=&quot;6&quot;/&gt; &lt;Sender className=&quot;org.apache.catalina.tribes.transport.ReplicationTransmitter&quot;&gt; &lt;Transport className=&quot;org.apache.catalina.tribes.transport.nio.PooledParallelSender&quot;/&gt; &lt;/Sender&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.TcpFailureDetector&quot;/&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.MessageDispatchInterceptor&quot;/&gt; &lt;/Channel&gt; &lt;Valve className=&quot;org.apache.catalina.ha.tcp.ReplicationValve&quot; filter=&quot;&quot;/&gt; &lt;Valve className=&quot;org.apache.catalina.ha.session.JvmRouteBinderValve&quot;/&gt; &lt;Deployer className=&quot;org.apache.catalina.ha.deploy.FarmWarDeployer&quot; tempDir=&quot;/tmp/war-temp/&quot; deployDir=&quot;/tmp/war-deploy/&quot; watchDir=&quot;/tmp/war-listen/&quot; watchEnabled=&quot;false&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.ClusterSessionListener&quot;/&gt; &lt;/Cluster&gt; 注意： 1.engine都要加上jvmRoute=&quot;独有的名称&quot;，避免session出现循环复制； 2.自改多播地址address=&quot;228.0.19.4&quot; 3.Receiver的address=&quot;IP&quot;,如果有多个网卡，最好将auto改成多台tomcat间能够通信的IP地址；2.修改web.xml文件 因为并不是说将上面的信息加到host中，host中的所有应用程序都可以使用集群会 话，而是只要在那些在自己的web.xml的配置文件中有&lt;distributable/&gt; 这一元素，才能够使用Delta manager [root@tomcat tomcat]# cp conf/web.xml /webapps/myapp/WEB-INF/web.xml [root@tomcat ~]# cd /webapps/myapp/WEB-INF/ [root@tomcat WEB-INF]# vim web.xml &lt;distributable/&gt; #在webapp标签内部加上此元素；3.重启tomcat并验证 [root@node02 tomcat]# ss -tnl LISTEN 0 50 ::ffff:192.168.34.118:4000 LISTEN 0 100 :::8080 LISTEN 0 100 :::8009 #验证Receiver的4000端口是正常监听的4.配置nginx 前端的nginx负载均衡最好还是使用session sticky,因为session复制是需要时间 的，短时间内再调度到同一台tomcat上可以更好的让用户获得体验； #同上此处省略5.测试 http://192.168.34.117/myapp #此时可以看到虽然被调度到不同的tomcat上，但是session还是由带有jvmRoute标签的来提供； 2.tomcat Session Server–server实现原理 1.session server是通过特殊的session管理器来驱动外部存储将session保存在专门的外部存储系统当中； 2.但是tomcat中并没有内建任何用户驱动外部存储系统的session manager,这就意味着如果 想要使用redis、memcache等外部存储系统，就需要专门添加这样的session manager; 3.存储系统性能必须高 1.因为session是比较多的，而且变化非常频繁，这就要求必须快速存取，redis的事务能力是50~100w/s,而mysql则是50次/s； 2.这是因为mysql有复杂的关系模型设计，要求内部的存储引擎必须做各种各样复杂的关联性检查，而redis/memcache这样的K/V型数据库只需要检查Key是不是冲突的就可以了 4.存储系统要有冗余能力 redis可以redis cluster扩展读写性能,通过RBD/AOF完成数据的持久存储，memcache 可以通过repcached实现数据安全性(无持久存储能力)，但不能提升读写性能； 5.数据流式化： 能够把本身有结构化的数据对象转换成0101这样的流式结构存储到外部的设备，随后对端能够还原来原来的数据结构的过程就称为数据流式化过程； 2.1.msm-memcached方式实现tomcat-session-servermsm项目使用说明 –double-writing 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576前提和注意事项 1.tomcat自己并默认不支持把session放入memcached中，需要借助第三方项目msm; 2.msm:memcached session manager 但是msm支持memcached、redis、couchbase三个客户端； 3.注意： 1.修改server.xml 这里不是为tomcat中的所有业务都配置seesion共享，而是为某各服务器配置，比如：/webapps/myapp项目，所以只需要改server.xml的内容即可； 2.修改META-INF/context.xml 如果不为某个业务配置seesion-server，需要修改context.xml添加下面这些： &lt;Context&gt; ... &lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:192.168.34.118:11211,n2:192.168.34.126:11211&quot; failoverNodes=&quot;n1&quot; requestUriIgnorePattern=&quot;.*\.(ico|png|gif|jpg|css|js)$&quot; transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot; /&gt; &lt;/Context&gt; 3.msm-memcache支持在添加配置段中的memcachedNodes填写多个memcached地址，并结合failoverNodes实现后端memcached的高可用； 说明：如果后端的memcached本身就是一个高可用复制集群时，在memcachedNodes填一个地址就行了，因为它可以使用集群实现故障转移!!1.准备依赖的jar包： 下载如下jar文件至各tomcat节点的tomcat安装目录下的lib目录中，其中的$&#123;version&#125;要换成你所需要的版本号，tc$&#123;6,7,8&#125;要换成与tomcat版本相同的版本号。 memcached-session-manager-$&#123;version&#125;.jar #memcached-session-manager自己的核心jar包 memcached-session-manager-tc$&#123;6,7,8&#125;-$&#123;version&#125;.jar #适配到tomcat具体版本的jar包 spymemcached-$&#123;version&#125;.jar #后端是memcached时使用的驱动jar包； msm-javolution-serializer-$&#123;version&#125;.jar #使用javolution完成对象序列化保存在memcached中 javolution-$&#123;version&#125;.jar #后端是redis时使用的驱动jar包；2.安装2台memcachedbin启动 [root@mem1]# yum install memcached libmemcached -y [root@mem1]# vim /etc/sysconfig/memcached PORT=&quot;11211&quot; USER=&quot;memcached&quot; MAXCONN=&quot;1024&quot; CACHESIZE=&quot;64&quot; OPTIONS=&quot;-f 1.1 -M&quot; [root@mem1]# systemctl start memcached3.将jar包拷贝到tomcat目录下 要下载tomcat对应版本的各种jar包 核心包： memcached-session-manager-2.3.0.jar memcached-session-manager-tc8-2.3.0.jar spymemcached-2.12.3.jar kyro的jar包： asm-6.2.jar kryo-4.0.2.jar kryo-serializers-0.42.jar minlog-1.3.0.jar msm-kryo-serializer-2.3.0.jar objenesis-2.6.jar reflectasm-1.11.7.jar 1.如果是rpm安装 将上面的所有jar包放在/usr/share/java/tomcat/目录下 2.如果是二进制安装 将上面的所有jar包放在/usr/local/tomcat/lib/目录下4.修改server.xml配置文件 [root@tomcat1 ~]# vim /usr/local/tomcat/conf/server.xml &lt;Context path=&quot;/myapp&quot; docBase=&quot;/webapps/myapp&quot; reloadable=&quot;&quot;&gt; &lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;n1:192.168.34.118:11211,n2:192.168.34.126:11211&quot; failoverNodes=&quot;n1&quot; requestUriIgnorePattern=&quot;.*\.(ico|png|gif|jpg|css|js)$&quot; transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot; /&gt; &lt;/Context&gt; #使用kryo.KryoTranscoderFactory完成对象序列化保存在memcached中 #为/webapps/myapp这个项目的app做session保存 #将session同时写入两个memcached中，n1为主 5.启动tomcat观察日志 [root@node03 ~]# tail -f /usr/local/tomcat/logs/catalina.2018-03-01.log –启动日志 6.设置前端负载 nginx配置还使用上文中的配置 7.登录测试 http://192.168.34.117/myapp –访问1 9.登录n1的memcached上进行验证 上图说明session是由n1提供的，登录验证 [root@mem1]# yum install libmemcached -y #安装连接memcached的工具包 [root@mem1]# memdump --servers=&apos;127.0.0.1:11211&apos; 74287C237A869EFF9C85D19E51A58345-n1 #验证确实和图上的session是一致的 10.故障测试 关闭n1的memcached，验证session是否变化 [root@mem1]# systemctl sop memcached –访问2 11.zabbix监控memcached 将memcached的tcp端口和连接数纳入到zabbix监控中，在memcached出现故障时，就可以以最快的时间进行修复； 2.2.msm-redis方式实现tomcat-session-server12345678910111213141516171819202122232425262728293031323334353637383940414243准备工作和注意事项： 1.下载jedis-2.9.0.jar #后端存储是redis时使用的驱动jar包 2.注意事项： 1.msm-memcached和msm-redis在配置段和高可用机制上还是 2.msm-redis在server.xml中的配置项memcachedNodes只允许填一个主节点的Redis地址不支持填多个redis地址，因为msm 把session高可用安全机制留给了外部的redis存储，所以后端的redis需要部署为redis主从或者redis-cluster!1.安装redis和基于Sentinel实现主从； 原因： msm-redis项目的配置文件中只允许填一个redis节点的地址，后端redis高可用是靠外部的redis主从或者redis-cluster实现的! 部署步骤省略2.将redis的jar包拷贝到tomcat下 核心包： memcached-session-manager-2.3.0.jar memcached-session-manager-tc8-2.3.0.jar jedis-2.9.0.jar #和memcached就这一个jar之差 kyro的jar包： asm-6.2.jar kryo-4.0.2.jar kryo-serializers-0.42.jar minlog-1.3.0.jar msm-kryo-serializer-2.3.0.jar objenesis-2.6.jar reflectasm-1.11.7.jar 1.如果是rpm安装 将上面的所有jar包放在/usr/share/java/tomcat/目录下 2.如果是二进制安装 将上面的所有jar包放在/usr/local/tomcat/lib/目录下3.修改server.xml配置文件 [root@tomcat1 ~]# vim /usr/local/tomcat/conf/server.xml &lt;Context path=&quot;/myapp&quot; docBase=&quot;/webapps/myapp&quot; reloadable=&quot;&quot;&gt; &lt;Manager className=&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot; memcachedNodes=&quot;redis://192.168.34.118&quot; sticky=&quot;flase&quot; sessionBackupAsync=&quot;false&quot; lockingMode=&quot;uriPattern:/path1|/path2&quot; requestUriIgnorePattern=&quot;.*\.(ico|png|gif|jpg|css|js)$&quot; transcoderFactoryClass=&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot; /&gt; &lt;/Context&gt; #1.只能填一个redis地址，故障转移是靠外部的redis-cluster实现的 #2.port可不写，默认是6379，如果redis带有密码，要加一个地段写上密码 4.启动tomcat观察日志 [root@node03 ~]# tail -f /usr/local/tomcat/logs/catalina.2018-03-01.log –启动日志 5.设置前端负载 nginx配置还使用上文中的配置 6.登录测试 http://192.168.34.117/myapp –访问3 7.登录redis进行验证 [root@node02 tomcat]# redis-cli 127.0.0.1:6379&gt; keys * 1) &quot;777937D858916E1389534B03D77D2E1E&quot; #验证确实和图上的session是一致的 8.zabbix监控redis 将redis的tcp端口和used_memory、used_cpu_sys纳入到zabbix监控中，在redis出现故障时，就可以以最快的时间进行修复； 3.tomcat-redis-session-manager方式实现tomcat-session-servertomcat-redis-session-manager开源项目地址 tomcat-redis-session-manager项目： 1.tomcat-redis-session-manager是一个使用redis作为tomcat-session的统一session管理开源项目； 2.对于后端redis而言，它是非粘性会话non-sticky； 3.这个项目很长时间没有更新了，而且尚未对Tomcat8提供支持； 1.将一下jar包上传到tomcat\lib目录下 binaryjedis-3.0.jar commons-pool-1.6.jar commons-pool2-2.3.jar jedis-2.8.1.jar redissession2-1.0.0.0.jar 2.修改tomcat\conf目录下的context.xml文件 添加一下内容： &lt;Valve className=&quot;cn.ce.redissession2.MyRedisSessionHandlerValve&quot; /&gt; &lt;Manager className=&quot;cn.ce.redissession2.MyRedisSessionManager&quot; host=&quot;10.2.61.1:6379;10.2.61.1:6380;10.2.61.2:6379;10.2.61.2:6380;10.2.61.3:6379;10.2.61.1:6380&quot; database=&quot;0&quot; password=&quot;redis123&quot; maxInactiveInterval=&quot;60&quot; prefix=&quot;creRedisSession&quot;timeout=&quot;30000&quot;/&gt; 解释： 1.cn.ce.redissession2.MyRedisSessionManager是指要把哪些session写进去,填一个名称 2.host：redis的地址 3.password=&quot;redis123&quot;:redis密码 4.database=&quot;0&quot;:将session写到redis的0号库中 5.prefix=&quot;creRedisSession&quot;： 写入redis时的session前缀，一般某个业务名称，记录几个系统间共用的存放在redis缓存里的前缀，所有tomcat的context.xml中都必须一样! 3.修改tomcat\conf目录下的server.xml文件 添加以下内容： &lt;Context docBase=&quot;/data/tomcat/webappa/cre&quot; sessionCookieDomain=&quot;.cecre.cn&quot; sessionCookiePath=&quot;/&quot; path=&quot;reloadable=&quot;false&quot; /&gt;]]></content>
      <categories>
        <category>web服务</category>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>web服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql_DQL操作]]></title>
    <url>%2F2017%2F11%2F03%2Fmysql-DQL%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Mysql和Mariadb的数据库操作之DQLMysql官网：官网；文档Mariadb官网：官网；文档 前文介绍了数据库操作之DDL&amp;DML&amp;DCL,下面专门介绍DQL SQL语句分类： DDL: Data Defination Language 数据定义语言 CREATE，DROP，ALTER ---&gt;创建、删除、修改 DML: Data Manipulation Language 数据操纵语言 INSERT，DELETE，UPDATE ---&gt;数据的增、删、改 DCL：Data Control Language 数据控制语言 GRANT，REVOKE，COMMIT，ROLLBACK ---&gt;授权、取消权限、提交、撤销操作 DQL：Data Query Language 数据查询语言 SELECT ---&gt;查询 DQL语句:数据查询语言—&gt;数据库的查询(select)select语法： 备注： 1.模糊匹配和正则表达式尽量少用，因为会影响服务器性能 1.*代表所有字段，当然也可以挑选字段来显示 2.字段显示可以使用别名：如用汉字显示字段名，只是显示，非更改表内容 col1 AS alias1, col2 AS alias2, ... 3.WHERE子句：指明过滤条件以实现“选择”的功能： 过滤条件：布尔型表达式 算术操作符：+, -, *, /, % 比较操作符：=,&lt;=&gt;（相等或都为空）, &lt;&gt;, !=(非标准SQL), &gt;, &gt;=, &lt;, &lt;= BETWEEN min_num AND max_num IN (element1, element2, ...) IS NULL IS NOT NULL 4.支持模糊匹配，用%表示， LIKE: % 任意长度的任意字符 _ 任意单个字符 5.支持正则表达式 RLIKE：正则表达式，索引失效，不建议使用 REGEXP：匹配字符串可用正则表达式书写模式，同上 6.逻辑操作符： NOT AND OR 与或 XOR 异或 7.DISTINCT 去除重复列 SELECT DISTINCT gender FROM students; select单表操作的用法示例select示例： 1.列过滤，使用别名 将student表name和address用别名显示出来，这里只是显示，而不是真正更改表 MariaDB [hahadb]&gt; select name as 姓名,age,address as 地址 from student; +-----------+------+-----------+ | 姓名 | age | 地址 | +-----------+------+-----------+ | li | 20 | beijing | | wang | 30 | shanghai | | 孙 | 20 | 花果山 | | 白居易 | 20 | NULL | +-----------+------+-----------+ 2.行过滤 显示年龄大于20的行 MariaDB [hahadb]&gt; select * from student where age &gt; 20; +----+------+------+------+-------+----------+ | id | name | sex | age | phone | address | +----+------+------+------+-------+----------+ | 2 | wang | m | 30 | 10010 | shanghai | +----+------+------+------+-------+----------+ 3.显示age大于等于25小于50的 select * from student where age &gt; 20 and age &lt; 50; 或者：更简洁的语法 select * from student where age between 25 and 50; #包括25但不包括50 4.显示age等于25或者等于30,或者等于50的 select * from student where age=25 or age=30 or age=50; 或者：更简洁的语法 select * from student where age in (25,30,50); 5.查询phone为NULL的行 select * from student where phone is null; 所以这就是为什么避免字段中出现空值，查询语法太特殊 6.模糊匹配name字段中包含w的行 select * from student where name like &apos;%w%&apos;; 匹配name字段中以w开头的行 select * from student where name like &apos;w%&apos;; 7.正则表达式 匹配name字段中以w开头的行 select * from student where name rlike &apos;^w&apos;; 8.将搜索到的字段进行去重，比如sex性别 MariaDB [hahadb]&gt; select distinct sex from student; +------+ | sex | +------+ | m | | f | +------+ 9.进行数字运算 MariaDB [hellodb]&gt; select 2*3; +-----+ | 2*3 | +-----+ | 6 | +-----+ 显示性别不是男的行 select * from student where gender &lt;&gt; &apos;m&apos; 10.下面示例理解其表达意思 DESC students; INSERT INTO students VALUES(1,&apos;tom&apos;，&apos;m&apos;),(2,&apos;alice&apos;,&apos;f&apos;); INSERT INTO students(id,name) VALUES(3,&apos;jack&apos;),(4,&apos;allen&apos;); SELECT * FROM students WHERE id &lt; 3; SELECT * FROM students WHERE gender=&apos;m&apos;; SELECT * FROM students WHERE gender IS NULL; SELECT * FROM students WHERE gender IS NOT NULL; SELECT * FROM students ORDER BY name DESC LIMIT 2; SELECT * FROM students ORDER BY name DESC LIMIT 1,2; SELECT * FROM students WHERE id &gt;=2 and id &lt;=4 SELECT * FROM students WHERE BETWEEN 2 AND 4 SELECT * FROM students WHERE name LIKE ‘t%’ SELECT * FROM students WHERE name RLIKE &apos;.*[lo].*&apos;; SELECT id stuid,name as stuname FROM students select选项(更复杂的操作)—&gt;更有意思的查询过滤方式GROUP BY：根据指定的条件把查询结果进行“分组”以用于做“聚合”运算 avg(), max(), min(), count(), sum() --常见的聚合函数 ！！！在这里应该注意一旦跟上group by子句以后，select后只能跟两种内容 要么是后面的分组的字段本身，要么是一些聚合函数，如：最大值，最小值，平均值总和等聚合函数！！！(后面有具体示例体现) 在group by后如果还需要过滤要用having,而不是where语句 HAVING: 对分组聚合运算后的结果指定过滤条件 ORDER BY: 根据指定的字段对查询结果进行排序 升序：ASC 降序：DESC LIMIT [[offset,]row_count]：对查询的结果进行输出行数数量限制 对查询结果中的数据请求施加“锁” FOR UPDATE: 写锁，独占或排它锁，只有一个读和写 LOCK IN SHARE MODE: 读锁，共享锁，同时多个读 select的复杂选项示例： 1.按性别统计男女的个数 MariaDB [hellodb]&gt; select gender,count(*) as 人数 from students group by gender; +--------+--------+ | gender | 人数 | +--------+--------+ | F | 10 | | M | 15 | +--------+--------+ 2.按性别统计男女的平均年龄 MariaDB [hellodb]&gt; select gender,avg(age) from students group by gender; +--------+----------+ | gender | avg(age) | +--------+----------+ | F | 19.0000 | | M | 33.0000 | +--------+----------+ 3.group by的错误示例：逻辑上不对的情况 MariaDB [hellodb]&gt; select name,gender,avg(age) from students group by gender; +-------------+--------+----------+ | name | gender | avg(age) | +-------------+--------+----------+ | Xi Ren | F | 19.0000 | | Shi Zhongyu | M | 33.0000 | +-------------+--------+----------+ 结论：这个是典型的group by的错误示例，select后是不应该带name字段的，因为 一旦跟上group by子句以后，select后只能跟两种内容要么是后面的分组的字段 本身，要么是一些聚合函数，所以name字段是多余的. 4.group by的多次分组统计 按班级和性别统计年龄的最大值 MariaDB [hellodb]&gt; select classid,gender,max(age) from students group by classid,gender; +---------+--------+----------+ | classid | gender | max(age) | +---------+--------+----------+ | NULL | M | 100 | | 1 | F | 20 | | 1 | M | 22 | | 2 | M | 53 | | 3 | F | 19 | | 3 | M | 26 | | 4 | M | 32 | | 5 | M | 46 | | 6 | F | 22 | | 6 | M | 23 | | 7 | F | 19 | | 7 | M | 23 | +---------+--------+----------+ 5.对性别统计男生的平均年龄 此处group by后需要过滤要用到having，而不是where 即先分组，再对分完组的结果进行过滤 MariaDB [hellodb]&gt; select gender,avg(age) from students group by gender having gender=&apos;m&apos;; +--------+----------+ | gender | avg(age) | +--------+----------+ | M | 33.0000 | +--------+----------+ 当然也可以用其他写法，虽然结果一样，但是前后的逻辑性就完全不同了 即先过滤完，再对结果进行分组 MariaDB [hellodb]&gt; select gender,avg(age) from students where gender=&apos;m&apos; group by gender; +--------+----------+ | gender | avg(age) | +--------+----------+ | M | 33.0000 | +--------+----------+ 6.order by排序 对年龄从小到大排显示： select * from students order by age asc; 对年龄从大到小排显示： select * from students order by age desc; 7.按age排序之后还可以再结果进行过滤 如：取出students表中年龄最小的三个 即先排序再取前三行 MariaDB [hellodb]&gt; select * from students order by age asc limit 3; +-------+-------------+-----+--------+---------+-----------+ | StuID | Name | Age | Gender | ClassID | TeacherID | +-------+-------------+-----+--------+---------+-----------+ | 14 | Lu Wushuang | 17 | F | 3 | NULL | | 8 | Lin Daiyu | 17 | F | 7 | NULL | | 19 | Xue Baochai | 18 | F | 6 | NULL | +-------+-------------+-----+--------+---------+-----------+ 8.按age排序之后，跳过前3个，取后面的4个 MariaDB [hellodb]&gt; select * from students order by age asc limit 3,4; +-------+--------------+-----+--------+---------+-----------+ | StuID | Name | Age | Gender | ClassID | TeacherID | +-------+--------------+-----+--------+---------+-----------+ | 15 | Duan Yu | 19 | M | 4 | NULL | | 12 | Wen Qingqing | 19 | F | 1 | NULL | | 10 | Yue Lingshan | 19 | F | 3 | NULL | | 7 | Xi Ren | 19 | F | 3 | NULL | +-------+--------------+-----+--------+---------+-----------+ 9.对多列排序： 如：先对班级排序，再按age排序 MariaDB [hellodb]&gt; select * from students order by classid,age desc; +-------+---------------+-----+--------+---------+-----------+ | StuID | Name | Age | Gender | ClassID | TeacherID | +-------+---------------+-----+--------+---------+-----------+ | 25 | Sun Dasheng | 100 | M | NULL | NULL | | 24 | Xu Xian | 27 | M | NULL | NULL | | 2 | Shi Potian | 22 | M | 1 | 7 | | 16 | Xu Zhu | 21 | M | 1 | NULL | | 22 | Xiao Qiao | 20 | F | 1 | NULL | | 12 | Wen Qingqing | 19 | F | 1 | NULL | | 3 | Xie Yanke | 53 | M | 2 | 16 | | 13 | Tian Boguang | 33 | M | 2 | NULL | | 1 | Shi Zhongyu | 22 | M | 2 | 3 | 但是classid结果中null值排在前面，可以在过滤的时候加一个- select * from students order by -classid,age 10.一些练习 (1) 在students表中，查询年龄大于25岁，且为男性的同学的名字和年龄 select name,age from students where age &gt; 25; (2) 以ClassID为分组依据，显示每组的平均年龄 select classid,avg(age) from students group by classid; (3) 显示第2题中平均年龄大于30的分组及平均年龄 select classid,avg(age) from students group by classid having avg(age) &gt; 30; (4) 显示以L开头的名字的同学的信息 select * from students where name like &apos;L%&apos;; (5) 显示TeacherID非空的同学的相关信息 select * from students where teacherid is not null; (6) 以年龄排序后，显示年龄最大的前10位同学的信息 select * from students order by age desc limit 10; (7) 查询年龄大于等于20岁，小于等于25岁的同学的信息 select * from students where age &gt;=20 and age &lt;= 25; 两表组合查询—&gt;重点多表操作一般对表起别名，一旦有别名，必须用别名，(因为有相同的字段，取相同字段的时候，分不清楚相同的字段是哪张表的，所以用别名区分表，然后表示不同表内的名字相同的字段)1.两张表合并的前提(又分纵向合并和横向合并)：两张表要有相同的，同一类型的字段2.两表纵向合并：即要有相同的字段，合并后的字段是两个表都有的字段3.两表横向合并：即合并后，总字段是两个表字段的总和 多表查询 横向合并：又分交叉连接和内连接 交叉连接：笛卡尔乘积：cross join 行的总数=表1的col*表2的col,虽然能查出来，但是结果没实际意义 内连接： inner join 等值连接：让表之间的字段以“等值”建立连接关系； 不等值连接 自然连接:去掉重复列的等值连接 自连接 纵向合并： 外连接：left outer join/right outer join 左外连接： FROM tb1 LEFT JOIN tb2 ON tb1.col=tb2.col 右外连接 FROM tb1 RIGHT JOIN tb2 ON tb1.col=tb2.col 完全外连接：mysql不支持，其他数据库支持 实验的功能：两张表全要，横向合并时是有条件的 就是左外连接和右外连接的union，把左外连接和右外连接重叠的部分进去去重，从而只保留一份 子查询:full outer join 查询语句中又嵌入了另外一个查询- 两表的纵向合并示例1.将students和teachers两张表纵向合并，也叫列合并 先挑取两张表相同的字段，为了好看，用到了别名 MariaDB [hellodb]&gt; select stuid as id,name,age,gender from students union select * from teachers; +----+---------------+-----+--------+ | id | name | age | gender | +----+---------------+-----+--------+ | 1 | Shi Zhongyu | 22 | M | | 2 | Shi Potian | 22 | M | | 3 | Xie Yanke | 53 | M | | 25 | Sun Dasheng | 100 | M | | 1 | Song Jiang | 45 | M | | 2 | Zhang Sanfeng | 94 | M | 当然也可以挑取出相同字段的一部分进行合并 如：只对id和name字段进行合并 select stuid as id,name from students union select tid,name from teachers; 2.如果students和teachers两张表有相同的行，则union会把相同的行去重 和前面提到的distinct的效果是一样的，当然如果表中有主键，则不是出现相同的行 两表横向合并示例：1.内连接：选两个表的交集(上图)：定义一个交集的条件：即都有的信息 2.内连接和cross join有什么区别？ cross join是把表完全组合一遍不做任何条件限制 而内连接从中挑出一部分条件的记录显示，是cross join的子集 3.内连接示例：(哪个表在左哪个表在右没有区别) 先来看一下students和teachers纵向合并有什么相同之处 MariaDB [hellodb]&gt; select * from students; +-------+---------------+-----+--------+---------+-----------+ | StuID | Name | Age | Gender | ClassID | TeacherID | +-------+---------------+-----+--------+---------+-----------+ | 1 | Shi Zhongyu | 22 | M | 2 | 3 | | 2 | Shi Potian | 22 | M | 1 | 7 | | 3 | Xie Yanke | 53 | M | 2 | 16 | | 4 | Ding Dian | 32 | M | 4 | 4 | +-------+---------------+-----+--------+---------+-----------+ MariaDB [hellodb]&gt; select * from teachers; +-----+---------------+-----+--------+ | TID | Name | Age | Gender | +-----+---------------+-----+--------+ | 1 | Song Jiang | 45 | M | | 2 | Zhang Sanfeng | 94 | M | | 3 | Miejue Shitai | 77 | F | | 4 | Lin Chaoying | 93 | F | +-----+---------------+-----+--------+ 我们发现都有TID=Teachers字段，就可以作为合并的条件 示例： 1.取students和teachers的交集，以相同的teacherid合并 两种写法：(上面是旧写法，下面是新写法) select * from students,teachers where students.teacherid=teachers.tid; 或者： select * from students inner join teachers on students.teacherid=teachers.tid; 2.第一步只是简单的合并，而我们的目的是在合并的结果里再次进行过滤 MariaDB [hellodb]&gt; select stuid,students.name as student_name,tid,teachers.name as teacher_name from students inner join teachers on students.teacherid=teachers.tid; +-------+--------------+-----+---------------+ | stuid | student_name | tid | teacher_name | +-------+--------------+-----+---------------+ | 5 | Yu Yutong | 1 | Song Jiang | | 1 | Shi Zhongyu | 3 | Miejue Shitai | | 4 | Ding Dian | 4 | Lin Chaoying | +-------+--------------+-----+---------------+ 要注意：前面的命令太长，所以一般会对表起别名，相同字段表示起来也不会太长显得啰嗦 即可以简写成： select stuid,s.name as student_name,tid,t.name as teacher_name from students as s inner join teachers as t on s.teacherid=t.tid; 外连接:(又分为左外连接和右外连接)，哪个表在左哪个表在右就很重要了有相同的记录，则把相同的合成一个大记录，即有去重功能 左外连接：意思是：左边的表记录全要，右边的表只要和左边选取的字段一样的记录，没有的行都自动 补NULL值，如下图 select * from students as s left outer join teachers as t on s.teacherid=t.tid; 左外连接特例：在左外连接的基础上，不要teachers.tid=NULL的部分,再过滤一次即可意思是：左边表记录去掉和右边表有交集的字段信息，可以在左外连接上通过条件()去过滤 select * from students as s left outer join teachers as t on s.teacherid=t.tid where t.tid is null; 右外连接：意思是：右边的表记录全要，左边的表只要和右边选取的字段一样的记录，和左外连接刚好相 反，如下图 select * from students as s right outer join teachers as t on s.teacherid=t.tid; 右外连接特例：同样道理，在右外连接的基础上，不要students.teacherid=NULL,再过滤一次即可意思是：右边表记录去掉和左边表有交集的字段信息，可以在右外连接上通过条件()去过滤， 从上图的右外连接可以对比看出明显的区别。 select * from students as s right outer join teachers as t on s.teacherid=t.tid where s.teacherid is null; 子查询：会产生临时表，消耗较多内存与CPU，极大影响数据库性能示例： 1.查询tachers表中年龄大于students表平均年龄的teacher信息 思路分析：将students表的平均年龄作为teachers查询调用的子查询 MariaDB [hellodb]&gt; select * from teachers where age &gt; (select avg(age) from students); +-----+---------------+-----+--------+ | TID | Name | Age | Gender | +-----+---------------+-----+--------+ | 1 | Song Jiang | 45 | M | | 2 | Zhang Sanfeng | 94 | M | | 3 | Miejue Shitai | 77 | F | | 4 | Lin Chaoying | 93 | F | +-----+---------------+-----+--------+ 完全连接(mysql不支持，其他数据库支持，但是在mysql中可以通过特殊方式实现)实验的功能：两张表全要，横向合并时是有条件的 就是左外连接和右外连接的union，由于union本身具有去重功能，当把左外连接和右外连 接重叠的部分进去去重，从而只保留一份 代码如下：select * from students as s left outer join teachers as t on s.teacherid=t.tid union select * from students as s right outer join teachers as t on s.teacherid=t.tid; 如下图所示 完全连接特例(mysql不支持，其他数据库支持，但是在mysql中可以通过特殊方式实现)这里实现完全连接的特例有两种思路；下面分析就是左外连接和右外连接的union，由于union本身具有去重功能，当把左外连接和右外连 接重叠的部分进去去重，从而只保留一份；然后在这个基础上再把相同的部分过滤掉！ 那么何为相同的部分呢？ 即完全连接(左外连接union右外连接):的结果上，将s.teacherid=t.tid相同的删除 但是这里表示方法特殊，要对完全连接的结果起来别名，即删除别名.teacherid=别名.tid，表示方法上要求很细致 select * from (select stuid,s.name as student_name,s.age as student_age,s.gender as student_gender,classid,teacherid,tid,t.name as teacher_name,t.age as teacher_age,t.gender as teacher_gender from students as s left outer join teachers as t on s.teacherid=t.tid union select stuid,s.name,s.age,s.gender,classid,teacherid,tid,t.name,t.age, t.gender from students as s right outer join teachers as t on s.teacherid=t.tid) as f where f.teacherid is null or f.tid is null; 在这里面因为是union，union要求有相同的字段(上文有介绍)所以在括号内的左外连接和 右外连接，select后的字段个数一样要一样且，表示的时候，由于两张表有相同的字段 名，所以还要通过别名加以区分;下图是结果 当然还可以想象是左外连接特例和右外连接特例的union，合并，结果是一样的 select * from students as s left outer join teachers as t on s.teacherid=t.tid where t.tid is null union select * from students as s right outer join teachers as t on s.teacherid=t.tid where s.teacherid is null; 自连接内连接，外连接的，别名的混合使用 下图的empolyee表内容如下 MariaDB [hellodb]&gt; select * from empolyee; +------+--------+----------+ +------+--------+----------+ | id | name | leaderid | | id | name | leaderid | +------+--------+----------+ +------+--------+----------+ | 1 | 于总 | NULL | | 1 | 于总 | NULL | | 2 | 赵 | 1 | | 2 | 赵 | 1 | | 3 | li | 2 | | 3 | li | 2 | | 4 | 周 | 3 | | 4 | 周 | 3 | +------+--------+----------+ +------+--------+----------+ 问：如何过滤出各个name和他对应的leader的name？ id,name,leadername 把一个表当成两个表，利用两个表来过滤就好理解了！如上图 MariaDB [hellodb]&gt; select a.id,a.name,b.name from empolyee as a left join empolyee as b on a.leaderid=b.leaderid; +------+--------+------+ | id | name | name | +------+--------+------+ | 2 | 赵 | 赵 | | 3 | li | li | | 4 | 周 | 周 | | 1 | 于总 | NULL | +------+--------+------+ 用到了左外连接和别名 备注：这个表容易用内连接来表示，内连接会造成左边的表少一行记录： 如： MariaDB [hellodb]&gt; select a.id,a.name,b.name from empolyee as a inner join empolyee as b on a.leaderid=b.id; +------+------+--------+ | id | name | name | +------+------+--------+ | 2 | 赵 | 于总 | | 3 | li | 赵 | | 4 | 周 | li | +------+------+--------+ 原因：内连接是取相同的交集，即下图可以明显的显示少了一条记录 MariaDB [hellodb]&gt; select * from empolyee as a inner join empolyee as b on a.leaderid=b.id; +------+------+----------+------+--------+----------+ | id | name | leaderid | id | name | leaderid | +------+------+----------+------+--------+----------+ | 2 | 赵 | 1 | 1 | 于总 | NULL | | 3 | li | 2 | 2 | 赵 | 1 | | 4 | 周 | 3 | 3 | li | 2 | +------+------+----------+------+--------+----------+ 三张表查询现在有下面三张表students，socres，courses, MariaDB [hellodb]&gt; select * from students; +-------+---------------+-----+--------+---------+-----------+ | StuID | Name | Age | Gender | ClassID | TeacherID | +-------+---------------+-----+--------+---------+-----------+ | 1 | Shi Zhongyu | 22 | M | 2 | 3 | | 2 | Shi Potian | 22 | M | 1 | 7 | | 3 | Xie Yanke | 53 | M | 2 | 16 | | 4 | Ding Dian | 32 | M | 4 | 4 | | 5 | Yu Yutong | 26 | M | 3 | 1 | +-------+---------------+-----+--------+---------+-----------+ MariaDB [hellodb]&gt; select * from courses; +----------+----------------+ | CourseID | Course | +----------+----------------+ | 1 | Hamo Gong | | 2 | Kuihua Baodian | | 3 | Jinshe Jianfa | | 4 | Taiji Quan | +----------+----------------+ 多多的关系用第三张表实现一对多的关系！如下图 MariaDB [hellodb]&gt; select * from scores; +----+-------+----------+-------+ | ID | StuID | CourseID | Score | +----+-------+----------+-------+ | 1 | 1 | 2 | 77 | | 2 | 1 | 6 | 93 | | 3 | 2 | 2 | 47 | +----+-------+----------+-------+ 问：如何过滤出学生姓名name，考试科目courseid和成绩score 分析：三表查询还是变向的实现量表查询！ a.可以先过滤出名字对应的课程编号和考试成绩 MariaDB [hellodb]&gt; select st.name,sc.courseid,sc.score from students as st inner join scores as sc on st.stuid=sc.id; +---------------+----------+-------+ | name | courseid | score | +---------------+----------+-------+ | Shi Zhongyu | 2 | 77 | | Shi Potian | 6 | 93 | | Xie Yanke | 2 | 47 | | Ding Dian | 5 | 97 | | Yu Yutong | 2 | 88 | | Shi Qing | 6 | 75 | | Xi Ren | 5 | 71 | | Lin Daiyu | 2 | 89 | | Ren Yingying | 1 | 39 | | Yue Lingshan | 7 | 63 | | Yuan Chengzhi | 1 | 96 | | Wen Qingqing | 1 | 86 | | Tian Boguang | 7 | 83 | | Lu Wushuang | 4 | 57 | | Duan Yu | 3 | 93 | +---------------+----------+-------+ b.再和第三张表内连接过滤出结果 MariaDB [hellodb]&gt; select st.name,co.course,sc.score from students as st inner join scores as sc on st.stuid=sc.id inner join courses as co on sc.courseid=co.courseid; +---------------+----------------+-------+ | name | course | score | +---------------+----------------+-------+ | Shi Zhongyu | Kuihua Baodian | 77 | | Shi Potian | Weituo Zhang | 93 | | Xie Yanke | Kuihua Baodian | 47 | | Ding Dian | Daiyu Zanghua | 97 | | Yu Yutong | Kuihua Baodian | 88 | | Shi Qing | Weituo Zhang | 75 | | Xi Ren | Daiyu Zanghua | 71 | | Lin Daiyu | Kuihua Baodian | 89 | | Ren Yingying | Hamo Gong | 39 | | Yue Lingshan | Dagou Bangfa | 63 | | Yuan Chengzhi | Hamo Gong | 96 | | Wen Qingqing | Hamo Gong | 86 | | Tian Boguang | Dagou Bangfa | 83 | | Lu Wushuang | Taiji Quan | 57 | | Duan Yu | Jinshe Jianfa | 93 | +---------------+----------------+-------+ 一些练习：导入hellodb.sql，实现下面要求 1、以ClassID分组，显示每班的同学的人数 select classid,count(*) from students group by classid; 2、以Gender分组，显示其年龄之和 select gender,sum(age) from students group by gender; 3、以ClassID分组，显示其平均年龄大于25的班级 select classid,avg(age) from students group by classid having avg(age) &gt; 25; 4、以Gender分组，显示各组中年龄大于25的学员的年龄之和 select gender,sum(age) from students where age &gt; 25 group by gender; 5、显示前5位同学的姓名、课程及成绩 思路：姓名、课程、成绩分别在三个表里，students scores courses,要想取出 这3个字段，就要对3个表查询，把3个字段联系到一起 姓名表和成绩表相同字段是stuid，成绩表和课程表相同字段是coureid，所以可以先 两表查询，再和第三个表查询 即：1.学生表和成绩表先纵向合并(stuid) select s.stuid,s.name,c.courseid,c.score from students as s inner join scores as c on s.stuid=c.stuid; 2.上面两表的查询结果再和课程表纵向合并(courseid) MariaDB [hellodb]&gt; select st.stuid,st.name,c.course,sc.score from students as st inner join scores as sc on st.stuid=sc.stuid inner join courses as c on sc.courseid=c.courseid where st.stuid &lt;= 5; 3.查询结果如下：（where s.stuid &lt;=5过滤前5个students） +-------+-------------+----------------+-------+ | stuid | name | course | score | +-------+-------------+----------------+-------+ | 1 | Shi Zhongyu | Kuihua Baodian | 77 | | 1 | Shi Zhongyu | Weituo Zhang | 93 | | 2 | Shi Potian | Kuihua Baodian | 47 | | 2 | Shi Potian | Daiyu Zanghua | 97 | | 3 | Xie Yanke | Kuihua Baodian | 88 | | 3 | Xie Yanke | Weituo Zhang | 75 | | 4 | Ding Dian | Daiyu Zanghua | 71 | | 4 | Ding Dian | Kuihua Baodian | 89 | | 5 | Yu Yutong | Hamo Gong | 39 | | 5 | Yu Yutong | Dagou Bangfa | 63 | +-------+-------------+----------------+-------+ 6、显示其成绩高于80的同学的名称及课程 和第5题一样，换一下过滤条件 MariaDB [hellodb]&gt; select st.stuid,st.name,sc.courseid,sc.score from students as st inner join scores as sc on st.stuid=sc.stuid inner join courses as c on c.courseid=sc.courseid where sc.score &gt; 80; +-------+-------------+----------+-------+ | stuid | name | courseid | score | +-------+-------------+----------+-------+ | 1 | Shi Zhongyu | 6 | 93 | | 2 | Shi Potian | 5 | 97 | | 3 | Xie Yanke | 2 | 88 | | 4 | Ding Dian | 2 | 89 | | 6 | Shi Qing | 1 | 96 | | 7 | Xi Ren | 1 | 86 | | 7 | Xi Ren | 7 | 83 | | 8 | Lin Daiyu | 3 | 93 | +-------+-------------+----------+-------+ 7、取每位同学各门课的平均成绩，显示成绩前三名的同学的姓名和平均成绩 MariaDB [hellodb]&gt; select s.name,avg(sc.score) from students as s inner join scores sc on s.stuid=sc.stuid group by s.name order by avg(sc.score) desc limit 3; +-------------+---------------+ | name | avg(sc.score) | +-------------+---------------+ | Shi Qing | 96.0000 | | Shi Zhongyu | 85.0000 | | Xi Ren | 84.5000 | +-------------+---------------+ 8、显示每门课程课程名称及学习了这门课的同学的个数 思路： 1.经过筛选，决定使用courses表、coc表和students表做查询 2.通过联系将三个表联系在了一起， select count(s.stuid),c.course from students as s inner join coc on s.classid=coc.classid inner join courses c on coc.courseid=c.courseid; 3.分组,得到的这个表用哪个分组合适？毫无疑问，用course字段合适，将该字段加入分组 MariaDB [hellodb]&gt; select count(s.stuid) as Stu_Num,c.course from students as s inner join coc on s.classid=coc.classid inner join courses c on coc.courseid=c.courseid group by c.course; +---------+----------------+ | Stu_Num | course | +---------+----------------+ | 4 | Dagou Bangfa | | 8 | Daiyu Zanghua | | 5 | Hamo Gong | | 7 | Jinshe Jianfa | | 11 | Kuihua Baodian | | 7 | Taiji Quan | | 3 | Weituo Zhang | +---------+----------------+ 9.显示其年龄大于平均年龄的同学的名字 1.子查询的写法：对数据库的性能要求比较高 MariaDB [hellodb]&gt; select name,age from students where age &gt; (select avg(age) from students); +--------------+-----+ | name | age | +--------------+-----+ | Xie Yanke | 53 | | Ding Dian | 32 | | Shi Qing | 46 | | Tian Boguang | 33 | | Sun Dasheng | 100 | +--------------+-----+ 2.第二种，内连接写法 select s.name,s.age from students as s inner join (select avg(age) as age from students) as ss on s.age &gt; ss.age; +--------------+-----+ | name | age | +--------------+-----+ | Xie Yanke | 53 | | Ding Dian | 32 | | Shi Qing | 46 | | Tian Boguang | 33 | | Sun Dasheng | 100 | +--------------+-----+ 10、显示其学习的课程为第1、2，4或第7门课的同学的名字 MariaDB [hellodb]&gt; select s.name,a.courseid from students as s inner join (select * from coc where courseid in (&apos;1&apos;,&apos;2&apos;,&apos;4&apos;,&apos;7&apos;)) as a on s.classid=a.classid; 11、显示其成员数最少为3个的班级的同学中年龄大于同班同学平均年龄的同学 思路： 1.先查询成员数量最少为3个的班级，且每个班的平均年龄 select classid,count(stuid),avg(age) from students group by classid having count(stuid)&gt;=3; 2.再将学生表的name、age与生成的该表做对比 select s.name,s.classid,cvg.ag from students as s inner join (select classid,count(stuid),avg(age) as ag from students group by classid having count(stuid)&gt;=3) as cvg where s.classid=cvg.classid and s.age &gt; cvg.ag; +---------------+---------+---------+ | name | classid | ag | +---------------+---------+---------+ | Shi Potian | 1 | 20.5000 | | Xie Yanke | 2 | 36.0000 | | Ding Dian | 4 | 24.7500 | | Yu Yutong | 3 | 20.2500 | | Yuan Chengzhi | 6 | 20.7500 | | Xu Zhu | 1 | 20.5000 | | Lin Chong | 4 | 24.7500 | | Hua Rong | 7 | 19.6667 | | Huang Yueying | 6 | 20.7500 | +---------------+---------+---------+ 12.统计各班级中年龄大于全校同学平均年龄的同学 和第12题是一样的 select stuid,name,age,classid from students where age &gt; (select avg(age) from students); +-------+--------------+-----+---------+ | stuid | name | age | classid | +-------+--------------+-----+---------+ | 3 | Xie Yanke | 53 | 2 | | 4 | Ding Dian | 32 | 4 | | 6 | Shi Qing | 46 | 5 | | 13 | Tian Boguang | 33 | 2 | | 25 | Sun Dasheng | 100 | NULL | +-------+--------------+-----+---------+ 示例： SELECT s.aage,s.ClassID FROM (SELECT avg(Age) AS aage,ClassID FROM students WHERE ClassID IS NOT NULL GROUP BY ClassID) AS s WHERE s.aage&gt;30; 联合查询：UNION SELECT Name,Age FROM students UNION SELECT Name,Age FROM teachers;]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy配置]]></title>
    <url>%2F2017%2F10%2F20%2Fhaproxy%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[HAProxy 负载均衡1.如上图，一般在防火墙后先是经过4层负载，只基于TCP协议的源IP、目标IP、源port、目标Port做转发； 2.用户请求的url是在下面的nginx服务器上做七层负载，所以在整个架构中就有了两层负载； 3.而且在HAProxy四层负载上，我们会把很多业务都放在四层负载上，所以haproxy上会根据 不同业务定义很多VIP地址(BACKEND);一个VIP再对应一个公网的IP地址；一个公网 IP再对应一个域名，这样就实现了一个负载均衡器复用的功能； 4.如何避免DDOS攻击 1.如上图，可以将域名解析成多个A记录，A记录对应不同的机房，平时80%的用户请求 转发到主机房入口，备用入口可以是阿里云的SLB或者同城机房的另外一套高可用负载； 2.或者直接使用CDN，优点很明显! 什么是负载均衡： LB是一种服务或基于硬件设备等实现的高可用反向代理技术，负载均衡将特定的业务 (web服务、网络流量等)分担给指定的一个或多个后端特定的服务器或设备，从而提高了 公司业务的并发处理能力、保证了业务的高可用性、方便了业务后期的水平动态扩展。 负载均衡优点： 1.Web服务器的动态水平扩展 对用户无感知 2.增加业务并发访问及处理能力 解决单服务器瓶颈问题 3.节约公网IP地址 降低IT支出成本 4.隐藏内部服务器IP 提高内部服务器安全性 5.配置简单 固定格式的配置文件 6.功能丰富 支持四层和七层，支持动态下线主机 7.性能较强 并发数万甚至数十万 负载均衡软件比较： 四层负载： LVS &gt; Haproxy &gt; nginx(1.9.0版本之后的stream功能) 七层负载 Haproxy &gt; nginx 应用场景： 四层：Redis、Mysql、RabbitMQ、Memcache等 七层：Nginx、Tomcat、Apache、PHP 、图片、动静分离、API等 HAProxyHAProxy官网 1.HAProxy是一款具备高并发、高性能的TCP和HTTP负载均衡器，支持基于cookie的持久性，自动故障切换，支持正则表达式及web状态统计 2.HAProxy是TCP/HTTP反向代理服务器，尤其适合于高可用性高并发环境 可以针对HTTP请求添加cookie，进行路由后端服务器 #基于cookie的会话保持颗粒度更高,nginx商业版才支持； 可平衡负载至后端服务器，并支持持久连接 #持久连接意味着会话保持可以在haproxy实现 支持基于cookie进行调度 支持所有主服务器故障切换至备用服务器 #say sorry服务器 支持专用端口实现监控服务 支持不影响现有连接情况下停止接受新连接请求 #可以对服务器打标签，不再接收请求，处理完旧请求后进行下线更新或重启 可以在双向添加，修改或删除HTTP报文首部 #修改头部报文信息达到隐藏后端web服务器版本的目的 支持基于pattern实现连接请求的访问控制 #基于正则表达式 通过特定的URI为授权用户提供详细的状态信息 #基于web页面监控服务器的状态和动态上下线服务器 haproxy组成： 程序环境： 主程序：/usr/sbin/haproxy 配置文件：/etc/haproxy/haproxy.cfg Unit file：/usr/lib/systemd/system/haproxy.service 配置段： global：全局配置段 进程及安全配置相关的参数 性能调整相关参数 Debug参数 proxies：代理配置段 defaults：为frontend, backend, listen提供默认配置 frontend：前端，相当于nginx中的server {} backend：后端，相当于nginx中的upstream {} listen：同时拥有前端和后端,适用于一对一环境 安装HAproxy12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091921.haproxy的版本区别： 1.进程管理方式不同 1.7版本之前是伪多进程，1.8以上是多进程(和nginx一样) 主进程会把内存空间共享给其他子进程，在做会话保持时，多个工作进程间的数据是共享的；如果进程之间是独立的就无法做数据共享；2.yum安装： [root@node04 ~]# yum install haproxy -y编译安装haproxy-1.8.17:1.安装依赖包： [root@node04 ~]# yum install gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel net-tools vim iotop bc zip unzip zlib-devel lrzsz tree screen lsof tcpdump wget ntpdate #由于1.8版本启动方式不同，必须安装systemd-devel包2.编译 [root@node04 src]# tar xvf haproxy-1.8.17.tar.gz &amp;&amp; cd haproxy-1.8.17 [root@node03 haproxy-1.8.17]# make ARCH=x86_64 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1 USE_CPU_AFFINITY=1 PREFIX=/usr/local/haproxy [root@node03 haproxy-1.8.17]# make install PREFIX=/usr/local/haproxy [root@node03 haproxy-1.8.17]# cp haproxy /usr/sbin/ #将编译生成的二进制命令拷贝到/usr/sbin/下 [root@node03 haproxy-1.8.17]# haproxy -v #通过命令查看编译安装的版本是否正确3.创建启动脚本： [root@node04 ]# vim /usr/lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=syslog.target network.target [Service] ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -c -q ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid ExecReload=/bin/kill -USR2 $MAINPID [Install] WantedBy=multi-user.target 4.准备配置文件： [root@node04 haproxy-1.8.17]# mkdir /etc/haproxy [root@node04 haproxy-1.8.17]# vim /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy uid 2002 gid 2002 daemon #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin nbproc 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats hide-version stats uri /status stats auth admin:admin123 stats admin if TRUE ### tomcat业务 #frontend web-port-80 # bind 192.168.34.126:80 # use_backend Web_hosts # #backend Web_hosts # server 172.20.141.45 172.20.141.45:8080 weight 2 check inter 2000 fall 3 rise 5 # server 172.20.141.44 172.20.141.44:8080 weight 1 check inter 2000 fall 3 rise 5 listen web-port-80-listen bind 192.168.34.126:80 mode http option forwardfor # rspadd X-Via:\ HAPorxy # balance first # redirect prefix https://www.liukui.tech # balance source # hash-type consistent cookie SERVER-COOKIE insert indirect nocache server 172.20.141.45 172.20.141.45:8080 cookie web45 weight 2 check inter 2000 fall 3 rise 5 server 172.20.141.44 172.20.141.44:8080 cookie web44 weight 1 check inter 2000 fall 3 rise 5 haproxy不支持像nginx一样的include配置文件，而是把所有的后端负载都写在一个文件中；5.创建用户： [root@node04 haproxy-1.8.17]# useradd haproxy -s /sbin/nologin6.启动： [root@node03 haproxy-1.8.17]# systemctl start haproxy #haproxy支持reload，会启动一个新的进程调用新的配置，处理新的请求 老的请求处理完请求后就被回收了，和nginx一样 haproxy.cfg配置文件详解详细字段说明参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136######################################################################### Haproxy 配置-global#########################################################################global配置参数 #进程及安全配置相关的参数 #性能调整相关参数pidfile /usr/local/haproxy/haproxy.pid #指定pid文件路径log 127.0.0.1 local3 info #定义全局的syslog服务器；最多可以定义两个chroot /usr/local/haproxy #锁定运行目录，类似于bind如果有漏洞，即使被攻击也只能访问这个目录deamon #以守护进程运行#stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin #socket文件 ##做服务器动态上下线摘除/开启服务器时，需要调用此socket文件，需要手动打开这个 配置，并且这个文件level必须是admin;user, group, uid, gid #运行haproxy的用户身份-------------------------------------------------------------------------- 下面这几个选项在不同版本有可能不支持--------------------------------------------------------------------------nbproc &lt;number&gt; #开启的haproxy进程数，与CPU物理核心数保持一致，新版本支持cpu-map 1 0 cpu-map 2 1 #绑定haproxy1号、2号进程与CPU核心0、1绑定，类似于nginx的affinitynbthread #指定每个haproxy进程开启的线程数，默认为每个进程一个线程； #新版本可配置，配置在1.5版本，haproxy是识别不了此字段的!!maxconn #1.每个haproxy进程的最大并发连接数；maxconn要设置很大(100000/65536) #2.只支持配置在defaults、frontend、listen字段生效 #3.需要先修改limit.conf优化内核参数；maxsslconn #SSL每个haproxy进程ssl最大连接数maxconnrate #1.每个haproxy进程每秒最大连接数； #2.只是有些业务需要限制速率时才会设置，平时是不设置的spread-checks #对后端server做健康状态检查的延迟时间 #后端server状态check随机提前或延迟百分比时间，建议2-5(20%-50%)之间######################################################################### HAProxy Proxies配置#########################################################################defaults #1.默认配置项，针对以下的frontend、backend和lsiten生效，可以多个name #2.defaults是代理后端的全局配置,最终由frontend、backend和lsiten内部再次定义的参数生效； #3.根据实际情况，在default和frontend等字段设置不同的参数值option redispatch #当server Id对应的服务器挂掉后，强制重定向到其他健康的服务器 option abortonclose #当服务器CPU负载很高的时候，自动结束掉当前队列处理比较久的链接 #类似于内核保护机制，某个进程消耗较大的资源时会被kill掉来保证系统运行option forwardfor #开启IP透传 #将用户的客户端IP传递给后端web服务器上，以便web服务的日志分析option http-keep-alive &lt;60s&gt; #开启会话保持 #在60s之内连接A服务器上如果过来不做任何操作，就会调度到后端其他服务器--------------------------------------------------------------------------mode http/tcp #1.需要指定默认工作类型 #2.如果default没设置，在frontend等字段一定要设置！-------------------------------------------------------------------------- 和502代码错误相关的timeout参数--------------------------------------------------------------------------timeout http-keep-alive 60s #session 会话保持时间timeout connect 120s/300000ms #连接到一台后端server的最长时间timeout client 600s/300000ms #与客户端的最长空闲时间 #在keep-alive 60s内-client 600s内如果客户端没有请求，就会强制断开！ #如果client time设置特别短时，就会出现很多TIME_OUT的状态，因为在TCP4次断开时，哪一方先断开连接，水才会出现TIME_OUT状态！timeout server 600s/300000ms #1.等待服务端的超时时长，一般要设置长一点！ #2.如果在600s时间内还没响应，就会报502的时间超时代码，一般是指服务间相互调用 #3.503是指haproxy没有检测到后端web服务器，就会返回503#timeout check 5s #1.对后端服务器的检测超时时间 #2.一般在default不配置，而是在backend上配置------------------------------------------------------------------------- haproxy的状态统计页面-------------------------------------------------------------------------listen statsmode httpbind 0.0.0.0:9999stats enablelog globalstats uri /haproxy-statusstats auth haadmin:q1w2e3r4ys-------------------------------------------------------------------------#########################################################################frontend &lt;name&gt; #前端servername，类似于Nginx的一个虚拟主机server&#123;&#125; #而且一定要写指定VIP和端口，不能写0.0.0.0/*:端口 #因为haproxy是会有N多VIP对应不同的业务； &lt;name&gt; #name一般写web-port-80易于区分是负载哪类业务！ bind IP:port #前端server的IP和端口(一般写keepalived的VIP地址) use_backend &lt;name&gt; #要关联的后端哪一组backend的名称 mode http/tcp #指定负载协议类型/优先级高于default字段定义--------------------------------------------------------------------------backend &lt;name&gt; #后端服务器组，等于nginx的upstream&#123;&#125; &lt;name&gt; #backend的名称，用于在frontend中调用 mode http/tcp #指定负载协议类型/优先级高于default字段定义 #frontend和backend必须成对出现；类似于nginx的server和upstream balance #定义调度算法 server servername(IP1) IP1:PORT check option server servername(IP2) IP2:PORT check option #1.经过生成环境测试，servername是要写IP地址，自动化上下线服务器时只要取得 其IP地址，上下线就很方便了！ #2.需要要server后添加check开启健康状态检测-------------------------------------------------------------------------- 后端server健康状态检测配置--------------------------------------------------------------------------check #对指定real进行健康状态检查，默认不开启 addr IP #可指定的健康状态监测IP port num #指定的健康状态监测端口 -------------------------------------------------- 常用配置项 -------------------------------------------------- inter num #健康状态检查间隔时间，默认2000ms fall num #后端服务器失效检查次数，默认为3 rise num #后端服务器从下线恢复检查次数，默认为2，一般改为5 #不过生产环境下，恢复次数要比下线次数要长，因为网络流量突然激增造成的网络 不稳定，导致可能交换机流量被打满，在网络波动没恢复之前一般多检查几次，确 保网络正常再加入进去！ weight #默认为1，最大值为256，0表示不参与负载均衡 backup #将后端服务器标记为备份状态 disabled #将后端服务器标记为不可用状态 redir http://www.cre.tech/ #1.将请求临时重定向至其它URL，只适用于http模式 #2.类似于nginx的url-rewrite -------------------------------------------------- maxconn &lt;maxconn&gt;： #当前后端server的最大并发连接数 backlog &lt;backlog&gt;： #当server的连接数达到上限后的后援队列长度 -------------------------------------------------------------------------- listen配置--------------------------------------------------------------------------listen &lt;name&gt; #将frontend和backend合并在一起配置 #一个listen可以不用定义frontend和backend了！ &lt;name&gt; #name一般写web-port-80-listen易于区分是负载哪类业务！ mode http/tcp #指定负载协议类型/优先级高于default字段定义 bind IP:port balance #定义调度算法 server servername(IP1) IP1:PORT check option server servername(IP2) IP2:PORT check option #########################################################################定义注意事项： 1.name字段只能使用&apos;-&apos;、&quot;_&quot;、&quot;.&quot;、和&quot;:&quot;，并且严格区分大小写 例如：AAA和aaa是完全不同的两组服务器######################################################################### HAproxy的调度算法–HAproxy的九种算法区别 balance： 1.指明对后端服务器的调度算法，配置在default,backend,listen 2.可以现在default指定一个默认调度算法，而且haproxy的默认调度算法是轮询 静态算法： 按照事先定义好的规则轮询公平调度，不关心后端服务器的当前负载、链接数和响应速度等，且无法实时修改权重，只能重启后生效; 动态算法： 基于后端服务器 状态进行调度适当调整，比如优先调度至当前负载较低的服务器，且权重可以在haproxy运行时动态调整无需重启； ----------------------------------------------------------------------- 两个不常用的静态算法 ----------------------------------------------------------------------- 1.first： 1.根据服务器在backend或者listen中的位置，自上而下进行调度，只有当第一台服务器的连接数达到上限，新请求才会分配给下一台服务，因此会忽略服务器的权重设置； 2.可以在server上指定maxconn &lt;number&gt;最大连接数 2.static-rr： 基于权重的轮询调度，不支持权重的运行时调整及后端服务器慢启动，其后端主机数量没有限制； ----------------------------------------------------------------------- 3.source:-会话保持，小型业务 1.源地址hash，基于用户源地址hash并将请求转发到后端服务器; 2.默认为静态即取模方式，但是可以通过hash-type支持的选项更改，后续同一个源地址 请求将被转发至同一个后端web服务器，比较适用于session保持等场景 3.类似于nginx的ip_hash; 4.适用场景： 适合于访问量比较少的场景，而且不适应于SNAT网络 hash-type map-based： 取模法，基于服务器权重的hash数组取模，该hash是静态的即不支持在线调整权重 ，不支持慢启动，其对后端服务器调度均衡，缺点是当服务器的总权重发生变化时， 即有服务器上线或下线，都会因权重发生变化而导致调度结果整体改变; 缺点： SNAT网络，ip_hash的颗粒度过于粗糙!!! hash-type consistent： 1.一致性哈希，该hash是动态的，支持在线调整权重，支持慢启动，优点在于当服务器的总权重发生变化时，对调度结果影响是局部的，不会引起大的变动； 2.支持慢启动： 新增一台服务器时，请求是逐步调度到此服务器而不是一次性全部调度的！ hash的缺点： 不管是取模法还是一致性hash都很容易导致后端服务器负载不均衡，但是比较适合 session保持!!! ----------------------------------------------------------------------- 4.uri:--缓存 基于对用户请求的uri做hash并将请求转发到后端指定服务器 mode http #负载协议类型是http才能分析用户的uri balance uri hash-type map-based：取模法 hash-type consistent：一致性哈希 ----------------------------------------------------------------------- 5.roundrobin： 轮询调度，适用于无状态，seesion共享或者会话保持 ----------------------------------------------------------------------- 6.leastconn: --适用于数据库,长连接 leastconn会根据后端服务器的负载算出最少连接的服务器，然后再调度上去， 适合于长连接 ----------------------------------------------------------------------- 7.url_param: 对用户请求的url中的&lt;params&gt;部分中的参数name作hash计算，并由服务器总权重相除以 后派发至某挑出的服务器；通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server； 适用场景： 适用于电商单点登录需要认证后的下一步操作！ 配置示例： listen web_prot_http_nodes bind 192.168.34.117:80 mode http #不支持tcp，会切换到tcp的roundrobin负载模式 balance url_param name #基于参数name做hash hash-type consistent log global option forwardfor server 192.168.7.101 192.168.7.101:8080 check inter 3000 fall 3 rise 5 server 192.168.7.102 192.168.7.102:8080 check inter 3000 fall 3 rise 5 测试： [root@node01 ~]# curl http://192.168.34.117/index.html?name=jack tomcat1 [root@node01 ~]# curl http://192.168.34.117/index.html?name=tomcat tomcat2 ----------------------------------------------------------------------- 8.hdr(&lt;name&gt;):---基于请求头部做hash(一般是host) 针对用户每个http头部(header)请求中的指定信息做hash，此处由&lt;name&gt;指定的http首 部将会被取出并做hash计算，然后由服务器总权重相除以后派发至某挑出的服务器，假如无有效的值，则会被轮询调度 hdr( Cookie、 User-Agent、host ) 配置示例： isten web_prot_http_nodes bind 192.168.7.101:80 mode http balance hdr(User-Agent) #根据不同的浏览调度到不同的后端服务器 hash-type consistent log global option forwardfor server 192.168.7.101 192.168.7.101:8080 check inter 3000 fall 3 rise 5 server 192.168.7.102 192.168.7.102:8080 check inter 3000 fall 3 rise 5 ----------------------------------------------------------------------- 9.rdp-cookie 远程桌面的负载，使用cookie保持会话 ----------------------------------------------------------------------- haproxy后端服务器的动态上下线1.需要安装socat软件 [root@node03 ~]# yum install socat 2.在配置文件中启用socket [root@node03 ~]# vim /etc/haproxy/haproxy.cfg stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin #启用socket [root@node03 ~]# mkdir /var/lib/haproxy 3.动态修改 echo &quot;set weight web-port-80-listen/172.20.141.44 1&quot; | socat stdio /var/lib/haproxy/haproxy.sock # echo &quot;show info&quot; | socat stdio /var/lib/haproxy/haproxy.sock # echo &quot;get weight web_host/192.168.7.101&quot; | socat stdio /var/lib/haproxy/haproxy.sock # echo &quot;disable server web_host/192.168.7.101&quot; | socat stdio /var/lib/haproxy/haproxy.sock # echo &quot;enable server web_host/192.168.7.101&quot; | socat stdio /var/lib/haproxy/haproxy.sock 注意： 在v1.5之后的新版本中动态修改一直是一个bug! –动态修改的bug]]></content>
      <categories>
        <category>负载均衡</category>
        <category>haproxy</category>
      </categories>
      <tags>
        <tag>LB负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy高级配置]]></title>
    <url>%2F2017%2F10%2F20%2Fhaproxy%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Haproxy高级配置 四层和七层实现透传地址–四层和七层的区别 haproxy占用内存很小 4core8G 支持几千几万的并发也就占用1~2G内存 四层： 在四层负载设备中，把client发送的报文目标地址(原来是负载均衡设备的IP地址)，根据 均衡设备设置的选择web服务器的规则选择对应的web服务器IP地址，这样client就可以直接跟此服务器建立TCP连接并发送数据； 七层： 七层负载均衡服务器起了一个代理服务器的作用，服务器建立一次TCP连接要三次握手， 而client要访问webserver要先与七层负载设备进行三次握手后建立TCP连接，把要访问 的报文信息发送给七层负载均衡；然后七层负载均衡再根据设置的均衡规则选择特定的we bserver，然后通过三次握手与此台webserver建立TCP连接，然后webserver把需要的数 据发送给七层负载均衡设备，负载均衡设备再把数据发送给client；所以，七层负载均衡设备起到了代理服务器的作用； 四层IP透传实现 配置段： listen web-port-80-listen bind 192.168.34.126:80 mode tcp #http七层IP透传 option forwardfor #如果是四层IP透传，即使开启这个也不会生效的，但不影响haproxy启动 server 172.20.141.45 172.20.141.45:8080 check inter 2000 fall 3 rise 5 server 172.20.141.44 172.20.141.44:8080 check inter 2000 fall 3 rise 5 但是需要修改后端nginx的配置： Nginx配置： listen 80 proxy_protocol; &apos;&quot;tcp_ip&quot;:&quot;$proxy_protocol_addr&quot;,&apos; #TCP获取客户端真实IP日志格式 –四层IP透传 七层IP透传实现 配置段： listen web-port-80-listen bind 192.168.34.126:80 mode http #http七层IP透传 option forwardfor #开启IP透传选项 server 172.20.141.45 172.20.141.45:8080 check inter 2000 fall 3 rise 5 server 172.20.141.44 172.20.141.44:8080 check inter 2000 fall 3 rise 5 前提： 前提是后端的nginx/tomcat的日志中开启支持的选项!!! –七层IP透传 基于cookie实现会话保持为什么要用到haproxy的cookie？ 1.会话保持是当用户在一段时间之内访问前端的负载均衡时，然后就把用户调度到和上次同一个后端web服务器上，实现方式有很多种，如ip_hash,hash consistent等调度 算法！ 2.ip_hash等算法调度的颗粒度过于粗糙，对于SNAT网络模型来说就更是如此； 3.但是cookie不同，cookie是由服务器发给每一个浏览器的，而且即使是在SNAT网络下 cookie也不会重复，所以说cookie的颗粒度就更适合网站了； 4.nginx只有商业版支持，haproxy却可以,基于cookie做会话保持就相当好了! Cookie实现: 1.为当前server指定cookie值，实现基于cookie的会话黏性；而且 2.cookie一定是在负载均衡上做判断的！ cookie &lt;name&gt; [ rewrite | insert | prefix ] [ indirect ] [ nocache ] [ postonly ] [ preserve ] [ httponly ] [ secure ] [ domain &lt;domain&gt; ]* [ maxidle &lt;idle&gt; ] [ maxlife &lt;life&gt; ] &lt;name&gt;：cookie名称，用于实现持久连接 rewrite：重写 #之前如果有cookie就会被覆盖掉 insert：插入 prefix：前缀 nocache：当client和hapoxy之间有缓存时，不缓存cookie，如CDN 具体示例： listen web-port-80-listen bind 192.168.34.126:80 mode http option forwardfor cookie SERVER-COOKIE insert indirect nocache server 172.20.141.45 172.20.141.45:8080 cookie web45 weight 2 check inter 2000 fall 3 rise 5 server 172.20.141.44 172.20.141.44:8080 cookie web44 weight 1 check inter 2000 fall 3 rise 5 server 172.20.141.43 172.20.141.43:8080 cookie web43 weight 1 check inter 2000 fall 3 rise 5 server 172.20.141.42 172.20.141.42:8080 cookie web42 weight 1 check inter 2000 fall 3 rise 5 #生产环境下的cookie我们一般在根据业务和端口来区分的!!! –cookie配置–cookie调度效果 配置HAProxy状态页stats enable #基于默认的参数启用stats page stats hide-version #haproxy隐藏版本 stats refresh &lt;delay&gt; #设定自动刷新时间间隔 stats uri &lt;prefix&gt; #自定义stats page uri，默认值：/haproxy?stats stats realm &lt;realm&gt; #账户认证时的提示信息，示例：stats realm : HAProxy\ Statistics stats auth &lt;user&gt;:&lt;passwd&gt; #认证时的账号和密码，可使用多次， 默认：no authentication stats admin { if | unless } &lt;cond&gt; #启用stats page中的管理功能 配置示例： listen stats mode http bind 192.168.34.126:9999 #只允许内网IP访问 stats enable #启用status监控页面 log global stats hide-version #为了安全，隐藏版本 stats uri /status stats auth admin:admin123 #验证用户和密码 stats admin if TRUE #启用页面上的管理功能 –管理页面 修改报文首部注意： 请求报文头部时http层的，所以需要定义mode http,而不是tcp 在请求报文尾部添加指定首部 reqadd &lt;string&gt; [{if | unless} &lt;cond&gt;] #支持条件判断 从请求报文中删除匹配正则表达式的首部 reqdel &lt;search&gt; [{if | unless} &lt;cond&gt;] reqidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 不分大小写 示例： reqdel User-Agent:* #删除请求报文中的浏览器类型，这样在后端的tomcat上就看不到了 在响应报文尾部添加指定首部 rspadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 示例：rspadd X-Via:\ HAPorxy 从响应报文中删除匹配正则表达式的首部 rspdel &lt;search&gt; [{if | unless} &lt;cond&gt;] rspidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 示例： rspidel server.* #从相应报文删除server信息 rspidel X-Powered-By:.* #从响应报文删除X-Powered-By信息 HAProxy的日志配置–一般是不开启的注意： 1.haroxy的日志是基于rsyslog来传输的，所以需要配置rsyslog.conf 2.haproxy虽然可以配置日志，但是不建议开启，影响haproxy性能，而且生产环境下是 通过ELK直接收集后端nginx/tomcat的日志进行分析的！ 1.在default配置项定义： log 127.0.0.1 local{1-7} info #基于syslog记录日志到指定设备，级别有(err、warning、info、debug) 2.配置rsyslog： [root@haproxy]# vim /etc/rsyslog.conf $ModLoad imudp $UDPServerRun 514 local6.* /var/log/haproxy.log #打开上面两个UDP配置和日志级别以及日志存放的位置 #要注意local6必须和haproxy.conf中是一致的！ 3.配置HAProxy： listen web_port bind 127.0.0.1:80 mode http log global #要注意listen和backend上要配置log global才可以记录访问信息 option tcplog server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5 4.重启rsyslog服务和haproxy并访问haproxy状态页 –日志信息 对HAProxy的后端服务集群检测option httpchk option httpchk &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt; 生产配置示例： listen web_prot_http_nodes bind 192.168.7.102:80 mode http log global option httpchk HEAD /wp-includes/js/jquery/jquery.js?ver=1.12.4 HTTP/1.0\r\nHost:\ 192.168.7.102 #通过request获取的头部信息进行匹配进行健康检测 server 192.168.7.102 192.168.7.102:80 cookie web1 check inter 3000 fall 3 rise 5 server 192.168.7.101 192.168.7.101:80 cookie web2 check inter 3000 fall 3 rise 5 检测结果： 因为检测间隔较短，所以准备的特定文件很小，在日志中大小在最后是没显示的！ –健康状态检测 haproxy自定义错误页面自定义错误页面： defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms errorfile 500 /usr/local/haproxy/html/500.html #自定义错误页面跳转 errorfile 502 /usr/local/haproxy/html/502.html #502是指haproxy向后端server发请求超时了！ errorfile 503 /usr/local/haproxy/html/503.html #503是指后端的server全down了； #自定义完，然后创建对应目录下的各种状态码的html文件！ 临时重定向跳转： errorloc 503 http://192.168.50.113/error_page/503.html #自定义跳转到事先定义的网站上 haproxy支持负载https生成证书 # mkdir /usr/local/haproxy/certs # cd /usr/local/haproxy/cert # openssl genrsa -out haproxy.key 2048 # openssl req -new -x509 -key haproxy.key -out haproxy.crt -subj &quot;/CN=www.test.com&quot; # cat haproxy.key haproxy.crt &gt; haproxy.pem # openssl x509 -in haproxy.pem -noout -text #查看证书 支持ssl会话； bind *:443 ssl crt /PATH/TO/SOME_PEM_FILE crt 后证书文件为PEM格式，且同时包含证书和所有私钥 cat demo.crt demo.key &gt; demo.pem 把80端口的请求重向定443 bind *:80 redirect scheme https if !{ ssl_fc } 向后端传递用户请求的协议和端口（frontend或backend） http_request set-header X-Forwarded-Port %[dst_port] http_request add-header X-Forwared-Proto https if { ssl_fc } 示例 frontend https bind 192.168.50.113:443 ssl crt /usr/local/haproxy/certs/haproxy.pem use_backend web_host backend default_host mode http server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5 server web2 192.168.50.81:8080 check inter 2000 fall 3 rise 5 backend web_host mode http http-request set-header X-Forwarded-Port %[dst_port] http-request add-header X-Forwarded-Proto https if { ssl_fc } server web1 192.168.50.178:8080 check inter 2000 fall 3 rise 5 server web2 192.168.50.81:8080 check inter 2000 fall 3 rise 5 将haproxy的配置文件内容类似于nginx的include方式加载作用： 由于haproxy默认不支持像nginx一样通过在主配置文件中include某个目录来加载该目录下 的所有配置文件，所以可以通过对不同版本的HAProxy启动脚本达到目的！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748########################################################################### Haproxy-V1.5版本修改方式########################################################################### 1.在haproxy的1.5版本是不支持启动时加载目录的，只支持加载多文件 [root@node01 ~]# haproxy -h HA-Proxy version 1.8.17 2019/01/08 Copyright 2000-2019 Willy Tarreau &lt;willy@haproxy.org&gt; Usage : haproxy [-f &lt;cfgfile&gt;]* #这里只支持通过多个-f &lt;文件&gt; #修改haproxy-V1.5版本的启动脚本支持加载conf下的配置文件 [root@node03 haproxy]# vim /usr/lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=syslog.target network.target [Service] EnviromentFile=/etc/sysconfig/haproxy ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/web1.cfg -p /run/haproxy.pid #启动时加载haproxy.cfg和/web1.cfg两个配置文件 ExecReload=/bin/kill -USR2 $MAINPID KillMode=mixed [Install] WantedBy=multi-user.target ########################################################################### Haproxy-V1.8版本修改方式########################################################################### 2.在haproxy的V1.8版本支持加载目录 [root@node03 ~]# haproxy -h HA-Proxy version 1.8.17 2019/01/08 Copyright 2000-2019 Willy Tarreau &lt;willy@haproxy.org&gt; Usage : haproxy [-f &lt;cfgfile&gt;]* #这里只支持多文件和目录 [root@node03 ~]# cd /etc/haproxy/ [root@node03 haproxy]# mkdir conf #创建一个存放配置文件的目录 [root@node03 haproxy]# vim conf/web1.cfg web2.cfg #修改haproxy的启动脚本支持加载conf下的配置文件 [root@node03 haproxy]# vim /usr/lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=syslog.target network.target [Service] ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/conf -c -q #启动时加载/etc/haproxy/conf目录下的所有.cfg文件 ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -f /etc/haproxy/conf -p /run/haproxy.pid ExecReload=/bin/kill -USR2 $MAINPID [Install] WantedBy=multi-user.target #这样就可以将haproxy的配置文件根据业务分开存放了；]]></content>
      <categories>
        <category>负载均衡</category>
        <category>haproxy</category>
      </categories>
      <tags>
        <tag>LB负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下双网卡绑定及Bridge]]></title>
    <url>%2F2017%2F10%2F18%2FLinux%E4%B8%8B%E5%8F%8C%E7%BD%91%E5%8D%A1%E7%BB%91%E5%AE%9A%E5%8F%8ABridge%2F</url>
    <content type="text"><![CDATA[Linux的双网卡绑定及Bridge一：linux操作系统下双网卡绑定有七种模式。现在一般的企业都会使用双网卡接入，这样既能添加网络带宽，同时又能做相应的冗余，可以说是好处多多。而一般企业都会使用linux操作系统下自带的网卡绑定模式，当然现在网卡产商也会出一些针对windows操作系统网卡管理软件来做网卡绑定，一共有其中方式，其中比较长用的是0/1/6：二：windows操作系统没有网卡绑定功能需要第三方支持：DELLr720一般都是博科的网卡，Inter网卡，随机光盘和网上 有很多双网卡绑定的软件. 1：网卡绑定案例，先做绑定，然后再把绑定后的网卡配置成桥接： 1.1：第一组配置，将eth1和eth5绑定为bond0： 1.1.1：先创建bond0配置那文件步骤及内容如下： [root@linux-host1 ~]# cd /etc/sysconfig/network-scripts/ [root@linux-host1 network-scripts]# cp ifcfg-eth0 ifcfg-bond0 [root@linux-host1 network-scripts]# cat ifcfg-bond0 #内容如下： BOOTPROTO=static NAME=bond0 DEVICE=bond0 ONBOOT=yes BONDING_MASTER=yes BONDING_OPTS=&quot;mode=1 miimon=100&quot; #指定绑定类型为1及链路状态监测间隔时间 BRIDGE=br0 #桥接到br0 1.1.2：配置br0： TYPE=Bridge BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=br0 DEVICE=br0 ONBOOT=yes IPADDR=X.X.X.X NETMASK=255.255.255.0 GATEWAY=X.X.X.X 1.1.3：eth1配置： [root@linux-host1 network-scripts]# vim ifcfg-eth1 BOOTPROTO=static NAME=eth1 DEVICE=eth1 ONBOOT=yes NM_CONTROLLED=no MASTER=bond0 USERCTL=no SLAVE=yes 1.1.4：eth5的配置： [root@linux-host1 network-scripts]# cp ifcfg-eth1 ifcfg-eth5 [root@linux-host1 network-scripts]# vim ifcfg-eth5 BOOTPROTO=static NAME=eth5 DEVICE=eth5 ONBOOT=yes NM_CONTROLLED=no MASTER=bond0 USERCTL=no SLAVE=yes 1.1.5：重启网络服务： [root@linux-host1 network-scripts]# systemctl restart network 1.1.6：验证网络是否正常： [root@linux-host1 network-scripts]# ping www.baidu.com PING www.a.shifen.com (61.135.169.125) 56(84) bytes of data. 64 bytes from 61.135.169.125: icmp_seq=1 ttl=128 time=6.17 ms 64 bytes from 61.135.169.125: icmp_seq=2 ttl=128 time=10.3 ms 64 bytes from 61.135.169.125: icmp_seq=3 ttl=128 time=5.36 ms 64 bytes from 61.135.169.125: icmp_seq=4 ttl=128 time=6.74 ms 64 bytes from 61.135.169.125: icmp_seq=5 ttl=128 time=5.71 ms 1.1.:6：可以验证当前是绑定在哪一块网卡上的： [root@linux-host1 ~]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011) Bonding Mode: fault-tolerance (active-backup) Primary Slave: None Currently Active Slave: eth1 #备份链路网卡 MII Status: up MII Polling Interval (ms): 100 Up Delay (ms): 0 Down Delay (ms): 0 Slave Interface: eth1 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 18:66:da:f3:34:e5 Slave queue ID: 0 Slave Interface: eth5 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0a:f7:99:ba:d1 Slave queue ID: 0 1.2：第二组配置，将eth2和eth6绑定为bond1： 1.2.1：创建bond1配置文件： [root@linux-host1 network-scripts]# cp ifcfg-bond0 ifcfg-bond1 [root@linux-host1 network-scripts]# vim ifcfg-bond1 BOOTPROTO=static NAME=bond1 DEVICE=bond1 TYPE=Bond BONDING_MASTER=yes BOOTPROTO=static NAME=bond1 ONBOOT=yes BONDING_OPTS=&quot;mode=1 miimon=100&quot; BRIDGE=br1 1.2.2：配置br1： TYPE=Bridge BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=br1 DEVICE=br1 ONBOOT=yes IPADDR=X.X.X.X NETMASK=255.255.255.0 GATEWAY=X.X.X.X DNS1=X.X.X.X 1.2.3：eth2的配置： [root@linux-host1 network-scripts]# vim ifcfg-eth2 BOOTPROTO=static NAME=eth2 DEVICE=eth2 ONBOOT=yes NM_CONTROLLED=no MASTER=bond1 USERCTL=no SLAVE=yes 1.2.4：eth6的配置： [root@linux-host1 network-scripts]# vim ifcfg-eth6 BOOTPROTO=static NAME=eth6 DEVICE=eth6 ONBOOT=yes NM_CONTROLLED=no MASTER=bond1 USERCTL=no SLAVE=yes 1.2.5：重启网络服务： [root@linux-host1 network-scripts]# systemctl restart network 1.2.6：测试内网网络是否正常： [root@linux-host1 network-scripts]# ping 192.168.20.12 PING 192.168.20.12 (192.168.20.12) 56(84) bytes of data. 64 bytes from 192.168.20.12: icmp_seq=1 ttl=64 time=1.86 ms 64 bytes from 192.168.20.12: icmp_seq=2 ttl=64 time=0.570 ms 64 bytes from 192.168.20.12: icmp_seq=3 ttl=64 time=0.410 ms 1.3：设置开机启动： [root@linux-host1 network-scripts]# vim /etc/rc.d/rc.local ifenslave eth1 eth5 ifenslave eth2 eth6 [root@linux-host1 network-scripts]# chmod a+x /etc/rc.d/rc.local 1.4：重启系统后验证网络]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes-集群外Promethues监控k8s集群]]></title>
    <url>%2F2017%2F10%2F18%2FKubernetes-%E9%9B%86%E7%BE%A4%E5%A4%96Promethues%E7%9B%91%E6%8E%A7k8s%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[创建文章的默认模板，可根据实际情况修改 Till I reach the end, then I’ll start again《Try Everything》 1 // 插入音乐 或者 // 表示图片在左边或者右边，中间(left，right，center) // markdown格式测试，就是要测试一下啊啊啊啊a 文本上带一条横线，表示错误 This is an H1 Red Green Blue This is a blockquoteinside a list item. http://example.com/ This is an H2// 插入图片并设置大小两种方法 // 颜色选择 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP三次握手、四次断开与十一种状态]]></title>
    <url>%2F2017%2F10%2F18%2FTCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E3%80%81%E5%9B%9B%E6%AC%A1%E6%96%AD%E5%BC%80%E4%B8%8E%E5%8D%81%E4%B8%80%E7%A7%8D%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[TCP三次握手、四次断开与十一种状态 OSI模型由下到上分别为物理层、数据链路层、网络层、传输层、会话层、表示层、应用层 1：第七层：应用层的功能： 为应用软件提供接口，使应用程序能够使用网络服务。常见的应用层协议： http(80)、ftp(20/21)、smtp(25)、pop3(110)、telnet(23)、dns(53)等 2：第六层：表示层的功能： 数据的编码和解码、数据的加密和解密、数据和压缩和解压缩，常见的标准有JPEG/ASCII等 3：第五层：会话层的功能： 建立、管理和终止表示层实体之间的会话连接，在设各或节点之间提供会话控制，它在系统之间协调通信过程,并提供3种 不同的方式来组织它们之间的通信:单工、半双工和全双工 4：第四层：传输层的功能： 负责建立端到端的连接，保证报文在端到端之间的传输。提供可靠TCP及不可靠UDP的传输机制,服务点编址、分段与重组 、连接控制、流量控制、差错控制。 5：第三层：网络层的功能： 定义逻辑地址,逻辑寻址，将数据分组从源传输到目的,路径选择、路由发现、维护路由表，功能是隔离广播域；隔离广播 ,路由选择；维护路由表,寻址及转发,流量管理并连接广域网 6：第二层：数据链路层的功能： 组帧、物理编址，将数据帧从链路上的一个节点传递到另一个节点，流量控制、差错控制、接入控制 7：第一层：物理层的功能： 在介质上传递比特流，定义接口和媒体的物理特性，定义比特的表示、数据传输速率、信号的传输模式（单工、半双工、全 双工），定义网络物理拓扑（网状、星型、环型、总线型等） TCP协议简介：TCP，全称Transfer Control Protocol，中文名为传输控制协议，它工作在OSI的传输层，提供面向连接的可靠传输服务，TCP的工作主要是建立连接，然后从应用层程序中接收数据并进行传输。TCP采用虚电路连接方式进行工作，在发送数据前它需要在发送方和接收方建立一个连接，数据在发送出去后，发送方会等待接收方给出一个确认性的应答，否则发送方将认为此数据丢失，并重新发送此数据。TCP的报文头部结构：-TCP的报文头部结构 TCP三次握手：在建立连接的时候，所谓的客户端与服务端是相对应的，即要看是谁主动连接的谁，如果A主动连接B那么A就是客户端 而B是服务端，如果返过来B主动连接A，那么B就是客户端而A就成了服务端。 1:连接过程： 第一次握手：客户端发送SYN标志位为1的请求到服务端，并随机生成一个seq 序列号x，其中seq是随机产生的数据包的序列号。 第二次握手：服务器收到客户端请求并返回SYN=1，ACK=1，seq=y，ack=x+1，其中ACK=1表示是响应报文，seq=y是 服务器随机产生的数据包序列号，ack=x+1是确认客户端序列号有效并返回给客户端确认。 第三次握手：客户端收到服务器的确认ack=x+1有效的验证信息，即在自己发送的序列号基础之上加了1表示服务器收到 并返回，表示第二次连接有效，然后客户端恢回复ACK=1，seq=x+1，ack=y+1，这是讲服务器发来+1后的序列号当做自 己的seq序列号，确认号ack使用服务器的随机号y再加1即ack=y+1，这样客户端就完成了第三次的验证在讲数据包发给 服务器，服务器收到后验证确认号是在自己的seq之上加了1，表示没有问题就开始传输数据。 注： ACK :TCP协议规定，只有ACK=1时有效，也规定连接建立后所有发送的报文的ACK必须为1 Seq:序号,4字节，范围为0^32—1^32,共4284967296，达到时重新开始计算 在第三次的时候SYN等于0，因为SYN(SYNchronization) 只i在连接建立时用来同步序号,当SYN=1而ACK=0时,表明这 是一个连接请求报文,对方若同意建立连接,则应在响应报文中使SYN=1和ACK=1. 因此, SYN置1就表示这是一个连接请求或连接接受报文，链路建立成功之后就将标志位置为0。 SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急) Sequence number(顺序号码) Acknowledge number(确认号码) -TCP三次握手 TCP的四次断开：TCP断开要四次是因为TCP传输数全双工的，即数据是在同一时间内两条数据链路双向互相传输的，因此每个方向都要单 独关闭一次，断开需要客户端到服务端断开一次，而服务端到客户端也需要断开一次，这样的断开才是完整的断开， 第一次断开：客户方发给服务器一个FIN为1的请求，FIN为1表示是一个断开连接的请求，即表示数据传输完毕请求断开 ，并发送seq序列号和Ack确认号。 第二次断开：服务器收到客户端请求并返回ACK标志位为1，Ack为Seq+1等于201，并将对方的Ack作为自己的Seq序列号 的确认数据包，biao 接收到请求同意断开。 第三次断开：服务器发送ACK=1，FIN=1，Seq等于客户端第一次请求断开的Ack确认号+1，即Seq等于501的断开请求给客户端。 第四次断开：客户端发送ACK=1，Ack在上一步Seq上+1等于502，并使用在第二次断开中服务器发送的Ack确号201作为 本次的序列号发给服务器表示同意断开，服务器收到后验证序列号是第二次的，验证Ack是第三次+1的，确认没有问题后 同意断开，然后将端口置为TIME_WAIT状态，等待2 MSL时间后置为关闭状态，被动方收到主动方的报文确认Ack确认号没有问题后将端口置为CLOSED，至此端口g。 SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急) Sequence number(顺序号码) Acknowledge number(确认号码) 四次断开的图形示意如下： -TCP四次挥手 TCP端口的十一种连接状态：TCP端口一共有十一种状态，CLOSE_WAIT表示是程序y关闭连接，而TIME_WAIT只占用一个socket连接，到时间之后会 释放，因此大量的CLOSE_WAIT是比大量的TIME_WAIT影响更大，另外还有FIN_WAIT1和FIN_WAIT2，如果有 FIN_WAIT2也表示服务有问题，以下是每个端口状态的含义： 1：CLOSED：端口默认是关闭状态。 2：LISTEN： 服务器程序开始监听一个端口，就是LISTEN状态。 3：SYN_RCVD：三次握手的第二次握手后的端口状态，是收到了客户端发送的SYN_SENT数据包之后的状态，这个状态很 短暂，正常在服务器上是很少看到的，除非服务器故意不发送最后一次握手数据包，服务器返回给客户端SYN确认之后就 会将在自己的端口置为SYN_RCVD。 4：SYN_SENT：SYN_SENT状态表示客户端已发送SYN=1的请求连接报文，发送之后客户端就会将自己的端口状态置为SYN_SENT。 5：ESTABLISHED：表示已经连接成功，客户端收到服务器的确认报文会回复服务器，然后就将端口置为ESTABLISHED， 服务器第三次收到客户端的Ack确认就会将端口置为ESTABLISHED并开始传输数据。 6：FIN_WAIT_1：出现在主动关闭方，FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，当任意一方想主动 关闭连接，向对方发送了FIN=1的断开连接请求报文，此时该SOCKET即 进入到FIN_WAIT_1状态。而当对方回应ACK报文 后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马 上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。 7：FIN_WAIT_2：出现在主动关闭方，当被动方回应FIN_WAIT_1的ACK报文后，则进入到FIN_WAIT_2状态 8：TIME_WAIT：出现在主动关闭方，表示收到了对方的FIN请求关闭报文，并发送出了ACK报文，就等2MSL后即可回到 CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到 TIME_WAIT状态，而无须经过FIN_WAIT_2状态。 9：CLOSING： 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送 FIN报文后，按理来说是应该先收到（或同时收到）对方的 ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你 发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什 么情况下会出现此种情况呢？其实细 想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报 文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。 10：CLOSE_WAIT： 表示在等待关闭端口，这种状态存在于被动关闭的一方。 11：LAST_ACK： 是被动关闭方在主动关闭一方在发送FIN报文后，最后等待对方的ACK报文，当再次收到ACK报文后，也即可以进入到CLOSED可用状态了。 12：区分主动断开和被动端口方的端口状态： 主动端口方：SYN_SENT、FIN_WAIT1、FIN_WAIT2、CLOSING、TIME_WAIT 。 被动断开方：LISTEN、SYN_RCVD、CLOSE_WAIT、LAST_ACK 。 都具有的：CLOSED 、ESTABLISHED 。 -TCP的11种状态 关于优化：socket就是一个TCP连接，包括源地址、源端口、目标地址、目标端口和协议(TCP|UDP),0端口是保留不能使用的， 因此服务器的最大端口使用数量为63353个，最大65536个端口是因为TCP报文头部有个端口长度为2^16次方等于 65536，查看当前打开的端口范围# cat /proc/sys/net/ipv4/ip_local_port_range，单个IP地址能接受的最大并 发为六万多，1万个TIME_WAIT大约使用1MB的内存CPU占用更小，因此资源使用很小可以忽略不计，但是会占用一个 socket，可以通过在负载上配置多个公网IP地址以提高高并发的问题， [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_recycle 0 #用于快速回收处于TIME_WAIT状态的socket以便重新分，在负载服务器不能打开，会导致通过nat上网的后续用户 无法打开网页，因为后面的访问用户时间戳小于前面的用户，会导致数据包被负载服务器丢弃，可以在内网使用，但是通常建议关闭。 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_reuse 0 #kernel会复用处于TIME_WAIT状态的socket，即允许将TIME_WAIT状态得socket用于直接新的TCP连接，负载服务器建议打开 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_timestamps 1 #记录数据包的时间戳，判断是新的数据包还是旧的，如果是旧的就丢弃，配合上面两个选项的时候一定要打开才生效。]]></content>
      <categories>
        <category>TCP协议</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpd]]></title>
    <url>%2F2017%2F10%2F18%2Fhttpd%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. 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]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建内网yum源]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%90%AD%E5%BB%BA%E5%86%85%E7%BD%91yum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[创建文章的默认模板，可根据实际情况修改 Till I reach the end, then I’ll start again《Try Everything》 1 // 插入音乐 或者 // 表示图片在左边或者右边，中间(left，right，center) // markdown格式测试，就是要测试一下啊啊啊啊a 文本上带一条横线，表示错误 This is an H1 Red Green Blue This is a blockquoteinside a list item. http://example.com/ This is an H2// 插入图片并设置大小两种方法 // 颜色选择 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之awk]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk%2F</url>
    <content type="text"><![CDATA[文本处理三剑客之awk Awk的用户使用指南awk用户指南 相关链接文章：正则表达式： 正则表达式grep文本编辑： grep用法sed文本编辑： sed用法 总结对比一下这三个剑客的特长之处grep、sed、awk被称为linux中的三剑客 grep更适合单纯的查找或匹配文件.sed更适合编辑皮匹配到的文本awk更适合格式化文本，对文本进行比较复杂格式处理 文本三剑客都是默认逐行处理，自带循环sed 可以对文本进行修改，而grep&amp;awk 只是对文本进行过滤,不进行内容修改 awk中的-F后面的分隔符,要用单引号’’,双引号””会产生弱引用,比如特殊符号’\\‘ ‘\\$’关于awk中的单引号和双引号的问题参照：awk中的输入分隔符单引号&amp;双引号 学习awk的一个重要知识点 先举两个例子： awk &apos;/^UUID/&apos; /etc/fstab = awk &apos;/^UUID/{print $0}&apos; /etc/fstab 其实是隐藏了{print $0}的写法 数组中的例子 awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6 实际上是隐藏了{print $0} 学习中遇到的混淆的问题：&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印 而后面的数组里的是加了双括号{}，即用的patter的空模式，即文本中的每一行都处理 Awk基本用法和功能以及各个功能示例：awk介绍awk基本用法awk变量awk格式化-printfawk操作符awk条件判断awk循环awk数组awk函数调用系统命令 awk介绍：whatis awk？ awk：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出，输出成报表格式 linux上默认使用 GNU awk(gawk) [root@centos7 data]which awk /usr/bin/awk [root@centos7 data]ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Sep 19 11:45 /usr/bin/awk -&gt; gawk which awk=/usr/bin/awk 是gawk的软链接 awk基本用法awk [options] &apos;program&apos; var=value file… awk [options] -f programfile var=value file… awk [options] &apos;BEGIN{action;… }pattern{action;… }END{action;… }&apos; file ... awk 程序可由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句 块，共3部分组成 program 通常是被放在单引号中 选项： -F “分隔符” 指明输入时用到的字段分隔符 -v var=value 变量赋值 基本格式：awk [options] &apos;program&apos; file… Program：pattern{action statements;..} 也就是说awk用法：awk [options] &apos;pattern{action statements;..}&apos; file… pattern和action • pattern部分决定动作语句何时触发及触发事件 BEGIN,END • action statements对数据进行处理，放在{}内指明 print, printf 分割符、域和记录 • awk执行时，由分隔符分隔的字段（域）标记$1,$2...$n称为域标识。$0 为所有域，注意：此时和shell中变量$符含义不同 • 文件的每一行称为记录 • 省略action，则默认执行 print $0 的操作 print格式：print item1, item2, ... 要点： (1) 逗号分隔符 (2) 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式 (3) 如省略item，相当于print $0 用法解析及示例：$0=代表处理的整行的内容 $1,$2,$3..代表每一列，也就域 BEGIN，END是为生成一个报表的头和尾准备的，用法通常为： BEGIN：为生成报告模式 添加表头;END:为生成的报告 进行信息汇总 awk &apos;BEGIN{print xxx}{print xxx}END{print xxx}&apos; 注意：BEGIN{print *xxx}处理文本前，打印一遍xxx的内容当成表头 END{print xxx},处理文本后，打印一遍xxx的内容作为表尾 BEGIN&amp;ENDBEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。 END：让用户在最后一条输入记录被读取之后发生的动作。 分隔符：awk默认使用空白符作为字段或列的分隔符；多个空白符被认为是一个，空白符包括空格，tab键/t，回车\n 也可以自定义-F&quot;分隔符&quot;自定义分隔符 print&amp;printf的区别：print命令只是单纯的把特定的内容进行打印，默认换行 printf命令可以把内容以灵活的格式进行显示,如左对齐,右对齐 示例1.awk支持标准输入输出，后面可以不跟文件 [root@centos7 ~]#awk &apos;{print $0}&apos; aaaa aaaa abcabc abcabc 2.打印/etc/passwd：对比几个输出结果 awk &apos;{print $0}&apos; /etc/passwd 把passwd文件全部打印出来 awk &apos;{print &quot;abc&quot;}&apos; /etc/passwd 读入的是passwd文件所有行，打印的是abc awk -v abc=1 &apos;{print abc}&apos; /etc/passwd 读入的是passwd文件所有行，打印的都是1 awk &apos;{print &quot;abc&quot;$0}&apos; /etc/passwd 把passwd文件所有行前都加一个abc,进行输出 所以在awk中不加双引号，abc被识别为变量，如果要引用变量，需要-v先定义值 如果只是想输出abc字符串，需要加双引号 3.awk{}中支持数字运算 awk &apos;{print 1+2}&apos; /etc/passwd 打印多行1+2=3的值 awk &apos;{print &quot;1+2&quot;}&apos; /etc/passwd 加双引号会把1+2当成字符串，输出多行1+2 4.取分区利用率df, df |awk &apos;{print $1,$5}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos; 5.以输入重定向方式，打印 passwd 文件的第1列，即获取当前系统中存在的所有用户和UID awk -F: &apos;{print $1,$3}&apos; &lt; /etc/passwd cat /etc/passwd | awk -F: &apos;{print $1,$3}&apos; awk -F: &apos;{print $1：$3}&apos; /etc/passwd 两列输出时，指定以：进行隔开，默认为空格隔开 awk -F: &apos;{print $1、$3}&apos; /etc/passwd 两列输出时，指定以：进行隔开，默认为空格隔开 cat /etc/passwd | awk -F: &apos;{print $1&quot;\n&quot; $3}&apos; 两列输出时,进行换行 cat /etc/passwd | awk -F: &apos;{print $1&quot;\t&quot; $3}&apos; 两列输出时,以tab键隔开 备注：多行输出时，可以在双引号之间加自定义的分隔符 格式：awk -F: &apos;{print $1&quot;=======&quot;$3}&apos; /etc/passwd Awk中的变量：变量分为：内置变量和自定义变量awk中的内置变量除了$0,$1,$2等，还有以下几种； 如果要使用这些变量需要加-v 选项先进行定义 FS：输入字段分隔符，默认为空白字符 =filed separator=域或列的分隔符 等于-F的选项，-F是选项，而FS是变量，实际作用是相等的 与-F的区别在于：可以下次调用FS变量 awk -v FS=&apos;:&apos; &apos;{print $1,$3}&apos; /etc/passwd = awk -F:&apos;{print $1,$3}&apos; /etc/passwd awk -v FS=&apos;:&apos; &apos;{print $1,FS$3}&apos; /etc/passwd 两列输出时以：做分隔符，调用变量FS awk -v FS=&apos;:&apos; &apos;{print $1,FS FS$3}&apos; /etc/passwd 两列输出时以：：做分隔符，调用2次变量FS 以空格隔开 可以先定义shell中的变量fs=:,awk再进行调用 fs=:;awk -v FS=$fs &apos;{print $1,FS,$3}&apos; /etc/passwd fs=:;awk –F$fs &apos;{print $1,$3,$7}&apos; /etc/passwd OFS：输出字段分隔符，默认为空白字符 =output filed separator 定义输出分隔符，不指定默认空空格做分隔符 awk -v FS=: -v OFS=+++ &apos;{print $1,$3,$7}&apos; /etc/passwd fs=+++;awk -v FS=: -v OFS=$fs &apos;{print $1,$3}&apos; /etc/passwd 调用shell变量做输出分隔符 RS：输入记录分隔符，指定输入时的换行符,自定义行的分隔符 =record记录 默认一行叫记录，行是以\n回车作为切割符的，RS可以自定义不用回车作为分隔符 awk -v RS=&apos; &apos; ‘{print }’ /etc/passwd awk -v RS=&apos;:&apos; &apos;{print NR,$0}&apos;/etc/passwd [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print $0}&apos; aa;xxx bb;bzzzz cc dd eex;zccc xxxx 以RS=：冒号自定义行的分隔符，输出结果如上 [root@centos7 ~]#cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; &apos;{print $1}&apos; aa bb cc dd eex xxxx 自定义FS&amp;RS，输出结果如上 ORS：输出记录分隔符，输出时用指定符号代替换行符 awk -v RS=&apos; &apos; -v ORS=&apos;###&apos;‘{print }’ /etc/passwd [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; -v ORS&quot;===&quot; &apos;{print $1}&apos; aa==bb==cc dd==eex==xxxx == 自定义FS,RS,ORS结果很明显 接下来是一个比较重要的变量 NF：字段数量,也就是域或列的总数量 awk -F: &apos;{print NF}&apos; /etc/passwd 以冒号做分隔符，显示每行的列的总数量 awk -F: &apos;{print $NF}&apos; /etc/passwd 显示以冒号做分隔符，每一行的最后一个字段即bash类型 awk -F：&apos;{print $(NF-1)}&apos; /etc/passwd 显示以冒号做分隔符，每一行的倒数第二个字段 统计光盘中所有安装包适用的cpu架构类型 root@centos7 mnt]#ls /mnt/Packages/*.rpm | awk -F&quot;.&quot; &apos;{print $(NF-1)}&apos;|sort|uniq -c 1371 noarch 2600 x86_64 NR：记录号，可以显示行数，如果有多个文件会合并后再统计总行 awk &apos;{print NR,$0}&apos; /etc/fstab 在每一行前加一个行号 awk BEGIN&apos;{print NR}&apos; /etc/fstab 输出结果为0 awk还没开始处理行，所以记录为0 awk END&apos;{print NR}&apos; /etc/fstab 输出结果为12 可以看出END是统计,awk处理的行数 1.通过加行号，可以很明显看出以冒号作为行的分隔符，每一行的都有什么；可以看出cc dd是一行的 [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print NR$0}&apos; 1aa;xxx 2bb;bzzzz 3cc dd 4eex;zccc 5xxxx 2.备注：如果awk跟两个文件，awk会把两文件合并成一个文件，统计总行数，都取第一个字段的信息 如果需要分开显示统计，则用FNR [root@centos7 ~]awk -F: &apos;{print NR,$1}&apos; /etc/passwd /etc/group 1 root 2 bin 3 daemon 4 adm FNR：各文件分别计数,记录号 1.FNR:多个文件，每个分别统计显示第一个字段并列出来 awk &apos;{print FNR}&apos; /etc/fstab /etc/inittab [root@centos7 ~]awk -F: &apos;{print FNR,$1}&apos; /etc/passwd /etc/group 1 root 2 bin 3 daemon 48 quagga 49 httpd 1 root 2 bin FILENAME：当前文件名 1.统计时，加上变量可以显示文件名 awk &apos;{print FILENAME}&apos; /etc/fstab [root@centos7 ~]awk -F: &apos;{print FILENAME,FNR,$1}&apos; /etc/passwd /etc/passwd 1 root /etc/passwd 2 bin /etc/passwd 3 daemon ARGC：命令行参数的个数 awk &apos;{print ARGC}&apos; /etc/fstab /etc/inittab 结果为3 awk &apos;BEGIN {print ARGC}&apos; /etc/fstab /etc/inittab 结果为3 ARGC统计参数：awk单独算一个参数，后面的每个文件算一个参数,通过下面的数组可以体现出来 ARGV：数组，保存的是命令行所给定的各参数 1.显示awk的每个参数分别是哪个 [root@centos7 ~]awk &apos;{print ARGV[0]}&apos; /etc/fstab /etc/inittab awk [root@centos7 ~]awk &apos;{print ARGV[1]}&apos; /etc/fstab /etc/inittab /etc/fstab 示例：1.统计当前网络连接情况的ip地址是 ss -nt ss -nt | awk &apos;{print $5}&apos; 2.取/var/log/httpd/access_log的时间如下： root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; 分两步取： cat /var/log/httpd/access_log | awk &apos;{print $4}&apos;|awk -F&quot;[&quot; &apos;{print $2}&apos; 一步取： cat /var/log/httpd/access_log | awk -F &quot;[\[ ]&quot; &apos;{print $5}&apos; 原理分析：[\[ ]代表（转义）\[和空格都算是分隔符，正则表达式的写法,或的关系， 而以空格分隔符，时间段为$4,那为什么是$5?在空格的标准里，[算$4,所以时间段为$5 3.取出磁盘分区利用率 -这次只取出利用率 两步取出： df | awk -F% &apos;{print $1}&apos;|awk &apos;{print $5}&apos; 一步取出： df | awk -F&quot;[[:space:]]+|%&quot; &apos;{print $5}&apos; awk用的是扩展的正则表达式 面试题：3-1,取出fstab中挂载的目录 [root@centos7 ~]cat /etc/fstab # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data xfs defaults 0 0 UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap swap defaults 0 0 [root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos; boot data swap 或者 [root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos; boot data swap 4.面试题：将文件f3中的第一个点前的字符串取出再写进去 [root@centos7 ~]cat f3 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4.news.sina.com.cn [root@centos7 ~]cat f3 | awk -F&quot;[ .]&quot; &apos;{print $2}&apos; &gt;&gt; f3 [root@centos7 ~]cat f3 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4.news.sina.com.cn test music sports news 4-1,扩展 前面-F&quot;[ .]&quot;既然是表达或的意思，那么是否可以这么写-F&quot;[ ]|.&quot;？？？ 答案：不可以！ 原因：因为此处用的是正则表达式，在正则表达式中点(.)代表任意单个字符，会把空格后的字母当成分隔符！ 所以是不可以的，那么如何写？ 如果不是点而是%呢？%是可以的，因为在正则表达式中%就是代表%， 但是$,或其他在正则表达式中有特殊含义的不可以作为分隔符，如果一定要做分隔符，需要反斜线转义 如下： 此处用3个反斜线转义 [root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\.&quot; &apos;{print $2}&apos; test music sports news 那如果文本中的第一个点是$呢？ 此处是4个反斜线进行转义 [root@centos7 ~]cat f2 1 test$sina.com.cn 2 music$sina.com.cn 3 sports$sina.com.cn 4 news$sina.com.cn [root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\\$&quot; &apos;{print $2}&apos; test music sports news [root@centos7 ~]cat f2 | awk -F&quot;[ $]&quot; &apos;{print $2}&apos; test music sports news 当用一个空格和具有特殊含义的符号时，最好是写在中括号[]里的 AWK中自定义变量自定义变量(区分字符大小写) (1) -v var=value (2) 在program中直接定义 (2-1)program可以放到一个文本里,awk -f 直接调用即可 示例：自定义变量可以-v var定义，也可以放到program即{}里，变量要先定义，后使用 awk -F: &apos;{name=&quot;magedu&quot;;print $1,name}&apos; /etc/passwd awk -F: -v name=&quot;magedu&quot; &apos;{print $1,name}&apos; /etc/passwd 例如 cat awk.txt {print $1,$2,$6} awk -F： -f awk.txt /etc/passwd =awk -F: &apos;{print $1,$2,$6}&apos; /etc/passwd Awk中的格式化在介绍printf前，先对其进行总结：1.使用printf动作输出的文本不会换行，如果需要换行，可以在对应的格式替换符后加入”\n”进行转义2.使用printf动作时，指定的格式和被格式化的文本之间，需要用”逗号”隔开。3.使用printf动作时，格式中的格式替换符比喻与被格式化的文本一一对应 printf命令-类似于shell里的printfprintf命令可以把内容以灵活的格式进行显示，如左对齐,右对齐 格式化输出：printf &quot;FORMAT&quot;, item1, item2, ... (1) 必须指定FORMAT (2) 不会自动换行，需要显式给出换行控制符，\n (3) FORMAT中需要分别为后面每个item指定格式符 格式符：与item一一对应 %c：显示字符的ASCII码 %d, %i：显示十进制整数 -用的比较多 %e, %E：显示科学计数法数值 %f：显示为浮点数 %g, %G：以科学计数法或浮点形式显示数值 %s：显示字符串 -用的比较多 %u：无符号整数 -用的比较多 %%：显示%自身 修饰符 #[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f + 左对齐（默认右对齐） %-15s * 显示数值的正负符号 %+d printf示例：1.设置对齐格式以及字符数 [root@centos7 ~]awk -F: &apos;{printf &quot;%-20s %-5d\n&quot;,$1,$3}&apos; /etc/passwd root 0 bin 1 pulse 171 gdm 42 gnome-initial-setup 990 $1为字符串，所以设置左对齐为20s个字符，$3为数字所以设置左对齐为5d个字符 printf默认不换行，所以需要加一个换行符 2.打印一个完整的报表格式 root@centos7 ~]awk -F: &apos;BEGIN{print &quot;username |uid\n--------&quot;} {printf &quot;%-10s |%-5d\n&quot;,$1,$3}END{print &quot;-------------&quot;}&apos; /etc/passwd username |uid ----------------------- root |0 bin |1 daemon |2 memcached |987 ceshi |1009 quagga |92 httpd |80 ------------------------- awk生成报表格式大概就是这个样子，所以awk称为报表生成器 3. [root@centos7 ~]awk -F: &apos;{printf &quot;Username: %s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwd Username: root,UID:0 Username: bin,UID:1 Username: daemon,UID:2 Username: adm,UID:3 4. [root@centos7 ~]awk -F: &apos;{printf &quot;Username: %-15s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwd Username: root ,UID:0 Username: bin ,UID:1 Username: daemon ,UID:2 awk操作符a.算术操作符： x+y, x-y, x*y, x/y, x^y, x%y - x：转换为负数 +x：将字符串转换为数值 字符串操作符：没有符号的操作符，字符串连接 赋值操作符： =, +=, -=, *=, /=, %=, ^=，++, --, b.比较操作符： ==, !=, &gt;, &gt;=, &lt;, &lt;= 模式匹配符： ~：左边是否和右边匹配包含 !~：是否不匹配 c.逻辑操作符：与&amp;&amp;，或||，非! d.条件表达式（三目表达式） selector?if-true-expression:if-false-expression 表达式；if-ture-xx:else-xxx eg:x&gt;y?var=x;var=y 操作符用法示例：1.下面两语句有何不同 • awk &apos;BEGIN{i=0;print ++i,i}&apos; 结果 1 1 • awk &apos;BEGIN{i=0;print i++,i}&apos; 结果 0 1 实际上AWK的语法是采用VC语言风格的 2.示例： awk中~&amp;!~是否包含的用法： [root@centos7 ~]awk -F: &apos;$0 ~ /root/{print $1}&apos; /etc/passwd root operator 意思是如果过滤的行中有包含root字符串的，则打印出这行的用户名 用到下文提到的patter模式，在这里是匹配是否包含root字符串 [root@centos7 ~]awk -F: &apos;$0 ~ &quot;/root&quot;{print $1}&apos; /etc/passwd root operator 区别上面的这个写法，在这里是包含/root字符串的行 [root@centos7 ~]awk -F: &apos;$0 !~ /root/{print $1}&apos; /etc/passwd bin daemon adm 和上面的命令刚好相反，如果行不包含字符串root，则打印该行用户名 [root@centos7 ~]awk -F: &apos;$3==0&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 意思：判断UID是否等于0，是则打印该行，判断是否为管理员 [root@centos7 ~]awk &apos;$0~&quot;^root&quot;&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 意思：判断该行是不是以root开头的行，是则打印 3.awk中的与&amp;&amp;，或|| 非!的使用示例： 示例： • awk –F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000 {print $1}&apos; /etc/passwd 如果0&lt;=UID&lt;=1000，则打印出该用户 • awk -F: &apos;$3==0 || $3&gt;=1000 {print $1,$3}&apos; /etc/passwd 打印出UID等于0和UID&gt;=1000的用户名和他的UID • awk -F: &apos;!($3==0) {print $1}&apos; /etc/passwd -要加括号 打印出UID不等于0的用户名 • awk -F: &apos;!($3&gt;=500) {print $3}&apos; /etc/passwd 如果UID&lt;=500,时，打印出该用户的UID 4.AWK中的条件判断表达式 即三目表达式 相当于把shell中的if;then,else,fi的放到awk中 • 示例： [root@centos7 ~]awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd sys root 0 sys bin 1 sys tcpdump 72 common test 1000 common nginx 1008 判断用户是否为系统用户，是则打印并在开头加common,不是也打印在开头加sys awk中的PATTERN和action模式匹配和处理动作=sed的地址定界+修饰符功能：和sed中的pattern一样起到过滤的功能，=sed的地址定界 PATTERN:根据pattern条件，过滤匹配的行，再做处理(1)如果未指定：空模式，匹配每一行 (2) /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来 awk &apos;/^UUID/{print $1}&apos; /etc/fstab awk &apos;!/^UUID/{print $1}&apos; /etc/fstab awk的匹配模式支持的是扩展的正则表达式 注意：不支持直接给出数字格式，但是可以变向的打印输出，详见下面的示例 (3) relational expression: 关系表达式，结果为“真”才会被处理 真：结果为非0值，非空字符串 假：结果为空字符串或0值都是假 字符串为空或者0为假 (4) line ranges：行范围 startline,endline：/pat1/,/pat2/ 不支持直接给出数字格式 awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/{print $1}&apos; /etc/passwd awk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20){print NR,$1}&apos; /etc/passwd NR表示行 (5) BEGIN/END模式 BEGIN{}: 仅在开始处理文件中的文本之前执行一次 END{}：仅在文本处理完成之后执行一次 模式：指定一个行的范围。该语法不能包括BEGIN和END模式。BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。END：让用户在最后一条输入记录被读取之后发生的动作。 patter用法示例：先写一个特殊的用法 1.当在awk命令中使用正则模式时，使用到的正则用法属于&quot;扩展的正则表达式&quot; 2.当使用{x,y}这种次数匹配正则表达式，需要配合--posix或者--re-interval选项 备注：这是网上找到一个示例，文中提到{x,y}必须加这个选项，然而不加选项也是可以过滤的 awk是是支持posix字符集的 [root@centos7 ~]cat f3 seex sex seeex seeeeex [root@centos7 ~]cat f3 | awk &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3 | awk -posix &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3 | awk --re-interval &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3|grep -E &quot;se{2,3}x&quot; seex seeex [root@centos7 ~]cat f3|sed -nr &apos;/se{2,3}x/p&apos; seex seeex 1.取系统磁盘分区空间利用率df,/dev/sd开头的分区(上文中虽然取出来了，但是没过滤) [root@centos7 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &apos;/^\/dev\/sd/{print $1,$5}&apos; /dev/sda2 8 /dev/sda3 1 /dev/sda1 17 2.取当前连接主机的IP地址(上文中虽然取出来了，但是没过滤) [root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $6}&apos; 192.168.34.1 192.168.34.105 或者用NF的表达方式 [root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos; 192.168.34.1 192.168.34.105 3.取登录当前系统失败（lastb）用户的IP [root@centos7 ~]#lastb root ssh:notty 192.168.34.105 Sun Nov 11 17:25 - 17:25 (00:00) root23 ssh:notty 192.168.34.1 Mon Nov 5 15:43 - 15:43 (00:00) btmp begins Fri Nov 2 09:58:52 2018 [root@centos7 ~]#lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c 3 192.168.34.1 1 192.168.34.101 因为最后一行有btmp这样的字样，只能通过包含的功能来过滤掉最后一行 如果要取失败连接次数大于3的扔到防火墙，可以先取出来 root@centos7 ~]lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c| awk &apos;$1 &gt;=3{print $2}&apos; 192.168.34.1 4.patter中为关系表达式的示例 空字符串或0值都是假，其他为真 awk &apos;0{print $0}&apos; /etc/passwd -0为假，结果为空 awk &apos;&quot;&quot;{print $0}&apos; /etc/passwd -空也为假，结果为空 awk &apos;1{print $0}&apos; /etc/passwd -1为真 awk &apos;&quot; &quot;{print $0}&apos; /etc/passwd -空白符也为真 awk -v abc=&quot; &quot; &apos;abc{print $0}&apos; /etc/passwd -abc为空白,不是空字符串,也为真 awk -v abc=&quot; &quot; &apos;! abc{print $0}&apos; /etc/passwd -abc为空白,为真,对真取反，结果为假 5.awk中patter的地址定界 root@centos7 ~]#awk -F: &apos;/^root/,/^adm/{print $0}&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin 打印以root开头的行到以adm开头的行之间的所有行 等于 sed -nr &apos;/^root/,/^adm/p&apos; /etc/passwd 6.如何打印从多少行到多少行之间的行？？ [root@centos7 ~]#awk -F: &apos;NR&gt;=10 &amp;&amp; NR&lt;=12 {print NR,$0}&apos; /etc/passwd 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 通过变量NR变向的打印出行 7.取出/etc/fstab配置文件中以UUID开头的行 [root@centos7 ~]#cat /etc/fstab | awk &apos;/^UUID/{print $0}&apos; UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 效果等于 grep &quot;^UUID&quot; /etc/fstab 效果等于 sed -n &apos;/^UUID/p&apos; /etc/fstab 8. awk &apos;!0&apos; /etc/passwd =awk &apos;!0{print $0}&apos; /etc/passwd 省略了{print $0}的写法 结果为真，即打印全部行 root@centos7 ~]#awk -F: &apos;i=1;j=1{print i,j}&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 1 1 bin:x:1:1:bin:/bin:/sbin/nologin 1 1 ？？？ [root@centos7 ~]#awk -F: &apos;$NF ~ /bash$/{print $1,$NF}&apos; /etc/passwd root /bin/bash test /bin/bash 判断用户shell是否为/bin/bash，是则打印用户名和shell类型，此处用变量NF来实现 效果等于 awk -F: &apos;$NF==&quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd 效果等于 awk -F: &apos;$7 == &quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd 效果等于 awk -F: &apos;$0 ~ /bash$/{print $1,$NF}&apos; /etc/passwd 9.打印奇数行和偶数行 [root@centos7 ~]#seq 6 | awk &apos;i=!i&apos; 打印奇数行 1 3 5 原理：i初始值为空，为假，取反时，则打印第一行，此时i=1 i=1时，为真，取反为假，所以第二行不打印，然后i=0 依次类推所以只打印奇数行 [root@centos7 ~]#seq 6 | awk &apos;!(i=!i)&apos; 打印偶数行 2 4 6 效果等于 seq 10 |awk -v i=1 &apos;i=!i&apos; 原理：同上，只要先定义i=1，为真，第一行就不打印了 或者用sed打印奇数行和偶数行(用sed步进的方式) seq 6 | sed -n &apos;1~2p&apos; 打印奇数行 seq 6 | sed -n &apos;2~2p&apos; 打印偶数行 awk actionaction除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能• (1) Expressions:算术，比较表达式等 • (2) Control statements：if, while等 • (3) Compound statements：组合语句 • (4) input statements • (5) output statements：print等 下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句awk中if-else控制语句的语法及用法语法： 双分支if if(condition){statement;…}(多条语句用;隔开)[else statement] 多分支if if(condition1){statement1}else if(condition2){statement2}else{statement3} 使用场景：对awk取得的整行或某个字段做条件判断 if-else示例：如判断考试分数，写法如下 [root@centos7 ~]awk -v score==80 &apos;BEGIN{if(score &lt;60){print &quot;no pass&quot;} else if(score &lt;=80){print &quot;soso&quot;}else {print good}}&apos; soso awk -F: &apos;{if($3&gt;=1000)print $1,$3}&apos; /etc/passwd 判断UID是否大于1000，是则打印用户名和UID awk -F: &apos;{if($NF==&quot;/bin/bash&quot;) print $1}&apos; /etc/passwd 判断用户shell是否为/bin/bash,是则打印用户名 awk &apos;{if(NF&gt;5) print $0}&apos; /etc/fstab 判断域或列个数是否大于5，是则打印该行 awk -F: &apos;{if($3&gt;=1000) {printf &quot;Common user: %s\n&quot;,$1} else {printf &quot;root or Sysuser: %s\n&quot;,$1}}&apos; /etc/passwd 等于上文中的 awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd 例如：随机生成1000个数字，用awk取出最大值和最小值(可以用shell写法) 1.生成1000个数字 for i in {1..1000};do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f1.txt;else echo -e &quot;,$RANDOM\c&quot; &gt;&gt; f1.txt ;fi;done 2.用awk取出最大值和最小值 awk -F&apos;,&apos; &apos;{i=2;max=$1,while(i&lt;=NF){if($i &gt; max){max=$i}else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; f1.txt 验证用awk是否取出的值为正确的： 方法一：用tr验证 tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | head -n1 tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | tail -n1 方法二：用shell脚本验证 #!/bin/bash for i in {1..1000};do awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理awk中while循环控制语句的语法及用法语法：while(condition){statement;…} 条件“真”，进入循环；条件“假”，退出循环 使用场景： 对一行内的多个字段逐一类似处理时使用 对数组中的各元素逐一处理时使用 此时涉及到系统自带的一个函数length(函数在下面会有介绍) 示例： 1.统计每一行第一个字段的长度 root@centos7 ~]awk -F: &apos;{print length($1),$1}&apos; /etc/passwd 4 root 3 bin 6 daemon 3 adm 2.统计/etc/passwd第一行的每个字段的长度 [root@centos7 ~]awk -F: &apos;NR==1{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/passwd root 4 x 1 0 1 0 1 root 4 /root 5 /bin/bash 9 3.统计grub2.cfg文件中linux16那行的每个字段的长度 [root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/grub2.cfg linux16 7 /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 ro 2 crashkernel=auto 16 rhgb 4 quiet 5 LANG=en_US.UTF-8 16 linux16 7 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 ro 2 crashkernel=auto 16 rhgb 4 quiet 5 4.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用while循环 root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){if(length($i)&gt;=10) {print $i,length($i)};i++}}&apos; /etc/grub2.cfg /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 LANG=en_US.UTF-8 16 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 5.面试题 用awk取出文本f5的最大值和最小值，需要先生成1000个随机数存到f5中 如何做？ 1.不用awk，可以通过脚本实现最大值和最小值 2.用awk如何来做？？ 先生成1000个随机数 [root@centos7 ~]for i in `seq 1000`;do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f5; else echo -e &quot;,$aRANDOM\c&quot; &gt;&gt; f5 ;fi;done 生成了1000随机数，如何取最大值最小值？ [root@centos7 ~]awk -F&quot;,&quot; &apos;{i=2;max=$1;min=$1;while(i&lt;=NF){if($i &gt; max){max=$i} else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; &lt; f5 max=32643 min=60 awk中do-while循环控制语句语法：do {statement;…}while(condition) 意义：无论真假，至少执行一次循环体 do-while使用示例：求1-100正整数的和 [root@centos7 ~]awk &apos;BEGIN{ total=0;i=0;do{ total+=i;i++;}while(i&lt;=100);print total}&apos; 5050 awk中for循环控制语句语法：for(expr1;expr2;expr3) {statement;…} 常见用法： for(variable assignment;condition;iteration process) {for-body} 特殊用法：能够遍历数组中的元素 语法：for(var in array) {for-body} for循环使用示例：1.求1-100正整数的和： [root@centos7 ~]awk &apos;BEGIN{for(i=1;i&lt;=100;i++)sum+=i;print sum}&apos; 5050 2.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用for循环 [root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{for(i=1;i&lt;=NF;i++){if(length($i)&gt;=10){print $i,length($i)}}}&apos; /etc/grub2.cfg /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 LANG=en_US.UTF-8 16 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 awk中的switch控制语句类似于shell中的case语句 语法：switch(expression) {case VALUE1 or /REGEXP/: statement1; caseVALUE2 or /REGEXP2/: statement2; ...; default: statementn} awk中的continue,break，next控制语句break和continuenext:提前结束对本行处理而直接进入下一行处理（awk自身循环） continue的示例求1000以内偶数的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==0)continue;sum+=i}print sum}&apos; 2500 求1000以内奇数的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==1)continue;sum+=i}print sum}&apos; 2550 求1000以内除了66的所有数字的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i==66)continue;sum+=i}print sum}&apos; 4984 break的示例：求1000数字中，当大于100时，跳出循环，即求100以内的和 [root@centos7 ~]#awk &apos;BEGIN{sum=0;for(i=1;i&lt;=1000;i++){if(i&gt;100)break;sum+=i}print sum}&apos; 5050 next的示例：因为提前结束对本行处理而直接进入下一行处理（因为awk本身就是循环行的功能），所以示例 打印/etc/passwd下的奇数行 [root@centos7 ~]awk -F: &apos;{if(NR%2==0)next;print NR,$0}&apos; /etc/passwd 1 root:x:0:0:root:/root:/bin/bash 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 还可以这样写：awk -F: &apos;NR%2==1{print NR,$0}&apos; /etc/passwd awk数组-一个非常使用的功能awk的数组全都是关联数组关联数组：array[index-expression] index-expression: • (1) 可使用任意字符串；字符串要使用双引号括起来 • (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值 初始化为“空串” • (3) 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历 数组的去重的效果示例：awk &apos;!arr[$0]++&apos; dupfile awk &apos;{!arr[$0]++;print $0, arr[$0]}&apos; dupfile echo abc abc ccc bcd ddd ddd abc abc &gt;&gt; f1.txt awk关联数组的遍历：若要遍历数组中的每个元素，要使用for循环:因为关联数组下标是无序性 for(var in array) {for-body} 注意：var会遍历array的每个索引 数组的使用示例：示例1.定义awk数组 [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;; title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]}&apos; zhang 可以用for循环把每一个数组的值都表示出来 [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]; for(i in title){print i,title[i]}}&apos; zhang coo liu ceo zhang cto wang 但输出时数组元素时，是无序的，这就是关联数组的特性 示例2.awk数组中的重要功能 [root@centos7 ~]cat f6 abc abc ddd ccc aaa ccc ccc [root@centos7 ~]awk &apos;!line[$0]++&apos; f6 abc ddd ccc aaa 问题：为什么执行结果是这个？？ 原因： awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6 实际上是隐藏了{print $0}，这个隐藏功能在awk很重要！！！， 但是要和后面patter中的空模式区别开 &apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印 而后面的数组里的是加了双括号{}，{line[$0]++}即用的patter的空模式，即文本中的每一行都处理 这两个写法是不一样的，别混淆了 分析： 基于这个考虑进行分析 &apos;!line[$0]++&apos; = &apos;!line[$0]++{print $0}&apos; 当读取文本f6的第一行时=abc !line[&quot;abc&quot;]++，因为abc没有值，line[&quot;abc&quot;]=0为假，取反！line[&quot;abc&quot;]后为真 所以把第一行的abc打印了一次，打印第一行结束后line[&quot;abc&quot;]=1 当读取文本f6的第二行时=abc !line[&quot;abc&quot;]++，在之前基础上line[&quot;abc&quot;]=1为假，取反！line[&quot;abc&quot;]=0后为假 所以把第二行的abc不打印，结束后line[&quot;abc&quot;]=2 以此类推，发现后续出现abc都不会打印，但是line[&quot;abc&quot;]都会在之前的基础上+1，即达到去重并统计的目的 而处理第三行!line[&quot;ddd&quot;]++时，和上述abc一样，第一次出现则打印，后续也不会打印 所以，命令执行结果为去重的效果 从这个命令执行结果也可以明显看到上述的分析结果 可以看出abc的值是递增的，也就是abc出现的次数 [root@centos7 ~]awk &apos;{!line[$0]++;print $0, line[$0]}&apos; f6 abc 1 abc 2 ddd 1 ccc 1 aaa 1 ccc 2 awk数组中的重要功能之for循环遍历数组，很具有实用性在后面的统计服务的一些日志文件很有作用如果要理解遍历awk数组，需要深刻理解上述的示例2:awk &apos;!line[$0]++&apos; f6是怎么实现的 但还是有些和数组里的，遍历$2,把$2不同的值，当成数组的下标有些区别的 若要遍历数组中的每个元素，要使用for循环for(var in array) {for-body} 注意：var会遍历array的每个索引 为什么要通过特殊写法去遍历awk中的数组？如果是普通数组，用循环0,1,2,3做个循环即可；而awk的数组都是关联数组，[]中括号里的下标都不固定 所以要通过 for(var in array(数组名称)) {for-body}这样的特殊写法，var的值会从array数组元素 取其下标，相当于每次循环var的值是等于array数组的下标的 注意：当我们直接引用一个数组中不存在的元素时，awk会自动创建这个元素，并且为其赋值为&quot;空字符串&quot; for循环遍历数组使用示例：示例1： [root@centos7 ~]awk &apos;BEGIN{print test[&quot;ip&quot;];test[&quot;ip&quot;]++;print test[&quot;ip&quot;]}&apos; 1 第一次输出为空，第二次自动加1 示例2： 1. [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;for(i in title){print title[i]}}&apos; liu zhang wang 分析： for(i in title){print title[i]，i的值来自于title的下标，即i=ceo coo cto,而且是无序打印 示例3： [root@centos7 ~]netstat -tan Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN tcp 0 0 192.168.122.1:53 0.0.0.0:* ESTABLISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN tcp 0 52 192.168.34.103:22 192.168.34.1:8816 ESTABLISHED tcp 0 0 192.168.34.103:22 192.168.34.105:49746 ESTABLISHED tcp6 0 0 :::111 :::* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 ::1:631 :::* LISTEN tcp6 0 0 ::1:25 :::* LISTEN [root@centos7 ~]netstat -tan | awk &apos;/^tcp/{state[$NF]++}END{for(i in state) { print i,state[i]}}&apos; LISTEN 8 ESTABLISHED 3 分析： state[$NF]++以空白做分隔符，统计同一类型的状态有多少个 for(i in state) { print i,state[i]} 即统计了出现状态的多少种以及出现的次数 不明白的可以看上文中的示例2：awk数组中的重要功能 当然，看懂这个命令，需要知道两个知识点 1.空模式，即全文反复提到的{state[$NF]++}={state[$NF]++}{print $0} 2.END模式，END的模式是在前面动作结束之后，最后执行依次END模式中的命令，所以先不用考虑空模式 下面再一次对空模式中的处理过程，做详细的描述 空模式中，我们创建了一个state数组，并将状态值(LISTEN、ESTABLISHED)作为引用下标， 所以执行到第一行时，我们引用的是state[&quot;LISTEN&quot;],很明显，这个元素并不存在，所以，当第一行被空模式的动作处理完毕后 state[&quot;LISTEN&quot;]的值已经被赋值为1了。 这时，空模式中的动作继续处理下一行，而下一行的$NF=ESTABLISTEN；state[&quot;ESTABLISTEN&quot;] 所以，state[&quot;ESTABLISTEN&quot;]第一次参与运算过程与上一个原理相同 直到再次遇到相同的状态时，使用同样一个IP地址作为下标的元素将会再次被自加 直到处理完所有的行，开始执行END模式中的动作。 而END模式中，我们打印出state数组中的所有元素的下标，以及元素对应的值。 此刻，state数组中的下标即为各种状态，元素的值即为对应状态出现的次数， 最终，我们统计出每个状态出现的次数。 3.统计/var/log/httpd/access_log，每个IP链接的次数 root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; &quot;Mozil&quot; 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; 192.168.34.103 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; [root@centos7 ~]awk &apos;{ip[$1]++}END{for(i in ip){print i,ip[i]}}&apos; /var/log/httpd/access_log 192.168.34.101 9 192.168.34.103 13 ::1 4 192.168.34.1 88 效果等于： [root@centos7 ~]awk &apos;{print $1}&apos; /var/log/httpd/access_log |sort|uniq -c 4 ::1 88 192.168.34.1 9 192.168.34.101 13 192.168.34.103 4.统计ss -nt ip链接次数 [root@centos7 ~]ss -nt State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 52 192.168.34.103:22 192.168.34.1:8816 ESTAB 0 0 192.168.34.103:22 192.168.34.105:49746 [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{ip[$(NF-2)]++}END{for(i in ip){print i,ip[i]}}&apos; 192.168.34.105 1 192.168.34.1 1 效果等于： [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;|sort|uniq -c 1 192.168.34.1 1 192.168.34.105 5.统计/etc/fstab文件系统类型分别有多少个 [root@centos7 ~]cat /etc/fstab # /etc/fstab # Created by anaconda on Wed Sep 19 11:44:48 2018 UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data xfs defaults 0 0 UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap swap defaults 0 0 [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos; swap 1 xfs 3 6.求下表中的男生和女生的平均成绩 [root@centos7 ~]cat f9 name sex score a m 90 b f 80 c f 99 d m 88 e m 80 如何利用awk的数组功能来求？ 思路先求男的和和女的和？ 利用两个数组？ [root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3}END{for(i in sum){print i,sum[i]}}&apos; -求男女分的和 m 258 f 179 [root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3;num[$2]++}END{for(i in sum){print i,sum[i]/num[i]}}&apos; m 86 f 89.5 7.统计下面每个名字出现的次数 [root@centos7 ~]cat f1 Allen Phillips Green Lee William Aiden Janmes Lee Angel Jack Jack Thomas Lucas Kevin Tyler Lee William Allen [root@centos7 ~]cat f1 | awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,cuont[j]}}&apos; Tyler Angel Lucas William Thomas Green Jack Phillips Kevin awk函数awk也包括内置函数和自定义函数内置函数包括 rand,length，sub,gsub,split，system数值处理： rand(i)：返回0和1之间一个随机数 awk &apos;BEGIN{srand(); for (i=1;i&lt;=10;i++)print int(rand()*100) }&apos; 字符串处理： • length([s])：返回指定字符串的长度 • sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,“-&quot;,$1)&apos; • gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表 示的内容 echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; • split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所 表示的数组中，第一个索引值为1,第二个索引值为2,… netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}&apos; END{for (i in count) {print i,count[i]} awk内置函数之sub、gsub、split实现搜索替换切割的用法示例1： sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s gsub(r,s,[t])表示全局替换 sub(r,s,[t])不是贪婪模式，默认值替换搜索出来的第一个 [root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,&quot;-&quot;,$1)&apos; 2008-08:08 08:08:08 只替换$1 root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$1)&apos; 2008-08-08 08:08:08 全局替换$0 [root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; 2008-08-08 08-08-08 示例2： 统计字符串中每个字母出现的次数abcdaabbccdd [root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 3 b 3 c 3 d 3 在文章最后会用另外一种写法进行过滤(文章最后会以以空位分隔符的特殊写法来表示) awk内置函数split的切割功能示例1: 统计链接本机的IP和端口号 [root@centos7 ~]#netstat -tn Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 52 192.168.34.103:22 192.168.34.1:8816 ESTABLISHED tcp 0 0 192.168.34.103:22 192.168.34.105:49746 ESTABLISHED [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}END{for (i in count) {print i,count[i]}}&apos; 192.168.34.105 1 192.168.34.1 1 [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[2]]++}END{for (i in count) {print i,count[i]}}&apos; 8816 1 49746 1 分析： split($5,ip,&quot;:&quot;)将192.168.34.1:8816进行切割，数组ip的下标1放IP地址，下标2放端口号 count[ip[1]]++ 把ip下标为1也就是IP地址，把出现的IP个数，又给count当下标，就统计每个IP出现的次数 count[ip[2]]++ 把ip下标为2也就是端口号，把出现的端口号个数，又给count当下标，就统计每个端口号出现的次数 awk中的自定义函数格式：awk自定义函数是用正规开发语言的函数格式 function name ( parameter, parameter, ... ) { statements return expression } awk自定义函数的用法：cat fun.awk,把函数写到文件中 function max(x,y) { x&gt;y?var=x:var=y return var } BEGIN{print max(i,j)} awk -v i=10 -v j=20 -f fun.awk 调用函数即可，和shell中的函数类似 awk中很实用的内置函数system命令system函数作用：在awk可以反过来调用linux里的命令示例： 空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用 空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来 示例1: 显示/boot/grub2下的文件列表；调用命令时要加双引号 [root@centos7 ~]#awk &apos;BEGIN{system(&quot;ls /boot/grub2&quot;)}&apos; device.map fonts grub.cfg grubenv i386-pc locale 或者这么写，先定义变量等于路径，再调用变量 [root@centos7 ~]#awk &apos;BEGIN{dir=&quot;/boot/grub2&quot;;system(&quot;ls &quot;dir)}&apos; device.map fonts grub.cfg grubenv i386-pc locale 调用hostname命令，显示主机名 [root@centos7 ~]#awk &apos;BEGIN{system(&quot;hostname&quot;)}&apos; centos7.localdomain 示例2： 之前处理过lastb中登录失败的IP，如果失败登录次数大于3次，扔到防火墙里， 当时是先取出IP放到文件里，然后iptables再禁用； 现在可以在awk中先取出IP,然后通过system(&quot;iptables &quot; IP)就可以直接扔到防火墙中 具体实现？ awk脚本将awk程序写成脚本，直接调用或执行 awk脚本使用示例： 1.先写文本再调用 cat f1.awk {if($3&gt;=1000)print $1,$3} awk -F: -f f1.awk /etc/passwd 2.也可以写成脚本形式 先写再调用 [root@centos7 ~]vim f2.awk #!/bin/awk -f {if($3 &gt;=1000)print $1,$3} [root@centos7 ~]./f2.awk -F: /etc/passwd nfsnobody 65534 test 1000 gentoo 1007 nginx 1008 ceshi 1009 向awk脚本传递参数格式： awkfile var=value var2=value2... Inputfile 注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通 过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变 量都需要一个-v参数 awk脚本传参使用示例：cat test.awk #!/bin/awk –f {if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3} chmod +x test.awk test.awk -F: min=100 max=200 /etc/passwd 工作中遇到的常用awk文本解决案例：Linux Web服务器网站故障分析常用的命令系统连接状态篇： 1.查看TCP连接状态 netstat -nat |awk &apos;{print $6}&apos;|sort|uniq -c|sort -rn 每出现一被/^tcp/模式匹配到的行，数组S[$NF]就加1，NF为当前匹配到的行的最后一个字段，此处用其值做为数组S的元素索引； netstat -n | awk &apos;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}&apos; 或 netstat -n | awk &apos;/^tcp/ {++state[$NF]}; END {for(key in state) print key,&quot;\t&quot;,state[key]}&apos; netstat -n | awk &apos;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,&quot;t&quot;,arr[k]}&apos; netstat -n |awk &apos;/^tcp/ {print $NF}&apos;|sort|uniq -c|sort -rn netstat -ant | awk &apos;{print $NF}&apos; | grep -v &apos;[a-z]&apos; | sort | uniq -c 2.查找请求数请20个IP（常用于查找攻来源）： 方法一： netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20 方法二： netstat -ant |awk &apos;/:80/{split($5,ip,&quot;:&quot;);++A[ip[1]]}END{for(i in A) print A[i],i}&apos; |sort -rn|head -n20 3.用tcpdump嗅探80端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; ‘{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}’ | sort | uniq -c | sort -nr |head -20 4.查找较多time_wait连接 netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n20 5.找查较多的SYN连接 netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more 6.根据端口列进程 netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1 网站日志分析篇1（Apache）：1.获得访问前10位的ip地址 cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10 cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’ 2.访问次数最多的文件或页面,取前20 cat access.log|awk ‘{print $11}’|sort|uniq -c|sort -nr|head -20 3.列出传输最大的几个exe文件（分析下载站的时候常用） cat access.log |awk ‘($7~/.exe/){print $10 &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -20 4.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数 cat access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -100 5.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面 cat access.log |awk ‘($7~/.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -100 6.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数 cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 7.列出传输时间超过 30 秒的文件 cat access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -20 8.统计网站流量（G) cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’ 9.统计404的连接 awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort 10. 统计http status cat access.log |awk &apos;{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}&apos; cat access.log |awk &apos;{print $9}&apos;|sort|uniq -c|sort -rn 10.蜘蛛分析，查看是哪些蜘蛛在抓取内容。 /usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E &apos;bot|crawler|slurp|spider&apos; 网站日分析2(Squid篇）按域统计流量cat squid_access.log.tar.gz| awk &apos;{print $10,$7}&apos; |awk &apos;BEGIN{FS=&quot;[ /]&quot;}{trfc[$4]+=$1}END{for(domain in trfc){printf &quot;%st%dn&quot;,domain,trfc[domain]}}&apos; 安全篇：(ssh lastb)ssh日志中失败登录的IP，取出来 /var/log/secure awk &apos;/Failed PASSWORD/{IP[$(NF-3)]++}END{for(i in IP){print i,IP[i]}&apos; /var/log/secure 1、文件ip_list.txt如下格式，请提取”.magedu.com”前面的主机名部分并写 入到回到该文件中 1 blog.magedu.com 2 www.magedu.com … 999 study.magedu.com 2、统计/etc/fstab文件中每个文件系统类型出现的次数 [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{print $3}&apos;|sort|uniq -c |sort -nr 3 xfs 1 swap [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos; swap 1 xfs 3 3、统计/etc/fstab文件中每个单词出现的次数 root@centos7 ~]cat /etc/fstab |awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,count[j]}}&apos; man 1 4、提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字 [root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|awk &apos;gsub(/[^0-9]/,&quot;&quot;,$0)&apos; 05973 [root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|tr -dc &quot;[0-9]&quot; 05973 5、有一文件记录了1-100000之间随机的整数共5000个，存储的格式 100,50,35,89…请取出其中最大和最小的整数 6、解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP 并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频 率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT [root@centos7 ~]awk &apos;{access[$1]++}END{for(i in access){if(access[i]&gt;=1){print i,access[i]}}}&apos; /var/log/httpd/access_log 192.168.34.101 9 192.168.34.103 13 只过滤出IP，监控任务可以写到计划任务里， 或者用内置函数system[&quot;iptables&quot;]调用？ 7、将以下文件内容中FQDN取出并根据其进行计数从高到低排序 http://mail.magedu.com/index.html http://www.magedu.com/test.html http://study.magedu.com/index.html http://blog.magedu.com/index.html http://www.magedu.com/images/logo.jpg http://blog.magedu.com/20080102.html [root@centos7 ~]#cat f5|sed -nr &apos;s@.*//([^/]+)/.*@\1@p&apos;|sort|uniq -c|sort -nr 2 www.magedu.com 2 blog.magedu.com 1 study.magedu.com 1 mail.magedu.com [root@centos7 ~]#cat f5|awk -F&quot;/&quot; &apos;{print $3}&apos;|sort|uniq -c|sort -nr 2 www.magedu.com 2 blog.magedu.com 1 study.magedu.com 1 mail.magedu.com 8、将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出 同一inode中，beginnumber的最小值和endnumber的最大值 inode|beginnumber|endnumber|counts| 106|3363120000|3363129999|10000| 106|3368560000|3368579999|20000| 310|3337000000|3337000100|101| 310|3342950000|3342959999|10000| 310|3362120960|3362120961|2| 311|3313460102|3313469999|9898| 311|3313470000|3313499999|30000| 311|3362120962|3362120963|2| 输出的结果格式为： 310|3337000000|3362120961|10103| 311|3313460102|3362120963|39900| 106|3363120000|3368579999|30000| awk -F&apos;|&apos; &apos;NR==1{print;next}{a[$1]?(a[$1]&gt;$2?a[$1]=$2:0):(a[$1]=$2);b[$1]?(b[$1]&lt;$3?b[$1]=$3:0):(b[$1]=$3);c[$1]+=$4} END{l=asorti(a,d);for(i=1;i&lt;=l;i++)print d[i] FS a[d[i]] FS b[d[i]] FS c[d[i]] FS}&apos; file [解析] 第一行直接打印。从第2行开始以$1为下标，建立3个数组，比较出$2的最小值，$3的最大值，然后把$4进行累加，最后进行排序后依次取出各项值。 这其中运用了三目运算的嵌套，跟我们 if(){if(){}}else{} 的使用是一个道理，不要认为复杂，如果觉得模糊不清，仔细读懂流程控制。 9.统计字符串中每个字母出现的次数abcdaabbccdd [root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 3 b 3 c 3 d 3 下面的写法在双引号前一定要加一个空格才能匹配出来 或者用单引号，但是也需要在前面几个空格 [root@centos7 mnt]#echo abcdaabbccdd|awk -F &quot;&quot; &apos;{for(i=1;i&lt;=NF;i++)x[$i]++}END{for(i in x){print i,x[i]}}&apos; a 3 此处一定有个空格 b 3 c 3 d 3 或者用单引号，但是也需要在前面几个空格 [root@mini7-1 ~]#echo abcdaabbccdd |awk -F &apos;&apos; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 2 b 3 c 3 d 2 root@centos7 mnt]#echo abcdaabbccdd | grep -o &quot;[a-z]&quot;|sort|uniq -c 3 a 3 b 3 c 3 d 10.面试题：取出/etc/fstab中的挂载目录 [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos; boot data swap [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos; boot data swap AWK中的输入分隔符我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。要一次指定多个分隔符，需要将分隔符用中括号[]包裹起来，如果多个分隔符中有至少一个特殊字符，那么还需要在中括号外加上双引号或者单引号，并且使用两个或两个以上的\将其进行转义 $、^、(、)、[、]、?、.、| 示例1： [root@node7-1 data]cat b.txt ssh:user1@192.168.1.10 ssh:user2@192.168.1.11 ssh:user3@192.168.1.12 1.取user和IP [root@node7-1 data]awk -F [:@] &apos;{print $2,$3}&apos; b.txt user1 192.168.1.10 user2 192.168.1.11 user3 192.168.1.12 2.上面b.txt中的：和@换成^和|，又该怎么取？ [root@node7-1 data]awk -F &apos;[\\^\\|]&apos; &apos;{print $2,$3}&apos; b.txt user1 192.168.1.10 user2 192.168.1.11 user3 192.168.1.12 示例2： 示例1： george[walker]bush william[jefferson]clinton 如果要打印出由分隔符[和]分隔的三段数据，即可以分别使用两个或两个以上的\对[和]进行转义，如下所示 方法一： awk -F &apos;[\\[\\]]&apos; &apos;{ print $1,$2,$3}&apos; name.txt george walker bush william jefferson clinton 方法二： awk -F &apos;[][]&apos; &apos;{ print $1,$2,$3}&apos; name.txt george walker bush william jefferson clinton 11.取出文本中的姓名和FQDN，awk的方法参照文章最上面的链接文章 [root@node7-1 data]cat a.txt xiaoming\t20\thttp://sougou.com xiaohua\t25\thttp://www.baidu.com xiaodong\t30\thttp://www.jidong.com 方法一：用awk取，以\t做分隔符，但是在表示方法上比较特殊 root@node7-1 data]awk -F&apos;\\\\t&apos; &apos;{print $1,$3}&apos; a.txt xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析： 第一个给第二个转义，第三个给第四个转义，传给awk对就是\\t，awk再将\\解释成\t 方法二：用awk和sed取 [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )t(.*)@\1\2@&apos; xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 12.扩展11题的内容把t换成$,又该如何取？ [root@node7-1 data]cat a.txt xiaoming\$20\$http://sougou.com xiaohua\$25\$http://www.baidu.com xiaodong\$30\$http://www.jidong.com 方法一：还是只用awk来取 [root@node7-1 data]awk -F&apos;\\\\\\$&apos; &apos;{print $1,$3}&apos; a.txt xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析： 1.\\$是转义$的 2.前四个\\\\是转义\的 方法二：awk和sed取 [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )\$(.*)@\1\2@&apos; xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析：先用awk用\做分隔符来取，再用sed取，sed中的$需要转义]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本处理工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB的profile、监控和备份恢复]]></title>
    <url>%2F2017%2F10%2F16%2FMongoDB%E7%9A%84profile%E3%80%81%E7%9B%91%E6%8E%A7%E5%92%8C%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[1.mongoDB的优化-Profiling捕捉慢查询 因为Mongodb中如果不添加索引，对Mongodb数据表进行查询操作的时候，需要把数据都加载到内存。当数据的数量达到几十万乃至上百万的 时候，查询就会变慢、而且Mongodb一直占据99%的CPU， 如果此时使用netstat -anp | grep ESTABLISHED过滤就会看到应用服务器有正在处理的连接请求，此时可以开启慢查询 1.1.开启profile的相关命令 db.setProfilingLevel(level,&lt;slowms&gt;) 0=off 1=slow 2=all #设置profile的级别和慢查询的超时时间 0代表关闭，1代表记录慢命令，2代表全部 注意： 1.profile需要在所有的集合下设置或则在开启的时候开启参数 ~]# vim /etc/mongodb.conf profile = 1 slowms = 200 2.每次设置之后返回给你的结果是修改之前的状态（包括级别、时间参数） db.getProfilingStatus() - returns if profiling is on and slow threshold #查看当前设置是否开启了profile db.system.profile.find() #开启了慢查询后，使用此命令可以看到超市时长的查询命令 1.2.示例： &gt; db.setProfilingLevel(1,100) #开启慢查询级别为1,时间为100ms &gt; db.system.profile.find({millis:{$gt:500}}) #查看慢查询时间超过500ms的查询语句 { &quot;op&quot; : &quot;query&quot;, #操作类型，有insert、query、update、remove、getmore、command &quot;ns&quot; : &quot;F10data3.f10_2_8_3_jgcc&quot;, &quot;query&quot; : { #具体的查询语句 包括过滤条件，limit行数 排序字段 filter&quot; : { &quot;jzrq&quot; : { &quot;$gte&quot; : ISODate(&quot;2017-03-31T16:00:00.000+0000&quot;), &quot;$lte&quot; : ISODate(&quot;2017-06-30T15:59:59.000+0000&quot;) }, &quot;jglxfldm&quot; : 10.0 }, &quot;ntoreturn&quot; : 200.0, &quot;sort&quot; : { #如果有排序 则显示排序的字段 这里是 RsId &quot;RsId&quot; : 1.0 } }, &quot;keysExamined&quot; : 0.0, #索引扫描数量 这里是全表扫描，没有用索引 所以是 0 &quot;docsExamined&quot; : 69608.0, #浏览的文档数 这里是全表扫描 所以是整个collection中的全部文档数 &quot;numYield&quot; : 546.0, #该操作为了使其他操作完成而放弃的次数。通常来说，当他们需要访问 还没有完全读入内存中的数据时，操作将放弃。这使得在MongoDB为了 放弃操作进行数据读取的同时，还有数据在内存中的其他操作可以完成。 &quot;locks&quot; : { #锁信息，R：全局读锁；W：全局写锁；r：特定数据库的读锁；w：特定数据库的写锁 &quot;Global&quot; : { &quot;acquireCount&quot; : { &quot;r&quot; : NumberLong(1094) #该操作获取一个全局级锁花费的时间。 } }, &quot;Database&quot; : { &quot;acquireCount&quot; : { &quot;r&quot; : NumberLong(547) } }, &quot;Collection&quot; : { &quot;acquireCount&quot; : { &quot;r&quot; : NumberLong(547) } } }, &quot;nreturned&quot; : 200.0, #返回的文档数量 &quot;responseLength&quot; : 57695.0, #返回字节长度，如果这个数字很大，考虑值返回所需字段 &quot;millis&quot; : 264.0, #消耗的时间（毫秒） &quot;planSummary&quot; : &quot;COLLSCAN, COLLSCAN&quot;, #执行概览 从这里看来 是全表扫描 &quot;execStats&quot; : { #详细的执行计划 这里先略过 后续可以用 explain来具体分析 }, &quot;ts&quot; : ISODate(&quot;2017-08-24T02:32:49.768+0000&quot;), #命令执行的时间 &quot;client&quot; : &quot;10.3.131.96&quot;, #访问的ip或者主机 &quot;allUsers&quot; : [ ], &quot;user&quot; : &quot;&quot; } 解释： ts：命令执行时间 info：命令的内容 query：代表查询 order.order： 代表查询的库与集合 reslen：返回的结果集大小，byte数 nscanned：扫描记录数量 nquery：后面是查询条件 nreturned：返回记录数及用时 millis：所花时间 分析和优化： 1.millis的时间较大，那么就需要作优化 2.nscanned或docsExamined数很大，或者接近记录总数，那么可能没有用到索引查询 3.如果keysExamined数为0，也可能是没用索引 4.结合 planSummary 中的显示，上例中是 &quot;COLLSCAN, COLLSCAN&quot; 确认是全表扫描 5.如果 keysExamined 值高于 nreturned 的值，说明数据库为了找到目标文档扫描了很多文档。这时可以考虑创建索引来提高效率 1.3.system.profile的结果中的&apos;type&apos;的返回参数说明 COLLSCAN #全表扫描 避免 IXSCAN #索引扫描 可以改进 选用更高效的索引 FETCH #根据索引去检索指定document SHARD_MERGE #将各个分片返回数据进行merge 尽可能避免跨分片查询 SORT #表明在内存中进行了排序（与老版本的scanAndOrder:true一致） 排序要有index LIMIT #使用limit限制返回数 要有限制 Limit+（Fetch+ixscan）最优 SKIP #使用skip进行跳过 避免不合理的skip IDHACK #针对_id进行查询 推荐,_id 默认主键,查询速度快 SHARDING_FILTER #通过mongos对分片数据进行查询 SHARDING_FILTER+ixscan最优 COUNT #利用db.coll.explain().count()之类进行count运算 COUNTSCAN #count不使用Index进行count时的stage返回 避免这种情况建议加索引 COUNT_SCAN #count使用了Index进行count时的stage返回 推荐 SUBPLA #未使用到索引的$or查询的stage返回 避免 TEXT #使用全文索引进行查询时候的stage返回 PROJECTION #限定返回字段时候stage的返回 选择需要的数据,推荐PROJECTION+ixscan 2.使用zabbix监控MongoDB由于所存储的业务数据比较重要，所以对MongoDB的监控显得尤为重要！Zabbix监控MongoDB性能的原理： 通过echo &quot;db.serverStatus()&quot; | mongo admin 来查看mongodb的状态; 1.1.Zabbix监控MongoDB性能，主要监控以下项目： - 连接数 db.serverStatus().connections.current：当前连接数 db.serverStatus().connections.available:可用连接数 注意： mongodb最大处理到2000个连接就不行了（要根据你的机器性能和业务来设定），所以设大了没意义。设个合理值的话，到达 这个值mongodb就拒绝新的连接请求，避免被太多的连接拖垮； - 内存使用情况： vsize 虚拟内存使用量，单位MB：db.serverStatus().mem.virtual res 物理内存使用量，单位MB：db.serverStatus().mem.resident - 每秒执行的查询、插入、删除、更新、getmore、等操作次数 query/s 每秒查询次数:db.serverStatus().opcounters.query inserts/s 每秒插入次数:db.serverStatus().opcounters.insert delete/s 每秒删除次数:db.serverStatus().opcounters.delete update/s 每秒更新次数:db.serverStatus().opcounters.update getmore/s:每秒getmore次数:db.serverStatus().opcounters.getmore - 每秒执行fsync将数据写入硬盘的次数 flushs/s - command/s 每秒的命令数，比以上插入、查找、更新、删除的综合还多，还统计了别的命令 - 所有的被mmap的数据量，单位是MB mapped/s - 锁 - 每秒访问的索引次数，每秒命中索引的次数 Index hit - MongoDB产生的总的页面错误数量 db.serverStatus().extra_info.page_faults - MongoDB的网络流量状况 1.2.mongod上安装zabbix_agent客户端 ~]# cat /usr/local/zabbix/etc/zabbix_agentd.conf|grep -v &quot;#&quot;|grep -v &quot;^$&quot; Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/ UnsafeUserParameters=1 #配置成1，表示启用自定义脚本功能！ 1.3.自定义监控脚本 ~]# vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/MongoDB.sh #!/bin/bash database=monitor user=monitor password=pass0p-! case $# in 1) output=$(/bin/echo &quot;db.serverStatus().$1&quot; |/bin/mongo 127.0.0.1:27017/$database -u$user -p$password|sed -n &apos;3p&apos;) ;; 2) output=$(/bin/echo &quot;db.serverStatus().$1.$2&quot; |/bin/mongo 127.0.0.1:27017/$database -u$user -p$password|sed -n &apos;3p&apos;) ;; 3) output=$(/bin/echo &quot;db.serverStatus().$1.$2.$3&quot; |/bin/mongo 127.0.0.1:27017/$database -u$user -p$password|sed -n &apos;3p&apos;) ;; esac #check if the output contains &quot;NumberLong&quot; if [[ &quot;$output&quot; =~ &quot;NumberLong&quot; ]];then echo $output|sed -n &apos;s/NumberLong(//p&apos;|sed -n &apos;s/)//p&apos; else echo $output fi ~]# setfacl -Rm u:zabbix:rwx /root #为脚本赋予zabbix执行权限 ~]# vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/userparameter_MongoDB.conf UserParameter=MongoDB.Status[*],/usr/local/zabbix/monitor_scripts/MongoDB.sh &quot;$1&quot; &quot;$2&quot; 1.4.导入监控模板，重启zabbix_agent测试即可 –mongodb监控1–mongodb监控2–mongodb监控3 3.MongoDB的单个collection和整库备份1.单个collection的导入与导出 1.1》导出工具：mongoexport mongoDB中的mongoexport工具可以把一个collection导出成JSON格式或CSV格式的文件 语法： mongoexport -d dbname -c collectionname -o file --type json/csv -f field 参数说明： -d ：数据库名 -c ：collection名 -o ：输出的文件名 --type ： 输出的格式，默认为json -f ：输出的字段，如果-type为csv，则需要加上-f &quot;字段名&quot; 示例： ~]# mongoexport -d testdb -c users -o /data/testdb_user.json --type json 2017-05-24T22:08:04.926+0800 connected to: localhost 2017-05-24T22:08:05.237+0800 exported 10000 records #总记录数 #将testdb库的users这个collection导出到/data/testdb_user.json文件 1.2.数据导入：mongoimport 语法： mongoimport -d dbname -c collectionname --file filename --headerline --type json/csv -f field 参数说明： -d ：数据库名 -c ：collection名 --type ：导入的格式默认json -f ：导入的字段名 --headerline ：如果导入的格式是csv，则可以使用第一行的标题作为导入的字段 --file ：要导入的文件 示例：删除后恢复 ~]# systemctl stop mongod #关闭mongod实例 ~]# rm -rf /data/mongodb/data/* #先删除所有数据 ~]# systemctl start mongod #重启mongod实例 ~]# mongoimport -d testdb -c users --file /data/testdb_user.json --type json 2017-05-24T22:09:52.189+0800 connected to: localhost 2017-05-24T22:09:52.396+0800 imported 10000 documents #将第一步备份的数据再导入进来 2.MongoDB备份与恢复 2.1.MongoDB数据库备份 语法： mongodump -h dbhost -d dbname -o dbdirectory 参数说明： -h： MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017 -d： 需要备份的数据库实例，例如：test -o： 备份的数据存放位置，例如：/home/mongodump/，当然该目录需要提前建立，这个目录里面存放该数据库实例的备份数据。 示例： ~]# mongodump -d hello -o /data/mongobak/ 2017-05-24T22:32:38.573+0800 writing hello.hello12345678 to 2017-05-24T22:32:38.573+0800 writing hello.hello to 2017-05-24T22:32:38.670+0800 done dumping hello.hello12345678 (10000 documents) 2019-05-24T22:32:38.704+0800 done dumping hello.hello (10000 documents) #可以看到hello库的所有collections都备份了 ~]# cd /data/mongobak/hello/ ~]# ls hello12345678.bson hello12345678.metadata.json hello.bson hello.metadata.json #可以看到collection的数据和元数据是分开存放的 2.2.MongoDB数据库恢复 语法： mongorestore -h dbhost -d dbname --dir dbdirectory 参数说明： -h： MongoDB所在服务器地址 -d： 需要恢复的数据库实例，例如：test，当然这个名称也可以和备份时候的不一样，比如test2 --dir： 备份数据所在位置，例如：/home/mongodump/itcast/ --drop： 恢复的时候，先删除当前数据，然后恢复备份的数据。就是说，恢复后，备份后添加修改的数据都会被删除，慎用！ 示例： 1.删除 &gt; use hello switched to db hello &gt; db.dropDatabase() { &quot;dropped&quot; : &quot;hello&quot;, &quot;ok&quot; : 1 } #先将hello库删除 2.恢复 [root@node02 ~]# mongorestore -d hellodb --dir /data/mongobak/hello/ 2017-05-24T22:35:40.192+0800 building a list of collections to restore from /data/mongobak/hello dir 2017-05-24T22:35:40.212+0800 reading metadata for hellodb.hello12345678 from /data/mongobak/hello/hello12345678.metadata.json 2017-05-24T22:35:40.227+0800 restoring hellodb.hello12345678 from /data/mongobak/hello/hello12345678.bson 2017-05-24T22:35:40.240+0800 reading metadata for hellodb.hello from /data/mongobak/hello/hello.metadata.json 2017-05-24T22:35:40.255+0800 restoring hellodb.hello from /data/mongobak/hello/hello.bson 2017-05-24T22:35:40.517+0800 restoring indexes for collection hellodb.hello from metadata 2017-05-24T22:35:40.528+0800 finished restoring hellodb.hello (10000 documents) 2017-05-24T22:35:40.544+0800 restoring indexes for collection hellodb.hello12345678 from metadata 2017-05-24T22:35:40.544+0800 finished restoring hellodb.hello12345678 (10000 documents) 2017-05-24T22:35:40.544+0800 done 3.数据库验证 &gt; show dbs hellodb 0.001GB local 0.000GB testdb 0.000GB &gt; use hellodb switched to db hellodb &gt; show collections hello hello12345678 #可以看到库和所有collection都恢复了 4.备注 恢复时-d databaseName 指定数据库名时可以和备份的库的名字不同!]]></content>
      <categories>
        <category>Nosql</category>
        <category>mongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB的Sharding集群实现]]></title>
    <url>%2F2017%2F10%2F16%2FMongoDB%E7%9A%84Sharding%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[1.MongoDB的sharding分片功能原理 在生产环境中，通常是这两种技术结合使用，分片+副本集 –为什么要分片–mongodb的分片框架架构 1.为什么要数据分片？ 1.随着业务的发展数据集肯定会越来越大，单节点上的CPU一直处于满负荷工作扛不住了； 2.数据量太大导致memory内存达到极限 3.数据量太大导致磁盘/网络IO达到瓶颈 扩展方式： 1.向上扩展：使用更大的内存和性能更好的CPU 2.向外扩展： 将大的数据集切分放到多个节点上,水平分片可以解决： 1.减少单机请求数,将单机负载,提高总负载 2.减少单机的存储空间,提高总存空间 2.Sharding分区概念和分片带来的问题？ 1.分片 (sharding)是指将数据库拆分,将其分散在不同的机器上的过程。将数据分散到不同的机器上,不需要功能强大的服务器就可以 存储更多的数据和处理更大的负载； 2.shard是如何将大的数据集切割的？ 1.首先sharding是collection级别的，为了能够保证整个sharding集群的每一个Shard上的数据副本大小尽可能的均衡； 2.而后这个collection会被切分成固定大小的块chunk（类似于raid），然后均匀的分散到各Shard上； 3.那么如何保证集群运行期间，各shard上的数据始终保持均衡分散的？ 下文解释! 3.MongoDB的分片框架架构 1.mysql的分片需要借助额外的技术来实现，如Gizzard,HiveDB,Mysql-proxy+HSACLE等等； 2.而MongoDB的分片实现比较简单，因为mongoDB直接支持sharding集群，而且是自动实现分片 3.mongoDB的分片框架架构，如上图 mongodb内部有三个组件：Router、Config Server、Shard 1.Router：mongos 1.mongos有一个即可，2个是为了实现冗余，相当于mongodb的代理,可以使用keepalived做高可用!! 2.用户查询请求会先到mongos，而mongos并不会存储和查询数据，它只是将用户请求路由到合适的分片上来执行而已； 3.因为要查询的数据有可能在ShardA、ShardB、ShardC上都有的，mongos必须知道每个节点上到底存储了哪些数据，因为 各Shard上存储的元数据都在Config Server上 2.Config Server 1.存储集群的元数据，所谓元数据是指对应shard上的collection的索引,也包括chunk信息； 2.mongos第一次启动或者关掉重启就会从config server加载配置信息； 3.Config Server需要至少三个节点，因为需要故障时重新选举 4.而Config-Server集群的正常工作需要借助外部的机制zookeeper来实现，zk是实现类似于paxos一样能够实现选举机制并 决定出哪个是主节点的，因此ZK是一个中心协调节点； 5.而zookeeper也是分布式的，它能够自己构建成三个节点实现内部选举!! 3.Shard:replica set 1.Shard真正存储数据的数据节点，也成为mongod实际节点 2.replica set 因为后端shard故障了，虽然能够工作但是数据少了一部分，因此后端的每一个shard都是一个副本集（至少三个节点）； 这就和分布式系统很像了，分布式系统有前端节点(元数据)和后端节点(数据)； 4.sharding上的数据是如何保证集群运行时始终保持数据均衡分散的？ 1.首先Router是根据Config Server来路由的 2.其次Config-Server存放的是collection的索引，而大家知道索引是把某一字段拿出来按升序、降序排列的一个范围，然后把索引 平均切成N段(shard的个数); 但是注意： 它不是根据范围平均切成N段，而是根据每一个范围所持有的数据数量做的平均,因此每个Shard上的范围不是平均的! 如： 0~20、21~30、31~60这样分散的，而不是0~20、21~40、41~60这样平均范围； 带来的问题： 根据范围的数据数量做平均带来的问题是：随着业务的增长，ShardA上的数据越来越大，而ShardC上可能只有极少数的数据甚至是空的!! 如： 0~20(10000条数据)、21~30(5000条数据)、31~60(100条数据) 解决办法： 此时就需要重新均衡数据，而平均均衡的方法是：将ShardA、ShardB、ShardC上的取值范围进行调整； 如： 将原理的0~20、21~30、31~60调整为0~10、11~25、26~60 因此每一个数据的重新均衡可能要全局都需要移动的!!! 3.其实mysql的分片也是如此： 把某一个表的某一字段做成索引，把索引当成分片的元数据，而后把一个大的数据集切成多个chunk再把这些chunk平均分散到 多个节点上去,在数据运行当中可能还需要进行数据的重新均衡：即数据在各个节点上挪来挪去!! – range分片–Hash的切片 5.如何切分和切分方式？ 切分方式和索引的类型有关，不同的索引类型切分方法是不一样的，而且业务使用何种分片方式取决于业务模型来判定的!! 1.基于范围切分 range分片，范围切片用到的索引一定是支持顺序排序的索引类型，如：B Tree类型的索引 如：按age索引进行切分 2.list:基于离散值进行分片 如 3.基于Hash的切片 hash索引类型的是无法排序的，因为对键排序没有任何意义，此时它就不是按范围进行切片了，它也是一种离散的切片方式 备注： 1.分片的意义： 分片的意义主要目的在于主要是分散写操作，顺带分散读操作，为了避免写热区使用离散切分是最有用的； 2.采用何种分片的指导方针： 写离散、读集中： 即分完片之后，写要离散分散到多个Shard上，而读要集中（读时涉及到的节点越少越好，因为多个节点需要综合起来重新排序） 2.MongoDB的sharding分片集群实现1.环境准备 1.1.主机分配 192.168.34.117 mongos #生产环境应该使用keepalived做高可用 192.168.34.118 config server #生产环境至少三台使用Zookeeper 192.168.34.123 Shard1 #生产环境每一个Shard都需要做Replica Set 192.168.34.126 Shard2 #生产环境每一个Shard都需要做Replica Set 1.2:搭建集群时时间一定要保持同步 ~]# ntpdate time1.aliyun.com 1.3.关闭防火墙和selinux ~]# setenforce 0 ~]# systemctl disable firewalld 2.和sharidng分片相关的命令 ~]# mongod --help sharding options: --configsvr #设定mongod实例为Config Server --configsvrMode arg # --shardsvr # 3.Sharding集群配置 3.1.先配置Config Server 1.Config Server就是一个mongod实例，通常只需要指明它是config Server即可 2.启动即可 ~]# mongod --dbpath /data/mongodb/data/ --logpath /data/mongodb/log/mongod.log --configsvr #启动时指定--configsvr即可 或者修改 ~]# vim /etc/mongod.conf --configsvr=true 3.Config Server会监听在27019端口上 [root@node01 mongodb]# ss -tnl State Recv-Q Send-Q Local Address:Port PeerAddress:Port LISTEN 0 128 192.168.34.118:27019 *:* 3.2.配置mongos 3.2.1.在192.168.34.117上配置mongos，对于mongos而言只需要安装mongos包即可 ~]# yum install mongodb-org-mongos-3.2.22-1.el7.x86_64.rpm #只需要安装mongos包即可 3.2.2.启动mongos ~]# mongos -help Sharding options: --configdb arg #启动时指定1~3个configdb的地址和端口即可 ~]# mongos --configdb=192.168.34.118:27019 --fork --logpath=/var/log/mongodb/mongos.log #启动时指定configdb的IP+端口，工作在后台和指定mongos的日志文件 3.2.3.mongos也监听在27017端口上 因为mongos是作为代理工作的，所以监听在27017端口上 3.2.4.测试连接mongos 在任意mongos客户端连接到192.168.34.117的mongos上 ~]# mongo --host 192.168.34.117 mongos&gt; help #此时可以看到显示的是mongos命令 mongos&gt; sh.help() #此时就可以使用sharding的相关命令操作了 3.3.配置所有的Shard 所有的shard配置和此前配置mongodb是一样的，指明数据目录启动即可 ~]# mongod --dbpath /data/mongodb/data/ --logpath /data/mongodb/log/mongod.log #所有shard节点直接指明数据目录启动即可 3.4.shard的管理相关命令 ~]# mongo --host 192.168.34.117 mongos&gt; sh.help() sh.addShard( host ) #添加shard节点 sh.enableSharding(dbname) #指明在某个db库上启用shard功能 默认即使构建了shard集群但并不是每个数据库都启用了shard功能 sh.shardCollection(fullName,key,unique) #因为shard是collection级别的，但并不是所有collection都需要做切割，所以需要指明对哪个库上的哪个collection做切割!!! sh.splitFind(fullName,find) sh.splitAt(fullName,middle) sh.moveChunk(fullName,find,to) sh.setBalancerState( &lt;bool on or not&gt; ) sh.getBalancerState() #查看当前均衡器的状态 sh.isBalancerRunning() #查看均衡器是否正常工作 sh.disableBalancing(coll) sh.enableBalancing(coll) sh.addShardTag(shard,tag) sh.removeShardTag(shard,tag) sh.addTagRange(fullName,min,max,tag) sh.removeTagRange(fullName,min,max,tag) sh.status() 3.5.在mongos节点添加各个Shard ~]# mongo --host 192.168.34.117 mongos&gt; sh.addShard(&quot;192.168.34.123&quot;) #添加第一个Shard mongos&gt; sh.addShard(&quot;192.168.34.126&quot;) #添加第二个Shard 3.6.使用shard功能 1.先做shard集群 2.指明对哪个库启用shard功能 3.指明对哪个库中的哪个collection的哪个键、索引做shard ~]# mongo --host 192.168.34.117 mongos&gt; sh.enableSharding(&quot;testdb&quot;) { &quot;ok&quot; : 1 } #在testdb库上启用shard功能 mongos&gt; sh.shardCollection(&quot;testdb.students&quot;,{&quot;age&quot;:1}) { &quot;collectionsharded&quot; : &quot;testdb.students&quot;, &quot;ok&quot; : 1 } #表示在testdb的students上的age字段上做升序索引 注意：collection一定要指明是哪个库的哪个collection mongos&gt; sh.status() #使用sh.status()查看shard的信息 --- Sharding Status --- sharding version: { &quot;_id&quot; : 1, &quot;minCompatibleVersion&quot; : 5, &quot;currentVersion&quot; : 6, &quot;clusterId&quot; : ObjectId(&quot;5ce6b9abe14fff2a5ded9696&quot;) } shards: { &quot;_id&quot; : &quot;shard0000&quot;, &quot;host&quot; : &quot;192.168.34.123:27017&quot; } { &quot;_id&quot; : &quot;shard0001&quot;, &quot;host&quot; : &quot;192.168.34.126:27017&quot; } active mongoses: &quot;3.2.22&quot; : 1 balancer: Currently enabled: yes Currently running: no Failed balancer rounds in last 5 attempts: 0 Migration Results for the last 24 hours: No recent migrations databases: { &quot;_id&quot; : &quot;testdb&quot;, &quot;primary&quot; : &quot;shard0000&quot;, &quot;partitioned&quot; : true } testdb.students shard key: { &quot;age&quot; : 1 } unique: false balancing: true chunks: shard0000 1 { &quot;age&quot; : { &quot;$minKey&quot; : 1 } } --&gt;&gt; { &quot;age&quot; : { &quot;$maxKey&quot; : 1 } } on : shard0000 Timestamp(1, 0) 解释： 1.&quot;primary&quot; : &quot;shard0000&quot;分片的意义 因为testdb库中并不是所有的collection都做分片，所以不做分片的collection都放在shard0000，做了分片的均衡分散在shard0000和shard0001上； 2.chunks: shard0000 1 { &quot;age&quot; : { &quot;$minKey&quot; : 1 } } --&gt;&gt; { &quot;age&quot; : { &quot;$maxKey&quot; : 1 } } on : shard0000 Timestamp(1, 0) #表示第一个分片shard0000，最小值--&gt;最大值都放在shard0000上，因为此时刚创建好没有数据； 3.7.创建数据并查看是否实现了分片 mongos&gt; use testdb switched to db testdb mongos&gt; for (i=1;i&lt;=10000;i++)db.students.insert({name:&quot;student&quot;+i,age:(i%120),address:{ city:&quot;北京&quot;, district:&quot;海淀区&quot; }}) WriteResult({ &quot;nInserted&quot; : 1 }) #创建students的数据 mongos&gt; sh.status() balancer: Currently enabled: yes Currently running: no Failed balancer rounds in last 5 attempts: 0 Migration Results for the last 24 hours: 2 : Success databases: { &quot;_id&quot; : &quot;testdb&quot;, &quot;primary&quot; : &quot;shard0000&quot;, &quot;partitioned&quot; : true } testdb.students shard key: { &quot;age&quot; : 1 } unique: false balancing: true chunks: shard0000 2 shard0001 1 { &quot;age&quot; : { &quot;$minKey&quot; : 1 } } --&gt;&gt; { &quot;age&quot; : 2 } on : shard0001 Timestamp(2, 0) { &quot;age&quot; : 2 } --&gt;&gt; { &quot;age&quot; : 10 } on : shard0000 Timestamp(2, 1) { &quot;age&quot; : 10 } --&gt;&gt; { &quot;age&quot; : { &quot;$maxKey&quot; : 1 } } on : shard0000 Timestamp(1, 3) 3.8.运维时故障案例 &gt; use text switched to db text &gt; db.books.insert({x:&quot;1&quot;,y:&quot;2&quot;}) can&apos;t create user databases on a --configsvr instance ##报错信息 解答： 这个错误是说在configsvr的实例上创建collection失败了，可以看出首先这是一个mongodb的sharding集群，所有数据插入 和查询的接口都是mongos服务器的IP+端口，报这个错只能说没有连到mongos而是连到了后端的Shard上了； 3.8.功能补充 查看哪些数据库启用了shard功能 db.databases.find({&quot;partitioned&quot;:true}) 列出所有的shard mongos&gt; use admin mongos&gt; db.runCommand(&quot;listShards&quot;) { &quot;shards&quot; : [ { &quot;_id&quot; : &quot;shard0000&quot;, &quot;host&quot; : &quot;192.168.34.123:27017&quot; }, { &quot;_id&quot; : &quot;shard0001&quot;, &quot;host&quot; : &quot;192.168.34.126:27017&quot; } ], &quot;ok&quot; : 1 } 显示shard集群的详细信息 db.printShardingStatus()=sh.status()]]></content>
      <categories>
        <category>Nosql</category>
        <category>mongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[旧事-大好河山]]></title>
    <url>%2F2017%2F10%2F01%2F%E6%97%A7%E4%BA%8B-%E5%A4%A7%E5%A5%BD%E6%B2%B3%E5%B1%B1%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. U2FsdGVkX1+hGPlCtthVTOXP555uxfQ3Zavo6pFGEHwMC2zLjLdXWKrH3r/KGf7v+BGN92XHLY/Y8Q4tMvuwtOwS0+LcpWnEd6+d6njhyPforyiWJZUefLRGuwN5K5Z1eeenAAzXZSc3cMJJFywlDot6atVm3/cpqpbQL6uActpRtwZ47IB1Ln/ho35B+htCtZQDhnsd81eR4/tHxz4uEI8OB3v1EkP4TuMWmdQ9A9VB6iEAz24qolsKYvqFSyRR9oGmWrSjj18XOV5PIIBihAdit8yXGrC7QpRkTLbFW42/V3uujrMEQ2x7LLoIaPpU/RZNd5XiCm71fQ3iMvxZt9un9IYRYV2CbuqPYzUCk/YfSLTQ9fzX8X3TaMR+9w5K]]></content>
      <categories>
        <category>旧事，杂记</category>
      </categories>
      <tags>
        <tag>旧事，杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MQ-activemq]]></title>
    <url>%2F2017%2F09%2F16%2FMQ-activemq%2F</url>
    <content type="text"><![CDATA[ActiveMQ基础 ActiveMQ官方 1.ActiveMQ ActiveMQ是Apache所提供的一个开源的消息系统，完全采用Java来实现，因此，它能很好地支持J2EE提出的 JMS（Java Message Service,即Java消息服务）规范。JMS是一组Java应用程序接口，它提供消息的创建、发送、读取等一系列服务。 JMS提供了一组公共应用程序接口和响应的语法，类似于Java数据库的统一访问接口JDBC,它是一种与厂商无关的API，使得Java程序 能够与不同厂商的消息组件很好地进行通信； 2.JMS：Java Message Service JMS支持两种消息发送和接收模型： 1.P2P(Ponit to Point)：点对点模型 P2P模型是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息，队列的存在使得消息的异步传输称为可能， P2P模型在点对点的情况下进行消息传递时采用 2.Pub/Sub(Publish/Subscribe):发布订阅模型 发布-订阅模型定义了如何向一个内容节点发布和订阅消息，这个内容节点称为topic(主题)。主题可以认为是消息传递的中介， 消息发布这将消息发布到某个主题，而消息订阅者则从主题订阅消息。主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消息的传递，发布-订阅模型在消息的一对多广播时采用 3.JMS术语 * Provider/MessageProvider：生产者 * Consumer/MessageConsumer：消费者 * PTP：Point To Point，点对点通信消息模型 * Pub/Sub：Publish/Subscribe，发布订阅消息模型 * Queue：队列，目标类型之一，和PTP结合 * Topic：主题，目标类型之一，和Pub/Sub结合 * ConnectionFactory：连接工厂，JMS用它创建连接 * Connnection：JMS Client到JMS Provider的连接 * Destination：消息目的地，由Session创建 * Session：会话，由Connection创建，实质上就是发送、接受消息的一个线程，因此生产者、消费者都是Session创建的 4.JMS和MQ的关系： 1.JMS是一个用于提供消息服务的技术规范，它制定了在整个消息服务提供过程中的所有数据结构和交互流程。而MQ则是消息队列 服务，是面向消息中间件（MOM）的最终实现，是真正的服务提供者；MQ的实现可以基于JMS，也可以基于其他规范或标准； 2.支持JMS的开源MQ： 前选择的最多的是ActiveMQ，ActiveMQ是一个完全支持JMS1.1和J2EE1.4规范的JMS Provider实现； 3.项目要求 1.由于最近一个项目并发请求压力比较大，所以考虑改进架构，引入消息中间件集群作为一个缓冲消息队列，具体需求： 1.将大量的WebService请求报文发送到mq集群之中，并保持消息先后顺序 2.保证每个消息的可靠性 3.维护MQ服务器的可扩展性 2.权衡利弊，公司倾向于使用activemq这种能力强劲的开源消息总线。本项目使用的是： activemq5.12，activemq5.12要求jdk6+，本次使用jdk8，并引入activemq服务器。 –activemq内部实现 4.ActiveMQ内部实现,如上图 生产者进程向activeMQ所在进程发送消息和消费者消费消息的过程如上图所示，消息传递的路径经过了核心领域模型，具体步骤如下： 1.生产者通过向activeMQ为它建立好的TransportConnection发送消息给activeMQ。 2.TransportConnection对象找到RegionBroker。 3.RegionBroker根据消息的类型找到对应的消息区域(Region)。 4.该Region在它自己里面找到相应的消息目的地。 5|6.该目的地首先根据需要进行持久化操作，并使用待发送消息指针对象。 7.当有合适的消息消费者、订阅者来到时，目的地会找到这些消费者。 8|9.通过该消费者对应的TransportConnection，消息从activeMQ中出来，发给相应的消费者进程 5.queue和topic 1.在JMS中，topic实现的是发布订阅的语义，在发布消息时，它将发送给所有感兴趣的订阅者——因此，对于许多订阅者来说，得到许 多订阅者将收到消息的副本。值得注意的是只有在代理接收到消息的时候拥有一个活跃订阅的订阅者将获得消息的副本； 2.queue实现的是负载均衡的语义。一条消息只被一个消费者接收，如果在发送消息时没有可用的用户，则将该消息保留，直到可以接收 该消息的用户可用为止。如果消费者收到一条消息，并且在关闭之前不承认它（not ack），那么消息将被重新发送到另一个消费者。 队列可以让许多消费者在可用的消费者之间平衡消息负载； 6.消息持久化 JMS规范支持两种类型的消息传递：持久性和非持久性； 1.持久性消息传递必须将持久性属性记录到稳定存储中，非持久性只是进行最大努力的传递信息，不用记录。ActiveMQ支持这两种消息 传递，也可配置为支持消息恢复，介于两者之间的状态的消息被存在内存中； 2.ActiveMQ很好的支持了消息的持久性(Persistence)。消息持久性对于可靠消息传递来说应该是一种比较好的方法，有了消息持久化， 即使发送者和接受者不是同时在线或者消息中心在发送者发送消息后宕机了，在消息中心重新启动后仍然可以将消息发送出去， 如果把这种持久化和ReliableMessaging结合起来应该是很好的保证了消息的可靠传送； 3.消息持久性的原理： 在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等，然后试图将消息发送给接 收者，发送成功则将消息从存储中删除，失败则继续尝试。消息中心启动以后首先要检查制定的存储位置，如果有未发送成功的 消息，则需要把消息发送出去。 对于ActiveMQ，消息的持久化是很简单的，仅仅通过配置信息就可以实现。非持久性消息通常被用 在发送通知和实时数据。当性能要求是第一位，确认消息交付在第二位时应该选用非持久性消息； 2.ActiveMQ+Zookeeper集群1.环境准备 activemq1 192.168.1.101 activemq2 192.168.1.102 activemq3 192.168.1.103 软件版本：activemq-5.12.1、zookeeper-3.4.13 2.zookeeper集群安装 参考：zookeeper集群部署.txt 3.部署ActiveMQ ~]# wget https://mirrors.aliyun.com/apache/activemq/5.12.1/apache-activemq-5.12.1-bin.tar.gz #active官方下载太慢，这里使用阿里云提供的地址下载 ~]# tar xf apache-activemq-5.15.9-bin.tar.gz -C /usr/local/src/ ~]# ln -sv /usr/local/src/apache-activemq-5.15.9 /usr/local/activemq #创建软链 4.修改配置文件activemq.xml称为集群 ~]# cd /usr/local/activemq/conf/ ~]# cp activemq.xml activemq.xml.bak #先备份一个文件再修改 ~]# vim activemq.xml ... &lt;broker xmlns=&quot;http://activemq.apache.org/schema/core&quot; brokerName=&quot;mq-cluster1&quot; dataDirectory=&quot;${activemq.data}&quot; useJmx=&quot;true&quot;&gt; ... &lt;!-- &lt;persistenceAdapter&gt; &lt;kahaDB directory=&quot;${activemq.data}/kahadb&quot;/&gt; &lt;/persistenceAdapter&gt; --&gt; &lt;persistenceAdapter&gt; &lt;replicatedLevelDB directory=&quot;${activemq.data}/leveldb&quot; replicas=&quot;3&quot; bind=&quot;tcp://192.168.1.101:62621&quot; zkAddress=&quot;192.168.1.101:2181,192.168.1.102:2181,192.168.1.103:2181&quot; zkPassword=&quot;&quot; hostname=&quot;192.168.1.101&quot; sync=&quot;local_disk&quot; zkPath=&quot;/activemq/leveldb-stores&quot;/&gt; &lt;/persistenceAdapter&gt; ... &lt;systemUsage&gt; &lt;systemUsage&gt; &lt;memoryUsage&gt; &lt;memoryUsage percentOfJvmHeap=&quot;70&quot; /&gt; &lt;/memoryUsage&gt; &lt;storeUsage&gt; &lt;storeUsage limit=&quot;100 gb&quot;/&gt; &lt;/storeUsage&gt; &lt;tempUsage&gt; &lt;tempUsage limit=&quot;50 gb&quot;/&gt; &lt;/tempUsage&gt; &lt;/systemUsage&gt; &lt;/systemUsage&gt; ... &lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name=&quot;openwire&quot; uri=&quot;tcp://192.168.1.101:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;!-- &lt;transportConnector name=&quot;amqp&quot; uri=&quot;amqp://0.0.0.0:5672?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;transportConnector name=&quot;stomp&quot; uri=&quot;stomp://0.0.0.0:61613?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;transportConnector name=&quot;mqtt&quot; uri=&quot;mqtt://0.0.0.0:1883?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; &lt;transportConnector name=&quot;ws&quot; uri=&quot;ws://0.0.0.0:61614?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt; --&gt; &lt;/transportConnectors&gt; 需要修改的地方： 1.brokerName=&quot;mq-cluster1&quot;和seJmx=&quot;true&quot; 1.修改集群内的所有的mq的brokerName为同一个值，也就是mq集群名称，不能使用默认的localhost; 2.useJmx=&quot;true&quot;的属性，用作server的负载均衡使用 2.注释掉kahaDB段，并新增replicatedLevelDB字段： replicas: 3 #表示activemq集群内有三个mq节点 bind: #不要使用tcp://0.0.0.0:0，改成192.168.1.130:62621 zkAddress: #zk集群三个节点的IP+port zkPasswdord: #zk的密码，如果没有留空就行 hostname: #当前主机的名称，可填IP或者主机名 zkPath=&quot;/activemq/leveldb-stores&quot; #activemq注册到zk集群中的ZNode节点路径，下文创建好activemq集群，在zk集群上就可以看到了； 3.ActiveMQ的内存分配信息 memoryUsage：表示所有队列对象占用的内存大小为70mb，可以不修改 4.配置activemq的服务端口：61616 1.注释name为amqp、stomp、mqtt、ws几行 2.修改openwire中的IP为本机IP； 5.另外两个节点配置 ~]# scp /usr/local/activemq/conf/activemq.xml 192.168.1.102:/usr/local/activemq/conf/ ~]# scp /usr/local/activemq/conf/activemq.xml 192.168.1.103:/usr/local/activemq/conf/ #经修改后的文件拷贝到各自目录，activemq.xml中也要改成各自的IP 6.启动三个节点的activeMQ ~]# /usr/local/activemq/bin/activemq start INFO: Loading &apos;/usr/local/src/apache-activemq-5.12.1//bin/env&apos; INFO: Using java &apos;/usr/bin/java&apos; INFO: Starting - inspect logfiles specified in logging.properties and log4j.properties to get details INFO: pidfile created : &apos;/usr/local/src/apache-activemq-5.12.1//data/activemq.pid&apos; (pid &apos;17915&apos;) #3个节点的activemq都要启动 7.验证activemq的高可用 1.因为使用zookeeper做负载均衡，三台activemq服务器中只会有一台是master，其他两台处于等待状态，所以只有其中一台提供服务。 2.所以其他两台服务器虽然active程序启动了，但是61616服务端口和8161管理端口是关闭等待状态（即也就是说这两台节点的这两个端口不会起来，只有当master节点故障时，他们中的一个节点的这两个端口才会接着起来） 3.查看3台activemq的端口情况 ~]# ss -tnl LISTEN 0 50 :::8161 LISTEN 0 128 ::ffff:192.168.1.101:61616 #1.8161是activemq的管理端口，可在jetty.xml中修改端口 #2.61616是active的服务端 #3.这有activemq的master节点才会监听8161和61616端口，其他两节点此时端口不会起来，只有master故障时才另外 两台activemq有一台会成为master; 8.查看zk集群上activemq集群的ZNode注册信息 ~]# /usr/local/zookeeper/bin/zkCli.sh [zk: localhost:2181(CONNECTED) 0] ls / [activemq, zookeeper] [zk: localhost:2181(CONNECTED) 2] ls /activemq [leveldb-stores] [zk: localhost:2181(CONNECTED) 3] ls /activemq/leveldb-stores [00000000003, 00000000004, 00000000005] #可以看到activemq注册的ZNode数据节点是/activemq/leveldb-stores和上文中activema.xml中的zkPath是一致的； 9.登录activemq的管理页面 http://192.168.1.101:8161/admin http://192.168.1.102:8161/admin http://192.168.1.103:8161/admin #只有master节点才会登录到管理页面，用户和密码都是admin –activemq管理界面 9.故障模拟 1.停止activemq的master：192.168.1.101 ~]# ps -ef|grep activemq|grep -v grep|awk &apos;{print $2}&apos;|xargs kill -9 或者 ~]# /usr/local/activemq/bin/activemq stop 2.查看另外两节点的端口监听情况 ~]# ss -tnl LISTEN 0 50 :::8161 LISTEN 0 128 ::ffff:192.168.1.103:61616 #最终查看master转移到了192.168.1.103主机上了 10.其他建议修改的地方，可改可不改 1.修改activemq管理端口 ~]# vim /usr/local/activemq/conf/jetty.xml &lt;property name=&quot;port&quot; value=&quot;8161&quot;/&gt; #管理端口不建议修改 ~]# /usr/local/activemq/bin/activemq stop ~]# /usr/local/activemq/bin/activemq start #重启activemq 2.修改activemq管理界面登陆的用户名和密码 默认的用户名和密码为admin，内部使用还好，但如果是对外服务，安全考虑，最好还是将用户名和密码修改下； ~]# vim /usr/local/activemq/conf/activemq.xml ... &lt;/shutdownHooks&gt; &lt;plugins&gt; &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username=&quot;${activemq.username}&quot; password=&quot;${activemq.password}&quot; groups=&quot;users,admins&quot;/&gt; &lt;/users&gt; &lt;/simpleAuthenticationPlugin&gt; &lt;/plugins&gt; &lt;/broker&gt; 备注： 账号密码时调用../conf/credentials-enc.properties文件中的activemq.username、activemq.password值； ~]# /usr/local/activemq/bin/activemq stop ~]# /usr/local/activemq/bin/activemq start #重启activemq后使用户名和密码system：manager登录即可；]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB索引和副本集实现]]></title>
    <url>%2F2017%2F09%2F16%2FMongoDB%E7%B4%A2%E5%BC%95%E5%92%8C%E5%89%AF%E6%9C%AC%E9%9B%86%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[1.mongodb的索引 –索引原理 1.因为mongoDB是用在大数据和海量存储场景使用的，适用于分布式场景存储数据的，因此当数据量很大时要想快速查询就应该依赖于索引； 2.索引是指对特定字段抽取出来定义好一个数据结构，对这个数据结构实现特定数据查找，这个数据会指向原始文档所在的位置； 3.索引原理 1.索引一般是把经常作为查找条件的字段抽取出来专门放到一个文件（数据结构），然后把这个文件中的内容根据对应的次序做好排序存 储为特定结构方便查找； 2.索引也是需要CRUD的，因为向表或者文档中插入、修改、删除数据时索引也需要随着原始数据的改变而改变，所以说虽然索引的存在的确 加速了查询操作但是也增加了额外的IO和延迟了写性能的，但是对大的数据集来说索引非常重要更何况很多索引应用支持延迟索引修改； 延迟索引修改： 当批量修改数据时，不会每一个索引都实时修改，而是把所有数据都修改完之后，它会过一段时间一批批的修改索引，这样就可以 降低索引对写性能的影响； 3.索引是一种特殊结构，而且索引中的数据通常是排序后的（升序或降序），索引中的每一个数据会有一个指针指向零碎的用户所在原始 collection中的文档位置；因此根据索引查到的不是直接结果还需要根据索引指向的位置在执行一次IO找到我们期望获取到的真正数据； 4.上面就是索引的基本要点,而且mongodb的索引命令接口使用比较简单，只需要关注索引的类型即可； 4.索引类型 1.B Tree索引 mysql是B+ Tree，平衡树的数据结构有线性结构、树形结构、图示结构 2.Hash索引 1.把对应字段的每一个值当做键构建成hash的格式，而后根据hash的值查找其在原始文件中的数据位置； 2.因为hash值一般来说都是唯一的，因此这些hash值被有效的分散至多个hash桶当中，比如如果hash值是16进制的，因为hash值（ 数字组合）开头是0-15的，就可以分成16段每一段称为一个hash桶，当定位某一个索引项时可以先找到某一个hash桶再找到这个 hash桶上的hash值，因此无论你有多少个条目超找所需要消耗的时间是一致的； 3.因此hash索引也类似于键值对查找,只不过和键值存储不同的是hash索引找到的并不是键的值value,hash索引所找到的是指向原始 数据的指针，因此还需要额外的一次IO才能找到原始数据； 4.hash索引的性能还是比B Tree性能高得多； 3.空间索引R-Tree 4.全文索引(FULLTEXT) 5.mongoDB所支持的索引类型 需要注意的是mongodb支持的索引类型并不是从索引本身的数据结构来描述的，而是根据索引所应用的位置和应用的字段来描述的； 1.单键索引:Single Field Indexes 构建在一个指定字段上的索引 2.组合索引：Compound Indexes 1.组合索引是将构建在多个字段上的索引（在mysql中的组合索引是最左前缀索引用法）； 2.多个单键索引查询效率较低，构建为组合索引的话就可以在一个索引中完成两次对应数据的查找、高效、返回比较精确的数据； 3.多键索引：Multikey Indexes Create命令：db.mycollName.insert({key1:value1,key2:{key21:value21}}) 如上面的创建命令，多键索引和单键索引是不同的，单键索引是指构建在key1:value1上的，而多键索引是构建在那些某个字段的值 又是一个子文档的索引，如构建在key2:{key21:value21}上； 4.空间索引：Geospatial Indexes and Queries 基于位置查找的称为空间索引，不过一般只能使用空间索引函数才能够有效的被引导 5.文本索引：Text Indexes 文本索引其实就是全文索引，它支持去搜索整个文档中的文本串； 6.hash索引 思想类似于上面提到的，这里说下简单的树状索引和hash索引最大区别在于hash索引仅支持精确值查找； 比如： age=20的使用hash索引非常容易找到，但是查询age&gt;20的就不不能实现了，因为hash的键中所保存的是hash值（20和21的 hash值相差太大），它有可能在不同的hash桶当中的，而树状（B-Tree）索引却不同，它是把值做有效排序后存储在同一个分支上，更容易实现做范围查找； 因此hash索引适用场景是： 只支持等值比较查询，包括=, &lt;=&gt;(也是等于的意思), IN() 6.在mongodb上创建索引 &gt; db.mycoll.help() db.mycoll.createIndex(keypattern[,options]) #新版本的创建方法 db.mycoll.ensureIndex(keypattern[,options]) #老版本的创建方法 keypattern：指明如何取创建索引 数字1表示升序，-1表示降序 options：并指定选项,且常用选项有 name:为索引取名 unique：true：唯一键索引 dropDups:把原有的重复数据drop掉 backgroud:true:数据库有大量数据，以后台方式创建索引 sparse:指明使用稀疏格式的索引 db.mycoll.createIndexes([keypatterns], &lt;options&gt;) db.mycoll.dropIndex(index) #删除索引，指明删除具体哪个索引 db.mycoll.dropIndexes() #删除某个collection上的所有索引 db.mycoll.getIndexes() #查看某个collection上的所有索引 db.mycoll.reIndex() #重建索引 db.mycoll.find().explain() #显示执行过程和mysql中的类似 7.示例： 在testdb库上名为students的collection上创建索引 &gt; use testdb #切换到testdb库 &gt; for (i=1;i&lt;=10000;i++)db.users.insert({name:&quot;user&quot;+i,age:(i%120),address:{ city:&quot;北京&quot;, district:&quot;海淀区&quot; }}) #使用for循环在users上插入10000行数据 &gt; db.users.find().count() 10000 #说明10000行数据插入成功了 &gt; db.students.find() #此时只显示前10行数据，说明数据插入成功 7.1.单键索引与组合索引 7.1.1:单键索引 &gt; db.users.createIndex({name:1},{background:true}) { &quot;createdCollectionAutomatically&quot; : false, &quot;numIndexesBefore&quot; : 1, &quot;numIndexesAfter&quot; : 2, &quot;ok&quot; : 1 } #表示在users的name字段上以后台方式创建索引 7.1.2：组合索引 &gt; db.users.createIndex({name:1,age:-1}) { &quot;createdCollectionAutomatically&quot; : false, &quot;numIndexesBefore&quot; : 1, &quot;numIndexesAfter&quot; : 2, &quot;ok&quot; : 1 } #为users表的name和age两个字段，分别按升序和降序创建索引 注意： 创建复合索引后，在使用时应当注意：查询字段要在索引中存在，且顺序一致；如果索引中的首个字段没有出现在查询条件 中，则不会用索引 7.2.唯一索引与强制使用索引 7.2.1：唯一索引 在关系型数据库中，我们可以为字段创建唯一索引，以保证字段值的唯一，MongoDB中同样可以使用唯一索引，创建索引时添加 unique:true选项即可； &gt; db.users.createIndex({name:1},{unique:true}) #在name字段上，创建唯一键索引 &gt; db.users.getIndexes() { &quot;v&quot; : 1, &quot;unique&quot; : true, #查看索引可以看到这时一个唯一键索引 &quot;key&quot; : { &quot;name&quot; : 1 }, &quot;name&quot; : &quot;name_1&quot;, &quot;ns&quot; : &quot;testdb.users&quot; } &gt; db.users.insert({name:user20,age:20}) WriteResult({ &quot;nInserted&quot; : 0, &quot;writeError&quot; : { &quot;code&quot; : 11000, &quot;errmsg&quot; : &quot;insertDocument :: caused by :: 11000 E11000 duplicate key error index: itbilu.users.$mobile_1 dup key: { : null }&quot; } }) 创建唯一索引后，当插入重复值时，MongoDB会报错 7.3.查看和删除索引 &gt; db.users.getIndexes() [ { &quot;v&quot; : 1, &quot;key&quot; : { &quot;_id&quot; : 1 }, &quot;name&quot; : &quot;_id_&quot;, &quot;ns&quot; : &quot;testdb.users&quot; }, #默认就有有一个索引 { &quot;v&quot; : 1, &quot;key&quot; : { &quot;name&quot; : 1 }, &quot;name&quot; : &quot;name_1&quot;, #索引名字 &quot;ns&quot; : &quot;testdb.users&quot;, &quot;background&quot; : true } #此为上面手动创建的索引 ] &gt; db.users.dropIndex(&quot;name_1&quot;) { &quot;nIndexesWas&quot; : 2, &quot;ok&quot; : 1 } #删除名为&quot;name_1&quot;的索引，字串需要用&quot;&quot;双引号 7.4.explain说明 &gt; db.users.find({name:&quot;user1000&quot;}).explain() #使用explain会显示详细的执行过程 &gt; db.users.find({name:{$gt:&quot;user1000&quot;}}).explain() #查询name大于user1000的信息 8.索引优化 MongoDB支持对DB的请求进行profiling，目前支持3种级别的profiling 0： 不开启profiling 1：将处理时间超过某个阈值(默认100ms)的请求都记录到DB下的system.profile集合 （类似于mysql、redis的slowlog） 2： 将所有的请求都记录到DB下的system.profile集合（生产环境慎用） 通常，生产环境建议使用1级别的profiling，并根据自身需求配置合理的阈值，用于监测慢请求的情况，并及时的做索引优化 2.mongoDB服务器的管理服务器管理其实就是mongodb自己如何定义它的服务器参数的； 即如何定义它的服务器参数和运行时参数、各个参数的意义 ~]# mongod -help General options: 通用选项 --dbpath=logpath:指定数据存储目录 --logfile=lgfilepath:指定日志目录 --fork={true|false}:mongod是否运行在后台 --bind_ip=IP：指定启动以后所监听的地址，在2.6以后默认是127.0.0.1 --port=PORT:指定监听的端口，默认是27017，管理接口是28017 --maxConns=NUM：支持的最大并发连接数，默认是1000000 --logpath：mongodb自己管理的日志 --syslog：发给syslog,由syslog管理mongodb的日志，两种日志管理方式 --logappend；这项是实现日志滚动的，而不是覆盖原来的日志 --keyFile：实现集群时的私钥文件存放位置 --httpinterface：是否启用内置的http接口，不启用就不会监听28017端口 --auth：是否启用mongod的认证功能，默认是没有的 --repair:启用mongodb时要先修改各个database，尤其是在断电后重启mongodb时 --journal: 1.log是历史事件信息，而journal是实现数据写入时为了保证数据一致性，先顺序写入到一个文件中然后每隔一段时间再同步 到文件中去（类似事务日志把随机IO转换成顺序IO以提高性能的； 2.在单实例的mongodb，journal是一定要启用的以保证数据是持久的 性能调试相关的 --cpu：周期性的显示CPU和IO的利用率信息 --sysinfo：显示系统级别的诊断信息的 在启动和运行过程中有问题时可以根据这个文件来判断问题所在的 在生产环境下如果mongodb运行时有问题可以打开此项来查找问题 --slowms arg (=100)：指明多长时间的查询是慢查询的，时间是毫秒ms --profile=[0=off|1=slow|2=all]:性能剖析,启动某一功能时评估运行性能 0=off：关闭性能剖析功能 1=slow：仅剖析慢查询 2=all：剖析所有查询操作 需要注意的是调试相关选项只有在调试时才开启，生成环境下不建议开启 Replication options:复制相关的选项，两种复制架构的通用选项 --oplogSize arg：自定义oplog的大小； mongdb支持主从复制(废弃了)和副本集复制两种复制，下面是各自的选项 1.Master/slave options：主从复制相关的选项 2.Replica set options:副本集(复制集)相关选项 --replSet arg --replIndexPrefetch arg --enableMajorityReadConcern Sharding options:分片/切片相关的选项 --configsvr --configsvrMode arg --shardsvr 3.mongoDB的复制功能-副本集复制–mongodb副本集架构图 复制功能是指在断电、磁盘故障等都会导致数据库服务器离线，所以为了防范此类故障带来损失通常为数据库服务器提供冗余能力，和mysql 一样可以通过复制方式在某一服务器故障时还能够提供数据服务的可用性； 1.mongdb支持主从复制和副本集复制两种复制，复制是最常见的故障解决方案 主从复制：master/slave mongodb的主从复制已经被废弃了，因为它和mysql的主从一样在主节点故障时，不能自动提升某一从节点为主节点； 副本集复制：replica set mongodb的副本集复制有很强大的自动故障转移，当主节点故障时他会自动从从节点选取出一个新的主节点，因为一般都是使用副本集复制的架构； 2.副本集复制的功能介绍 1.副本集其实是指服务于同一数据集的一组mongodb实例，在副本集中有一个实例负责读写，其他副本只能读，即一个主节点多个从节点； 2.副本集的主从节点是如何复制数据的？ 1.mysql复制是主节点将数据保存到二进制日志中，从节点是通过复制二进制日志中的事件来完成复制的； 2.而mongodb是主节点通过将修改操作保存在操作日志中oplog,各从节点通过此oplog复制数据并应用到本地的； 3.由于mongodb本身的工作机制当中内部数据的sechme和mysql有所不同，所以oplog和二进制日志还是有着相当大的不同之处的， 而且oplog在副本集中有着独有的内在格式是不能查看的(不像mysql读取二进制日志的方式); 4.mongodb虽然也是主从、异步复制的，但它有诸多方案来保证从节点尽可能的时刻与主节点保持一致的（在副本集中有心跳信息）! 3.主节点故障判断 1.多个从节点会通过副本集内部的心跳信息不断的监测着主节点（每个2s发送一次心跳检测），在超过10s没有接收到主节点的心跳， 多个从节点之间会重新触发一次新的选举其中一个从为新的主节点（根据优先级的高低）； 2.注意： 各节点间是通过不断的传递心跳信息来判定健康状态的，而且是每隔2s进行一次； 4.仲裁节点：arbiter节点 1.和主从架构不同的是，副本集通常至少应该有三个节点，因为主节点故障时，至少有两个以上节点判定主节点是否出现故障； 2.第三个节点可以不参与数据复制，它的作用只是作为仲裁节点参与选举即可，这样数据只在一主一从节点复制； 5.工作特性 1.至少三个节点，且应该为奇数个节点，可以使用arbiter来参与选举 2.hearbeat（2s一次） 3.自动失效转移 超过10s找不到主节点会触发重新选举，进而实现自动故障转移 6.副本集中的4种特殊节点 0优先级的节点： 1.冷备节点，不会被选举称为主节点，但可以参与选举 2.0优先级的节点通常是用于异地容灾的场景 被隐藏的从节点： 1.隐藏的从节点首先必须是0优先级的节点，是不会被客户端访问到 2.其次它也不会显示在对应的mongodb的很多状态信息显示的程序中 3.但隐藏的从节点依然具有选举权 延迟复制的从节点： 1.延迟复制的节点会比主节点慢一个指定的时间窗口，它的数据集一定是处于过期状态的，因此不能选举为主节点； 2.延迟复制的从节点首先必须是0优先级的节点，不能被选举称为主节点，但可以参与选举； 3.适用场景 当主节点出现误操作时，在指定的时间窗口内断开与主节点关系，这个延迟节点的数据就是安全的； arbiter:仲裁节点 只是参与选举仲裁的，不会参与数据复制 3.MongoDB的复制架构 1.副本集复制依赖到的两个基础性的工具 1.oplog:实现复制过程的基础工具 2.hearbeat:心跳信息传递和触发重新选举 2.oplog 1.和mysql的主从复制一样，每一个从节点都有可能被提升为主节点，因此都需要开启oplog; 2.oplog的大小是大小固定的文件，默认存储在local库中的，但是只有启用副本集的场景中才会出现和副本集相关的文件； 3.oplog是记录主节点的每一个修改操作的，尽管副本集每一个节点都需要开启oplog,但仅有主节点会写入oplog并传递给其他从节点; 4.oplog的大小是对应的oplog所在的文件系统大小的5%，如果计算结果小于1G,通常会被指定为1G； 5.oplog和mysql二进制日志不同，它是幂等性的这就意味着同一oplog可以在同一个mongodb上运行多次而且结果是一样的，它比二进制日志更好用； 6.既然oplog是大小固定的，那么它能够存储的有效时长的数据也是固定的，因此新加一个节点时他不会从oplog开始复制数据， 而是先从主机上的数据集复制再复制oplog中的数据； 7.新节点加入后操作分为三步： 1.初始同步（initial sync） 2.回滚后追赶（post-rollback catch-up） 3.切分块迁移（sharing chunk migrations） 3.local： 1.oplog是存放在local数据库中的; 2.local存放了副本集的所有元数据和oplog,而且local不会参与复制过程 3.用于存储oplog的是一个名为oplog.rs的collection,默认不会被创建，只要这个节点加入到副本集并启动时才会被创建； 4.oplog.rs的大小依赖于OS及文件系统，但可以使用--oplogSize选项自定义其大小 4.MongoDB的数据同步类型 1.第一是初始同步：又有2种方式 1.节点没有任何数据时 2.节点丢失副本复制历史 备注： 初始同步的步骤： 1.克隆所有数据库 2.应用数据集的所有改变：复制oplog并应用于本地 3.为所有collection构建索引 2.第二是复制 初始化后这个操作会一直持续的进行着,以保持各个secondary节点之间的数据同步。 注意： 当有从节点加入副本集时，最初会显示STARTUP，STARTUP表示在追赶主节点的数据，数据同步时就会显示SECONDARY状态 4.mongoDB的副本集实现1.相关命令 ~]# mongod -help Replication options:复制相关的选项，两种复制架构的通用选项 --oplogSize arg：自定义oplog的大小； Replica set options:副本集(复制集)相关选项 --replSet arg #副本集名称，至关重要决定着每个节点加入的是哪个副本集 --replIndexPrefetch arg #副本集的索引预取功能，可以使复制过程更高效 none:不开启预取索引 _id_only：只预取id的索引 all：预取所有索引 注意：预取操作只能定义在从节点上，主节点无意义! --enableMajorityReadConcern #mongo3.2引入的控制读策略 local,默认值。直接读取当前的MongoDB实例，但是可能会读到副本集中不一致的数据，甚至可能回滚 majority策略读取那些已经被副本集大多数成员所认可的数据，因此数据不可能被回滚 目前majority只被WiredTiger存储引擎所支持 读发生回滚，这个地方可能有不理解，为什么读操作会有回滚呢。其实在上面已经提到过了，如果设置成local，不能保证读到 的数据都已经被写入到replicate set的各个节点，有可能还只是在primary node上。primary node down重新上线后，就会发生roll back 2.修改配置文件，配置副本集 2.1.环境准备： 192.168.34.117 node01 192.168.34.118 node02 192.168.34.126 node03 并更新三台主机的hosts文件 ~]# vim /etc/hosts 192.168.34.117 node01 192.168.34.118 node02 192.168.34.126 node03 2.2.安装和准备配置文件 ~]# yum install mongodb-org -y ~]# mkdir /data/mongodb/data #数据目录 ~]# mkdir /data/mongodb/log #日志目录 ~]# chown -R mongod.mongod /data/mongodb/ #修改目录属主属组 2.3.启动mongodb ~]# mongod --dbpath /data/mongodb/data/ --logpath /data/mongodb/log/mongod.log --replSet=rs0 #在三台mongodb主机上启动，并指定副本集的名称为rs0 3.rs命令 &gt; rs.help() rs.status() #获取rs的副本集的状态信息 rs.initiate() #把当前副本集做初始化的 rs.initiate(cfg) #使用指定的cfg文件对当前副本集做初始化 rs.conf() #获取当前副本集的配置信息 rs.reconfig(cfg) #从cfg文件中重新配置副本集 rs.add(hostportstr) #添加主机的方式1：直接给IP地址 rs.add(membercfgobj) #添加方式2:即rs.status()中的me信息mbers信息 rs.addArb(hostportstr) #设置仲裁节点 rs.stepDown([stepdownSecs, catchUpSecs]) #强制主节点为从节点 rs.syncFrom(hostportstr) rs.freeze(secs) #冻结某个节点在一定时间不能选举为主节点 rs.remove(hostportstr) #移除节点 rs.slaveOk() #当从节点加入副本集时默认都是不允许查询的，只有在从节点执行此命令后才被允许查询； rs.printReplicationInfo() #查看当前从节点的oplog信息的 rs.printSlaveReplicationInfo() #在从节点上执行是否落后于主节点的信息 db.isMaster() #查看当前节点是否为主节点的命令 4.初始化副本集和添加副本集成员 4.1.初始化主节点 把192.168.34.118 node02这台主机当做主节点开始初始化 &gt; rs.initiate() #使用rs.initiate()命令初始化当前节点 { &quot;info2&quot; : &quot;no configuration specified. Using a default configuration for the set&quot;, &quot;me&quot; : &quot;node02:27017&quot;, &quot;ok&quot; : 1 } &gt; rs.status() { &quot;set&quot; : &quot;rs0&quot;, &quot;date&quot; : ISODate(&quot;2019-05-23T08:46:42.943Z&quot;), &quot;myState&quot; : 1, &quot;term&quot; : NumberLong(1), &quot;heartbeatIntervalMillis&quot; : NumberLong(2000), &quot;members&quot; : [ #显示当前副本集的所有成员信息 { &quot;_id&quot; : 0, #节点标识符 &quot;name&quot; : &quot;node02:27017&quot;,#节点名称 &quot;health&quot; : 1, #节点健康状态，0表示下线 &quot;state&quot; : 1, #节点的信息 &quot;stateStr&quot; : &quot;PRIMARY&quot;, #所处副本集的节点状态，主节点 &quot;uptime&quot; : 646, #运行时长 &quot;optime&quot; : { #最近一次oplog操作的时间戳 &quot;ts&quot; : Timestamp(1558601187, 1), &quot;t&quot; : NumberLong(1) }, &quot;optimeDate&quot; : ISODate(&quot;2019-05-23T08:46:27Z&quot;), &quot;infoMessage&quot; : &quot;could not find member to sync from&quot;, &quot;electionTime&quot; : Timestamp(1558601186, 2), &quot;electionDate&quot; : ISODate(&quot;2019-05-23T08:46:26Z&quot;), &quot;configVersion&quot; : 1, &quot;self&quot; : true #表示对当前节点来说是这个节点 } ], &quot;ok&quot; : 1 } 4.2.添加从节点 将192.168.34.117node01和192.168.34.126node03加入到当前副本集 rs0:PRIMARY&gt; rs.add(&quot;192.168.34.117&quot;) { &quot;ok&quot; : 1 } #返回信息即表示成功添加从节点，同样的方法将192.168.34.126加入副本集即可 登录到各个从节点查看副本集信息 rs0:SECONDARY&gt; rs.slaveOk() #从节点都是SECONDARY 执行rs.slaveOk()各个节点才允许数据查询 rs0:SECONDARY&gt; show dbs local 0.000GB testdb 0.000GB #可以看到主节点上的testdb库也自动同步过来了，这样就配置成功了 4.3.查看副本集信息 rs0:PRIMARY&gt; rs.conf() { &quot;_id&quot; : &quot;rs0&quot;, #当前副本集的名称 &quot;version&quot; : 3, #类似于DNS配置文件改变一次序号增加1 &quot;protocolVersion&quot; : NumberLong(1), &quot;members&quot; : [ { &quot;_id&quot; : 0, #这个成员在当前副本集的id号 &quot;host&quot; : &quot;node02:27017&quot;, #这个成员的主机名 &quot;arbiterOnly&quot; : false, #是否为仲裁节点 &quot;buildIndexes&quot; : true, # &quot;hidden&quot; : false, #是否为隐藏节点 &quot;priority&quot; : 1, #被选举时的优先级，默认都为1 &quot;tags&quot; : { #表示当前节点的用途信息的 }, &quot;slaveDelay&quot; : NumberLong(0), #是否为延迟复制节点 &quot;votes&quot; : 1 #是否拥有选票，0表示没有投票权 }, { &quot;_id&quot; : 1, &quot;host&quot; : &quot;192.168.34.117:27017&quot;, &quot;arbiterOnly&quot; : false, &quot;buildIndexes&quot; : true, &quot;hidden&quot; : false, &quot;priority&quot; : 1, &quot;tags&quot; : { }, &quot;slaveDelay&quot; : NumberLong(0), &quot;votes&quot; : 1 } 第二个从节点类似此处省略粘贴了......... ], &quot;settings&quot; : { &quot;chainingAllowed&quot; : true, #是否允许链接式复制功能 即一个从节点把它的主节点指为另外一个从节点 &quot;heartbeatIntervalMillis&quot; : 2000, # &quot;heartbeatTimeoutSecs&quot; : 10, #传递心跳信息的超时时间 &quot;electionTimeoutMillis&quot; : 10000, &quot;getLastErrorModes&quot; : { #获取错误信息的方式 }, &quot;getLastErrorDefaults&quot; : { #获取最新一次的错误信息 &quot;w&quot; : 1, &quot;wtimeout&quot; : 0 }, &quot;replicaSetId&quot; : ObjectId(&quot;5ce66853d4caa139c6fab211&quot;) } 修改配置信息 rs.conf()命令输出信息实际是保存在local库中的system.replset中的 5.主节点故障模拟 1.主节点上执行rs.stepDown() rs0:PRIMARY&gt; rs.stepDown() 2017-05-23T18:39:00.550+0800 I NETWORK [thread1] trying reconnect to 127.0.0.1:27017 (127.0.0.1) failed 2017-05-23T18:39:00.551+0800 I NETWORK [thread1] reconnect 127.0.0.1:27017 (127.0.0.1) ok 2.rs0:SECONDARY&gt; rs.status() #此时之前的主节点就变成了SECONDARY了 #粘贴信息省略，可以看到node02节点成了从节点，而node03变成了主节点 6.影响副本集重新选举的条件 1.心跳信息： rs.status()的health的值[0|1] 2.priority优先级： 即rs.conf()输出的priority值，默认都是1，0表示既能成为主节点也不能触发选举过程； 3.optime: 某成员节点最近一次应用于本地oplog条目的时间戳，必须与主节点最近一次更新的时间戳保持一致；即rs.status()的optime字段； rs0:PRIMARY&gt; db.printReplicationInfo() configured oplog size: 1000.7371091842651MB log length start to end: 3387secs (0.94hrs) oplog first event time: Thu May 23 2017 17:43:54 GMT+0800 (CST) oplog last event time: Thu May 23 2017 18:40:21 GMT+0800 (CST) now: Thu May 23 2017 18:44:58 GMT+0800 (CST) 4.网络连接： 一旦拥有多个节点的mongodb副本集出现了分区状况，为了保证选举过程是有效的，只有票数超过法定票数一半的一方才能选举出新的主节点； 5.网络分区： 和网络连接类似 7.触发选举的条件 1.新副本集初始化时，第一个初始化的节点自动成为主节点 2.all从节点联系不到主节点时 3.主节点down时 1.主节点执行rs.stepDown()命令时 2.某从节点有更改的优先级且已经满足成为主节点其他所有条件 3.主节点无法联系到副本集的&quot;多数方&quot;; 8.修改各节点的优先级,或者 由于当所有因素一样时，系统会随机选举一个节点为主节点，但可以人为修改某个节点的优先级priority,方法如下： 在主节点上执行： 1.rs0:PRIMARY&gt; cfg=rs.conf() #先保存原来的配置 2.rs0:PRIMARY&gt; cfg.members[0].priority=100 100 #然后设置成员id为0的优先级为100(范围是0-1000) 3.rs0:PRIMARY&gt; rs.reconfig(cfg) { &quot;ok&quot; : 1 } #表示重读配置文件成功 4.rs0:PRIMARY&gt; rs.conf() #再次执行rs.conf()可以看到members为0的节点的priority是100了 注意：当重读cfg文件之后，优先级高的节点会立刻成为主节点!!! 9.设置仲裁节点，两种方法 1.rs.addArb() 在添加新的节点时直接使用rs.addArb()命令设置该节点为仲裁节点 2.将已加入的节点移除之后再加入为仲裁节点 注意：mongodb是不允许设置已经同步完数据的节点为仲裁节点的 1.rs0:PRIMARY&gt; rs.remove(&quot;192.168.34.126:27017&quot;) { &quot;ok&quot; : 1 } 2.rs0:PRIMARY&gt; rs.addArb(&quot;192.168.34.126&quot;) { &quot;ok&quot; : 1 } 3.rs0:PRIMARY&gt; rs.status() { &quot;_id&quot; : 2, &quot;name&quot; : &quot;192.168.34.126:27017&quot;, &quot;stateStr&quot; : &quot;ARBITER&quot;, } #可以看到该节点被设置为了仲裁节点 10.MongoDB的同步延迟问题 在MongoDB的Replica Sets模式中,同步延迟也经常是困扰使用者的一个大问题； 1.什么是同步延迟？ 首先,要出现同步延迟,必然是在有数据同步的场合,在 MongoDB 中,有两种数据冗余方式,一种是Master-Slave 模式, 一种是Replica Sets模式。这两个模式本质上都是在一个节点上执行写操作, 另外的节点将主节点上的写操作 同步到自己这边再进行执行。在MongoDB中,所有写操作都会产生 oplog,oplog 是每修改一条数据都会生成一条,如果你采用一个批 量 update 命令更新了 N 多条数据, 那么抱歉,oplog 会有很多条,而不是一条。所以同步延迟就是写操作在主节点上执行完后, 从节点还没有把 oplog 拿过来再执行一次。而这个写操作的量越大,主节点与从节点的差别也就越大,同步延迟也就越大了。 2.同步延迟带来的问题 首先,同步操作通常有两个效果,一是读写分离,将读操作放到从节点上来执行,从而减少主节点的压力。对于大多数场景来说,读多写少 是基本特性,所以这一点是很有用的。另一个作用是数据备份, 同一个写操作除了在主节点执行之外,在从节点上也同样执行,这样我们 就有多份同样的数据,一旦 主节点的数据因为各种天灾人祸无法恢复的时候,我们至少还有从节点可以依赖。但是主从延迟问题可能会 对上面两个效果都产生不好的影响。 3.如果主从延迟过大,主节点上会有很多数据更改没有同步到从节点上。这时候如果主节点故障,就有 两种情况： 1.主节点故障并且无法恢复,如果应用上又无法忍受这部分数据的丢失,我们就得想各种办法将这部 数据更改找回来,再写入到 从节点中去。可以想象,即使是有可能,那这也绝对是一件非常恶心的活； 2.主节点能够恢复,但是需要花的时间比较长,这种情况如果应用能忍受,我们可以直接让从节点提 供服务,只是对用户来说, 有一段时间的数据丢失了,而如果应用不能接受数据的不一致,那么就只能下线整个业务,等主节点恢复后再提供服务了 最后： 1.如果你只有一个从节点,当主从延迟过大时,由于主节点只保存最近的一部分oplog,可能会导致从 节点青黄不接,不得不进行resync 操作, 全量从主节点同步数据。 2.带来的问题是：当从节点全量同步的时候,实际只有主节点保存了完整的数据,这时候如果主节点故障,很可能全 部数据都丢掉了 11.一些补充事项 10.1.mongodb3.0建议开启的设置 echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag 10.2.修改服务器hostname名 1.首先修改 secondary 服务器的 hostname;然后 stop secondary; 2.重启 secondary 以修改后的新hostname； 3.登录 primary ； 4.用rs.reconfig()命令修改 复制集的配置信息； &gt;conf=rs.conf() &gt;conf.members[x].host=&apos;new_address:27017&apos; &gt;rs.reconfig(conf); 10.3.Rollback mongodb只支持小于300M的数据量回滚，如果大于300M的数据需要回滚或要回滚的操作在30分钟以上，只能是手动去回滚。会在mongodb日志中报以下错误： [replica set sync] replSet syncThread: 13410 replSet too much data to roll back 经量避免让rollback发生。方法是：使用 复制的 写顾虑（Write Concern）规则来阻止回滚的发生。 如果发生了回滚操作，则会在mongodb数据文件目录下产生一个以database.collection.timestamp.bson的文件。查看该文件的内容用 bsondump 工具来查看。 5.MongoDB复制集常用监控工具复制集状态查询命令 1）复制集状态查询：rs.status() 2）查看oplog状态： rs.printReplicationInfo() 3）查看复制延迟： rs.printSlaveReplicationInfo() 4）查看服务状态详情: db.serverStatus()]]></content>
      <categories>
        <category>Nosql</category>
        <category>mongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB基础]]></title>
    <url>%2F2017%2F09%2F15%2FMongoDB%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[NoSQL简介 –nosql分片实现逻辑 NoSQL数据库管理系统：非关系模型、分布式、不支持ACID数据库设计范式 NoSQL特点： 1.简单数据模型：不像关系型数据拥有很多约束、范式 2.元数据和数据分离： 3.弱一致性：大多数nosql支持BASE理论，数据会达到最终一致性 4.高吞吐量： nosql设计时就是为了海量数据存取、并行高性能读写，因此吞吐量很高； 5.高水平扩展能力和低端硬件集群： nosql设计时就是可以运行在PC server(X86)中低端服务器上的； 总结： nosql不像mysql那样需要依靠外部的分片框架，而是设计时就已经内置了自动分片的功能来应对写操作请求过大的问题，而且分片的 方式和效用很强大，比如redis、mongoDB、HBase； NewSQL数据库管理系统： 1.因为关系型数据库在处理事务时对性能影响非常大，一般要优化的因素有很多，如节点间的通信、存储、日志(事务日志)、锁(事务是依靠锁实现的)、 缓冲区管理(一般事务功能为了能够实现，通常将数据组成固定大小的页缓存在内存中)等等； 2.为了上述问题，很多新式的数据库采用不同的设计方式，如：取消了缓冲池把数据直接运行在内存中、用并行模式的多线程使用同一个锁 使用冗余机器实现故障和恢复以代替单机加锁的故障恢复操作、等改变了传统关系型数据库固有性能的处理解决方案进而能够提升其性能的就称为NewSQL; 3.NewSQL在设计上就避免了非常容易出现性能瓶颈的问题，大大的打破了单机本身所容易出现的问题并且将运行机制扩展到多机系统上； MongoDB安装和使用mongoDB官网下载地址 MongoDB是一个易于扩展、高性能的、灵活schema、文档类型的nosql数据库； 1.MongoDB和Elasticsearch都属于NoSQL中的文档存储数据库，所谓文档存储指每一个文档不仅仅存储JSON Object数据还有数据本身的描述信息； 2.基于json格式实现数据存储和组织数据 3.性能高： 1.由C++研发 2.支持全面索引，在单个collection上支持多达64个索引 3.不支持事务，但是支持原子(atomic operations) 4.memory-mapped file使用内存映射文件，因此可以实现延迟写保持性能的强大 4.强大的扩展功能 replication:复制功能,已被mongoDB舍弃 auto-sharding: 内置的副本集复制功能，实现自动分片机制，而mysql需要借助分片框架机制； 5.查询语句也是基于文档方式 不像mysql使用select查询，而其查询语句是基于json格式的需要使用其内部特有的查询格式，这也是nosql有各自的查询接口的一个缺点； 6.Map/Reduce 支持map/reduce机制，支持映射以后做折叠，因此非常容易实现数据处理和聚合； 可以在all shards上基于map/reduce机制实现并行查询(parallel query) 7.GirdFS 为mongoDB的存储能力提供了GirdFS分布式文件系统，尤其是单个大文件的存储解决方案； 8.Geospatial indexing mongoDB支持二维空间索引,使用空间索引,也叫地理位置索引； 适用场景： mysql能支持的MongoDB也都支持，只不过MongoDB不支持跨表事务，除了事务MongoDB的性能是强于mysql的，但对于web应用来说大多数 场景都不会对事务有严格要求，因此这也是文档存储(如：mongodb)非常适用于web应用的原因； 1.websites：web站点 2.cache:缓存，不过一般用的不多，而使用列式存储或者K/V存储比较多 3.High volume,low value:较大数据量的场景 4.High scalability:对扩展性要求较高的场景 5.对数据存储本身的事务要求低，只要使用JSON格式存储数据的场景 6.mongoDB是用在大数据和海量存储场景使用的，适用于分布式场景存储数据的 不适用场景： 1.Highly transactional:对事务要求很高的场景 2.期望用SQL接口来实现数据操作的(因为不支持像mysql的) 应用程序结合mongoDB： 下文只是通过mongoDB的shell接口进行CRUD，事实上应用程序时通过mongoDB的API接口来实现； 如： php+mongoDB: php的mongoDB的扩展驱动，驱动里有编程调用接口API mongoDB安装： 1.直接使用编译好的版本即可； mongodb-org-server-3.0.15-1.el7.x86_64.rpm：服务器端包 mongodb-org-tools-3.0.15-1.el7.x86_64.rpm：工具包(备份、导入导出工具) mongodb-org-shell-3.0.15-1.el7.x86_64.rpm:客户端包 mongodb-org-mongos-3.0.15-1.el7.x86_64.rpm：在分片sharding时用到的包 #因为下载太慢了，这里使用阿里云的yum源或者二进制包安装 2.二进制包安装方式 1.安装 ~]# cd /usr/local/src/ src]# tar -zvxf mongodb-linux-x86_64-rhel62-3.4.4 src]# ln -s mongodb-linux-x86_64-rhel62-3.4.4 /usr/local/mongodb src]# cd /usr/local/mongodb #Mongodb主目录 mongodb]# ll 总用量 120 drwxr-xr-x. 2 root root 4096 6月 3 14:51 bin -rw-r--r--. 1 root root 34520 4月 21 06:19 GNU-AGPL-3.0 -rw-r--r--. 1 root root 16726 4月 21 06:19 MPL-2 -rw-r--r--. 1 root root 1359 4月 21 06:19 README -rw-r--r--. 1 root root 55625 4月 21 06:19 THIRD-PARTY-NOTICES mongodb]# mkdir /usr/local/mongodb/data #Mongodb数据目录，可以存放在一个独立的大分区上 mongodb]# mkdir /usr/local/mongodb/log #Mongodb日志目录 2.启动mongoDB 使用mongod命令建立一个mongodb数据库链接，端口号设置为10001，数据库的路径为/usr/local/mongodb/data， 日志路径为/usr/local/mongodb/log/mongo.log; mongodb的启动程序放在后台执行，下面命令执行后，按ctrl＋c mongodb]# nohup /usr/local/mongodb/bin/mongod --dbpath=/usr/local/mongodb/data/ --logpath=/usr/local/mongodb/log/mongo.log &amp; 3.yum安装方式： 1.配置阿里云yum源： ~]# cd /etc/yum.repos.d/ ~]# vim mongodb.repo [mongodb-org] name=MongoDB Repository baseurl=https://mirrors.aliyun.com/mongodb/yum/redhat/7Server/mongodb-org/3.2/x86_64/ gpgcheck=0 enabled=1 2.安装 ~]# yum install mongodb-org -y #安装时会默认把下面所有的包都安装 mongodb-org-mongos mongodb-org-server mongodb-org-shell mongodb-org-tools 3.创建mongodb的数据目录和日志目录 ~]# mkdir /data/mongodb/data #数据目录 ~]# mkdir /data/mongodb/log #日志目录 ~]# id mongod #mongoDB默认的运行用户 uid=997(mongod) gid=992(mongod) groups=992(mongod) ]# chown -R mongod.mongod /data/mongodb/ #修改目录属主属组都为mongod 4.修改配置文件 ~]# cat /etc/mongod.conf|grep -v &quot;#&quot;|grep -v &quot;^$&quot; systemLog: destination: file logAppend: true #是否支持附加追加日志 path: /data/mongodb/log/mongod.log #日志路径 storage: dbPath: /data/mongodb/data #mongoDB的数据目录，生产环境一定修改 journal: enabled: true processManagement: fork: true pidFilePath: /var/run/mongodb/mongod.pid #pid文件路径 processManagement: net: port: 27017 # bindIp: 127.0.0.1 #注释掉只监听在127.0.0.1，配置其可远程访问 5.启动： ~]# systemctl start mongod #启动 ~]# systemctl enable mongod #设置开机自启 ~]# ss -tnl LISTEN 0 128 *:27017 #mongoDB默认是监听在所有地址的27017端口上 MongoDB的CRUD使用1.连接mongodb ~]# mongo --help MongoDB shell version: 3.2.22 usage: mongo [options] [db address] [file names (ending in .js)] ~]# mongo --host 192.168.34.118 #直接进入到mongodb的shell接口 MongoDB shell version: 3.2.22 connecting to: 192.168.34.118:27017/test #默认连接的test库 2.MongoDB的认证功能 2.1.MongoDB默认是不认证的，默认没有账号，只要能连接上服务就可以对数据库进行各种操作，MongoDB认为安全最好的方法就是在一 个可信的环境中运行它，保证之后可信的机器才能访问它，可能这些对一些要求高的环境，安全还不够。 MongoDB提供用户认证，需要在启动时加上--auth开启认证； 3.mongodb的database： 1.和mysql一样支持多个database &gt; show dbs; local 0.000GB #默认有一个local库 2.无需创建库直接使用，而且是延迟创建的 只需要在这个库下创建一个collection就会自动创建出来这个库 4.常用命令 &gt; help show dbs #显示已存储的数据库名称 注意： 如果某个库的数据太小，用show dbs看到是0.000GB 这时可以use dbname,再使用db.stats(),就可以看到真实的大小了 show collections #显示某一库中的所有collections，类似于mysql中的表 和db.getCollectionNames()显示的一样 show users #启用认证功能时可以查看已有用户信息 show profile #显示性能评估探测工具 show logs #显示日志文件 use &lt;db_name&gt; #切换当前数据库 db.foo.find() db.foo.find( { a : 1 } ) #这两个都是json格式的查询接口 #####################和数据库相关的命令####################### db.help() #数据库的帮助信息，有很多子项 db.auth(username, password) #设置认证信息的 db.dropDatabase() #删除数据库 db.logout() #登出数据库 db.stats() #显示当前库的状态和信息的 db.version() #显示mongodb的版本号 db.serverStatus() #显示服务器级别的各种信息，和zabbix监控相关 db.getCollectionNames() #显示当前库的所有collections的列表 [] #中括号表示当前库没有collections 等等 db.mycoll.help() #和collection相关的所有命令 db.mycoll.insert(obj) #创建一个collection并插入数据 db.collection.stats() #显示这个collection的统计数据 db.mycoll.find(...) #查询一个collection的信息 db.mycoll.dataSize() #统计一个collection的数据大小 db.mycoll.drop() #删除一个collection，而不是中的数据 db.mycoll.remove(query) #删除collection的一行或多行的数据 db.mycoll.update #更新collection的一个数据 db.mycoll.update( query, object[ multi_bool] ) #更新所有符合条件的行 db.mycoll.dropIndexes() #删除索引 sh.help() #和shard分片集群的命令集 rs.help() #副本集replica Set相关的命令集 help admin # help connect # help keys # help misc # help mr # 5.MongoDB的Documents 1.mongodb是一个json风格的键值对文档存储Documents,它其实是BSON格式的，但可以理解为JSON，格式为： { name: &quot;Liming&quot; age: &quot;20&quot; status: &quot;A&quot; groups: [&quot;news&quot;,&quot;sports&quot;] } 对于文档来说，每一对键值对称为一个域filed; 2.mongoDB为了能够追踪每一个文档，mongodb会为每一个文档都生成一个隐藏的_id字段，它相当于mysql表的主键(primary key); 6.MongoDB的Collections 1.mongoDB stores all documents in collections 相似的文档放在一起称为collections，它就是一组具有类似相关联的文档的集合，它们可以构建索引，它就是关系型数据库中的表； 7.什么是JSON？ JSON：JavaScript Object Notation 是一种轻量级的数据交换格式，也被称为轻量级的XML扩展标记语言，易于阅读和编写 它是基于JavaScript编程语言的第三版的子集采用了完全独立于语言的文本格式，它通常被构建成两种结构： 1.名称/值对象的集合：也就是一些键值对的集合 2.值的有序列表：类似于数组的概念，用[]来书写 如:[&quot;a&quot;,&quot;b&quot;],可以通过下标来引用其值 8.CRUD操作(在mysql中称为DDL和DML操作) C：create database 1.在mongodb这无需创建、直接use &lt;dbname&gt;即可，而且是延迟创建的，只需要在这个库的某一个collection上插入数据，这个库就会自动创建的； 2.而且collection也无需手动实现，因为它是scheme-free(表示没有任何需要提前定义的字段，不像mysql)，因此直接使用即可； 3.Create的基本命令 db.mycollName.insert({key1:value1,key2:{key21:value21}}) 4.示例 如：&gt; use test #切换到test库 &gt; db.users.insert({name:&quot;tom&quot;,age:&quot;18&quot;}) WriteResult({ &quot;nInserted&quot; : 1 }) #向名为users的collection中插入数据就会自动创建collection &gt; show collections; users #使用show可以看到创建好的所有collection了 &gt; db.users.stats() { &quot;ns&quot; : &quot;test.users&quot;, &quot;count&quot; : 1, #1行数据 &quot;size&quot; : 48, &quot;avgObjSize&quot; : 48, &quot;storageSize&quot; : 4096, &quot;capped&quot; : false, nindexes&quot; : 1, &quot;totalIndexSize&quot; : 4096, &quot;indexSizes&quot; : { &quot;_id_&quot; : 4096 } #查看users这个collection的状态 &gt; show dbs; local 0.000GB test 0.000GB #可以看出db无需创建、创建一个collection就会自动创建db了 &gt; db.users.insert({name:&quot;lili&quot;,age:&quot;20&quot;,gender:&quot;M&quot;}) WriteResult({ &quot;nInserted&quot; : 1 }) #再插入一行数据 &gt; db.users.stats() { &quot;ns&quot; : &quot;test.users&quot;, &quot;count&quot; : 2, #2行数据 &quot;size&quot; : 111, &quot;avgObjSize&quot; : 55, &quot;storageSize&quot; : 4096, &quot;capped&quot; : false, } #此时就有两行数据了 R:mysql中叫做read,mongo中称为find操作 Query操作：(query,fileds,limit,skip,sort) db.mycoll.find() #下文有find的高级使用方法 db.mycoll.find(...).count() #只统计符合条件的行 db.mycoll.find(...).limit(n) #只显示符合条件的多少行 db.mycoll.find(...).skip(n) #跳过符合条件的前多少行 db.mycoll.find(...).sort(...) #根据指定字段进行排序 db.mycoll.findOne() #只返回第一个值 如： &gt; db.users.find() { &quot;_id&quot; : ObjectId(&quot;5cd01acc164a7478c7e12725&quot;), &quot;name&quot; : &quot;tom&quot;, &quot;age&quot; : &quot;18&quot; } { &quot;_id&quot; : ObjectId(&quot;5cd029d2164a7478c7e12727&quot;), &quot;name&quot; : &quot;lili&quot;, &quot;age&quot; : &quot;20&quot;, &quot;gender&quot; : &quot;M&quot; } #直接查询某个collection中插入的所有数据内容 而且ObjectId是自动生成的16进制数据 &gt; db.users.count() 2 #统计users这个collection中有多少documents &gt; db.users.find({age: {$in: [20,40]}}).count() 0 #统计符合age在20~40之间的所有行 &gt; db.users.find({age: {$in: [20,40]}}).limit(2) #只显示符合age在20~40之间的2行数据 &gt; db.users.find({age: {$in: [20,40]}}).skip(1) #跳过符合age在20~40之间的第一行显示其他行数据 &gt; db.users.dataSize() 111 #显示users这个collection的数据大小 find()的高级操作 1.比较操作： $gt：大于，语法格式 {filed:{$gt:VALUE}} 示：&gt; db.users.find({age:{$gt: 30}}) $gte:大于等于 $lt：小于 $lte：小于等于 $ne:不等于 $in:在制定列表中的 语法格式{filed：{$in: [&lt;value&gt;]}} $nin：不在指定列表中的 2.组合条件：逻辑运算 $or:或运算，语法格式{$or: [{&lt;expressions&gt;}...]} 示： &gt; db.users.find({$or: [{age: {$in: [20,40]}},{age:{$nin: [20,40]}}]}) $and:与运算 $not:非运算 $nor:反运算，返回不符合指定条件的所有文档 3.元素查询 根据文档中是否存在指定的字段进行的查询 $exists:存在，语法格式{$filed:{$exists:&lt;boolean&gt;}},0、1或者true 示例： &gt; db.users.find({gender:{$exists:0}}) &gt; db.users.find({gender:{$exists:false}}) #表示返回users中没有gender字段的所有文档，两者均可 $mod:取模运算 $type:返回指定字段的值的类型为自定义类型的文档， 语法格式{filed:{$type:&lt;BSON type&gt;}} BSON type有： 1 Double,2 String,3 Object,Array,Binary data,Undefined Boolean,Date,Null,Regular Expression,JavaScript Timestamp 注意：每一种类型都有一个编号，编程需要 U：修改更新操作 db.mycoll.update #默认只更新第一个符合条件的行 db.mycoll.update( query, object[ multi_bool] ) #更新所有符合条件的行 $set:修改字段的值为新指定的值， 语法格式({filed:value},{$set: {filed:new_value}}) $unset：删除指定字段 语法格式({filed:value},{$unset:{filed1,filed2,...}}) $rename:更新字段名 语法格式({$rename:{oldname:newname}}) 示例： &gt; db.users.update({name:&quot;tom&quot;},{$set: {age:21}}) #将name=tom的行的age改为21 D：Delete删除操作 db.mycoll.remove(&lt;query&gt;,&lt;justOne&gt;) #删除collection的一行或多行的数据 #在老版本里是使用的delete命令 db.mycollName.drop() #删除一个collection，而不是中的数据 #注意：需要先切换至到数据库中 db.dropDatabase() #切换到某个库后再删除这个库，无法恢复，慎用 示例： &gt; db.users.remove({age:21}) #删除users中age=21的所有行的文档 &gt; use test #切换到这个库 &gt; db.students.drop() #删除students这个collection]]></content>
      <categories>
        <category>Nosql</category>
        <category>mongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主从复制]]></title>
    <url>%2F2017%2F08%2F12%2Fmysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[MySQL的主从复制 mysql的主从复制是基于二进制日志实现的 MySQL的扩展 读写分离 复制：每个节点都有相同的数据集 向外扩展 二进制日志 单向:复制是单向进行的 复制的功用： 数据分布：一个数据可以存多份保证数据冗余 负载均衡读：对读请求有负载均衡效果 备份：主节点故障，从节点可以立即提升为主节点对外提供服务； 高可用和故障切换：MHA MySQL升级测试 可以先把从数据库下线，升级到5.5--&gt;10.2版本，然后再上线，测试没问题后，再逐步升级其他的数据库 mysql主从复制原理–mysql主从复制原理 主从复制集群当中，无论从节点有多少个，都只能分散用户读取数据的压力，但对写入数据没有任何分散/负载均衡的能力； MySQL主从复制过程： MySQL主从同步一共需要三个线程的操作，主MySQL有一个dump Thread线程，从MySQL有一个I/O Thread线程和一个 SQL Thread线程， MySQL主从是实现MySQL高可用、数据备份、读写分离架构的一种最常见的解决方案，在绝大部分公司都有 使用，要实现MySQL主从复制，必须要在Master打开binary log(bin-log)功能，因为整个MySQL的复制过程实际就是 Slave从Master端获取响应的二进制日志，然后在Slave端顺序的执行日志中所记录的各种操作，二进制日志中几乎记录了出 select以外的所有针对数据库的sql操作语句，具体的复制过程如下： 1.Slave端启动一个专门的I/O Thread线程，把自己当做是mysql的客户端通过mysql协议向mysql服务器端请求读取对方二进制 日志中的事件，mysql服务器端会接收到从节点请求二进制日志的位置position,然后从自己的二进制日志的请求位置处发送给从 节点(新部署的Master和Slave从最开始的日志)； 2.Master接收到来自Slave的I/O Thread线程请求，dump Thread线程会根据Slave的请求信息读取相应的日志内容，然后将本 地读取的bin-log的文件名、位置及指定位置之后的内容一起返回给Slave的I/O Thread线程处理； 3.Slave的I/O Thread线程将接收到的信息依次添加到Slave端的relay-log文件的最末端，并将读取到的Master端的bin-log的 文件名和位置记录到Master-info文件中，以便在下一次读取的时候能够清楚的告诉Master&quot;我需要从哪个bin-log的哪个位置开 始往后的日志内容请发给我&quot;;当下次再向主节点请求时，就会从记录之后的位置开始请求，以此类推... 4.Slave的SQL Thread线程检查到relay-log中新增了内容后，会马上将relay-log中的内容解析为在Master端真实执行时候的 可执行命令，并顺序执行，从而保证对Slave的MySQL进行响应的增加或删除等操作，最终实现和Master数据保持一致; 主从复制线程： 主节点： dump Thread： 为每个Slave的I/O Thread启动一个dump线程，用于向其发送binary log events; 从节点： I/O Thread：向Master请求二进制日志事件，并保存于中继日志中 SQL Thread：从中继日志中读取日志事件，在本地完成重放 跟复制功能相关的文件： master.info： 用于保存slave连接至master时的相关信息，例如账号、密码、服务器地址等 relay-log.info： 保存在当前slave节点上已经复制的当前二进制日志和本地 replay log日志的对应关系 主从复制特点： 异步复制: mysql的主从复制是异步的，异步意味着主节点在修改完以后在本地存储结束后就返回客户端说是结束了，它是不管有没 有从节点复制以及复制了哪些数据，即使从节点复制失败主节点也是不关心的； 优点是：性能好 缺点：从节点有可能未能执行成功,从节点数据会落后主节点数据；而且这个落后是必然的，因为需要网络复制、本地加载到内存再到磁盘的过程等等； 主从数据不一致比较常见 复制架构： Master/Slave, Master/Master, 环状复制 一主多从 从服务器还可以再有从服务器 一从多主:适用于多个不同数据库 复制需要考虑二进制日志事件记录格式 STATEMENT（5.0之前） ROW（5.1之后，推荐） MIXED mysql主从配置解析主从配置过程：参看官网 https://mariadb.com/kb/en/library/setting-up-replication/ https://dev.mysql.com/doc/refman/5.5/en/replication-configuration.html 主节点配置： (1) 启用二进制日志 [mysqld] log_bin (2) 为当前节点设置一个全局惟一的ID号 [mysqld] server_id=# log-basename=master 可选项，设置datadir中日志名称，确保不依赖主机名 (3) 创建有复制权限的用户账号 GRANT REPLICATION SLAVE ON *.* TO &apos;repluser&apos;@&apos;HOST&apos; IDENTIFIED BY &apos;replpass&apos;; 从节点配置： (1) 启动中继日志 [mysqld] server_id=# 为当前节点设置一个全局惟的ID号 read_only=ON 设置数据库只读 relay_log=relay-log #relay log的文件路径，默认值hostname-relay-bin relay_log_index=relay-log.index #默认值hostname-relay-bin.index (2) 使用有复制权限的用户账号连接至主服务器，并启动复制线程 mysql&gt; CHANGE MASTER TO MASTER_HOST=&apos;host&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;replpass&apos;, MASTER_LOG_FILE=&apos; mariadb-bin.xxxxxx&apos;, MASTER_LOG_POS=#; 备注： 详见help change master to, 只需要主节点账户、密码、复制账号、从哪个二进制日志复制、二进制日志复制的位置、其他信息(relay-log、ssl默认即可)； mysql&gt; START SLAVE [IO_THREAD|SQL_THREAD]; 注意： 1.如果主从节点都是全新的，在确定还没写入过业务数据之后，即使通过show master logs;可以看到很多二进制日志 ，因为前面的二进制日志记录的可能是初始化的信息，在从库上即使不同步也都有这些信息，所以只需要用从最后一个开始复制即可； 2.或者在做准备做主从复制时，重启mysql(自动滚动二进制文件)，随即主节点的操作从这个二进制日志开始复制即可； 示例：实现一主一从数据库主节点： 1.配置文件中前两项是必须要加的项： server-id=1 log_bin(主必须启用二进制日志) binlog_format=row(建议加) 2.查看当前二进制日志： show master logs; 记录当前二进制日志的位置，以便从当前位置进行复制测试 3.创建一个复制权限的用户： grant replication slave on *.* to repluser@&apos;192.168.34.%&apos; identified by &apos;root123&apos;; 4.先在主节点上导入一个数据库，一会做测试 mysql -S /var/lib/mysql/mysql.sock &lt; hellodb_innodb.sql 5.查看复制的线程是否启动： show processlist; 没复制是复制和监控线程是没启动的 从节点： 1.配置文件中必须加的两项： read-only server-id=2 2.设置change master to (help change master to可以查看帮助) CHANGE MASTER TO MASTER_HOST=&apos;192.168.34.103&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;root123&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;mysql-bin.000004&apos;, MASTER_LOG_POS=245; 修改change mater to的主服务器，复制用户，密码，从二进制日志的哪个位置开始复制 3.执行完之后，可以通过 show salve status\G; 也就是执行上面的change master to的结果 （在没执行change master to，之前查询的是空的） MariaDB [(none)]&gt; show slave status\G; ************************ 1. row ********************** Slave_IO_State: Master_Host: 192.168.34.103 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000004 #从master的哪个二进制文件复制的 Read_Master_Log_Pos: 245 #master的二进制的位置 Relay_Log_File: mariadb-relay-bin.000001 #保存在哪个relay文件 Relay_Log_Pos: 4 #保存的relay-log的位置 Relay_Master_Log_File: mysql-bin.000004 #当前relay-log文件 Slave_IO_Running: No #表示复制线程是否开启了 Slave_SQL_Running: No 这两项表示复制线程还没启动 Seconds_Behind_Master: NULL ---复制延迟时长 Master_SSL_Verify_Server_Cert: No Seconds_Behind_Master: NULL 显示主从服务器之间的延迟时间 时间越长，主从之间差别越大 4.启动复制线程 mysql&gt; start slave; #同时启动从节点上的 io_thread和sql_thread #选项有IO_THREAD | SQL_THREAD 5.启动复制线程后 a.在主数据库上show processlist; 可以看到I/O thread和dump线程一直监控数据库是否有新的变化 b.从上show slave status;看到两个线程是YES状态,且二进制日志的位置也和 主上的是同步的 6.而且在从节点的数据目录(默认是/var/lib/mysql/下)生成一个master.info文件 该文件记录的是show slave status的信息 验证： 1.从数据库服务器down机后，在主服务器上创建数据库，重启从服务器后， 只要数据库是启动的，新的数据就会自动同步到从服务器上 2.主数据库down机后，再重启主服务器，从服务器的复制线程会尝试连接主服务器后， 主从复制的线程会恢复，数据可以正常同步 注意： 1.在做主从之前，一定要先记录主数据库的二进制日志的位置，确保复制的数据是完整的 2.虽然主从复制架构已经搭建好了，但是要注意从节点一定不能执行写入操作，因为从节点的数据是不会同步给主节点的， 这样就造成主从数据不一致了； 3.除了上面的一些简单配置，还有一些需要注意的配置项来确保主从架构是安全的 Mysql主从复制复制架构中应该注意的问题：1.限制从服务器为只读 1.在从服务器上设置写在my.cnf配置文件中 read_only=ON 注意：此限制对拥有SUPER权限的用户均无效 2.阻止所有用户, 包括主服务器复制的更新 mysql&gt; FLUSH TABLES WITH READ LOCK; #为了不让从节点出现写操作，可以在从节点终端上开启全局读锁，这样就可以确保从节点不会被执行写操作了； #而且sql thread线程不会被此语句阻塞因为它不是通过线程连接进来执行写操作的； 2.如何保证主从复制的事务安全？ 1.当主节点在执行提交事务操作时，是需要立即同步到磁盘上以保证持久性的；但是事务提交操作也是会被写到二进制日志 中的，而二进制日志为了加速其写操作也是需要先保存在内存中做缓冲的，再写到二进制日志中的； 2.当主节点down了之后，主节点是保存了提交的事务信息了，但是在事务写到二进制日志中的事务就丢失了，这就意味着从 节点是没收到事务提交的，主从数据不一致； 3.所以为了避免上述问题的发生，使得主节点提交事务时，从节点能够尽快尽早的得到于事务相关的语句(至少能够保存在 主节点的二进制日志中)，这样才能保证从节点上也能得到完整的事务； 4.所以有以下参数来确保事务安全： 参看https://mariadb.com/kb/en/library/server-system-variables/ 在master节点启用参数： sync_binlog=1 每次写后立即同步二进制日志到磁盘，性能差 而且现在都是用InnoDB存储引擎： innodb_flush_log_at_trx_commit=ON #在事务提交时要将内存中和事务相关的数据立即写到事务日志当中 innodb_support_xa=ON #默认值，分布式事务MariaDB10.3.0废除 sync_master_info=0|1 #有必要时设置 #每一次给从节点dump一些event之后本地的master-info信息会不会立即同步到磁盘上然后让从节点能够获取到 #就是为了从节点的master-info信息能够及时更新的 在slave节点启用服务器选项： skip_slave_start=ON #从节点启动时不自动启动复制线程(为了数据安全需要检查后手动启动) 在slave节点启用参数： sync_relay_log=0|1 #因为relay-log也是先写到内存中的然后再写入relay-log当中的 #为1时数据安全性提升了，性能下降了增加磁盘IO sync_relay_log_info=# #次事务后同步relay-log.info到磁盘 #本地保存sql thread重放的位置和信息 2.RESET SLAVE 在从服务器清除master.info ，relay-log.info, relay log ，开始新的relay log ,注意：需要先STOP SLAVE RESET SLAVE ALL 清除所有从服务器上设置的主服务器同步信息如： PORT, HOST, USER和 PASSWORD 等 3、sql_slave_skip_counter = N 从服务器忽略几个主服务器的复制事件，global变量 实现一主多从：(在已有的主从复制数据库上，再添加新的从数据库)需求：生产环境下，当前的主从数据库性能达不到了，需要再加一个从节点 思路： 1.通过备份恢复数据至从服务器,(此时记录二进制日志位置) 2.复制起始位置为备份时二进制日志文件名称和其位置positon; 第二个从节点: 1.修改配置文件： read-only server-id=3 2.将之前已经正在运行的主从数据库，先进行数据库备份 mysqldump -A -F --single-transaction --master-data=1 &gt; /data/all_back.sql #此处不要--master-data=2，而是1是因为我们需要这个CHANGE MASTER TO的信息的，只不过这个信息缺失了一部分，需要加上下面这些参数就可以了； 3.将备份完的完整数据库拷贝到新的节点 打开all_bask.sql，在原有的change master to中加入主节点的信息； 当然也可以先导入数据库，再执行这一段 vim all_back.sql MASTER_HOST=&apos;192.168.34.103&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;root123&apos;, MASTER_PORT=3306, 4.导入数据库 mysql &lt; all_back.sql 5.启动复制线程 start slave; 注意：因为根据生产需求，这个从服务器是后来添加的，所以最好的办法就是把主服务器的 数据库全部备份一遍再导入到从节点的数据库，备份的数据库中记录了全部的数据库信息 只需要把change master to设置准确就行了，再启动复制线程 start slave;]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP和PXE]]></title>
    <url>%2F2017%2F07%2F06%2FDHCP%E5%92%8CPXE%2F</url>
    <content type="text"><![CDATA[PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobblercobbler实现系统自动化安装cobbler自动化系统安装 DHCP服务&amp;PXE自动化安装系统DHCP服务:(著名的Inter系统协会组织：研发的DHCP和DNS技术)DHCP官方文档：DHCP文档BIND官网文档：BIND文档DNS搭建的相关文档:DNS原理解析&amp;搭建 PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobblercobbler实现系统自动化安装cobbler自动化系统安装 全文只有二个实验：搭建DHCP和在centos7实现基于PXE安装centos7和centos6(centos6上原理类似) 搭建DHCP服务器：基于UDP协议(dhcp服务器端口：67、dhcp客户端端口：68)DHCP: （Dynamic Host Configuration Protocol） 动态主机配置协议 局域网协议，UDP协议(67端口) 主要用途： 用于内部网络和网络服务供应商自动分配IP地址给用户 用于内部网络管理员作为对所有电脑作集中管理的手段 使用场景 自动化安装系统 解决IPV4资源不足问题 DHCP申请网络地址是通过四个过程实现的：四个数据报文DHCP共有八种报文 1.DHCP DISCOVER：客户端到服务器 2.DHCP OFFER ：服务器到客户端 3.DHCP REQUEST：客户端到服务器 4.DHCP ACK ：服务器到客户端 DHCP NAK：服务器到客户端,通知用户无法分配合适的IP 地址 DHCP DECLINE ：客户端到服务器，指示地址已被使用 DHCP RELEASE：客户端到服务器，放弃网络地址和取消 剩余的租约时间 DHCP INFORM：客户端到服务器, 客户端如果需要从DHCP 服务器端获取更为详细的配置信息，则发送Inform报文向 服务器进行请求，极少用到 同网段多DHCP服务 DHCP服务必须基于本地 先到先得的原则 跨网段 RFC 1542 Compliant Routers dhcrelay: 中继 相关协议 Arp rarp DHCP服务器的实现方式：搭建DHCP服务器Linux DHCP协议的实现程序：dhcp, dnsmasq（dhcp,dns） 1.实现DHCP的软件有两个：dnsmasp,这个软件是安装系统是默认的一个 可以同时提供dns和dhcp两种服务，不是很专业 如：ss -ntl 看到的默认就有dnsmasp服务 LISTEN 0 5 192.168.122.1:53 users:((&quot;dnsmasq&quot;,pid=1506,fd=6)) 2.DHCP更专业：下面主要介绍 实验：DHCP服务的搭建实验前提： 1.把vmware虚拟机的主机都设置成仅主机模式，要不然会影响所在的 工作中的DHCP服务器，其他人可能会获取到实验配置的DHCP服务 获取到一个不能上网的IP地址 2.编辑vmware的虚拟网络编辑器，将仅主机的DHCP服务关闭，这样当前 就只有自己配置的DHCP服务器了 Dhcp Server相关配置文件： /etc/dhcp/dhcpd.conf ---&gt;主要配置文件 /usr/lib/systemd/system/dhcpd.service ---&gt;服务名 /usr/sbin/dhcpd ---&gt;dhcp的主程序 /etc/dhcp/dhcpd.conf --&gt; /etc/rc.d/init.d/dhcpd /etc/dhcp/dhcpd6.conf--&gt; /etc/rc.d/init.d/dhcpd6 /var/lib/dhcpd/dhcpd.leases ---&gt;租出去的地址信息库文件 /usr/sbin/dhcrelay /etc/rc.d/init.d/dhcrelay dhcp server:67/udp dhcp client: 68/udp dhcpv6 client:546/udp Dhcp client dhclient 自动获取的IP信息： /var/lib/dhclient dhcp.conf配置文件内容设置：安装DHCP完,默认是启动不了的，因为配置文件dhcpd.conf是空的 1.先通过模板生成新的配置文件 cp /usr/share/doc/dhcp*/dhcpd.conf.example /etc/dhcp/dhcpd.conf 2.模板里的网段地址不对，需要修改，网段和IP范围 question：那么如何修改dhcd.conf配置文件？ answer：根据上面的模板文件中的信息自改自定义的一些值 该文件中定义了： 1.默认续租时间和最长租期 2.DHCP默认分配的网段和分配的IP地址范围 3.DHCP服务提供的默认网关地址和DNS地址 3.前两项设置其他主机只是通过DHCP自动获取地址的需求，如果通过dhcp实现系统的 自动化安装，就不仅仅获取到地址，还需要从DHCP获取能启动计算机的文件，即 dhcp的配置文件中要有配置的地址：类似于grub的文件 其它配置选项： filename: 指明引导文件名称 next-server：提供引导文件的服务器IP地址 示例： filename &quot;pxelinux.0&quot;; next-server 192.168.100.100; 网络中下载文件的主机地址，带有tftp功能 备注：如果网卡有pxe的功能即自带tftp的功能 所以具有完整的功能的dhcp配置文件dhcp.conf内容类似； default-lease-time 600; max-lease-time 7200; subnet 192.168.34.0 netmask 255.255.255.0 { range 192.168.34.20 192.168.34.100; option routers 192.168.34.1; option domain-name-servers 6.6.6.6; ext-server 192.168.34.103; filename &quot;pxelinux.0&quot;; PXE安装相关的配置 } 上面是主要配置内容，在dhcpd.conf中还可以把指定的mac地址与IP绑定 host passacaglia { hardware ethernet 00:0c:29:af:45:f7; fixed-address 192.168.34.80 } 安装tftp服务:(UDP协议：69端口) yum install tftp-server -y [root@node7-1 tftpboot]#rpm -ql tftp-server /etc/xinetd.d/tftp /usr/lib/systemd/system/tftp.service /usr/lib/systemd/system/tftp.socket /usr/sbin/in.tftpd /var/lib/tftpboot 存放下载上传的路径:系统所需要的文件 centos7和centos6上安装tftp是由区别的 centos7上需要安装tftp-server服务--&gt;UDP69端口 yum install tftp-server systemctl start tftp 在centos6上安装和telnet是一个道理，都依赖于xinetd chkconfig tftp on--&gt; /etc/xinetd.d/tftp配置文件 service restart xinted PXE介绍PXE： Preboot Excution Environment 预启动执行环境 Intel公司研发 基于Client/Server的网络模式，支持远程主机通过网络从远端服务器下载 映像，并由此支持通过网络启动操作系统 PXE可以引导和安装Windows,linux等多种操作系统 实验：在centos7实现基于PXE安装centos7和centos6自动化安装步骤： 1.安装前准备：关闭防火墙和SELINUX，DHCP服务器静态IP 2.安装软件包 httpd tftp-server dhcp syslinux system-config-kickstart httpd:实现yum源 tftp-server：实现网络下载的文件 syslinux: 准备pxelinux.0文件 备注：centos6上是安装syslinux-nonlinux system-config-kickstart制作kickstart软件，建议自己制作 3.配置文件共享服务： 准备centos7&amp;centos6的yum源 systemctl enable httpd systemctl start httpd mkdir -pv /var/www/html/centos/{6,7}/os/x86_64 mount /dev/sr0 /var/www/html/centos/7/os/x86_64 mount /dev/sr1 /var/www/html/centos/6/os/x86_64 4.准备kickstart文件 拷贝已经安装机器上的anaconda文件，按照自定义稍微修改，放到http目录下 注意：644权限 cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg ks应答文件的内容可以用system-config-kickstart或者anaconda修改就行了 最好是通过system-config-kickstart做一个应答文件，通过界面更深刻理解 每一项代表的意义 大概内容如下：(最后附件的有详细的ks文件内容) url --url=http://192.168.34.7/centos/7/os/x86_64/ text firewall --disabled selinux --disabled clearpart --all --initlabel zerombr reboot %packages @core %end 5.配置tftp服务 systemctl enable tftp.socket systemctl start tftp.socket 6.配置DHCP服务 cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcpd/dhcpd.conf vim /etc/dhcp/dhcpd.conf option domain-name &quot;example.com&quot;; default-lease-time 600; max-lease-time 7200; subnet 192.168.34.0 netmask 255.255.255.0 { range 192.168.34.20 192.168.34.100; option routers 192.168.34.1; option domain-name-servers 6.6.6.6; next-server 192.168.34.103; filename &quot;pxelinux.0&quot;; } systemctl enable dhcpd systemctl start dhcpd 7.准备PXE相关文件 放pxelinux.0的专用目录，启动菜单 mkdir /var/lib/tftpboot/pxelinux.cfg/ 分别存放6和7的vmliuz和initrd.img文件 mkdir linux{6,7} 拷贝6和7安装必要文件 cp /var/www/html/centos/6/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/linux6/ cp /var/www/html/centos/7/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/linux7/ cp /usr/share/syslinux/{pxelinux.0,menu.c32} /var/lib/tftpboot/ 将光盘里的启动菜单拷贝到并改名为default cp /var/www/html/centos/7/os/x86_64/isolinux.cfg /var/lib/tftpboot/ pxelinux.cfg/default 拷贝完所有文件,文件列表如下： /var/lib/tftpboot/ . ├── linux6 │ ├── initrd.img │ └── vmlinuz ├── linux7 │ ├── initrd.img │ └── vmlinuz ├── menu.c32 ├── pxelinux.0 └── pxelinux.cfg └── default 8.准备启动菜单 菜单项可以自定义多个，如只有mini7和mini6的，还有必须要有本地硬盘启动的菜单项 但是要在文件内把各个的linuz和initrd路径 vim /var/lib/tftpboot/pxelinux.cfg/default default menu.c32 timeout 100 menu title PXE Install CentOS label mini7 menu label ^Auto Install Mini CentOS 7 kernel linux7/vmlinuz append initrd=linux7/initrd.img ks=http://192.168.34.7/ksdir/ks7-mini.cfg label mini6 menu label ^Auto Install Mini CentOS 6 kernel linux6/vmlinuz append initrd=linux6/initrd.img ks=http://192.168.34.7/ksdir/ks6-mini.cfg label local menu default menu label Boot from ^local drive localboot 0xffff. 9.准备完所有的文件和软件后，启动所有的服务，就可以测试PXE安装了。 附带centos7和centos6的ks应答文件模板：建议通过ystem-config-kickstart做一个应答文件，通过界面更深刻理解每一项代表的意义，当然也可以修改anaconda-ks.cfg文件ks6-mini.cfginstall url --url=http://192.168.34.103/centos/6/os/x86_64/ #httpd的yum源路径 lang en_US.UTF-8 keyboard us text #纯文本安装 reboot #安装完重启 network --onboot yes --device eth0 --bootproto dhcp --noipv6 rootpw --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt JjA57WrZO0 firewall --service=ssh 关闭防火墙 authconfig --enableshadow --passalgo=sha512 selinux --enforcing 关闭selinux timezone Asia/Shanghai 时区信息 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work clearpart --all 清空分区信息 zerombr 清空mbr #自定义的分区信息 part /boot --fstype=ext4 --size=1024 part / --fstype=ext4 --size=50000 part /data --fstype=ext4 --size=30000 part swap --size=2048 #自定义的分区信息 %packages @core %end 只安装最基本的核心包，后面也可以加上安装后脚本 ks7-mini.cfg：类似centos6的只是稍微的区别auth --enableshadow --passalgo=sha512 url --url=http://192.168.34.103/centos/7/os/x86_64/ text firstboot --enable ignoredisk --only-use=sda keyboard --vckeymap=us --xlayouts=&apos;us&apos; lang en_US.UTF-8 network --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --activate network --hostname=centos7.localdomain rootpw --iscrypted $6$j2QVLmDO2xasQEW0$xEvr1jyj1mHs0HBtCc7jD73r6u4NrQCxwVoAu.SMXhwm8GiKBHq5ETZ2zFxP4rFsNavYbG0u6Gq13 Igxrn1Ry. firewall --disabled selinux --disabled services --enabled=&quot;chronyd&quot; timezone Asia/Shanghai --isUtc user --name=test --password=$6$Awcwirg.mougtUlL$Yr1a9e2Vfs2k/Nizdn/ZeiunlsU.rJAmI1vhp1iafeccRt48h3PVIlnVwGvKPPt4dVum a/W32jzYIsn1XCrva. --iscrypted --gecos=&quot;test&quot; bootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda clearpart --all --initlabel zerombr reboot part / --fstype=&quot;xfs&quot; --ondisk=sda --size=51200 part /boot --fstype=&quot;xfs&quot; --ondisk=sda --size=1024 part swap --fstype=&quot;swap&quot; --ondisk=sda --size=4096 part /data --fstype=&quot;xfs&quot; --ondisk=sda --size=30720 %packages @core %end]]></content>
      <categories>
        <category>系统安装</category>
      </categories>
      <tags>
        <tag>运维，linux，windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MHA实现mysql高可用]]></title>
    <url>%2F2017%2F05%2F20%2FMHA%E5%AE%9E%E7%8E%B0mysql%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[MHA实现mysql的高可用 问题引入： 1.首先要知道无论是mysql的主从架构、主主架构都只是解决了mysql的读请求的负载均衡，对mysql的写请求没有任何平均负载的效果； 注意：双主模型只是为了实现高可用(任何一个主节点down机后还可以提供写操作)，它只能分摊多操作，不能分摊写操作； 2.因为如果想让mysql每个节点分摊一部分写操作，那么只有对mysql做切分； 1.垂直切分：分库 1.将一个库中的多张表(无跨库join的需求)分割放到多台物理服务器上，这样 就意味着读和写操作只能到特定的服务器上，而且每个服务器上只有整个数据库集的一部分； 2.当需要读取全部数据时就需要在在多台数据库上读取出来然后再应用程序级别整合，这种框架类似于mysql的中间件，称之为mysql的切分框架； 3.如果能分库通常意味着业务本身是可以通过多个数据库完成读写操作的，这时只需要在应用程序上配置完从分库查询的； 2.水平切分：分表，sharding 1.当不能使用垂直切分时(多张表写入数据量很大，且不能分库存放是)，就只 能通过将多张表进行表切分存放这种方式就是水平切分； 2.当然将表水平切分的方式有很多种，比如按ID号、按年龄、hash(ID、年龄)等进行分表存放； 3.如果是分表方式就意味着前端必须要有个中间件，这个中间件有：cobar,Mycat等； 3.因此mysql服务器要想能够实现分摊写操作，主从复制是做不到的，只能通过水平切分或者垂直切分； 4.把一个数据库切分成多个片段又必然会带来其中任何一个片段出现故障都会导致数据丢失，则又回到了分片--&gt;分片主从--&gt;MMM、MMA 解决方案： 1.mysql自带的主从、主主架构都各自存在很多问题，而为了负载均衡写操作的分片sharding方式又会带来主从问题，而这个问 题又回到了master高可用上来了； 2.因此在主从(分片/主库)架构上，有很多第三方辅助性工具工作在一个单独的节点上并且基于心跳方式周期性监控主从架构中的 主节点，一旦发现主节点down，就会自动提升其中的一个从节点为新的主节点； 3.因此在mysql级别纯粹负责实现mysql主从复制结构中主节点高可用性，这种高可用机制是通过提升主从架构中的从节点为主节 点完成的，而不是通过master active/master inactive来实现的； 4.这种高可用方案主要有两类：MMM和MHA MMM:Multi Master Mysql MHA:Master High Variables 注意： MMM、MHA只是提供master节点高可用方案，它是建构在主从复制集群之上的方案； –MHA自动切换逻辑 MHA:必须基于一主多从架构实现 1.MHA自动切换逻辑: 1.对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点，基于主从复制实现；那么 MHA是如何解决自动切换和数据完整的？ 如图示： 1.当master出现故障时，为了避免一些未复制到从节点的lost events二进制事件丢失，MHA会先在自己管理节点本地保存一份master的二进制 日志副本； 2.而且会从各个从节点的中继日志中的事件指针指向的位置分析出来哪个从节点从master上复制的数据更多，然后把 事先保存在本地的lost events应用到这个同步数据多的从节点上； 3.然后再把其他从节点的master指向新的主节点，从而提升一个从节点称为新的主节点； 4.为了能够完成对主从节点的信息监控，MHA需要依赖于SSH服务； 2.Manager节点需要部署在独立的主机之上，而且MHA可以监控多个mysql主从复制集群； 2.MHA工作原理 1.从宕机崩溃的master保存二进制日志事件（binlog events） 2.识别含有最新更新的slave 3.应用差异的中继日志（relay log）到其他的slave 4.应用从master保存的二进制日志事件（binlog events） 5.提升一个slave为新的master，一般在10s左右 6.使其他的slave连接新的master进行复制 Galera Cluster工作原理：多主模型 1.Galera-Cluster使用的不是mysql协议，它不是在mysql层通过二进制日志、中继日志来复制的，而是在最底层通过存储级别基于wsrep协议完成； 2.任何一节点都可读写，不需要主从复制，实现多主读写，实现的是多主方案的实现，前端也不需要再使用r/w spliter; 3.基于wsrep(MySQL extended with the Write Set Replication)通过wsrep协议在全局实现复制； MHA的实现–MHA集群架构 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062071.架构角色和软件包： 1.依赖于epel源，需启用 2.MHA管理节点：Manager工具包和Node工具包 1.MHA通常单独部署在一台独立的机器上管理多个master/slave集群，每个master/slave集群称作一个application； 2.当然在没有故障时，也可以手动切换master节点； 3.在管理节点上安装两个包： mha4mysql-manager mha4mysql-node 3.数据库各节点：安装Node工具包 1.运行在每台Mysql服务器上master/slave/manager,它通过监控具备解析和清理logs功能的脚本来加快故障转移； 2.node安装完之后会有4个脚本程序能够辅助完成日志分析各个slave上的数据多少和中继日志中的位置从而实现提升一个从为主节点； 3.在被管理节点安装： mha4mysql-node 4.MHA软件由两部分组成，Manager工具包和Node工具包 5.Manager工具包主要包括以下几个工具： masterha_check_ssh 用来检查MHA的SSH配置状况 masterha_check_repl 用来检查MySQL复制状况(基于主从架构) masterha_manger 用来启动MHA主程序 masterha_check_status 用来检测当前MHA运行状态 masterha_master_monitor 用来检测master是否宕机 masterha_master_switch 故障转移（自动或手动） masterha_conf_host 添加或删除配置的server信息 masterha_stop #用来关闭MHA服务的工具，当然也可以使用kill命令 6.Node工具包： save_binary_logs #保存和复制master的二进制日志 apply_diff_relay_logs #识别差异的中继日志事件并将其差异的事件应用于到其他的slave filter_mysqlbinlog #去除不必要的ROLLBACK事件（MHA已不再使用此工具） purge_relay_logs #由MHA负责清除各节点的中继日志（不会阻塞SQL线程），而不是由mysql自己去清理和下面那个参数有关； 7.自定义扩展： 因为只依靠上面Manager和Node提供的工具还不足以实现MHA的完整功能，比如客户端应该访问的是一个VIP，当一个从提升 为主时对外提供服务的IP地址必然会改变，所以应该设置VIP，因为下面这几个工具都是为完善MHA功能的： secondary_check_script： 通过多条网络路由检测master的可用性 master_ip_ailover_script： #更新Application使用的masterip #实际上就是管理VIP的，实现VIP迁移的工具但是需要依赖于脚本实现 #当然也可以使用keepalived来实现； shutdown_script： 强制关闭master节点 强制关闭故障的master节点，避免出现资源争抢的情况 report_script： #当发生主从切换时通过脚本通知给管理员 init_conf_load_script： 加载初始配置参数 master_ip_online_change_script： 在线更新master节点ip地址，即在不使用VIP的方案时手动修改 8.配置文件： 因为MHA可以管理多个主从复制集群，每一个集群称为一个application,而这些集群可以有公用的配置段global和独自的配置段application； global配置: 为各application提供默认配置 application配置： 为每个主从复制集群 注意： 为了尽可能的减少主库硬件损坏宕机造成的数据丢失，因此在配置MHA 的同时建议配置成MySQL 5.5的半同步复制；2.配置MHA实现： 1.因为每个从节点都有可能被提升为主节点，所以所有从节点都要开启二进制日志和中继日志； 2.主节点可以不开启中继日志(当主节点down了之后当做从节点被加进来时再开启也可以)，但是为了统计，主从最好都开启二进制日志和中继日志； 3.环境准备： 1.服务器： node1:MHA manager(也可以部署在某一个从节点上)，10.10.0.3 node2:mysql master 10.10.0.5 node3:mysql slave1 10.10.0.6 node4:mysql slave2 10.10.0.7 2.各主机互相基于ssh-key验证 ssh-keygen ssh 10.10.0.5(自己的IP) scp /root/.ssh 10.10.0.3|6|7:/root/ #即可 3.各主机的时间需要同步 4.mysql主从配置 1.初始化主节点master配置: ~]# vim /etc/my.cnf [mysqld] server-id=1 skip-name-resolve innodb_file_per_table=1 relay-log=relay-bin log-bin=master-bin ... #其他需要配置的参数根据实际情况添加即可 2.初始化两台从节点: ~]# vim /etc/my.cnf [mysqld] server-id=2|3 #复制及群中的各节点的id均为唯一； skip-name-resolve innodb_file_per_table=1 relay-log=relay-bin log-bin=slave1-bin relay_log_purge=0 #关闭relay-log的自动清理功能 因为MHA要根据中继日志判断各个从节点的中继日志位置的，所以需要关闭mysql的中继日志自动清理功能，由MHA去清理中继日志； read_only=1 #MHA根据read_only来判断主从节点的，一旦某个从提升为主时会自动改成read_only=0 3.创建主从复制账号和MHA的管理账号 mysql&gt; show master status; +-------------------+-----------+ | Log_name | File_size | +-------------------+-----------+ | node2-bin.000001 | 245 | #从此位置后开始复制 +-------------------+-----------+ mysql&gt; grant replication slave on *.* to repluser@&apos;10.10.0.%&apos; identified by &apos;root123&apos;; #创建复制账号 mysql&gt; grant all on *.* to mhauser@&apos;10.10.0.%&apos; identified by &apos;mha123&apos;; #创建MHA账号用于管理各节点 4.设置change master to 主节点：mysql&gt; show master status; +-------------------+-----------+ | Log_name | File_size | +-------------------+-----------+ | node2-bin.000001 | 245 | #创建用户前的二进制日志位置 +-------------------+-----------+ 各从节点执行： CHANGE MASTER TO MASTER_HOST=&apos;10.10.0.5&apos;, #主节点IP MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;root123&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;node2-bin.000001&apos;, #初始二进制日志 MASTER_LOG_POS=245; #日志位置 mysql&gt; start slave; #各从节点设置完后启动复制线程 mysql&gt; show slave status\G; 5.在mysql主从节点都安装node安装包 ~]# yum install mha4mysql-node-0.56-0.el6.noarch.rpm #el6的包同样适用于el7上，都可以使用； #base和epel源，需要事先配置好epel； ~]# rpm -qlp mha4mysql-node-0.56-0.el6.noarch.rpm /usr/bin/apply_diff_relay_logs /usr/bin/filter_mysqlbinlog /usr/bin/purge_relay_logs /usr/bin/save_binary_logs #主要就是这四个程序 5.MHA管理节点上配置：10.10.0.3 1.安装manager包 ~]# yum install mha4mysql-manager-0.56-0.el6.noarch.rpm ~]# yum install mha4mysql-node-0.56-0.el6.noarch.rpm #管理节点两个包都需要安装，依赖base和epel源 2.准备MHA的application配置文件 1.因为MHA可以管理多个主从复制集群，每一个集群称为一个application，所以可以在/etc/mha/路径下创建 多个*.cnf文件为监控的每个集群设置独有的配置信息； 2.这里以mysqlcluster1.cnf名为例为上面的集群定义配置信息 ~]# vim /etc/mha/mysqlcluster1.cnf [server default] #为各集群提供默认配置 user=mhauser #上面创建好的MHA管理账号 password=mha123 #管理账号的密码 manager_workdir=/etc/mha/cluster1/ #当前集群的工作目录且目录会自动创建 manager_log=/etc/mha/cluster1/manager.log #当前集群的监控日志文件 remote_workdir=/etc/mha/cluster1/ #在管理节点上(master/slave)准备MHA的工作目录和上面一致即可 ssh_user=root #ssh的用户为root用户，无需密码已经认证 repl_user=repluser #主从复制集群的账号 repl_password=root123 #主从复制集群的账号的密码 ping_interval=1 #MHA每隔多久检测master是否在线，1s [server1] hostname=10.10.0.5 #master节点信息 # ssh_port=22022 #如果ssh使用了非默认端口，修改即可 candidate_master=1 #将来此节点是否可以提升为新的master节点 [server2] hostname=10.10.0.6 #slave1节点信息 # ssh_port=22022 candidate_master=1 #no_master=1 #如果不想提升此节点为master，启用此项即可 [server3] hostname=10.10.0.7 #slave2节点信息 candidate_master=1 6.配置完之后检查是否满足MHA的基本功能 1.检查各主机间SSH是否成功 masterha_check_ssh --conf=/etc/mha/mysqlcluster1.cnf #显示SSH connection tests passed successfully说明是成功的 2.检查主从复制是否成功 masterha_check_repl --conf=/etc/mha/mysqlcluster1.cnf #显示Mysql Replication Health is OK,说明是正常的 7.启动MHA 当测试完成后可以启动MHA了 ~]# nohup masterha_manager --conf=/etc/mha/mysqlcluster1.cnf #剥离当前终端在后台运行MHA ~]# masterha_check_status --conf=/etc/mha/mysqlcluster1.cnf mysqlcluster1 is running(0:PING_OK)，master:10.10.0.5 #启动了MHA，可以通过此命令查看MHA集群的状态； #表示MHA监控的mysqlcluster1集群状态时OK的，并显示master信息3.MHA故障转移测试 1.手动把主节点down机 ~]# killall mysqld mysqld_safe 2.可以通过查询cat /etc/mha/cluster1/manager.log日志查看故障转移的节点信息 3.在从节点上验证 此时发现10.10.0.6这个从节点被提升为主节点了； mysql&gt; show Global variables like &apos;read_only&apos;; +---------------+-------+ | read_only | OFF | #之前从节点上设置的只读被MHA关闭了 +---------------+-------+ mysql&gt; show master status; #可以看到自己时主节点 4.将原来的master再加入到这个主从集群(修复上线的节点) 1.在新的主节点上做一次完全备份并记录二进制日志名字和位置 2.将备份出的数据库导入到这个从节点上，并从上面记录的二进制日志文件和位置之后开始复制； 3.这里要把它当成一个新的从节点加入集群的方式进行安全操作； 5.停止MHA ~]# masterha_stop --conf=/etc/mha/mysqlcluster1.cnf #使用masterha_stop指定配置文件停止一个监控集群 6.注意： 1.MHA一旦监测并提升一个从节点为主节点后，MHA程序会自动退出的，需要人为的再次将MHA启动起来； 2.如果不想再次手动启动MHA，可以写一个监控脚本即可 7.备注： 1.MHA切换时，主节点的IP肯定是变化了，对于前端应用程序来说就很方便，所以一般应用程序访问的是VIP，这里通过 master_ip_ailover_script的脚本来实现VIP漂移； 2.当然这里也可以使用keepalived的来实现； 3.为了避免故障的master上线出现脑裂的情况，也需要使用shutdown_script脚本给故障的master发送shutdown -h now关闭服务器； –主节点自动切换]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql备份恢复]]></title>
    <url>%2F2017%2F05%2F17%2Fmysql%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[备份和恢复–差异备份–增量备份 1.要注意的要点： 1.能容忍最多丢失多少数据？ 2.恢复数据需要在多长时间内完成？ 3.需要恢复哪些数据？ 2.还原要点： 1.做还原测试，用于测试备份的可用性； 2.还原演练 3.备份类型： 根据不同的角度，备份又分下面几种类型 1.完全备份，部分备份： 完全备份：整个数据集 部分备份：只备份数据子集，如部分库或表 2.完全备份、增量备份、差异备份： 增量备份： 仅备份最近一次完全备份或增量备份（如果存在增量）以来变化的数据，备份较快，还原复杂 还原方式：完全备份+N个增量备份(+二进制日志) 差异备份： 仅备份最近一次完全备份以来变化的数据，备份较慢，还原简单 还原方式：完全备份+最后一个差异备份(+二进制日志) 注意：二进制日志文件不应该与数据文件放在同一磁盘 3.热备、温备、冷备 热备：备份过程中读写操作均可执行； 虽然热备实现起来很复杂但实际上还是需要做热备 温备：读操作可执行；但写操作不可执行，此时需要加全局读锁(FLUSH命令)； 实现过程中也比较难 冷备：读写操作均不可进行，实现起来不切合实际 4.物理和逻辑备份 物理备份： 1.直接复制数据文件进行备份,与存储引擎有关,占用较多的空间,速度快 2.物理备份有可能占用更多的空间，但是速度很多不需要专用的工具，不用基于协议而是直接cp、tar文件即可； 3.物理备份与存储引擎有关，恢复时也必须是同样的存储引擎； 逻辑备份： 1.逻辑备份不是备份物理文件的，它是mysql的客户端通过根据mysql协议连到mysql服务器上把它的所有数据导出一份； 2.从数据库中&quot;导出&quot;数据另存而进行的备份，与存储引擎无关，占用空间少，速度慢，可能丢失精度； 3.缺点是： 逻辑备份工具通常都是基于协议工作的客户端工具，需要先转换成文本，像浮点型数据会丢失数据还有可能更占用空间； 4.逻辑备份和存储引擎无关，恢复时不用考虑存储引擎的问题； 4.为什么MyISAM不支持热备，而InnoDB支持热备？ 1.对数据集做热备时，因为数据集都在做读写操作，为了避免产生脏数据，就要求某些存储引擎支持快照功能，而InnoDB的每一个事务启动时都是基于MVCC创建快照实现的； 2.InnoDB实现方式：当打算开始备份时，对整个数据集做一次阻断内部做一个快照，而后只需要对这个快照做一次备份就行了；InnoDB每一次数据修改都有一个LSN(日志序列号)，但是MyISAM确没有； 3.所以说备份技术是和存储引擎有关系的； MyISAM：支持温备，不支持热备 InnoDB：三种都支持 5.需要备份什么数据？ 1.数据 2.二进制日志、InnoDB的事务日志(是否一定备份取决于对数据安全的需求级别) 3.程序代码（存储过程、函数、触发器、事件调度器） 4.服务器的配置文件 6.设计备份方案 数据集：完全+增量 备份手段：物理，逻辑 不过一般来说都是通过完全+增量的方式进行备份 7.备份工具 1.mysqldump: 1.逻辑备份工具，适用于所有存储引擎(因为逻辑备份与存储引擎无关)，支持温备、完全备份、部分备份(单个库、单个库中的某个/写表)； 2.对InnoDB存储引擎支持热备(这种热备是通过启动一个大事务进行的)，结合binlog的增量备份； 3.在数据库较小时(不大于2G)，使用mysqldump还是很好用的；当数据更大的需要物 理备份工具；，而不是mysqldump这种逻辑备份工具； 2.cp, tar等复制归档工具 物理备份工具，适用于所有存储引擎，只能进行冷备、完全部分、部分备份； 物理备份直接在文件系统级别直接通过复制文件的方式来实现； 3.LVM的快照: 实现几乎热备(先加锁，做快照后解锁);借助文件系统工具cp、tar进行备份; 4.mysqlhotcopy 几乎冷备,仅适用于MyISAM存储引擎,因为InnoDB存储引擎流行的今天这个备份工具几乎不用了； 5.xtrabackup 由Percona提供支持对InnoDB做热备(物理备份)的工具,支持完全备份、增量备份; 支持并行多数据集同时备份、远程复制 MyISAM:不能热备，不能增量 InnoDB：LSN热备、增量 8.备份策略：（备份工具+备份方案） 1.mysqldump+复制binlog: mysqldump:完全备份 复制：复制binlog中指定时间范围的event：增量备份 2.lvm2快照+复制binlog: lvm2快照：使用cp或者tar等做物理备份、完全备份 复制binlog:复制binlog中指定时间范围的event：增量备份 3.xtrabackup: 对InnoDB做热备(物理备份)的工具,支持完全备份、增量备份;支持并行多数据集同时 备份、远程复制 假如有一个10G/100G的数据库，如何做备份？ 显然如果使用mysqldump是即为麻烦的而且很慢，如果是使用xtrabackup更可行： 策略： 每周一次完全备份+每天一次增量备份+二进制日志做时间点还原 9.逻辑备份工具 mysqldump, mydumper, phpMyAdmin都可以实现逻辑备份，逻辑备份的缺点： 逻辑备份的备份方式： 逻辑备份mysqldump是通过协议连到mysql服务器端去读取出来所有数据然后把它放在一个文本文件中，把所有数据抽取出来改写成一个insert语句，这个insert语句 是有100w行，每张表就是一个大的insert语句还有create database语句、create table语句； 在恢复时导入到mysql数据库中时，先创建库，在创建表，然后再insert数据； 所以逻辑备份是把Schema(表的结构定义、数据库结构定义、数据库的属性定义等)+数据存储在一起、巨大的SQL语句、单个巨大的文件： 10.要实现数据库的安全备份，笔者的理解是必须要有以下几点： 1.全量备份（一周或者二周一次） 2.二进制日志：能够实现基于时间点的恢复。 根据业务场景选择适当的时间间隔定时备份二进制日志，如rsync。 3.至少要有一台备机：否则主机出问题后，恢复数据库期间会造成业务中断 4.完备的数据恢复测试：根据恢复后的日志文件、数据文件的大小、关键事件信息验证备份信息是否有效。 使用mysqldum实现逻辑备份使用mysqldump工具，类似的有mypump（5.7.11之后有用，多线程导出，能实现数据一致性）. 这种方法适合在数据量比较少的情况下使用（个人认为数据量&lt;100G可行），在一台30G的数据库上进行备份，备份出来的数据文件8G（因为没有导出来索引等其他数据库信息，因此文件通常比数据库小的多），使用时间8分钟，恢复时间用了差不多半个小时。顺便说一句，导出时使用order-by-primary参数应该可以提高几倍的导入性能（和mysql的聚集索引有关） mysqldump是mysql自带的逻辑备份工具，它是一个客户端命令通过mysql协议连到mysql服务器； 生产环境： 如果数据量不大时，可以使用mysqldump一周做一次完全备份，然后每一天(每半天)做一次通过复制二进制日志文件做增量； 每半天去复制滚动一次二进制日志文件，将此前的复制出来，过半天再滚动一次，然后再把前一个复制出来； 恢复时: 完全备份+N分增量的二进制日志 1.用法： shell&gt; mysqldump [options] db_name [tbl_name ...] #此方式不会自动创建create databases语句，因为他只会把db_name中的的每个 table名称创建出来，当恢复时,还是需要先创建db_name shell&gt; mysqldump [options] --databases db_name ... shell&gt; mysqldump [options] --all-databases #下面两张方式都会有create database语句 mysqldump [options] [db_name [tbl_name ...]] -A,--all-databases 备份所有数据库，含create database -B,--databases db_name… 指定备份的数据库，包括create database语句 --single-transaction #启动一个巨大的事务 -E,--events：备份相关的所有event scheduler -R,--routines：备份所有存储过程和自定义函数 --triggers：备份表相关触发器，默认就是启用,用--skip-triggers,不备份触发器 --default-character-set=utf8 指定字符集 --master-data[=#]： 此选项须启用二进制日志 --flush-logs #锁定表完成后，执行flush logs命令 #此选项的好处在于备份完，生成一个新的二进制日志文件， 不再像--master-data选项一样从旧的二进制日志中选出一部分日志了； --skip-TZ-UTC： 在使用的mysqldump备份含有时间戳类型列的表时，需要指定--skip-TZ-UTC选项，否则可能会导致备份数据异常； 推荐使用的日期时间，与时区无关且存储范围更大，可以避免一些问题 --ignore-table=数据库名.表名 #备份时忽略某个库中的某个表 如--ignore-table=hellodb.students 2.备份： 1.在备份前一定不能直接使用mysqldump去备份全部或某些表，因为这些数据库都是在生产环境下被使用的，如果有其他事务正在写数据的话，通过mysqldump的数据就会不一致!!! 2.mysqldump对MyISAM表只能实现温备，对InnoDB可以实现热备，所以对MyISAM来说要先锁定要备份的所有表，然后再进行备份操作； 3.MyISAM备份选项: 支持温备；不支持热备，所以必须先锁定要备份的库，而后启动备份操作 锁定方法如下： -x,--lock-all-tables： 能够锁定指定所有库中的所有表，施加全局读锁(温备) -l,--lock-tables 锁定要备份的库的所有表，而不是所有库的所有表，适合备份单个库 注：以上选项对InnoDB表一样生效，只能实现温备，但不推荐使用 4.InnoDB备份选项 支持热备，可用温备但不建议用 --single-transaction #启动一个巨大的事务 1.因为mysql是基于MVCC实现并发控制的，开启一个事务相当于是做了一个快照，此时无论外表数据如何修改，在这个开启的事务中数据都不会改变，所以可以实现热备； 2.但是MyISAM是不支持事务的，所以此参数项对MyISAM是没有意义的； 3.所以此选项只能在Innodb中使用，不适用MyISAM，此选项会开始备份前，先执行START TRANSACTION指令开启事务； 5.完全备份+增量备份+二进制日志 1.上面只是进行了完全备份，但是当需要使用二进制日志时，还需要考虑的是之前做的完 全备份是在二进制日志的哪个位置？只有知道在二进制日志中的位置才能再把这个位置之 后的二进制日志恢复确保数据的完整性； 2.所以在mysqldump的参数中--master-data[=#] =1:表示记录为CHANGE MASTER TO语句，词语局不被注释 =2:记录为注释的CHANGE MASTER TO语句 当--master-data=2时，备份数据库时会有change master to日志记录和备份时的 位置，恢复时只要把从这个位置之后的二进制日志导出放到一个sql文件中，再导入到数据库中就可以保证数据的完整性了； 3.这个记录在二进制日志中的位置至关重要!!! 示例: 1.备份： mysqldump -uroot --all-databases --lock-tables --master-data=2 &gt; /root/all.sql vim /root/all.sql CHANGE MASTER TO MASTER_LOG_FILE=&apos;node02-bin.000001&apos;,MASTER_LOG_POS=245 #这一行就是记录备份开始时，二进制日志是哪个和二进制的位置，即使后来数据库再有写、修改操作，只需要从这个二进制日志的245位置之后的数据导出再导入即可； 2.增加新数据 insert table ..... #这里做修改操作，演示数据是被修改了 3.恢复 1.先把完全备份导入 mysql &lt; all.sql #此时还需要导入后来变化的数据 2.找到记录在二进制日志中后来变化的数据 mysqbinlog --start-position=245 /data/mysql/node02-bin.000001 #此时把245之后的语句导出到一个文件中即可 mysqbinlog --start-position=245 /data/mysql/node02-bin.000001 &gt; new.sql 3.将二进制数据导入 mysql &lt; new.sql #此时数据就是完整的了 mysqldump备份工具默认使用的字符集时utf8 所以备份数据库时，要先查看数据库的字符集，避免因为字符集不统一出现问题。 生产实例的数据备份和还原1.生产环境实战备份策略： 1.InnoDB建议备份策略 mysqldump –uroot –A –F –E –R --single-transaction --master-data=1 -flush-privileges --triggers --default-character-set=utf8 --hex-blob &gt;$BACKUP/fullbak_$BACKUP_TIME.sql 2.MyISAM建议备份策略 mysqldump –uroot –A –F –E –R –x --master-data=1 --flush-privileges -triggers --default-character-set=utf8 --hex-blob &gt;$BACKUP/fullbak_$BACKUP_TIME.sql 2.如何实现把每个库备份到各自的备份文件中，分库备份？ 分库备份脚本 for db in `mysql -e &apos;show databases&apos; |grep -Ev &apos;^(Database|information_schema|performance_schema)$&apos;`;do mysqldump -B $db|gzip &gt; $db`date +%F`.sql.gz;done mysql -e &apos;show databases&apos; |grep -Ev &apos;^(Database|information_schema|performance_schema)$&apos;|sed -r &apos;s/(.*)/mysqldump -B \1 |gzip &gt; \/data\/\1.sql.gz/&apos; |bash mysqldump –uroot –A –F --single-transaction --master-data=2 --default-character-set=utf8 --hex-blob &gt;$BACKUP/fullbak_$BACKUP_TIME.sql 3.生成环境示例： 对于mysql正在运行过程当中，0~2点执行备份，但是在第二天上午10点删除了一个库或者删除了一个表发生了一次误操作，在12点的时候发现数据库故障了，应该怎么解决？ 1.将0~2点的完全备份，因为备份时肯定加了--master-data=2记录了备份时的二进制日志位置，所以先将完全备份恢复； 2.将备份时的二进制日志位置之后的二进制日志导入到一个新的文件中，因为这个二进制日志中有删除的操作，所以找到误操作的语句进行删除，然后再replay到数据库了，保证数据的完整性； Xtrabackup物理备份Percona官网 该工具功能十分强大，能满足中型和部分大型生产环境。该工具也是基于数据库物理文件进行备份，现执行物理备份，然后使用--prepare选项对拷贝的文件进行一次内部崩溃恢复，以便产生一致性备份。该工具可以进行全量备份和增量，我在一台测试环境上测试，30G的数据库备份之后用了17分钟，cpu占用率也不高，备份后大小是20G，几个小时后基于上次的全量备份做了次增量备份，居然花了13分钟。 1.前提： 1.对于mysqldump来说，它能实现对MyISAM存储引擎做温备，对InnoDB存储引擎温备和其中一个单个事务基础之上完成热备，但它是一个逻辑备份工具； 2.而如果真正期望在线上做真正意义上的热备而且还是物理操作，那么xtrabackup是一个很好的备份工具； 3.InnoDB--&gt;XtraDB Xtrabackup就是为了备份XtraDB存储引擎的工具，而且还可以对 InnoDB进行备份； 特点： 1.备份还原过程快速、可靠 2.备份过程不会打断正在执行的事务 3.能够基于压缩等功能节约磁盘空间和流量 4.自动实现备份检验 5.开源，免费 2.一些概念： 1.xtrabackup支持对innodb进行热备、增量备份、差量备份 2.xtrabackup支持对myisam进行温备，因为在备份myisam表时，会对myisam表添加读锁，而且不能对myisam表进行增量备份，每次备份myisam数据都是全量，即使名义上是增量，但是实际上仍然是全量; 3.与mysqldump不同，xtrabackup是一种物理备份工具，但是，它是需要通过协议连接到mysql服务端（这一点与mysqldump相同，它们都是客户端工具，都需要连接到服务端），然后读取并复制innodb底层的&quot;数据块&quot;，完成所谓的&quot;物理备份&quot;。 综上所述，xtrabackup是一种客户端工具，我们能够通过它对mysql数据库实现物理备份; 3.安装percona-xtrabackup 它可以备份5.1到5.7版本上InnoDB,XtraDB,MyISAM存储引擎的表 ~]# yum install percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm -y #安装时依赖base和epel源 ~]# rpm -pql percona-xtrabackup-24-2.4.12-1.el7.x86_64.rpm /usr/bin/innobackupex /usr/bin/xtrabackup Xtrabackup有两个主要的工具：xtrabackup、innobackupex 1.xtrabackup是一个C程序，只能备份InnoDB和XtraDB两种数据表，而不能备份MyISAM数据表 2.在2.3之前的版本，innobackupex是一个perl脚本，它对xtrabackup这个C程序进行了封装，在备份innodb表时，此脚本会调用xtrabackup这个C程序； 如果使用innobackupex进行备份，则可以备份innodb或xtradb的表，同时也能够备份myisam表。 注意： 1.在2.4版本,innobackupex的功能已经完全整合到了xtrabackup中，innobackupex不再是perl脚本了，但是，为了兼容之前用户的使用习惯，官方保留了innobackupex，它作为一个软连接，指向了xtrabackup，也就是说，在2.4版本中，不管我们使用innobackupex命令，还是xtrabackup命令，其实使用的都是C程序; 2.所以，一般在使用XtraBackup备份工具进行数据备份时，通常会选择使用innobackupex命令进行备份； 4.xtrabackup命令使用用法： xtrabackup --backup --target-dir=/data/backups/base --datadir=/var/lib/mysql/ #备份时指明备份的目标目录和数据目录 5.innobackupex命令使用用法： innobackupex --user=DBUSER --password=DBUSERPASS /path/to/BACKUP-DIR/ #不用指明datadir，因为它会自动读取配置文件中的mysqld中的datadir参数的值 前提： 使用innobackupex执行备份操作是需要连接mysql服务端的账号和密码 如： mysql&gt; CREATE USER &apos;bkupdbuser&apos;@&apos;192.168.1.146&apos; IDENTIFIED BY &apos;123123&apos;; #创建数据库用户bkupdbuser mysql&gt; GRANT RELOAD,LOCK TABLES,REPLICATION CLIENT,PROCESS ON *.* TO &apos;bkupdbuser&apos;@&apos;192.168.1.146&apos;; #为bkupdbuser用户授权，如下权限为正常备份的最小权限 mysql&gt; FLUSH PRIVILEGES; – 4.xtrabackup怎样实现物理备份? xtrabackup是怎样对innodb存储引擎实现所谓的物理备份的呢？ 如果想要搞清楚这一点，需要回顾一下innodb的存储结构，借用一张网上流传比较广的innodb逻辑存储结构图，如上图： 1.innodb存储引擎的逻辑结构如上图所示，逻辑单元从大到小分别为:表空间(tablesapce)、段(segment)、区(extent)、页(page)、行(row)，如上图所示，每个大的逻辑单元中都包含了N个小的逻辑单元; 2.而我们只要关心上图中的extent逻辑单元和page逻辑单元即可，我们可以把上图中Extent区域中的每个&quot;小方块(page)&quot;当做xtrabackup需要备份的&quot;数据块&quot;，因为数据存放于行中，行存在于page中，所以，我们备份对应page，即可备份出对应的数据，当我们使用xtrabackup连接到mysql服务端的时候，xtrabackup会读取innodb中的page，进行备份； 5.xtrabackup怎样实现完全备份? xtrabackup是基于日志序列号LSN来识别它是完全备份还是增量备份的，也是通过LSN来保证增量备份能够在线进行的； 6.xtrabackup怎样实现增量备份? 事实上xtrabackup的所有备份操作都是基于LSN(log sequence number来实现的)，它的热备正是通过读取lsn序列号实现的； 注意： 增量备份仅能应用于InnoDB或XtraDB,对于MyISAM表而言，执行增量备份时其实进行的是完全备份； 7.一些注意点 7.完全备份和恢复 注意： 备份前要确保：innodb_file_per_table=ON是开启的 1.备份： ~]# innobackupex --defaults-file=/etc/my.cnf --host=192.168.34.118 --user=root --password=123123 /backup #表示备份当前数据库服务器上的所有数据库，对所有数据库进行全量备份，将备份的文件存放在/backup目录下 #如果使用root用户,备份本机上的数据库,那么除了-p password之外其他都可以省略； 执行结果： 170415 21:32:22 Backup created in directory &apos;/root/backups/2017-04-15_21-32-20/&apos; MySQL binlog position: filename &apos;node02-bin.000006&apos;, position &apos;16575&apos; 170415 21:32:22 [00] Writing /root/backups/2017-04-15_21-32-20/backup-my.cnf 170415 21:32:22 [00] ...done 170415 21:32:22 [00] Writing /root/backups/2017-04-15_21-32-20/xtrabackup_info 170415 21:32:22 [00] ...done xtrabackup: Transaction log of lsn (1923968) to (1923968) was copied. 170415 21:32:23 completed OK! #1.看到completed OK才算备份成功。 #2.可以看到屏幕上输出了xtrabackup备份的大致过程，可以看出，xtrabackup先备份了innodb数据文件，然后才开始备份非innodb数据，备份非innodb数据文件之前，施加了读锁； 2.进入备份目录看一下都备份了哪些文件: ~]# cd /root/backups/2017-04-15_21-32-20/ ~]# ls #从备份的文件中的信息可以看出，这是一次全量备份 cre mysql test #上面三个目录就是数据文件备份目录 backup-my.cnf 此文件中包含了my.cnf中的一些设置信息，但是，并不是my.cnf中的所有信息都会包含在此文件中，此文件中只包含了备份时需要的信息 xtrabackup_checkpoints 此文件中记录此次备份属于那种类型的备份，是全量还是增量，备份时起始的LSN号码，结束的LSN号码等信息。 xtrabackup_logfile 记录了备份过程中的日志，在对数据进行prepare时需要通过日志将数据还原成一致的可用的数据 xtrabackup_binlog_info 此文件中记录了备份开始时二进制日志文件的&quot;位置(position)&quot; xtrabackup_info 本次备份的概要信息，此文件中的信息还是比较全面的 3.准备(prepare)一个完全备份 现在，我们即可进行数据还原操作了，只是我们说过，备份出的数据并不能直接使用，因为备份出的数据是不一致的，我们需要把已提交的事务合并到数据文件里面，未提交的事务进行回滚，才能得到一份完整、一致、可用的数据，xtrabackup称这一步操作为prepare； ~]# innobackupex --apply-log /root/backups/2017-04-15_21-32-20/ #表示整理的是2017-04-15_21-32-20这个备份目录 #如果执行正确会返回类似下面的这些信息 xtrabackup: starting shutdown with innodb_fast_shutdown = 1 InnoDB: FTS optimize thread exiting. InnoDB: Starting shutdown... InnoDB: Shutdown completed; log sequence number 1928744 170415 21:59:43 completed OK! #只有看到completed OK!说明才是没问题的!!! 4.恢复、还原操作 完成上述工作以后，我们已经得到了一份可用的，数据一致的备份，那么此刻，我们即可完成真正的恢复数据操作了，真正的恢复数据操作也非常简单，我们只要把可用的备份&quot;拷贝回&quot;数据库的数据目录即可。但是，拷贝工作并不是手工的使用cp命令或者mv命令进行，而是使用innobackupex命令进行； ~]# innobackupex --copy-back /root/backups/2017-04-15_21-32-20/ #注意如果此处是用root用户执行的，那么mysql启动时会报错的 170415 22:12:01 completed OK! #恢复完成会显示是OK的!!! ~]# /etc/init.d/mysqld start Starting MySQL.. ERROR! The server quit without updating PID file (/data/mysql/node02.pid). #启动时报错是因为执行上一条命令时。数据目录下的属主属组都是root,需要改成mysql ]# chown mysql.mysql /data/mysql/* -R #修改为mysql.mysql,或者在执行恢复时以mysql用户就行了 注意： 在此恢复时还有个报错，是因为事务日志的大小问题，有的事务日志默认是5M，而有的是48M，所以在恢复时还要先查一下默认的事务日志大小； 8.使用innobackupex进行增量备份(差异备份)和恢复 每个InnoDB的页面都包含一个LSN信息，每当相关的数据发生改变，相关的页面的LSN就会自动增长，这正是InnoDB表可以进行增量备份的基础，即innobackupex通过备份上次完全备份之后发生改变的页面来实现； 要实现第一次增量备份，可以使用： innobackupex --incremental /root/backup --incremental-basedie=BASEDIR #通过--incremental选项明确表示这是一次增量备份 #还要--incremental-basedie=BASEDIR来指明是基于哪个完全备份或者增量备份再做的增量备份； #如果BASEDIR每次都指的是完全备份，那么此处做的就是差异备份 注意1： 不管是增量备份还是差量备份，都是对于innodb表来说的，对于myisam表，即使执行了所谓的&quot;增量&quot;备份，其实也是全量备份，因为MyISAM不支持增量 注意2: 准备(prepare)增量备份与整体完全备份有些不同之处，尤其要注意的是： 1.需要在每个备份(包括完全和各个增量备份)上，将已提交的事务进行&apos;重放&apos;，&apos;重放&apos;之后，所有的备份数据将合并到完全备份上 2.基于所有的备份将未提交的事务进行回滚； 具体命令： innobackupex --apply-log --redo-only BASE-DIR #先整理完全备份，只提交已提交的事务 innobackupex --apply-log --redo-only BASE-DIR --incremental-dir=INCREMENTAL-DIR-1 #将第一个增量合并到完全备份 innobackupex --apply-log --redo-only BASE-DIR --incremental-dir=INCREMENTAL-DIR-2 #将第二个增量合并到完全备份 #BASE-DIR是指完全备份所在的目录，而INCREMENTAL-DIR-1是指第一次增量备份的目录，INCREMENTAL-DIR-2是指第二次增量备份的目录，其他依次类推，即如果有多个增量备份，每一个都要执行如上操作 注意： 1.跨完全备份和增量备份的事务，除了最后一个增量，其他的事务都不能回滚，最后一个才能回滚； 2.其实最后一个增量备份也是做的redo-only可能会有问题，有些未提交的事务会没有回滚，但是这也没关系，因为msyql或mariadb启动时自己会将未提交的事务进行回滚的； 示例： 1.先做完全备份 ~]# innobackupex /root/backups/ ~]# cd 2017-04-15_22-39-22/ #进入全量备份的目录 ~]# vim xtrabackup_checkpoints backup_type = full-backuped #记录第一次是做的全量备份 from_lsn = 0 to_lsn = 1928792 last_lsn = 1928792 #第一次全量备份后的最后一个LSN位置 compact = 0 recover_binlog_info = 0 2.做第一次增量备份 ~]# innobackupex --incremental /backups/ --incremental-basedir=/backups/2017-04-15_22-39-22 #指明是基于2017-04-15_22-39-22这个完全备份做的增量备份 ~]# cd 2019-04-15_22-46-04 #进入到增量备份的目录下 ~]# vim xtrabackup_checkpoints backup_type = incremental #可以看到这个目录是做的增量备份 from_lsn = 1928792 #起始位置刚好就是完全备份的LSN编号 to_lsn = 1930626 last_lsn = 1930626 #最后一个LSN位置 compact = 0 recover_binlog_info = 0 3.准备prepare 1.先整理完全备份 ~]# innobackupex --apply-log --redo-only /root/backups/2019-04-15_22-39-22 2.将2019-04-15_22-46-04这个增量备份合并到完全备份上 ]# innobackupex --apply-log --redo-only /backups/2019-04-15_22-39-22 --incremental-dir=/backups/2019-04-15_22-46-04 #将第一次的增量合并到完全备份 3.此时进入完全备份的目录下 ~]# cd 2017-04-15_22-39-22/ #进入全量备份的目录 ~]# vim xtrabackup_checkpoints backup_type = log-applied # from_lsn = 0 to_lsn = 1930626 last_lsn = 1930626 #可以看到是和最后一次增量备份的LSN一致 compact = 0 recover_binlog_info = 0 4.还原数据库 ~]# systemctl stop mysql #先关闭mysql实例 ~]# innobackupex --copy-back /root/backups/2019-04-15_22-39-22/ #从合并完的完全备份中恢复 5.恢复二进制日志中的位置 如果完全备份和增量备份后还有数据未恢复，就需要从二进制日志中基于时间点进行恢复后边的数据； ~]# systemctl start mysql #恢复后再重启mysql 9.xtrabackup单表导出和导入 默认情况下，InnoDB表不能通过直接复制表文件的方式在mysql服务器之间进行移植，即便使用了innodb_file_per_table选项，而使用Xtrabackup工具可以实现此种功能，不过，此时需要&quot;导出&quot;表的mysql服务器启用了innodb_file_per_table选项(严格来说，是要导出的表在其创建之前，mysql服务器就启用了innodb_file_per_table选项)，并且&quot;导入&quot;表的服务器职期间同时启用了innodb_file_per_table和innodb_expand_import选项 1.导出表 1.导出表再是备份的prepare阶段进行的，这就意味着需要先做一次完全备份 2.因此一旦完全备份完成，就可以在prepar过程中通过--export选项将某表导出了； ~]# innobackupex /root/backups/ ~]# cd 2017-04-15_16-17-06/ ~]# innobackupex --apply-log --export /root/backups/2017-04-15_16-17-06/ #将多有表都导出单个可用的表 此命令回味每个innoDB表的表空间创建一个以.exp结尾的文件，这些以.exp结尾的文件就可以用于导入其他服务器； 2.导入表 1.要在mysql服务器上导入来自其他服务器的某innoDB表，需要现在当前服务器上创建一个根原表表结构一致的表，而后才能实现将表导入； mysql&gt; use mydatabase; mysql&gt; create table mytable (...) ENGINE=InnoDB; #通过show create mydatabase.mytable;查看之前的这个表创建时语句，然后再其他mysql上再创建一个即可； 2.然后将此表的表空间删除 mysql&gt; ALTER table mydatabase.mytable DISCARD TABLESPACE ~]# cd /data/mysql/mydatabase #进入mydatabase库 #可以看到mytable的frm文件还有，ibd文件被删除了 3.接下来，将来自于&quot;导出&quot;表的服务器的mytable表的mytable.ibd和mytable.exp文件复制到当前服务器的数据目录，然后使用如下命令将其&quot;导入&quot;； ~]# cd /data/mysql/mydatabase ~]# cp /root/backups/2017-04-15_16-17-06/mytable.exp mytable.ibd /data/mysql/mydatabase #将这两个文件复制到目录下即可 mysql&gt; ALTER table mydatabase.mytable IMPORT TABLESPACE; 还原注意事项：1.datadir目录必须为空。除非指定innobackupex --force-non-emptydirectorires选项指 定，否则--copy-backup选项不会覆盖； 2.在restore之前,必须shutdown MySQL实例，不能将一个运行中的实例 restore到datadir目录中 3.由于文件属性会被保留，大部分情况下需要在启动实例之前将文件的属主改 为mysql，这些文件将属于创建备份的用户 chown -R mysql:mysql /data/mysql 备份脚本1234567891011121314151617181920212223242526备份数据库脚本和计划任务： vi /usr/local/mysql/run/mysql_backup_full.sh #!/bin/bash #这个脚本用来对数据库作全备份 user=root password=123456 backupdir=/opt/mysql/backup/ #备份目录 #取一天前备份时生成的那个二进制日志文件 val_binlog=$(less /opt/mysql/binlog/mysql-binlog.index | awk -F&quot;/&quot; &apos;&#123;print $5&#125;&apos; |tail -n 2|head -n 1) #创建备份目录 [ ! -d $backupdir ] &amp;&amp; mkdir -p $backupdir #备份除Database|information_schema|mysql|test|performance_schema这几个数据库之外的所有库 mysql -u $user -p$password -e &quot;show databases&quot; | grep -Ev &quot;Database|information_schema|mysql|test|performance_schema&quot; |xargs mysqldump -u $user -p$password --lock-all-tables --routines --events --triggers --master-data=2 --flush-logs --databases &gt; $&#123;backupdir&#125;mysql_full_`date +%F-%H:%M:%S`.sql #删除两天前的备份文件，即保留三个备份文件 find $backupdir -type f -mtime +2 -exec rm -f &#123;&#125; \; #删除两天前的二进制日志文件,即保留三个二进制日志文件 mysql -u $user -p$password -e &quot;PURGE MASTER LOGS TO &apos;$val_binlog&apos;&quot;赋予权限： ~]# chmod 700 /usr/local/mysql/run/mysql_backup_full.sh #加上x执行权限 注意：此脚本里面包含了mysql的root密码，为了安全，设置700权限，其他人都不可访问创建任务计划： [root@www run]#crontab -e （创建计划任务） #分 时 日 月 周 用户名 命令 0 1 * * * cd /usr/local/mysql/run;./mysql_backup_full.sh #每天的凌晨1点进行数据备份和删除]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cobbler]]></title>
    <url>%2F2017%2F05%2F06%2FCobbler%2F</url>
    <content type="text"><![CDATA[在服务器很多的情况下，用U盘或者光盘安装时，就显得有点吃力了，虽然可以用PXE进行安装，但是PXE不支持UEFI所以现在更多使用Cobbler来实现自动化部署. Cobbler工作原理 系统自动安装之-cobbler之前写过PXE自动化安装的文档，但是PXE只支持BIOS，不支持UEFI:PXE系统自动化部署Cobbler可以同时支持BIOS和UEFI两种：基于PXE技术为基础的整合 BIOS+MBR：分区最多支持2T的UEFI+GPT：分区可以支持大于2T的分区 在之前的工作中，需要建立大于2T的分区时，PXE安装就不合适了 cobbler:具有图形化管理界面的工具cobbler是什么？ 实际上是把PXE技术用python代码做了封装，形成了相对完整的自动化安装， 但是实现PXE的原有的httpd，DHCP，tftp服务还是需要提前安装的。 Cobbler: 快速网络安装linux操作系统的服务，支持众多的Linux发行版：Red Hat、 Fedora、CentOS、Debian、Ubuntu和SuSE，也可以支持网络安装windows PXE的二次封装，将多种安装参数封装到一个菜单 Python编写 提供了CLI和Web的管理形式 安装cobbler：EPEL源安装包 cobbler 基于EPEL源 cobbler 服务集成 前面说过因为是基于PXE的,安装cobbler因为有依赖性，会自动安装下面的服务 PXE DHCP rsync Httpd DNS Kickstart syslinux tftp-server IPMI 电源管理 启动cobbler:依赖于httpd，要想启动cobbler,必须先启动httpd systemctl start httpd tftp dhcp systemctl start cobblerd 然后再检查cobbler环境 cobbler check cobbler的相关配置文件安装：yum install cobbler dhcp 配置文件目录 /etc/cobbler /etc/cobbler/settings : cobbler 主配置文件(下文会对该文件修改4行) /etc/cobbler/iso/: iso模板配置文件 /etc/cobbler/pxe: pxe模板文件 /etc/cobbler/power: 电源配置文件 /etc/cobbler/user.conf: web服务授权配置文件 /etc/cobbler/users.digest: web访问的用户名密码配置文件 /etc/cobbler/dhcp.template : dhcp服务器的的配置末班 /etc/cobbler/dnsmasq.template : dns服务器的配置模板 /etc/cobbler/tftpd.template : tftp服务的配置模板 /etc/cobbler/modules.conf : 模块的配置文件 数据目录 /var/lib/cobbler/config/: 用于存放distros，system，profiles 等信息配置文件 /var/lib/cobbler/triggers/: 用于存放用户定义的cobbler命令 /var/lib/cobbler/kickstart/: 默认存放kickstart文件 /var/lib/cobbler/loaders/: 存放各种引导程序 镜像目录 /var/www/cobbler/ks_mirror/: 导入的发行版系统的所有数据 /var/www/cobbler/images/ : 导入发行版的kernel和initrd镜像用于远程网络启动 /var/www/cobbler/repo_mirror/: yum 仓库存储目录 日志目录 /var/log/cobbler/installing: 客户端安装日志 /var/log/cobbler/cobbler.log : cobbler日志 cobbler命令介绍cobbler commands介绍 cobbler check 核对当前设置是否有问题 cobbler list 列出所有的cobbler元素 cobbler report 列出元素的详细信息 cobbler sync 同步配置到数据目录,更改配置最好都要执行下 cobbler reposync 同步yum仓库 cobbler distro 查看导入的发行版系统信息 cobbler system 查看添加的系统信息 cobbler profile 查看配置信息 cobbler重要的参数:及下面需要修改的4行内容/etc/cobbler/settings中重要的参数设置 default_password_crypted: &quot;$1$gEc7ilpP$pg5iSOj/mlxTxEslhRvyp/&quot; server: 192.168.34.17 next_server: 192.168.34.17 server：&lt;cobbler服务器的 IP 地址&gt; manage_dhcp: 1 manage_tftpd：1 pxe_just_once：1 cobbler环境检查：先启动cobbler服务再检查1.先启动cobbler服务，再用cobbler check 进行检查 执行Cobbler check命令会报如下异常 1 : The ‘server’ field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it. 2 : For PXE to be functional, the ‘next_server’ field in /etc/cobbler/ settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 3 : some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run ‘cobbler get-loaders’ to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a recent version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The ‘cobbler get-loaders’ command is the easiest way to resolve these requirements. 4 : change ‘disable’ to ‘no’ in /etc/xinetd.d/rsync 5 : comment ‘dists’ on /etc/debmirror.conf for proper debian support 6 : comment ‘arches’ on /etc/debmirror.conf for proper debian support 7 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to ‘cobbler’ and should be changed, try: “openssl passwd -1 -salt ‘random-phrase-here’ ‘your-password-here’” to generate new one 8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them Cobbler的8项报错解决方法错误信息都是在/etc/cobbler/settings文件改了4行，在下文体现 执行Cobbler check报错解决方式 第一个错误解决方法： 1.修改/etc/cobbler/settings文件中的server参数的值为提供cobbler服务的主机相 应的IP地址或主机名：384行，然后重新启动cobbler server: 192.168.34.107 2.修改/etc/cobbler/settings文件中的next_server参数的值为提供PXE服务的主机 相应的IP地址:272行，指定的tftp的服务器地址 next_server: 192.168.34.107 3.执行cobbler get-loaders和cobbler sync； 如果当前节点可以访问互联网，执行&quot;cobbler get-loaders&quot;命令即可； cobbler会自动通过互联网把最小化的系统启动文件下载下来放到 /var/lib/cobbler/loaders/下，再通过&quot;cobbler sync&quot;命令同步到/var/lib/tftpboot/下 4.cobbler认为是在centos6上，tftp服务是依赖于xinetd的，提示启动xinetd,在 这里，由于是在cnetos7上安装的，这项可以忽略 5.执行“chkconfig rsync on”命令即可 4,5,6项如果是在centos7上安装的cobbler是不需要修改也可以启动的 7.第7项是说安装的操作系统密码cobbler事先已经帮忙设置好了，但是不安全，需要自己 去修改一个自定义的密码(通过openssl passwd -1)生成：101行 default_password_crypted：修改成自己设置的密码 备注：在这个提示里，还有一项建议修改，之前用PXE的时候，搭建的DHCP服务，dhcpd.conf 文件时通过模板生成的，但是在cobbler中，可以通过colbber来生成，但是需要改 /etc/cobbler/settings一项配置：242行 manage_dhcp: 0 改成 manage_dhcp: 1 再通过cobbler自带的dhcp模板：/etc/cobbler/dhcp.template，生成dhcpd.conf 只需要把这个模板改一下就行了，而不用想PXE那样通过模板生成dhcpd.conf文件 把dhcp.template里的网段地址改一下 subnet 192.168.34.0 netmask 255.255.255.0 { option subnet-mask 255.255.255.0; range dynamic-bootp 192.168.34.20 192.168.34.100; 再通过cobbler sync重新生成/etc/dhcp/dhcpd.conf,并且会开启DHCP服务 上面的报错全部解决之后，且httpd,tftp，dhcp,cobbler都启动之后，实际上就已经具备了雏形了/var/lib/tftpboot的目录结构:上面的第三步完成后就生成下面的所有文件了[root@mini7-1 tftpboot]#tree /var/lib/tftpboot /var/lib/tftpboot ├── boot │ └── grub │ └── menu.lst ├── etc ├── grub │ ├── efidefault │ ├── grub-x86_64.efi │ ├── grub-x86.efi │ └── images -&gt; ../images ├── images ├── images2 ├── memdisk ├── menu.c32 ├── ppc ├── pxelinux.0 ├── pxelinux.cfg │ └── default ├── s390x │ └── profile_list └── yaboot 接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘(centos6&amp;centos7)cobbler命令的选项： cobbler &lt;distro|profile|system|repo|image|mgmtclass|package|file&gt; ... [add|edit|copy|getks*|list|remove|rename|report] [options|--help] cobbler &lt;aclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink&gt; [options|--help] 这里用import选项将6和7的光盘导入cobbler的主机上 mount /dev/sr0 /mnt/ ---&gt;挂载centos7光盘 mount /dev/sr1 /media ---&gt;挂载centos6光盘 cobbler import --path=/mnt/ --name=Centos-7.5-x86_64 --arch=x86_64 cobbler import --path=/media/ --name=Centos-6.10-x86_64 --arch=x86_64 cobbler会把光盘拷贝到/var/www/cobbler/下分开存放，目录结构如下 [root@mini7-1 cobbler]#tree -d /var/www/cobbler /var/www/cobbler ├── images │ ├── Centos-6.10-x86_64 │ └── Centos-7.5-x86_64 ├── ks_mirror │ ├── Centos-6.10-x86_64 │ │ ├── EFI │ │ │ └── BOOT │ │ ├── images │ │ │ └── pxeboot │ │ ├── isolinux │ │ ├── Packages │ │ └── repodata │ ├── Centos-7.5-x86_64 │ │ ├── EFI │ │ │ └── BOOT │ │ │ └── fonts │ │ ├── images │ │ │ └── pxeboot │ │ ├── isolinux │ │ ├── LiveOS │ │ ├── Packages │ │ └── repodata │ └── config ├── links │ ├── Centos-6.10-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-6.10-x86_64 │ └── Centos-7.5-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-7.5-x86_64 ├── localmirror ├── misc ├── pub ├── rendered ├── repo_mirror └── svc 拷贝完，cobbler sync再同步一次 然后cobbler会把/var/lib/tftpboot/pxelinux.cfg/default文件自动更新，生成新的菜单 DEFAULT menu PROMPT 0 MENU TITLE Cobbler | http://cobbler.github.io/ TIMEOUT 200 TOTALTIMEOUT 6000 ONTIMEOUT local LABEL local MENU LABEL (local) MENU DEFAULT LOCALBOOT -1 LABEL Centos-6.10-x86_64 kernel /images/Centos-6.10-x86_64/vmlinuz MENU LABEL Centos-6.10-x86_64 append initrd=/images/Centos-6.10-x86_64/initrd.img ksdevice=bootif lang= kssendmac text ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-6.10-x86_64 ipappend 2 LABEL Centos-7.5-x86_64 kernel /images/Centos-7.5-x86_64/vmlinuz MENU LABEL Centos-7.5-x86_64 append initrd=/images/Centos-7.5-x86_64/initrd.img ksdevice=bootif lang= kssendmac text ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-7.5-x86_64 ipappend 2 MENU end 此时，就可以用cobbler实现自动化安装了，但是不能自定义ks应答文件安装，下面会讲解如何自定义cobbler的应答文件 Cobbler中自定义应答文件之前在PXE安装时，是自定义的kickstart应答文件，在cobbler中如何实现？ 1.在cobbler中，应答文件是放在/var/lib/cobbler/kickstarts/中 2.把之前制作的ks6-mini.cfg，ks7-mini.cfg拷贝到此目录，但是拷贝完，但cobbler是无 法识别这些应答文件是对应的那个发行版本的，所以要绑定 3.将自定义的应答文件和安装版本进行绑定 4.这两个应答文件有一项需要修改 即url --url=这一项，要改成cobbler的yum源路径，$tree 这里只显示ks6-mini.cfg的详细信息 install url --url=http://192.168.34.103/centos/6/os/x86_64/ (PXE下的源路径) #httpd的yum源路径，要改成$tree 或者改成具体的地址：即光盘拷贝到cobbler的具体路径 http://192.168.34.107/cobbler/ks_mirror/Centos-6.10-x86_64/ lang en_US.UTF-8 keyboard us text #纯文本安装 reboot #安装完重启 network --onboot yes --device eth0 --bootproto dhcp --noipv6 rootpw --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt JjA57WrZO0 firewall --service=ssh 关闭防火墙 authconfig --enableshadow --passalgo=sha512 selinux --enforcing 关闭selinux timezone Asia/Shanghai 时区信息 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work clearpart --all 清空分区信息 zerombr 清空mbr #自定义的分区信息 part /boot --fstype=ext4 --size=1024 part / --fstype=ext4 --size=50000 part /data --fstype=ext4 --size=30000 part swap --size=2048 #自定义的分区信息 %packages @core %end 只安装最基本的核心包，后面也可以加上安装后脚本 将KS和OS关联，生成启动新的菜单自定义的应答文件的绑定、删除、重命名、显示菜单栏对应的ks应答文件信息 在cobberl中 distro中记录的是cobbler中安装的发型版本对应的原文件的 [root@mini7-1 kickstarts]#cobbler distro list Centos-6.10-x86_64 Centos-7.5-x86_64 在cobberl中 profile是对应的各个发型版本的安装方法，就是安装启动界面的选择菜单栏，有多少个 就对应多少个菜单栏：如下图只有两个 [root@mini7-1 kickstarts]#cobbler profile list Centos-6.10-x86_64 Centos-7.5-x86_64 将自定义的应答文件和安装版本进行绑定：cobbler profile命令绑定 将ks6-mini.cfg和centos6进行绑定 cobbler profile add --name=centos-6.10-x86_64_mini --distro=Centos-6.10-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks6-mini.cfg cobbler profile add --name=centos-7.5-x86_64_mini --distro=Centos-7.5-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks7-mini.cfg 也可以删除应答文件： cobbler profile remove --name=Centos-6.10-x86_64 cobbler profile remove --name=Centos-7.5-x86_64 也可以修改带单名 cobbler profile rename --name=Centos-7.5-x86_64 --newname=centos-7.5-x86_64_desktop 查看菜单项对应的具体是哪个应答文件信息 cobbler profile report --name=centos-7.5-x86_64_mini /var/lib/tftpboot/pxelinux.cfg/default会自动生成新的菜单项，从cobbler profile list,也可以看出来 [root@mini7-1 tftpboot]#cobbler profile list Centos-6.10-x86_64 Centos-7.5-x86_64 centos-6.10-x86_64_mini centos-7.5-x86_64_mini cobbler的web管理实现此外cobbler是带有web管理界面的，不过需要安装web界面的包 yum install cobbler-web -y 配置文件： [root@mini7-1 kickstarts]#rpm -qf cobbler-web /etc/httpd/conf.d/cobbler_web.conf cobbler-web是经过http协议的，所以 安装完，需要重启httpd服务 然后看到对应的是443端口启动了 登录界面是，因为cobbler-web是https加密的/etc/cobbler/modules.conf 验证方法;/etc/cobbler/users.digest 记录的用户增加用户]]></content>
      <categories>
        <category>系统安装</category>
      </categories>
      <tags>
        <tag>运维，linux，windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql读写分离]]></title>
    <url>%2F2017%2F03%2F22%2Fmysql%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[Mysql的读写分离 ProxySQL官方网站:ProxySQL&amp;安装手册Mycat:基于Cobar研发的Mycat 为什么要用到读写分离器(负载均衡器)？ 1.网站的架构由最初的单机站点发展到大规模站点，达到了性能瓶颈，需要向外扩展以实现更高的性能需求，如mysql的主从复制集群 2.mysql的主从复制虽然好用，但是不可避免的带来了读写语句是如何负载均衡的问题； 即： 客户端请求来了之后，它是如何将请求平均负载的问题，这时可以在主从复制前端加一个调度器，而且这个调度器必须是七层调度能够 分析并精确理解请求语句是读请求还是写请求，如果是读请求，这个调度器还可以通过负载均衡的方式发送给后端多个从服务器进行负 载均衡；这种代理就是mysql的七层反向代理，也成为mysql的r/w spliter：读写分离器； 3.数据库的读写分离有效减小了主数据库的压力，如果没有读写分离器只能代码中标记哪个是读数据库哪些是写数据库，耦合性较差； 4.读写分离器(语句路由软件)可以实现对数据库的读写进行分离，以扩展数据库的性能 5.mysql数据库的写操作遇到瓶颈时，双主模型对写操作不会有任何提升，而是做数据库切分，将数据库表拆分到多个数据库上. 6.NewSQL(例如TiDB)本身是分布式的，背后由多台服务器支持读写操作,而且完全在 协议上支持mysql. proxysql实现读写分离架构缓存层分析: 1.因为对mysql而言，它是有query_cache查询缓存的，当通过proxysql调度到后端不同的从服务器负责读操作时，那么为了使得保存在 每一台的query_cache能够被命中，就需要调度时是基于取模或者一致性hash的，但是这样会损坏负载均衡效果的； 2.所以一般在应用程序侧需要加一个memcached或者redis作为缓存层的； 如上图示架构 3.虽然像LVS这种四层调度器不能识别mysql的read和write七层操作，不能代理前端的proxysql的操作，但是在后端所有slave前却可以 加一层LVS，因为： 1.尽管proxysql也有调度功能，但是没有LVS的强大 2.LVS加在这一层，即使它不是七层的但因为后端都是Slave节点，不用区分读写了! proxysql功能： 1.是一个高性能的mysql代理服务器，MYSQL中间件，有官方版和percona版； 2.多种方式的的读/写分离 3.定制基于用户、基于schema、基于语句的规则对SQL语句进行路由 4.缓存查询结果 5.后端节点监控 数据分发路由机制， proxysql只能对读做分发，依然不能对写做分发，真正能够对写做分发，需要语句路由，如mysql的分片框架，能够实现写的时候帮 忙写到一台只负责写的服务器上，读的时候能够从所有服务去查 ProxySQL安装基于YUM仓库安装 vim /etc/yum.repos.d/proxysql.repo [proxysql_repo] name= ProxySQL YUM repository baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever gpgcheck=1 gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key 基于RPM下载安装：https://github.com/sysown/proxysql/releases ProxySQL组成 服务脚本：/etc/init.d/proxysql 配置文件：/etc/proxysql.cnf 主程序：/usr/bin/proxysql proxysql使用： proxysql本身是个小型的数据库，启动后在数据库中配置即可 ProxySQL的读写分离实现1.实现读写分离前，先实现主从复制 注意：slave节点需要设置read_only=1 如果不加，proxysql是无法判断该服务器是负责读还是负责写的 2.启动ProxySQL：service proxysql start 启动后会监听两个默认端口 6032：ProxySQL的管理端口，也就是配置端口，在数据库中配置即可 6033：ProxySQL是读写分离的调度服务器发布在外网的端口 使用mysql客户端连接到ProxySQL的管理接口6032，默认管理员用户和密码都 是admin： mysql -uadmin -padmin -P6032 -h127.0.0.1 3.配置proxysql 在main和monitor数据库中的表： 1.runtime_开头的是运行时的配置，不能修改；即生效的表 2.mysql_开头的是配置的表，配置完生效的就是runtime_开头的表了 3.修改mysql_开头的表后必须执行LOAD … TO RUNTIME才能加载到RUNTIME生效； 4.执行save … to disk将配置持久化保存到磁盘 4.向ProxySQL中添加MySQL节点，以下操作不需要use main也可成功 MySQL &gt; select * from mysql_servers; MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;10.10.0.5&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;10.10.0.6&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,&apos;10.10.0.7&apos;,3306); MySQL &gt; load mysql servers to runtime; MySQL &gt; save mysql servers to disk; 意思是先把所有的服务器节点都加入到一个主机组中，然后proxysql会根据my.cnf配置文件中的read-only,自动区分哪些是只读的，哪些是只写的数据库服务器 5.配置监控账号： a.在主节点上，创建监控账号 grant replication client on *.* to monitor@&apos;10.10.0.%&apos; identified by &apos;root123&apos;; 备注：replication client权限是负责监控的，和replication slave是不同的权限 b.Proxysql上配置监控 实际上是保存在global_variables表中，可以查看是否修改成功 MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;; MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;; c.使global_variables表生效 MySQL [mian]&gt; load mysql variables to runtime; MySQL [mian]&gt; save mysql variables to disk; 6.监控模块的指标保存在monitor库的log表中 MySQL [monitor]&gt; use monitor MySQL [monitor]&gt; select * from mysql_server_ping_log; 类似于ping命令，测试所有的数据库是不是连接成功的 mysql&gt; select * from mysql_server_connect_log; mysql&gt; select * from mysql_server_read_only_log; mysql&gt; select * from mysql_server_replication_lag_log; 查看read_only和replication_lag的监控日志 7.设置分组信息和读写规则 main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20 插入读写组的编号： insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;); +------------------+------------------+---------+ | writer_hostgroup | reader_hostgroup | comment | +------------------+------------------+---------+ | 10 | 20 | test | +------------------+------------------+---------+ 生效和保存： MySQL [monitor]&gt; load mysql servers to runtime; MySQL [monitor]&gt; save mysql servers to disk; 再次查看 select hostgroup_id,hostname,port,status,weight from mysql_servers; +--------------+-----------+------+--------+--------+ | hostgroup_id | hostname | port | status | weight | +--------------+-----------+------+--------+--------+ | 10 | 10.10.0.5 | 3306 | ONLINE | 1 | | 20 | 10.10.0.6 | 3306 | ONLINE | 1 | | 20 | 10.10.0.7 | 3306 | ONLINE | 1 | +--------------+-----------+------+--------+--------+ 8.创建用于测试读写分离的账号 主节点上创建访问用户： grant all on *.* to sqluser2@&apos;10.10.0.%&apos; identified by &apos;root1234&apos;; 在ProxySQL配置，将用户sqluser添加到mysql_users表中： insert into mysql_users(username,password,default_hostgroup)values(&apos;sqluser2&apos;,&apos;root1234&apos;,10); 生效和保存： MySQL [monitor]&gt; load mysql users to runtime; MySQL [monitor]&gt; save mysql users to disk; 此时通过mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033可以测试 创建和读取数据库信息，但是读写没有分离出来 9.配置路由规则，实现读写分离 与规则相关的表：mysql_qeury_rules 插入路由规则,实现读写分离的规则 insert into mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply) VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1); 分析： 将select语句分离到20的读组中, 但是在select语句中有一个特殊语句SELECT...FOR UPDATE它会申请写锁，应该属于写 组，所以应该排除在读组之外，放到写组中，放在前面是先匹配到后就放到写组了 (类似于iptables规则，谁在前，谁生效不看接下来的规则) 生效和保存到磁盘： load mysql query rules to runtime; save mysql query rules to disk; 10.用sqluser2测试读写分离效果 读： mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos; 因为是读操作会在2和3上随机选择 写： mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos; 事务是非select开头的，所以查询的都是1上 11.路由的信息：查询stats库中的stats_mysql_query_digest表 MySQL [monitor]&gt; use stats MySQL [stats]&gt; SELECT hostgroup hg,sum_time, count_star, digest_text FROM stats_mysql_query_digest ORDER BY sum_time DESC; +----+----------+------------+-----------------------------------+ | hg | sum_time | count_star | digest_text | +----+----------+------------+-----------------------------------+ | 10 | 100685 | 5 | select @@server_id | | 10 | 39916 | 2 | select @@server_id | | 20 | 25787 | 23 | select @@server_id | +----+----------+------------+-----------------------------------+ 可以看到通过不同的命令具体被调度到哪个数据上的信息 复制的问题和解决方案1. 数据损坏或丢失 Master： MHA + semi repl Slave： 重新复制 2. 混合使用存储引擎 MyISAM：不支持事务 InnoDB： 支持事务 3. 不惟一的server id 重新复制 4. 复制延迟 需要额外的监控工具的辅助 一从多主:mariadb10版后支持 多线程复制：对多个数据库复制]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ高可用集群]]></title>
    <url>%2F2017%2F03%2F12%2FRabbitMQ%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[RabbitMQ分布式集群架构和高可用性(HA) 1.引言： 1.Rabbitmq在分布式系统当中用于连接各组件的，整个系统必然受到影响，因此RabbitMQ的高可用性就是必然要实现的； 2.Rabbitmq的HA实现有两种方案： 1.普通模式 1.默认的集群模式，以两个节点（rabbit01、rabbit02）为例来进行说明。对于Queue来说，消息实体只存在于其中一个节点 rabbit01（或者rabbit02），rabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构。当消息进入rabbit01节点的 Queue后，consumer从rabbit02节点消费时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把A中的消息实体取出 并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理 Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。当rabbit01节点故障后，rabbit02节点 无法取到rabbit01节点中还未消费的消息实体。如果做了消息持久化，那么得等rabbit01节点恢复，然后才可被消费；如果 没有持久化的话，就会产生消息丢失的现象; 2.它只是一种联合机制，其实就是一种树状结构将它的负载、承载的队列等分摊到多个节点上去，它是一种负载均衡机制，而不是HA的机制； 2.镜像模式 1.将需要消费的队列变为镜像队列，存在于多个节点，这样就可以实现RabbitMQ的HA高可用性。作用就是消息实体会主动在镜像 节点之间实现同步，而不是像普通模式那样，在consumer消费数据时临时读取。缺点就是，集群内部的同步通讯; 2.此模式下有任何一台服务器宕机不会影响正常的生产和消费，但集群内部的通讯会占用较大的带宽； 3.LB负载均衡集群 1.任何一个rabbitmq节点故障时，通过其他节点也可以正常访问数据，但是这需要前端有个路由器能够在节点故障时， 完成自动切换，这个LB可以是Haproxy; 2.Haproxy对多个rabbitmq节点做负载均衡，把对5672端口的访问代理至后端的rabbitmq集群，而且还可以对后端 rabbitmq集群做健康状态检测； 3.节点类型 1.RAM node: 内存节点将所有的队列、交换机、绑定、用户、权限和vhost的元数据定义存储在内存中，好处是可以使得像交换机和队列声明等 操作更加的快速; 2.Disk node: 将元数据存储在磁盘中，单节点系统只允许磁盘类型的节点，防止重启RabbitMQ的时候，丢失系统的配置信息; 问题说明： RabbitMQ要求在集群中至少有一个磁盘节点，所有其他节点可以是内存节点，当节点加入或者离开集群时，必须要将该变更通知 到至少一个磁盘节点。如果集群中唯一的一个磁盘节点崩溃的话，集群仍然可以保持运行，但是无法进行其他操作（增删改查），直到节点恢复。 解决方案： 设置两个磁盘节点，至少有一个是可用的，可以保存元数据的更改 4.Erlang Cookie 1.Erlang Cookie是保证不同节点可以相互通信的密钥，要保证集群中的不同节点相互通信必须共享相同的Erlang Cookie。具体的目录存放在/var/lib/rabbitmq/.erlang.cookie 2.说明： 这就要从rabbitmqctl命令的工作原理说起，RabbitMQ底层是通过Erlang架构来实现的，所以rabbitmqctl会启动Erlang节点， 并基于Erlang节点来使用Erlang系统连接RabbitMQ节点，在连接过程中需要正确的Erlang Cookie和节点名称，Erlang节点 通过交换Erlang Cookie以获得认证。 1.RabbitMQ Cluster配置1.准备三台主机和时间同步 ~]# vim /etc/hosts 192.168.1.105 node1 192.168.1.106 node2 192.168.1.107 node3 ~]# hostnamectl set-hostname node1 ~]# hostnamectl set-hostname node2 ~]# hostnamectl set-hostname node3 注意: 必须保持主机名和启动的rabbitmq-server时的status显示的主机名是匹配的，否则搭建集群时必然会出错； 2.在node1上执行 将node1节点的/var/lib/rabbitmq/.erlang.cookie复制到其它集群节点，因为各集群节点之间通讯必须共享相同的erlang-cookie，这就是rabbitmq底层的工作原理; ~]# systemctl start rabbitmq-server #启动生成cookie ~]# rabbitmqctl cluster_status Cluster status of node &apos;rabbit@node1&apos; ... [{nodes,[{disc,[&apos;rabbit@node1&apos;]}]}, {running_nodes,[&apos;rabbit@node1&apos;]}, {cluster_name,&lt;&lt;&quot;rabbit@node1&quot;&gt;&gt;}, {partitions,[]}] ...done. #这个cluster_name就是node2、node3加入时的集群名称 ~]# scp /var/lib/rabbitmq/.erlang.cookie node2:/var/lib/rabbitmq/ ~]# scp /var/lib/rabbitmq/.erlang.cookie node3:/var/lib/rabbitmq/ 注意： 此文件是在rabbitmq-server服务第一次启动是才会生成的，并且些文件的权限为400，属主和属组为rabbitmq。所以我们需要 在node1上面启动一次rabbitmq-server服务，再执行复制; 3.在node2和node3执行下面的命令： ~]# chown rabbitmq:rabbitmq /var/lib/rabbitmq/.erlang.cookie #确保属主属组都是rabbitmq ~]# systemctl start rabbitmq-server #启动node2、node3上的rabbitmq-server 4.将node2和node3加入到集群，分别在node2和node3执行下面命令: ~]# rabbitmqctl stop_app ~]# rabbitmqctl join_cluster rabbit@node1 ~]# rabbitmqctl start_app 5.验证集群配置，以node2为例： ~]# rabbitmqctl cluster_status Cluster status of node &apos;rabbit@node2&apos; ... [{nodes,[{disc,[&apos;rabbit@node1&apos;,&apos;rabbit@node2&apos;,&apos;rabbit@node3&apos;]}]}, {running_nodes,[&apos;rabbit@node1&apos;,&apos;rabbit@node2&apos;,&apos;rabbit@node3&apos;]}, {cluster_name,&lt;&lt;&quot;rabbit@node1&quot;&gt;&gt;}, {partitions,[]}] ...done. #此时node2加入的就是node1集群，集群内的成员分别是node1、node2、node3 6.集群内的所有节点启用rabbitmq_management插件： ~]# rabbitmq-plugins enable rabbitmq_management #启用management插件 ~]# systemctl restart rabbitmq-server &amp;&amp; systemctl enable rabbitmq-server 7.配置指定虚拟主机的所有队列为镜像模式 ~]# rabbitmqctl set_policy -p /myhost1/test2 ha-all &quot;^\.*&quot; &apos;{&quot;ha-mode&quot;:&quot;all&quot;}&apos; #配置指定虚拟主机的所有队列为镜像模式，-p指定虚拟主机，不指定默认为/这样配置后我们将会有两个镜像节点， 只要保障有一台rabbitmq正常工作那么集群就可以提供服务； ~]# rabbitmqctl list_policies Listing policies ... / ha-all all ^\\.* {&quot;ha-mode&quot;:&quot;all&quot;} 0 ...done. #验证 基于HAProxy+Keepalived的LB集群实现RabbitMQ负载均衡备注： 1.为了实现我们的RabbitMQ集群高可用，我们需要在前端加一个HAProxy来代理RabbitMQ访问，另外防止HAProxy单节点故障，所以 我们使用HAProxy+Keepalived+RabbitMQ的方案来实现整套集群环境； 2.将HAProxy和Keepalived部署在node1和node2上面，并使用192.168.1.200为VIP，在node1和node2上面行以下命令安装 1.安装Haprpxy和keepalived ~]# yum install haproxy keepalived -y 2.node1的keepalived配置 ~]# vim /etc/keepalived/keepalived.conf global_defs { router_id node1 } vrrp_script chk_haproxy { script &quot;/etc/keepalived/haproxy_check.sh&quot; interval 2 weight 20 } vrrp_instance VI_1 { state MASTER interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass admin123 } track_script { chk_haproxy } virtual_ipaddress { 192.168.1.200 dev ens33 label ens33:1 } } 3.node1的keepalived配置 ~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id node2 } vrrp_script chk_haproxy { script &quot;/etc/keepalived/haproxy_check.sh&quot; interval 2 weight 20 } vrrp_instance VI_1 { state BACKUP interface eth0 virtual_router_id 51 priority 90 advert_int 1 authentication { auth_type PASS auth_pass admin123 } track_script { chk_haproxy } virtual_ipaddress { 192.168.1.200 dev ens33 label ens33:1 } } 4.haproxy_check.sh脚本配置 ~]# vim /etc/keepalived/haproxy_check.sh #!/bin/bash A=`ps -C haproxy --no-header | wc -l` if [ $A -eq 0 ];then haproxy -f /etc/haproxy/haproxy.cfg sleep 2 if [ `ps -C haproxy --no-header | wc -l` -eq 0 ];then pkill keepalived fi fi ~]# chmod a+x /etc/keepalived/haproxy_check.sh #加执行权限 5.HAPorxy配置文件（node1和node2相同） ~]# vim /etc/haproxy/haproxy.cfg global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/stats defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 4000 listen rabbitmq_cluster bind 192.168.1.200:5670 mode tcp option tcplog timeout client 3h timeout server 3h timeout connect 3h balance roundrobin server node1 192.168.1.105:5672 check inter 5000 rise 2 fall 3 server node2 192.168.1.106:5672 check inter 5000 rise 2 fall 3 server node3 192.168.1.107:5672 check inter 5000 rise 2 fall 3 listen rabbitmq_cluster bind 192.168.1.200:15670 balance roundrobin server node1 192.168.1.105:15672 check inter 5000 rise 2 fall 3 server node2 192.168.1.106:15672 check inter 5000 rise 2 fall 3 server node3 192.168.1.107:15672 check inter 5000 rise 2 fall 3 备注： 1.192.168.1.200:5670 供product和consumer来进行选择，由于5672端口已经默认使用，这里选择5670端口； 2.mode tcp #mode类型为tcp 3.balance roundrobin: 使用roundrobin的原因在于一个rabbitmq节点down之后，可以被调度到其他节点 6.启动服务 ~]# systemctl start haproxy keepalived -y 7.测试 登录http://192.168.1.200:15670查看集群信息 –rabbitmq集群 附录：rabbitmq集群常用命令1.将node2rabbitmq移除集群 node2: rabbitmqctl stop_app node2: rabbitmqctl reset (force_reset 强制重置) node2: rabbitmqctl start_app 2.将node3rabbitmq由磁盘节点转换成内存节点 node3: rabbitmqctl stop_app node3: rabbitmqctl change_cluster_node_type ram node3: rabbitmqctl start_app 3.远程移除节点,在node1上移除node3节点 node1: rabbitmqctl stop_app node1: rabbitmqctl forget_cluster_node rabbit@node3 4.更改节点储存类型: node1: rabbitmqctl stop_app node1: rabbitmqctl change_cluster_node_type disc|ram node1: rabbitmqctl start_app 5.查看集群的用户 node1: rabbitmqctl list_users 6.重启集群,(最后一个关闭的集群最先启动,如果不知道可使用以下命令) rabbitmqctl force_boot rabbit-server start 7.rabbitmq内存使用控制(默认使用物理内存的40%,到达40会做gc,设置为0关闭), rabbitmqctl set_vm_memory_high_watermark 0]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql存储引擎、事务和锁]]></title>
    <url>%2F2017%2F02%2F20%2Fmysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E3%80%81%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81%2F</url>
    <content type="text"><![CDATA[mysql的存储引擎 –存储引擎对比 在mysql5.1之前默认的存储引擎是MYISAM;在mysql5.5以后默认存储引擎是InnoDB 主要区别： InnoDB支持事务功能，而MYISAM不支持； MariaDB中使用的是&apos;XtraDB&apos;,它是对InnoDB的改进增强版，而不是使用InnoDB; 存储引擎： 其实存储引擎在mysql中也叫表类型，如创建表时可以使用create table...ENGINE= &apos;存储引擎type&apos;来指定使用的存储引擎类型，但在mysql不建议交叉使用不同的存储引擎 类型，因为不同的存储引擎它们所支持的特性是各不相同的； 如何选择存储引擎： 1.因为MyISAM相对简单所以在效率上要优于InnoDB.如果系统读多，写少。对原子性要求低。那么MyISAM最好的选择。 且MyISAM恢复速度快。可直接用备份覆盖恢复。 2.如果系统读少，写多的时候，尤其是并发写入高的时候。InnoDB就是首选了。 3.两种类型都有自己优缺点，选择那个完全要看自己的实际情况； InnoDB存储引擎特点InnoDB的特性总结: 1.行级锁 读写阻塞与事务隔离级别相关； 行级锁意味着一旦两个线程争用同一个资源时，它就需要对数据进行加锁，而且加锁的力度是行row级的； 2.支持事务，适合处理大量短期事务 1.InnoDB是mysql新版本默认的存储引擎，也是最重要最广泛使用的存储引擎； 2.它主要被设计用来处理大量短期事务的：短期事务大部分都是正常提交很少回滚的； 3.InnoDB的性能和自动崩溃恢复的特性： 比如mysql运行期间因为断电等原因会造成很多数据还在内存中还未写到磁盘上，这对数据来说是绝对不允许的， InnoDB本身是支持自动崩溃恢复的，所以使得它在很多非事务性存储引擎中也很流行，而MYISAM确无法完成崩溃 后自动恢复需要手动进行进行(即使手动进行也可能造成数据不一致的)； 3.读写阻塞与事务隔离级别相关 4.可缓存数据和索引 5.支持聚簇索引 索引：聚集索引、辅助索引 InnoDB表还支持&quot;自适应hash索引&quot; 这就意味着自己没办法显示创建的,而是由InnoDB在内部自行维护的； 6.崩溃恢复性更好 7.支持MVCC高并发 并发：MVCC,间隙锁 基于MVCC实现并发控制控制等功能 1.InnoDB采用了MVCC(多版本并发控制机制)来支持较高并发 2.基于MVCC支持四个事务隔离级别，默认级别叫做可重读的功能(REPEATABLE READ) 3.基于间隙锁策略防止幻读的出现; 8.从MySQL5.5后支持全文索引 9.从MySQL5.5.5开始为默认的数据库引擎 10.数据存储：表空间 InnoDB使用表空间的方式有两种： 1.把所有InnoDB表的数据和索引放置于同一个表空间中； 即属于不同库的表可以放在一个表空间中，这样一来备份恢复就很不方便了； 这个表空间文件是在：datadir定义的目录下 ibddata1,ibddata2,... 2.每个表单独使用一个表空间存储表的数据和索引； 启用：innodb_file_per_table=ON #这个配置就是每个表使用单独的表空间 正是因为每个表单独使用一个表空间，它的众多高级特性才得以实现，比如单表备份(导入导出)功能； 两类文件放在数据库独立目录中： 数据文件(存储数据和索引)：tb_name.ibd 表格式定义：tb_name.frm (format:每张表都有字段每个字段都有自己的格式) 11.性能：通过预读操作自适应hash索引、插入缓存区 12.备份：支持热备、在线备份(使用xtrabackup工具) MyISAM存储引擎特点MyISAM特性： 1.不支持事务 MyISAM早期被设计用来专门服务于数据仓库，即较少的插入操作但较多的读操作；所以它不是特别适用于在线事务处理的应用场景； 适用场景： 只读(或者写较少)、表较少(可以忍受崩溃后的长时间的修复操作) Aria：crash-safe 2.表级锁定 ---&gt;表级锁会造成不能并发访问，行级锁不会 读写相互阻塞，写入不能读，读时不能写 加锁和并发：表级锁 MyISAM的锁力度是表级别的，哪怕只是改表中的一行数据他也会把整张表锁住；而锁力度比较粗糙，这样就意味着它的竞争态是非常容易出现的(锁竞争)； 3.只缓存索引,不支持数据缓存 4.不支持外键约束 5.不支持聚簇索引，支持全文索引 非聚集索引、延迟更新索引键 MyISAM支持全文索引(Fulltext index),支持直接对表数据进行压缩,支持空间函数(GIS),但是不支持事务,不支持行row级锁； 6.读取数据较快，占用资源较少 7.不支持MVCC（多版本并发控制机制）高并发 8.崩溃恢复性较差：因为不支持事务 修复：手工或者自动修复，但可能丢失数据 MyISAM在崩溃后无法安全恢复，所以在mariadb中对MyISAM做了改进，改进后的存储引擎叫做Aria;Aria支持崩溃后安全恢复； 9.MySQL5.5.5前默认的数据库引擎 10.MyISAM引擎文件：数据和索引放在不同文件，保证了安全性 tbl_name.frm 表格式定义 tbl_name.MYD 数据文件 tbl_name.MYI 索引文件 #每张表有三个文件 管理存储引擎查看mysql支持的存储引擎 show engines; 查看当前默认的存储引擎 show variables like &apos;%storage_engine%&apos;; MySQL [(none)]&gt; show variables like &apos;%storage_engine%&apos;; +----------------------------+--------+ | Variable_name | Value | +----------------------------+--------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | storage_engine | InnoDB | +----------------------------+--------+ 设置默认的存储引擎 vim /etc/my.conf [mysqld] default_storage_engine= InnoDB 查看库中所有表使用的存储引擎 show table status from db_name; 查看库中指定表的存储引擎 show table status like &apos; tb_name &apos;; 如：MySQL [(none)]&gt; show table status from hellodb\G; 或者 MySQL [hellodb]&gt; use hellodb; MySQL [hellodb]&gt; show table status\G; #判断hellodb库中表的存储引擎类型 show create table tb_name; 设置表的存储引擎： CREATE TABLE tb_name(... ) ENGINE=InnoDB; #创建表时指定存储引擎类型为InnoDB; ALTER TABLE tb_name ENGINE=InnoDB; #修改表的存储引擎为InnoDB mysql中的锁和并发控制实现锁的策略：加锁是为了安全，但是会影响并发访问 对于mysql来说它是支持多用户创建线程同时访问mysql中的数据的;但是mysql中一个数据库的数据集只有一个； 1.并发访问控制机制： 1.当A用户正在修改file1文件时，B用户是否可以读file1文件中的数据呢？这就叫资源竞争的位置； 2.mysql也是一样，它是多用户的建立多会话的，A线程请求对table1中的数据进行修改时，B线程的会话是否能查table1中的数据呢？ 3.所以对于mysql而言它也必然面临并发访问控制时对数据集的资源竞争以及资源如何分配的问题，这个机制就称为并发访问控制； 4.像这样多个进程访问同一个数据都不可避免的面临并发访问控制的问题，但是mysql对资源竞争是通过读写锁来实现的； 2.锁：又分为读锁和写锁 1.读锁：共享锁 1.共享锁意思是一个线程对资源请求施加读锁以后其他线程可以继续进行读操作，所以一个资源上可以被多次请求施加读锁； 2.多个读互不阻塞,配合myisam进行温备适用于数据库备份 2.写锁：独占锁 1.独占锁意思是当一个资源被一个线程请求施加写锁时，其他线程既不能施加写锁也不能施加读锁，写锁也叫排它锁； 2.一个写锁会阻塞其它读和它锁牺牲并发量来换取安全性,only master can； 在实际数据系统当中，几乎每时每刻只要有用户访问都会发生锁的操作，于是锁粒度就至关重要了； 3.锁粒度： 1.如果一个锁粒度越精细，它的并发性就会越好； 2.比如一个表中有100w行，如果线程请求的是写锁的是整张表，那么其他任何线程都无法访问了；如果锁的粒度是按行来锁的话，那么多个线程对这个表中的不同行施加写锁是互相不影响的，就会加大并发访问； 3.锁粒度常用的有两种： 1.表级锁 表级锁是mysql中的基本策略，也是开销最小的锁策略同时它也是粒度最粗糙 的，在在线事务处理的情况下、读写一样多时势必会导致读饥饿或者写饥饿； MyISAM就是表级锁； 2.行级锁 行级锁的设计的主要目的是为了最大程度的支持并发处理操作，InnoDB就是行级锁； 4.锁策略： 1.要注意的是加锁本身是消耗资源的，所以锁粒度不是越精细越好的，这就意味需要采用较好的锁策略在锁的开销和数据安全之间保持一种平衡； 2.mysql中的每一种存储引擎都可以实现自己的锁策略和锁粒度； 3.Mysql在自己的服务器级(不是存储引擎级别)也实现了锁，而且这个锁是表级锁，用户 可以显示请求使用这个锁； 服务器级：实现了锁，表级锁；用户可显式请求 分类： 隐式锁：由存储引擎自动施加锁 显式锁：用户手动请求 4.但是要注意的是mysql自己在服务器层仅实现了表锁，比起InnoDB来说锁的颗粒度过于粗糙，而且InnoDB自己的行级锁 是自动完成请求时施加的用户无需人工参与，所以大多数情况下是不建议用户自己手动显示请求施加写操作的； 5.如何请求锁和如何手动去施加锁？ mysql在自己的服务器层实现了表级锁，而且这个锁是可以显示请求的，下面示例演示手动施加锁的效果： 1.显式使用锁的命令： MySQL [(none)]&gt; help lock LOCK TABLES #加锁，对一个表或多个表加锁 tbl_name [[AS] alias] lock_type #表明要使用的锁类型 [, tbl_name [[AS] alias] lock_type] ... lock_type: #锁类型 READ [LOCAL] #读锁 | [LOW_PRIORITY] WRITE #写锁 2.解锁命令： UNLOCK TABLES #解锁 3.第二种施加锁的命令 FLUSH TABLES [tb_name[,...]] [WITH READ LOCK] 1.表示把表的所有数据从内存清到磁盘上而后并关闭重新打开这个表(清除查询缓存); 2.通常在备份前(温备)施加全局读锁； 4.第三种施加锁的命令 SELECT clause [FOR UPDATE | LOCK IN SHARE MODE] 查询时施加写或读锁 示例： 开启两个终端启用两个mysql线程连接： 1.在第一个mysql线程施加读锁： MySQL [hellodb]&gt; LOCK tables students READ; 此时第二个mysql线程仍然可以查询 MySQL [hellodb]&gt; select * from students; 2.在第一个mysql线程施加写锁： MySQL [hellodb]&gt; LOCK tables students WRITE; 此时第二个mysql线程的查询请求就会被阻塞 直到第一个mysql线程将写锁解除查询才会返回； 总结： 其实对于mysql而言，锁仅仅是在资源被争用时对其资源争用的解决机制，事实上mysql作为关系型数据库其重要的一个特性是对事务的支持； 事务(Transactions)：事务日志，事务的特性，MyIsam没有–事务流程 1.事务(Transactions)是什么？ 1.事务对关系型数据库来说是一个基础功能，要想进一步的理解其并发控制功能的话还是需要仔细研究一下关系型数据库的事务和事务的实现方式； 2.从根本上来讲事务是一组原子性的SQL查询，或者说是一个独立的工作单元； 3.事实上我们在执行很多数据库操作完成需要做一件完整的事情时，是需要执行很多条 sql语句的，但是像mysql这种关系型数据库自身并不能保证完成一件完整的事情中执行的 所有sql语句要么全部都执行和要么全部都不执行这种原子性，需要引入一些辅助性的机制来解决这种问题； 4.锁机制和事务隔离都会极大的增加系统开销； 2.为什么要用到事务？ 比如像银行业务中的转账操作，它是需要A转出--&gt;B接收至少2步操作才能完成的，按照正常的逻辑A转出B就应该收到，但是 当A转出之后mysql服务器出现故障，B是否收到了是无法判断的，这时就需要通过一些辅助手段在mysql服务器出现故障时实 现要么A转出-B就收到，要么A转出后在服务器出故障时把A转出的操作进行撤销回来，在数据库服务器正常后重新做出转账操作； 3.ACID: 1.一般来讲，要说一个存储引擎或者一个关系型数据库是支持事务的前提是它能够满足ACID测试； 2.事务Transactions：一组原子性的SQL语句，或一个独立工作单元 3.事务日志：记录事务信息，实现undo,redo等故障恢复功能 4.存储引擎实现事务的功能是依赖于事务日志的相关功能，或者说需要借助事务日志才能满足ACID测试的； ACID特性： A：atomicity原子性； 1.整个事务中的所有操作要么全部成功执行，要么全部失败后回滚; 2.执行回滚的前提是一个关系型数据库应该有撤销日志用于执行回滚操作； 3.一个关系型数据库还应该有重做日志：把此前执行过的操作再运行一次； C：consistency一致性； 数据库总是从一个一致性状态转换为另一个一致性状态； I：Isolation隔离性； 1.一个事务所做出的操作在提交之前，是不能为其它事务所见； 2.如果一个事务隔离性很高且事务涉及的语句有很多需要提交的时间很长，那么这个事务在未完成之前其他事务 只能处于等待状态，此时就会大大的影响数据库的并发性，因此又不能对事务之间做完全意义上的隔离； 3.所以隔离就有多种隔离级别，这就意味着隔离级别越高的安全性越高，并发就越低；隔离级别越低安全性越低，并发性就越高； D：durability持久性； 持久性是指一旦事务提交，其所做的修改会永久保存于数据库中； 4.事务是如何进行的？ 启动事务： BEGIN BEGIN WORK START TRANSACTION #在mysql中显示启动一个事务 结束事务： 1.COMMIT：提交 (确保永久有效) 2.ROLLBACK: 回滚 注意： 1.只有支持事务型存储引擎中的DML语句方能支持此类操作； 2.像MyISAM这种不支持事务的存储引擎每执行一条语句回车都是持久化的，所有有可能会丢失数据 3.所以但凡对数据安全性要求较高的场景都应该使用事务型存储引擎； 自动提交： 对于mysql的InnoDB来说没执行一个语句也会自动提交被存储到数据库中的，因为在全局变量中有一个参数autocommit来完成的； MySQL [hellodb]&gt; show global variables like &apos;autocom%&apos;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | autocommit | ON | #自动提交默认是开启的 +---------------+-------+ autocommit=ON时，InnoDB的每条语句都被当成一个事务自动提交的；因为自动提交会相当影响性能的; 建议: 1.一般建议显示请求和提交事务,而不要使用&quot;自动提交&quot;功能; 2.建议关闭autocommit自动提交功能，使用事务时通过START TRANSACTION和 COMMIT进行提交； 关闭autocommit: mysql&gt; set GLOBAL[SESSION] autocommit=0; #关闭全局/会话级别的自动提交功能 mysql&gt; set GLOBAL[SESSION] autocommit=1; #开启全局/会话级别的自动提交功能 5.事务支持保存点：savepoint 1.事务的保存点是指启动事务时，可能会执行很多次操作，当执行一条语句设置一个保存 点1，执行第二条语句后再设置一个保存点2，如果不想撤销执行第二条语句的操作只需要回到保存点1就行了；(类似于在游戏中设置不同的存档功能...) 2.如果没有savepoint就只能回到最开始的地方了； 用法： MySQL [(none)]&gt; help savepoint; SAVEPOINT identifier #设置保存点 ROLLBACK [WORK] TO [SAVEPOINT] identifier #回到某一个保存点 RELEASE SAVEPOINT identifier #删除保存点 示例： MySQL [hellodb]&gt; start transaction; MySQL [hellodb]&gt; delete from students where StuID=6; MySQL [hellodb]&gt; commit; #因为默认的事务隔离级别是REPEATABLE-READ，所以其他mysql线程只有在commit后才能看到数据是修改的； –事务隔离级别 6.mysql的事务的隔离级别？ 1.事务和锁一样都有颗粒度之分，事务级别如果过于严格的话，任何一个事务都有可能会阻塞其他访问同一个资源的事务； 2.所以为了避免因为事务过多的影响mysql的并发性，对关系型数据库的ACID标准中事务的隔离等级做了定义； 3.每一种关系型数据库都可以设定自己支持到哪种隔离级别，大多数数据库都支持到第二级别，mysql可以支持到第三级别； 4.事务隔离级别：从上至下更加严格 1.read-uncommitted:读未提交 可以读别人尚未提交的数据，它会存在下面四种问题的前三种 脏读会带来不可重复读和幻读的问题； 2.read-committe:不可重复读 只有别人提交的数据才可以读，未提交的数据是看不到的； 它会存在不可重复读和幻读两种问题 3.repeatable-read:可重复读 它是InnoDB默认的事务隔离级别 repeatable-read虽然解决了不可重复读问题，但是它还是存在幻读的问题； 4.serializable:可串行化 1.serializable虽然能解决幻读的问题，但是它会带来加锁读的问题； 2.当启动事务进行操作时，别的事务会被阻塞而不能查询，只有等到前一个事务 commit之后才能查看，这样做是确保后一个事务读到的数据是准确的； 3.所以它的数据安全准确性是最高的，但是会因为阻塞问题导致并发性非常低； 一般来说不同的隔离级别可能会产生不同的问题，隔离级别越低产生问题的可能性 越大，可能存在的问题： 1.脏读：脏读是指读到了别人没提交的数据 2.不可重复读：两次读到的数据不一样，只有可重读才能解决不可重复读问题； 3.幻读： 明明对方修改一条数据已提交了，但是另外一个线程在修改之前也启动事 务了，虽然对方通过事务删除了一条数据，但是在自己的事务中查看时发 现还是有这条数据，而实际上保存在磁盘是上也没有这条数据此时就会出 现幻读的情况:即使自己看到了此条数据却只能当做没看到就是幻读； 4.加锁读：对自己读的数据加锁，别人都不能读 5.定义事务隔离级别： MySQL [(none)]&gt; show GLOBAL variables like &apos;%tx_isolation%&apos;; +---------------+-----------------+ | Variable_name | Value | +---------------+-----------------+ | tx_isolation | REPEATABLE-READ | #默认的事务隔离级别 +---------------+-----------------+ 通过服务器变量tx_isolation来指定隔离级别，默认为REPEATABLE-READ，可在GLOBAL和SESSION级进行设置： SET GLOBAL[SESSION] tx_isolation=&apos;&apos; READ-UNCOMMITTED READ-COMMITTED REPEATABLE-READ SERIALIZABLE 或者修改my.cnf配置文件 vim /etc/my.cnf [mysqld] transaction-isolation=SERIALIZABLE 7.MVCC：多版本并发访问控制 在repeatable-read级别上会发现一个特殊的情况即：即便是别人提交过的数据，我们看到的仍然是手动启动事务之前的数 据，那么mysql是怎么实现这个多个事务看到不同数据的？ 1.InnoDB是靠MVCC(多版本并发访问控制)机制来实现的; 2.所谓的MVCC其实就是在mysql内部当每一个事务启动时为它们创建一个当前锁涉及到的数据集的快照，一旦设置了快照 那么看到的数据一定是创建快照时的数据了，别的事务即使修改数据也不会影响此时看到的数据； 8.并发控制 在mysql内部存在各式各样的锁操作，他们通过锁来解决资源竞争问题，但是有了锁有不可避免的产生另外一个问题：死锁 死锁： 1.两个或多个事务在同一资源相互占用，它们互相等待对方释放资源的状态就会造成死锁； 2.mysql一旦产生死锁就会查询时卡住了，所有操作都无法进行下去； 3.为了避免死锁问题，InnoDB引入了死锁检测和死锁超时机制； –事务日志原理 9.事务日志 1.mysql为了保证事务必要时能够回滚，和避免事务执行过程服务器出故障，mysql引入了一个特性：一旦事务提交了必须 立即执行一次IO操作以确保事务能够立即从内存写入到磁盘上； 2.但是如果事务中有很多语句操作，即使立即执行磁盘IO也需要几秒，在几秒钟的时间内服务器出现故障也会造成数据丢 失，因为为了避免这种情况mysql就引入了事务日志的功能； 3.事务日志相当于undo/redo log，并且每一次事务提交时，这个事务所做的所有操作不会立即写入到数据文件中而是先写 入到事务日志中； 4.因为事务日志在磁盘上必须是一段连续的空间，当数据库崩溃时内存中的数据是没了，当数据库重新启动时就必须有一次 崩溃后恢复操作：即把事务日志中的操作全同步到数据文件中去； 5.事务日志是保证数据能够持久、回滚等相关操作的一个非常重要的工具，事务日志还能帮助提升事务效率：使用事务日志 修改表中数据只需要修其内存中的copy,再把改修改行为直接持久到磁盘上的事务日志中而不是每一次都直接写到磁盘文件中，从而避免了大量的随机IO； 6.因为事务日志的写操作是追加方式进行的，因此它是&quot;顺序IO&quot;,通常也被称 为：预写式日志write ahead logging; 它会导致每一份数据都会写两份，因此将事务日志和数据文件放在不同的磁盘上以提高其IO能力； 7.事务日志文件表现形式为:ib_logfile0,ib_logfile1默认都是5M大小;路径默认是mysql的数据存储目录； 修改事务日志的默认大小和存储位置： MySQL [hellodb]&gt; show variables like &apos;%innodb_log%&apos;; +-----------------------------+----------+ | Variable_name | Value | +-----------------------------+----------+ | innodb_log_buffer_size | 8388608 | | innodb_log_compressed_pages | ON | | innodb_log_file_size | 50331648 | #每个日志文件大小 | innodb_log_files_in_group | 2 | #同一日志组中的数量,默认是2个 | innodb_log_group_home_dir | ./ | #mysql的datadir目录 +-----------------------------+----------+ #注意： 1.下面这三个参数是不支持运行时修改的，要想生效需要写到配置文件中，重启mysql服务； 2.建议不要使用太大的事务日志，因为如果太大的话会导致存储大量未同步到磁盘上的事务时间，而且崩溃恢复会需要大量的时间； 至于具体是多大，可以根据实际业务情况进行估算的； 3.而且事务日志是分组进行的，一般默认一组内是2个，以达到循环使用的目的，不过一般生产环境要调大或者调多； 4.事务日志也要和数据分开存放的，最好也放在raid10的磁盘之上，因为事务日志对崩溃恢复至关重要!!! 事务备注： 事务不是万能的，比如truncate命令的执行时是不可撤销的 DML可以撤销 INSERT，DELETE，UPDATE DDL不可撤销 CREATE，DROP，ALTER]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables-NAT表管理]]></title>
    <url>%2F2017%2F02%2F01%2Fiptables-NAT%E8%A1%A8%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[NAT表：网络防火墙原理及示例本地通信：两个主机在没有网关或者路由下进行通信，所有的本地通信是通过MAC地址进行通信的 name--&gt;IP--&gt;MAC地址基于广播机制 如果有交换机，交换机会查找MAC地址表(是通过源地址学习得到的), 将数据报文直接发送到连接到交换机的目标主机上 网络通信：其实就是多个本地通信实现的，由多个路由器进行中继转发最后到达目标主机的 而把linux服务器扮演成路由器的角色，则这台linux服务器充当是网关，就需要打开核心转发功能 FORWARD链 右边是生产环境 左边是研发测试环境： 隧道VPN 实验模拟：用linux服务器当做防火墙，需要先开启核心转发功能 sysctl -w net.ipv4.ip_forward=1 主机A上加路由: route add -net 192.168.10.10/24 gw 192.168.34.103 主机B上加路由: route add -net 192.168.34.0/24 gw 192.168.10.10 情景一：客户端确定服务端不确定；源地址确定，目标地址不确定 情景二：服务端确定，客户端不确定；源地址不确定，目标地址确定 对于情景一的情况： 客户端确定,服务端不确定；即源地址确定，目标地址不确定 示例1: 1.先在FORWARD链上默认为拒绝 如控制客户端只能访问httpd和ping操作，就可以在FORWARD链上添加如下规则 tcp:80端口限制: iptables -A FORWARD 1 -s 192.168.34.0/24 -p tcp --dport 80 -j ACCEPT iptables -I FORWARD 2 -d 192.168.34.0/24 -p tcp --sport 80 -j ACCEPT icmp的ping限制： iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -j ACCEPT iptables -I FORWARD 4 -d 192.168.34.0/24 -p icmp --icmp-type 0 -j ACCEPT 默认拒绝策略： iptables -I FORWARD 5 -j REJECT 2.因为之前介绍过state的状态追踪功能： 就可以简化成这样的规则： iptables -I FORWARD 1 -m state --state ESTABLISHED -j ACCEPT iptables -A FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -j ACCEPT iptables -I FORWARD 4 -j REJECT 3.情景一因为都是内网的服务器，是不能接收外网的请求的 所以对于ping和tcp只允许从内网出去的，外网是不能进来的，规则如下 iptables -I FORWARD 1 -m state --state ESTABLISHED -j ACCEPT iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCEPT iptables -I FORWARD 4 -j REJECT 示例2：控制访问ping,httpd：80,vsftp：21,dns：53 规则如下： iptables -I FORWARD 1 -m state --state ESTABLISHED -j ACCEPT iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp -m multiport --dport 80,21,53 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p udp --dport 53 -m state --state NEW -j ACCEPT iptables -I FORWARD 4 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCEPT iptables -I FORWARD 5 -s 192.168.34.0/24 -p tcp -m state --state RELATED -j ACCEPT iptables -I FORWARD 6 -j REJECT 在这里需要指定-s 源，不然外网向内网主动发送报文请求也是可以到达内网的！ 结论： 1.所以说有时服务器ping不通不代表服务不能访问，而且通过内网ping外网时，在外网服务器 进行抓包时，可以看出源地址是内网IP,非网关IP，目标地址是外网IP地址[root@centos7 data]# tcpdump -i ens33 -nn icmptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytes21:10:24.541810 IP 192.168.34.107 &gt; 192.168.10.10: ICMP echo request, id 1764, seq 3, length 6421:10:24.541877 IP 192.168.10.10 &gt; 192.168.34.107: ICMP echo reply, id 1764, seq 3, length 64 2.用linux防火墙做网关网络防火墙，有一个问题，内网的机器是保护了，但是这台linux服务 是没有防护的，所以还需要在这台网络防火墙上在INPUT和OUTPUT链上加上规则，来防护 这台linux网关网络防火墙！所以当用一台linux服务器做网络防火墙时，INPUT,OUTPUT FORWARD链是都需要设置规则的！ 对于情景二的情况： 右边的图则控制：源地址不确定，目标地址确定 示例3：控制允许互联网的主机访问ping,httpd：80,vsftp：21,dns：53 所以规则应该如下： iptables -I FORWARD 1 -p tcp -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -d 192.168.10.0/24 -p tcp -m multiport --dports 80,53,21 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -d 192.168.10.0/24 -p udp --dport 53 -j ACCEPT iptables -I FORWARD 4 -d 192.168.10.0/24 -p icmp --icmp-type 8 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 5 -d 192.168.10.0/24 -m state --state RELATED -j ACCEPT iptables -I 6 FORWARD -j REJECT NAT： 1.NAT规则是在FORWARD的基础上进行安全加固的，隐藏源地址和目标地址，达到保护内网的安全和提供服务的主机安全 2.当然NAT规则还是建立在FORWARD的基础上做地址转换，不能转发做NAT也没意义，所以放行和控制限制还是需要在FORWARD链上去做的 NAT: network address translation，地址转换 NAT技术的产生核心原因：隐藏本不需要公开的主机 1.请求报文的源地址地址转换是人为在NAT上加规则实现的 2.响应报文中的目标地址转换，是基于连接追踪功能实现的，不需要人为干预 比如内网的机器要访问互联网，就必然留下IP地址或者端口信息，则有些攻击木马通过真正的 地址来扫描这些内网机器，如果有漏洞，则可能就会被攻击，所以NAT的技术的出现，就 会隐藏我们内网机器访问互联网时的真正IP地址和端口。 实现隐藏的原理： 1.将数据报文中的源地址IP，修改为具有很强防护能力的IP地址，比如网关等,这样的话，互联网上的主机看到的源地址就会是网关的地址，即使被攻击也是攻击网关，而网关一般是具有很高的防护能力的，所以就达到了隐藏源地址的目的. 2.一般来说请求报文经过防火墙时，会拆掉以太网帧首部，看到目标地址不是自己时，会转发出去，但是对于NAT的情况，防火墙会修改数据报文的IP首部的源地址或者目标地址，然后重新封装数据报文，再到达目标主机，这样就会达到保护源主机和目标主机被攻击的风险，在这个过程中，请求报文由手动修改的，响应报文是由NAT连接追踪功能实现的。 NAT的方式：SNAT,DNAT,FullNAT,PortNAT NAT规则可加的链： 支持PREROUTING INPUT OUTPUT POSTROUTING,但是一般只在PREROUTING和 POSTROUTING上做NAT规则，INPUT和OUTPUT只有在特殊情况下才做NAT。 那么在netfilter上是如何实现的？ SNAT的实现 数据报文经过防火墙时，如上图示，只有当数据报文进入防火墙时，才知道目标地址不是 自己，还是需要转发，所以不适合在PREROUTING链上做地址转发，如果目标地址不是当前 主机，就要经由FORWARD链进行转发，而FORWARD链本身确不支持地址转换功能，所以只 有在离开本机再一次进行路由选择，路由完之后才扔给网卡发送队列中，所以只能在POSTROUTING链上加地址转换规则 DNAT的实现 SNAT：POSTROUTING源地址转换 原理： 请求报文发生了源地址修改：人为介入修改 响应报文经过防火墙的NAT规则时，同连接追踪机制自动修改目标地址 所以源地址转换适合隐藏服务端 作用： 1.隐藏内网主机的IP地址，防止被攻击 2.SNAT可以解决IPV4端口不够用的问题： IPV4的地址短缺的问题使得SNAT技术更加流行，因为私网地址使用一个公网地址， 所以通过SNAT地址转换，报文通过公网IP出去的时候，都会把源地址(私网地址)转 换成公网地址，才能与公网通信，响应报文回来的时候是发给公网IP的，则通过连接 追踪功能返回给原来的私网地址。 –实验原理图 SNAT实验： 192.168.34.0/24网段SNAT到192.168.10.11上，且只限制80和ping操作能进行 规则如下： NAT的POSTROUTING链规则： iptables -t nat -I POSTROUTING 1 -s 192.168.34.0/24 ! -d 192.168.34.0/24 -j SNAT --to-source 192.168.10.11 注意：这里的source是一个固定的地址，如果这个地址是变动的呢？ 那么可能下次这条规则就不生效了！--&gt; 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 验证：通过在192.168.10.10上抓icmp包和http日志也可以看出，确实是做了SNAT地址转换的 [root@node7-3 data]#tcpdump -i ens33 -nn icmp 14:56:14.315375 IP 192.168.10.11 &gt; 192.168.10.10: ICMP echo request, id 1373, seq 1, length 64 14:56:14.315473 IP 192.168.10.10 &gt; 192.168.10.11: ICMP echo reply, id 1373, seq 1, length 64 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.10.11 - - [29/Dec/2018:15:20:45 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; MASQUERADE：对SNAT的弥补，地址伪装只能作用在POSTROUTING链上，对SNAT的缺点弥补 外网地址是动态的就用MASQUERADE,如果是静态的就用SNAT； 因为MASQUERADE会消耗更多的系统资源，能用SNAT就用SNAT，特殊场景才使用MASQUERADE 只能作用在POSTROUTING链上，对SNAT的缺点弥补 比如： iptables -t nat -I POSTROUTING 1 -s 192.168.34.0/24 ! -d 192.168.34.0/24 -j SNAT --to-source 192.168.10.11 如果SNAT规则上的要访问的外网地址(192.168.10.11)是动态的，规则就失效了 这就要用到MASQUERADE了,如果是静态的就用SNAT； 当然能用SNAT还是要用SNAT的，特殊场景才使用MASQUERADE，因为MASQUERADE会消耗更多的系统资源 实验： 将SNAT的规则修改一下，不指定--to-source 192.168.10.10 规则如下： NAT的POSTROUTING链规则： iptables -t nat -A POSTROUTING -s 192.168.34.0/24 ! -d 192.168.34.10 -j MASQUERADE 验证：通过在192.168.10.10查看http日志也可以看出，确实是做了SNAT地址转换的，即使没指定source也是通过NAT服务器的随机端口进行访问的，达到地址伪装的目的 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.10.11 - - [29/Dec/2018:18:07:36 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; DNAT：PREROUTING和OUTPUT目标地址转换 原理: 请求报文的目标地址需要修改成真正的IP地址 响应报文经过防火墙的NAT规则，通过连接追踪机制，自动修改目标地址 作用： 1.隐藏提供服务的服务器的真实IP地址，防止被服务被劫持，如DNS劫持，http服务等 2.DNAT也通过PortNAT方式可以解决IPV4地址不够用的问题 缺点： 防火墙和目标主机必须在一个物理网络中 ，而且目标主机的网关必须指向防火墙的 IP地址，多以受限于传输范围，可以使用FULLNAT解决必须在同一物理网络的问题 DNAT实验： 访问192.168.10.10的http服务时，只需要访问防火墙NAT服务器的地址即可 即把192.168.10.10DNAT到192.168.34.103上，这里只做简单的DNAT不做portnat 规则如下： NAT的POSTROUTING链规则： iptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 验证：在192.168.34.107上获取192.168.10.10的页面信息：curl 192.168.10.10 因为DNAT是隐藏192.168.10.10的真实地址的，在互联网上只会暴露防火墙的192.168.34.103地址是提供http服务的，真正的地址得以保护，所以这里curl 192.168.34.103即可 [root@node7-2 data]#curl 192.168.34.103 haha 192.168.10.10 而在192.168.10.10查看http日志 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.34.107 - - [29/Dec/2018:17:24:20 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 192.168.34.107 - - [29/Dec/2018:17:26:42 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 从实验也可以看出DNAT的规则生效了，达到了隐藏真正提供服务的192.168.10.10地址 从而保证了服务器被攻击的风险 PortNAT:端口映射端口映射在docker容器中的实现方式更加方便，直接加-p选项即可,而且源端口和目标端口可以指定 进程与进程的通信，实际上就是端口号之间的通信 1.对于SNAT来说，因为访问是互联网的随机端口，所以都转换即可 2.而对于DNAT的情况来说： a.很多情况下，并不是说只要访问防火墙F的地址，都通过DNAT转换成主机A的IPA， 而是当访问主机A的某个服务特定端口时，才进行地址转换 b.而访问F的端口和要转换的IPA的端口不一定需要一样 即IPF：port1--&gt;IPA:port2，port1和port2可以不一样 3.DNAT也可以解决IPV4地址不够用的情况：如下图 那么就可以说地址转换可以发生在网络层，而且借助端口映射也可以发生在传输层首部(端口) DNAT端口映射实验：如上图 访问192.168.10.10：8080的http服务时，只需要访问防火墙NAT服务器的地址即可 即把192.168.10.10:8080DNAT到192.168.34.103:80上,在上面的DNAT基础上做修改即可 规则如下： NAT的POSTROUTING链规则： iptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10:8080 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 验证：curl 192.168.34.103:80查看是否能获取到192.168.10.10：8080的页面 [root@node7-2 data]#curl 192.168.34.103 haha 192.168.10.10 [root@node7-2 data]#curl 192.168.10.10:8080 haha 192.168.10.10 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.34.107 - - [29/Dec/2018:17:27:01 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 从实验也可以看出DNAT的端口映射规则生效了，映射的端口不一样也可以访问到页面 1.这里只模拟同一台服务器上的一个服务的DNAT端口映射情景 2.对于同一台服务上的多个服务DNAT端口映射也是同样道理，加上对应的PORTNAT规则即可 3.对于多台服务器上的多个服务DNAT端口映射同样是这样的，只需要在NAT服务器上添加多个地址，然后将对应地址进行多台服务器的服务映射即可 FullNAT：源地址和目标地址都修改 既是网关又是NAT fullnat能实现网关和主机不在同一个网段 FullNAT的存在是为了弥补SNAT和DNAT模式下，主机和NAT服务器必须在同一个网段的缺点 SNAT和DNAT都受限于NAT服务器和客户端都在一个网段 1.在SNAT中，主机的网关都是需要指向NAT服务器的，不然如果在主机和防火墙之间存在路由器的话，那么出去的请求报文就不一定经由NAT服务器了，也就达不到地址转换的目的 2.在DNAT中，如果提供服务器的主机和防火墙NAT服务器之间有路由器，那么响应的报文 也不一定经由NAT服务器，也达不到转换目标地址的目的。 3.所以FullNAT的存在就弥补了SNAT和DNAT的缺点 4.主要是为了解决DNAT的必须近距离传输的问题 FullNAT的地址转换原理： 如下图示 FullNAT实验： FullNAT的实验原理和SNAT,DNAT,PORTNAT实验方式一样，这里就不做演示了 REDIRECT:端口重定向作用于nat表的PREROUTING和OUTPUT redirect 只改端口，响应报文还是使用连接追踪功能,自动转换成原来端口]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux防火墙实现原理]]></title>
    <url>%2F2017%2F02%2F01%2Flinux%E9%98%B2%E7%81%AB%E5%A2%99%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[linux上的防火墙实现linux的防火墙是模仿OpenBSD实现的防火墙 1.纯软件实现 2.内核级实现的，只负责TCP协议的下4层的协议报文(传输层极其以下的层数)中工作和防护 也就是在前文所说的传输子网上进行工作和防护的]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables基本使用]]></title>
    <url>%2F2017%2F02%2F01%2Fiptables%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[iptables的命令使用格式 获取帮助： CentOS 7：man iptables-extensions CentOS 6：man iptables 规则的编写格式： iptables [-t table] COMMAND chain [rulesnum][-m matchname [per-match-options]] [-j targetname [per-target-options]] 表--&gt;命令--&gt;chain--&gt;对链 -t table： 默认为filter；其它可用的有raw, mangle, nat； 子命令COMMAND: 管理链： -P：policy，策略，定义链的默认策略； 一般有两种选择，ACCEPT和DROP； -N：new，新建一条自定义的规则链；被内建链上的规则调用才能生效；[-j chain_name]； -X：drop，删除自定义的、空的、或者引用计数为0的空链； -F：flush，清空指定的链； -E：重命名引用计数和为0的自定义链； -F：flush, 清空整条链 -Z：zero，计数器置零；改为零 iptables的每条规则和每个链都有专用的两个计数器： 每一个规则所匹配到的报文数量个数：pkts 和体积计数器之和：bytes 管理规则：增删改、插入 -A：append，追加，在指定链的尾部追加一条规则； -I：insert，插入，在指定的位置（省略位置时表示链首）插入一条规则； -D：delelte，删除，删除指定的规则； -R：replace，替换，将指定的规则替换为新规则；不能仅修改规则中的部分，而是整条规则完全替换； 查看：链上查看规则的动作，属于action的一种 -L：list，列出表中的链上的规则； -n：numeric，以数值格式显示； -v：verbose，显示详细格式信息； -vv, -vvv -x：exactly，计数器的精确结果； --line-numbers：显示链中的规则行号； 重置规则计数器： -Z：zero，置0； 计数器： 规则，以及默认策略有专用的计数器； 记录被当前规则所匹配到的： (1) 报文个数； (2) 字节总数； chain： (1) 内建链；INPUT OUTPUT FORWARD PREROUTING POSTROUTING (2) 自定义链； 自定义连只存在于iptables的上下文，只有被主链调用时，才会 存在于netfilter的上下文和5个hook挂上钩，才会生效。 匹配条件：matchname 多重条件：逻辑关系为“与”； 检查报文： TCP或UDP首部：源端口、目标端口、标记为ACK FSM: 有限状态机:TIME_WAIT,监听状态等 IP首部: SIP，DIP MAC首部：MAC地址 将防火墙规则保存下来 iptables-save &gt; /tmp/iptables-rules.v0.1 iptables-restore &lt; /tmp/iptables-rules.v0.1 开机自动加载iptables规则 yum install iptables-services -y 规则的保存和永久生效： 将iptables保存在文件 iptables-save iptables-restore iptables-server的service脚本 保存在/etc/sysconfig/iptables中，开启启动自动加载 firewalld,firewalld-cmd是不能调用iptables定义的规则，用iptables-server 必须先安装，不能并行 匹配条件又分为：通用匹配和扩展匹配 通用匹配条件： 检查的是下四层协议，对网络层的源地址-s，目标地址-d，协议类型-p进行检查 对数据链路层对从网卡的流入-i,流出-o进行检查 [!] -s, --sip,--source-ip报文源地址 其值可以是单个IP，或者连续IP，可以是网络地址，不能是离散的地址 [!] -d, --destination address[/mask][,...]：检查报文中的目标IP地址是否符合此处指定的地址或范围； [!] -i, --in-interface name：数据报文从哪个网卡接口进入； PREROUTING，INPUT, FORWARD 因为-i是数据报文流入的选项； 所以-i选项只能上面这三个链有关,用在前半部分相关的链上 [!] -o, --out-interface name：数据报文从哪个网卡接口出去； FORWARD, OUTPUT POSTROUTING 同理因为-o是数据报文流出的选项； 所以-o选项只能上面这三个链有关,用在后半部分相关的链上 [!] -p, --protocol protocol：四层协议 tcp|udp|icmp|sctp 这也是为什么iptables叫网络防火墙的原因，正常的工作只能工作在网络层， 检查网络层属性，但是-i -o和网络层属性没关系，和网络层下面的协议有关 正常情况下，网络防火墙是用来检查网络层首部来获得相关信息的 扩展匹配条件：又分为隐式扩展和显示扩展 扩展匹配是为了更精准的条件过滤，比如httpd传输时是需要资源压缩的， 而只有文本文件才适合压缩，所以在扩展中才能进行过滤。 /lib/modules/$(uname -r)/net/netfilter/下xt开头的就是扩展模块 默认没有载入到内核中，只有当用时才加载的，就叫隐式扩展 netfilter为了做深入的条件检查，通过特定的模块来实现检查功能 隐式扩展：不用-m选项指出matchname即可使用此match的专用选项进行匹配； -p tcp：隐含了-m tcp； [!] --source-port,--sport port[:port] 匹配报文中传输层的源端口； 可以使用单个端口或者连续端口，但是不能使用离散端口 [!] --destination-port,--dport port[:port]、 匹配报文中传输层的目标端口； 可以使用单个端口或者连续端口，但是不能使用离散端口 端口也只有2^16-1=65535个端口 [!] --tcp-flags mask comp SYN，ACK，FIN，RST，URG，PSH； mask：要检查的标志位列表，以逗号分隔； comp：必须为1的标志位列表，余下的出现在mask列表中的标志位则必须为0； --tcp-flags SYN,ACK,FIN,RST SYN 如果只定义SYN则代表tcp握手的第一次，一般只检查第一次 如果定义的是SYN，ACK代表tcp握手的第二次 如果是ACK，则代表tcp的正常通信过程 [!] --syn：因为检查tcp握手的第一次比较常用 所以系统内就设置这个选项代表下面这个选项 相当于--tcp-flags SYN,ACK,FIN,RST SYN -p udp：隐含了-m udp： [!] --source-port,--sport port[:port]：匹配报文中传输层的源端口； [!] --destination-port,--dport port[:port]：匹配报文中传输层的目标端口； -p icmp：隐含了-m icmp:互联控制消息协议 [!] --icmp-type {type[/code]|typename} icmp是有状态的 8：echo-request 0：echo-reply 显式扩展：必须使用-m选项指出matchname，有的match可能存在专用的选项； 显示扩展能帮我们更灵活的设置控制规则 获取帮助： CentOS 7：man iptables-extensions CentOS 6：man iptables 1、multiport扩展 离散方式的多端口匹配 离散最多为15个，以冒号隔开的算一个，所以连续的端口用冒号隔开 [!] --source-ports,--sports port[,port|,port:port]...：指定多个源端口； [!] --destination-ports,--dports port[,port|,port:port]...：指定多个目标端口； [!] --ports port[,port|,port:port]...：指定多个端口； 2、iprange扩展：连续的地址集 以连续的ip地址范围指明连续的多地址匹配条件； [!] --src-range from[-to]：源IP地址； [!] --dst-range from[-to]：目标IP地址； 3、set扩展：定义离散地址集 如果要开放的地址既不是连续的，也不是网络地址就需要使用set了 set依赖于ipset命令行工具；需要用ipset先定义一个地址集， 再用set调用地址集即可；需要先安装ipset安装包 yum install ipset ，重启iptables服务 set存在类型，常用的有两个： hash:net 网络地址的集合：两个网段剧哦多个网段 hash:ip IP地址的集合：离散地址集 使用方式： 先创建集合：ipset create NAME TYPE( hash:ip/hash:net) 向集合添加元素：ipset add NAME ELEMENT set再调用 --match-set NAME src --match-set NAME dst 4、string扩展：字串匹配， 借助string扩展，iptables把触角伸到了应用层 对报文中的应用层数据做字符串匹配检测； [!] --string pattern：要检测字符串模式； [!] --hex-string pattern：要检测的字符串模式，16进制编码； --algo {bm|kmp} 2组比较算法 5、time扩展 根据报文到达的时间与指定的时间范围进行匹配度检测； --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：起始日期时间； --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：结束日期时间； --timestart hh:mm[:ss] --timestop hh:mm[:ss] [!] --monthdays day[,day...] [!] --weekdays day[,day...] --kerneltz：使用内核中配置的时区 ~]# iptables -I INPUT -d 172.16.100.67 -p tcp --dport 23 -m time --timestart 09:00:00 --timestop 18:00:00 --weekdays Tue,Thu,Sat -j ACCEPT 6、connlimit扩展 根据每客户端IP做并发连接数匹配； --connlimit-upto n：连接数数量小于等于n，此时应该允许； --connlimit-above n：连接数数量大于n，此时应该拒绝； ~]# iptables -A INPUT -d 172.16.100.67 -p tcp --dport 23 -m connlimit --connlimit-upto 2 -j ACCEPT 7、limit扩展 基于收发报文的速率进行匹配； 基于令牌桶算法：bucket --limit rate[/second|/minute|/hour|/day]：平均速率 --limit-burst number：峰值速率,突发速率，最大速率 8、state扩展：有状态追踪的防火墙 stateful有状态；stateless无状态； 状态检测；连接追踪的状态监测机制（conntrack）； a.ip报文是无状态的，客户端向当前主机第一次发出请求，而第二次再发出请 求，对于服务器来说都当成第一次 b.对于服务器在IP层控制上来说，服务器响应报文和服务器主动发出请求报文 是没有区别的 c.基于以上两点，可以让第二次的报文和第一次关联起来，让IP报文有记忆功 能，让当前主机能识别一个新的连接请求是否和之前的连接有关联关系，记忆功能就是把之前的连接请求记录在内核的连接追踪表中，但是这个表是占用内核的 内存中，所以还需要进行连接数和时长的限制 d.因为需要查追踪表，所以效率是比之前慢的 e.然而是使用hash方式查找的，1w和10w查找时间是大概一致的，效率不会太低 f.对tcp,udp.icmp.stmp都是可以进行追踪的，和tcp的状态是没什么实际关系的. NEW：新连接；这个新连接是和协议无关的，独立于四层协议之外的 ESTABLISHED：已建立的连接； RELATED：相关联的连接；FTP INVALID：无法识别的状态； UNTRACKED：未追踪的连接； SNAT： DNAT： nf_conntrack内核模块；记忆是由内核空间的conntrack模块实现的 追踪到的连接：/proc/net/nf_conntrack文件中； 能追踪的最大连接数量定义在：/proc/sys/net/nf_conntrack_max 此值可自行定义，当主机作为网关网络防火墙时，更应该必要时调整到足够大； 要想永久保存修改的值需要保存到 vim /etc/sysctl.d/nf_conntrack_max.conf net.nf_conntrack_max = 1000000 再加载一次就行了 sysctl -p /etc/sysctl.d/nf_conntrack_max.conf 不同的协议的连接追踪的时长： /proc/sys/net/netfilter/ [!] --state STATE 如何开放被模式的ftp服务： 21端口是命令连接， (1) 装载追踪ftp协议的模块； modprobe nf_conntrack_ftp (2) 放行命令连接 ~] # iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT ~] # iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state NEW -j ACCEPT (3) 放行数据连接 ~] iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state RELATED -j ACCEPT 处理动作（目标） -j targetname [per-target-options] j是jump的意思，自定义链也可以放在target上，即主链跳转到自定义链 targetname： 简单： ACCEPT：接受； DROP：丢弃； 被请求的服务器数据报文丢弃了，请求端需要等待时间会消耗服务端和客户端资源 扩展： REJECT：--reject-with:icmp-port-unreachable默认 拒绝；适用内网，直接弹回报文请求 RETURN:当被调用的自定义链上没有规则则自动返回主链继续匹配; REDIRECT：端口重定向 SNAT：源地址转换 DNAT：目标地址转换 MASQURADE:地址伪装 LOG：日志 自定义链：可以先定义自定义链，再通过主链调用， 当自定义链被引用时，需要先删除引用，再清空自定义链，然后再删除 每个表对应控制的链，各不相同，记住对应关系网络层tcp协议的头部信息 2btye 2^16-1（0表示通用）2个半连接*2这里因为有两个半连接，请求和回应报文，所以防火墙要设置input接收请求和output回应报文，开启接收请求关闭回应报文，对方也是无法接收到回应报文的 生产环境下如何设置防火墙？：1.因为生产环境下，被管理的主机不在本地或者在其他省份，我们是通过ssh远程连接管理的! 2.防火墙规则一般是要设置白名单的，而默认策略是需要设置为DROP或者REJECT，这时，如果 不先把SSH或者VNC先设置白名单，我们就无法管理了！那就是给自己找麻烦了 3.所以要先为SSH服务设置白名单，再设置默认策略为DROP或者REJECT！！！ 4.默认策略可以用-P设置，也可以用自定义策略；自定义策略的好处 5.防火墙的检查机制,是按照顺序从上往下一个个匹配，如果最上面的一旦匹配即使下面有更 严格的条件，也会不生效，所以我们应该把检查严格的条件放到检查宽松的上面 比如：string检查规则(具体看示例)等 iptables的使用规范iptables -F 即清空filter表的所有链，因为默认是filter表 iptables -F INPUT，清空filter表上的INPUT链的所有规则 服务器要设置黑名单 极端清空下所有链都是drop的 如果主机有多个网卡，当网关来用的时，forward链就是用来当网络防火墙来用的 规则优化： (1) 注意规则的优先顺序，检查严格的要放到前面 (2) 可安全放行所有入站及出站，且状态为ESTABLISHED的连接； (3) 服务于同一类功能的规则，匹配条件严格的放前面，宽松放后面； (4) 服务于不同类功能的规则，匹配报文可能性较大扩前面，较小放后面； (5) 设置默认策略； (a) 最后一条规则设定； (b) 默认策略设定；可以使用-P或者-A ，建议使用-A (6)对于一类的规则限制，最好只写一条规则 隐式扩展示例：隐式扩展示例1：SSH服务 因为是ssh连接的，如果要设置默认策略为DROP，就一定要先开启SSH服务的请求和回应 iptables -A INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 22 -j ACCEPT 再设置默认INPUT链策略为DROP：两种写法：下文会表示自定义链的写法好处 iptables -P INPUT -j REJECT 设置默认策略是拒绝 或者用自定义写法： iptables -t filter -A INPUT -j REJECT，定义流入的默认策略 iptables -A OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 22 -j ACCEPT iptables -t filter -A OUTPUT -j REJECT(代替默认策略的写法) 设置自定义白名单的好处： 必要时，所有规则都可以通过自己明确给定的规则来定义 可以写一个脚本把自定义规则写进去，执行后就可以不受控于默认策略 因为管理的主机不在本地，如果再修改iptables规则时，把ssh也拒绝了，那么就有很大问题 可以把规则写在一个脚本里，在任务计划里创建一个清空防火墙规则的命令 即使脚本里的规则把自己拒绝了，可以等任务计划执行后，就可以登进去了，易于控制 隐式扩展示例2：http服务 在会前基础上开放80端口的访问 iptables -I INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 80 -j ACCEPT iptables -I OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 80 -j ACCEPT 隐式扩展示例3：lo网卡 将127.0.0.1设置不受控 在之前的基础上ping 127.0.0.1是受控的 之前的iptables -t filter -P INPUT DROP，是将0.0.0.0到0.0.0.0都拒绝了 本地127.0.0.1也被拒绝了，所以稍微修改为非lo网卡受控，lo网卡即不受控了 iptables -R INPUT 3 ! -i lo -j REJECT iptables -R OUTPUT 3 ! -o lo -j REJECT 隐式扩展示例4：-p icmp的隐式扩展；ping请求 如何设置当前主机可以ping其他主机，加在最后一条的前面 在之前的基础上此时主机主动ping其他主机也是受控的 icmp是有类型的,见下图，8 echo-request; 0 echo reply 当前主机主动ping其他主机： iptables -I OUTPUT 3 -p icmp --icmp-type 8 -j ACCEPT iptables -I INPUT 3 -p icmp --icmp-type 0 -j ACCEPT 其他主机ping防火请主机： iptables -I INPUT 3 -p icmp --icmp-type 8 -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 0 -j ACCEPT 隐式扩展示例5：DNS -p udp 如何设置开放本机可以通过DNS解析域名 从本机出去，到达互联的DNS服务器，再接收回应的报文 iptables -I OUTPUT -p udp --dport 53 -j ACCEPT 出去的报文 iptables -I INPUT -p udp --sport 53 -j ACCEPT 回来的报文 自定义链的使用示例(-N -E -X -F)以在自定义链中加入samba服务为例 -N：新建一条自定义的规则链 只不过在自定义链上是由计数器的 iptables -N new_rules 新建自定义链 iptables -E new_rules cifs_rules 改自定义链，必须要0引用的，0 references 自定义规则链的创建、调用、删除； 以在自定义链中加入samba服务;然后主链在调用自定义链为例 先设置入栈的规则 iptables -A cifs_rules -p tcp --dport 139 -j ACCEPT iptables -A cifs_rules -p tcp --dport 445 -j ACCEPT iptables -A cifs_rules -p udp --dport 137:138 -j ACCEPT iptables -A cifs_rules -j RETURN 还要加一条RETURN规则表示，当cifs_rules规则被主链调用时，如果自定义链上的规则 没有被匹配到，则return到主链上继续匹配主链上的后续规则. 在INPUT链去调用自定义链cifs_rules iptables -I INPUT 5 -s 192.168.34.0/24 -j cifs_rules 删除自定义链：需要先删除引用 iptables -D INPUT 5 iptables -F cifs_rules iptables -X cifs_rules 显示扩展示例必须使用-m选项指出matchname，有的match可能存在专用的选项 显示扩展示例1：multiport扩展 --多端口匹配 将21 22 80 139 445一起开启允许访问： iptables -I INPUT -p tcp -m multiport --dports 21:22,80,139,445 -j ACCEPT iptables -I OUTPUT -p tcp -m multiport --sports 21,22,80,139,445 -j ACCEPT 显示扩展示例2： ip-range:必须是连续的范围 允许ping的主机为192.168.34.100-192.168.34.106段的IP地址： iptables -I INPUT 3 -p icmp --icmp-type 8 -m iprange --src-range 192.168.34.100-192.168.34.106 -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 0 -m iprange --dst-range 192.168.34.100-192.168.34.106 -j ACCEPT 显示扩展示例3：set扩展 ipset先定义地址集: ipset create allowpinghosts hash:ip --先定义IP地址集 ipset add allowpinghosts 192.168.34.107 --向地址集添加IP地址 set再调用地址集： iptables -I INPUT 4 -p icmp --icmp-type 8 -m set --match-set allowpinghosts src -j ACCEPT iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m set --match-set allowpinghosts dst -j ACCEPT 显示扩展示例4：string扩展：字串匹配 比如：控制httpd服务的报文带有sex字串的都拒绝进入和访问 事先构建一个带有sex字串的html文件，然后设置规则 （因为这个规则比较严格，所以记得要放到允许访问httpd规则的前面！） iptables -I INPUT -p tcp --dport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT iptables -I OUTPUT -p tcp --sport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT 但是如果httpd有多个页面，只有访问特定页面时才拒绝时，其他的页面还是需要能访问 iptables -A INPUT -p tcp --dport 80 -j ACCEPT iptables -A OUTPUT -p tcp --sport 80 -j ACCEPT 显示扩展示例5：time扩展 比如1：控制httpd服务访问时间为8:00-18:00 iptables -I INPUT 1 -p tcp --dport 80 -s 192.168.34.107 -m time --timestart 08:00:00 --timestop 20:00:00 --kerneltz -j ACCEPT iptables -I OUTPUT 1 -p tcp --sport 80 -d 192.168.34.107 -m time --timestart 08:00:00 --timestop 20:00:00 --kerneltz -j ACCEPT 比如2：控制对IP:192.168.34.107的ping命令访问时间为8:00-16:00 iptables -I INPUT 3 -p icmp --icmp-type 8 -s 192.168.34.107 -m time --timestart 08:00:00 --timestop 16:00:00 --kerneltz -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 0 -d 192.168.34.107 -m time --timestart 08:00:00 --timestop 16:00:00 --kerneltz -j ACCEPT 显示扩展示例6：connlimit扩展 以SSH服务为例，当当连接数大于3时，拒绝连接 iptables -I INPUT 1 -p tcp --dport 22 -m connlimit --connlimit-above 3 -j REJECT 对于一类的规则限制，最好只写一条规则 显示扩展示例7：limit扩展 比如：限制192.168.34.105ping防火墙主机为每分钟20个，最大峰值速率为5 iptables -R INPUT 3 -p icmp --icmp-type 8 -s 192.168.34.105 -m limit --limit 20/minute --limit-burst 5 -j ACCEPT iptables -I OUTPUT 2 -p icmp --icmp-type 0 -j ACCEPT 显示扩展示例8：state扩展 1.使用state就可以简化之前的所有规则了，这里对21,22,80,53,139,445做连接追踪功能 先建立入栈的ESTABLISHED的规则 iptables -A INPUT -m state --state ESTABLISHED -j ACCEPT 再建立出栈的ESTABLISHED的规则 iptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPT 再建立入栈的NEW的规则 iptables -A INPUT -p tcp -m multiport --dports 21:22,80,53,139,445 -m state --state NEW -j ACCEPT 2.对于FTP来说，因为是被动模式，服务端还开启一个随机端口，但是之前并没有建立 随机端口的NEW规则，也没有创建RELATED的规则，所以这里要新建一条RELATED规则 a.ftp的RELATD,依赖于nf_conntrack_ftp模块 b.创建FTP的RELATED规则 iptables -I INPUT 3 -p tcp -m state --state RELATED -j ACCEPT 因为端口是不确定的，所以用RELATED 这样就建立了FTP的访问限制了 通过state的显示扩展，可以看出上面所有的规则都可以简化成NEW,ESTABLISHED,RELATED的状态具体可以参考下面的各种服务进行规则控制写法示例 通过iptables规则对下面服务实现控制：基于连接追踪功能对下面服务进行控制 dns httpd：互联网 nfs samba vsftpd 仅允许loaclnet mysql:loaclhost ping :all 限制速率为10/min ssh:IP最大并发连接数3，工作时间的8:00-18:00允许连接 要求默认策略为拒绝 iptables -I INPUT 1 -m state --state ESTABLISHED -j ACCEPT iptables -I INPUT 2 -p tcp -m multiport --dports 53,80 -m state --state NEW -j ACCEPT iptables -I INPUT 3 -p udp --dport 53 -m state --state NEW -j ACCEPT iptables -I INPUT 4 -p tcp --dport 22 -m connlimit --connlimit-above 3 -m time --timestart 08:00:00 --timestop 18:00:00 --weekday 1,2,3,4,5 -j REJECT iptables -I INPUT 5 -p tcp -s 192.168.34.0/24 -m multiport --dports 21:22,2049,139,445 -m state --state NEW -j ACCEPT iptables -I INPUT 6 -p tcp -s 127.0.0.1 --dport 3306 -m state --state NEW -j ACCEPT modprobe nf_conntrack_ftp iptables -I INPUT 7 -p tcp -m state --state RELATED -j ACCEPT iptables - I INPUT 8 -p icmp --icmp-type 8 -m limit --limit 10/minute --limit-burst 1 -j ACCEPT iptables -I INPUT 9 -p icmp --icmp-type 0 -j ACCEPT iptables -A INPUT -j REJECT iptables -I OUTPUT 1 -m state --state ESTABLISHED -j ACCEPT iptables -A OUTPUT 2 -p tcp -m tcp --sport 10000:65535 -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 8 -j ACCEPT iptables -A OUTPUT -j REJECT]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux上系统监控命令]]></title>
    <url>%2F2017%2F02%2F01%2Flinux%E4%B8%8A%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[linux上的系统监控命令：ps、uptime、top、sar、vmstat、iostat、dstat、iotop、lsof的使用 –linux上常用性能调优工具 ps命令：process stateLinux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照， 就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。； ps report a snapshot of the current processes #ps可以看到当前进程的快照状态，所以ps每次看到的可能不一样 Linux系统各进程的相关信息均保存在/proc/PID目录下的各文件中 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令就是最基本同时也是非常强 大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多 的资源等等。总之大部分信息都是可以通过执行该命令得到的。 ps 为我们提供了进程的一次性的查看，它所提供的查看结果并不动态连续的；如果想对进程时间监控，应该用 top 工具; kill 命令用于杀死进程; 1.ps命令使用 支持三种选项： UNIX选项 如-A -e;类似 ls -l BSD选项 如a GNU选项 如--help 类似 ls --all BSD类型的选项：默认显示当前终端中的进程 a 选项包括所有终端中的进程 x 选项包括不链接终端的进程 u 选项显示进程所有者的信息 f 选项显示进程树,相当于 --forest k|--sort 属性对属性排序,属性前加-表示倒序 o 属性… 选项显示定制的信息 pid、cmd、%cpu、%mem L 显示支持的属性列表 UNIX类型的选项： -C cmdlist 指定命令，多个命令用，分隔 -L 显示线程 -e: 显示所有进程，相当于-A -f: 显示完整格式程序信息 -F: 显示更完整格式的进程信息 -H: 以进程层级格式显示进程相关信息 -u userlist 指定有效的用户ID或名称 -U userlist 指定真正的用户ID或名称 -g gid或groupname 指定有效的gid或组名称 -G gid或groupname 指定真正的gid或组名称 -p pid 显示指pid的进程 --ppid pid 显示属于pid的子进程 -M 显示SELinux信息，相当于Z 2.linux上进程有5种状态: 1. 运行(正在运行或在运行队列中等待) 2. 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 3. 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 4. 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 5. 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行) 3.ps工具标识进程的5种状态码: D 不可中断 uninterruptible sleep (usually IO) R 运行 runnable (on run queue) S 中断 sleeping T 停止 traced or stopped Z 僵死 a defunct (”zombie”) process 4.ps aux 和ps -ef的使用 前面说过这是两种输出风格，输出项都是差不多的 ps aux 是用BSD的格式来显示、其格式如下： [root@node1 ~]# ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 2 0.0 0.0 0 0 ? S 11:58 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S 11:58 0:00 [ksoftirqd/0] 同ps -ef 不同的有列有 USER #用户名 %CPU #进程占用的CPU百分比 %MEM #占用内存的百分比 VSZ #该进程使用的虚拟內存量（KB） Virtual memory SiZe,虚拟内存集,进程占用的虚拟内存空间、线性内存 RSS #该进程占用的固定內存量（KB）（驻留中页的数量） ReSident Size, 常驻内存集、物理内存集,进程占用实际物理内存空间 STAT #进程的状态 START #该进程被触发启动时间 TIME #该进程实际使用CPU运行的时间,越小代表没占用资源 其中STAT状态位常见的状态字符有 D: uninterruptable sleeping #无法中断的休眠状态（通常 IO 的进程）； R：running #正在运行可中在队列中可过行的； S: interruptable sleeping #处于休眠状态； T: stopped #停止或被追踪； W #进入内存交换 （从内核2.6开始无效）； X #死掉的进程 （基本很少见）； Z: zombie #僵尸进程； &lt;: 高优先级进程 #优先级高的进程 N：低优先级进程 #优先级较低的进程 L：内存分页并带锁 #有些页被锁进内存； s: session leader，会话(子进程)发起者 #进程的领导者(在它之下有子进程)； l: 多线程进程 #多线程，克隆线程（使用 CLONE_THREAD, 类似 NPTL pthreads）； +: 前台进程 #位于后台的进程组； ps -ef 是用标准的格式显示进程的: [root@node1 ~]# ps -ef UID PID PPID C STIME TTY TIME CMD root 2 0 0 11:58 ? 00:00:00 [kthreadd] root 3 2 0 11:58 ? 00:00:00 [ksoftirqd/0] 其中各列的内容意思如下 UID #用户ID、但输出的是用户名 PID #进程的ID PPID #父进程ID C #进程占用CPU的百分比 STIME #进程启动到现在的时间 TTY #该进程在那个终端上运行，若与终端无关，则显示? 若为pts/0等则表示由网络连接主机进程。 CMD #命令的名称和参数 iftopiftop监控网络中哪个进程使用流量最大,它可以实时监控哪个进程对网络接口当中带宽占用率最大； iftop是一款实时流量监控工具,监控TCP/IP连接等,缺点就是无报表功能。必须以root身份才 能运行。 Linux下使用iftop工具结合iptables服务来解决带宽资源被恶意请求满的问题，主要通过2个步骤来实现; 监控eth1 iftop -i eth1 基于实例讲解输出含义 执行iftop -N -n -i eth1后界面为 19.1Mb 38.1Mb 57.2Mb 76.3Mb 95.4Mb +-----------------+-----------------+--------------------+--------- 192.168.1.11 =&gt; 192.168.1.66 5.3Mb 3.22Mb 3.20Mb &lt;= 219kb 45.7kb 49.3kb 192.168.1.11 =&gt; 192.168.1.29 144kb 30.8kb 29.6kb &lt;= 11.3Mb 2.38Mb 2.74Mb 192.168.1.11 =&gt; 12.2.11.71 0b 6.40kb 6.66kb &lt;= 0b 0b 0b 192.168.1.11 =&gt; 192.168.1.8 2.63kb 1.43kb 932b &lt;= 1.31kb 1.05kb 893b 192.168.1.11 =&gt; 192.168.2.78 2.53kb 1.54kb 2.15kb &lt;= 160b 160b 187b 192.168.1.11 =&gt; 111.126.195.69 0b 166b 69b &lt;= 0b 0b 0b --------------------------------------------------------------------------- TX: cum: 9.70MB peak: 15.6Mb rates: 15.4Mb 3.26Mb 3.23Mb RX: 8.38MB 14.9Mb 11.5Mb 2.42Mb 2.79Mb TOTAL: 18.1MB 30.5Mb 27.0Mb 5.69Mb 6.03Mb iftop界面含义如下 第一行：带宽显示 中间部分：外部连接列表，即记录了哪些ip正在和本机的网络连接 中间部分右边：实时参数分别是该访问ip连接到本机2秒，10秒和40秒的平均流量 =&gt;代表发送数据，&lt;= 代表接收数据 底部三行：表示发送，接收和全部的流量 底部三行第二列：为你运行iftop到目前流量 底部三行第三列：为高峰值 底部三行第四列：为平均值 通过iftop的界面很容易找到哪个ip在霸占网络流量，这个是ifstat做不到的。不过iftop的流量显示单位是Mb,这个b是bit，是位，不是字节，而ifstat的KB，这个B就是字节了，byte是bit的8倍。初学者容易被误导。 进入iftop的命令 进入iftop画面后的一些操作命令(注意大小写) 按h切换是否显示帮助; 按n切换显示本机的IP或主机名; 按s切换是否显示本机的host信息; 按d切换是否显示远端目标主机的host信息; 按t切换显示格式为2行/1行/只显示发送流量/只显示接收流量; 按N切换显示端口号或端口服务名称; 按S切换是否显示本机的端口信息; 按D切换是否显示远端目标主机的端口信息; 按p切换是否显示端口信息; 按P切换暂停/继续显示; 按b切换是否显示平均流量图形条; 按B切换计算2秒或10秒或40秒内的平均流量; 按T切换是否显示每个连接的总流量; 按l打开屏幕过滤功能，输入要过滤的字符，比如ip,按回车后，屏幕就只显示这个IP相关的流量信息; 按L切换显示画面上边的刻度;刻度不同，流量图形条会有变化; 按j或按k可以向上或向下滚动屏幕显示的连接记录; 按1或2或3可以根据右侧显示的三列流量数据进行排序; 按&lt;根据左边的本机名或IP排序; 按&gt;根据远端目标主机的主机名或IP排序; 按o切换是否固定只显示当前的连接; 按f可以编辑过滤代码，这是翻译过来的说法，我还没用过这个！ 按!可以使用shell命令，这个没用过！没搞明白啥命令在这好用呢！ 按q退出监控。 uptime命令[root@node02 ~]# uptime 11:19:15 up 20 min, 1 user, load average: 0.00, 0.01, 0.05 输出的项分别表示： 11:19:15 #显示当前时间 up 20 min #系统已启动的时间 1 user #当前系统登录的上线人数 load average: 0.00, 0.01, 0.05是指 #系统平均负载（1、5、10 分钟的平均负载，一般不会超过1） 注意： 1.系统平均负载: 是指在特定时间间隔内运行队列中的平均进程数 2.通常每个CPU内核的当前活动进程数不大于3，那么系统的性能良好。如果每 个CPU内核的任务数大于5，那么此主机的性能有严重问题 注意：上面是指单核cpu，如果是双核的应该不大于6，以此类推 3.如果linux主机是1个双核CPU，当Load Average 为6的时候说明机器已经被充分使用 进程管理工具–&gt;top命令–top输出详解 [root@node02 ~]# top top - 11:33:09 up 34 min, 1 user, load average: 0.10, 0.11, 0.08 Tasks: 98 total, 1 running, 97 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 481876 total, 23980 free, 232296 used, 225600 buff/cache KiB Swap: 2097148 total, 2096628 free, 520 used. 185472 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 6542 root 20 0 161984 2216 1560 R 0.7 0.5 0:00.02 top 288 root 20 0 0 0 0 S 0.3 0.0 0:00.63 xfsaild/sda2 top：有许多内置命令 排序： 通过下面这些字母进行切换可以看到不同的显示信息 P：以占据的CPU百分比,%CPU M：占据内存百分比,%MEM T：累积占据CPU时长,TIME+ 首部信息显示： uptime信息：l命令 tasks及cpu信息：t命令 cpu分别显示：1 (数字) memory信息：m命令 退出命令：q 修改刷新时间间隔：s 终止指定进程：k 保存文件：W 栏位信息简介 us：用户空间 sy：内核空间 ni：调整nice时间 id：空闲 wa：等待IO时间 hi：硬中断 si：软中断（模式切换） st：虚拟机偷走的时间 选项： -d # 指定刷新时间间隔，默认为3秒 -b 全部显示所有进程 -n # 刷新多少次后退出 -H 线程模式，示例：top -H -p `pidof mysqld` Linux top命令的用法详细详解 首先介绍top中一些字段的含义： top 命令实时显示进程的状态。默认状态显示的是cpu密集型的进程，并且每5秒钟更新一次。你可以通过PID的数字大小， age (newest first), time (cumulative time),resident memory usage（常驻内存使用）以及进程从启动后占用cpu的时间。 VIRT：virtual memory usage 虚拟内存 1、进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据等 2、假如进程申请100m的内存，但实际只使用了10m，那么它会增长100m，而不是实际的使用量 RES：resident memory usage 常驻内存 1、进程当前使用的内存大小，但不包括swap out 2、包含其他进程的共享 3、如果申请100m的内存，实际使用10m，它只增长10m，与VIRT相反 4、关于库占用内存的情况，它只统计加载的库文件所占内存大小 SHR：shared memory 共享内存 1、除了自身进程的共享内存，也包括其他进程的共享内存 2、虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小 3、计算某个进程所占的物理内存大小公式：RES – SHR 4、swap out后，它将会降下来 DATA 1、数据占用的内存。如果top没有显示，按f键可以显示出来。 2、真正的该程序要求的数据空间，是真正在运行中要使用的。 top 运行中可以通过 top 的内部命令对进程的显示方式进行控制。内部命令如下： s – 改变画面更新频率 l – 关闭或开启第一部分第一行 top 信息的表示 t – 关闭或开启第一部分第二行 Tasks 和第三行 Cpus 信息的表示 m – 关闭或开启第一部分第四行 Mem 和 第五行 Swap 信息的表示 N – 以 PID 的大小的顺序排列表示进程列表 P – 以 CPU 占用率大小的顺序排列进程列表 M – 以内存占用率大小的顺序排列进程列表 h – 显示帮助 n – 设置在进程列表所显示进程的数量 q – 退出 top s – 改变画面更新周期 序号 列名 含义 a PID 进程id b PPID 父进程id c RUSER Real user name d UID 进程所有者的用户id e USER 进程所有者的用户名 f GROUP 进程所有者的组名 g TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? h PR 优先级 i NI nice值。负值表示高优先级，正值表示低优先级 j P 最后使用的CPU，仅在多CPU环境下有意义 k %CPU 上次更新到现在的CPU时间占用百分比 l TIME 进程使用的CPU时间总计，单位秒 m TIME+ 进程使用的CPU时间总计，单位1/100秒 n %MEM 进程使用的物理内存百分比 o VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 q RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r CODE 可执行代码占用的物理内存大小，单位kb s DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t SHR 共享内存大小，单位kb u nFLT 页面错误次数 v nDRT 最后一次写入到现在，被修改过的页面数。 w S 进程状态。（D=不可中断的睡眠状态，R=运行，S=睡眠，T=跟踪/停止，Z=僵尸进程） x COMMAND 命令名/命令行 y WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 z Flags 任务标志，参考 sched.h 默认情况下仅显示比较重要的 PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND 列。可以通过下面的快捷 键来更改显示内容。 通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z 即可显示或隐藏对应的列，最后按回车键确定。 按 o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z 可以将相应的列向左移动。最后按回车键确定。 按大写的 F 或 O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的 R 键可以将当前的排序倒转。 sarsar（System ActivityReporter系统活动情况报告）是目前Linux上最为全面的系统性能分析工具之一，可以从多方面对系统 的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动 等，sar命令有sysstat安装包安装，本文主要以CentOS 6系列x64系统为例，介绍sar命令。 1.sar输出 [root@node02 ~]# sar Linux 3.10.0-862.el7.x86_64 (node02) 04/20/2019 _x86_64_ (1 CPU) 12:10:01 PM CPU %user %nice %system %iowait %steal %idle 12:20:01 PM all 1.48 0.00 0.82 0.08 0.00 97.61 12:30:01 PM all 2.39 0.00 0.94 0.01 0.00 96.65 12:40:02 PM all 2.10 0.00 1.24 0.05 0.00 96.61 12:50:01 PM all 0.27 0.00 0.39 0.01 0.00 99.33 Average: all 1.56 0.00 0.85 0.04 0.00 97.55 内存管理工具之–&gt;vmstat:虚拟内存信息1.用来获得有关进程、虚存、页面交换空间及CPU活动的信息。这些信息反映了系统的负载情况; 2.虚拟内存运行原理： 在系统中运行的每个进程都需要使用到内存，但不是每个进程都需要每时每刻使用系统分配的内存空间。当系统运行所需内存 超过实际的物理内存，内核会释放某些进程所占用但未使用的部分或所有物理内存，将这部分资料存储在磁盘上直到进程下 一次调用，并将释放出的内存提供给有需要的进程使用。 在Linux内存管理中，主要是通过“调页Paging”和“交换Swapping”来完成上述的内存调度。调页算法是将内存中最近不常使 用的页面换到磁盘上，把活动页面保留在内存中供进程使用。交换技术是将整个进程，而不是部分页面，全部交换到磁盘上。 分页(Page)写入磁盘的过程被称作Page-Out，分页(Page)从磁盘重新回到内存的过程被称作Page-In。当内核需要一个分页 时，但发现此分页不在物理内存中(因为已经被Page-Out了)，此时就发生了分页错误（Page Fault）。 当系统内核发现可运行内存变少时，就会通过Page-Out来释放一部分物理内存。经管Page-Out不是经常发生，但是如果 Page-out频繁不断的发生，直到当内核管理分页的时间超过运行程式的时间时，系统效能会急剧下降。这时的系统已经运行 非常慢或进入暂停状态，这种状态亦被称作thrashing(颠簸)。 3.vmstat输出信息 [root@node02 ~]# vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 3 0 776 12968 168 230708 0 0 111 7 157 286 1 1 99 0 0 具体代理的意义： procs: r：可运行（正运行或等待运行）进程的个数，和核心数有关 b：处于不可中断睡眠态的进程个数(被阻塞的队列的长度) memory： swpd: 交换内存的使用总量 free：空闲物理内存总量 buffer：用于buffer的内存总量 cache：用于cache的内存总量 swap: si：从磁盘交换进内存的数据速率(kb/s) so：从内存交换至磁盘的数据速率(kb/s) io： bi：从块设备读入数据到系统的速率(kb/s) bo: 保存数据至块设备的速率 system： in: interrupts 中断速率，包括时钟 cs: context switch 进程切换速率 cpu： us:Time spent running non-kernel code sy: Time spent running kernel code id: Time spent idle. Linux 2.5.41前,包括IO-wait time. wa: Time spent waiting for IO. 2.5.41前，包括in idle. st: Time stolen from a virtual machine. 2.6.11前, unknown 选项： -s: 显示内存的统计数据 内存管理工具之–&gt;iostat:统计CPU和设备IO信息1.iostat是用来专门统计CPU和设备IO信息 2.iostat输出详情： [root@node02 ~]# iostat Linux 3.10.0-862.el7.x86_64 (node02) 04/20/2019 _x86_64_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 9.22 0.00 11.37 1.70 0.00 77.71 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 94.95 3944.03 690.62 443506 77660 sdb 0.78 18.50 0.00 2080 0 sdc 0.78 18.50 0.00 2080 0 sdd 0.78 18.50 0.00 2080 0 scd0 0.16 9.14 0.00 1028 0 输出信息解释： avg-cpu: %user %nice %system %iowait %steal %idle #是指平均cpu利用率 Device: #每块磁盘的具体情况 tps #当前磁盘每秒钟处理事务的速度 kB_read/s #当前磁盘每秒钟读的字节数 kB_wrtn/s #当前磁盘每秒钟写的字节数 kB_read #当前磁盘读的总量 kB_wrtn #当前磁盘写的总量 3.使用： 在生产环境中可以通过这个信息观察每块磁盘的写入和读取速度进行监控 系统监控工具–&gt;dstat命令：系统资源统计,代替vmstat,iostat,ifstat1.dstat命令是监控系统资源统计,代替vmstat(虚拟内存),iostat(磁盘读写),ifstat(网卡监控) 2.安装dstat [root@node02 ~]# yum install dstat -y #dstat命令来自dstat-0.7.2-12.el7.noarch包 3.dstat输出 [root@node02 ~]# dstat You did not select any stats, using -cdngy by default. ----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system-- usr sys idl wai hiq siq| read writ| recv send| in out | int csw 2 2 95 0 0 0| 814k 122k| 0 0 |1714B 2301B| 215 555 0 0 100 0 0 0| 0 0 | 60B 890B| 0 0 | 142 230 1 1 98 0 0 0| 0 0 | 60B 346B| 0 0 | 150 227 0 1 98 0 0 1| 0 0 | 60B 346B| 0 0 | 168 251 0 1 99 0 0 0| 0 0 | 60B 346B| 0 0 | 149 232 输出信息： total-cpu-usage #cpu信息 dsk/total #磁盘信息 net/total #网卡信息 paging： #swap信息 system #进程信息 4.dstat相关选项 dstat [-afv] [options..] [delay [count]] -c 显示cpu相关信息 -C #,#,...,total -d 显示disk相关信息 -D total,sda,sdb,... -g 显示page相关统计数据 -m 显示memory相关统计数据 -n 显示network相关统计数据 -p 显示process相关统计数据 -r 显示io请求相关的统计数据 -s 显示swapped相关的统计数据 监视磁盘I/O工具–&gt;iotopiostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动 统计情况，同时也会汇报出CPU使用情况。iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析; iotop命令是一个用来监视磁盘I/O使用状况的top类工具iotop具有与top相似的UI，其中包括 PID、用户、I/O、进程等相关信息，可查看每个进程是如何使用IO; 1.iotop输出信息 [root@node02 ~]# iotop Total DISK READ : 0.00 B/s | Total DISK WRITE : 0.00 B/s Actual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND 1 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % systemd --switched-root --system --deserialize 22 2 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [kthreadd] 3 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [ksoftirqd/0 输出信息： 第一行： Total DISK READ：Read速率总计 Total DISK WRITE：Write速率总计 第二行： Actual DISK READ：实际的Read速率 Actual DISK WRITE：实际的Write速率 第三行：参数如下： TID：线程ID（按p切换为进程ID） PRIO：优先级 USER：用户 DISK磁盘读速率 READ 磁盘写速率 SWAPIN：swap交换百分比 IO&gt;：IO等待所占的百分比 COMMAND：线程/进程命令，这通过查看IO速率看到的是哪个进程/线程的问题 面试常问： 它可以查哪个进程的IO是最频繁的以及它的IO速率怎么样(精确到进程)，最后 一项就是具体的某个进程COMMAND； 监控： 在zabbix监控磁盘读取和写入的速率可以判断web服务器是否受到攻击； 主要就是将Total DISK READ和Total DISK WRITE过滤出来进行监控 2.命令格式： iotop -[选项] --version：//显示程序的版本号并退出 -h, --help：//显示此帮助消息并退出 -o, --only：//仅显示实际执行I / O的进程或线程，只显示在划硬盘的程序 -b, --batch：//非交互模式，批量处理 用来记录日志的 -n NUM, --iter=NUM：//设定循环几次 -d SEC, --delay=SEC：//设定显示时间间隔[秒] -p PID, --pid=PID：//要监控的进程/线程[全部] -u USER, --user=USER：//用户监控[全部] -P, --processes：//只显示进程，而不是所有线程 -a, --accumulated：//显示累积的I / O而不是带宽 -k, --kilobytes：//使用千字节而不是人性化的单位 -t, --time：//在每一行上添加一个时间戳（暗示--batch） -q, --quiet：//抑制一些标题行（暗示--batch） 3.怎么获取该程序正在读的什么文件？ 这个问题其实很简单，通过 lsof 命令我们就可以达到目的：lsof -c APPname 同样，如果我们知道了被频繁读取的文件是哪个，也可以反查程序： iotop查看用户进程，lsof -p pid在按该用户进程 pid 查看所打开的文件，lsof -u username按用户名查看打开的文件， 列出某用户的某进程打开的文件lsof -u USERNAME -c APPNAME； 也是可以根据目录进行查询：lsof | grep path； 4.结论： 1.我们给服务器做压力测试时，有的时候很容易碰到磁盘IO读取瓶颈，持续高的IO会导致磁盘读取密集读写磁盘IO成为短 板，程序运行过慢；常见的IO服务器例如：数据库服务器，文件服务器，视频服务器等； 2.使用top命令查看%wa指标，该项阈值表示io waiting等待磁盘磁盘写入完成的时间，一般不能高于30%，假如该值过大 且持续很久，就证明遇到了I/O瓶颈，需要对软件进行优化，或对硬件进行升级； 3.iostat -d -x 1输出磁盘相关统计信息； 4.iotop定位负载来源于那个进程/线程 5.可以使用pt-ioprofile工具定位IO文件信息；（是Percona公司开发用于管理MySQL的工具） 或者使用下列命令进行IO文件定位： 1.lsof -c oracle // 2.lsof | grep path /oracle/app/oracle......................... 3.iotop //查看用户进程 4.lsof -p pid //查看该用户下打开的文件 5.lsof -u oracle -c oracle 5.补充：如何进行IO瓶颈测试？ 如何进行大文件IO测试： 1.生成 5g 大小的文件并输出时间，执行速度等信息 time dd if=/dev/zero of=test.file bs=1G count=5 2.测试写入20G数据，数据量越大，测试值应该更精确 sync;/usr/bin/time -p bash -c &quot;(dd if=/dev/zero of=test.dd bs=1M count=20000)&quot; sync;/usr/bin/time -p bash -c &quot;(dd if=/dev/zero of=test.dd bs=1000K count=20000;sync)&quot; dd bs=1M count=20000 if=/dev/zero of=test.dd conv=fdatasync dd命令测试是IO的顺序写和读方式 lsof:list open filesLsof是遵从Unix哲学的典范，它只完成一个功能，并且做的相当完美——它可以列出某个进程打开的所有文件信息。打开的文件可 能是普通的文件、目录、NFS文件、块文件、字符文件、共享库、常规管道、命名管道、符号链接、Socket流、网络Socket、UNIX域S ocket，以及其它更多类型。因为“一切皆文件”乃为Unix系统的重要哲学思想之一，因此可以想象lsof命令的重要地位; list open files查看当前系统文件的工具。在linux环境下，一切皆文件， 用户通过文件不仅可以访问常规数据，还可以访问 网络连接和硬件如传输控制 协议 (TCP) 和用户数据报协议 (UDP)套接字等，系统在后台都为该应用程序分配了一个文件描述符; lsof ［options］ filename lsof /path/to/somefile：显示打开指定文件的所有进程之列表 lsof -c string： 显示其COMMAND列中包含指定字符(string)的进程所有打开的文件；此选项可以重复 使用，以指定多个模式； lsof -p PID： 查看该进程打开了哪些文件；进程号前可以使用脱字符“^”取反； lsof -u USERNAME： 显示指定用户的进程打开的文件；用户名前可以使用脱字符“^”取反，如“lsof -u ^root”则用于显示非root用户打开的所有文件； lsof -g GID： 显示归属gid的进程情况 lsof +d /DIR/： 显示指定目录下被进程打开的文件 lsof +D /DIR/ #基本功能同上，但lsof会对指定目录进行递归查找，注意这个参数要比grep版本慢： lsof -a： #按“与”组合多个条件，如lsof -a -c apache -u apache lsof -N： #列出所有NFS（网络文件系统）文件 lsof -d FD： #显示指定文件描述符的相关进程；也可以为描述符指定一个范围，如0-2表示0,1,2三个文件描述符；另外，-d还支持其它很多特殊值，如： mem: 列出所有内存映射文件； mmap：显示所有内存映射设备； txt：列出所有加载在内存中并正在执行的进程，包含code和data； cwd：正在访问当前目录的进程列表； lsof -n： #不反解IP至HOSTNAME lsof -i： #用以显示符合条件的进程情况 lsof -i[46] [protocol][@hostname|hostaddr][:service|port] 46：IPv4或IPv6 protocol：TCP or UDP hostname：Internet host name hostaddr：IPv4地址 service：/etc/service中的服务名称(可以不只一个) port：端口号 (可以不只一个) 示例： 1.指定进程号，可以查看该进程打开的文件 [root@tomcat ~]# ps -ef | grep java root 6657 1 9 12:36 pts/0 [root@tomcat ~]# lsof -p 6657 #可以看到java进程打开的文件 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME java 6657 root cwd DIR 8,2 4096 100663361 /root [root@tomcat ~]# lsof -p 6657 | wc -l #统计打开的文件描述符总数 2.查看8080端口现在运行的情况 [root@node02 ~]# lsof -i:8080 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME java 6657 root 59u IPv6 45756 0t0 TCP *:webcache (LISTEN) #类似于于ss -tnpl|grep 8080命令 [root@node02 ~]# ss -tnpl|grep 8080 LISTEN 0 100 :::8080 :::* users:((&quot;java&quot;,pid=6657,fd=59)) 3.查看指定进程打开的网络连接 lsof -i –n -a -p 9527 参数-i、-a、-p等，-i查看网络连接情况，-a查看存在的进程，-p指定进程 4.恢复删除正在使用的文件： ~]# lsof |grep /var/log/messages #打开这个文件，模拟正在使用的情况 ~]# rm -f /var/log/messages #误删除操作 ~]# lsof |grep /var/log/messages #再次查看，就会看到delete的信息 ~]# cat /proc/653/fd/6 #进入到这个文件描述符目录，可以看到文件是红色的表示删除了 ~]# cat /proc/653/fd/6 &gt; /var/log/messages #将文件重定向即可达到恢复的目的 注意： 1.这里说的是误删除了正在使用的文件，如果某个文件未被使用删除了那就不能恢复了； 2.在清除mysql日志的时候如果误删除了就可以使用这种方法； lsof输出信息解释： 上述命令中，每行显示一个打开的文件，若不指定条件默认将显示所有进程打开的所有文件。lsof输出各列信息的意义如下： COMMAND：进程的名称 PID：进程标识符 USER：进程所有者 FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等 TYPE：文件类型，如DIR、REG等 DEVICE：指定磁盘的名称 SIZE：文件的大小 NODE：索引节点（文件在磁盘上的标识） NAME：打开文件的确切名称]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux网络管理命令]]></title>
    <url>%2F2017%2F02%2F01%2Flinux%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[linux网络管理命令：route、netstat、ip、ss命令 route命令路由管理命令 查看：route -n 添加：route add route add [-net|-host] target [netmask Nm] [gw Gw] [[dev] If] 目标：192.168.1.3 网关：172.16.0.1 route add -host 192.168.1.3 gw 172.16.0.1 dev eth0 目标：192.168.0.0 网关：172.16.0.1 route add -net 192.168.0.0 netmask 255.255.255.0 gw 172.16.0.1 dev eth0 或者使用： route add -net 192.168.0.0/24 gw 172.16.0.1 dev eth0 默认路由，网关：172.16.0.1 route add -net 0.0.0.0 netmask 0.0.0.0 gw 172.16.0.1 或者使用： route add default gw 172.16.0.1 删除：route del route del [-net|-host] target [gw Gw] [netmask Nm] [[dev] If] 目标：192.168.1.3 网关：172.16.0.1 route del -host 192.168.1.3 目标：192.168.0.0 网关：172.16.0.1 route del -net 192.168.0.0 netmask 255.255.255.0 netstat命令netstat命令是一个监控TCP/IP网络的非常有用的工具，它可以显示路由表、实际的网络连接以及每一个网络接口设备的状态信息； [root@node02 3615]# rpm -qf /usr/bin/netstat net-tools-2.0-0.24.20131004git.el7.x86_64 #netstat和route命令都来自net-tools包 netstat [选项]：常用前8个 -t或--tcp：显示TCP传输协议的连线状况； -u或--udp：显示UDP传输协议的连线状况； -l或--listening：显示监控中的服务器的Socket； -n或--numeric：直接使用ip地址，而不通过域名服务器； -a或--all：显示所有连线中的Socket； -e或--extend：显示网络其他相关信息； -p或--programs：显示正在使用Socket的程序识别码和程序名称； -r或--route：显示Routing Table； 即：netstat -r = route -n -A&lt;网络类型&gt;或--&lt;网络类型&gt;：列出该网络类型连线中的相关地址； -c或--continuous：持续列出网络状态； -C或--cache：显示路由器配置的快取信息； -F或--fib：显示FIB； -g或--groups：显示多重广播功能群组组员名单； -h或--help：在线帮助； -i或--interfaces：显示网络界面信息表单； -M或--masquerade：显示伪装的网络连线； -N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称； -o或--timers：显示计时器； -s或--statistice：显示网络工作信息统计表； -v或--verbose：显示指令执行过程； -V或--version：显示版本信息； -w或--raw：显示RAW传输协议的连线状况； -x或--unix：此参数的效果和指定&quot;-A unix&quot;参数相同； --ip或--inet：此参数的效果和指定&quot;-A inet&quot;参数相同 常用组合： -tan, -uan, -tnl, -unl 统计示例： [root@node02 3615]# netstat -ntau Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN tcp 0 0 192.168.34.118:22 192.168.34.1:4436 ESTABLISHED ~]# netstat -ntau| sed -nr &apos;/^tcp/s/.* ([^ ]+) ?/\1/p&apos;|sort |uniq -c 1 ESTABLISHED 7 LISTEN ip命令配置Linux网络属性：ip命令 ip - show / manipulate routing, devices, policy routing and tunnels ip [ OPTIONS ] OBJECT { COMMAND | help } OBJECT := { link | addr | route } ip link - network device configuration set dev IFACE 可设置属性： up and down：激活或禁用指定接口 ifup/ifdown show [dev IFACE]：指定接口 [up]：仅显示处于激活状态的接口 ip addr { add | del } IFADDR dev STRING [label LABEL]：添加地址时指明网卡别名 [scope {global|link|host}]：指明作用域 global: 全局可用 #默认网卡时工作在内核的 link: 工作在链接层 #即通过这个网卡的链路进来的才接收，从当前主机的其他网卡进来的都不接收 前提是/proc/sys/net/ipv4/ip_forward=1打开了核心转发功能 host: 本机可用 [broadcast ADDRESS]：指明广播地址 ip address show - look at protocol addresses [dev DEVICE] [label PATTERN] #加标签=网卡别名 [primary and secondary] ip address flush - 使用格式同show ip addr add 172.16.100.100/16 dev eth0 label eth0:0 ip addr del 172.16.100.100/16 dev eth0 label eth0:0 ip addr flush dev eth0 label eth0:0 ip route - routing table management 添加路由：ip route add ip route add TARGET via GW dev IFACE src SOURCE_IP TARGET: 主机路由：IP 网络路由：NETWORK/MASK ip route add 192.168.0.0/24 via 172.16.0.1 ip route add 192.168.1.13 via 172.16.0.1 添加网关：ip route add default via GW dev IFACE ip route add default via 172.16.0.1 删除路由： ip route del TARGET 显示路由： ip route show|list 清空路由表： ip route flush [dev IFACE] [via PREFIX] ip route flush dev eth0 ss命令[root@node02 ~]# which ss /usr/sbin/ss [root@node02 ~]# rpm -qf /usr/sbin/ss iproute-4.11.0-14.el7.x86_64 #ip和ss命令都来自iproute这个包 优点： 在网络连接特别多的时候，使用ss显示特别快，使用netstat特别慢； 格式：ss [OPTION]... [FILTER] netstat通过遍历proc来获取socket信息，ss使用netlink与内核tcp_diag模块通信获取 socket信息。 选项： -t: tcp协议相关 -u: udp协议相关 -w: 裸套接字相关 -x：unix sock相关 -l: listen状态的连接 -a: 所有 -n: 数字格式 -p: 相关的程序及PID -e: 扩展的信息 -m：内存用量 -o：计时器信息 FILTER : [ state TCP-STATE ] [ EXPRESSION ] TCP的常见状态： tcp finite state machine: LISTEN: 监听 ESTABLISHED：已建立的连接 FIN_WAIT_1 FIN_WAIT_2 SYN_SENT SYN_RECV CLOSED EXPRESSION: dport = sport = 示例：&apos;( dport = :ssh or sport = :ssh )&apos; 常用组合： -tan, -tanl, -tanlp, -uan 统计示例： [root@node02 ~]# ss -ant | awk &apos;NR&gt;1 {++s[$1]} END {for(k in s) print k,s[k]}&apos; LISTEN 7 ESTAB 1]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS类型及实现]]></title>
    <url>%2F2017%2F01%2F20%2FLVS%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[LVS LVS集群的4种网络模型LVS Type是指lvs工作的拓扑结构和转发机制 1.NAT:多目标DNAT，通过修改请求报文的目标IP和Port为经由调度算法挑选出的某后端RS的 RIP和PORT，再发送到POSTROUTING链上 2.DR:不动源IP、源端口、目标IP、目标端口，即传输层TCP/UDP首部保持不变，转发方式通过 先拆除帧首部再在IP报文外封装新的以太网帧首部(源MAC-DIPmac,目标MAC-RIPmac)扔回给交换机，由交换机通过MAC地址完成调度， 目标MAC是由调度算法挑选出的某后端 RS的MAC地址; 而MAC地址通信就意味着是在本地网络中，所以DR模型就限制了DIP和RIP在同一个二层网络设备中， 中间不能隔路由器和网关只能由交换机来进行交换，来实现调度. 3.TUN:IP隧道方式;转发方式： 不修改请求报文的IP首部（源IP为CIP，目标IP为VIP），而是在原IP报文之外再封装 一个新的IP首部（源IP是DIP，目标IP是RIP），这样报文就有两个IP首部(内部一个，外部还一个)，这就叫做IP隧道，将报文发往挑选出的目标 RS；RS直接响应给客户端（源IP是VIP，目标IP是CIP）,这样就弥补了DR模型必须在同 一个物理网络的限制，TUN模型不受限于网络. 4.FULLNAT:默认不支持，需要打内核补丁 通过修改请求报文的源IP和目标IP为经由调度算法挑选出的某后端的RS的RIP和PORT； 不过一般不修改源端口和目标端口。CIP--&gt;DIP;VIP--&gt;RIP、 LVS-NAT模式和特性 NAT:多目标DNAT，通过修改请求报文的目标IP和Port为经由调度算法挑选出的某后端RS的 RIP和PORT，再发送到POSTROUTING链上 1.DIP和各个RIP必须在同一个网段内； 2.RS应该使用私有地址，且RS的网关必须指向DIP;RIP:GW---&gt;DIP； 3.支持端口映射(转换)；VIP:80---&gt;RIP:8080,而后端有多个RS，所以也叫多目标IP的DNAT 4.请求和响应报文都必须经过Director Server转发,高负载场景中，Director Server易成为性能瓶颈； DNAT的工作原理： 请求报文中的源IP(CIP)--&gt;目标IP(VIP);而响应报文中的源IP(RIP)--&gt;目标IP(CIP), 对于客户端来说并未访问RIP，所以响应报文必须经由DIP(网关)，将源IP(RIP)改成VIP，对CIP来说才能接收 到正常的响应报文，这就是为什么RIP的网关必须指向DIP，而这个过程是由NAT内部的连接追踪功能自动完成的. 5.LVS必须是linux系统，因为LVS只支持linux,而RS可以使用任意操作系统,因为只是应用层协议的交互调度. 缺陷： 1.对Director Server压力会比较大，因为请求和响应都需经过director server 一般来说web应用的GET中用户的请求报文很轻，而响应报文中要承载用户资源数据(很大)，由于NAT模型的原因响应报文还必须经由Director Server, 那么Director Server服务器的压力就很大，后端的RS最多也就5、6个而已，这就是为什么有DR模型的存在了. 2.DIP和RIP必须在同一个IP网段，中间不能隔路由器，Director和RS的位置就不能距离太远，一般是在同一个机架上. lvs-nat： 设计要点： (1) RIP与DIP在同一IP网络, RIP的网关要指向DIP； (2) 支持端口映射； (3) Director要打开核心转发功能； 实践作业（博客）：负载均衡两个php应用（wordpress，discuzx）； 测试：(1) 是否需要会话保持；(2) 是否需要共享存储； LVS-DR模式和特性 1.DR模型是如何解决NAT模型中Director Server易成为性能瓶颈的问题的？ 响应报文是不需要不经由Director Server的，所以极大的缓解了 Director只需要有一个网卡和RS在同一个二层网络中(可以连不同交换机，交换机在连接) 特点： 1.Director Server和RS在同一个二层网络中(可以在同一个交换机也可以在不同 交换机，但交换机是相连的),中间是不能隔路由器的！ 2.Director Server只有VIP，没有DIP 3.响应报文由RS直接通过交换机--&gt;路由器发送给客户端，所以就要求各个RS有两个IP 一个是RIP，一个是VIP，而且响应报文发出时的源IP必须是VIP不能是RIP. 4.RS和Director必须在同一物理网络，因为需要MAC地址完成地址解析报文转发的; 5.RS的RIP可以使用私网地址，也可以是公网地址，RIP与DIP在同一IP网络(因为要apr的广播应答找到某一RS的MAC地址完成报文传输)， RIP的网关一定不能指向Director(一旦指定DIP，那么响应报文就会经由Director进行转发了!) 6.请求报文必须先经由Director，但响应报文不能经由Director(理由同上5)，而是由RS直接发往客户端; 7.不支持端口映射；因为报文是由RS直接发往客户端的，如果Director转发时将端口进行映射80:8080，那么RS的VIP响应时也是8080端口响应的！ LVS-DR模型必须要解决地址冲突问题： 1.Director Server和RS是在同一个网络中的，如何解决地址冲突问题的？ 由于ARP本地工作逻辑和地址解析协议，每个主机加入到网络中来时，一般来说会有两类ARP报文发送； 即通告和广播请求，但arp解析地址缓存有效时长是5min(IP和 MAC的对应关系)，再次需要通信时，就需要arp_request请求，而请求是广播式的， 由于本地有多个VIP，就会产生arp冲突。 解决arp冲突的办法： 1.在前端的路由器上把VIP和Director的MAC进行绑定，如果LVS使用keepalived做 高可用，备用的LVS的MAC地址肯定和主LVS的MAC地址不一样，所以切换时还需要重新绑定，这样可用性就很差了，无法实现. 2.让RS的VIP地址的ARP通告和广播应答出不去即可，而方式又有两种 a.arptables就是arp防火墙，但是依赖第三方工具. b.通过修改各个RS服务器的内核参数达到不让RS的VIP进行ARP通告和响应的目的；而linux内核从2.4.x， 2.6.x只要是linux系统都可以修改内核参数中的apr通告和应答方式就能做到加入到当前网络时， 不与通告apr信息,不与应答前端路由器和网关发送的apr路由信息; 2.RS是如何做到响应报文源IP是VIP而不是RIP的？ 因为Director将源报文(CIP-VIP)进行封装一次以太网帧首部(DIP-MAC--&gt;RIP-MAC),RS收到报文后拆除 以太网帧首部后看到的IP层的源IP是CIP，目标IP是本机的VIP，所以响应时的源IP是本机的VIP，目标IP是CIP，完成报文传输. 缺点： DR类型，DIP和RIP是通过MAC地址传输报文的，所以和NAT类型一样也需要在同一物理网络中，而且不能隔路由器，不易于异地容灾. lvs-dr： 设计要点： dr模型中，各主机上均需要配置VIP，解决地址冲突的方式有三种： (1) 在前端网关做静态绑定； (2) 在各RS使用arptables； (3) 在各RS修改内核参数，来限制arp响应和通告的级别； 限制响应级别：arp_ignore 0：默认值，表示可使用本地任意接口上配置的任意地址进行响应； 1: 仅在请求的目标IP配置在本地主机的接收到请求报文接口上时，才给予响应； 限制通告级别：arp_announce 0：默认值，把本机上的所有接口的所有信息向每个接口上的网络进行通告； 1：尽量避免向非直接连接网络进行通告； 2：必须避免向非本网络通告； 注意： arp_ignore和arp_announce这两个参数是接口级别的，应该在服务器所在的所有接口上都配置，避免出现问题； LVS-DR类型实现之-调整内核中的APR参数APR通告和应答： 1.如果服务器有多个网卡，当加入到某个网络，默认会把IP和MAC地址的对应关系通告给每一个网络； 2.2.4.x kernels和2.6.x kernels都支持修改内核中的apr参数来限制apr的通告和应答，避免各个RS的lo回环网卡在配置上VIP时通告给其他网络. 3.arp_ignore参数是关闭了前端直连网关的arp应答； 4.arp_announce参数，由于VIP是配置在lo上的，arp通告只是通告给其直接连接的所在网络，而lo所在网络是 专有网关不是直连网络所以不会进行arp通告. 注意： 1.为了避免出现问题，最好是在/proc/sys/net/ipv4/conf下的all和lo网卡上都对这两项参数做限制； 2.Director的VIP的设置需要注意的是使用255.255.255.255netmask，使用此掩码是为了避免与其他主机进行多余 通信，然后广播只发给自己broadcat VIP》 脚本实现： 各个RS都执行此脚本，方便关闭和启用： [root@node03 ~]# lvs_dr_rs.sh #!/bin/bash vip=172.18.140.10 #VIP地址 mask=&apos;255.255.255.255&apos; # interface=&quot;lo:0&quot; #rpm -q httpd &amp;&gt; /dev/null || yum -y install httpd &amp;&gt;/dev/null #service httpd start &amp;&gt; /dev/null &amp;&amp; echo &quot;The httpd Server is Ready!&quot; #echo &quot;&lt;h1&gt;`hostname`&lt;/h1&gt;&quot; &gt; /var/www/html/index.html case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $interface $vip netmask $mask broadcast $vip up route add -host $vip dev $interface #添加到达VIP的路由信息 echo &quot;The RS Server is Ready!&quot; ;; stop) ifconfig $interface down #VIPdown后，路由和IP也就没有了只需清楚内核参数即可 echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;The RS Server is Canceled!&quot; ;; *) echo &quot;Usage: $(basename $0) start|stop&quot; exit 1 ;; esac IPIP:LVS-TUN：异地容灾 目的： 不管是NAT还是DR类型，由于其特点限制必须在同一个机房中，不易于容灾，所以就需要有IP隧道(TUN)类型的. 转发方式： 1.Director不修改请求报文的IP首部(源IP为CIP，目标IP为VIP)，而在原IP报文之外再 封装一个IP首部(源IP是DIP，目标IP是RIP,将报文发往挑选出的目标RS； RS直接响应给客户端(源IP是VIP，目标IP是CIP); 2.当RS收到报文后，拆除第一层IP首部(VIP-RIP)看到的是(CIP-VIP),那么所有的RS都需要配置一个VIP, 但此时确不会出现DR模型的apr冲突的问题，因为这些服务器在不同的机房中，不存在这种情况. 特点： 1.DIP,VIP,RIP都需要是公网地址； 2.由于距离的限制，RS的网关也不能指向DIP的； 3.请求报文要经由Director，但响应报文不能经由Director(同DR模型)； 4.不支持端口映射(同DR模型原理)； 5.RS的操作系统需要支持IP隧道功能； 缺点： 由于MTU的最大值是1500字节，留给IP层、TCP层、传输层、首部的也就40字节，而IPIP类型则会多出一个IP层首部， 即1520字节，而很多路由器设备会将1520的传输单元进行切片才能进行传输,所以对于TUN类型的必须人为指定最大传 输单元，留出额外需要封装的IP首部大小而不超过1500. FullNatFullNat类型没有收录到linux内核中；需要打补丁; FullNAT工作原理： 为了弥补NAT类型的DNAT中的RS网关必须指向DIP，FullNAT则在转发给RS时的源IP和目标IP由CIP-&gt;VIP修改为 DIP-&gt;RIP,RS的响应报文则由RS直接响应给DIP，即使中间跨多个路由器，也会转发给Director,Director最终响应给CIP 优点： 既有DR模型中不受限于距离限制的，又可以通过NAT模型不直接将RS暴露在公网的完全有点. LVS的实现：ipvsadm1.ip_vs:先启用内核中的ip_vs模块，默认是没启用的 2.生成ipvs规则：使用ipvsadm工具 1.先定义集群服务：service 三种定义集群服务的方式： 1.TCP协议+端口 2.UDP协议+端口 3.FireWall Mark：混合上面两种方式 2.编辑管理集群服务的RS Server RIP+端口 3.安装ipvsadm， [root@node01 ~]# yum -y install ipvasdm [root@node01 ~]# rpm -ql ipvsadm /etc/sysconfig/ipvsadm-config /usr/lib/systemd/system/ipvsadm.service #Unitfile文件 /usr/sbin/ipvsadm #二进制主程序 /usr/sbin/ipvsadm-restore #重载规则 /usr/sbin/ipvsadm-save #保存现有规则 4.负载均衡集群设计时要注意的问题： (1) 是否需要会话保持； (2) 是否需要共享存储； 共享存储：NAS， SAN， DS（分布式存储） 数据同步： 课外作业：rsync+inotify实现数据同步 5.健康状态检测缺点： 1.LVS的Director不会对后端RS集群的健康状态做检测，不像Nginx或者HAproxy可以对后端集群对健康状态检测， 并根据检测结果动态的添加或移除某个RS，这也是LVS的极大缺陷. 2.但可以通过其他软件实现，如keepalived高可用IPVS，顺便为ipvs添加了多个checks检测器，从而周期性的检测 后端RS是否为健康的. FireWall Mark：防火墙标记为服务提供分类器，从而实现将多个服务归类一个服务； 1.比如对80和443端口的访问，如果不用防火墙标记的话，需要定义两个LVS集群;但是这两个端口对应的又是一个服务， 我们不希望区别对待,就可以对进来的报文进行标记; 2.iptables的mangle表(修改报文格式)，对报文进行分类，在PREROUTING链上对进来的报文进行标记，对80和443端口 的报文都定义为一类服务，然后再ipvsadm进行firewalld mark进行定义. 示例： 1.标记 iptables -t mangle -A PREROUTING -d 172.18.140.10 -p -m multiport --dports 80,443 -j MARK --set-mark 6 #在刚进入linux服务器时，对进来对172.18.140.10的80和8080的访问都归于6号mark中 2.添加集群： ipvsadm -A -f 6 -s wrr #对FWM为6的设置一个集群，因为FWM=6已经有IP了只需要指定算法就行了. 3.添加RS ipvsadm -a -f 6 172.18.140.5 -g -w 1 ipvsadm -a -f 6 172.18.140.6 -g -w 1 #因为访问的端口有80和8080，所以后端RS是不能写端口的 4.查看规则： [root@node01 data]# ipvsadm -Ln FWM 6 wrr -&gt; 172.18.140.5:0 Route 1 0 0 -&gt; 172.18.140.6:0 Route 1 0 0 #因为0端口代表通配，用于通配FWM 6中的80和8080端口 ipvsadm命令：核心功能： 集群服务管理：增、删、改； 集群服务的RS管理：增、删、改； 查看： ##大写的命令是用来管理集群服务的，后面必须跟集群服务地址 ##小写的命名是用来管理后端RS集群的； ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [--pe persistence_engine] [-b sched-flags] ipvsadm -D -t|u|f service-address ipvsadm -C ipvsadm -R ipvsadm -S [-n] ipvsadm -a|e -t|u|f service-address -r server-address [options] ipvsadm -d -t|u|f service-address -r server-address ipvsadm -L|l [options] ipvsadm -Z [-t|u|f service-address] #清空集群的连接数计算器 管理集群服务：增、改、删； 增、改： ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] 删： ipvsadm -D -t|u|f service-address service-address： -t|u|f： -t: TCP协议的端口，VIP:TCP_PORT -u: UDP协议的端口，VIP:UDP_PORT -f：firewall MARK，是一个数字； [-s scheduler]：指定集群的调度算法，默认为wlc； 管理集群上的RS：增、改、删； 增、改： ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 删： ipvsadm -d -t|u|f service-address -r server-address server-address： rip[:port] 选项： lvs类型： -g: gateway, DR类型 -i: ipip, TUN类型 -m: masquerade, NAT类型 -w weight：权重； 清空定义的所有内容： ipvsadm -C 查看： ipvsadm -L|l [options] --numeric, -n：numeric output of addresses and ports --exact：expand numbers (display exact values) --connection， -c：output of current IPVS connections --stats：统计计算器的总和值 --rate ：统计速率值 保存和重载： ipvs和iptables一样，规则写完是送到内核内存中保存的，内核一旦关闭，规则也就没有了，所以必要时一定要将规则保存起来. 保存： ipvsadm -S = ipvsadm-save &gt; /etc/sysconfig/ipvsadm 重载： ipvsadm -R = ipvsadm-restore 设置开机自启： systemctl enable ipvsadm #启动时自动加载保存好的规则 ##因为ipvsadm启动时加载的文件是/etc/sysconfig/ipvsadm，只需要将规则保 存到此文件中，就会启动时自动加载，规则就不会丢失了. [root@node01 data]# vim /usr/lib/systemd/system/ipvsadm.service [Service] Type=oneshot ExecStart=/bin/bash -c &quot;exec /sbin/ipvsadm-restore &lt; /etc/sysconfig/ipvsadm&quot; ExecStop=/bin/bash -c &quot;exec /sbin/ipvsadm-save -n &gt; /etc/sysconfig/ipvsadm&quot; LVS-NAT类型实验(Docker上实现)：1.先在docker上启动两个容器作为RS，为了方便区别，分别在web页面下创建index.html文件以示区别 [root@node01 ~]# docker run --name c1 -it -v /data/vols/vol1:/data/web/html busybox cd /data/web/html vim index.html nginx1 [root@node01 ~]# docker run --name c2 -it -v /data/vols/vol2:/data/web/html busybox cd /data/web/html vim index.html nginx2 2.定义集群，以宿主机的桥接IP为VIP [root@node01 vols]# ipvsadm -A -t 172.18.140.6:80 -s wrr #创建一个集群，并指定调度算法为wrr加权轮询 3.向集群添加两个RS #向集群添加RS，并指定-m为NAT类型，权重为都是1 [root@node01 vols]# ipvsadm -a -t 172.18.140.6:80 -r 172.17.0.2:80 -m -w 1 [root@node01 vols]# ipvsadm -a -t 172.18.140.6:80 -r 172.17.0.3:80 -m -w 1 #查看定义好的集群 [root@node01 vols]# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 172.18.140.6:80 wrr -&gt; 172.17.0.2:80 Masq 1 0 0 -&gt; 172.17.0.3:80 Masq 1 0 0 4.在其他服务器进行测试 [root@node02 ~]# while true;do curl 172.18.140.6; done nginx1 nginx2 nginx1 nginx2 nginx1 nginx2 #可以看到是根据wrr算法进行调度的 5.修改其中一个RS的权重： 修改： [root@node01 vols]# ipvsadm -e -t 172.18.140.6:80 -r 172.17.0.2:80 -m -w 2 #此时权重就为2： [root@node01 vols]# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 172.18.140.6:80 wrr -&gt; 172.17.0.2:80 Masq 2 0 37 -&gt; 172.17.0.3:80 Masq 1 0 36 测试： [root@node02 ~]# while true;do curl 172.18.140.6; done nginx2 nginx1 nginx1 nginx2 #可以看到权重比和调度的关系 6.终止其中一个后端RS： docker kill c2 #终止RS-c2 [root@node02 ~]# while true;do curl --connect-timeout 1 172.18.140.6 sleep .5; done curl: (28) Connection timed out after 1001 milliseconds curl: (28) Resolving timed out after 1517 milliseconds curl: (6) Could not resolve host: .5; Unknown error nginx2 curl: (28) Resolving timed out after 1517 milliseconds #因为LVS没有对后端RS健康状态检测的功能，所以即使后端的RSdown了，也会被调度上去,这也是LVS的一个重要缺点. LVS-DR类型实验：1.环境准备： 4台物理机： node01 172.18.140.6 node02 172.18.140.5 node03 172.18.140.7 #都关闭防火墙 [root@node01 ~]# systemctl stop firewalld.service [root@node01 ~]# systemctl disable firewalld.service 2.安装httpd [root@node01 ~]# yum install httpd -y [root@node01 ~]# systemctl start httpd 3.为node2和ndoe3进行内核参数设置 [root@node03 ~]# lvs_dr_rs.sh #!/bin/bash vip=172.18.140.10 #VIP地址 mask=&apos;255.255.255.255&apos; # interface=&quot;lo:0&quot; #rpm -q httpd &amp;&gt; /dev/null || yum -y install httpd &amp;&gt;/dev/null #service httpd start &amp;&gt; /dev/null &amp;&amp; echo &quot;The httpd Server is Ready!&quot; #echo &quot;&lt;h1&gt;`hostname`&lt;/h1&gt;&quot; &gt; /var/www/html/index.html case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $interface $vip netmask $mask broadcast $vip up route add -host $vip dev $interface #添加到达VIP的路由信息 echo &quot;The RS Server is Ready!&quot; ;; stop) ifconfig $interface down #VIPdown后，路由和IP也就没有了只需清楚内核参数即可 echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;The RS Server is Canceled!&quot; ;; *) echo &quot;Usage: $(basename $0) start|stop&quot; exit 1 ;; esac 4.为node1设置VIP ifconfig ens37:0 172.18.140.10 netmask 255.255.255.255 broadcast 172.18.140.10 5.添加集群和RS ipvsadm -A -t 172.18.140.10:80 -s wrr ipvsadm -a -t 172.18.140.10:80 -r 172.18.140.5 -g -w 1 ipvsadm -a -t 172.18.140.10:80 -r 172.18.140.7 -g -w 2 6.测试调度效果： [root@node04 ~]# while true; do curl 172.18.140.10 ; done node03 node03 node2 node03 node03 #显示轮询调度效果 7.修改调度算法： 修改为源地址sh的算法： [root@node01 data]# ipvsadm -E -t 172.18.140.10:80 -s sh 测试： [root@node04 ~]# while true; do curl 172.18.140.10 ; done node2 node2 node2 #可以看到同一个地址，始终会被调度到一个后端RS上. LVS的持久连接机制实现lvs persistence：持久连接 持久连接模板：实现无论使用任何调度算法，在一段时间内，能够实现将来自同一个地址的请求始终发往同一个RS； ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] port Affinity： 每端口持久：每个端口对应定义为一个集群服务，每集群服务单独调度； 每防火墙标记持久：基于防火墙标记定义集群服务；可实现将多个端口上的应用统一调度，即所谓的port Affinity； 每客户端持久：基于0端口定义集群服务，即将客户端对所有应用的请求统统调度至后端主机，必须定义为持久模式； 持久连接和算法无关系，和采用的持久连接方式有关！ session 绑定：对共享同一组RS的多个集群服务，需要统一进行绑定，lvs sh算法无法实现 对于sh的算法来说，某个IP地址的访问会通过hash PCC:所有端口 PFWM:持久防火墙标记 PPC:单个端口]]></content>
      <categories>
        <category>负载均衡</category>
        <category>LVS</category>
      </categories>
      <tags>
        <tag>LB负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的日志]]></title>
    <url>%2F2017%2F01%2F12%2Fmysql%E7%9A%84%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[Mysql的日志功能 1.对于一个数据库管理系统来讲，它的日志文件种类非常多，这些日志文件表现在mysql物理视图上的各类文件，只不过当 mysql使用不同的存储引擎，日志文件的表示方式有所不同而已； 2.对于MyISAM来说每个表都有三个文件(*.MYD,*.MYI,*.frm)，对于InnoDB来说每个表有两个文件(*.ibd,*.frm)这些都是真正 的存储的数据文件，为了保证mysql服务器正常运行和记录mysql运行中产生的事件、错误等，mariadb有诸多类型的日志功能， 这些日志文件最终还要表现为存储的一种文件的，所以mariab除了数据、索引文件之外还有第三类文件： 查询日志(通用日志)：query log(general log),默认是不开启的 慢查询日志:slow query log 错误日志:error log 二进制日志:binary log 中继日志:reley log 事务日志:transaction log mysql的客户端日志 家目录下隐藏的.mysql_history，记录在客户端上操作的命令 下文介绍每一种日志类型的配置和使用 1.查询日志:general log查询日志也叫通用日志就是记录查询操作，这些查询信息可以记录在两种位置： 1.文件file 2.表中table MySQL [(none)]&gt; show GLOBAL VARIABLES like &apos;%gen%&apos;; +------------------+------------------------+ | Variable_name | Value | +------------------+------------------------+ | general_log | OFF | #默认是关闭的 | general_log_file | /data/mysql/node02.log | #日志名称=简写的主机名.log | log_output | FILE | #日志输入路径为FILE或TABLE +------------------+------------------------+ log_output FILE #日志可以保存在file，也可以是table 2.慢查询日志1.在mysql中查询语句超出指定界限的都叫慢查询，一旦超出这个界限就会把这个语句记录下来，随后分析慢的原因； 2.慢查询并不一定是查询语句自己执行速度慢导致的，有可能是这个查询语句所需要查询依赖的表被施加了写锁阻塞了查询； 3.慢查询参数： MySQL [(none)]&gt; show GLOBAL VARIABLES like &apos;%slow%&apos;; +---------------------------+-----------------------------+ | Variable_name | Value | +---------------------------+-----------------------------+ | slow_query_log | OFF | #默认是关闭 | slow_query_log_file | /data/mysql/node02-slow.log | #日志文件路径 | log_slow_rate_limit | 1 | | log_slow_filter | | | log_slow_queries | OFF | | log_slow_verbosity | Query_plan,explain | +---------------------------+-----------------------------+ 注意： 1.为了排查问题，一般都要开启慢查询日志的 2.log_slow_filter是慢查询日志过滤器，定义日志是如何被记录的，默认配置即可； 3.log_slow_queries和slow_query_log没区别； 4.log_slow_rate_limit是记录日志记录的速率 5.log_slow_verbosity是记录慢查询日志的详细度的，根据实际情况而定； 4.慢查询时长： MySQL [(none)]&gt; show GLOBAL VARIABLES like &apos;%long%&apos;; +--------------------------------------+-----------+ | Variable_name | Value | +--------------------------------------+-----------+ | long_query_time | 10.000000 | #慢查询时长 +--------------------------------------+-----------+ 修改慢查询时长的方法： MySQL [(none)]&gt; SET GLOBAL long_query_time=15; #临时有效 5.修改慢查询日志参数使其永久有效： 上面通过命令的方法都是临时有效的，要想永久有效就需要写在配置文件中 [root@node02 mysql]# vim /etc/my.cnf slow_query_log=ON slow_query_log_file=/data/mysql/mysql-master-slow.log long_query_time=15 6.使用慢查询日志 上面慢查询日志可以看出查询慢，但是为什么慢？ 可以通过profiling； show @@profiling; show profiles;启用后查询记录 show profile for query 5; set profiling=on 3.错误日志：error log错误日志并不能完全按照名字理解，因为它记录的并不全是错误信息，它包括： 1.mysql服务器启动、关闭所产生的事件信息； 2.mysqld运行中产生的错误信息，称为错误日志的主要原因； 3.event scheduler运行一个event时产生的日志信息； 4.在主从复制架构中的从服务器上启动从服务器线程时产生的错误信息； 相关参数： MySQL [(none)]&gt; show GLOBAL VARIABLES like &apos;%log_error%&apos;; +---------------------+---------------------+ | Variable_name | Value | +---------------------+---------------------+ | log_error | /var/log/mysqld.log | #错误日志路径，可自定义 | log_warnings | 1 | #记录警告信息到错误日志中 +---------------------+---------------------+ log_warnings记录是否记录警告信息到错误日志中； log_warnings = [0|1] 设置错误日志路径： [root@mysql ~]# vim /etc/my.cnf [mysqld_safe] log-error=/data/mysql/error_log.log #注意是在mysqld_safe下修改而不是mysqld下 4.二进制日志1.二进制文件的作用： 1.二进制日志主要记录mysql所接收到的查询语句当中潜在引起数据发生改变的SQL语句，由于它保存下来就是以二进制格式保存的，所以叫二进制日志； 2.不要用cat命令打开这个文件，可能造成文件损坏； 3.功能：用于通过&quot;重放&quot;日志文件中的事件来生成数据副本; 4.二进制日志文件要和数据分开存放到不同的磁盘上，而且这些磁盘最好都做raid10来保证数据安全； 2.相关命令： 1.SHOW {BINARY | MASTER} LOGS 1.显示mysql正在使用中的所有二进制日志文件列表，但是要注意mysql的二进制文件是滚动的，重启mysql后会生成一个新的二进制文件； 2.这个命令是通过mysql数据目录下的node02-bin.index的二进制索引文件来显示的； 2.SHOW MASTER STATUS #显示mysql当前正在使用的二进制日志文件 3.SHOW BINLOG EVENTS [IN &apos;log_name&apos;] [FROM pos] [LIMIT [offset,] row_count] #显示某个二进制日志文件有哪些日志事件 3.二进制日志记录的三种格式： 1.基于&quot;语句&quot;记录:statement 2.基于&quot;行&quot;记录:row，日志量会很大 3.混合模式:mixed,让系统自己判定改基于哪种方式进行 4.二进制日志文件的构成： 有两类： 1.日志文件：mysql|mariadb-bin.文件名后缀，二进制格式 2.索引文件：mysql|mariadb-bin.index，文本格式 注意：这个索引不是mysql内部的索引，而是二进制文件的个数，它是用来追踪mysql/mariadb正在使用中的可用的二进制日志文件序列； 5.和二进制文件相关的服务器变量： MySQL [(none)]&gt; show GLOBAL VARIABLES like &apos;%log%&apos;; +-------------------+-------------+ | Variable_name | Value | | sql_log_bin | ON | #启用二进制日志 | log_bin | OFF | #表示日志的路径,默认是OFF，必须为ON | binlog_format | STATEMENT | #二进制日志的格式 | max_binlog_size | 1073741824 | #日志自动滚动的大小，默认1G | sync_binlog | 0 | | expire_logs_days | 0 | #日志的过期时长，0表示不启用 +-------------------+-------------+ 1.log_bin和sql_log_bin都是可以控制启用二进制日志的，2项只要有一项是ON的就表示启用了二进制日志； 2.log_bin=/PATH/TO/BIN_LOG_FILE:表示二进制日志存放的路径,默认是OFF的； 必须改成ON,才能记录二进制日志 (注意不要写成log_bin=on),因为=等号后面跟的是存放路径和文件前缀名称; 3.binlog_format=STATEMENT|ROW|MIXED:二进制日志记录的格式 4.max_binlog_size=1073741824 1.对于生产环境来说如果不做日志滚动的话，当事务量较大时单个日志文件会很大，那么日志重放就会很慢，所以单个二进制日志文件不能太大； 2.单个二进制日志文件的最大体积，到达最大值会自动滚动，默认为1G 5.sync_binlog=0|1；设定是否启动二进制日志同步功能； 1-表示当遇到事务commit时就要触发一次将语句同步到二进制文件中的操作；等于 1虽然会影响，但是保证出现故障时的数据安全性 0-表示由操作系统负责同步日志到磁盘； 至于应该怎么选择取决于生成环境下领导怎么决定。。。 6.expire_logs_days=0: 二进制日志可以自动删除的天数，默认是0，0表示不启用根据时间自动删除的功能； 6.二进制日志中的事件格式:mysqlbinlog 有一个客户端命令可以直接查看生成的二进制日志文件：mysqlbinlog 命令格式： mysqlbinlog [OPTIONS] log_file… --start-position=# 指定开始位置 --stop-position=# --start-datetime= --stop-datetime= 通过mysqlbinlog查看数据目录下的/data/mysql/node02-bin.000002正在使用的二进 制日志文件看到： [root@mysql ~]# mysqlbinlog /data/mysql/node02-bin.000002 # at 328 #180306 16:32:42 server id 1 end_log_pos 431 Query thread_id=1 exec_time=0 error_code=0 use `mydb`/*!*/; SET TIMESTAMP=1446712300/*!*/; CREATE database ceshi /*!*/; 具体代表意义： 事件发生的日期和时间：180306 16:32:42 事件发生的服务器标识：server id 1 事件的结束位置：end_log_pos 431 事件的类型：Query(广义上来讲所有语句都必须先执行Select,所以这里都是查询) 事件发生时所在服务器执行此事件的线程的ID：thread_id=1 语句的时间戳与将其写入二进制文件中的时间差：exec_time=0 错误代码：error_code=0 时间内容： 后面三项都属于事件的内容 GTID：Global Transaction ID称为全局事务的ID号， 1.表示在同一个复制集群中，每一个服务器上执行任何事务它都有唯一的标识符； 2.作用是将来在复制时避免事务之间产生冲突； 3.mysql5.6以mariadb10以上版本专属属性：GTID 7.清除指定的二进制日志 PURGE { BINARY | MASTER } LOGS 示例： PURGE BINARY LOGS TO &apos;node02-bin.000003&apos;;删除3之前的日志 PURGE BINARY LOGS BEFORE &apos;2017-01-23&apos;; PURGE BINARY LOGS BEFORE &apos;2017-03-22 09:25:30&apos;; 删除所有二进制日志，index文件重新记数 RESET MASTER [TO #]; 删除所有二进制日志文件，并重新生成日志文件，文件名从#开始记数，默认从1开始，一般是master主机第一次启动时执行， MariaDB10.1.6开始支持TO # 手动滚动二进制日志文件： FLUSH LOGS; 备注： 对于mysql而言，重启mysql可以让二进制日志文件滚动一次，使用此命令也可以滚动以生成新的二进制文件； 示例： MySQL [(none)]&gt; show master status; #显示正在使用的二进制日志文件 +------+----------+-------------+------------------+------------------+ | File | Position |Binlog_Do_DB | Binlog_Ignore_DB |Executed_Gtid_Set | +------+----------+-------------+------------------+------------------+ |node02-bin.000002| 120 | | | +-----------------+------+-------------+---------------+--------------+ #显示正在使用的二进制文件再记录一个新事件是从120开始的； MySQL [(none)]&gt; show binlog events in &apos;node02-bin.000001&apos;; #显示二进制日志node02-bin.000001文件中有哪些事件 +-----------------+-----+--------+-----------+-------------+------------+ | Log_name | Pos | Event_type | Server_id | End_log_pos | Info | +-----------------+-----+--------+-----------+-------------+------------+ |node02-bin.000001| 4 | Format_desc| 1 | 120 | Server ver: 5.6.34-log, Binlog ver: 4 | +-----------+-----+--------+-----------+-------------+------------------+ Log_name：二进制日志文件名 Pos：position，表示当前事件是这个二进制文件中的位置，按字节开始算 Event_type：此条事件的类型 Server_id：表示在哪个服务器上执行的，在主从复制中唯一的标识符 End_log_pos：要注意的是这个位置是当前事件结束以后，下一个事件的开始位置 Info：记录此条事件具体执行了什么操作 二进制日志是以完全备份为基础，先导入备份数据库再找到二进制日志的某些行(前提是基于行的记录格式)导入执行， 清理二进制日志: 5.事务日志:transaction log–事务日志原理 事务型存储引擎自行管理和使用,见事务功能介绍 6.中继日志：relay log中继日志是mysql复制架构中，从服务器用于保存从主服务器的二进制日志中读取到的事件 MySQL [(none)]&gt; show GLOBAL VARIABLES LIKE &apos;%relay_log%&apos;; +---------------------------+----------------+ | Variable_name | Value | +---------------------------+----------------+ | max_relay_log_size | 0 | | relay_log | relay-log | #开启relay-log | relay_log_basename | | | relay_log_index | |#relay-log的索引类似于二进制index | relay_log_info_file | relay-log.info | | relay_log_info_repository | FILE | | relay_log_purge | ON | | relay_log_recovery | OFF | | relay_log_space_limit | 0 | | sync_relay_log | 10000 | #relay-log将数据经过内存 | sync_relay_log_info | 10000 | +---------------------------+----------------+]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>MySql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS调度算法]]></title>
    <url>%2F2017%2F01%2F10%2FLVS%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[LVS Cluster的集群的概念Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster集群的类型： LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure） MTBF:Mean Time Between Failure 平均无故障时间 MTTR:Mean Time To Restoration（ repair）平均恢复前时间 A=MTBF/（MTBF+MTTR） (0,1)：99%, 99.5%, 99.9%, 99.99%, 99.999% HPC：High-performance computing，高性能 www.top500.org 调度算法： 分布式系统： 作用：因为seesion和cookie的 LB Cluster的实现根据工作的网络层次ISO模型可以分： 通信子网和资源子网 四层调度器：在内核级中，即ISO模型的下四层，完成请求报文的分析 转发，交换 LVS(ipvs),nginx(stream模块),HAProxy(mode tcp) 七层调度器：在用户空间中，即ISO模型的应用层上的 代理：proxy nginx(http_upstream)，HAProxy,ATS,Envoy,Traefik 硬负载：F5,BigIP,Netscaler,Citrix 四层调度的工作过程： 因为tcp/ip协议栈是在内核中的，四层调度是工作在下四层的,四层调度器只需要分析用 户的请求报文中的网络层(目标IP)和传输(目标端口)是什么，就可以做出调度决策，这个 请求报文就不会进入到调度器的用户空间中，而只是在内核空间中分析进而又通过内核进 行转发传输出去了.而用户的请求报文是没有被更改过的，因为调度是在内核中完成的，所以四层调度也叫内核级调度. 四层调度不受限于客户端套接字，最大支持400w个并发 七层调度的工作原理： 详见nginx七层调度工作原理 七层调度因为要与后端服务器进行通信，就需要使用套接字，则最大能使用4W个socket 而绝大多数的网站最多也就4W个并发，即使七层调度最大支持4w个并发，如果是使用短连接，长连接默认60s， 所以网站一天也可以有4w*2*86400个请求，弹性计算可以支持峰值 过去之后的服务器资源伸缩. 负载均衡和会话保持只要提到负载均衡那么会话保持也是必然要提到的问题 有状态的负载均衡服务器就必然要保持会话粘性，而会话保持的方式又分三种 session保持的三种方式： session sticky:seesion粘性 1.基于客户端IP做hash将seesion保存在一台服务器上，如果是SNAT网络则IP是 一样的，seesion的颗粒度过于粗糙.(SH算法) 2.cookie机制即使是在通过SNAT网络中，不同的浏览器客户端也会被识别为不同 客户端，seesion的颗粒度精细的多.nginx可以识别应用层的cookie信息， 完全可以基于cookie信息做会话绑定的.而cookie是应用层数据，工作在四层的LVS是识别不了的， 而七层的nginx只有商业版支持.但是同样是七层的HAproxy可以实现！！！ seesion既损害负载均衡效果，又可能造成seesion丢失(后端服务器down机) seesion replication server(cluster):seesion复制集群 在同一集群中，session是共享的，但是对内存的消耗比较大,但传输是由延迟的 把自己的seesion复制给集群的其他主机，这样seesion集群中的每个主机都会拥有 集群中所有服务器的seesion. 只适合于网站架构初创阶段！！！ session server: 把用户访问的seesion保存单独的一台服务器，通过api调用这个服务器，如redis, memcached，squid等，还是做redis集群保证seesion的安全 但是session的冗余实现比较麻烦和cookie(seesion sticky的另外一种表现) LVS的模型原理:Linux Virtual Server 1.LVS是工作四层，也就是内核中完成调度的,而且源代码也被整合到内核中，就像iptables的 netfilter一样，需要把写的规则送到内核中才能够生效. 2.依赖于内核中的LVS模块和LVS的调度算法模块，需要将集群的定义发送到内核中，并指明 使用哪种调度算法. 3.ipvs在内核中类似netfilter的框架，而ipvsadm是工作在用户空间用来生成规则的命令行 工具，然后送到内核的ipvs上，进而生效的 4.ipvs是工作在INPUT链上的，因为客户端请求的是调度器的VIP地址，必然会被送到INPUT链 而ipvs发现请求的是某个集群服务的，会强行将请求报文送到FORWARD链上，这样就实现 了转发的效果，而不进入LVS的用户空间. 5.所以需要事先在ipvs上放置一些集群的规则，才能实现转发FORWARD或者POSTROUTING链 所以iptables和ipvs在INPUT最好不要同时存在规则. LVS是通过在内核中的netfilter的INPUT链上内置了ipvs的框架并且根据请求报文中的目标IP和端口来判别是否为用户 此前定义过的集群服务，如果是就根据用户定义的调度算法来完成调度的，而每一个调度算法都是内嵌在内核中的内核模块(常用的10种). LVS的组成和相关术语LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。 1.ipvs(ip virtual server)：一段代码工作在内核空间，叫ipvs， 是真正生效实现调度的代码。 2. ipvsadm：另外一段是工作在用户空间，叫ipvsadm，负责为ipvs内核框架编写规则， 定义谁是集群服务，而谁是后端真实的服务器(Real Server) 相关术语： 1. DS：Director Server。指的是前端负载均衡器节点。 2. RS：Real Server。后端真实的工作服务器。 3. VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 4. DIP：Director Server IP，主要用于和内部主机通讯的IP地址。 5. RIP：Real Server IP，后端服务器的IP地址。 6. CIP：Client IP，访问客户端的IP地址。 LVS的调度算法WLC是LVS的默认调度算法 [root@node01 ~]# grep -i &quot;ip_vs&quot; /boot/config-3.10.0-862.el7.x86_64 CONFIG_IP_VS=m CONFIG_IP_VS_IPV6=y # CONFIG_IP_VS_DEBUG is not set CONFIG_IP_VS_TAB_BITS=12 CONFIG_IP_VS_PROTO_TCP=y CONFIG_IP_VS_PROTO_UDP=y CONFIG_IP_VS_PROTO_AH_ESP=y CONFIG_IP_VS_PROTO_ESP=y CONFIG_IP_VS_PROTO_AH=y CONFIG_IP_VS_PROTO_SCTP=y CONFIG_IP_VS_RR=m CONFIG_IP_VS_WRR=m CONFIG_IP_VS_LC=m CONFIG_IP_VS_WLC=m CONFIG_IP_VS_LBLC=m CONFIG_IP_VS_LBLCR=m CONFIG_IP_VS_DH=m CONFIG_IP_VS_SH=m CONFIG_IP_VS_SED=m CONFIG_IP_VS_NQ=m CONFIG_IP_VS_SH_TAB_BITS=8 CONFIG_IP_VS_FTP=m CONFIG_IP_VS_NFCT=y CONFIG_IP_VS_PE_SIP=m 在定义调度算法时，要根据实际情况使用合适的调度算法. lsmod | grep ipvs modinfo ip_vs 静态算法和动态算法的区别： 动态算法对系统资源消耗更多，调度效果更慢，但调度效果要好的多.原因在于动态算法 讲究结果公平，静态算法讲究起点公平 静态算法： 区别： 1.仅根据算法本身和请求报文特征进行调度，实现短连接 静态算法的实现： 1.RR:round-robin, 是对RS群的轮询，按依次循环的方式将请求调度到不同的服务器上,该算法最大的特点就是实现简单且假设 所有的服务器处理请求的能力都一样，调度器会将所有的请求平均分配给每个RS,只关注RS群的个数. 2.WRR:weighted rr,权重/加权轮询， 加权轮调是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1， 服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。 静态算法中的hash算法 对源地址/目标地址进行hash(md5,sha1等)计算然后对后端服务器集群的权重取模，模是 多少，就被调度到哪台后端服务器上. 3.SH: source ip hashing 源地址hash 地址绑定：对访问的源地址进行hash值计算(所谓hash就是IP的MD5或者SHA计算的值)，而只要访问的IP地址 不变那么hash的结果对权重之和取模的结果一定也是不变的，如果再次访问时就会再被调度到RS上， 所以地址绑定机制实现了session的sticky的会话保持。 缺点： 对于SNAT网络来说，地址绑定的机制会对LVS的工作造成极大的问题在权重模型下的工作逻辑是一样的 适用场景： 在没有使用会话共享的又需要保存会话的环境下（如电子商务网站），建议使用此算法。 4.DH: destination ip hashing 目标地址hash sh是为了追踪并保持会话的，而DH 对访问的解析的地址，进行hash值计算/权重，根据权重分配到某个RS上 动态算法： 区别： 1.不仅根据算法本身和请求报文特征进行调度 2.还要额外考虑后端各RS服务器当前的负载状态，消耗的资源更多 3.动态算法需要对后端服务集群的状态进行采样,考虑到后端每一台服务器的活动连接和非活动连接数以及空闲连 接数，统计的值叫overhead=value较小的RS将被调度，这样就实现资源的均衡调度 负载(overhead)的计算公式: overhead=activeconn(服务器当前活动连接数)*256+inactiveconns 正常情况下我们认为活动连接数消耗的资源是非活动连接的256倍，所以要乘以256，这样就可以得出后端服务器的当前负载情况了。 动态算法的实现： 5.LC:least connections 适用于长连接应用 Overhead=activeconns*256+inactiveconns 把新的连接请求分配到当前连接数最小的服务器，通过服务器当前活跃的连接数来估计服务器的情况。 调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1； 当连接中断或者超时，其连接数减1。 当然实际情况下，后端服务器的权重有可能是不一样的，所以就引入了WLC算法 6.WLC：Weighted LC，LVS的默认调度方法 叫加权最少连接，算法是： Overhead=(activeconns*256+inactiveconns)/weight 加权最少连接数是最小连接调度的优化，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1， 系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数 和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 7.SED：Shortest Expection Delay,初始连接高权重优先，最短期望延迟 Overhead=(activeconns+1)*256/weight WLC算法表面上是合理的，但是当出现计算的overhead值(权重一样)是一样的或者集群刚刚启动时(此时activeconn和inactiveconn都是0， 那么overhead也都是0,那么第一个请求应该发给哪个后端服务器？ 如果权重一样可以自上而下发送给后端服务器即可，如果权重不一样，而且刚好权重最小的在最上面， 如果把请求分配给它，那么处理速度就会慢 而我们期望的是由权重大的是处理第一个请求，所有就有了SED算法的出现. SED是如何实现让权重最大的接收处理第一个请求的？ Overhead=(activeconns+1)*256/weight SED算法不再考虑非活动连接状态，把当前活动连接的数目+1除以服务器的权值，此时的计算方法会因为 权重大的值反而overhead值越小，这样就实现了让权重大的优先处理请求的目的. 缺点： 如果权重比较大(1:9),那么前8个请求都是让权重为9的服务器来处理的， 如果刚好只有7个请求，那么权重为1的又会闲着，但是我们又不期望有服务器空闲，就有了nq算法. 8.nq:Never Queue，第一轮均匀分配，后续SED,SED的增强版 nq算法是对SED算法的弥补，第一轮都需要处理一个请求，后面再进来的请求再进行权重进行分配， 这样所有的服务器都不会空闲,也叫永不排队算法 9.lblc:locality-Base LC，基于本地的最少连接算法，是DH算法的动态版 正向代理情形下的cache server的调度，该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器 ，若该服务器是可用的且没有超载，将请求发送到该服务器;若服务器不存在，或者该服务器超载且有服务器 处于一半的工作负载，则用“最少链接”的原则选出一个可用的服务器，将请求发送到该服务器｡ 10.lblcr：Locality-Based Least-Connection with Replication 带复制功能的LBLC算法，它与LBLC算法的不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护 从一个目标IP地址到一台服务器的映射｡该算法根据请求的目标IP地址找出该目标IP地址对应的服务器组，按”最小连接”原则从 服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接” 原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器｡同时，当该服务器组有一段时间没有被修改， 将最忙的服务器从服务器组中删除，以降低复制的程度。 具体使用：不同的服务器集群的算法应该怎么选择？ 1.算法的选择和与后端服务是短连接和长连接有着重要关系 短连接使用静态算法，长连接使用动态算法，因为如果是长连接，那么计算后端服务器集群的overhead负载状态是很有必要， 如果是短连接，计算的过程中可能连接就已经断开了，所以短连接不用考虑动态算法。长连接必须要考虑动态。 2.与服务所使用的协议是否有状态有关系 3.与静态内容和动态内容有关系 示例： 1.一组纯静态内容的web服务站点： 因为都是是静态内容、http协议是无状态且是短连接的，最好的算法就是rr或者wrr 2.mysql主从服务器： 1.LVS是四层调度，无法识别mysql的读写命令操作，所以mysql是不能使用LVS来调度的； 2.如果一定要在mysql上用LVS，可以用到proxysql后端的多个从服务器上，因为proxysql的轮询调度功能有限 ，可以使用LVS代理多个从服务器实现轮询调度，这是两个概念，和mysql主从能不能使用LVS调度是完全不同的思想. 3.如果是fpm服务器,运行电商等应用服务站点 电商站点最大的特点就是要追踪用户身份而且是状态的，有状态就需要有seesion，所以要进行seesion会话 保持，最好是使用sh源地址hash算法，但是由于SNAT网络的原因，IPhash太过于粗糙. 当然这里只是举例说明算法的选择，实际情况是需要进行seesion relication cluster或者 seesion server来解决用户身份追踪的，这就和算法没有直接关系了. 4.如果是https服务，能不能用LVS？ http是可以用LVS的，但是https的ssl是工作在OSI协议的第五层(TCP协议的应用层)，LVS是无法识别并建立ssl会话，而SSL证书的subject主体应该是 后端RS的FQDN的主机名，而不是Director(因为LVS无法识别)； 1.但是ssl会话既贵且慢，为了使得更快一般是在服务器上做ssl缓存的，以便命中加速访问， 如果LVS轮询调度，那么ssl缓存是有可能失效的无法命中的; 2.Diector和RS应该是在一个机房的，局域网内的通信使用ssl无疑是多次一举的， 互联网上的通信只是在客户端和负载均衡间采用ssl通信的.这样一来也就nginx、haproxy这样的七层调度器才能够实现.]]></content>
      <categories>
        <category>负载均衡</category>
        <category>LVS</category>
      </categories>
      <tags>
        <tag>LB负载均衡</tag>
      </tags>
  </entry>
</search>
