<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Promethues监控]]></title>
    <url>%2F2019%2F01%2F15%2FPromethues%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"></content>
      <categories>
        <category>监控</category>
        <category>promethues</category>
      </categories>
      <tags>
        <tag>promethues</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpd脚本]]></title>
    <url>%2F2018%2F12%2F30%2Fhttpd%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[httpd服务 httpd服务脚本#!/bin/bash # # httpd Startup script for the Apache HTTP Server # # chkconfig: - 85 15 # description: The Apache HTTP Server is an efficient and extensible \ # server implementing the current HTTP standards. # processname: httpd # config: /etc/httpd/conf/httpd.conf # config: /etc/sysconfig/httpd # pidfile: /var/run/httpd/httpd.pid # ### BEGIN INIT INFO # Provides: httpd # Required-Start: $local_fs $remote_fs $network $named # Required-Stop: $local_fs $remote_fs $network # Should-Start: distcache # Short-Description: start and stop Apache HTTP Server # Description: The Apache HTTP Server is an extensible server # implementing the current HTTP standards. ### END INIT INFO # Source function library. . /etc/rc.d/init.d/functions if [ -f /etc/sysconfig/httpd ]; then . /etc/sysconfig/httpd fi # Start httpd in the C locale by default. HTTPD_LANG=${HTTPD_LANG-&quot;C&quot;} # This will prevent initlog from swallowing up a pass-phrase prompt if # mod_ssl needs a pass-phrase from the user. INITLOG_ARGS=&quot;&quot; # Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server # with the thread-based &quot;worker&quot; MPM; BE WARNED that some modules may not # work correctly with a thread-based MPM; notably PHP will refuse to start. # Path to the apachectl script, server binary, and short-form for messages. apachectl=/usr/sbin/apachectl httpd=${HTTPD-/usr/sbin/httpd} prog=httpd pidfile=${PIDFILE-/var/run/httpd/httpd.pid} lockfile=${LOCKFILE-/var/lock/subsys/httpd} RETVAL=0 STOP_TIMEOUT=${STOP_TIMEOUT-10} # The semantics of these two functions differ from the way apachectl does # things -- attempting to start while running is a failure, and shutdown # when not running is also a failure. So we just do it the way init scripts # are expected to behave here. start() { echo -n $&quot;Starting $prog: &quot; LANG=$HTTPD_LANG daemon --pidfile=${pidfile} $httpd $OPTIONS RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch ${lockfile} return $RETVAL } # When stopping httpd, a delay (of default 10 second) is required # before SIGKILLing the httpd parent; this gives enough time for the # httpd parent to SIGKILL any errant children. stop() { status -p ${pidfile} $httpd &gt; /dev/null if [[ $? = 0 ]]; then echo -n $&quot;Stopping $prog: &quot; killproc -p ${pidfile} -d ${STOP_TIMEOUT} $httpd else echo -n $&quot;Stopping $prog: &quot; success fi RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f ${lockfile} ${pidfile} } reload() { echo -n $&quot;Reloading $prog: &quot; if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then RETVAL=6 echo $&quot;not reloading due to configuration syntax error&quot; failure $&quot;not reloading $httpd due to configuration syntax error&quot; else # Force LSB behaviour from killproc LSB=1 killproc -p ${pidfile} $httpd -HUP RETVAL=$? fi fi echo } # See how we were called. case &quot;$1&quot; in start) start ;; stop) stop ;; status) status -p ${pidfile} $httpd RETVAL=$? ;; restart) stop start ;; condrestart|try-restart) if status -p ${pidfile} $httpd &gt;&amp;/dev/null; then stop start fi ;; force-reload|reload) reload ;; graceful|help|configtest|fullstatus) $apachectl $@ RETVAL=$? ;; *) echo $&quot;Usage: $prog {start|stop|restart|condrestart|try-restart|force-reload|reload|status|fullstatus|grace ful|help|configtest}&quot; RETVAL=2 esac exit $RETVAL]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP协议]]></title>
    <url>%2F2018%2F12%2F18%2FHTTP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[HTTP协议和APACHE原理Apache官网：软件基金会组成：apache名下有很多项目，如HTTP，Kafka，tomcat等本文说的是HTTP SERVERapacheHTTP2.4的官方文档http2.4文档：安装，模块，指令等说明HTTP2.4官方指令参考文档指令参考文档 http协议:应用层协议,主流http/1.1版本http协议的版本区别http0.9、http1.0、http1.1和http2.0的版本区别 http/0.9: 只有一个GET命令，且只能回应.html文件格式，像.txt等都不支持 http/1.0:效率太低 1.支持cache, MIME(支持各种资源类型), method2.建立TCP三次握手之后,每个TCP连接只能发送一个请求，发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接,效率太低3.引入了POST命令和HEAD命令，头部信息和4.http协议加了头信息,ip(tcp(http(data))),data可以是各种MIME的资源类型可以用 http/1.1:主流使用版本 1.http/1.1版本开始引入持久连接（persistent connection）,即TCP连接默认不关闭， 对于同一个域名，大多数浏览器允许同时建立6个持久连接，提高了请求的并发性 这里所说的是指一个域名最大6个连接，但是在一个网页上可以有很多域名，所以会有相当多的持久连接，实现高并发请求 2.引入了管道机制（pipelining），即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率3.新增方法：PUT、PATCH、OPTIONS、DELETE(删除功能通常不用)4.缺点： 同一个TCP连接三次握手之后，所有的数据通信是按顺序进行传输的。服务器只能顺序处理回应，当前面的数据比较大，传输比较慢时，后面的许多请求则会一直处于排队状态，就造成”队头堵塞”现象5.解决队头堵塞的办法： 为避免上述问题，两种方法：一是减少请求数，二是同时多开持久连接。网页优化技巧，如合并脚本和样式表、将图片嵌入CSS代码、域名分片（domain sharding）等6.HTTP 协议不带有状态，每次请求都必须附上所有信息。请求的很多字段都是重复的，浪费带宽，影响速度: 不带状态怎么理解？ http不像tcp拥有限状态机；http协议是没有状态的，刷新页面信息丢失，所以会通过cookie和session来弥补这个缺点 http/2.0：解决 HTTP/1.1效率不高的问题 1.头信息和数据体都是二进制，称为头信息帧和数据帧2.和http1.1区别：请求不需要排队，提高效率 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，避免了“队头堵塞“,此双向的实时通信称为多工（Multiplexing）3.引入头信息压缩机制（header compression）,头信息使用gzip或compress压缩后再发送；客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，不发送同样字段，只发送索引号，提高速度4.HTTP/2 允许服务器未经请求，主动向客户端发送资源，即服务器推送（server push）：http2.0的推送既有好处又有缺点(产生很多垃圾信息) HTTP工作机制 工作机制主要分为两步：请求和响应 http请求：http requesthttp响应：http response一次http事务：请求响应 Web资源：web resource一个网页由多个资源构成，打开一个页面，会有多个资源展示出来，但是每个资源都要单独请求。因此，一个“Web 页面”通常并不是单个资源，而是一组资源的集合 静态页面/文件：无需服务端做出额外处理; 服务器端是什么样传到客户端就是什么样，比如下面这些 比如文件后缀：.html, .txt, .jpg, .js, .css, .mp3, .avi 只不过浏览器有时会解析出来以好看的页面展示给用户 动态页面/文件：服务端执行程序，返回执行的结果 服务器放的资源和客户端看到的不一样，看到的不是代码本身，而是代码的执行结果 文件后缀：.php, .jsp ,.asp,.sh等 将上面的文件程序代码执行结果配合数据库，再通过http协议封装报文传给用户 提高HTTP连接性能 并行连接：通过开多个TCP连接发起并发的HTTP请求持久连接：keep-alive,长连接，通过一次TCP三次握手连接后，传输多个请求再关闭tcp连接，关闭连接可以有两种方式：1.是设置每次的tcp连接时间；2.是规定传输的请求个数，HTTP的配置文件中可以进行设置，如http1.1和http2.0都支持持久连接，管道化连接：通过共享TCP连接发起并发的HTTP请求复用的连接：交替传送请求和响应报文（实验阶段） HTTP协议的其他相关技术 1.URI：一般把URI认为是URLURI: Uniform Resource Identifier 统一资源标识，分为URL和URN 1.URN: Uniform Resource Naming，统一资源命名 如P2P、迅雷等下载使用的磁力链接是URN的一种实现，不是从一个服务器上下载，从互联网任何一个有资源的地方下载，没有体现出这个资源在互联网上的路径，URN只代表这个资源叫什么名 2.URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置 如输入一个网址，能具体体现出这个资源在互联网上的位置 两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之，URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名，而不指定地址 URL的组成scheme://user:password@host:port/path;params?query#frag scheme:表示访问服务器获取资源时，使用的哪种协议,如http，https,ftp等user:用户，某些方案访问资源时需要的用户名password:密码，用户对应的密码，中间用：分隔Host:主机，资源宿主服务器的主机名或IP地址，一般写FQDN通过DNS解析port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号，如80,8080/path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔，一般是键值对query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&amp;分隔，类似sql语句的select查询功能frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔 网站访问量 1.IP(独立IP)：即Internet Protocol,指独立IP数。 如果一个局域网内通过一个公网IP出去，则局域网内IP数只算一个 2.PV(访问量)： 即Page View, 页面浏览量或点击量，用户每次刷新即被计算一次，PV反映的是浏览某网站的页面数， PV与来访者的数量成正比，PV并不是面的来访者数量，而是网站被访问的页面数量 一般为了博客为了好看的访问量，都是统计PV量 3.UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。 网站判断来访电脑的身份是通过来访电脑的cookies或者session来实现的。 如果更换了IP后但不清除cookies，再访问相同网站，该网站的统计中UV数是不变的 如：局域网内三个人用同一台电脑访问一个网站，则这个网站的 IP:1;PV:6;UV:1 Web服务请求处理步骤很切合实际生活：比如当我们打开一个浏览器，输入一个www.taobao.com，在互联网后台发生了什么？这就涉及到web服务请求处理步骤和一次完整的http请求处理过程了，如下图 当然在建立连接前还有DNS解析–&gt;TCP建立连接的三次握手—&gt;再到完整的http的处理过程每个过程都是一段需要原理详细描述的. 一次完整的http请求处理过程1.建立连接：接收或拒绝连接请求 2.接收请求：接收客户端请求报文中对某资源的一次请求的过程 Web访问响应模型（Web I/O） 单进程I/O模型：访问量不大 启动只有一个进程处理用户请求，而且一次只处理一个，多个请求被串行响应 会造成请求排队现象，只适用于访问并发不大的情况 多进程I/O模型： 系统开启多个进程处理用户请求,而且每个进程只响应一个连接请求 如果并发请求过高时，也会造成请求排队现象，只是比单进程稍微高效一点 而且服务器上开多个进程是要占用消耗资源的，CPU、内存的容量也是不支持的 复用I/O结构： 开启多个进程进程，而一个进程又同时监控N个连接请求 只有当N个连接请求真正进行数据传输时，这个进程才会响应，就不需要像多进程一样开启多个进程，极大的减小服务器的资源消耗 实现方法：多线程模型和事件驱动 多线程模型：一个进程生成N个线程，每线程响应一个连接请求 事件驱动：一个进程处理N个请求 复用的多进程I/O模型： 启动M个进程，每个进程响应N个连接请求，同时接收M*N个请求 充分使用CPU个数，每个核开启一个进程，一个进程响应多个请求，这就是典型的 nginx使用的复用多进程I/O模型 1.apache使用的就是多进程I/O模型，缺点：就是开启很多进程，用户量太大时，当达到并发连接数10k时，进程数太多，CPU、内存资源消耗严重，服务器性能下降，apache的响应速度就会变慢，不能支持高并发的连接请求，通过 ps auxf可以看出是一个父进程多个子进程 2.nginx使用的是复用的多进程I/O模型，CPU的每个核开启一个进程，一个进程负责N个连接请求，当这些连接请求真正进行数据传输时，这个进程才会响应 避免了多进程I/O模型来一个请求就开启一个进程的缺点，即使不进行数据传输也会占用一个进程的问题，会造成很大的资源占用浪费 同时也避免了复用I/O模型的缺点：N个进程同时进行数据传输时，一个进程无法同时相应的问题 参考下面的HTTP的MPM三种工作模式 3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相关信息，根据方法，资源，首部和可选的主体部分对请求进行处理 分析元数据：请求报文首部信息获得method &lt;method&gt; &lt;URL&gt; &lt;VERSION&gt; HEADERS 格式 name:value &lt;request body&gt; 通过method来响应用户请求，比如下载(get)，上传等信息 HTTP常用请求方式，Method GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS 4.访问资源： 服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源 在apache中默认的根/是---&gt; /var/www/html/index.html 可以修改配置文件 web服务器资源路径映射方式： (a) docroot (b) alias (c) 虚拟主机docroot (d) 用户家目录docroot 5.构建响应报文： 一旦Web服务器识别除了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包括响应主体 1）响应实体 描述了响应主体MIME类型的Content-Type首部 描述了响应主体长度的Content-Length 2）URL重定向 web服务构建的响应并非客户端请求的资源，而是资源另外一个访问路径 3）MIME类型 当get到/var/www/html/index.html文件后，http会添加响应实体或者URL重定向，MIME类型信息 6.发送响应报文 将构建完的响应报文发送给用户 将index.html(构建完的报文)进行http、tcp、IP头等封装后的响应报文发给用户 用户再层层解封装获得index.html的内容 7.记录日志 最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务 通过在/var/log/httpd/acess_log日志中记录http的响应记录数 方便分析日志统计该网站的IP，PV量等信息 Http协议http协议 http/0.9, http/1.0, http/1.1, http/2.0 http协议：stateless 无状态 服务器无法持续追踪访问者来源 解决http协议无状态方法 cookie 客户端存放 session 服务端存放 http事务：一次访问的过程 请求：request 响应：response Session和Cookie的区别前言: HTTP是一种无状态的协议，为了分辨链接是谁发起的，就需要我们自己去解决这个问题。 不然有些情况下即使是同一个网站我们每打开一个页面也都要登录一下。而Session和 Cookie就是为解决这个问题而提出来的两个机制。 应用场景: 1.日常登录一个网站，今天输入用户名密码登录了，第二天再打开很多情况下就直接打开 了。这个时候用到的一个机制就是cookie。 2.session的一个场景是购物车，添加了商品之后客户端处可以知道添加了哪些商品，而 服务器端如何判别呢，所以也需要存储一些信息，这里就用到了session。 Cookie的原理： HTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。 也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。 这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设 计成如此简单的。可是随着 Web 的不断发展，很多业务都需要对通信状态进行 保存。于是引入了 Cookie 技术。使用 Cookie 的状态管理Cookie 技术通过在 请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服 务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端 保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报 文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后， 会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录， 最后得到之前的状态信息。 通俗讲，Cookie是访问某些网站以后在本地存储的一些网站相关的信息，下次再访问的时 候减少一些步骤。另外一个更准确的说法是：Cookies是服务器在本地机器上存储的小段文 本并随每一个请求发送至同一个服务器，是一种在客户端保持状态的方案。 session的原理： session就是一种保存上下文信息的机制，她是针对每一个用户的，session的内容在服 务器端，通过sessionId来区分不同的客户，session是以cookie或url重写为基础的， 默认用cookie来实现，系统会创造一个JSESSIONID的输出cookie，我们成为session cookie，以区分persistent coookies，注意session cookie是存储于浏览器内存中的 ，并不是写到硬盘上的；我们通常是看不见JSESSIONID的，但是当我们禁用浏览器的 cookie后，web服务器会采用url重写的方式传递sessionid，我们就可以在浏览器看到 sessionid=HJHADKSFHKAJSHFJ之类的字符串；session cookie针对某一次会话而言，会话结束session cookie也就消失了 session与cookie的区别： 1.session保存在服务器，客户端不知道其中的信息；cookie保存在客户端，服务端可以 知道其中的信息 2.session中保存的是对象，cookie中保存的是字符串 3.session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个 地方都可以访问到；而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不道德 session与cookie的联系： session是需要借助cookie才能正常工作的，如果客户端完全禁止cookie，session将失 效 Http应用层的报文头部:又分请求报文和响应报文两种-HTTP请求报文头部 开始行 方法：method GET： 从服务器获取一个资源 HEAD： 只从服务器获取文档的响应首部 POST： 向服务器输入数据，通常会再由网关程序继续处理 PUT： 将请求的主体部分存储在服务器中，如上传文件 DELETE： 请求删除服务器上指定的文档 TRACE： 追踪请求到达服务器中间经过的代理服务器 OPTIONS：请求服务器返回对指定资源支持使用的请求方法 URL:路径 首部行 实体行 -HTTP响应报文头部 开始行 版本：version HTTP/&lt;major&gt;.&lt;minor&gt;1.1/2等等 状态码： 三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况 短语： 状态码所标记的状态的简要描述 首部行 实体行 Http常见的状态码和状态码分类status(状态码)： 1xx：100-101 信息提示 2xx：200-206 成功 3xx：300-305 重定向 4xx：400-415 错误类信息，客户端错误 5xx：500-505 错误类信息，服务器端错误 200： 成功，请求数据通过响应报文的entity-body部分发送;OK 301： 请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资 源现在所处的新位置；Moved Permanently 302： 响应报文Location指明资源临时新位置 Moved Temporarily 304： 如果之前访问一个网站，在本机上有缓存了，当再次访问时，就会出现304的状态码， 提示本地有不需要再去服务器上下载页面 401： 需要输入账号和密码认证方能访问资源；Unauthorized 403： 没有权限访问，请求被禁止了；Forbidden 404： 服务器无法找到客户端请求的资源；要访问的文件不存在 500： 服务器内部错误；Internal Server Error 502： 代理服务器从后端服务器收到了一条伪响应，如无法连接到网关；Bad Gateway 503： 服务不可用，临时服务器维护或过载，服务器无法处理请求 可能是服务器down机了，或者http服务关闭了 504： 网关超时；转给后端服务器时，时间太长 curl和elinks工具：网站测试工具，更专业测试出网络不通是什么原因curl是基于URL语法在命令行方式下工作的文件传输工具 1.它支持FTP, FTPS,HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议。 2.curl支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证， HTTP上传，代理服务器，cookies，用户名/密码认证,下载文件断点续传，上载文件断 点续传, http代理服务器管道（ proxy tunneling） 3.还支持IPv6，socks5代理服务器，通过http代理服务器上传文件到FTP服务器等 4.curl的强大在于能模拟各种浏览器自定义请求报文头部等信息，来访问某些控制严格的网站 curl [options] [URL...] -A/--user-agent &lt;string&gt; 冒充浏览器类型，实际上在请求报文修改了User-Agent curl -A &apos;IE20&apos; http://192.168.34.103在http日志中可看到 一般用于测试访问网站或者爬虫功能要使用不同浏览器访问 -e/--referer &lt;URL&gt; 来源网址，防盗链相关 比如，伪装从百度跳转的192.168.34.103 curl -e &apos;www.baidu.com&apos; http://192.168.34.103 --cacert &lt;file&gt; CA证书 (SSL) -k/--insecure 允许忽略证书进行 SSL 连接 --compressed 要求返回是压缩的格式 -H/--header &lt;line&gt;自定义首部信息访问网站 -i 显示页面内容，包括报文首部信息 -I/--head 只显示响应报文首部信息 -D/--dump-header &lt;file&gt; 将url的header信息存放在指定文件中，重定向 --basic 使用HTTP基本认证，401认证 -u/--user &lt;user[:password]&gt;设置服务器的用户和密码 -L 如果有3xx响应码，重新发请求到新位置 如果访问的网页被重定向到其他地方时，系统只会提示网页被重定向了，并不会跳转 -L就可以请求到新的页面上 -O 使用URL中默认的文件名保存文件到本地 -o &lt;file&gt; 将网络文件保存为指定的文件中 --limit-rate &lt;rate&gt; 设置传输速度 -0/--http1.0 数字0，使用HTTP 1.0 -v/--verbose 更详细 -C 选项可对文件使用断点续传功能 -c/--cookie-jar &lt;file name&gt; 将url中cookie存放在指定文件中 -x/--proxy &lt;proxyhost[:port]&gt; 指定代理服务器地址 -X/--request &lt;command&gt; 向服务器发送指定请求方法 -U/--proxy-user &lt;user:password&gt; 代理服务器用户和密码 -T 选项可将指定的本地文件上传到FTP服务器上 --data/-d 方式指定使用POST方式传递数据 -b name=data 从服务器响应set-cookie得到值，返回给服务器 elinks工具： 字符界面的浏览器，显示页面内容和源码等 elinks [OPTION]... [URL]... -dump: 非交互式模式，将URL的内容输出至标准输出 比如有些网站是不允许复制的，通过-dump就可以把网站页面文字抓取到本地了 elinks -dump www.baidu.com 不过一般都是用js脚本限制了复制功能，在浏览器关闭js，或查看源码都可以 -source:打印源码 HTTP介绍特性：高度模块化：core + modulesDSO: Dynamic Shared Object 动态加/卸载MPM：multi-processing module多路处理模块 HTTP的三种工作模型：MPM工作模式多用途的处理模块，三种模型分别是，默认使用prefork模型因为http很多软件是只支持prefork模型而不支持woker或者event模型的，所以一般都是使用prefork模型 1.prefork：多进程I/O模型，每个进程响应一个请求，默认模型一个主进程：生成和回收n个子进程，创建套接字，不响应请求 多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过 1024个，消耗比较大内存资源 受限于并发访问控制的内部系统调用机制： select()；内生使用限制最多只能使用1024个描述符，所以最多也就1024个进程 epoll(); Prefork MPM: 预派生模式，有一个主控制进程，然后生成多个子进程，使用select模型，最 大并发1024，每个子进程有一个独立的线程响应用户请求，相对比较占用内存，但是比较稳定 ，可以设置最大和最小进程数，是最古老的一种模式，也是最稳定的模式，适用于访问量不是很大的场景。 优点：稳定 缺点：慢，占用资源，不适用于高并发场景 配置文件原内容： &lt;IfModule mpm_prefork_module&gt; StartServers 5 #定义apache服务在启动时启动的子进程数量 MinSpareServers 5 #定义最小空闲进程数，空闲进程就是没有处理用户请求的进程数 MaxSpareServers 10 #定义最大空闲进程数 MaxRequestWorkers 250 #定义在prefork模式下的最大并发连接数，表示了apache的最大并发处理能力，超过的连接请求将被排队等候处理。 MaxConnectionsPerChild 0 #进程生命周期内，处理的最大请求数目。达到该数目后，进程将死掉。如果设置 为0，表示没有限制。该参数的意义在于，避免了可能存在的内存泄露带来的系统问题。 &lt;/IfModule&gt; 如果确定合适的MaxRequestWorkers呢？ 首先，通过top命令查看apache进程占用的资源，主要看%CPU和%MEM这两个指标，例如，每个进程的CPU占用率不超过 1%，每个进程的内存占用率不超过2%，考虑内存限制，比较合适的apache进程数量为50个，然后，逐步测试最大值。 通过观测得来的CPU和内存的指标有一定的误差，一般可以适当调节这个数值，例如调到1.5或者2倍，再通过峰值场景下的机器是否卡顿来判断是继续上调还是下调。 2.worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型一个主进程生成m个子进程，每个子进程又负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，支持高并发性 缺点：线程消耗资源比进程要小很多，但是如果子进程中的线程出现问题，则会影响整个子进程，从这个方面考虑，没有prefork稳定！ woker MPM：是一种多进程和多线程混合的模型，有一个控制进程，启动多个子进程，每个子进程里面包含固定的线程 ，使用线程程来处理请求，当线程不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求， 由于其使用了线程处理请求，因此可以承受更高的并发。 优点：相比prefork 占用的内存较少，可以同时处理更多的请求 缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输数据，也需要一直等待到超时才会被释放 。如果过多的线程，被这样占据，也会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会发生） 配置文件原内容详解： &lt;IfModule mpm_worker_module&gt; StartServers 3 # #定义apache服务在启动时启动的子进程数量，默认是3个 MinSpareThreads 75 # 整个控制进程保持最小数的空闲线程数 MaxSpareThreads 250 # 整个控制进程保持最大数的空闲线程数 #ThreadLimit 64 # 每个子进程可以启动的线程数量上限值，默认没有设置 ThreadsPerChild 25 # 每个子进程启动的线程默认数量，开启启动两个子进程每个子进程25个 线程，就是apache 启动后开启25个线程。 MaxRequestWorkers 400 # 所有子进程加起来的线程数量最大值，数量等于最大启动的进程数*ThreadsPerChild(每个进程的线程数) MaxConnectionsPerChild 0 # 每个子进程被请求多少次服务后被kill掉重新生成一个新的子进程，为了解决内存回收方面的问题，0为不设置 &lt;/IfModule&gt; 3.event：事件驱动模型（worker模型的优化,worker模型的变种）event模型在httpd-2.4：event 稳定版，centos7默认版本开始使用 每一个cpu核心生成一个进程； 一个主进程：生成m个子进程，每个进程直接响应n个请求，并发响应请求：m*n 注意这里的m*n和work的m*n是不同的机制 相比较worker的有点： 有专门的线程来监控管理这些keep-alive类型的线程，当有真实请求时，将请求传递给服务线程，执行完毕后，又允许 释放。这样增强了高并发场景下的请求处理能力 event MPM：Apache中最新的模式，属于事件驱动模型(epoll)，每个进程响应多个请求，在现在版本里的已经是稳定 可用的模式。它和worker模式很像，最大的区别在于，它解决了keep-alive场景下，长期被占用的线程的资源浪费问题 （某些线程因为被keep-alive，空挂在哪里等待，中间几乎没有请求过来，甚至等到超时）。event MPM中，会有一个 专门的线程来管理这些keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程，执行完毕后， 又允许它释放。这样增强了高并发场景下的请求处理能力。 event只在有数据发送的时候才开始建立连接，连接请求才会触发工作线程，即使用了TCP的一个选项，叫做延迟接受连 接TCP_DEFER_ACCEPT，加了这个选项后，若客户端只进行TCP连接，不发送请求，则不会触发Accept操作，也就不会 触发工作线程去干活，进行了简单的防攻击（TCP连接）,可以使用Telnet进行测试验证： 主机192.168.10.130为客户端机器，192.168.10.131为apache服务器机器使用event模式： 在192.168.10.130上telnet 192.168.10.131 80，然后在192.168.10.130客户端机器上使用netstat查看，发现连 接已经建立，处于ESTABLISHED状态，然后再到apache服务器192.168.10.131使用netstat查看，发现是处于 SYN_RECV状态。 优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线程来管理keep-alive类型的线程， 当有真实请求过来的时候，将请求传递给服务线程，执行完毕后，又允许它释放 缺点：没有线程安全控制 配置文件内容： &lt;IfModule mpm_event_module&gt; StartServers 3 #apache服务启动的子进程数，默认3个 MinSpareThreads 75 #控制进程保持最小的空闲线程数 MaxSpareThreads 250 #控制进程保持的最大空闲线程数 ThreadsPerChild 25 #每个子进程启动的线程数 MaxRequestWorkers 400 #并发最大请求数，也就是所有子进程加起来的线程数量，woker模式下的 400就是并发400，但是由于是异步处理请求的，因此这里的400比woker模型下的并发处理速度要快很多，因为event省略了工作线程的会话保持。 MaxConnectionsPerChild 0 #每个子进程请求多少次以后被kill掉重新生成一个新的子进程。 &lt;/IfModule&gt; 注意： event模型的强大的I/O机制 httpd从设计上就默认支持prefork 而nginx从设计上就支持event事件驱动模型 进程工作的角色切换 Httpd的功能特性httpd的常见特性： 虚拟主机：在一个物理服务器上搭建多个网站 IP、Port、FQDN CGI：Common Gateway Interface，通用网关接口 通过CGI接口处理动态的程序处理 反向代理 当有用户访问量大时，在前端有一个服务器充当调度器的角色 通过调度算法把请求发送到后端真正提供服务的服务器上去，用户只看到调度器的信息 看不到后端真正提供服务的服务器群 负载均衡 路径别名 丰富的用户认证机制 basic digest 支持第三方模块 Httpd2.4新特性和安装以及配置新特性 MPM支持运行为DSO机制；以模块形式按需加载 在centos7上的httpd2.4上只有一个二进制程序 /usr/sbin/httpd，更改MPM模式只需要加载event或者worker模块即可 但是在centos6上的httpd2.2版本： 每个MPM模式都有各自对应的二进制程序 /usr/sbin/httpd /usr/sbin/httpd.event /usr/sbin/httpd.worker 如果更改MPM的模式，是需要改对应的二进制程序的 event MPM生产环境可用 异步读写机制 支持每模块及每目录的单独日志级别定义 每请求相关的专用配置 增强版的表达式分析式 毫秒级持久连接时长定义：httpd2.2只能精确到秒级别 上文提到http1.1和http2.0协议版本都支持持久连接，但是持久连接也是有时长的 所以在http中是可以定义连接时长(时长和传输请求两种方式)的 基于FQDN的虚拟主机不需要NameVirutalHost指令 httpd2.2创建虚拟主机时还需要NameVirutalHost指令 httpd2.4就不需要了 新指令，AllowOverrideList 支持用户自定义变量 更低的内存消耗 Httpd2.4的具体安装和配置Httpd的软件比较复杂，所以很多功能都模块化了，需要什么功能，加载模块就行了还支持第三方的模块，按需加载模块存放模块的路径：/etc/httpd/modules CentOS7程序环境安装：httpd-2.4 yum install httpd yum install httpd-manual 帮助文档，无网络环境下可以查看帮助文档 主要配置文件： /usr/sbin/httpd httpd的主程序文件 /usr/lib/systemd/system/httpd.service httpd的启动单元文件 /etc/httpd/conf/httpd.conf 主要配置文件 配置文件里的路径都是以/etc/httpd/为参考点的 /etc/httpd/conf.d/*.conf /etc/httpd/conf.modules.d/00-mpm.conf mpm相关 /etc/httpd/conf.modules.d/00-proxy.conf 配置代理相关 /etc/httpd/conf.modules.d/00-systemd.conf /etc/httpd/conf.modules.d/01-cgi.conf CGI相关 /var/cache/httpd httpd的缓存目录 /var/log/httpd httpd的日志文件目录 access_log: 访问日志 error_log：错误日志 /etc/httpd/modules httpd的模块存放路径，软件比较复杂 /usr/lib64/httpd/modules 也是httpd的模块存放路径 两个模块的路径实际上是软链接关系 /var/www/html httpd存放网页的目录：默认index.html 帮助文档包：在没有网络时查看帮助文档，建议安装 httpd-manual 检查配置文件语法： httpd –t 类似DNS的rndc语法检查功能 sudo：visudo功能 ansible:ansible -C|--check 执行前检查语法功能 cobbler 也有 httpd的控制和启动命令 systemctl enable|disable httpd.service systemctl {start|stop|restart|status|reload} httpd.service 备注：很多服务都有reload功能，但是需要注意的是修改或加载模块等操作 有时reload是无效的，只能restart服务 Httpd2.4的常见配置 1.显示服务器版本信息HTTP2.4官方指令参考文档指令参考文档 主要组成: Global Environment 全局配置 Main server configuration 一个服务器上搭建一个网站叫主服务器 virtual host 虚拟主机，一台主机上搭建多个网站 练习一下grep命令：只显示配置文件中的非注释的行(出去注释行和空行)egrep -v ‘^ #.|^$’ /etc/httpd/conf/httpd.conf 常见配置一般都在/etc/httpd/conf/httpd.conf的文件中没有的配置选项可以加在httpd.conf文件最后，也可以放在/etc/httpd/conf.d/*.conf 创建一个 .conf文件，比如test.conf下面的一些配置都是在/etc/httpd/conf.d/test.conf文件中添加 1.显示服务器版本信息 访问http://192.168.34.103 打开f12调试模式，可以看到回应头的信息中带有apache的版本信息 也可以通过curl -I http://192.168.34.103来显示头信息 可以看到头信息里有：Server: Apache/2.4.6 (CentOS)，显示出具体版本会是网站不安全 查看指令参考文档：修改ServerTokens选项建议使用：ServerTokens Prod，重启httpd服务，apache版本信息关闭了，加固安全 2.修改监听的IP和Port Listen [IP:]PORT (1) 省略IP表示为本机所有IP (2) Listen监听端口至少一个，可以有多个端口 (3) 监听端口可以绑定到服务器的特定IP上，只能通过这个IP才能使用此端口 test.conf添加listen端口： listen 172.18.132.151:6666 6666端口只能通过此IP才能访问 3.持久连接：默认KeepAlive是开启的 Persistent Connection：连接建立，每个资源获取完成后不会断开连接，而是继续等待其它的请求完成，默认关闭持久连接 断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4的新特性支持毫秒级 副作用：对并发访问量大的服务器，持久连接要设置短一点，要不然会造成请求排队堵塞 折衷：使用较短的持久连接时间 设置： KeepAlive On|Off 设置持久连接开启或者关闭 KeepAliveTimeout 15 设置持久连接为15s 测试：telnet WEB_SERVER_IP PORT GET /index.html HTTP/1.1 Host: WEB_SERVER_IP host可以随便填写，但是在虚拟主机中是有区别的 4.MPM（ Multi-Processing Module）多路处理模块：prefork,worker,event 默认是prefork：/etc/httpd/conf.modules.d/00-mpm.conf 修改mpm的文件 建议还是使用prefork模块，因为后续的很多模块都依赖于prefork模块的 查看静态编译的模块 httpd -l 查看当前系统中httpd的静态编译及动态装载的加载的模块 httpd –M 动态模块加载：不需重启即生效 动态模块路径 /usr/lib64/httpd/modules/ 切换使用的MPM模块 在/etc/httpd/conf.modules.d/00-mpm.conf中 选择要启用的MPM相关的LoadModule指令即可 prefork的配置： StartServers 8 MinSpareServers 5 保留5个空闲子进程处理新的请求 MaxSpareServers 20 允许的最大空闲进程数 ServerLimit 256 最多进程数,最大20000，并发量建议最多10000 MaxRequestsPerChild 4000 子进程最多能处理的请求数量。在处理 MaxRequestsPerChild个请求之后,子进程将会被父进程终止，这时候子进 程占用的内存就会释放(为0时永远不释放） worker和prefork配置类似，只不过会有线程数量的限制 从下面ps auxf的进程图可以看书httpd是使用的prefork模型，而且因为端口是80，开启需要特殊权限，所以父进程是root,子进程是apache 5.DSO： Dynamic Shared Object 加载动态模块配置 /etc/httpd/conf/httpd.conf Include conf.modules.d/*.conf 配置指定实现模块加载格式： LoadModule &lt;mod_name&gt; &lt;mod_path&gt; 模块文件路径可使用相对路径： 相对于ServerRoot（默认/etc/httpd） 6.定义’Main’ server的文档页面路径：存放页面的主目录 主目录是由DocumentRoot指令来设置的 网页文件默认是存在/var/www/html/下的，此处可以自定义 在/etc/httpd/conf/httpd.conf中默认DocumentRoot是”/var/www/html” 如果要自定义主目录，还需要设置该目录为允许访问 在httpd2.2上是不需要设置权限访问的 但是在httpd2.4上是需要设置该目录允许访问的 修改格式如下： #DocumentRoot &quot;/var/www/html&quot; DocumentRoot &quot;/data/www&quot; &lt;directory /data/www&gt; Require all granted &lt;/directory&gt; 7.定义站点默认主页面 访问192.168.34.103默认显示的是index.html的内容， 这一项是由DirectoryIndex指令设置的 在/etc/httpd/conf/httpd.conf中有定义默认页面，修改即可 添加：DirectoryIndex haha.html，当然前提是存放页面的主目录下有这个html文件 此处需要了解httpd的权限和访问报错的相关问题和默认主页面：1.访问192.168.34.103跳出的页面默认是index.html页面，如果不存在，则去找conf.d/welcome.conf文件，即报错提示，如果两个都不存在，显示的是/var/www/html目录下的文件列表，因为在httpd.conf配置文件中，定义options indexes选项2.默认页面和默认访问目录都是可以通过指令来指定的3.如果没有index.html文件，没有welcome.conf文件，没有options indexes配置，访问时会报错You don’t have permission to access / on this server.的提示.4.上面三条在下面第12条配置别名时，可以体现的很明显5.所以如果自定义目录和用别名，有时是需要设置目录访问权限、设置目录对应的index.html文件或者跳转的html文件(如果该文件存在就不需要设置了)，设置options indexes选项 8.站点访问控制常见机制 可基于两种机制指明对哪些资源进行何种访问控制 访问控制机制有两种：1.客户端来源地址，2.用户账号 而文件系统路径：可以是 1.具体的目录；2.可以是具体到一个文件；3.可以是扩展的正则表达式匹配 示例： ‘‘’ 用的是扩展的正则表达式 通配符 &lt;Location /status&gt; 9.中”基于源地址”实现访问控制:Options和Allowoverride和基于IP的控制 (1) Options：后跟1个或多个以空白字符分隔的选项列 在选项前的+，- 表示增加或删除指定选项 常见选项： Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户,即显示/var/www/html/下的所有文件给用户看，比如阿里和清华镜像源就是这个机制 适用于下载网站和镜像网站，不适合电商网站 FollowSymLinks：允许访问符号链接文件所指向的源文件, None：全部禁用 All： 全部允许 Indexes使用示例：前提是定义站点默认主页面的index.html不存在，存在的话显示的 就是index.html的内容，适用于下载网站和镜像网站，不适合电商网站 &lt;directory &quot;/data/www&quot;&gt; options Indexes Require all granted &lt;/directory&gt; FollowSymLinks使用示例：文件列表显示链接(创建的软硬链接)文件 &lt;directory &quot;/data/www&quot;&gt; options Indexes FollowSymLinks Require all granted &lt;/directory&gt; 实现options indexes的前提：存放页面的主目录下没有index.html文件，但是此时即使加上 options Indexes选项，页面也不会列出主目录下的所有文件，因为httpd找不到主目录下的index.html文件则会找/etc/httpd/conf.d/下的welcome.conf文件，welcome.conf文件就是页面上经常看到的测试123页面，把welcome.conf文件改名或删除，就会显示主目录下的所有列表文件了. (2) AllowOverride allowoverride意思是：把options选项放到.htaccess的文件里，而不是放在httpd.conf中,只需要把.htaccess文件放到你需要控制的目录下并设置allowoverride权限即可 只对语句有效; allowoverride权限时卸载httpd的*.conf配置文件中的 AllowOverride All: .htaccess中所有指令都有效 AllowOverride None： .htaccess 文件无效 AllowOverride AuthConfig Indexes 除了AuthConfig 和Indexes的其它 配置allowoverride示例： /etc/httpd/conf.d/test.conf中添加访问控制的目录 &lt;directory /data/www&gt; allowoverride all --&gt;这条必须写，代表.htaccess文件中的options生效 Require all granted &lt;/directory&gt; 在/data/www/目录下，创建.htaccess文件，将options添加到.htaccess中 options indexes FollowSymLinks (3) 基于IP的访问控制: 无明确授权的目录，默认拒绝 允许所有主机访问：Require all granted 拒绝所有主机访问：Require all denied 控制特定的IP访问： Require ip IPADDR：授权指定来源的IP访问 Require not ip IPADDR：拒绝特定的IP访问 控制特定的主机访问： Require host HOSTNAME：授权特定主机访问 Require not host HOSTNAME：拒绝 HOSTNAME：FQDN：特定主机和domin.tld：指定域名下的所有主机 基于IP的访问控制示例： 如：1.只拒绝特定IP地址访问/data/www目录，其他IP可以看到主目录下的文件列表 除了/data/www/ceshi文件夹 &lt;directory /data/www&gt; options indexes &lt;RequireAll&gt; Require all granted Require not ip 192.168.34.107 &lt;/RequireAll&gt; &lt;/directory&gt; 2.设置/data/www目录为所有IP可访问，并显示目录文件列表，但是在目录下的ceshi子目录只允许192.168.34.107访问 &lt;directory /data/www&gt; options indexes Require all granted &lt;/directory&gt; &lt;directory /data/www/ceshi&gt; &lt;RequireAny&gt; Require all denied Require ip 192.168.34.107 &lt;/RequireAny&gt; &lt;/directory&gt; 10.日志设定：日志默认/var/log/httpd/下format官方说明文档 日志类型：访问日志(access_log)和错误日志(error_log) 日志的格式，先通过Logformat指令指定然后起个名，然后生成的日志再调用这个日志格式 在/etc/httpd/conf/httpd.conf中定义了访问日志和错误日志的存放路径和日志格式定义 LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%{Referer}i\&quot; \&quot;%{User-Agent}i\&quot;&quot; combined --&gt;由Logformat指令定义完起一个combined名 CustomLog &quot;logs/access_log&quot; combined再调用这个日志格式 ErrorLog &quot;logs/error_log&quot; 可以看出日志文件都是以/etc/httpd/为根的，所以写的是相对路径 日志中的格式各个项说明 %h 客户端IP地址 %l 远程用户,启用mod_ident才有效，通常为减号“-” %u 验证（basic，digest）远程用户,非登录访问时，为一个减号“-” %t 服务器收到请求时的时间 %r First line of request，即表示请求报文的首行；记录了此次请求的“方法”， “URL”以及协议版本 %&gt;s 响应状态码 %b 响应报文的大小，单位是字节；不包括响应报文http首部 %{Referer}i 请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的，通过referer可以分析出网页 是否被调用了，比如说广告生效了，或者说搭建的个人网站被别人盗链了，占用了自己的服务器资源，所以网站一般要加防盗链，防止资源被盗和占用服务器资源 %{User-Agent}i 指客户端的浏览器版本 11.设定默认字符集 一般不需要设置：基本上使用的是utf-8; AddDefaultCharset UTF-8 此为默认值 如果需要修改字符集，在test.conf或者httpd.conf下添加 AddDefaultCharset gb2312 即可 12.定义路径别名作用：默认访问的文件夹是设置的DocumentRoot文件夹，如果不是在默认文件夹下，而需求要实现把其他路径下的目录共享出来，这就用到了定义路径别名的功能 把一个URL起一个别名不指向真正的目录 在httpd2.4里目录如果没有开启允许时，默认是不允许访问的 例如：访问 /var/www/html/111,111这个目录可有可无，只是充当别名 实际上访问的是/data/www/ceshi目录 directoryindex ceshi.html alias /111 /data/www/ceshi &lt;directory /data/www/ceshi&gt; options indexes Require all granted &lt;/directory&gt; 注意：1.111只是一个别名，在/var/www/html下不需要创建；但是如果/var/www/html下有111的文件夹，如果设置别名后，则访问的是/data/www/ceshi目录，原目录下的111文件夹就失效了。2.在这里和上文第7条设置权限时有联系的，httpd2.4设置路径别名的时候，真正的路径也是需要在test.conf下设置权限的(/data/www/ceshi目录)3.如果/data/www/ceshi/下没有index.html会报权限不允许的错误，所以要设置默认主页面directoryindex，当然可以设置options indexes选项 13.基于虚拟账户的登录访问控制：提示401状态码 认证质询：WWW-Authenticate：响应码为401，拒绝客户端请求，并说明要求客户端提供账号和密码 认证：Authorization：客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源 两种认证方式： basic：用的多，缺点是明文，后面可以用https进行加密 digest：兼容性差，用的少 用户的账号和密码:非linux用户密码 虚拟账号：多种存储方式，只用于httpd服务的，类似vsftp，samba服务的虚拟用户 存储：账号可放在文本文件，SQL数据库，ldap目录存储，nis等 因为basic使用的多，下文以basic认证配置示例 1.提供账号和密码存储（文本文件），如创建一个tom虚拟账户管理httpd htpasswd --&gt;可以指定加密算法 -c 自动创建文件，仅应该在文件不存在时使用 -p 明文密码 -d CRYPT格式加密，默认 -m md5格式加密 -s sha格式加密 -D 删除指定用户 htpasswd -c httpdpass tom :设定密码即可;目录可指定，后面改配置文件即可 htpasswd -s httpdpass jerry 再添加jerry用户，就不需要-c选项了 htpasswd -D httpdpass jerry 从文件中删除jerry用户 修改httpdpass权限，加固安全 chmod 600 httpdpass 或者也可以创建组文件httpdgroup，通过组来管理,组文件组和成员列表 testgroup: tom jerry 2. 在test.conf或者httpd.conf下定义安全域 &lt;directory /var/www/html/ksdir&gt; AuthType Basic ---&gt;使用的认证方式 AuthName &quot;Login&quot; ----&gt;登录提示信息 AuthUserFile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;加密账户文件 AuthGroupFile &quot;/etc/httpd/conf/httpdgroup&quot; --&gt;组账户 Require user tom ---&gt;允许用户访问的列表 Require group testgroup ---&gt;允许访问的组 &lt;/directory&gt; 但是：因为httpd线程是以apache运行的，而httpdpass是600权限，所以默认tom登录是没有权限的，让apache对httpdpass有读权限： setfacl -m u:apache:r httpdpass 即可 14.实现用户家目录的http共享;并实现账户机密访问 实现基础：基于模块mod_userdir.so实现 httpd -M |grep user 可以看出user加密的模块是已经加载的，直接改配置文件即可 在/etc/httpd/conf.d/userdir.conf文件中定义了家目录共享的格式，只需要启用就行了 实现步骤： 1. vim /etc/httpd/conf.d/userdir.conf &lt;IfModule mod_userdir.c&gt; UserDir enabled ---&gt;启用即可；默认不启用 UserDir public_html ---&gt;创建一个public_html文件 &lt;/IfModule&gt; 2.在test家目录下，创建public_html文件夹和public_html文件 su test mkdir public_html/ echo 23333 &gt; /public_html/public_html 3.因为httpd线程是apache身份登录的，所以要允许apache访问test用户的家目录 setfacl -m u:apache:x /home/test 4.设置test家目录访问权限及用户加密 &lt;directory /home/test/public_html&gt; authtype basic authname &quot;test home&quot; authuserfile &quot;/etc/httpd/conf/httpdpass&quot; --&gt;调用之前创建的虚拟账户文件即可 Require user haha &lt;/directory&gt; 5.http访问test家目录方式,即可用加密账户登录 192.168.34.103/~test 15.ServerSignature On|Off|EMail 作用：当用户访问的页面不存在的情况下服务器会产生错误文档，而当ServerSignature选项是打开的情况下，错误文档会将服务器的名字，apahce的版本信息，显示在页面上，某种程度上会对web服务器产生不安全因素，所以一般建议关闭 在配置文件添加一行： ServerSignature off 即可 16.status页面 作用：显示apache的工作状态，有助于判断apache是否正常工作 status页面功能是由下面这个模块实现的：httpd LoadModule status_module modules/mod_status.so 实现步骤：在配置文件添加 &lt;Location &quot;/status&quot;&gt; SetHandler server-status &lt;/Location&gt; ExtendedStatus ON #显示扩展信息 记录的信息包括：启动时间，线程数，等待连接数，cpu，进程，MPM等信息 在实际生产中，由于apache服务器很多，就可以通过curl 192.168.34.103/status来抓取页面，分析apache某个指标是不是正常的； 比如编写简单一个脚本： curl 192.168.34.103/status |grep &quot;Apache Status&quot; || systemctl start httpd 17.实现http的虚拟主机 作用：一个物理服务器上实现多台虚拟主机，至于为什么会用到虚拟主机，有可能是因为要上线的同一网站的有多个域名，却只有一个公网IP地址，也有可能是主机不多啊..，所以虚拟主机的价值就体现出来了… 实现虚拟主机有三种方式 基于ip：为每个虚拟主机准备至少一个ip地址，一个主机可以配多个内网IP地址 基于port：为每个虚拟主机使用至少一个独立的port；80,8081,8082等等 基于FQDN：为每个虚拟主机使用至少一个FQDN 当然这三种方式，基于IP和port的对于用户来说不太现实，一般都是通过输入域名方式来实现虚拟主机搭建. 1.基于IP的虚拟主机搭建：但是这种方式用的比较少 先准备三个网站目录，和在本机上添加三个IP地址 &lt;virtualhost 192.168.34.103&gt; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost 192.168.34.200&gt; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost 192.168.34.210&gt; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; 重启服务即可 通过curl 192.168.34.103 curl 192.168.34.200 curl 192.168.34.210 即可获取到各自的index.html文件内容，对应的日志也都生成了 2.基于port的虚拟主机搭建，监听三个port即可;使用的不多 listen 8081 listen 8082 listen 8083 &lt;virtualhost *:8081&gt; servername &quot;www.a.com&quot; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost *:8082&gt; servername &quot;www.b.cn&quot; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost *:8083&gt; servername &quot;www.c.net&quot; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; 通过本机IP+port获得不同网站的信息 curl 192.168.34.103:8081 curl 192.168.34.103:8082 curl 192.168.34.103:8083 3.基于FQDN的虚拟主机搭建：用的最多 前提：这里就不搭建DNS服务器了，使用本机的hosts文件进行域名解析 &lt;virtualhost *:80&gt; servername &quot;www.a.com&quot; DocumentRoot &quot;/data/asite&quot; &lt;directory /data/asite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_a.log combined &lt;/virtualhost&gt; &lt;virtualhost *:80&gt; servername &quot;www.b.cn&quot; DocumentRoot &quot;/data/bsite&quot; &lt;directory /data/bsite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_b.log combined &lt;/virtualhost&gt; &lt;virtualhost *:80&gt; servername &quot;www.c.net&quot; DocumentRoot &quot;/data/csite&quot; &lt;directory /data/csite&gt; Require all granted &lt;/directory&gt; customlog /var/log/httpd/access_c.log combined &lt;/virtualhost&gt; 测试：curl www.a.com curl www.b.cn curl www.c.net 就可获得各自的主页面信息从这telnet就可以理解出，如果在互联网通过域名访问时(同一IP)，返回的结果是不同网站的信息 [root@node7-1 ~]#telnet 192.168.34.103 80 Trying 192.168.34.103... Connected to 192.168.34.103. Escape character is &apos;^]&apos;. GET /index.html HTTP/1.1 HOST: www.a.com 当访问192.168.34.103时 HOST：即网站的域名，返回的结果就是其对应的页面信息在互联网上，一般是先在本地服务器上通过第三种方式搭建多个网站，然后再通过服务商的智能DNS解析，可以通过访问不同的域名，解析到IP地址，服务器根据输入的HOST：域名判断访问的是哪个网站，进而返回对应网站站点的信息，对于主机较少或者IP有限的环境中，使用http虚拟主机还是很方便的。]]></content>
      <categories>
        <category>web服务</category>
        <category>http</category>
      </categories>
      <tags>
        <tag>Web服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译安装LAMP]]></title>
    <url>%2F2018%2F12%2F10%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85LAMP%2F</url>
    <content type="text"><![CDATA[LAMP Centos7上编译安装LAMP 备注：本文编译PHP是基于fastCGI方式，php-fpm 编译准备： 在192.168.34.105上实现，准备安装包都放在/data/src下 apr-1.6.5.tar.bz2 apr-util-1.6.1.tar.bz2 httpd-2.4.37.tar.bz2 php-7.1.18.tar.bz2 wordpress-5.0-zh_CN.zip mariadb-10.2.19-linux-x86_64.tar.gz 准备开发包组： yum install &apos;develoment tools&apos; -y 1.编译安装httpd和apr 准备依赖包和解压安装包 yum install pcre-devel openssl-devel expat-devel apr-util-devel -y tar xvf apr-1.6.5.tar.bz2 tar xvf apr-util-1.6.1.tar.bz2 tar xvf httpd-2.4.37.tar.bz2 cp -r apr-1.6.5 httpd-2.4.37/srclib/apr cp -r apr-util-1.6.1 httpd-2.4.37/srclib/apr-util a.编译 cd httpd-2.4.37 ./configure \ --prefix=/data/httpd24 \ --enable-so \ --enable-ssl \ --enable-cgi \ --enable-rewrite \ --with-zlib \ --with-pcre \ --with-included-apr \ --enable-modules=most \ --enable-mpms-shared=all \ --with-mpm=prefork make &amp;&amp; make install b.准备环境变量 用自带的服务控制脚本：/app/httpd24/bin/apachectl就需要设置环境变量了 echo &apos;PATH=/mysql/httpd24/bin:$PATH&apos; &gt; /etc/profile.d/httpd24.sh . /etc/profile.d/httpd24.sh c.修改配置文件，为了安全以apache用户运行，并监听在本地 useradd -r -s /sbin/nologin apache vim /data/httpd24/conf/httpd.conf User apache Group apache ServerName localhost:80 2.二进制安装mariadb-10.2.19 a.准备用户和mysql数据库目录 useradd -r -s /sbin/nologin -d /data/mysql mysql mkdir /data/mysql chown mysql.mysql mysql/ b.解压二进制安装包： tar xvf mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local/ cd /usr/local ln -s mariadb-10.2.19-linux-x86_64/ mysql chown -R root.mysql /usr/local/mysql/ c.创建数据库文件:(通过自带脚本工具) cd /usr/local/mysql/ scripts/mysql_install_db --datadir=/mysql/data --user=mysql d.准备配置文件(不修改/etc/my.cnf)拷贝解压完的文件 mkdir /etc/mysql/ cp support-files/my-huge.cnf /etc/mysql/my.cnf 路径优先级高于/etc/my.cnf 根据性能来拷贝配置文件 [mysqld]中添加三个选项：/etc/mysql/my.cnf datadir = /mysql/data innodb_file_per_table = on skip_name_resolve = on 禁止主机名解析，建议使用 e.准备服务脚本，并启动服务 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld service mysqld start f.准备PATH路径 echo &apos;PATH=/usr/local/mysql/bin:$PATH&apos; &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh systemctl start mysqld 为wordpress准备数据库和账号密码 mysql -e &apos;create database wordpress&apos; mysql -e &quot;grant all on *.* to php1@&apos;192.168.34.%&apos; identified by &apos;php123&apos;&quot; 3.FastCGI方式编译安装php-7.1.18 tar xf php-7.1.18.tar.bz2 安装依赖包 yum install libxml2-devel bzip2-devel libmcrypt-devel -y a.编译，指定安装数据路劲和配置文件路径 cd php-7.1.18 ./configure --prefix=/data/php \ --enable-mysqlnd \ --with-mysqli=mysqlnd \ --with-openssl \ --with-pdo-mysql=mysqlnd \ --enable-mbstring \ --with-freetype-dir \ --with-jpeg-dir \ --with-png-dir \ --with-zlib \ --with-libxml-dir=/usr \ --enable-xml \ --enable-sockets \ --enable-fpm \ --with-config-file-path=/etc \ --with-config-file-scan-dir=/etc/php.d \ --enable-maintainer-zts \ --disable-fileinfo make &amp;&amp; make install b.准备php配置文件 cd php-7.1.18 cp php.ini-production /etc/php.ini 可以修改当前时区和按照生产环境修改并发连接数等信息 c.创建nginx用户 useradd -s /sbin/nologin nginx d.准备php的conf文件 cd /data/php cp php-fpm.conf.default php-fpm.conf cp php-fpm.d/www.conf.default php-fpm.d/www.conf 修改监听地址和允许连接地址，因为是在一台编译的，监听地址不用改了 vim php-fpm.d/www.conf listen = 127.0.0.1:9000 ;listen.allowed_clients = 127.0.0.1 user = nginx group = nginx e.准备服务脚本: cp /data/src/php-7.1.18/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm chkconfig --add php-fpm chkconfig php-fpm on 4.修改httpd文件，支持php和启用代理 编辑apache配置文件httpd.conf，以使apache支持php,并启用代理 vim /data/httpd24/conf/httpd.conf 1.取消下面两行的注释 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 2.定位至DirectoryIndex index.html 修改为DirectoryIndex index.php index.html 3.最后添加4行 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/app/httpd24/htdocs/$1 重启apache服务，apachectl restart 5.准备wordpress,把wordpress文件全部移动到httpd24/htdocs下 cd /data/src unzip wordpress-5.0-zh_CN.zip cd wordpress mv * /data/httpd24/htdocs 为wordpress准备配置文件和数据库连接 cd /data/httpd24/htdocs mv wp-config-sample.php wp-config.php vim wp-config.php define(&apos;DB_NAME&apos;, &apos;wordpress&apos;); define(&apos;DB_USER&apos;, &apos;php&apos;); define(&apos;DB_PASSWORD&apos;, &apos;php123&apos;); define(&apos;DB_HOST&apos;, &apos;192.168.34.105&apos;); 修改/data/httpd24/htdocs的所有者和所属组 cd /data/httpd24 chown -R nginx.nginx htdocs/ 到此所以的编译安装和准备工作都做完了，把mysql,php-fpm,httpd启动即可 apachectl start systemctl start php-fpm systemctl start mysqld http://192.168.34.105 配置wordpress即可 备注： 创建的文章和账户是放在wordpress数据库中的; 图片是放在/data/httpd24/htdocs/wp-content/uploads下的 然后把这套系统搬到自己的云服务上就可以轻松的实现了,本文是基于LAMP架构实现的不过推荐使用LNMP架构，毕竟Nginx的强大可不是吹出来的.. 安装完成后，开启了一个新的世界，就可以开心的玩耍了,helloworld！]]></content>
      <categories>
        <category>web服务</category>
        <category>个人博客搭建</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker的资源限制]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E7%9A%84%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Docker资源限制 docker容器得以实现的三个组件： Namespace:内核中的名称空间是实现容器技术非常重要的组件 CGroups：实现容器的资源配额 1.如果没有资源配额的限定，比如恶意代码会占用宿主机上的很多资源，会造成其他容器无法运行的情况， 默认是宿主机上的所有资源. 2.cgroup允许将宿主机上的所有技术资源(CPU,内存等)做资源分割,以指定方式进行分配，而CPU和内存又分别支持两种不同的配额方式 3.CPU属于可压缩型资源，如果程序运行的cpu不够，只需要等待cpu资源即可，不会造成容器崩溃。 4.内存属于不可压缩型资源，如果一个进程依赖于3g内存来运行，宿主机只分配给它1g，则会造成OOM，这个进程就会因为内存耗尽而被终止. 内存的限制方式： -m|--memory= 限制容器的最大内存使用量，进程并不是一启动就占用最大内存的，而是 运行一段时间慢慢增长的，所以要分配给进程运行的最大内存. --memory-swap * 当前容器所允许使用的交换分区大小(生产环境是禁止启用交换内存 的，因为性能会急剧下降.) --memory-swappiness 使用交换分区的倾向性：因为使用交换分区会极大影响性能， 只有到万不得已才使用交换分区，数值越小,越会较晚使用交换分区，所以一般这个 值建议调小，默认是0-100 --memory-reservation 为系统保留多的内存空间，保证系统的正常运行 --kernel-memory 为内核保留多少内存空间 --oom-kill-disable 一旦某个容器发生OOM是否立刻kill这个容器，建议设置，因为 会造成整个宿主机的崩溃，也可以事先设定好内核和系统的内存空间，然后手动处理 发生OOM的容器，以便分析发生OOM的原因. 注意： 1.在容器内使用free命令可以看到的swap空间并不具有其所展现的空间指示意义. 2.-m|--memory=和 --memory-swap *一般是结合起来生效的 CPU的限制方式： 主流的分两种：共享式和CPU绑定式 --cpu-shares 共享方式是基于权重分配的，而且是根据容器的数量和CPU的权重动态 分配调整的.如果只有一个容器在运行，那么这个容器也会尽可能的占用宿主机的CPU资源，这种分配方式依然会有可能造成系统崩溃. --cpus &lt;value&gt; 定义容器最多跑满宿主机的几个核心数，例如宿主机有8核，限制容器 最多跑满2个核心数，而且这个2核可以跑在8个核心上加起来是2个核心数，也可以是 在2个核心上跑满.真正限制了容器使用的最大核心数. docker的1.13版以后都使用这个选项来定义. --cpuset-cpus 定义容器只能跑在宿主机核心的几号核心上，例如只允许跑在1号和3号核心上，那么 这个容器最多也就只能跑满这两个核心,也叫CPU绑定. 所以在创建启动容器一定要做资源限制，即使不清楚容器中某个程序要占用多大的资源时，也应该设置只允许占用宿主机一半的资源. 资源限制压测在docker hub上的lorel/docker-stress-ng镜像 -c N 启动几个进程对CPU进行压测 -vm N 启动几个进程对内存做压测 示例：通过该镜像进行压测 限制只能跑在cpu的0号和3号上，最多只能跑满2个核心数 限制最多占用512m的内存大小 docker run --name stress --cpus 2 --cpuset-cpus 0,3 -m 512m --rm lorel/docker-stress-ng -c 2 -vm 2 -docker stats命令查看结果 -top命令显示宿主机资源(安装1显示全部的CPU核心数信息)]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker存储卷]]></title>
    <url>%2F2018%2F10%2F18%2Fdocker%E5%AD%98%E5%82%A8%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[Docker Data Volume：docker存储卷 存储卷是什么： 存储卷是容器上一个或者多个“目录”，并将此“目录”与宿主机上的某目录建立关联关系， 存储卷在容器初始化之时会被创建，由baseimage提供的卷中的数据数据会在此时完成复制 为什么需要用到存储卷: docker启动一个容器是基于镜像的只读层，并在其上添加一个读写层，而镜像是由多个只读层叠加而来。如果运行中 的容器修改了现有一个已存在的文件，那该文件将会从只读层复制到读写层，而该文件的只读版本仍然存在，只是 被读写层中该文件的副本所隐藏而已，而此时关闭该容器，该容器所修改的文件的将会丢失且不能被其它容器共享、复用，因而需要一个存储卷。 如何实现容器内的路径与容器外的存储建立关联关系？ 实际应用场景： 1.通常在可写层上只保存临时数据，有效数据保存在和宿主机关联的目录下，这样就 剥离了程序和产生的数据间紧密的耦合关系，即程序在容器的名称空间上，数据在 宿主机或存储上，数据就独立于容器的生命周期之外 2.当容器down后，再启动一个新容器，指定数据路径为宿主机或存储上的路径，则 又恢复了数据，这就叫做Docker的存储卷 存储卷存在的问题： 存在的问题 •存储于联合文件系统中，不易于宿主机访问； •容器间数据共享不便 •删除容器其数据会丢失 解决方案：“卷(volume)” •“卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机 上的某目录“绑定(关联)” •Volume于容器初始化之时即会创建，由base image提供的卷中的数据会于此期间 完成复制 •Volume的初衷是独立于容器的生命周期实现数据持久化，因此删除容器之时既不会 删除卷，也不会对哪怕未被引用的卷做垃圾回收操作； 存储卷的type: 1. Bind mount volume 绑定挂载卷，永久生效 容器内目录和宿主机中的目录都是由用户自己指定的， 2. Docker-managed volume： 称为docker自己指定的卷 容器中的卷是用户自己指定的，而宿主机上的目录是由docker-daemon进程自行 决定与宿主机的哪个目录建立 关联关系的存储卷，只能用于临时挂载。 存储卷的相关命令: docker run -v 运行时，指定存储卷 --volumes-from list 复制其他容器的卷，达到共享卷的目的 --sorkdir string docker volume ls：列出当前已和宿主建立关联关系的存储卷 create： inspect name:查看一个卷的详细信息 prune rm: 因为docker container inspect c1看到的容器内的详细信息是JSON格式的 所以就可以通过过滤特殊字段显示查询的信息 docker container inspect CONTAINER_NAME -f {{.JSON_VALUE}} Docker-managed volume • ~]# docker run -it -name c1 –v /data busybox • ~]# docker inspect -f {{.Mounts}} c1 • 查看c1容器的卷、卷标识符及挂载的主机目录 和docker container inspect c1的过滤效果一样 Bind-mount Volume • ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name c1 busybox • ~]# docker inspect -f {{.Mounts}} c1 如图以过滤IP地址为例，其他信息类似 示例1.Docker-managed volume 临时创建挂载一个mydata卷 docker run --name c1 -it --rm -v /mydata busybox:latest 并通过docker container inspect c1 探测 mydata被docker指定与宿主机的哪个目录建立了关联关系 从上图看mydata是被docker-manager指定与该容器目录下的_data建立了关系注意：创建容器的时候加–rm选项时，停止容器后，宿主机上的卷也会被删除的不加–rm选项，停止容器，并rm容器，宿主机上的卷是不会被删除的缺点是对应的宿主机上的目录难查找 示例2.Bind mount volume 现在宿主机上创建卷的目录 mkdir /data/volume/c1 docker run --name c1 -it --rm -v /data/volumes/c1:/mydata busybox:latest 并通过docker container inspect c1 可以看出宿主机的/data/volumes/c1与容器内的/mydata是建立的bind类型的卷即使容器被删除，数据还在存在的而且如果/data/volume/c1是在NFS网络文件系统上的话，即使宿主机down了，数据也是无损的 示例3：多容器之间的数据共享 1.先创建容器c1 docker run --name c1 -it --rm -v /data/volumes/c1:/mydata busybox:latest 2.创建容器c2时，共享容器c1的卷 docker run --name c2 -it --rm --volumes-from c1 busybox:latest 此时c1和c2上看到的mydata卷看的数据都是一样的，达到共享卷的目的 示例4.用docker实现类似于k8s上的pod组件机制 要求： 1.c1上挂载多个NFS存储上的卷和bridge桥 2.c3和c4使用c1的网络名称空间和c1上的卷 实现： c1: docker run --name c1 -v /data/volumes/c1:/mydata -v /data/volume2:/mydata2 busybox:latest c3. docker run --name c3 -it --rm --network container:c1 --volumes-from c1 busybox:latest c4. docker run --name c4 -it --rm --network container:c1 --volumes-from c1 busybox:latest]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker仓库管理工具Harbor]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7Harbor%2F</url>
    <content type="text"><![CDATA[Docker仓库管理工具Harbor HARBORgithub上的harbor harbor官方功能介绍： 1.基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可 以对多个镜像仓库在同一命名空间（project）里有不同的权限。 2.镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡， 高可用，混合云和多云的场景。 3.图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库， 管理项目和命名空间. 4.Harbor支持安装在多个Registry节点的镜像资源复制，镜像全部保存在私有Registry中， 确保数据和知识产权在公司内部网络中管控。 5.AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。 6.审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。 依赖环境和使用介绍： 1.harbor是基于distribution二次开发的企业级私有仓库，云原生registry，多租户机制，允许用户创建自己的名称空间 2.因为harbor内置了mysql,nginx等服务才能构建一个harbor,所以依赖于docker-compose进行容器编排和依赖于至少docker-17.03.0版本 3.harbor为了安全，也需要以https运行，需要在harbor服务器提供证书，而且也需要为 其他客户端提供证书，为harbor验证使用，当然可以关闭https功能 4.因为需要实时下载镜像，提供了离线安装和在线安装，也可以安装到vSphere平台(OVA方式)虚拟设备。 离线版安装和配置：harbor离线安装包下载离线版安装部署文档 1.先安装docker-compose，docker-ce yum install docker-compose docker-ce -y 2.tar xf harbor-offline-installer-v1.4.0.tgz -C /usr/local/ 3.cd /usr/local/harbor并修改主配置文件harbor.cfg [root@mysql_2 harbor]# grep &quot;^[a-Z]&quot; harbor.cfg hostname = mysql_2 #设置主机名/IP ui_url_protocol = http #访问协议，支持http和https max_job_workers = 10 #最大进程连接数 #####设置使用https协议的证书和路径##### customize_crt = on #是否使用自定义证书 ssl_cert = /data/cert/server.crt ssl_cert_key = /data/cert/server.key secretkey_path = /data log_rotate_count = 50 #本地最多保存50次日志滚动 log_rotate_size = 200M #当日志达到200M时滚动一次 http_proxy = #是否使用代理 https_proxy = no_proxy = 127.0.0.1,localhost,core,registry ####设置用户上下载镜像时，是否启用发邮件功能######### email_identity = email_server = smtp.mydomain.com email_server_port = 25 email_username = sample_admin@mydomain.com email_password = abc email_from = admin &lt;sample_admin@mydomain.com&gt; email_ssl = false email_insecure = false ####使用互联网上的邮箱############## harbor_admin_password = Harbor12345 #harbor默认的管理员密码 auth_mode = db_auth #默认使用的数据库类型 db_host = mysql #设置连接mysql的端口和用户密码 db_password = root123 db_port = 3306 db_user = root #这里还支持 ldap 以及 本地文件存储方式。 #####修改数据库类型和用户和密码######### 4.运行install.sh 因为是离线安装包，会从tar文件中装入所需的镜像文件并启动，启动时会检查 docker-ce和docker-compose的版本开始加载镜像(mysql,redis,nginx等等) [root@mysql_2 harbor]# ./install.sh [Step 0]: checking installation environment ... Note: docker version: 18.09.0 Note: docker-compose version: 1.18.0 [Step 1]: loading Harbor images ... - 5.启用的容器可能会使用宿主机的名称空间 6.通过docker-compose管理harbor cd /usr/local/harbor/ docker-compose stop docker-compose start 登录web管理界面：http://x.x.x.x，默认用户名：admin，密码为配置文件中自定义的密码 7.创建用户和测试仓库： 创建lk用户，测试登录 创建test仓库用于测试上传镜像 直接创建test仓库即可 内网服务器登录harbor-登录报错–Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。如果配置文件中启用了https，而且也有证书等信息，就不会有这个报错 解决方法： 1.在所有的内网需要上传下载镜像的服务器上都创建daemon.json文件 vim /etc/docker/daemon.json { &quot;insecure-registries&quot;:[&quot;192.168.100.17&quot;] ###该选项表示从不安全的仓库下载或上传镜像 } 2.还要注意： 如果[&quot;192.168.100.17&quot;]中使用的主机名，那么需要在本地hosts文件或者局域网DNS 服务器上进行主机名解析 3.也可以修改vim /usr/lib/systemd/system/docker.service文件 vim /usr/lib/systemd/system/docker.service ExecStart=/usr/bin/dockerd --insecure-registry 192.168.100.17 重启docker systemctl daemon-reload systemctl restart docker 4.docker login 192.168.100.17|主机名 #登录私有harbor仓库 docker logout 192.168.100.17|主机名 #退出私有harbor仓库 - 4.制作镜像并测试上传 制作镜像：docker tag httpd:v0.1 192.168.100.17/test/httpd:v1 将之前制作好的镜像改标签再上传上去 docker image build . -t 192.168.100.17/test/httpd:v2.0 也可以通过dockerfile重新制作一个再上传 上传到test仓库中: docker push 192.168.100.17/test/httpd:v1 - 5.测试拉取镜像 在页面上点击复按钮，在命令行中就可以拉取镜像了 - 如何修改配置：[root@linux-host1 harbor]# /usr/local/harbor [root@linux-host1 harbor]# docker-compose stop #先停止服务 [root@linux-host1 harbor]# vim harbor.cfg #编辑配置 [root@linux-host1 harbor]# docker-compose start #重新启动服务]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile]]></title>
    <url>%2F2018%2F10%2F18%2FDockerfile%2F</url>
    <content type="text"><![CDATA[DockerFile：构建镜像 前面说过： 1.镜像是分层的，当基于这个镜像创建一个容器时，docker是通过联合挂载机制把镜像层 进行叠加作为容器的只读层，而后又在这个镜像栈上构建了一个可写层作为这个容器的工 作目录. 2.所有的底层数据在第一次发生修改操作时，是通过CoW写时复制机制，把数据复制到读 写层进行修改并保存在读写层，覆盖底层的原始文件；写入新数据时，则直接保存在读写 层，而在读写层看到的数据就是全部的镜像层数据(镜像栈) 3.而Graph Driver则又在构建在本地文件系统之上的二级文件系统(aufs,overlay2) 4.基于Graph Driver这种特有的图形驱动程序，就可以把分成构建的镜像堆积在存储 空间当中，紧邻的镜像是有依赖关系的 5.docker commit可以把当前的读写层及其底层依赖的镜像关系打包成一个镜像层存储 在Graph Driver当中，并且指向底层依赖的镜像层，形成一个新的镜像层，如果基于 同一个镜像commit多个可写层，这些新的镜像层都是指向之前的底层镜像的，这也是 docker镜像不是很大的原因。 6.所以在制作镜像时，完全不必基于某个基础镜像显示启动一个新容器，然后在上面创建 修改可写层并打包成镜像；commit只是一种方式，也可以使用dokcerfile 7.如果再本地将软件源码编译/二进制编译到容器也是可以的 dockerfile基本要求1.dockerfile的工作逻辑： 制作镜像无非就是基于某个基础镜像创建一个可写层修改后再commit成一层新的镜像 这个过程可以由docker自身完成，只需要在dockerfile配置文件中写清楚，基于哪个基础镜像， 按需修改(通过各种指令生成)，而docker build可以读取dockerfile文件，隐 式的执行这些指令集生成一个新的镜像层保存在Graph Driver中 2.工作目录 构建docker镜像时，必须有一个工作目录docker,这个目录下只存在dockerfile和在 dockerfile中定义要复制的文件，是起始目录 3.dockerfile format：语法 dockerfile就是一个纯文本文件; 注释行 dockerfile instruction args:指令要纯大写 第一条指令必须是FROM：基础镜像名称 docker build是按顺序读取执行dockerfile中的指令集的 4.dockerfile中的每一条指令都会生成一个新的镜像层 如果指令比较多，生成的镜像层就比较多，就会造成第一次的CoW从底层读取数据时很慢 但是镜像层比较多又容易被分享和易控，较少又会比较繁琐 所以一般是把做同一个件事的多个操作通过\换行符，用一条指令完成(见下文) 5.镜像内唯一要运行的程序一定必须要运行在前台 dockerfile中的环境变量1.docker为了满足同一镜像在不同环境下的使用场景引入了环境变量的方式 某个容器基于镜像启动时，通过传递环境变量参数，来生成容器内的不同的配置文件 docker container run --name CONTAINER_NAME -e VAR -it IMAGE_NAME COMMAND 这样一来，就可以用基于同一基础镜像，传递不同的环境变量作为参数值，创建适应 于不同环境的容器 2.entrypoint.sh脚本 但是传统的代码不支持传环境变量作为参数，而在docker中又需要传参，这时就有了衔接 层也就是shell脚本，这个脚本作为容器第一个要运行的程序然后运行完退出，再退出去 之前读取用户传的环境变量，将环境变量的值写到程序的配置文件中； 而且很多镜像通过docker image inspect mysql:8.0 |grep entrypoint过滤是可以 看到有这个脚本的 3.环境变量的两类用法： a.在构建dockerfile中使用 b.以dockerfile构建的镜像为基础镜像，启动容器时使用 而dockerfile中的指令的生命周期是有两个阶段的 build：基于基础镜像构建镜像的阶段 run: 启动容器的阶段 dockerfile中的一些指令或者环境变量在不同阶段使用发挥的价值是不一样的 4.环境变量的设定和引用 设置：ENV statement 两种引用方式： 1.${variable:-word} 如果变量variable为空或不存在时，就使用word值 如果设置了variable，就使用该变量值 2.${variable:+word} 如果变量有值，就使用word值，如有没值就是空值 .dockerignore file1.dockerignore是工作目录中专门记录需要忽略的文件列表 2.而且docker build会自动忽略.dockerignore自身和记录在其中的所有文件 Dockerfile基本语法FROM： FROM必须是文件的第一指令 FROM &lt;repository&gt;[:&lt;tag&gt; 镜像的标签 或者&lt;resository&gt;@&lt;digest&gt; 镜像的ID号校验码 推荐使用digest因为校验码是安全的，而且最好不要使用lasted LABLE: authtor&apos;s infomation;提供该镜像的标签信息 语法： maintainer &quot;liu &lt;liu@163.com&gt;&quot; COPY: 从宿主机复制文件至创建的新镜像 COPY &lt;src&gt;... &lt;dest&gt; COPY [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;] &lt;src&gt;：要复制的源文件或目录，支持使用通配符 &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则，COPY指定则以WORKDIR为其起始路径； 注意：在路径中有空白字符时，通常使用第二种格式 注意： 1. src：必须为build上下文中的路径，可使用相对路径 2.如果src是目录，其内部的文件或子目录会自动被递归复制，但src自身不会被复制 等于cp -r /src/* /dest/ 3. src有多个，或者src使用通配符，则dest必须是一个目录，且必须以/结尾 4. 如果dest事先不存在，它将会被自动创建 ADD: 类似于COPY，但是额外支持tar文件和URL路径 ADD &lt;src&gt;... &lt;dest&gt; ADD [&quot;&lt;src&gt;&quot;,...&quot;&lt;dest&gt;&quot;] 1. 如src为URL时且dest不以/结尾，ADD会自动将指定的文件下载并创建为dest， 如dest以/结尾，则会下载指定的文件并保存为dest/FILENAME 即一个是下载并改名，一个是下载到这个文件目录下 2. 如src是一个本地的tar文件，则会被自动展开为一个目录，但通过URL获取到的文件 则不会自动展开，即在本地的就展开，互联网的就不展开 3. 如src有多个，或使用通配符，则dest必须是目录且以/结尾，如dest不以/结尾， 则被视为一个普通文件，src的内容将被直接追加写入到dest文件中 WORKDIR： 1.用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录 2.WORKDIR指令可出现多次，表示下个指令可以以此目录为父目录，路径可以表示为相对 路径，也可以写成绝对路径 3.WORKDIR的有效范围当前workdir向下，下一个workdir之前的范围 4.另外，WORKDIR也可调用由ENV定义的环境变量的值，如果下次修改环境变量的值，响应生成信息的镜像层 5.而且如果设定了WORKDIR，容器启动时，默认就进入到workdir路径了 VOLUME： 用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的卷 注意： 1.在dockerfile中定义的卷，启动容器时，是被docker管理的卷与宿主机的某个 路径建立关联关系 2.如果需要定义的卷与宿主机特定的目录建立关联关系，还需要在run container时 指定-v选项 3.如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此 前的所有文件复制到新挂载的卷中 EXPOSE:都是动态端口暴露 用于为容器打开指定要监听的端口以实现与外部通信 EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议 注意： 1.即使在dockerfile中定义了暴露的端口，启动为容器时，端口也不会暴露的 因为是有安全风险的； 但可以用run container时加 -P选项强行暴露端口，但这是个动态端口暴露 用起来极其鸡肋！ ENV： build阶段使用的： 用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令 如ENV、ADD、COPY等）所调用，调用格式为$variable_name或${variable_name} 两种语法： 1.ENV &lt;key&gt; &lt;value&gt; &lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只 能设置一个变量； 2.ENV &lt;key&gt;=&lt;value&gt; ... 可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果 &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另外，反斜线也可用于续行； 定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能 缺点：如果想修改ENV定义的值，只能修改dockerfile中的值，比价麻烦，此时 就可以使用ARG来代替ENV ARG： arg是在build阶段进行传值，替换dockerfile中的值 ARG &lt;name&gt; [=&lt;default&gt;] 可以设置默认值 当build创建镜像时没有传值，则使用在dockerfile中设置的默认值 既可以弥补ENV的缺点也可以和RUN，CMD的ENV传环境变量区别开 如：在build时更改home的值 docker image build --build-arg home=&quot;/webdata/&quot; /data/dockerfile/ -t myimg:v0.4 RUN,CMD,ENTRYPOINT的区别 区别： RUN： 用于指定docker build过程中运行的程序，可以是任何命令 (这就意味着RUN的命令必须是使用的基础镜像支持的命令) 1.是指在docker build过程中通过运行RUN定义的shell命令，以达到在镜像中安装软件等操作 2.RUN可以设定多次，而且每一个都会在build的时执行 语法： RUN &lt;command&gt; 通常运行的是一个shell命令，且以&quot;/bin/sh -c&quot;运行，且/bin/sh是PID为1的进程，command是作为shell的子进程存在 RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] 此种格式指定的命令不会以&quot;/bin/sh -c&quot;，因此无法支持shell的诸多特性，如要依赖于shell特性，可替换成如下格式： RUN [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;] CMD： 1.当把镜像运行容器时，需要指定默认运行的程序，这在dockerfile中需要用CMD命令来 指定，ENTRYPOINT也可以 2.默认运行的程序必须运行在前台 3.由于CMD设定的是容器启动默认运行的程序，所以必须只有一个，如果有多个， 则最后一个CMD生效 语法： CMD &lt;command&gt; 或 CMD [“&lt;executable&gt;”, “&lt;param1&gt;”, “&lt;param2&gt;”] 或 CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;] 前两种语法格式的意义同RUN 第三种则用于为ENTRYPOINT指令提供默认参数 systemctl start httpd启动是运行在systemd的前台上，所以启动就会退出 ENTRYPOINT： 1.CMD和ENTRYPOINT都表示镜像启动为容器时，容器默认运行的程序，而且CMD和ENTRYPOINT有多个，也都是最后一个生效 2.如果CMD和ENTRYPOINT同时存在，CMD和ENTRYPONIT需要组合起来，则CMD指定的内容 都作为ENTRYPOINT所指定内容的参数 语法： ENTRYPOINT &lt;command&gt;或者 ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到 ENTRYPOINT命令最后做为其参数使用 Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效 示例： docker run –name c1 -P -d myimg:v0.1 以后台运行容器]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker网络]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[Docker Network KVM上虚拟桥接式网络类型： 隔离桥：只能与连接到同一个桥上的主机通信，IP地址还需要在同一网段 仅主机桥：可以和连接的桥地址进行通信 路由桥： 1.打开宿主机核心转发功能 2.虚拟机的网关都指向这个桥的地址 就可以与宿主机通信，不能与外网通信 NAT桥：在路由桥的基础上，在宿主机上做SNAT规则，即可访问外网地址 Docker提供的四种网络： 桥网络：桥接网络 bridge，默认就是docker0桥，docker0是SNAT桥 查看网络定义：docker network inspect bridge 大多数的容器还是使用bridge网络 而且这是个SNAT网络，容器只能访问外网，外网主机确无法访问该容器 共享桥：联盟式网络 每一个容器都是靠在内核级虚拟资源分配的独立的6种名称空间来支撑的 这6种名称空间是IPC,Net,Mount,UTS,PID,USER 虽然每个容器都有各自独立的名称空间，但是确可以共享，于是就有了这种方式 共享桥的原理： 共享Net UTS(主机名) IPC,使用同一个网络地址，主机名和网络协议栈 而mount user PID还是隔离的，文件系统也是隔离的 这样做的效果就可以构建出一个模型 httpd---&gt;fpm127.0.0.1:9000---&gt;mysql127.0.0.1:3306 那么对于fpm和mysql来说只监听在本地端口上，保证了安全性 host宿主机网络：共享宿主机网络 既然多个容器可以使用同一个容器的网络名称空间，而且宿主机在内核中也有自己的 网络名称空间，那么容器也理所当然的可以使用宿主机的网络名称空间 容器使用宿主机的网络和DNAT方式有关系 作用：可以做日志收集主机，host一般在特殊环境下使用 none网络：封闭式网络 当容器不需要网络服务时，不创建网卡，只有本地lo网卡 除了bridge桥之外，其他三种网络都是docker所独有的 Docker网络的相关命令docker run 命令中涉及网络的相关命令 --network 启动容器时，指定使用的网络 [bridge|host|none|container:name] --hostname 启动容器时，指定容器的主机名 --add-host list 启动容器时，指定内部的hosts解析文件 如：docker run --add-host c1:192.168.10.1 busybox:latest cat /etc/hosts可以看到添加的解析 --dns 启动容器时，指定DNS地址 如：docker run --dns 114.114.114.114 --dns 8.8.8.8 busybox:latest cat /etc/resolve可以看到指定的DNS地址 --ip string 启动容器时，指定容器的iPv4地址 -p|--publish 因为Bridge桥是SNAT桥,容器是不能被外网访问的，所以就需要加DNAT规则 docker network: ls：显示docker内部的全部网络 connect: 让容器连接到某个网络上 disconnect: 把容器从某个网络断开 create: 创建自定义网络，和KVM创建网络类似 inspect:查看某个网络是怎么定义的 prune:删除所有未被使用的网络，即没有任何容器使用该网络，危险命令 rm: 删除docker内部的网络 Docker network的端口暴露docker run --network [bridge|host|none] -p|--publish 作为一个容器，是要提供web服务的，而docker默认的桥是bridge，而且是个SNAT桥 容器只能访问外网，而不能被外网所访问，那么就失去了web服务器对外提供服务的初衷 而docker提供了一个-p选项来自动生成DNAT规则，来避免每次都手写DNAT规则带来的麻烦 -p选项的用法和使用格式： •-p &lt;containerPort&gt; 将指定的容器端口映射至主机所有地址的一个动态端口 •-p &lt;hostPort&gt;:&lt;containerPort&gt; 将容器端口&lt;containerPort&gt;映射至指定的主机端口&lt;hostPort&gt; •-p &lt;ip&gt;::&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的动态端口 •-p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; “动态端口”指随机端口，具体的映射结果可使用docker port命令查看 不过一般还是要使用第四种方式指定宿主机的端口 指定了映射的端口后，可以使用命令查看映射关系： docker container port [name] 示例： 1.docker run --name c1 -it --rm --network bridge -p 80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 0.0.0.0:32768 2.docker run --name c1 -it --rm --network bridge -p 80:80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 0.0.0.0:80 3.docker run --name c1 -it --rm --network bridge -p 192.168.34.103::80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 192.168.34.103:32768 4.docker run --name c1 -it --rm --network bridge -p 192.168.34.103:80:80 busybox:latest 使用docker port tiny 查看映射的端口 [root@node7-1 ~]#docker container port c1 80/tcp -&gt; 192.168.34.103:80 Docker的自定义网络docker network create connect:相当于创建一对网卡，一半在桥上，一半在容器中 而且默认创建的网络都是SNAT桥 选项： -d|--driver string 创建时，要指定桥的类型 默认是bridge，当然还有 host macvlan null overlay四种类型 --gateway strings 默认是定义的子网的第一个IP地址 --subnet strings 子网地址 --ip-range strings 地址分配的IP地址范围 修改默认的bridge，docker0桥的子网 自定义docker0桥的网络属性信息：也就是镜像加速的文件 vim /etc/docker/daemon.json文件 { &quot;bip&quot;: &quot;192.168.1.5/24&quot;, &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mtu&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;] } 核心选项为bip，即bridge 桥接口的IP地址 ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。 示例： 1.创建一个mybr2的网络，并指定子网地址 docker network create --subnet 10.0.0.0/8 mybr2 2.创建容器c1指定加入到mybr2网络中 docker run --name c1 -it --rm --network mybr2 busybox:latest 3.给容器c1再加入一个bridge网络中 docker network connect bridge c1 此时c1就有了两个网络地址 4.删除容器c1的网卡 docker network disconnect mybr2 c1 Docker指定容器启动的网路类型1.启动为none类型的网络 docker run --name c1 -it --rm --network none busybox:latest 2.启动为bridge类型的网络:docker默认的网络模型 docker run --name c2 -it --rm --network bridge busybox:latest 3.启动为joined类型的网络 启动的c3共享的是c2的Net,UTS,IPC,而Mount,PID,User进程，用户，文件系统还是隔离的 因为共享桥只是共享了Net网络，UTS主机名，IPC，此时IP地址和hostname都是一样，就可以通过127.0.0.1进行通信了而mount(文件系统)，user,PID还是隔离的，所以在1上创建一个文件，2上是看不到的这就是共享桥的工作机制 4.启动为host宿主机类型的网络 docker run --name c4 -it --rm --network host busybox:latest 可以看出hostname,Net都是和宿主机是一样的 此时在容器内部启动httpd服务，其他主机是可以通过宿主机提供服务的]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker镜像]]></title>
    <url>%2F2018%2F10%2F18%2FDocker%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[Docker Images 1.docker image是docker贡献给容器极具创造性的使用方式！2.分成构建，联合挂载这种镜像集中存储的Registry方式确实是一个创造性成果！3.容器编排技术：—Docker通过镜像机制极富创造性的解决了应用程序打包的根本性难题，它推动了容器技术的快速普及和生产落地—容器本身仅提供托管运行应用的底层逻辑，而容器编排(Orchestration)才是真正产生价值的位置所在； -docker-image和读写机制 1.Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器 a.docker镜像就像KVM镜像一样，包含了启动容器/虚拟机所依赖的所有文件，文件系统 包括程序文件，库文件，配置文件,数据目录等等 b.dokcer采用分层构建机制，最底层为bootfs，其上是rootfs bootfs：在创建的容器中是看不到的，只是用于系统引导的文件系统，包括 bootloader和kernel，因为在创建启动容器时，其实是用到内核的， 只不过只是启动引导容器启动的，当容器启动完成后会被卸载以节约内存资源; 而且把对应的对容器的管理委托给宿主机的内核，所以容器镜像的内核只 是启动时有用，而且看不到，所以bootfs叫引导文件系统 rootfs:位于bootfs之上，表现为docker容器的根文件系统; 1.在传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为&quot;只 读&quot;模式，完整性自检完成后将其重新挂载为读写模式；也就是fstab 的最后两项，只有通过自检次序时，才会把根文件系统重新以&quot;读写&quot;方式挂载. 2.但是在docker中，rootfs由内核挂载为&quot;只读&quot;模式，就算容器启动完成 ，rootfs也不会以读写方式重新挂载！也就是说docker容器的用户空 间和根文件系统一直都是只读的！ 3.docker是通过&quot;联合挂载&quot;技术额外挂载一个“可写”层；docker image layer 2.Docker Images Layer 如上图 a.完整的docker镜像包括bootfs,rootfs b.而rootfs又包括Base Image+自定义的镜像层+可写层writable 除了writable是可写层，其他都是只读层 c.而可写层writable并不是容器镜像自带的；而是创建容器时自动在镜像的最上层添加 一个可写层，这个可写层writable是属于容器的 d.如果基于同一个镜像创建多个容器，那么可写层是各个容器独占的，只读层是共享的 容器的读写原理：如上图示： 1.对于docker来说有一个专门存放镜像的路径叫Graph Driver，而这个文件系统必须是特殊 格式的(aufs或者overlay2),在linux系统内默认是/var/lib/docker/image/overlay2； overlay2目录就是构建在宿主机(xfs或ext4)的/var/lib/docker/image/目录的二级文件系统 2.前面说镜像数据文件都放在bootfs和rootfs上的，可写层writbale是创建时创建的 那么在可写层上是如何看到底层的数据目录？又是怎么把数据增删改到容器内的？ 默认xfs和ext4是不支持COW机制的 如何看到镜像目录的？ a.在创建容器时，是把镜像内的多层镜像通过联合挂载方式作为可写层的底层，也就是这个容器内部的可访问文件系统接 口 b.所谓联合挂载，是通过把镜像内的多层一层一层叠加上去的，而这个叠加方式的原理是： 第一层上有数据时，而第二层没相同数据，在第二层是可以看到第一层数据的;如果第二层有第一层相同数据， 则会覆盖第一层上的相同数据，在第二层上看到的是第一层和第二层总的文件，以此类推，在可写层上就可以看到 镜像内的数据目录了， 如何修改和写文件？ a.对于修改文件，因为文件是放在只读层的，只能是通过COW写时复制机制，先把文件从只读层复制到可写层上再进行修改 然后保存在可写层,当然是首次修改，第二次再修改因为在可写层有文件了，在可写层修改即可，而只读层的该文件 版本仍然存在，只不过是被读写层中该文件的副本所隐藏了. b.对于写文件，新创建的文件是保存在可写层的，所以最终用户看到的是只读层和可写层的全 部数据文件，这就是镜像的工作逻辑 通过上面的分析可以得出： 1.这就是为什么基于同一镜像创建的两个容器，用户在不同的容器上看到的相同的数据都是只读层的，不同的数据是可写 层上各自独有的，因为可写层是独占的，只读层是共享的 2.这就是为什么镜像背后必须要求特殊文件系统的原因：因为ext4和xfs默认是不支持联合挂载和写时复制机制的 3.因为可写层是可以自定义修改的，把可写层保存为镜像，然后再和原始镜像进行叠加成一个自定义的镜像， 就可以作为基础镜像使用了，不过一般不这么做，而是通过dockerfile自定义镜像 docker imge相关命令docker image 相关命令 docker imges:镜像的管理命令 ls： 查看本地所有的镜像列表 build: import: inspect: 查看下载/创建的镜像详细信息 可以查看下载的某个镜像的具体信息 如：CMD:镜像启动默认运行的命令 Volume: network: 下文中构建docker file时这些都可以自定义 load: prune: pull：从远程仓库拉取镜像到本地 push: 把本地镜像推到远程的Registry rm: docker image rm = docker rmi 删除镜像 tag: 给镜像打标签 save: 2.将当前容器可写层保存为镜像并上传docker hub上 docker container commit [options] container [repository:[tag]] 选项： -a:指定作者 -c:镜像内部默认运行的命名 -p|--pause:因为制作镜像时，容器还在运行，可能制作出的镜像和当前容器不 一致，可以在制作时，暂停容器，保持数据一致 比如： 1.在docker hub上注册用户，并创建镜像仓库 创建的仓库：myimg 2.把centos1容器做成镜像仓库下的myimg：v0.1版本 docker container commit -p -a &quot;liu &lt;liu@163.com&gt;&quot; -c &quot;CMD [&apos;/bin/httpd -f&apos;]&quot; centos1 liukkui/myimg:v0.1 然后新容器就可以基于这个镜像启动了 3.上传docker hub docker login 登录到docker hub 输入账号密码，正常登录后 4.push镜像 docker image push liukkui/myimg:v0.1 正常情况下，如果hub仓库中有底层的基础镜像，则只推变化的镜像层]]></content>
      <categories>
        <category>虚拟化</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s-volumes]]></title>
    <url>%2F2018%2F08%2F10%2Fk8s-volumes%2F</url>
    <content type="text"><![CDATA[Kubernetes Volumes k8s上的volumes和docker中的volumes都是为了保存数据，但还是有区别的： 1.docker上因为是在单机上运行容器的，删除容器只要加载本地之前挂载的卷就可以了。 2.在k8s集群上，如果删除一个Pod,则这个pod的卷数据会保存在之前的这个node节点上了，而scheduler的调度是随机的， 有可能不会运行在之前的node上，那么之前保存的数据是无意义，不能利用的. 3.k8s是分布式集群，如果所有节点都挂载网络文件系统，那么数据就可以跨节点使用了. 数据冗余实现方式： 1.存储设备做镜像，主备模式 2.分布式存储 不会对存储节点设备做冗余，而是在软件数据管理级别上对每个数据对象做冗余； 根据调度规则和冗余级别在当前集群的多个节点上都存放一份数据 还支持向外扩展 如何挂载： 1.pod中是有个基础容器pause的,同一个pod中是共享pause容器的UTS(主机名),Network(网络名称空间),IPC(进程间通信，网络协议栈). 2.因为在节点上的pod是共享节点内核的，驱动也是在内核，所以节点本身需要先识别适配外部的各种存储系统. 3.节点是可以挂载多种外部存储系统的，所以pause挂载存储时，需要指明挂载的是哪种文件系统类型的存储并有相应的存储插件驱动. 4.同一Pod中的其他容器要想使用pause中的volumes,需要先通过volumes定义pause中定义卷，pod再通过volumeMounts复制并挂载pause定义的卷. CSI: Container Storage interface，通过容器存储接口自定义存储卷 k8s中内置的存储卷类型 kubectl explain pod.spec.volumes 定义存储卷 详见：kubectl explain pod.spec.volumes #如何定义挂载卷 要用存储卷需要现在pod.spec字段定义挂载卷类型和目录等信息 挂载存储： 详见： kubectl explain pod.spec.containers.volumeMounts #定义如何挂载卷 是使用挂载卷，需要在pod.spec.containers中挂载上去才能用 spec中的详细定义说明： spec: volumes: #先定义pause中的挂载卷 - name #必须定义存储卷名称,以便挂载时引用 下面根据存储类型不同定义方式也不同，按需修改 hostPath/nfs #必须指定存储类型 - path #定义宿主机或者网络存储的路径 type #指定的目录/文件不存在时，应该怎么创建 DirectoryOrCreate #不存在则创建 Directory #目录必须事先存在 File #文件可以挂载，但是必须事先存在 FileOrCreate #文件不存在则自动创建 Socket #必须是套接字文件，必须事先存在 CharDevice #字符设备文件，必须事先存在 BlockDevice #块设备文件，必须事先存在 containers: - name: image: volumeMounts: #复制并挂载pause中定义的卷 - name: #引用volumes中定义的1个或多个卷的卷名 mountPath #挂载在容器的哪个路径(应用程序的文件路径) readOnly：true|false #挂载的路径是否只读，默认是读写权限 mountPropagation # 本地存储：hostPath和local示例1：hostPath类型 #节点级的目录 vim myapp-hostpath-volumes.yaml apiVersion: v1 kind: Pod metadata: name: myapp namespace: volumes-test spec: containers: - name: myapp image: ikubernetes/myapp:v1 volumeMounts: - name: website mountPath: /usr/share/nginx/html readOnly: true volumes: - name: website hostPath: path: /volumes/myapp type: DirectoryOrCreate 示例2：local类型 k8s1.10版本之后的类型，且是节点级的设备或者节点级目录 临时存储：emptyDir临时存储作用： 1.为容器提供缓存存储空间 1.支持在节点的内存中切分一部分空间作为缓存来用 2.为没有持久存储必要的同一Pod中的两个容器共享数据 3.临时存储随着Pod的删除自动删除 用法： kubectl explain pod.spec.volumes.emptyDir medium #默认是disk磁盘，还可以是Memory内存 sizeLimit #当medium是memory时，则必须进行限制 简单示例： volumes: - name: ceshi # emptyDir: {} #如果medium和sizelimit都不定义，则为磁盘的任意空间 emptyDir: medium: Memeory #使用内存当空间 sizeLimit: 200Mi #使用内存空间为200M 网络存储：NFS用法： kubectl explain pods.spec.volumes.nfs path： #nfs的共享目录：如/vols/v1 readOnly：true|false #是否只读，默认读写 server: #nfs服务IP或者主机名 缺点： 1.需要事先知道nfs服务器的地址 2.nfs导出的存储空间目录 示例： 先准备nfs的共享目录:在10.10.0.29上测试 vim /etc/exports /vols/v1 10.10.0.0/8(rw,no_root_squash) [root@master01 manifsets]# vim redis-nfs-volumes.yaml apiVersion: v1 kind: Pod metadata: name: redis namespace: volumes-test spec: nodeName: node03 containers: - name: redis image: redis:alpine ports: - name: redis containerPort: 6379 volumeMounts: - name: redisdata mountPath: /data readOnly: false volumes: - name: redisdata nfs: path: /vols/v1 #nfs导出的共享目录 server: 10.10.0.29 #nfs服务器的地址 持久卷申请存储：PV&amp;PVC为了使用存储方便，为volumeMounts和后端存储设备加加了两个中间层 在spec.volumes和存储间加了一个persistentVolume中间层 把存储系统的所提供的存储能力抽象成k8s上的标准资源：persistentVolume持久存储卷 persistentVolume： 1.PV和存储系统之间不是一一对应关系，而是与对应后端存储系统上可被单独访问的逻辑单元； 2.一个PV对应nfs的一个导出目录、ceph的一个image、云存储的一个云盘; 3.把后端存储的一个个逻辑单元映射为k8s上的一个个PV; 4.PV是集群级别的资源，不属于任何名称空间; PV的lifecycle: provisioning: #PV的动态供给 bingding #PV被绑定 using #PV被使用 reclaiming #PV被回收 PV的供给方式： 动态供给： 1.存储系统上需要事先有逻辑存储单元，根据PVC的空间需求，在底层存储上选择适合空间需求的存储单元动态得创建为PV. 2.底层存储的逻辑单元不存在，只有存储空间 1.PVC向SC请求调用存储系统的API存储接口，临时创建需求空间大小的逻辑存储单元. 2.然后在SC内部把此存储单元创建为PV，与PVC进行binding. 3.动态供给是创建SC，而不是PV 静态供给： 存储系统上事先有存储，手动创建PV，再手动创建PVC与之绑定. PV的回收策略：reclaim Pod删除时，PVC也可以删除，则引用的PV就处于回收状态，PV删除有二种策略 Delete: #PVC删除时连带PV一起删除 Retain #PV和PV上的数据都保留 备注： 1.如果是retain的，PV上仍然会有数据，但是不能被其他PVC所绑定了 2.可以手动删除PV，并手动删除存储上逻辑单元下的数据 persistentVolumeClaim 1.PV属于集群级别资源，Pod属于名称空间级别资源，如果pod想使用PV就需要把PV注册到名称空间中; 2.Pod是通过PVC请求占用PV，来使用PV的，一旦名称空间A占用PV1，其他名称空间就不能再用PV1了; 3.PVC占用PV称为binding;为被PVC占用的PV称为avaiable(可用的PV); 4.Pod通过volumes.persistentVolumeClaim使用PVC，进而间接使用PVC所占用的PV的. 5.PVC是属于某个名称空间，可以由管理员手动创建的. PVC和存储系统的多路访问模型： 1.单路读写： RW0:ReadWriteOnce iscsi 2.多路读写: RWX:ReadWriteMany 3.多路只读: ROX:ReadOnlyMany 作用： PV是与后端存储的逻辑单元做映射的，存储系统是否支持多路读写应该体现在PV的定义上，才能避免PVC关联PV是否能多路读写出现存储故障. PV和PVC的删除保护： 当PVC和PV被Pod使用时，在k8s的1.10版本之后，即使PVC和PV被删除，此时也不会真的被删除，只有Pod被删除时， PVC和PV才会被允许删除，这就是PVC和PV的删除保护. 定义PV： pv.spec和pod.spec.volumes是一样的，这样在创建pod时就不要再定义volumes了直接在containers.volumeMounts进行复制挂载就行了. kubectl explain persistentVolume.spec spec: accessModes #定义存储系统的访问模型的字符串列表 RW0/RWZ/ROX capacity: #定义存储容量 storage #单位是Ki Mi Gi等等 volumeMode: #存储设备的访问接口(文件系统接口和块设备接口) Fileystem|block persistentVolumeReclaimPolicy #定义PV的回收策略 Delete|Retain storageClassName: #定义使用哪种存储类 mountOptions: #自定义挂载选项,下面这两项是默认的 - hard - nfsvers=4.1 nfs/ceph: #定义PV关联的存储类型 下面选项根据不同存储系统定义不同的属性值 server: path: 定义PVC： kubectl explain pvc.spec accessModes #访问权限必须要要绑定的PV权限的子集 volumeMode #存储设备的访问接口(文件系统接口和块设备接口) resources #资源请求 requests: #资源需求 storage: #具体的需求存储空间大小 limit #资源上限 storageClassName #存储类(PVC和PV必须在同一存储类中) selector #通过标签选择器去选PV 不定义选择器，则从所有PV中选择合适的PV volumeName # dataSource # 存储类SC：StorageClass SC:Storageclass是k8s上的标准资源 SC是实现PVC动态创建存储单元PV的基础 1.SC上定义了如何连接外部存储API管理接口的方式 2.PVC只能向同一个SC中的PV请求绑定，不能跨SC. 定义SC： 详见：kubectl explain sc apiVersion kind metadata parameters #对接外部存储时的参数 reclaimPolicy #在此SC中的PV回收策略 provisioner #指明后端存储设备-----必须项 volumeBindingMode #后端存储支持的访问模型(RWX,ROX,RWO) allowVolumeExpansion #后端存储系统是否支持空间拉伸 官方示例： glusterfs类型的SC apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: slow provisioner: kubernetes.io/glusterfs parameters: resturl: &quot;http://127.0.0.1:8081&quot; clusterid: &quot;630372ccdc720a92c681fb928f27b53f&quot; restauthenabled: &quot;true&quot; restuser: &quot;admin&quot; secretNamespace: &quot;default&quot; secretName: &quot;heketi-secret&quot; gidMin: &quot;40000&quot; gidMax: &quot;50000&quot; volumetype: &quot;replicate:3&quot; ceph-rbd类型的SC: kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: fast provisioner: kubernetes.io/rbd parameters: monitors: 10.16.153.105:6789 adminId: kube adminSecretName: ceph-secret adminSecretNamespace: kube-system pool: kube userId: kube userSecretName: ceph-secret-user userSecretNamespace: default fsType: ext4 imageFormat: &quot;2&quot; imageFeatures: &quot;layering&quot; 示例-创建静态供给PV和PVC以nfs为例定义一个PV： [root@master01 manifsets]# vim pv-test.yaml apiVersion: v1 kind: PersistentVolume metadata: name: pv-nfs-v1 labels: storagefs: nfs spec: # accessModes: [&quot;ReadWriteOnce&quot;,&quot;ReadWriteMany&quot;,&quot;ReadOnlyMany&quot;] accessModes: - ReadWriteMany - ReadWriteOnce - ReadOnlyMany capacity: storage: 1Gi #定义PV能提供多大存储空间 volumeMode: Filesystem persistentVolumeReclaimPolicy: Retain #定义PV回收策略 nfs: path: /vols/v2 server: 10.10.0.29 创建PVC： apiVersion: v1 kind: PersistentVolumeClaim metadata: name: redis-pvc #定义PVC的名称，以便Pod中引用 namespace: volumes-test spec: selector: #定义关联到哪个PV，不指定则根据需求空间找相近空间大小的PV matchLabels: storagefs: nfs2 accessModes: - ReadWriteMany volumeMode: Filesystem resources: requests: storage: 500Mi #根据PV的存储空间定义PVC有多少空间 创建Pod挂载PVC apiVersion: v1 kind: Pod metadata: name: redis namespace: volumes-test spec: nodeName: node03 containers: - name: redis image: redis:alpine ports: - name: redis containerPort: 6379 volumeMounts: #容器复制挂载volumes - name: redisdata mountPath: /data readOnly: false volumes: - name: redisdata persistentVolumeClaim: claimName: redis-pvc #挂载PVC 测试： [root@master01 ~]# kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pv-nfs-v1 1Gi RWO,ROX,RWX Retain Available 8m14s pv-nfs-v2 2Gi RWO,ROX,RWX Retain Released volumes-test/redis-pvc-1 8m14s pv-nfs-v3 3Gi RWO,ROX,RWX Retain Bound volumes-test/redis-pvc 8m14s [root@master01 ~]# kubectl get pvc -n volumes-test NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE redis-pvc Bound pv-nfs-v3 3Gi RWO,ROX,RWX 5m55s 特殊存储：ConfigMap和Secret都是为pod中的容器提供配置变更，扮演了k8s系统上一组控制器控制的pod的配置中心 docker中的应用程序根据不同的环境配置不同的配置文件是依靠两种方式： 1.应用程序镜像是云原生或者支持通过enterpoint脚本可以传递环境变量来适应不同的场景使用. 缺点是：要修改传的值需要删除容器重新创建 2.先配置好不同的配置文件，通过挂载卷将文件传递到容器中. 缺点是：在本地映射的路径下修改了配置文件，容器是不会自动加载新的配置文件的. k8s上面临相同的问题，为了解决修改配置文件或参数值能够使Pod自动重载配置信息，就将配置文件做成了k8s上的configMap资源. ConfigMap和Secret 1.Pod中的容器提供配置信息 2.配置中心：配置发生变更，测试完成后，通知方式(灰度) 区别： configMap用来保存非敏感数据，Secret用来保存敏感数据的 configMap和Secret是如何将配置传递至Pod中的？ 先定义configMap和secret类型的资源，而这种资源时K/V键值对存在的 1.如果是环境变量，则定义这两种资源时，指定key和value 2.如果是配置文件，则文件名为Key,文件内容为值value 创建pod时，只需要引用此资源的Key即可： 1.把configmap和secret资源的key映射给pod容器中的环境变量或者文件名 2.给环境变量传key的名称，通过k/v替换，获得v的值，如果想变更配置，只需要修改pod外部configmap中的value的值即可 ，pod会在一段时间内自动传递新的value值，进行配置更新. ConfigMap注意： 1.命令行创建configmap比资源清单更简单，但是配置清单更易维护. 2.通过资源清单配置的configMap中嵌套的是K/V数值还比较简单如果嵌套的是文件内容 的话，配置格式还是有些麻烦的. 创建ConfigMap的两种方式 1.基于命令行的 kubectl create configmap -h --from-literal #手动指定K/V值，定义多个K/V值需要有多个--from-literal --from-file #从文件中读取创建 2.配置清单(比命令行麻烦，但是更易维护) kubectl explain configmap data: #只有data字段，而没有spec字段 两种引用configMap的方式: pod和configMap必须在同一名称空间 1.基于环境变量方式引用configMap (用于传递环境变量) [root@master01 ~]#pod.spec.containers.env env #直接手动给变量 - name #镜像中所能接收的变量名 value #手动给值(一般用valuefrom) valuefrom #从其他位置引用值 configMapKeyRef #引用一个configMap的键key name #configMap的名称 key #configMap中的一个键名 optional #被引用的configMap资源存在就可以，不存在则报错 true|false #默认是必须存在 secretKeyRef #引用一个Secret的键key,用于敏感数据传输 envfrom #从其他地方加载环境变量 缺点： 1.如果修改configmap中的环境变量的值，pod是不会更新环境变量的，除非删除重建pod，新的环境变量才会生效. 2.基于存储卷方式引用configMap (用于传递文件) 是把configmap资源当成存储卷来用的 kubectl explain pods.spec.volumes.configMap volumes: - name #定义存储卷名称以便挂载时使用 configMap: name #configMap资源的名称 items #要引用configmap中的那些键映射为本地的文件 - key #configmap中的键名 mode #映射的文件权限时多少，没定义则使用外部的defaultMode path #映射到pod中叫什么文件名(可以和key一样，也可以随意更改) 必须是相对路径，而且是相对于挂载点而言 defaultMode #映射到本地的文件权限为多少 默认是0644读写权限，可以自己指定 optional #引用的configMap资源或者引用的键不存在是否报错 注意： 1.相对于环境变量方式引用configmap，存储卷方式的pod会根据configmap内容的变化而更新自己pod中的配置信息. 2.如果一个deploy控制的多个pod，并定义挂载了configMap类型的存储，如果修改configMap文件中的内容，这些pod一般会在一分钟之内都更新到最新configmap中新的值. 3.在deploy控制的后端pod众多的情况下，需要借助互联网上的配置中心组件实现pod的滚动更新或者金丝雀更新. 4.后端pod较少的情况下，可以用ansible或者puppet进行灰度更新. 创建并引用ConfigMap示例1.基于命令行的--from-literal创建 kubectl create configmap filebeat-cfg -n config-ns --from-literal=redis_host=&quot;filebeat.defalut.svc.cluster.local&quot; --from-literal=log_level=&quot;Info&quot; 创建名为filebeat-cfg的cm,并设定两个key和他的值 2.基于命令行的--from-file创建 kubectl create cm nginx-cfg --from-file=nginx-./server1.conf --from-file=server-zhihui.conf=./nginx-server2.conf -n config-ns 引用示例： 1.基于环境变量引用configMap 此处手动创建一个Pod，用来演示使用env属性值引用configMap：filebeat-cfg apiVersion: v1 kind: Pod metadata: name: filebeat namespace: config-ns #pod和configMap必须在同一名称空间 spec: containers: - name: filebeat image: ikubernetes/filebeat:5.6.5-alpine env: - name: REDIS_HOST valueFrom: configMapKeyRef: name: filebeat-cfg key: redis_host - name: LOG_LEVEL valueFrom: configMapKeyRef: name: filebeat-cfg key: log_level 2.基于存储卷方式引用configMap 此处手动创建一个Pod，用来演示挂载configMap类型的存储 apiVersion: v1 kind: Pod metadata: name: nginx namespace: config-ns #pod和configMap必须在同一名称空间 spec: containers: - name: nginx image: ikubernetes/myapp:v1 volumeMounts: - name: config mountPath: /etc/nginx/conf.d #挂载的目录 volumes: - name: config configMap: name: nginx-cfg items: - key: nginx-server1.conf #本地文件名 path: server1.conf #映射到pod中的文件名 - key: server-zhihui.conf #本地文件名 path: server2.conf #映射到pod中的文件名 测试： 通过手动修改configmap的值，查看pod中的文件是否也会发生改变 kubectl edit cm/nginx-cfg -n config-ns 测试看出基于存储卷方式引用configMap的pod的文件内容也会自动更新. Secret1.Secret和configMap在功能上是一样的，只不过Secret是保存敏感数据的. 2.Secret的数据是通过base64编码处理过的，不是真正意义上的加密，可以通过base64进行解码. 3.Secret资源一般是通过命令行创建，而不是配置清单，因为如果通过配置清单配置时，需要 手动将敏感数据(密码)进行base64编码，是很麻烦的，而命令行创建，会自动把敏感数据进行 base64编码后保存到secret中. Secret的三种类型： 详见：kubectl create secret -h 1.docker-registry 私有镜像仓库需要登录才能够访问，docker-registry就是将账号密码进行加密认证，以便kubelet可以认证到镜像仓库服务器上. 认证方式有两种： 1.kubectl explain pod.spec.imagePullSecrets name:可以定义多个列表用于认证 缺点：如果想使用不同的账户时，是不易修改Secret的 2.kubectl explain pod.spec.serviceAccountName 服务账号：可以使用pod之外的系统认证方式 即使修改账号只需要修改serviceAccountName就可以了. 2.generic 非证书的私有敏感信息都用generic类型,通用型 3.tls #tls是专用于把ssl的tls中的x509格式的证书和私钥打包到一个secret中 而且不管原来的*.key和*.crt都被转成名为tls.key和tls.crt 创建secret-generic资源: 1.命令行创建，类似于configmap kubectl create secret [secret类型] secret名称 --from-literal= --from-file=[key=]source 2.资源清单创建，要注意将密码进行base64编码后填到data资源中的key:value中 kubectl explain secret 创建secret-tls资源: 1.命令行创建： kubectl create secret tls NAME --cert=path/to/cert/file --key=path/to/key/file -n namespace #需要先创建证书和私钥，再在创建secret-tls时引用即可. 创建docker-registry资源: 1.命令行创建： kubectl create secret docker-registry my-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL # 创建docker-registry类型的资源时，要指定连接的私有docker仓库的IP/域名，用户名，密码，注册时使用的账号 引用secret的方式 1.通过env环境变量引用 kubectl explain pod.spec.containers.env env: - name #Pod镜像中的存在的变量名 valueFrom: secretKeyRef: #表示从secret类型资源引用键 name: #引用的Secret资源的名称 key #secret资源中的键名 optional: #secret资源或者引用的key不存在时报错 true|false 2.通过存储卷引用Secret资源 kubectl explain pod.spec.volumes.secret volumes: - name: #定义存储卷名称以便挂载时使用 secret: secretName #引用的secret资源名称 items: #引用的多个键对象 - key #引用的secret资源中的键名 mode: #文件权限，私密数据建议600权限，不指定则使用外部默认的 path: #映射到pod中叫什么文件名(可以和key一样，也可以随意更改) defaultMode #引用资源的默认权限，0644 optional 注意： 1.tls类型的证书和私钥一般要用存储卷方式进行引用，不然value的值太长的. 示例： 1.generic类型的secret引用示例 apiVersion: v1 kind: Pod metadata: name: mysql namespace: config-ns spec: containers: - name: mysql image: mysql:5.6 env: - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mysql-root-password key: passwd optional: true 2.tls类型secret引用示例 apiVersion: v1 kind: Pod metadata: name: nginx namespace: config-ns spec: containers: - name: nginx image: nginx:1.14-alpine volumeMounts: - name: tls mountPath: /etc/nginx/ssl volumes: - name: tls secret: - secretName: nginx-tls items: - key: nginx.crt #原来的证书名 path: nginx-server.crt #映射到pod中的证书名 - key: nginx.key #原来的私钥名 path: nginx-server.key #映射到pod中的私钥名 mode: 0600]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现四层和七层负载均衡]]></title>
    <url>%2F2018%2F03%2F26%2Fnginx%E5%AE%9E%E7%8E%B0%E5%9B%9B%E5%B1%82%E5%92%8C%E4%B8%83%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[nginx实现七层负载均衡 –nginx实现七层调度的动静分离架构和调度算法分析 1.先通过upstream模块将多个后端服务器定义成server服务器组，再使用proxy_pass向后端 代理到这个server组 2.upstream模块实现模块级的负载均衡算法调度 3.upstream模块可以实现对后端服务器集群的健康状态监测，当有服务器down机了自动从这个 组中剔除，服务器恢复正常也会重新加入到这个组中，还支持所有服务器down机，然后由 一台sorry server提供服务 4.session保持的三种方式： session sticky: 1.基于客户端IP做hash将seesion保存在一台服务器上，如果是SNAT网络则IP是 一样的，seesion的颗粒度过于粗糙. 2.cookie机制即使是在通过SNAT网络中，不同的浏览器客户端也会被识别为不同 客户端，seesion的颗粒度精细的多.nginx可以识别应用层的cookie信息， 完全可以基于cookie信息做会话绑定的.但是只有nginx商业版支持. seesion replication: 在同一集群中，session是共享的，但是对内存的消耗比较大 把自己的seesion复制给集群的其他主机 session server: 把用户访问的seesion保存单独的一台服务器，但是session的冗余实现比较麻烦 和cookie ngx_http_upstream_module模块作用于server之外的http上下文 1.upstream name {...} 定义后端服务器组；引入一个新的上下文；只能用于http{}上下文中； 默认调度算法是round robin，也就是加权轮询wrr；默认权重是1 2.server address [parameters]; 定义服务器地址和相关的参数； 地址格式： IP[:PORT] HOSTNAME[:PORT] unix:/PATH/TO/SOME_SOCK_FILE server的修饰参数： weight=number 权重，默认为1； max_fails=number 失败尝试连接的最大次数；默认是1次 fail_timeout=time 设置服务器为不可用状态的超时时长； 失败的默认健康状态检测超时时长，默认10s 备注：max_fails和fail_timeout的乘机算一个周期，比如下面这个例子 backup 把服务器标记为“备用”状态；用于say sorry服务器 down 手动标记其为不可用；手动下线服务器，用于发布更新服务 支持的算法： 3.least_conn; 1.短连接最好使用轮询wrr，长连接最好使用wlc; 2.如果不启用保持连接，即使改成least conn,效果也不是很明显. 3.最少连接调度算法，当server拥有不同的权重时其为wlc，当所有后端主机连接数 相同时，则使用wrr，适用于长连接 4.ip_hash;静态hash算法 对源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server； 1.ip_hash是对源地址进行hash，然后对后端服务器的权重之和取模，模是多少， 就把对应的结果映射到第几台服务器上，如果有服务器down了，那么权重 之和也会变，那么原来的hash结果大概率不能命中，所以ip_hash的调度算法存在很大的缺陷. 2.如果采用ip_hash算法，一旦后端有一台缓存服务器down了，由于是取模法，会造 成后台缓存服务器集群全部不能命中，并发请求数10W时，会把请求压力全部集 中到后端服务器上，造成系统崩溃 3.所以生产环境下一般不用ip_hash，而是采用一致性hash算法. 5.hash key [consistent]; consistent,虚拟主机的一致性hash算法； 此处可以对任意的key进行hash,所选取的key的值不同，hash的结果可以实现不同的 请求调度功能.而且此处的key可以是文本，变量或者二者的组合 例如： hash $remote_addr consistent = ip_hash 即还是对源地址进行hash，但是效果确实一致性hash hash $request_uri consistent 后端服务器是缓存服务器时，对静态内容的请求资源request_uri进行hash， 极有可能在缓存中命中,从而缓解了并加大了服务器的并发访问数. hash $cookie_name consistent 对cookie的hash，首先服务端需要给客户端端强行插入cookie,就需要用到 sticky_cookie_insert,而这个功能只有在nginx plus版本中才能够使用 6.keepalive connections; 可使用长连接的连接数量；每worker与后端服务保持的最大空闲长连接数量； 为每个worker进程保留的空闲的长连接数量，可节约nginx端口，并减少连接管理的消耗 长连接的作用： connections意思代理服务器与后端服务器之前先建立一定数量的始终不断开的长连接数量，当有用户请求时，这些长连接相当于一个一直处于连接状态管道，即一个连接上可以 发N个请求，既可以提升响应速度又可以减少代理服务器的套接字占用，避免了重复建立、断开、再建立的消耗资源的步骤,属于一种优化方式. 示例： upstream staticwebservs { # ip_hash; # hash $remote_addr consistent; hash $request_uri consistent; server 172.17.0.2 weight=2 fail_timeout=2 max_fails=2; server 172.17.0.3 fail_timeout=2 max_fails=2; keepalive 32； } server { listen 8083; location / { proxy_pass http://staticwebservs/; } 这样就可以检测后端服务器集群健康状态的时长，在4s内检测到服务器有问题，就标记为down 而且建立不断开的长连接 总结： 1.对静态资源的请求，因为是短连接，要用weight round robin,加权轮询算法:wrr 2.对动态资源的请求，因为要有会话保持seesion sticky，所以要用ip_hash或者 hash $remote_addr consistent 算法，但是对IP hash的颗粒度较为粗糙，可以 对cookie进行hash,但是nginx社区版不支持. 3.如果网站有缓存层，要用hash $request_uri consistent一致性hash的绑定机制算 法,避免因为后端的一台缓存服务器down机，而影响全局的缓存层! nginx实现四层负载均衡(调度)功能 1.nginx实现四层调度，在nginx和后端服务器集群中建立一个四层的转发通道，对客户端发来 的请求报文不做任何解析，而是对客户端请求的地址和端口转发. 2.如果后端有服务器集群，可以通过upstream模块实现不同算法的负载均衡调度效果. 3.四层负载调度功能，作用于stream上下文，需要单独定义 4.对数据存储等有状态的一类的应用一定不能做负载均衡，而是通过一种数据分发路由机制的 高级组件来完成，比如mysql的读写分离，mysql的分片框架等 5.如上图示，因为只是实现四层调度，不存在什么动静分离资源，只是简单的四层调度功能 ngx_stream_core_moduleThe ngx_stream_core_module module is available since version 1.9.0. This module is not built by default, it should be enabled with the --with-stream configuration parameter. (1) listen address:port [ssl] [udp] [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; 监听的端口； 默认为tcp协议； udp: 监听udp协议的端口； ngx_stream_upstream_module实现四层调度需要在upstream中定义，负载均衡调度的组 upstream name {...}，作用于stream上下文 server address [parmameters] 修饰符： weight=number max_conns=number max_fails=number fail_timeout=time backup down ngx_stream_proxy_module(1) proxy_pass address; (2) proxy_timeout timeout; 默认为10m; (3) proxy_connect_timeout time; 设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s； 示例： stream { upstream sshsrvs { server 192.168.10.130:22; server 192.168.10.131:22; hash $remote_addr consistent; } server { listen 172.16.100.6:22202; proxy_pass sshsrvs; proxy_timeout 60s; proxy_connect_timeout 10s; } } 实现Nginx高并发的Linux入门级内核优化虽然nginx本身就支持高性能的并发访问，除了在配置文件级别的一些性能调优的必要参数之外有时也需要在linux内核级进行简单的调优. 优化说明： 优化是很复杂的一个问题，不是明显的设置缺点的话，不建议对nginx进行优化，因为不确定哪个是导致nginx明显短板的因素，有时也可以通过nginx的二级调度来实现高并发的 访问. 1.由于默认的Linux内核参数考虑的是最通用场景，这明显不符合用于支持高并发访问的 Web服务器的定义，所以需要修改Linux内核参数 2.Nginx可以拥有更高的性能,根据业务特点来进行调整，当Nginx作为静态web内容服务器、反向代理或者提供压缩服务器的服务器时，期内核参数的调整都是不同的，这里针对最通用的、使Nginx支持更多并发请求的TCP网络参数做简单的配置,修改/etc/sysctl.conf来更改内核参数 3.sysctl的用法： sysctl命令： 默认配置文件：/etc/sysctl.conf (1) 设置某参数 sysctl -w parameter=VALUE (2) 通过读取配置文件设置参数 sysctl -p [/path/to/conf_file] (3) 查看所有生效参数 sysctl -a 最好是写在/etc/sysctl.conf中，再通过sysctl -p /etc/sysctl.conf生效即可 比如： 进制本机被ping的设置 sysctl -w net.ipv4.icmp_echo_ignore_all=1 fs.file-max = 999999：单个进程较大可以打开的文件描述符数量 ulimit -n 999999 net.ipv4.tcp_tw_reuse = 1 (必调) 参数设置为1，表示允许将TIME_WAIT状态的socket重新用于新的TCP连接，因为在服务器端有大量的处于TCP中的TIME_WAIT状态的链接存在，能够复用这个socket对于繁忙的服务器来说意义重大. echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse (sysctl) net.ipv4.tcp_keepalive_time = 600 当keepalive启动时，TCP发送keepalive消息的频度，默认为2小时，将其设置10分钟，可以更快的清理无效连接 net.ipv4.tcp_fin_timeout = 30 当服务器主动关闭连接是，socket保持在FIN_WAIT2状态的较大时间 net.ipv4.tcp_max_tw_buckets = 5000 默认是8000，建议调小 允许TIME_WAIT套接字数量的较大值，如果超过这个数字，TIME_WAIT套接字将立刻清除并打印警告信息，默认为8000，过多TIME_WAIT套接字会使web服务器变慢 net.ipv4.ip_local_port_range = 1024 65000 TCP和UDP连接的本地端口取值范围 net.ipv4.tcp_rmem = 1024 87380 12582912 TCP接收缓存的最小值、默认值、最大值 net.ipv4.tcp_wmen = 1024 87380 12582912 TCP发送缓冲的最小值、默认值、最大值 net.core.netdev_max_backlog = 8096 网卡接收队列最大值 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_sync_backlog = 8192 TCP三次握手建立阶段接收SYN请求队列的最大长度，默认为1024 net.ipv4.tcp_tw_recyle = 1 启用timewait的快速回收]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于lnnmp搭建个人博客]]></title>
    <url>%2F2018%2F03%2F22%2F%E5%9F%BA%E4%BA%8Elnnmp%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[基于openstack/docker搭建LNNMP -个人网站基本架构图 环境准备1.所有服务器时间要同步 2.proxysql要和mysql所有服务器在同一个网段，不然会影响mysql的性能 nginx调度服务器：192.168.100.10 nginx+fpm-1服务器：192.168.100.3 nginx+fpm-2服务器：192.168.100.4 proxysql数据库读写分离：192.168.100.30 mysql_1服务器:192.168.100.9 mysql_2服务器:192.168.100.16 mysql_3服务器:192.168.100.17 NFS主：在mysql_2服务器上192.168.100.16 NFS备：在mysql_3服务器上192.168.100.17 软件版本： wordpress: wordpress-5.0-zh_CN.zip (默认安装再升级) wordpress-5.0.2-zh_CN.zip(用于测试升级版本) 依赖于php7.3版本之上和mysql5.6或者mariadb10.0版本之上 mysql:mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz(和一键安装脚本) nginx:nginx-1.12.2.tar.gz php-fpm:php-7.2.14.tar.gz nfs: nfs-utils 1.搭建一主二从数据库二进制安装mysql，此处用事先准备好的脚本进行安装(供参考)； 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@mysql_1 ~]# vim mysql-install.sh #!/bin/bashDIR=`pwd`NAME=&quot;mysql-5.6.34-linux-glibc2.5-x86_64.tar.gz&quot;FULL_NAME=$&#123;DIR&#125;/$&#123;NAME&#125;DATA_DIR=&quot;/data/mysql&quot;yum install vim gcc gcc-c++ wget autoconf net-tools lrzsz iotop lsof iotop bash-completion -yyum install curl policycoreutils openssh-server openssh-clients postfix -yif [ -f $&#123;FULL_NAME&#125; ];then echo &quot;安装文件存在&quot;else echo &quot;安装文件不存在&quot; exit 3fiif [ -h /usr/local/mysql ];then echo &quot;Mysql已经安装&quot; exit 3else tar xvf $&#123;FULL_NAME&#125; -C /usr/local/src ln -sv /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64 /usr/local/mysql if id mysql;then echo &quot;mysql用户已经存在&quot; fi useradd mysql -s /sbin/nologin if id mysql;then chown -R mysql.mysql /usr/local/mysql/* -R if [ ! -d /data/mysql ];then mkdir -pv /data/mysql &amp;&amp; chown -R mysql.mysql /data -R /usr/local/mysql/scripts/mysql_install_db --user=mysql --datadir=/data/mysql --basedir=/usr/local/mysql/ cp /usr/local/src/mysql-5.6.34-linux-glibc2.5-x86_64/support-files/mysql.server /etc/init.d/mysqld chmod a+x /etc/init.d/mysqld cp $&#123;DIR&#125;/my.cnf /etc/my.cnf ln -sv /usr/local/mysql/bin/mysql /usr/bin/mysql chkconfig --add mysqld service mysqld start else echo &quot;MySQL数据目录已经存在&quot; exit 2 fi fifi 主节点数据库： 1.启用二进制日志和跳过主机名称解析 server-id=1 log_bin=/data/mysql/master-log skip_name_resolve = on 2.授权主从复制账号 grant replication slave on *.* to repluser@&apos;192.168.100.%&apos; identified by &apos;root123&apos;; 3.show master logs; 查看二进制日志位置，准备change master to信息 4.创建wordpress数据库 create database wordpress; 5.创建php连接mysql的用户和proxysql读写分离的用户 grant all on *.* to wordpress@&apos;192.168.100.%&apos; identified by &apos;wordpress123&apos; 此账号既作为php连接数据库的账号，又作为proxysql中读写分离的账户 从节点数据库： 1.每个从节点都需要如下设置，设置只读，启用中继日志 server-id=2|3 read-only relay_log=/data/mysql 2.设置change master to: CHANGE MASTER TO MASTER_HOST=&apos;192.168.100.9&apos;, MASTER_USER=&apos;repluser&apos;, MASTER_PASSWORD=&apos;root123&apos;, MASTER_PORT=3306, MASTER_LOG_FILE=&apos;master-log.000001&apos;, MASTER_LOG_POS=4, MASTER_CONNECT_RETRY=120; 3.start slave; 启动MySQL主从 service mysqld start 安装配置proxysql读写分离器1.基于YUM仓库安装 vim /etc/yum.repos.d/proxysql.repo [proxysql_repo] name= ProxySQL YUM repository baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever gpgcheck=1 gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key 2.安装启动 yum install proxysql &amp;&amp; systemctl start proxysql 3.向ProxySQL中添加MySQL所有节点，以下操作不需要use main也可成功 MySQL &gt; select * from mysql_servers; MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.9&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;192.168.100.16&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,&apos;192.168.100.17&apos;,3306); MySQL &gt; load mysql servers to runtime; MySQL &gt; save mysql servers to disk; 4.配置监控账号： a.在主节点上，创建监控账号 grant replication client on *.* to monitor@&apos;192.168.100.%&apos; identified by &apos;root123&apos;; 备注：replication client权限是负责监控的，和replication slave是不同的权限 b.Proxysql上配置监控 实际上是保存在global_variables表中，可以查看是否修改成功 MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;; MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;; c.使global_variables表生效 MySQL [mian]&gt; load mysql variables to runtime; MySQL [mian]&gt; save mysql variables to disk; 5.设置分组信息和读写规则 main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20 插入读写组的编号： insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;); 生效和保存： MySQL [monitor]&gt; load mysql servers to runtime; MySQL [monitor]&gt; save mysql servers to disk; 再次查看 select hostgroup_id,hostname,port,status,weight from mysql_servers; 6.创建用于测试读写分离的账号 主节点上创建访问用户： 用上面创建的wordpress账户即可 在ProxySQL配置，将用户wordpress添加到mysql_users表中： insert into mysql_users(username,password,default_hostgroup)values(&apos;wordpress&apos;,&apos;wordpress123&apos;,10); 生效和保存： MySQL [monitor]&gt; load mysql users to runtime; MySQL [monitor]&gt; save mysql users to disk; 7.配置路由规则，实现读写分离 与规则相关的表：mysql_qeury_rules 插入路由规则,实现读写分离的规则 insert into mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply) VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1); 生效和保存到磁盘： load mysql query rules to runtime; save mysql query rules to disk; 8.可以现在本机用wordpress测试是否可以实现读写分离 读：因为是读操作会在2和3上随机选择 mysql -wordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos; 写：事务是非select开头的，所以查询的都是1上 mysql -uwordpress -pwordpress123 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos; 编译安装php1.准备环境依赖包： yum -y install wget vim pcre pcre-devel openssl openssl-devel libicu-devel gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel ncurses ncurses-devel curl curl-devel krb5-devel libidn libidn-devel openldap openldap-devel nss_ldap jemalloc-devel cmake boost-devel bison automake libevent libevent-devel gd gd-devel libtool* libmcrypt libmcrypt-devel mcrypt mhash libxslt libxslt-devel readline readline-devel gmp gmp-devel libcurl libcurl-devel openjpeg-devel 2.编译php: ./configure --prefix=/usr/local/php \ --with-config-file-path=/usr/local/php/etc \ --with-config-file-scan-dir=/usr/local/php/etc/conf.d \ --enable-fpm --with-fpm-user=www \ --with-fpm-group=www --with-pear \ --with-curl --with-png-dir --with-freetype-dir \ --with-iconv --with-mhash --with-zlib --with-xmlrpc \ --with-xsl --with-openssl --with-mysqli --with-pdo-mysql \ --disable-debug --enable-zip --enable-sockets \ --enable-soap --enable-inline-optimization --enable-xml \ --enable-ftp --enable-exif --enable-wddx \ --enable-bcmath --enable-calendar --enable-shmop \ --enable-dba --enable-sysvsem --enable-sysvshm --enable-sysvmsg make &amp;&amp; make install 3.创建用户 useradd www 4.准备配置文件 cd /usr/local/php/etc/ cp php-fpm.conf.default php-fpm.conf cp php-fpm.d/www.conf.default php-fpm.d/www.conf 1.修改php-fpm.d/www.conf配置文件，使用dynamic动态模式，并设置最大，最少 空闲进程等信息 2.修改启动php的用户为www 5.准备启动脚本 cp /root/ php-7.2.14/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm chmod +x /etc/init.d/php-fpm chkconfig --add php-fpm chkconfig php-fpm on 也可以使用编译生成的 /usr/local/php/sbin/php-fpm直接启动 编译安装nginx实现web服务因为在上文架构图中nginx既做web服务，又作为前端负载均衡服务器 在这两台服务器上编译安装nginx,实现转发wordpress请求 nginx+fpm-1服务器：192.168.100.3 nginx+fpm-2服务器：192.168.100.4 1.解压并编译 tar xf nginx-1.12.2.tar.gz cd nginx-1.12.2 ./configure \ --prefix=/usr/local/nginx \ --with-pcre \ --with-http_stub_status_module \ --with-http_ssl_module make &amp; make install 2.修改配置文件将php资源请求调度到php-fpm 在server的上下文定义：因为nginx和php在同一台服务器，所以直接写127.0.0.1:9000 location / { root /data/nginx/wordpress; index index.php index.html index.htm; } location ~ \.php$ { root /data/nginx/wordpress;(可不写) fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 如果location中不写root，$document_root就要写/data/nginx/wordpress$fastcgi_script_name; 3.启动服务 /usr/local/nginx/sbin/nginx 部署wordpress-5.0在两台nginxweb服务器上安装同样的wordpress和配置 1.创建存放wordpress目录 mkdir -pv /data/nginx/wordpress 2.解压并将全部文件拷贝到/data/nginx/wordpress下 tar xf wordpress-5.0-zh_CN.zip mv wordpress/* /data/nginx/wordpress/ 3.修改/data/nginx/wordpress的所有者和所属组 chown -R www.www /data/nginx/wordpress 4.准备连接数据库的文件 cp wp-config-sample.php wp-config.php vim wp-config.php /** WordPress数据库的名称 */ define(&apos;DB_NAME&apos;, &apos;wordpress&apos;); /** MySQL数据库用户名 */ define(&apos;DB_USER&apos;, &apos;wordpress&apos;); /** MySQL数据库密码 */ define(&apos;DB_PASSWORD&apos;, &apos;wordpress123&apos;); /** MySQL主机 */ define(&apos;DB_HOST&apos;, &apos;192.168.100.30:6033&apos;); 此处连接的mysql数据库主机是proxysql读写分离的IP和端口 通过NFS共享图片目录准备NFS主备后端存储： 1.这里nfs主备用mysql的两台从服务来实现 yum install nfs-utils -y 一定要安装nfs-utils，实际环境测试不安装utils，访问nfs的速度很慢 准备共享目录： mkdir -pv /nfsdata/images 设置权限nfs共享目录权限 vim /etc/exports /nfsdata/images *(rw,no_root_squash) 2.实现主备NFS的图片同步 rsync -avrlopg /nfsdata/images/* 192.168.100.17:/nfsdata/images/ 在nginx+pfp-fpm的两台服务器挂载nfs的共享目录 showmount -e 192.168.100.16 显示该主机上可以挂载的nfs目录 1.挂载目录并设置开机自动挂载 因为wordpress的图片是保存在/data/nginx/wordpress/wp-content/uploads中的 所以要把该目录用nfs共享 1.vim /etc/fstab 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads/ nfs defaults,_netdev 0 0 写在fstab文件中一定要加_netdev选项,刚开机没有IP地址时，即使挂载不上也可以启动 2.也可以写在/etc/rc.d/rc.local中，因为该文件是系统启动最后加载的文件，此时 已经获取到IP地址了，当然可以实现自动挂载,要设置执行权限 vim /etc/rc.d/rc.local mount -t nfs 192.168.100.16:/nfsdata/images /data/nginx/wordpress/wp-content/uploads chmod +x /etc/rc.d/rc.local 3.备注： NFS共享，为了避免IP地址的问题，最好要配置一个DNS服务器来主机名和IP地址 挂载的时候最好使用主机名取挂载，即使IP地址出问题了，也可以临时在DNS服务器上 修改主机名和IP地址的对应关系. 编译安装nginx实现负载均衡nginx调度服务器：192.168.100.10 1.解压并编译 tar xf nginx-1.12.2.tar.gz cd nginx-1.12.2 ./configure \ --prefix=/usr/local/nginx \ --with-pcre \ --with-http_stub_status_module \ --with-http_ssl_module make &amp; make install 2.修改配置文件实现七层调度 在http上下文定义： vim /usr/local/nginx/conf/nginx.conf upstream blogs { server 192.168.100.3:80 weight=1 max_fails=3 fail_timeout=100s; server 192.168.100.4:80 weight=1 max_fails=3 fail_timeout=100s; hash $remote_addr consistent; (做会话保持) } server { listen 80; server_name www.lkblog.net; index index.html index.php; location / { proxy_pass http://blogs; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; add_header X-Via $server_addr; proxy_next_upstream http_502 http_504 error timeout invalid_header; } } 3.启动服务 /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx -t /usr/local/nginx/sbin/nginx -s reload 配置完后重新加载 启动各服务，并测试读写-注册完后生成数据库各表-上传图片测试，在nfs也是可以看到的，说明挂载是成功的 -浏览站点，因为是普通的http请求，用轮询的方式是没问题的 -对于登录页面，如果没有做会话保持是登不上去的，这也是为什么Nginx负载均衡器上做源地址hash的原因. 升级wordpress版本版本更新需要注意最好不要跨大版本进行更新，一般更新也是在大版本下进行小版本的更新 以下以wordpress-5.0--&gt;wordpress-5.0.2 步骤： 1.停止Nginx服务 2.备份元数据或删除 3.升级版本 4.启动服务 简单的以脚本方式实现一台wordpress升级 vim updates.sh ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx -s stop&quot; ssh 192.168.100.4 &quot;rm -rf /data/nginx/wordpress/*&quot; scp wordpress-5.0.2-zh_CN.zip 192.168.100.4:/data ssh 192.168.100.4 &quot;unzip wordpress-5.0.2-zh_CN.zip -d /data/nginx/wordpress/&quot; ssh 192.168.100.4 &quot;chown -R www.www /data/nginx/wordpress/&quot; ssh 192.168.100.4 &quot;/usr/local/nginx/sbin/nginx&quot;]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现反向代理功能]]></title>
    <url>%2F2018%2F03%2F22%2Fnginx%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[Nginx实现反向代理服务器的配置 nginx实现反代的工作原理： 1.代理服务器需要注册监听端口，用来接收用户请求，而监听端口是可以被复用的，且一个端口可以接收N路请求. 2.代理服务器本地没有资源，当请求报文送达时，由于代理服务本身就是个web服务器，所以能够充分理解请求报 文的MIME类型，URL等，差别只是本来是需要通过IO加载本地资源的，但是由于本地没有，则会向后端服务器 去取资源，但是此时请求报文已经被完完整整的拆开了，是不能把请求报文发往后端的 3.所以在nginx中是由一个模块扮演成类似客户端浏览器角色的，把自己模拟成客户端程序，封装一个新的http请求， 向后端服务器发起请求. 4.而后端服务器会把响应报文发送给代理服务器，代理服务器则又会拆掉网络层封装，传输成封装，应用层封装， 看到响应报文的body主体部分，把主体部分拿出来重新封装成一个响应报文发回给客户端》 5.只要是向后端请求必然会再占用一个端口 6.代理服务器要维持两路连接，而且是彼此隔离且独立的 7.那么向后端发送的请求报文要不要带客户端请求中所独有的私有的信息数据？ 如果不传递，后端服务器是无法识别并相应的，必要时要把客户端的属性信息:请求 的url,用户认证信息等等重新封装到向后端发送的请求报文中，还是引用了客户端 发来的数据，而且代理服务器是可以修改请求报文的信息和响应报文中的信息 8.代理服务器可以操纵发往后端的请求和操纵响应给客户端的请求 9.这些也只有工作在应用层并且能识别应用层协议才可以实现的，如果再加一些访问控制 的功能，那么就可以做到四层防火墙做不到的访问控制能力，这也是代理服务器叫做 代理网关的原因，对于iptables和LVS是做不到的 10.面向客户端工作http/https协议，面向后端工作http,tcp,fastCGI,memcache，uwsgi(python的web框架) 等协议，那么这个能模拟客户端的模块就需要是多种专用模块 1.nginx作为代理服务器来说，面向于客户端和服务端可以代理多种协议 代理服务器又叫代理网关，因为工作在应用层可以控制用户访问请求的资源，具有防护功能 面向客户端： 一般是http/https协议：通过http模块实现 mail:简单邮件传输协议等 stream:stream模块实现代理四层协议：tcp/udp (nginx从1.9版本后可以实现四层负载均衡的) 代理后端服务器： nginx内嵌了很多客户端模块来适配不同的后端协议： http协议的服务器：ngx_http_proxy_modules模块 fpm服务器：ngx_http_fastcgi_module模块 memche服务器： 代理后端http协议的模块：专门代理后端是http协议的服务器集群(httpd和nginx) 1.nginx作为代理服务器是，代理客户端和后端服务器，在数据报文是有两段的： 1.客户端—&gt;代理服务器 2.代理服务器作为客户端—&gt;后端的httpd/fpm/memche服务器 而且代理服务器可以把客户端发来的数据报文进行修改重新封装发给后端服务器， 后端服务器响应给代理服务器的报文也可以被代理服务器修改，再响应给客户端 在设置中，可以通过不能功能体现出数据报文被如何修改的！ 2.作为代理配置和nginx作为web服务器差不多，只不过要把root/alias缓存proxy_pass 如果同时又root和proxy_pass，proxy_pass的优先级高 3.在location中将.php或者.jpg代理到不同的后端服务器上，可以实现资源请求的动静分离 实现了在一台代理服务器上的资源路由. ngx_http_proxy_module模块：1.proxy_pass URL 代理http协议的主要功能，是将客户端的请求代理至后端服务的路径上 Context: location, if in location, limit_except； server { ... server_name HOSTNAME; location / { proxy http://hos[:port]; 优先级高于server的root } location /uri/ { proxy http://host/new_uri/; } location ~|~* /uri/ { proxy http://host; } ... } http://HOSTNAME/uri --&gt; http://host/uri http://HOSTNAME/uri/ --&gt; http://host/new_uri/ http://HOSTNAME/uri/ --&gt; http://host/uri/； 路径映射，前后端的location和proxy_pass是映射关系,必要加/ 如果location是正则表达式路径，proxy_pass的路径必须没有/和URI，因为是正则表达 式，无法判断路径 -前后端路径映射 2.proxy_set_header field value; 前面说过代理服务器可以修改客户端请求数据报文的信息发送给后端服务器，而对于后端 服务器来说看到的请求报文的源IP一直是代理服务器，但是可以通过修改参数是的后端 服务器看到的IP地址是真正的客户端地址而不是代理服务器！ 设定发往后端主机的请求报文的请求首部的值；Context:http,server,location 设置代理服务器： proxy_set_header X-Real-IP $remote_addr; 或者 proxy_set_header X-Real-HOST $host;将 或者 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 然后修改后端服务器的日志格式： LogFormat &quot;%{X-Real-IP}i %l %u %t \&quot;%r\&quot; %&gt;s %b&quot;重启httpd服务即可 此时，后端服务器看到的IP就是客户端的IP了，所以可以设置任何真实的信息传递给后端服务器 Nginx代理Web服务的Proxy缓存功能Nginx是一个高性能的web服务器，尤其在高并发和处理静态页面的时候有先天的优势；很大一部分得益于缓存的开启，缓存的实现逻辑 * 此处是作用于http的上下文，因为每个代理模块都有缓存功能，但是不能混用 * 要想使用proxy的缓存功能，必须先定义再引用 * 定义缓存所以列表：对文件进行hash生成hash串，hash串是16进制数字，如果把hash串的前三位数字，按照数字放在对应的层级生成一个三级索引列表 * 根据实际情况定义缓存层级，每多一次就是对磁盘IO的消耗，灵活定义缓存层级很有必要，比如一层以1个16进制数就是16个目录，2个16进制数就是2^8=256个目录，可以通过增加每次的级数，减小层数，对磁盘的IO消耗就降低了 nginx的缓存功能： 不一定启用nginx缓存，可以使用varnish,或者CDN 只有真正需要启用时，才会启用nginx缓存 3.proxy_cache_path nginx作为代理服务器是可以使用缓存功能的 定义缓存功能键也就是索引，是放在内存中的 定义可用于proxy功能的缓存；Context:http的上下文 proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 4.proxy_cache ksys_zone的name | off; 指明要调用的缓存，或关闭缓存机制；Context:http, server, location 5.proxy_cache_key string; 虽然定义了缓存，还需要定义键，而这个键就是用户访问的地址; 1.为了避免后端有两台server_name有一模一样的URI,造成缓存索引出错，这里引入 了更多的差别数据，把整个访问路径都引入进来进行hash值缓存. 2.然而把整个url都引入进来，也会有问题，比如一个server有两个主机名，路径本 来就应该是相同的，如果引入了全路径则造成缓存不能命中了 3.所以如何定义这个&quot;键&quot;是根据不同场景使用的 默认值：proxy_cache_key $scheme$proxy_host$request_uri; 有时也可以定义为：$request_uri 所以根据不同使用场景proxy_cache_key的值需要修改 6.proxy_cache_valid [code ...] time; 通过定义不同的响应码来定义不同的缓存时长；(也可以统一为一个值) 7.proxy_cache_use_stale 当后端服务器有问题时，是否能够用过期的缓存资源响应客户端请求，默认是关闭的 proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...; 8.proxy_cache_methods GET | HEAD | POST ...; 设置客户端通过什么方法查询时，才调用缓存功能 9.proxy_hide_header field; 隐藏发送给客户端的响应报文的信息；f12中的header中看到的 默认nginx在响应报文中不传递后端服务器的首部字段Date, Server, X-Pad, X-Accel-等，用于隐藏后端服务器特定的响应首部 代理服务器请求后端服务器的几个超时时长： 10.proxy_connect_timeout time; 定义代理服务器后端服务器发请求的三次握手的连接时长 默认为60s，最长75s,不需要调 11.proxy_read_timeout time; 从后端接收响应报文的超时时长 12.proxy_send_timeout time; 连接建立后，向后端发送请求报文的超时时长 示例： 先在http上下文中定义缓存； proxy_cache_path /data/cache/nginx levels=1:1:2；keys_zone webcache:10m max_size=2G; 再在server或者location中调用缓存和设置&quot;键&quot;以及过期时长； location ~* \.(jpg|gif|jpeg)$ { proxy_pass http://172.17.0.2; proxy_cache webcache; proxy_cache_key $request_uri;(这里根据不同场景定义) proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; proxy_cache_methods GET HEAD; proxy_cache_use_stale error timeout http_500 http_502 http_503; 这样就表示把缓存放在/data/cache/nginx中,最好是固态硬盘，磁盘IO越快，索引 查询的速度越快，定义了1:1:2三层路由索引，第一层16个目录，第二层16个子目录 第三次256个子目录 ngx_http_headers_module模块：操纵响应报文首部区别于proxy_set_header： 是代理服务器把客户端请求报文中的某些信息通过修改代理服务器请求报文首部的方式发送给后端服务器 headers： 代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值；达到隐藏 某些信息不发给客户端。 1.add_header name value [always]; 添加自定义首部； add_header X-Via $server_addr; 或者 add_header X-Accel $server_name; 发送给客户端的响应报文时，显示真正的后端服务器IP或者主机名 2.expires [modified] time; expires epoch | max | off; 响应缓存的缓存时长 用于定义Expire或Cache-Control首部的值； Nginx代理后端fastCGI协议 1.fpm其实就是一种类似于httpd的MPM模型中的prefork模型 启用一个fpm主进程，生成n个子进程，由子进程内部的php解释器负责处理并发的多路 请求，再将在本地运行完的php页面程序处理结果响应给请求的调用者 2.fastcgi其实就是简装版的http协议，后端对应的php的fpm就是fastcgi协议的服务器后端 的解析fastcgi协议，而且还能够让fpm的子进程加载磁盘上的php程序文件在php解释器 中运行执行出结果 3.Php并不支持编译成nginx的模块，那么Nginx只能调fastcgi模块与后端的fpm(php)服务器 进行通信，实现LNMP的架构 4.真正与mysql等数据库通信的是php程序代码，即php到mysql的驱动模块，而不是php解释器 5.如上图，因为fpm对进程的管理能力较弱，可以用nginx与全端调度器去连接，而且nginx可 以根据fastcgi处理请求的并发数，在nginx处限制向后端的请求连接数，nginx可以实现 中间件进行流量控制的效果. 6.php管理自己子进程的方式有两种，static和dynamic动态和静态管理方式 7.实现fpm的负载均衡调度，也是需要 ngx_http_fastcgi_module模块：1.fastcgi_pass address; address为fastcgi server的地址； location, if in location； 如：fastcgi_pass localhost:9000; http://www.ilinux.io/admin/index.php --&gt; /admin/index.php (uri) /data/application/admin/index.php 2.fastcgi_index name; fastcgi默认的主页资源; web的是index.html,php应该为index.php 如：fastcgi_index index.php 3.fastcgi_param parameter value [if_not_empty]; 1.由于动态站点在处理请求时，需要取得客户端在连接请求报文中的很多信息(IP,请求 方法,flag,param等)，所以nginx代理必须把保存在变量中与客户端连接状态的 数据，原样的传递给后端的fpm-server或fastcgi. 2.但是保存在nginx的变量名格式和fastcgi的变量名表示格式是不一样的，nginx的 是$+全小写的变量名，fpm是全大写的变量名 3.安装nginx默认就带有/etc/nginx/fastcgi_params,这个文件记录了需要向后端 fpm传递的所有变量. 4.除了传递变量，还需要将请求的uri与后端fpm服务器的路径建立映射关系，即定义 fpm上存放请求页面资源的真正路径. 配置示例： 比如先起一个fpm的容器：并且将动态资源保存在php容器的/data目录下 docker run --name php1 -d -v /data/php1:/data php:7-fpm-alpine 在nginx代理上如下设置： location ~* \.php$ { fastcgi_pass 172.17.0.4:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; include fastcgi_params; } fpm的状态监控4.php的状态监控 1.fpm的进程有static和dynamic两种管理方式，而且为了监控fpm是否正常工作，fpm的 配置文件中内嵌了/pm_status和/ping两个url来监控，status用来输出内嵌信息的 ，而默认是通过fastcgi协议显示的，不能直接看到状态信息，所以可以通过http协 议进行反代来检测fpm的工作状态. 2.可以通过显示监控状态的值，再通过ab,JMeter等工具进行压力测试，调整fpm的实际 场景下的并发访问量 配置示例：通过/pm_status和/ping来获取fpm server状态信息； location ~* ^/(status|ping)$ { fastcgi_pass 172.17.0.2:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; include fastcgi_params; } 测试： 如下图可以通过http://192.168.34.107:8082/status?xml&amp;full 或者html、json格式输出并显示出来，而且还可以通过接口调用加入到zabbix监控中 fastcgi的压力测试和缓存功能a.fastcgi的动态资源缓存意义更大，因为php不用每次都执行代码了 b.要使用缓存就需要先定义缓存； c.因为后端动态资源服务器是有用户认证和用户支付的资源的，为了信息安全对动态资源的缓 存一定不要缓存包含用户信息的资源 定义缓存：和proxy的缓存是不能兼容的，需要单独定义(在server外,http的上下文定义) 4.fastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义； levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE leves=1:2:2 keys_zone=name:size k/v映射的内存空间的名称及大小 inactive=time 非活动时长 max_size=size 磁盘上用于缓存数据的缓存空间上限 调用缓存： 5.fastcgi_cache keys_zone的名称 | off; 调用指定的缓存空间来缓存数据；http, server, location 无定义默认使用的键，需要手动指定 6.fastcgi_cache_key string; 定义用作缓存项的key的字符串； 7.fastcgi_cache_methods GET | HEAD | POST ...; 为哪些请求方法使用缓存； 8.fastcgi_cache_min_uses number; 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； 9.fastcgi_cache_valid [code ...] time; 不同的响应码各自的缓存时长； 10.fastcgi_keep_conn on | off; 默认情况下，fastCGI响应一个请求后会立刻断开，如果是on状态会保持长连接 fastcgi缓存定义示例： http { fastcgi_cache_path /data/cache/fcgi levels=1:2 keys_zone=fcgicache:10m max_size=2G; server { ... location ~* \.php$ { fastcgi_pass 172.17.0.4:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; include fastcgi_params; fastcgi_cache fcgicache; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 301 1h; fastcgi_cache_valid any 1m; fastcgi_cache_methods GET HEAD; } 缓存性能测试： ab -n 1000 -c 50 http://192.168.34.107:8082/index.php 在缓存前和缓存后通过模拟50路并发请求测试响应时间]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现web服务配置]]></title>
    <url>%2F2018%2F03%2F20%2Fnginx%E5%AE%9E%E7%8E%B0web%E6%9C%8D%E5%8A%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[nginx安装和配置文件Nginx下载安装和模块使用说明手册 nginx安装： 源码编译,二进制安装，yum安装，要注意使用次版本为偶数的版本 nginx所说的高度模块化是指静态模块，如果编译安装了很多模块，启动时不管在配 置文件是否使用该模块，默认都是加载的，不过在Nginx的新版本中少量的动态模块 是可以按需加载的 而httpd是可以通过modprobe安装加载模块的 配置文件的组成部分： 主配置文件： /etc/nginx/nginx.conf 还包括 conf.d/*.conf和default.d/*.conf 对于同以功能的配置最好放到一个*.conf中，方便管理 /usr/lib/systemd/system/nginx.service Unit file文件 /usr/sbin/nginx 主程序文件 /usr/share/nginx/html/404.html /usr/share/nginx/html/50x.html /usr/share/nginx/html/index.html 页面文件 fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 启动和配置： yum install nginx -y （编译时按需加载模块即可） systemctl start nginx / nginx 备注： 在生产环境下只要是修改nginx相关的配置文件,一定要nginx -t先进行测试 再nginx -s reload使配置文件生效 配置： 主配置文件的配置指令： 指定生效的范围，三个上下文中 directive value [value2 ...]; 注意： (1) 指令必须以分号结尾； (2) 支持使用配置变量； 内建变量：由Nginx模块引入，可直接引用； 自定义变量：由用户使用set命令定义； set variable_name value; 引用变量：$variable_name 主配置文件结构： main block：主配置段，也即全局配置段；都是顶格写的 event { ... }：事件驱动相关的配置； http { server {} root proxy_pass server {} ... }：http/https 协议相关的配置段； mail { ... } stream { ... } 主配置段都不管是web服务、mail服务还是四层代理是都需要配置的，而且这三个功能一般是 不会一起使用的，至少http和mail功能是不一起使用的 Nginx的全局配置和优化必调参数项配置指令： main配置段常见的配置指令：全局配置 分类： 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置： 1、user，group,是默认运行nginx的用户和组，按需修改 2、pid /PATH/TO/PID_FILE; 指定存储nginx主进程进程号码的文件路径； 3、include file | mask; 指明包含进来的其它配置文件片断； 4、load_module file; 指明要装载的动态模块； 性能优化相关的配置： 1、worker_processes number | auto; worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数； auto：当前主机物理CPU核心数； 2、worker_cpu_affinity cpumask ...; worker_cpu_affinity auto [cpumask]; nginx进程的CPU亲缘性解释； 1.因为CPU有三级缓存，一级和二级是每个CPU所独有的，只有三级缓存是共享的； 2.将worker进程与cpu绑定，这个进程会在cpu本地缓存很多数据和状态信息 3.如果把这个进程调到其他cpu上，那么之前的缓存就失效了，从而影响了性能，而cpu的绑定则起到刚好的负载效果和性能 CPU MASK： 00000000： 0000 0001：0号CPU 0000 0010：1号CPU 0000 0100：2号CPU 0000 1000：3号CPU ... ... 0000 0111：表示0和1号和2号CPU； 3、worker_priority number; 指定worker进程的nice值，设定worker进程优先级；[-20,19] 4、worker_rlimit_nofile number; worker进程所能够打开的文件数量上限； 对于高并发的服务器来说至关重要，每一个连接都需要打开一个套接字，每一个套接 字的维持都需要一个文件描述符，默认情况下linux限制每个用户最多同时打开1024 个文件，所以并发数量很高时，并发数量受限于文件数量，因此对于高并发服务器来 说都需要修改ulimit数量(ulmit -a/-n number) 事件驱动相关的配置: events { ... } 1.worker_connections number; 事件驱动决定了单个worker进程所能够打开的最大并发连接数数量； 所以nginx最大并发连接上限= [worker_processes] * [worker_connections] 在要求高并发的服务器上这两个是必调参数 2.use method; 指明并发连接请求的处理方法； use epoll；是事件驱动模型得以运行的根本 3.accept_mutex on | off;是否打开mutex互斥锁 处理新的连接请求的方法； on意味着由各worker轮流处理新请求，默认为on Off意味着每个新请求的到达都会通知所有的worker进程；会造成进程抢夺请求的情况 调试、定位问题： 1、daemon on|off; 是否以守护进程方式运行Nignx；默认为on 2、master_process on|off; 是否以master/worker模型运行nginx；默认为on； 调试时，把只有主进程处理请求和以前台运行来查找错误原因 3、error_log file [level]; 默认级别 Nginx实现web服务的全局配置和主要模块1.Nginx无论是作为web服务器或者是web服务器的代理服务器，所有配置都在http的上下文 2.location和directory的区别 1.httpd和nginx作为web服务器都可以对用户访问的资源进行限制 2.&lt;Directory &quot;/var/www/html/images/&quot;&gt; 也可以写成 &lt;Location &quot;/images/&quot;&gt; http协议的全局配置匹配检查顺序：server_name和Port–&gt;location–&gt;if in location–&gt;匹配路径(root和alias) ngx_http_core_module:Nginx的核心模块Nginx不管作为什么功能，都要使用core核心模块 http协议上下文的相关配置： http { ... ... 是http的全局配置，共享给多个server使用 server { ... listen server_name root/proxy_pass (root是作为web服务器的，proxy_pass是作为代理服务器使用的) location [OPERATOR] /uri/ (类似于httpd的directory） ... } } server { ... } } 与套接字相关的配置： 1、server { ... } 配置一个虚拟主机； server { listen address[:PORT]|PORT; server_name SERVER_NAME; root /PATH/TO/DOCUMENT_ROOT; } server只能出现在http的上下文中，而且不能嵌套server 2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] 特殊设置：前两个尤为重要 default_server：设定为默认虚拟主机； 如httpd基于主机名配置的多个虚拟主机，访问时是由上而下匹配的 ssl：强制只能通过ssl连接提供服务； backlog=number：后援队列长度； rcvbuf=size：接收缓冲区大小； sndbuf=size：发送缓冲区大小；(默认值足以满足需求) 3、server_name name ...; 必然要使用通配符来设置虚拟主机名和设置优先级 1.支持*通配任意长度的任意字符；server_name *.baidu.com www.baidu.* 2.支持~起始的字符做正则表达式模式匹配；server_name ~^www\d+\.baidu\.com$ (\d匹配单个数字) 匹配机制优先级： (1) 首先是字符串精确匹配; (2) 左侧*通配符； (3) 右侧*通配符； (4) 正则表达式； (并发访问多时，不建议使用正则表达式匹配主机名，对服务器性能有很大消耗) 4、tcp_nodelay on | off; 在keepalived模式下的连接是否启用TCP_NODELAY选项 当为off时，延迟发送，合并多个请求后再发送 默认On时，不延迟发送 可用于：http, server, location 5.tcp_nopush on|off; 在sendfile模式下，是否启用TCP_CORK选项； 5.sendfile on | off; 是否启用sendfile功能； 和定义路径相关的配置： 6.root path; 设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径； root可以作用在http, server, location, if in location上下文中， 如果多有多层级的root，则精确到最内层的root生效 7.location [ = | ^~ | ~ | ~* ] uri { ... } 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置； 用户请求server_name--&gt;server--&gt;Location--&gt;if in Location 会根据正则表达式匹配的优先级匹配到一个最佳的路径 修饰符号： 修饰符匹配优先级：=, ^~, ~/~*，不带符号； 1.=：对URI做精确匹配； 2.^~：对URI的左半部分做匹配检查，不区分字符大小写； 左半部分是指scheme中不包含path和它之后的部分 如https://www.lk.tech/images/1.jpg的左半部分是https://www.lk.tech 3.~：对URI做正则表达式模式匹配，区分字符大小写； 4.~*：对URI做正则表达式模式匹配，不区分字符大小写； 5.不带符号：以URI为前缀的所有uri；通配性最高级location / 还可以在location中定义if这种三级路由选择 root /vhosts/www/htdocs/ http://www.lk.tech/index.html --&gt; /vhosts/www/htdocs/index.html server { root /vhosts/www/htdocs/ location /admin/ { root /webapps/app1/data/ } } –官方示例 8.alias path; 定义路径别名，文档映射的另一种机制；仅能用于location上下文； 注意：location中使用root指令和alias指令的意义不同； (a) root，给定的路径对应于location中的/uri/左侧的/； (b) alias，给定的路径对应于location中的/uri/右侧的/； 如： location /images/ alias &quot;/data/www/&quot;; alias定义的意思是即 /images/* = /data/www/* location /images/ { alias &quot;/data/www/&quot;; root定义的意思就是访问 /data/www/images/* 9、设置默认主页：index file ...; 默认资源；http, server, location； 10、error_page code ... [=[response]] uri; 例如：error_page 404 /404.html; location = /404.html { root &quot;/www/error_pages&quot;; } 11、try_files file ... uri; 定义客户端请求的相关配置 定义客户端请求的相关配置 12、keepalive_timeout timeout [header_timeout]; 设定保持连接的超时时长，0表示禁止长连接；默认为75s； 13、keepalive_requests number; 在一次长连接上所允许请求的资源的最大数量，默认为100; 14、keepalive_disable none | browser ...; 对哪种浏览器禁用长连接； 15、send_timeout time; 向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长； 16、client_body_buffer_size size; 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置； 17、client_body_temp_path path [level1 [level2 [level3]]]; 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量； 16进制的数字； client_body_temp_path /var/tmp/client_body 1 2 2 1：表示用一位16进制数字表示一级子目录；0-f 2：表示用2位16进程数字表示二级子目录：00-ff 2：表示用2位16进程数字表示三级子目录：00-ff 对客户端进行限制的相关配置： 18、limit_rate rate; 限制响应给客户端的传输速率，单位是bytes/second，0表示无限制； 19、limit_except method ... { ... } 限制对指定的请求方法之外的其它方法的使用客户端； limit_except GET { allow 192.168.1.0/24; deny all; } 文件操作优化的配置 访问控制和认证的两个模块ngx_http_access_module模块：实现基于ip的访问控制功能，比httpd的控制更简单 1.allow address | CIDR | unix: | all; 2.deny address | CIDR | unix: | all; http, server, location, limit_except ngx_http_auth_basic_module模块 实现基于用户的访问控制，使用basic机制进行用户认证； 1.auth_basic string | off; 2.auth_basic_user_file file; 需要先生成账号密码，而且htpasswd命令由httpd-tools所提供； htpasswd -c -m /data/.nginxpasswd tom htpasswd -b -m /data/.nginxpasswd haha haha123 如： location /admin/ { auth_basic &quot;需要提供用户密码&quot;;(提示信息) auth_basic_user_file /etc/nginx/.ngxpasswd; } ngx_http_stub_status_module模块：状态监控一般和监控系统一起用，可以在编译安装nginx时加上这个选项 可以通过脚本函数监控这七个数值，纳入到zabbix中进行图形化监控 为了不影响其他location，一般定义专用的location来监控nginx状态，放在server内即可 用于输出nginx的基本状态信息； Active connections: 291 当前的活动连接 server accepts handled requests 连接数，接收并处理的，， 16630948 16630948 31070465 Reading: 6 Writing: 179 Waiting: 106 中间三个是统计数据，其他四个是当前数据； Active connections: 正在处理活动状态的连接数； accepts：已经接受的客户端请求的总数；(tcp建立的连接数) handled：已经处理完成的客户端请求的总数；(客户端发送，nginx处理过的) requests：客户端发来的总的请求数；(建立tcp连接并发送的请求数) Reading：处于读取客户端请求报文首部的连接的连接数；(接收报文) Writing：处于向客户端发送响应报文过程中的连接数；(nginx发送报文) Waiting：处于等待客户端发出请求的空闲连接数； (已经读取未发送的) 用于监控nginx的连接数脚本 1.stub_status; 配置示例： location = /status { stub_status; } ngx_http_log_module模块：日志分析展示nginx官方日志变量说明 1.log_format name string ...; string可以使用nginx核心模块及其它模块内嵌的变量； 日志格式： $remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos; http_x_forward_for 表示被代理服务器的日志记录的访问的IP地址是代理服务器，为了在后端服务器上记录真实的客户端，需要启用这一项 实现：1.为nginx定义使用类似于httpd的combined格式的访问日志； 2.把combined的日志格式定义输出成json格式(KV键值对) 2.access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 访问日志文件路径，格式及相关的缓冲的配置； buffer=size flush=time 3.open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 缓存各日志文件相关的元数据信息； max：缓存的最大文件描述符数量； min_uses：在inactive指定的时长内访问次数低于min_uses就认为是无效的； inactive：非活动时长； valid：验正缓存中各缓存项是否为活动项的时间间隔；检查inactive的间隔 ngx_http_gzip_module：文本资源压缩传输节约带宽在CPU等硬件资源不稀缺的情况下，带宽流量的稀缺使得资源压缩必须启用 启用资源压缩功能，虽然可以大大减小了带宽的消耗，要注意适用的场景； 1.比如当前服务器CPU负载较大，压缩功能本身就会消耗更多的CPU资源，如果启用 对服务器的压力就会更大 2.应该只对文本内容进行压缩，视频、图片、流媒体等本身就已经是有压缩比的资源 3.实现逻辑：先使用压缩过滤器过滤出来有很好压缩比的资源(css,js,html)等文本 再定义压缩规则 1.gzip on | off; 需要先开启gzip压缩功能 2.gzip_comp_level level; 设置压缩比1~9,压缩比越大对CPU的消耗越大 3.gzip_disable regex ...; 过滤User_Agent浏览器类型，禁用较老的浏览器版本不启用压缩功能。 4.gzip_min_length length; 当响应报文大小达到某个值，才压缩，太小就不值得压缩了 比如：低于100k不压缩，高于这个值才进行资源压缩，单位:byte字节 5.gzip_buffers number size; 支持实现压缩功能时为其配置的缓冲区数量(number)及每个缓存区的大小(size)； 在服务器的内存资源充沛时，启用缓冲区可以更快的对资源进行压缩 6、gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...; nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的； off：对代理的请求不启用 no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能； any:任何内容不压缩 7.gzip_types mime-type ...; 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能； 过滤需要压缩的类型，纯文本和html不需要，因为默认就对其压缩 示例： gzip on; gzip_comp_level 6; gzip_min_length 64; gzip_proxied any; gzip_types text/xml text/css application/javascript; ngx_http_ssl_module模块：如上图，代理服务用nginx不采用LVS的一个原因就是LVS不支持SSL的代理，nginx可以实现 面对客户端使用https协议，面对后端服务器集群使用http协议，所以有时nginx反代也叫https的会话卸载器 如果是四层调度，https访问必须是客户端与后端服务器之间建立； 如果两段式连接，对内调度是明文的，把压力放在前端代理服务器上，本身前端调度器 岁CPU资源消耗不是很大 1.ssl on | off; Enables the HTTPS protocol for the given virtual server. 2.ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件； 3.ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件； 4.ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2]; 支持ssl协议版本，默认为后三个； 5.ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; nginx的ssl会话有两种： 1.builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有； 2.[shared:name:size]：在各worker之间使用一个共享的缓存； ssl的session建立是很慢的,所以要启用ssl的缓存，而且还是shared类型的共享缓存方式 6、ssl_session_timeout time; 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长； 实现https加密： 生成私钥和证书： openssl genrsa -out nginx.key 2048 openssl req -new -x509 -key nginx.key -out nginx.crt -days 3650 -subj &quot;/CN=www.lk.tech&quot; 配置https主体： server { listen 443 ssl; server_name www.lk.tech; root /data/lk; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; ssl_session_timeout 10m; } ngx_http_rewrite_module模块：实现URL重写 什么是url重写？为什么要用到url重写？ 1.客户端访问URL被重写到另外一个路径了 http://www.lk.tech/photos/1.jpg ---&gt; http://images.lk.tech/1.jpg 2.全站ssl加密时，将用户访问的http://请求全部被重写到https://的虚拟主机上 http://www.lk.tech/images/1.jpg---&gt;https://www.lk.tech/1.jpg rewirte的处理逻辑： 1.将用户请求的URL基于(regex)正则表达式的查找，而后完成替换即可(replacement) 2.如果出现server中两个location互相rewrite，则会出现死循环的现象，所以就引入 了last和break的两个机制 3.last表示接着检查其他rewrite，break表示匹配到当前的rewrite.就不检查其他的 rewrite了这样就避免了死循环。 1.rewrite regex replacement [flag] a.将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement 指定的新的URI； b.rewrite重写的路径可以是相对路径也可以是绝对路径 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制； 如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端 ；用的比较多的是301和302 301：permanent,永久重定向； 302：redirect,临时重定向； [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环； break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环； redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；302 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；301 2.return：类似于重定向的操作 return code [text]; return code URL; return URL; Stops processing and returns the specified code to a client. 3.rewrite_log on | off; 是否开启重写日志；可能出现安全风险，所以没有必要时不用开启 4.if (condition) { ... } 引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令； 一般用于server, location； condition： 比较操作符： == != ~：模式匹配，区分字符大小写； ~*：模式匹配，不区分字符大小写； !~：模式不匹配，区分字符大小写； !~*：模式不匹配，不区分字符大小写； 文件及目录存在性判断： -e, !-e -f, !-f -d, !-d -x, !-x 5.set $variable value; 用户自定义变量； 示例： location ~* ^/(photos|pictures) { ## rewrite ^/photos/(.*)$ /image/$1 last; # rewrite ^/photos/(.*)$ http://images.lk.tech:8081/$1; # rewrite ^/(photos|pictures)/(.*)$ http://images.lk.tech:8081/$2 permanent; # } -redirect和permanent的示例演示 ngx_http_referer_module模块：网站防盗链检查客户端的请求数据报文首部，实际就是防盗链的过滤器，所以在日志中记录referer referer来源： 1. 2. 1.valid_referers none | blocked | server_names | string ...; 定义referer首部的合法有效的值 none：请求报文首部没有referer首部； blocked：请求报文的referer首部没有值； server_names：参数，其可以有值作为主机名或主机名模式； arbitrary_string：直接字符串，但可使用*作通配符； regular expression：被指定的正则表达式模式匹配到的字符串； 要使用~打头，例如 ~.*\.lk.com； 使用说明和示例： 先定义valid_referers的允许连接网站，再通过if判断如果不是在 valid_referers中定义的网站，就返回一张图片或者文字说明 valid_referers none block server_names *.lk.com lk.* ~\.lk\.; if ($invalid_referer) { return http://www.lk.tech/hello.html; }]]></content>
      <categories>
        <category>web服务</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible]]></title>
    <url>%2F2018%2F03%2F06%2Fansible%2F</url>
    <content type="text"><![CDATA[运维自动化管理工具之Ansible 内容：1.软件发布环境机制优势对比 和 2.ansible的应用ansible的相关的文档ansible的中文权威指南：ansible中文指南Github上的ansible-galaxy示例：ansible-galaxy 其他相关运维管理工具使用方法：pssh的使用方法参照链接文章：psshsaltstack介绍及使用参照链接文章：saltstackpuppet介绍及使用参照链接文章：puppet 当下有许多的运维自动化工具( 配置管理 )，例如：Ansible、SaltStack、Puppet、Fabric 常用自动化运维工具 PSSH：适用于主机数量很少的环境(基础ssh的key验证) Ansible:python,Agentless,中小型应用环境(自带代理功能) Saltstack:python，一般需部署agent，执行效率更高 Puppet:ruby, 功能强大,配置复杂，重型,适合大型环境 Fabric：python，agentless Chef: ruby,国内应用少 Cfengine func 发布更新环境灰度发布：又叫金丝雀发布(核心概念：一次只发布一部分主机)比如：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器 而软件更新实际上是将旧版本或者新版本创建一个软链接指向软件的工具路径 如： 软件路径为:/data/app 正在用的软件版本V1.0：/data/app1.0 更新的软件版本V2.0：/data/app2.0 则需要把删除原来的软链接：/data/app1.0---&gt;/data/app 创建新的软链接：/data/app2.0---&gt;/data/app 10台机器升级软件版本后，先上线进行，然后再逐渐把剩余的90台主机升级上线 发布步骤： 1.准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。 2.从负载均衡列表中移除掉「金丝雀」服务器。 3.升级「金丝雀」应用（排掉原有流量并进行部署）。 4.对应用进行自动化测试。 5.将「金丝雀」服务器重新添加到负载均衡列表中（连通性和健康检查）。 6.如果「金丝雀」在线使用测试成功，升级剩余的其他服务器（否则就回滚）。 A/B Testing A/B测试是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等等。 A/B 测试通常用在应用的前端上，不过当然需要后端来支持。 优势与不足： 优势：用户体验影响小，灰度发布过程出现问题只影响少量用户 不足：发布自动化程度不够，发布期间可引发服务中断 预发布验证： 新版本的代码先发布到服务器,和线上环境配置相同，只是未接入调度器 灰度发布： 可以基于主机，用户或者业务，又细分为地区，VIP和普通用户 蓝绿发布：核心：主备两套环境定义：不停老版本，升级备环境版本然后进行测试。确认OK后将流量切到新版本，然后老版本同 时也升级到新版本 主：绿色环境-活动环境：负责对外提供服务，版本：v1.0 备：绿色环境-非活动环境：版本：v2.0 工作机制： 先把备环境升级v1.0---&gt;v2.0版本，然后上线 把主环境的v1.0版本下线，已经升级的备环境进行替换 特点： 蓝绿部署无需停机，并且风险较小. 注意事项： 1.需要提前考虑数据库与应用部署同步迁移/回滚的问题 2.蓝绿部署需要有基础设施支持 3.在非隔离基础架构（ VM 、 Docker 等）上执行蓝绿部署，蓝色环境 和绿色环境有被摧毁的风险. 优势与不足： 优势：升级切换和回退速度非常快 不足：需要有2套基础设施,v2.0版本有问题，则对用户体验有直接影响 滚动发布：在灰度发布的基础上进行进一步优化定义： 一般是取出一个或者多个服务器停止服务，执行更新，并重新将其投入使用。周而复始，直到集群中所有的实例都更新成新版本，是自动化程度较高的发布方式. 特点： 1.这种部署方式相对于蓝绿部署，更加节约资源——它不需要运行两个集群、两倍的实例数. 可以部分部署，例如每次只取出集群的20%进行升级。 2.滚动式发布需要比较复杂的发布工具和智能LB,支持平滑的版本替换和流量拉入拉出 优势和不足: 优势：用户体验影响小，体验较平滑 不足：发布和回退时间比较缓慢。 发布工具比较复杂，LB需要平滑的流量摘除和拉入能力 滚动发布目前成熟型技术组织所采用的主流发布方式 Ansible ansible特性：-最多管理500台主机，更多效率会降低1.模块化：调用特定的模块，完成特定任务 -类似linux中的小命令 2.有Paramiko，PyYAML，Jinja2（模板语言）三个关键模块 3.支持自定义模块 4.基于Python语言实现 5.部署简单，基于python和SSH(默认已安装)，agentless(没有自己的代理服务) 6.安全，基于OpenSSH 7.支持playbook编排任务 -类似于脚本功能，多个脚本的集合成为Roles 8.幂等性： 一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 9.无需代理不依赖PKI（无需ssl） 10.可使用任何编程语言写模块 11.YAML格式，编排任务，支持丰富的数据结构 12.较强大的多层解决方案 Ansible的学习过程：1.ansible基本命令使用 2.ansible常用模块详解，介绍ansible单个命令的使用 3.YAML语法介绍 4.ansible playbook基础：剧本初体验，类似于写脚本 5.playbook中的变量：tags，handlers使用 6.plsybook模板：templates 7.playbook的条件判断：when 8.playbook的字典：with_items 9.Ansible Roles -多个playbook的组合，类似于多个脚本的集合 会在playbook的同目录下生成一个*.retry的文件记录会记录执行时的错误IP地址。 ansible命令执行过程ansible命令执行过程 1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg 2. 加载自己对应的模块文件，如command 3. 通过ansible将模块或命令生成对应的临时py文件，并将该 文件传输至远程 服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 4. 给文件+x执行 5. 执行并返回结果 6. 删除临时py文件，sleep 0退出 执行状态：(颜色定义在/etc/ansible/ansible.cfg中) 绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 CMDB作用介绍:CMDB:Configuration Management Database 配置管理数据库 将服务器的配置，网络配置写到数据库里 CMDB即配置管理数据库，通过识别、控制、维护，检查企业的IT资源，从而高效控制与管理不 断变化的IT基础架构与IT服务，并为其它流程，例如事故管理、问题管理、变更管理、发布管 理等流程提供准确的配置信息. 了解更多CMDB可参照文章：CMDB 1.ansible基本命令使用ansible软件安装：多种安装方法1.基于epel源安装： yum install ansible,非服务，只是一个管理工具 2.编译安装： 3.Github方式安装：可以同步安装 4.pip安装：pip是安装Python包的管理器，类似yum ansible的重要&amp;主要文件配置文件： /etc/ansible/ansible.cfg 配置ansible的工作特性 /etc/ansible/hosts 主机清单 /etc/ansible/roles 存放的角色目录 程序文件： /usr/bin/ansible ansible的可执行命令--&gt;2.7的软链接，都是软链接的思想 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具，man帮助 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-playbook 管理执行编排的playbook剧本任务 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 常用命令： ansible all --list 查看ansible管理的主机群 ansible all -m &quot;模块名&quot; -a &apos;执行的命令&apos; 用什么模块执行什么命令 all也可以换成定义的--list中组的名字 ansible-playbook -C &apos;*.yml&apos; 对所有主机执行剧本 ansible-plsybook -C -t &apos;标签&apos; &apos;*.yml&apos; 对所有主机执行哪个标签的剧本 ansible主机清单配置：/etc/ansible/hosts,第一步(下文中介绍主机清单的多种表示方法)支持不分组，分组，等方式 如： 192.168.34.100 [webservers] 192.168.34.101 192.168.34.102 [dbservers] 192.168.34.[1:6]7 (17,27..67) db[01:100].cenntos.com ansible配置文件：/etc/ansible/ansible.cfg （一般保持默认）配置文件只提供默认值，但可以通过playbook的设置进行覆盖 配置文件可以放在/etc/ansible/ansible.cfg中 也可以放到一个工作目录下命名为.ansible.cfg [defaults] inventory = /etc/ansible/hosts - 主机列表配置文件 library = /usr/share/my_modules/ - 库文件存放目录 remote_tmp = $HOME/.ansible/tmp -临时py命令文件存放在远程主机目录 local_tmp = $HOME/.ansible/tmp - 本机的临时命令执行目录 forks = 5 - 默认并发数 sudo_user = root - 默认sudo 用户 ask_sudo_pass = True -每次执行ansible命令是否询问ssh密码 ask_pass = True remote_port = 22 host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 [color] 定义ansible命令的执行结果颜色的 配置文件说明和建议修改的项：local_tmp和remote_tmp： 本地临时文件和远程临时文件：把playbook转化成python程序，先放在本地 家目录的.ansible/tmp下，然后再通过ssh协议复制到远程主机的.ansible/tmp下，执行完毕后自动删除. host_key_checking = False -检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log -建议启用日志文件，利于排错 module_name = command -默认使用的命令模块，可以修改成shell module_name = shell 2.ansible常用模块详解，介绍ansible单个命令的使用ansible模块的使用查询方法ansible-doc: 显示模块帮助 ansible-doc [options] [module...] -a 显示所有模块的文档 -l, --list 列出可用模块 -s, --snippet显示指定模块的playbook片段 示例： ansible-doc –l 列出所有功能模块 ansible-doc ping 查看ansible中的ping用法 ansible-doc -s shell 查看shell模块的使用方法 ansible的常用基本选项ansible通过ssh实现配置管理、应用部署、任务执行等功能，建议配置ansible 端能基于密钥认证的方式联系各被管理节点 ansible语法： ansible &lt;host-pattern&gt; [-m module_name] [-a args] --version 显示版本 -m module 指定模块，默认为command，主要使用选项 -v 详细过程 –vv -vvv更详细 --list-hosts 显示主机列表，可简写 --list -k, --ask-pass 提示输入ssh连接密码，默认Key验证 -K, --ask-become-pass 提示输入sudo时的口令 -C, --check 检查，并不执行 -T, --timeout=TIMEOUT 执行命令的超时时间，默认10s -u, --user=REMOTE_USER 执行远程执行的用户 -b, --become 代替旧版的sudo 切换 ansible的主机清单表示方法:Host-pattern1.All ：表示所有Inventory中的所有主机 如：ansible all -m ping ansible all --list-hosts列出所有主机清单 ansible &quot;dbservers&quot; --list-hosts列出db组中的所有主机IP 2.* :通配符 如：ansible &quot;*&quot; = ansible all ansible 192.168.34.* 表示34网段的所有IP 3.或的关系 如：ansible &quot;websrvs:appsrvs&quot; 对两个组的主机执行操作 ansible &quot;192.168.1.10:192.168.1.20&quot;对两个主机执行操作 4.与的关系(且) 如：ansible &quot;websrvs:&amp;dbsrvs&quot;既在websrvs组并且在dbsrvs组中的主机 5.非，取反 如：ansible &apos;websrvs:!dbsrvs&apos; 在websrvs组，但不在dbsrvs组中的主机;注意：此处为单引号 6.正则表达式 如：ansible &quot;~(web|db).*\.centos\.com&quot; ansible的常见模块(第二步：具有很多模块，先列出比较常见且重要的，遇到再更新新的模块)ansible-doc +模块名 可以查看具体使用方法：显示都有哪些选项1.Command：在远程主机执行命令，默认模块，可忽略-m选项 可以在ansible.cfg中修改默认模块项 支持：chdir(切换目录) command模块不支持 $ &lt; &gt; | ; &amp; 等，可以用shell模块实现 使用示例： ansible all -a &apos;rm -f /data/f1&apos; 删除远程所有主机下f1文件，类似pssh ansible all -a &apos;useradd test&apos; 所有主机上创建test用户 2.Shell：和command相似，用shell执行命令，执行时要加-m shell选项 支持功能：支持$ &lt; &gt; | ; &amp; 等 chdir 执行前，先切换到该文件夹 示例:ansible appsrvs -m shell -a &apos;echo $HOSTNAME&apos; 显示appsrvs组的主机名 ansible all -m shell -a &apos;chdir=/data rm -rf *&apos; 先切换到/data目录下，再执行删除命令 3.Script: 批量运行脚本 可以现在管理机上先把复杂命令写成脚本，再通过script去批量管理 功能：creates:远程主机的文件存在，则不运行 removes:远程主机的文件不存在，则也不运行==即文件存在，则执行命令 示例：ansible all -m script -a &quot;/data/test.sh&quot; ansible all -a &quot;creats=/etc/fstab rm -rf /data/*命令&quot; 因为fstab文件存在，则不执行rm -rf /data/*命令 ansible all -a &quot;removes=/etc/fstab rm -rf /data/*&quot; 因为fstab文件存在，则执行rm -rf /data/*命令 4.Copy:从服务器复制文件到目标主机 src,dest,mode,owner,content,backup,mode 示例：1.nsible all -m copy -a &apos;src=/etc/fstab dest=/data/fstab2 backup=yes owner=test&apos; 将fstab拷贝到主机被改名为fstab2，如果存在先备份，所有者改为test用户 2.ansible all -m copy -a &apos;content=&quot;selinux1\nselinux2&quot; dest=/data/selinux1&apos; 根据自己写的字符串生成文件 5.Fetch:从目标主机抓取文件至服务器端，copy相反，目录可先tar再抓取 src，dest(抓取到本机目录) 示例：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos; 将远程主机fstab2文件抓取到本机/data下 如果抓取的是目录，先打包再抓取 打包：ansible all -a &apos;tar cf /root/data.tar /data&apos; 抓取：ansible all -m fetch -a &apos;src=/data/fstab2 dest=/data/&apos; 6.File：设置文件属性，创建/删除文件 src(创建链接文件),path=dest,state：(touch,absent,link,direcotory) 示例：创建文件：ansible all -m file -a &apos;dest=/data/f10 state=touch&apos; 创建文件夹：ansible all -m file -a &apos;dest=/data/haha state=directory&apos; 删除文件夹/目录：ansible all -m file -a &apos;dest=/data/haha state=absent&apos; 7.Hostname：管理主机名 可以通过后面的变量来实现 a.先在hosts后定义hostname变量名 [centos6] 192.168.34.106 hostname=mini6-2 192.168.34.101 hostname=node6-1 [centos7] 192.168.34.107 hostname=mini7-1 b.再通过hostname模块批量修改 ansible all -m hostname -a &apos;name={{hostname}}&apos; 8.Cron：计划任务 支持：minute，hour，day，month，weekday 示例：ansible all -m cron -a &apos;minute=*/5 job=&quot;/usr/sbin/ntpdate 172.18.0.1 &amp;&gt;/dev/null&quot; name=Synctime&apos; 创建计划任务 ansible srv -m cron -a &apos;name=Synctime state=absent&apos; 删除指定的计划任务名 ansible srv -m cron -a &apos;name=Synctime disable=true&apos; 禁用指定的计划任务名 9.Yum：管理包 支持：name,state=(started stopped reloaded restarted),absent 更新缓存：update_cache=yes， 示例：ansible all -m yum -a &apos;name=httpd,samba,vsftpd&apos;安装多个包 ansible all -m yum -a &apos;name=httpd,samba,vsftpd state=absent&apos;删除包 10.Service：管理服务(同一systemctl&amp;service) name，state(stopped,started,reloaded,restarted) enable(设置开启启动) 示例：ansible srv -m service -a &apos;name=httpd state=stopped&apos; 停止服务 ansible srv –m service –a &apos;name=httpd state=reloaded&apos; 重新加载服务 ansible srv -m service -a &apos;name=httpd state=restarted&apos; 重启服务 ansible srv -m service -a &apos;name=httpd enable=yes&apos; 设置开机启动 11.User：管理用户 name,comment(描述)，group(主组),groups(附加组)，uid，home，shell,system(系统用户) (absent,remove删除用户及家目录) 示例：ansible all -m user -a &apos;name=user1 uid=234 home=/data/user1 system=yes group=root groups=bin shell=/sbin/nologin comment&apos; 创建用户，指定uid，家目录，主组，附加组，shell类型，指定为系统用户 ansible all -m user -a &apos;name=user1 state=absent remove=yes&apos;删除用户及家目录 12.Group：管理组 支持：group,name,gid,system,state=(absent) 示例：ansible srv -m group -a &apos;name=testgroup system=yes&apos; 创建系统组 ansible srv -m group -a &apos;name=testgroup state=absent&apos; 删除组 ansible系列的一些模块(用的不多)简单介绍与了解： ansible-galaxy 互联网上的角色分享 ansible-pull 推送命令至远程，效率无限提升，对运维要求较高 Ansible-vault管理yaml文件 功能：管理加密解密yml文件 ansible-vault [create|decrypt|edit|encrypt|rekey|view] ansible-vault encrypt hello.yml 加密 ansible-vault decrypt hello.yml 解密 ansible-vault view hello.yml 查看 ansible-vault edit hello.yml 编辑加密文件 ansible-vault rekey hello.yml 修改口令 ansible-vault create new.yml 创建新文件 Ansible-console ansible重要知识之playbook(上面的各种模块的组合) YAML语言（编写playbook的专门语言）YAML语法： 在单一档案中，可用连续三个连字号(——)区分多个档案。另外，还有选择性的连续三 个点号( ... )用来表示档案结尾 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 使用#号注释代码 缩进必须是统一的，不能空格和tab混用 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过 缩进结合换行来实现的 YAML文件内容是区别大小写的，k/v的值均需大小写敏感 k/v的值可同行写也可换行写。同行使用:分隔 v可是个字符串，也可是另一个列表 一个完整的代码块功能需最少元素需包括 name: task 一个name只能包括一个task YAML文件扩展名通常为yml或yaml List：列表，其所有元素均使用“-”打头 Dictionary：字典，通常由多个key与value构成 Playbook中的核心元素:1.Hosts 执行的远程主机列表 2.remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远 程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使 用sudo_user指定sudo时切换的用户 3.Tasks 任务集 4.Varniables 内置变量或自定义变量在playbook中调用 5.Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件 6.Handlers 和notity结合使用，由特定条件触发的操作，满足条件方才执行，否 则不执行 7.tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible 具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其 确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可 以通过tags跳过此些代码片断 8.handlers和notify 运行playbook运行playbook的方式 ansible-playbook &lt;filename.yml&gt; ... [options] 常见选项 -C|--check 只检测可能会发生的改变，但不真正执行操作,建议执行前先检测 --list-hosts 列出运行任务的主机 --limit 主机列表 只针对主机列表中的主机执行 -v 显示过程 -vv -vvv 更详细 备注： 执行前建议 ansible-plsybook -C install_httpd.yml检查语法错误 ansible-playbook install_httpd.yml --list-hosts可以查看对哪些主机执行 执行playbook时，更改正确的是绿色的，更改的显示黄色的，错误信息显示红色，可以根据颜色变化判断是否更改，或者是否更改成功了。示例：以下实验均在centos7管理centos7集群，因为6&amp;7配置文件不同，均在7上实验将centos7的httpd.conf复制到centos7主机，6上的配置文件不同示例1：写一个安装启动httpd的playbook:install_httpd.yml 包括创建用户，安装httpd包，开启服务，并设置开机启动 - hosts: all remote_user: root tasks: - name: creat user user: name=httpd shell=/sbin/nologin uid=1234 home=/data/httpd - name: copy config copy: src=/data/httpd.conf dest=/etc/httpd/conf/httpd.conf - name: install package yum: name=httpd - name: service service: name=httpd state=started enabled=yes 备注： 执行完通过以下命令判断每个任务都否都执行成功了 1.ansible all -a &apos;getent passwd httpd&apos; 2.ansible all -a &apos;rpm -q httpd&apos; 3..ansible all -a &apos;ss -ntlp|grep 80&apos; 示例2：写一个删除上面的playbook:remove_httpd.yml 包括：删除用户，卸载httpd包 - hosts: all remote_user: root tasks: - name: del user user: name=httpd state=absent remove=yes - name: remove package yum: name=httpd state=absent 备注： 如果只删除特定主机的httpd，而不是全部，需要加--limit选项 ansible-playbook --limit 192.168.34.105 remove_httpd.yml 只限制在192.168.34.105的主机执行 上面的playbook只是实现了简单的安装配置功能，但是不能根据在更改配置文件后，再次执行，因为服务设置是start，不合理，所以要用到下面触发条件，来达到更改控制的目的。handlers和notify结合使用触发条件:当达到某个条件时，触发执行对应的task任务。Handlers: 是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生 变化时，才会采取一定的操作 Notify: 此action可用于在每个play的最后被触发，这样可避免多次有改变发生 时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。 在notify中列出的操作称为handler，也即notify中调用handler中定义的操作 示例：示例3：将memcached的配置文件的端口更改后再复制到各主机上，服务需要重启，则用到了handlers和notify功能 （端口11211改成11200） - hosts: all remote_user: root tasks: - name: creat user user: name=memcached shell=/sbin/nologin uid=2345 - name: install package yum: name=memcached - name: copy config copy: src=/data/memcached dest=/etc/sysconfig/memcached notify: restart service 和handlers名称一致 - name: service service: name=memcached state=started enabled=yes handlers: - name: restart service 和notify名称一致 service: name=memcached state=restarted 备注：停止并删除用户和安装包 ansible all -a &apos;service memcached stop&apos; ansible all -a &apos;ss -ntl&apos; ansible all -a &apos;rpm -q memcached&apos; ansible all -a &apos;getent passwd memcached&apos; 可以多个notify对应一个handlers，也可以多个motify对应多个handlers示例4：多个notify对应一个handlers - hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ notify: restart httpd 第一个notify - name: ensure apache is running service: name=httpd state=started enabled=yes notify: restart httpd 第二个notify handlers: - name: restart httpd 对应一个handlers service: name=httpd status=restarted 示例5：多个notify对应多个handlers- hosts: websrvs remote_user: root tasks: - name: config copy: src=/root/config.txt dest=/etc/nginx/nginx.conf notify: - Restart Nginx - Check Nginx Process 多个notify的写法 handlers: - name: Restart Nginx 对应写多个handlers service: name=nginx state=restarted enabled=yes - name: Check Nginx process shell: killall -0 nginx &gt; /tmp/nginx.log tags的用法：作用：挑选某一段的task来执行将安装memcached的yml，在拷贝的动作后加一个标签,执行时指定标签运行 然后执行：ansible-plsybook -t ceshi install_memcached.yml 只会触发拷贝文件和handlers的动作 --- #test yaml file - hosts: all remote_user: root tasks: - name: creat user user: name=memcached shell=/sbin/nologin uid=2345 - name: install package yum: name=memcached - name: copy config copy: src=/data/memcached dest=/etc/sysconfig/memcached notify: restart service 和handlers名称一致 tags: ceshi 对拷贝动作加一个标签 - name: service service: name=memcached state=started enabled=yes handlers: - name: restart service 和notify名称一致 service: name=memcached state=restarted Playbook中变量使用:可以多出定义，但是存在优先级优先级的顺序为：-e var &gt; yaml中的var &gt; hosts中的普通变量 &gt; hosts公共变量变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1 ansible setup facts 远程主机的所有变量都可直接调用 setup是一个模块，收集所有主机的各种信息，如果要用变量，需要先在里面找出对应的 代码块，然后用代码块当变量 比如：ansible all -m setup | grep &quot;version&quot; 过滤和版本有关的 ansible all -m setup | grep &quot;name&quot; 过滤和主机名有关的 2 在/etc/ansible/hosts中定义 普通变量：主机组中主机单独定义，优先级高于公共变量 公共（组）变量：针对主机组中所有主机定义统一变量 3 通过命令行指定变量，优先级最高 可以对单个变量赋值：ansible-playbook –e varname=value 也可以对多个变量赋值：ansible-playbook –e &quot;var1=1 var2=2&quot; 4 在playbook中定义 vars: - var1: value1 - var2: value2 5 在独立的变量YAML文件中定义，即roles下的var目录下的var.yml文件 很适合在roles中进行单独定义 6 在role中定义（下文中有介绍） 从setup模块中查找到的有用的变量；可以通过判断变量的值，然后执行不同的操作，类似于shell中，先判断version==7？然后再执行不同的命令#####先列出setup中几个有用的变量,然后在plsybook中执行不同操作 ansible_fqdn 主机名的变量 ansible_hostname 主机名 ansible_distribution_major_version: “6” 版本名变量 ansible_processor_vcpus 虚拟cpu个数变量 ansible_memtotal_mb 内存的变量 示例： ansible all -m setup -a “filter=ansible_memtotal_mb” 用此命令来查看系统内变量的值 调用不同变量来源的示例：得出变量的优先级顺序示例1：调用setup中的ansible_hostname主机名变量，来生成对应文件 var.yml - hosts: all remote_user: root tasks: - name: touch file file: name=/data/{{ ansible_hostname }}.log state=touch 示例2：将变量定义在/etc/ansible/hosts中(濮普通变量和公共变量)，然后调用变量 /etc/ansible/hosts：中定义的变量： [websrvs] 192.168.34.105 port1=80 192.168.34.106 port1=90 -普通变量 [websrvs:vars] -公共组变量 mark=&quot;-&quot; [appsrvs] 192.168.34.101 port1=100 [appsrvs:vars] mark=&quot;=&quot; vars.yml中书写格式： - hosts: all remote_user: root tasks: - name: touch file file: name=/data/app{{mark}}{{ port1 }}.log state=touch 最后生成的文件为： app=100.log，app-80.logapp-90.log 示例3：在示例1的基础上，再通过命令行中定义变量: 在外部定义ansible_hostname=&quot;hahaha&quot;，对比示例1的执行结果： ansible-playbook -e ansible_hostname=&quot;hahaha&quot; vars.yml 可以看出，最后新建的文件名为hahaha.log 示例4：在playbook中定义变量 - hosts: all remote_user: root vars: - port1: 200 - mark: +++ tasks: - name: touch file file: name=/data/app{{mark}}{{ port1 }}.log state=touch 生成的文件： app+++200.log 示例5：先写在var.yml中定义变量， 1.先准备cat vars.yml:文件内容格式 var1: httpd var2: nginx 2.在cat var.yml，中调用准备好的vars.yml文件这种方式适用于在roles中单独定义 - hosts: web remote_user: root vars_files: - vars.yml tasks: - name: create httpd log file: name=/app/{{ var1 }}.log state=touch - name: create nginx log file: name=/app/{{ var2 }}.log state=touch 模板templates，作用：文本文件，嵌套有脚本（使用模板编程语言编写） Jinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1, item2, ...] 元组：(item1, item2, ...) 字典：{key1:value1, key2:value2, ...} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;= 逻辑运算：and, or, not 流表达式：For If When templates功能：根据模块文件动态生成对应的配置文件 templates文件必须存放于templates目录下，且命名为 .j2 结尾 yaml/yml 文件需和templates目录平级，目录结构如下： ./ ├── temnginx.yml └── templates └── nginx.conf.j2 示例1：通过templates模板nginx1.先生成nginx.conf.j2模板 cp /etc/nginx/nginx.conf templates/nginx.conf.j2 2.创建playbook - hosts: all remote_user: root tasks: - name: inastll nginx yum: name=nginx - name: template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: service - name: start service service: name=nginx state=started handlers: - name: service service: name=nginx state=restarted when配合templates实现根据不同版本执行不同的功能条件测试: 如果需要根据变量、facts或此前任务的执行结果来做为某task执行与 否的前提时要用到条件测试,通过when语句实现，在task中使用，jinja2的语法 格式 when语句 在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 示例： tasks: - name: &quot;shutdown RedHat flavored systems&quot; command: /sbin/shutdown -h now when: ansible_os_family == &quot;RedHat&quot; 非赋值，而是比较是否为某个值 示例2：通过templates模板根据不同的centos版本，安装不同的httpd,就用到了when步骤：涉及到多个notify对应一个handlers,定义端口变量 1.hosts文件配置：修改了4台主机httpd的端口 [centos6] 192.168.34.105 http_port=86 192.168.34.106 http_port=87 192.168.34.101 http_port=88 [centos7] 192.168.34.107 http_port=89 2.将centos6&amp;centos7的httpd配置文件复制到templates/并改名为*.j2文件 httpd_6.conf.j2 httpd_7.conf.j2 3.将端口都自定义：修改httpd_6.conf.j2和httpd_7.conf.j2的 Listen {{http_port}} 调用hosts列表中的端口变量 4.plsybook如下： --- - hosts: all remote_user: root tasks: - name: install httpd yum: name=httpd - name: templates 6 template: src=httpd_6.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: restart service when: ansible_distribution_major_version == &quot;6&quot; - name: templates 7 template: src=httpd_7.conf.j2 dest=/etc/httpd/conf/httpd.conf when: ansible_distribution_major_version == &quot;7&quot; notify: restart service - name: service service: name=httpd state=started handlers: - name: restart service service: name=httpd state=restarted 迭代：with_items，类似于shell中的for循环迭代：当有需要重复性执行的任务时，可以使用迭代机制 对迭代项的引用，固定变量名为”item“ 要在task中使用with_items给定要迭代的元素列表 列表格式： 字符串 字典 字典构成一个键值对{key:vavul},如示例3 迭代的示例：示例1：比如创建user1.user2.user3个用户 - hosts: all remote_user: root tasks: - name: touch users user: name={{item}} with_items: - haha1 - haha2 - haha3 示例2：拷贝3个文件，file1 file2 file3 - hosts: all remote_user: root tasks: - name: copy files copy: src=/data/playbook/{{item}} dest=/data/ with_items: - file1 - file2 - file3 迭代嵌套子变量:涉及到多个键值对的表达方式示例3：创建3个组，再创建3个用户，指定加入一一对应的组 - hosts: all remote_user: root tasks: - name: creat groups group: name={{item}} with_items: - group1 - group2 - group3 - name: creat users user: name={{item.name}} group={{item.group}} with_items: - { name: &apos;haha1&apos;, group: &apos;group1&apos; } - { name: &apos;haha2&apos;, group: &apos;group2&apos; } - { name: &apos;haha3&apos;, group: &apos;group3&apos; } 备注：注意创建用户时，键值对的表达和使用方法 上面的执行结果是：先用单个迭代创建多个组，再通过多个键值对创建用户和组的一一对应关系:即：haha1属于group1;haha2属于group2;haha3属于group3; Playbook中template结合for循环生成具有重复性的代码段语法: for的写法： {% for vhost in nginx_vhosts %} server { listen {{ vhost.listen | default('80 default_server') }} ### Playbook中template结合for循环生成具有重复性的代码段 if的写法和表达的意思：如果键值对中的vhost.server_name被定义了，则使用 如果没定义，则不执行接下来的代码：示例2 {% if vhost.server_name is defined %} server_name {{ vhost.server_name }}; {% endif %} {% if vhost.root is defined %} root {{ vhost.root }}; {% endif %} ### for和if的示例，帮助理解其要执行语句的含义 示例2：生成listen加不同端口的和fqdn文件，由多个键值对组成 先创建for.j2文件： {% for i in ports %} server{ listen {{i.listen}} name {{i.name}} root {{i.root}} } {% endfor %} 创建playbook:再其中调用for.j2文件 - hosts: all remote_user: root vars: ports: - web1: listen: 81 name: www.baidu.com root: /data/web1 - web2: listen: 82 name: www.baidu1.com root: /data/web2 tasks: - name: test for template: src=for.j2 dest=/data/for1.conf 效果为： server{ listen 81 name www.baidu.com root /data/web1 } server{ listen 82 name www.baidu1.com root /data/web2 } 示例2：template配合if的涵义： 在示例1中的playbook中，把name注释掉，即不定义name的值 - web1: listen: 81 # name: www.baidu.com root: /data/web1 然后playbook:再调用for.j2文件 {% for i in ports %} server{ listen {{i.listen}} {% if i.name is defined%} 表示：如果i.name的值定义了，就用，没定义不用 name {{i.name}} {% endif %} root {{i.root}} } {% endfor %} 结果：则web1没有name的值，即可以理解if的用法 server{ listen 81 root /data/web1 少了web1的name的值 } server{ listen 82 name www.baidu1.com root /data/web2 } Roles：什么是roles,为什么要用roles？什么场景适合于roles?roles的结构？ansible重要内容之Roles；playbook的集合和拆分 ansilbe自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles 能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需 要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、 文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一 种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程 等场景中 复杂场景：建议使用roles，代码复用度高 变更指定主机或主机组 如命名不规范维护和传承成本大 某些功能需多个Playbook，通过Includes即可实现 roles的意义和适用场景：角色(roles)：角色集合 适用场景：如系统内有多台数据库服务器，httpd服务器,nginx服务器，可以事先把 同一类的服务器所需的软件，数据库等写成各自的角色roles，然后就可以批量部署了， 当需要临时增加扩容一台服务器时，就可以使用事先编排好的role来对一台或多台服务器进行部署,从而提高了安装部署的效率。 如系统内会存在如下的各类服务，可以先编排好角色 roles/ ├── httpd/ ├── memcached/ ├── mysql/ └── nginx/ roles的目录结构（一般分成以下目录进行存放一类的文件）Roles各目录作用： /roles/project/ :项目名称,有以下子目录 如创建http，memcached，nginx等目录 files/ ：存放由copy或script模块等调用的文件 保存需要拷贝的配置文件 templates/：template模块查找所需要模板文件的目录 保存通过template的jinja2模板调用的配置文件 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此 文件中通过include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要 在此文件中通过include进行包含，可以单独定义变量的目录 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为 main.yml的文件，其它文件需在此文件中通过include进行包含 tasks目录下，组合任务顺序的文件 default/：设定默认变量时使用此目录中的main.yml文件 roles playbook的tags的标签的作用：通过标签可以更灵活的调用playbook的角色.- hosts: all remote_user: root roles: - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;]} - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]} - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]} playbook调用角色：介绍前文提到的变量来源第六条：来自于roles的变量方法一：把需要调用的角色写在一个playbook里 - hosts: all remote_user: root roles: - role: httpd - role: memcached - role: nginx 弊端：如果要执行次playbook，三个角色都会执行一遍，不灵活 方法二；可以把变量在角色中定义 传递变量给角色 - hosts: remote_user: roles: - mysql - { role: nginx, username: nginx } 键role用于指定角色名称 后续的k/v用于传递变量给角色 调用角色方法3：还可基于条件测试实现角色调用 方法三：还可基于条件测试实现角色调用 roles: - { role: nginx, username: nginx, when: ansible_distribution_major_version == ‘7’ } roles示例：以httpd&amp;nginxmemcached三个role为例，下面为整个roles的目录结构和调用角色的playbook:role_playbook.ymlroles的目录结构下的httpd&amp;nginxmemcachedroles ├── httpd │ ├── files │ │ ├── index_6.html │ │ └── index_7.html │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ ├── copyhtml_6.yml │ │ ├── copyhtml_7.yml │ │ ├── group.yml │ │ ├── main.yml │ │ ├── package.yml │ │ ├── service.yml │ │ ├── tempconfig_6.yml │ │ ├── tempconfig_7.yml │ │ └── user.yml │ ├── templates │ │ ├── httpd_6.conf.j2 │ │ └── httpd_7.conf.j2 │ └── vars ├── memcached │ ├── files │ ├── handlers │ │ └── main.yml │ ├── tasks │ │ ├── group.yml │ │ ├── main.yml │ │ ├── package.yml │ │ ├── service.yml │ │ ├── tempconfig.yml │ │ └── user.yml │ ├── templates │ │ └── memcached.j2 │ └── vars └── nginx ├── files │ ├── index_6.html │ └── index_7.html ├── handlers │ └── main.yml ├── tasks │ ├── copyhtml_6.yml │ ├── copyhtml_7.yml │ ├── group.yml │ ├── main.yml │ ├── package.yml │ ├── service.yml │ ├── tempconfig.yml │ └── user.yml ├── templates │ └── nginx.conf.j2 └── vars └── main.yml 调用角色的playbook:roles.yml可以通过加变量和标签和条件测试调用更灵活的调用各种角色) vim /data/roles.yml - hosts: all remote_user: root roles: - {role: httpd,tags: [&apos;httpd&apos;,&apos;web&apos;],when: ansible_distribution_major_version == &quot;6“} - {role: memcached,tags: [&apos;memcached&apos;,&apos;web&apos;]} - {role: nginx,tags: [&apos;nginx&apos;,&apos;web1&apos;]} 比如： 1.ansible-playbook -C -t httpd roles.yml 选择测试安装httpd，检查语法 2.ansible-playbook -t httpd roles.yml 只选择安装httpd 3.ansible-playbook -t nginx roles.yml 只选择安装nginx 4.ansible-playbook -t web roles.yml 安装httpd和memcached 5.ansible-playbook -t web1 roles.yml 只选择安装nginx 下图为每个role的各个文件内容：图一：参照roles的httpd的目录各个文件内容 图二：参照roles的nginx的目录各个文件内容 涉及到跨角色调用配置文件，避免产生多余的垃圾文件：截图上也有 跨角色调用配置文件写法： - name: copy index6 copy: src=roles/httpd/files/index_6.html dest=/usr/share/nginx/html/index.html 图三：参照roles的memcached的目录各个文件内容]]></content>
      <categories>
        <category>自动化运维</category>
      </categories>
      <tags>
        <tag>ansible,运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix基础]]></title>
    <url>%2F2018%2F02%2F05%2Fzabbix%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[zabbix介绍 监控主要工作： 1.解决生产和测试环境遇到的问题 2.部署业务； 3.查看监控系统 查看服务是否出现问题和即将出现瓶颈等问题 如：mysql连接达到1500~2000时就变慢了；最近三个月的趋势 web服务的并发数达到一定值，就要考虑扩容了 实时监控服务是否down机，服务是否不可用，比如java服务内存溢出，tomcat由于内存溢出，导致访问异常，出现503，500等异常服务代码，如果zabbix对其做了监控，就可以实时及时的看到报警和展示，及时进行修复 4.监控系统是随着业务增加和服务器增加，在监控上不能出现瓶颈，不能因为监控系统的资源不够，导致监控项采集不完整和出故障时报警不及时等问题 2.如何规划监控 在大规模集群中是通过不同的群组来管理： 1.根据不同业务分组 2.根据虚拟机/物理机分组 3.虚拟机内部又根据业务划分很多组 Zabbix核心任务主流监控系统功能介绍： 数据采集：周期性时序数据 1.主机/对象：服务器、路由器、交换机、存储、防火墙、IP、URL、自定义监控对象... 2.采集目标：监控项，指标数据（metrics data） 数据存储： 存储系统： SQL: MySQL、PostgreSQL NoSQL：MongoDB、HBase、InfluxDB、Prometheus、redis ... rrd: Round Robin Database 数据： 历史数据: 每个监控项采集到的每个监控值 趋势数据: 趋势表里主要保留某个监控项一个小时内历史数据的最大值、最小值和平均值以及该监控项一个小时内所采集到的数据个数。 阈值：severity，可按照等级实现层级报警 告警：通过email, 短信, 微信,语音,故障自治愈 通过脚本将报警信息发送到公众号上 Zabbix四大核心任务： 采集：zabbix-server, zabbix-proxy,zabbix-agent 1.agentless SNMP、Telnet、ssh、IPMI、JMX(监控tomcat) #不能安装agent客户端的只能通过特殊协议来采集 #IPMI:服务器上的特殊接口，用来采集CPU温度和风扇转速等硬件进行监控 2.zabbix-server 核心组件，负责数据的存储、管理、查看 3.zabbix-agent 负责各节点的数据采集发送给server 4.zabbix-proxy 用于非常庞大的环境下是需要的：超过几百台服务器 多个agent--&gt;proxy--server #可以有效减少server端的端口和CPU性能消耗; 存储: zabbix database--&gt;mysql 展示： zabbix web：支持图形聚合 graph -&gt; screen -&gt; slideshow(将多个screen以幻灯片的方式进行轮流展示) 告警： host (host groups) &lt;---templates host --&gt; items --&gt; triggers --&gt; action (conditions, operations) #先创建模板，在模板里设置告警，然后把模板关联到某个主机上，使用模板的好处 是不需要在每个主机上都设置告警信息了. 1.安装Zabbix-server和数据库源码安装：zabbix-4.0.3.tar.gz版本 1.环境准备： 安装常用命令： [root@zabbix-server ~]# yum install vim iotop bc gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel zip unzip zlib-devel net-tools lrzsz tree ntpdate telnet lsof tcpdump wget libevent libevent-devel 安装依赖包： [root@zabbix-server ~]# yum install gcc libxml2-devel net-snmp net-snmp-devel libevent-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel –y [root@zabbix-server ~]# yum install /root/jdk-8u191-linux-x64.rpm #安装java-jdk 2.安装mariadb数据库 [root@mysql ~]# yum install mariadb-server mariadb -y [root@mysql ~]# systemctl start mariadb [root@mysql ~]# systemctl enable mariadb [root@mysql ~]# mysql -proot123 [root@mysql ~]# MariaDB [(none)]&gt; create database zabbix character set utf8 collate utf8_bin; #创建一个zabbix库，专门存放监控数据 [root@mysql ~]# MariaDB [(none)]&gt; grant all privileges on zabbix.* to zabbix@&quot;192.168.34.%&quot; identified by &apos;zabbix123&apos;; #授权zabbix用户有权限访问zabbix库任何操作 3.编译安装zabbix-server端 [root@zabbix-server ~]# cd /usr/local/src/ [root@zabbix-server src]# tar xf zabbix-4.0.3.tar.gz [root@zabbix-server src]# cd zabbix-4.0.3 [root@zabbix-server zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java [root@zabbix-server zabbix-4.0.3]# make &amp;&amp; make install [root@zabbix-server zabbix-4.0.3]# cd /usr/local/zabbix/ [root@zabbix-server zabbix]# cd etc/ 修改配置文件： [root@zabbix-server etc]# grep &quot;^[a-Z]&quot; zabbix_server.conf LogFile=/usr/local/zabbix//zabbix_server.log #日志路径 DebugLevel=3 #日志级别 PidFile=/usr/local/zabbix/zabbix_server.pid #pid路径 SocketDir=/usr/local/zabbix #zabbix目录 DBHost=192.168.34.126 #mysql的IP地址 DBName=zabbix #连接的数据名 DBUser=zabbix #连接数据的用户 DBPassword=zabbix123 #连接数据库的密码 DBPort=3306 #数据库的端口 Timeout=4 # LogSlowQueries=3000 # 准备启动脚本： [root@node02 zabbix-4.0.3]# cp misc/init.d/fedora/core/zabbix_* /etc/init.d/ [root@node02 zabbix-4.0.3]# cd /etc/init.d/ [root@node02 zabbix-4.0.3]# vim zabbix_server BASEDIR=/usr/local/zabbix PIDFILE=/usr/local/zabbix/$BINARY_NAME.pid #将启动脚本里的zabbix的目录修改为编译安装的路径 #将pid路径修改和配置文件的路径一致(编译目录) 创建用户： [root@node02 init.d]# useradd zabbix -s /sbin/nologin 修改zabbix编译目录权限： [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R 初始化zabbix数据库： [root@node02 ~]# cd /usr/local/src/zabbix-4.0.3 [root@node02 zabbix-4.0.3]# cd database/mysql/ [root@node02 mysql]# mysql -uzabbix -pzabbix123 -h192.168.34.126 zabbix &lt; schema.sql 启动zabbix: [root@node02 zabbix]# /usr/local/zabbix/sbin/zabbix_server -c /usr/local/zabbix/etc/zabbix_server.conf #通过编译生成目录下的二进制命令指定配置文件启动zabbix 查看端口： [root@node02 zabbix]# ss -tnl LISTEN 0 128 *:10051 #zabbix-server启动后监听在10051端口 2.安装zabbix-web页面zabbix的前端服务是PHP程序，需要安装httpd [root@node02 zabbix]# yum install php httpd #安装php和httpd [root@node02 zabbix-4.0.3]# mkdir /var/www/html/zabbix #创建zabbix目录 [root@node02 zabbix]# cd /usr/local/src/zabbix-4.0.3 [root@node02 zabbix-4.0.3]# cp -a frontends/php/* /var/www/html/zabbix/ #因为zabbix的前端程序都在解压的目录下，所以把其拷贝到httpd下的目录 启动httpd: [root@node02 zabbix]# systemctl start httpd 访问： http://192.168.34.118/zabbix –启动报错 解决报错信息： 1.安装依赖包： [root@node02 zabbix]# yum install php-gettext php-session php-ctype php-xmlreader php-xmlwriter php-xml php-net-socket php-gd php-mysql 2.更改vim /etc/php.ini参数： post_max_size = 8M 改为 post_max_size = 16M max_execution_time = 30 改为 max_execution_time = 300 max_input_time = 60 改为 max_input_time = 300 date.timezone = 改为 date.timezone = date.timezone = Asia/Shanghai 3.重启httpd,进入zabbix配置 注意： 如果在页面上连接mysql时出错，可以检查一下httpd_can_network_connect的值是不是on的； [root@node02 conf]# getsebool -a | grep httpd_can_network_connect httpd_can_network_connect --&gt; off 如果是off，需要修改成on [root@node02 conf]# setsebool httpd_can_network_connect 1 上述状态改变只是暂时性的，一旦系统重启，该变量状态将改变回初始状态，因此，可以使用如下命令永久性改变状态： [root@node02 conf]# setsebool -P httpd_can_network_connect_db on 4.配置完成后将zabbix.conf.php放到/var/www/html/zabbix/conf下 zabbix.conf.php保存了刚才在页面上填写的信息，可以修改 5.登录 账户：Admin 密码：zabbix 6.登录后： 1.确认zabbix server是running状态； 2.默认会有一个报警，因为zabbix-server上的zabbix-agent进程没启动; 3.在Administartion-Users-ADMIN模板中修改语言和默认账户密码 7.启动zabbix-server的agent服务 [root@node02 etc]# vim zabbix_agentd.conf Server=127.0.0.1 #被动模式下的Server的IP StartAgents=3 #agent进程起来之后，启动几个子进程收集日志 #需要启动起来 ServerActive=127.0.0.1 #主动模式下的Server的IP Hostname=Zabbix server #当前主机的IP地址 #hostname是zabbix中用于区分监控主机的有效值，必须保留且不能重复 即一定要与web页面上的配置--&gt;主机--&gt;模板--&gt;主机名称保持一致，基于设置的hostname来监控，一般是改成IP地址 8.启动zabbix-agent [root@node02 etc]# /etc/init.d/zabbix_agentd start #监听在10050端口 然后再web页面就可以看到主机zabbix server的ZBX为绿色正常状态了. 9.字体优化 将windows下或者网上下载合适的字体上传到zabbix上 [root@node02 ~]# cd /var/www/html/zabbix/fonts/ DejaVuSans.ttf root@node02 fonts]# grep &quot;DejaVuSans&quot; ../* -R Binary file ../fonts/DejaVuSans.ttf matches ../include/defines.inc.php:define(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;DejaVuSans&apos;); // font file name ../include/defines.inc.php:define(&apos;ZBX_FONT_NAME&apos;, &apos;DejaVuSans&apos;); 修改方式： 1.将上传的字体改成DejaVuSans.ttf把原来的字体删除 2.将上面两个文件中调用的字体修改为上传的字体名 在需要监控的主机上部署zabbix-agent1.环境准备： [root@zabbix-server ~]# yum install gcc libxml2-devel net-snmp net-snmp-devel libevent-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel –y [root@zabbix-server ~]# yum install /root/jdk-8u191-linux-x64.rpm #安装java-jdk 2.安装zabbix-agent [root@node01 src]# tar xf zabbix-4.0.3.tar.gz [root@node01 src]# cd zabbix-4.0.3 [root@node01 zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-agent [root@node01 zabbix-4.0.3]# make &amp;&amp; make install [root@node01 zabbix-4.0.3]# cd /usr/local/zabbix/ 3.配置zabbix-agent [root@node01 zabbix]# cd etc/ [root@node03 etc]# vim zabbix_agentd.conf PidFile=/usr/local/zabbix/zabbix_agentd.pid LogFile=/usr/local/zabbix/zabbix_agentd.log DebugLevel=3 Server=172.18.140.5 #被动模式下的server的IP ListenPort=10050 #agent的端口 ListenIP=0.0.0.0 #agent本机监听的地址 StartAgents=3 #启用几个agent子进程用于收集数据 ServerActive=127.0.0.1 #主动模式的IP(可以是server或者proxy) Timeout=30 #收集数据的超时时长，一定要设置成最长的30s ##上面的选项都是agent客户端的通用配置 Hostname=192.168.34.107 ##一定要写成每个agent客户端自己的IP地址 #因为server是依靠Hostname来区分客户端的 #AllowRoot=0 # User=zabbix # Include=/usr/local/etc/zabbix_agentd.userparams.conf # Include=/usr/local/etc/zabbix_agentd.conf.d/ # Include=/usr/local/etc/zabbix_agentd.conf.d/*.conf #用于存放自定义监控项和脚本的 UnsafeUserParameters=1 #需要改成1即启用特殊字符，因为脚本里需要特殊字符 # UserParameter= #自定义监控项(启用) 4.准备启动脚本并修改 ##此处在公司是通过ansible推送到各个主机上的 ##安装的zabbix路径都是/usr/local/zabbix的，所以启动脚本也都一样 ###创建用户也是通过ansible来管理的 [root@node03 etc]# cp /usr/local/src/zabbix-4.0.3/misc/init.d/fedora/core/zabbix_agentd /etc/init.d/ ##此处在公司是通过ansible推送到各个主机上的 5.创建用户 [root@node03 init.d]# useradd zabbix -s /sbin/nologin 6.修改zabbix目录权限 [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R 7.启动zabbix-agent [root@node03 init.d]# /etc/init.d/zabbix_agentd start 测试相关命令： 当把主机加入server时没有数据，可以先通过zabbix-get进行测试 [root@node02 bin]# cp /usr/local/zabbix/bin/zabbix_get /usr/bin/ [root@node02 bin]# zabbix_get -s 172.18.140.7 -p10050 -k &quot;agent.ping&quot; 1 #1表示172.18.140.7客户端时正常的 1.监控tomcat注意： 1.java gateway如果要监控的后端java程序比较多，最好部署在一台单独的服务器上； 2.使用阿里云上的java-gateway安装包，直接yum安装即可 https://mirrors.aliyun.com/zabbix/zabbix/4.0/rhel/7/x86_64/zabbix-java-gateway-4.0.1-1.el7.x86_64.rpm1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071721.要想监控java-tomcat,需要先在编译安装zabbix-server时加--enable-java选项;2.监控逻辑： zabbix监控java服务的时候很特殊，并不是有agent和server直接监控的，而是在中间加 了一个代理层叫做java gateway，需要在tomcat服务中开启JMX服务(监听在TCP：12345 端口)，然后java gateway连接到JMX：12345端口，将监控项发给JMX，再将采集的数据发给zabbix-server.3.修改启动java-getway服务： [root@node02 ~]# cd /usr/local/zabbix/sbin/zabbix_java/ [root@node02 zabbix_java]# vim settings.sh LISTEN_IP=&quot;0.0.0.0&quot; #java-gateway监听的地址 LISTEN_PORT=10052 #java-gateway端口 PID_FILE=&quot;/usr/local/zabbix/zabbix_java.pid&quot; START_POLLERS=5 #启动多少线程数 #因为如果有后端100个java(tomcat)程序，最好设置20个线程，那就采集5次， 避免采集的很慢，根据实际情况修改 TIMEOUT=30 ##采集数据的超时时长，一定要设置成最长的30s 启动： [root@node02 zabbix_java]# /usr/local/zabbix/sbin/zabbix_java/startup.sh #监听在10052端口 备注： 如果是以单独的服务安装的java-gateway,可以通过systemctl来控制启动关闭！4.在zabbix-server上配置java-getway服务的地址和端口 [root@node02 etc]# vim zabbix_server.conf JavaGateway=172.18.140.5 #Java-gate的IP地址 JavaGatewayPort=10052 #Java-gate的端口 StartJavaPollers=5 #启动多少线程数要和java-gate配置文件中一致5.配置JDK环境： [root@node01 ~]# tar xf jdk-8u191-linux-x64.tar.gz -C /usr/local/src/ [root@node01 src]# ln -sv /usr/local/src/jdk1.8.0_191/ /usr/local/jdk #为了JDK升级方便，将其创建一个软链接，后期只要创建一个新的软链接即可 [root@node01 local]# vim /etc/profile export JAVA_HOME=/usr/local/jdk export TOMCAT_HOME=/apps/tomcat export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$TOMCAT_HOME/bin:$PATH export CLASSPATH=.$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar [root@node01 local]# source /etc/profile #是配置生效 [root@node01 local]# java -version #查看是否为安装的JDK版本6.配置tomcat [root@node01]# tar xf apache-tomcat-8.5.37.tar.gz -C /usr/local/src/ [root@node01]# cd /usr/local/src/apache-tomcat-8.5.37/ [root@node01 apache-tomcat-8.5.37]# cd webapps/ [root@node01 apache-tomcat-8.5.37]# bin/startup.sh #启动tomcat服务7.配置tomcat监控参数 #修改catalina.sh启动脚本，放在第一个非注释行的前面 [root@node01 apache-tomcat-8.5.37]# vim bin/catalina.sh CATALINA_OPTS=&quot;$CATALINA_OPTS -Dcom.sun.management.jmxremote #启用远程监控JMX -Dcom.sun.management.jmxremote.port=12345 #默认启动的JMX端口号，要和zabbix添加主机时候的端口一致即可 -Dcom.sun.management.jmxremote.authenticate=false #不使用用户名密码认证 -Dcom.sun.management.jmxremote.ssl=false #不使用ssl认证 -Djava.rmi.server.hostname=172.18.140.6&quot; #tomcat主机自己的IP地址，不要写zabbix服务器的地址8.重新启动tomcat即可 [root@node01 etc]# /usr/local/tomcat/bin/startup.sh9.在zabbix监控页面配置 1.填写JMX的IP和端口 2.关联tomcat监控模板 3.导入制作好的tomcat模板，然后将主机关联到此模板即可.10.测试 如果window上安装了JDK，可以使用jconsole.exe进行登录测试JMX服务是否采集到数据 C:\Program Files\Java\jdk1.8.0_191\bin\jconsole.exe11.监控java排错方法 测试能否获取到java 当前已经分配的 线程数 # java -jar cmdline-jmxclient-0.10.3.jar - 192.168.15.203:12345 &apos;Catalina:name=&quot;http-bio-8080&quot;,type=ThreadPool&apos; currentThreadCount12.自制tomcat监控模板 busy-nio #nio线程达到某个值时，通知给管理员 –正常的tomcat的JMX状态 2.zabbix的主动模式和被动模式–zabbix监控架构 1.主动与被动 这是对于zabbix agent来说的工作模式 1.被动模式就是由zabbix server向zabbix agent发出指令获取数据，即zabbix agent被动的去获取数据并返回给zabbix server，zabbix server周期性的向agent 索取数据，这种模式的最大问题就是会加大zabbix server的工作量，在数百台服务器的 环境下zabbix server不能及时获取到最新数据，但这也是默认的工作方式; 而且在server上回打开很多随机端口； 2.主动模式是有zabbix agent主动向server索取监控项，根据拿到的监控项再去采集数据然后返回给zabbix server，不再需要zabbix serve进行干预，因此主动模式在一定程度上可减轻zabbix server的压力； 主动模式下，只会向zabbix server的10051端口发出请求连接，就不会有随机端口 3.基于zabbix-proxy代理实现监控–zabbix主动模式 1.zabbix_proxy zabbix 是一个分布式的监控系统，支持通过代理服务器zabbix proxy收集zabbix agent的数据，然后把收集保存在本地数据库并发送给zabbix server进行统一存储和展示； 2.优点： 1.更轻量，无图形化界面 2.临时保存在本地 可以独立采集数据并存储，临时的 3.易维护：配置完成后基本无需管理 4.报警通知： 代理服务器不发送邮件通知 5.独立数据库 保留少量最近数据 3.编译安装zabbix-proxy 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 1.环境准备： [root@node01]#yum install gcc libxml2-devel net-snmp net-snmp-devel curl curl-devel php php-bcmath php-mbstring mariadb mariadb-devel java-1.8.0-openjdk-devel 2.创建数据库 MariaDB [(none)]&gt; create database zabbix_proxy character set utf8 collate utf8_bin; MariaDB [(none)]&gt; grant all privileges on zabbix_proxy.* to proxy@&apos;172.18.140.%&apos; identified by &apos;zabbix123&apos;; 3.安装zabbix-proxy [root@node04 zabbix-4.0.3]# useradd zabbix -s /sbin/nologin [root@node04 src]# tar xf zabbix-4.0.3.tar.gz [root@node04 src]# c zabbix-4.0.3 [root@node04 zabbix-4.0.3]# ./configure --prefix=/usr/local/zabbix --enable-proxy --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java [root@node04 zabbix-4.0.3]# make &amp;&amp; make install 4.初始化数据库 [root@node02 mysql]# mysql -uproxy -pzabbix123 -h172.18.140.7 zabbix_proxy &lt; schema.sql4.修改zabbix-proxy配置文件 ProxyMode=1 #0为主动，1为被动 Server=172.18.140.5 #被动模式下zabbix server服务器的地址或主机名 #如果proxyMode是0，就不需要填此地址 Hostname=zabbix-proxy-active #代理服务器名称，需要与zabbix server添加代理时候的proxy name是一致的！ LogFile=/tmp/zabbix_proxy.log DBHost=172.18.140.7 #数据库服务器地址 DBName=zabbix_proxy #使用的数据库名称 DBUser=proxy #连接数据库的用户名称 DBPassword=zabbix123 #数据库用户密码 DBPort=3306 #数据库端口 ################################################################### 框中的配置只会在主动模式下生效，被动模式不生效 ################################################################### ProxyLocalBuffer=3 #已经提交到zabbix server的数据保留时间(单位小时，最大720) ProxyOfflineBuffer=24 #未提交到zabbix server的时间保留时间(单位小时，最大720) HeartbeatFrequency=60 #心跳间隔检测时间，默认60秒，范围0-3600秒，被动模式不使用 ConfigFrequency=5 #建议时间短一点 #间隔多久从zabbix server索取获取监控信息 DataSenderFrequency=5 #需要改长 #数据发送时间间隔，默认为1秒，范围为1-3600秒，被动模式不使用 ################################################################### StartPollers=20 #启动的数据采集器线程数量(生产环境下尽量多点) StartHTTPPollers=5 #启动多少线程响应http的请求 JavaGateway=172.18.140.5 #java gateway服务器地址,当需要监控java的时候必须配置否则监控不到数据 JavaGatewayPort=10052 #Javagatewa服务端口 StartJavaPollers=5 #启动多少个线程采集数据和java-gate一致 ################################################################### !!!和性能相关的非常重要的两项优化!!! !!!zabbix-server和zabbix-proxy都需要优化这两项!!! zabbix保存监控项是放在内存中的，所以CacheSize默认的8M内存空间是不够的 在zabbix-proxy服务器内存较大时，一定要把这个值调大(2G/4G)！！ ################################################################### CacheSize=2G #保存所有主机的监控项而占用的最大内存 HistoryCacheSize=2G #保存监控历史数据占用的最大内存 HistoryIndexCacheSize=4M #建议改成128M TrendCacheSize=128M #建议改成128M ValueCacheSize=128M #建议改成128M ################################################################### HistoryCacheSize默认才16M，建议一定要改成做大的2G内存 ################################################################### Timeout=30 #监控项超时时间，单位为秒 LogSlowQueries=3000 #毫秒，多久的数据库查询会被记录到日志 5.授权并启动： [root@node02 init.d]# chown zabbix.zabbix /usr/local/zabbix/ -R [root@node04 zabbix]# /usr/local/zabbix/sbin/zabbix_proxy -c /usr/local/zabbix/etc/zabbix_proxy.conf #这里直接使用二进制命令指定配置文件启动了 或者 将yum安装的zabbix-proxy的启动脚本拷贝过来，修改里面的配置文件路径和二进制命令的路径即可启动.]]></content>
      <categories>
        <category>监控</category>
        <category>zabbix监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控系统]]></title>
    <url>%2F2018%2F02%2F05%2Fzabbix%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Zabbix监控进阶-监控常用服务(自定义模板) 1.监控TCP连接数[root@node04 ~]# cd /usr/local/zabbix/etc/zabbix_agentd.conf.d/ 123456789101112131415161718192021[root@node04 zabbix_agentd.conf.d]# vim tcp_conn.sh#!/bin/bashtcp_conn_status()&#123; TCP_STAT=$1 ss -ant | awk &apos;NR&gt;1 &#123;++s[$1]&#125; END &#123;for(k in s) print k,s[k]&#125;&apos; &gt; /usr/local/zabbix/tcp_conn.txt TCP_STAT_VALUE=$(grep &quot;$TCP_STAT&quot; /usr/local/zabbix/tcp_conn.txt | cut -d &apos; &apos; -f2) if [ -z $TCP_STAT_VALUE ];then TCP_STAT_VALUE=0 fi echo $TCP_STAT_VALUE&#125;main()&#123; case $1 in tcp_status) tcp_conn_status $2; ;; *) echo &quot;$0 + tcp_status + STATUS&quot; esac&#125;main $1 $2 1.由于TCP三次握手和TCP四次挥手是有11种状态，最多的就是TIME_WAIT和ESTABLISHED的 和SYN_RCVD; 2.脚本准备好了，还需要在zabbix-agent.conf中去调用此脚本 LogFile=/usr/local/zabbix/zabbix_agentd.log DebugLevel=3 Server=172.18.140.5,172.18.140.97 #proxy和server的IP ListenPort=10050 #agent的端口 ListenIP=0.0.0.0 StartAgents=3 ServerActive=172.18.140.97 #proxy的IP Hostname=172.18.140.97 #客户端自己的IP Timeout=30 UnsafeUserParameters=1 #启用特殊字符 UserParameter=linux_status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/tcp_conn.sh &quot;$1&quot; &quot;$2&quot; #设置键和参数，以及脚本的路径 3.授权 1.zabbix用户要tcp_conn.sh脚本授权zabbix用户访问，不然agent日志文件中会有权限问题的报错 或者 2.被监控服务器为zabbix 用户授权： [root@node01 ~]# vim /etc/sudoers 99 zabbix ALL =(ALL) NOPASSWD: ALL 3.如果是使用root用户先生成的测试文件，zabbix是没有权限读取的，所以要把测试的文件先删除，不然会采集不到数据. 4.在zabbix web上添加监控TCP连接的11种状态的模板 因为，要监控的主机众多，不能每个主机里手动添加监控项的，所以一般是先定义一个TCP连接的模板，其他主机再在模板中调用即可; 步骤： 配置-&gt;模板-&gt;创建模板-&gt;添加应用集-&gt;添11个监控项--&gt;为11个监控项添加图形 生产环境： 1.生产环境会发现ESTABLISHED已连接的值特别大，不同的负载服务器一般都是3w、5w以上，见过nginx最多是7-8w连接，因为VIP有很多，80端口只有一个； –tcp模板监控报错–TCP监控状态 2.监控memcachedmemcached一般监控curr_connections当前连接数的值 123456789101112131415[root@node01 zabbix_agentd.conf.d]# vim memcached.sh#!/bin/bash memcached_status()&#123; M_PORT=$1 M_COMMAND=$2 echo -e &quot;stats\nquit&quot; | nc 127.0.0.1 &quot;$M_PORT&quot; | grep &quot;STAT $M_COMMAND &quot; | awk &apos;&#123;print $3&#125;&apos;&#125;main()&#123; case $1 in memcached_status) memcached_status $2 $3 ;; esac&#125;main $1 $2 $3 1.准备配置文件和memcached.sh [root@node01 zabbix]# vim etc/zabbix_agentd.conf Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf [root@node01 zabbix_agentd.conf.d]# vim all.conf UserParameter=memcached_status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/memcached.sh &quot;$1&quot; &quot;$2&quot; &quot;$3&quot; 2.在zabbix web上添加memcached_status监控模板 监控项有：curr_connections和threads等等 图形：把监控的多个项创建各自的图形 设置触发器：在触发器项添加触发值， 聚合图形：在memcached的聚合图形标签 –memcached模板配置–memcached触发器–memcached监控状态 3.监控redis1234567891011121314151617181920212223[root@node01 zabbix_agentd.conf.d]# vim redis.sh#!/bin/bashredis_status()&#123; R_PORT=$1 R_COMMAND=$2 (echo -en &quot;INFO \r\n&quot;;sleep 1;) | nc 127.0.0.1 &quot;$R_PORT&quot; &gt; /usr/local/zabbix/redis_&quot;$R_PORT&quot;.tmp REDIS_STAT_VALUE=$(grep &quot;&quot;$R_COMMAND&quot;:&quot; /usr/local/zabbix/redis_&quot;$R_PORT&quot;.tmp | cut -d &apos;:&apos; -f2) echo $REDIS_STAT_VALUE &#125;help()&#123; echo &quot;$&#123;0&#125; + redis_status + PORT + COMMAND&quot;&#125;main()&#123; case $1 in redis_status) redis_status $2 $3 ;;*) help ;; esac&#125;main $1 $2 $3 1.准备配置文件和redis.sh [root@node01 zabbix]# vim etc/zabbix_agentd.conf Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf [root@node01 zabbix_agentd.conf.d]# vim all.conf UserParameter=memcached_status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/redis.sh &quot;$1&quot; &quot;$2&quot; &quot;$3&quot; 2.在zabbix web上添加redis_status监控模板 监控项有： used_memory # used_cpu_sys #CPU的信息类型必须是浮点数不能是字符串或者其他 图形：把监控的多个项创建各自的图形 设置触发器：在触发器项添加触发值， 聚合图形：在redis的聚合图形标签 –redis监控模板–redis图形监控 4.监控mysql监控mysql的方案有很多，这里列出procona和自定义监控mysql数据库两种方案. 1.部署mysql主从(太简单,省略了) 2.采用procona的插件来监控mysql 下载地址：安装说明 3.安装并修改配置 [root@mysql ~]# yum install php php-mysql -y #安装php [root@mysql ~]# rpm -ivh percona-zabbix-templates-1.1.8-1.noarch.rpm [root@mysql zabbix_agentd.conf.d]# cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /usr/local/zabbix/etc/zabbix_agentd.conf.d/ [root@mysql ~]# vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php.cnf &lt;?php $mysql_user = &apos;root&apos;; $mysql_pass = &apos;&apos;; [root@node01 zabbix_agentd.conf.d]# /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gg 140 #配置完之后使用此命令测试是否配置成功 注意： 使用脚本测试完后会在/tmp下生成/tmp/localhost-mysql_cacti_stats.txt监控 测试文件，如果是 4.将准备好的mysql监控模板导入到zabbix 由于procona插件安装时自带的模板有问题，在其基础上根据生产环境修改后再导入到zabbix上. zbx_mysql_export_templates.xml.xml(模板文件名) 注意： 这个模板上监控项达到200多个，根据实际情况删除或禁止即可！ 5.关联到mysql主机上即可！ –procona监控mysql–procona监控mysql进程 二：自定义监控项监控mysql主从 ##主要是监控mysql主从同步及延时!!! ### 使用此脚本放在mysql的slave上，连接的账户密码按实际情况修改!!! 12345678910111213141516171819202122232425262728[root@node04 zabbix_agentd.conf.d]# vim mysql_monitor.sh#!/bin/bashSeconds_Behind_Master()&#123; NUM=`mysql -uroot -hlocalhost -e &quot;show slave status\G;&quot; | grep &quot;Seconds_Behind_Master:&quot; | awk -F: &apos;&#123;print $2&#125;&apos;` echo $NUM&#125;master_slave_check()&#123;NUM1=`mysql -uroot -hlocalhost -e &quot;show slave status\G;&quot; | grep &quot;Slave_IO_Running&quot; | awk -F: &apos;&#123;print $2&#125;&apos; | sed &apos;s/^[ \t]*//g&apos;`#echo $NUM1NUM2=`mysql -uroot -hlocalhost -e &quot;show slave status\G;&quot; | grep &quot;Slave_SQL_Running:&quot; | awk -F: &apos;&#123;print $2&#125;&apos; | sed &apos;s/^[ \t]*//g&apos;`#echo $NUM2if test $NUM1 == &quot;Yes&quot; &amp;&amp; test $NUM2 == &quot;Yes&quot;;then echo 50else echo 100fi&#125;main()&#123; case $1 in Seconds_Behind_Master) Seconds_Behind_Master; ;; master_slave_check) master_slave_check ;; esac&#125;main $1 1.在/usr/local/zabbix/etc/zabbix_agentd.conf.d下创建all.conf [root@node04 zabbix_agentd.conf.d]# vim all.conf UserParameter=mysql_monitor[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/mysql_monitor.sh &quot;$1&quot; 2.修改agent.conf文件 [root@node04 zabbix_agentd.conf.d]# vim ../zabbix_agentd.conf Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf 3.在zabbix-web上添加mysql_monitor模板 如下图 4.定义触发器报警值 –mysql主从复制监控 5.自定义监控端口和进程123456789101112131415161718192021222324252627vim process_port_check.sh#!/bin/bash check_process()&#123; NUM=`ps -ef | grep -v grep | grep -v bash | grep $&#123;NAME&#125; | wc -l` echo $&#123;NUM&#125;&#125;check_port()&#123; ss -tnl | grep $&#123;PORT&#125; &amp;&gt; /dev/null if [ $? -eq 0 ];then echo 50 else echo 100fi&#125;main()&#123; case $1 in process) NAME=$2 check_process; ;; port) PORT=$2 check_port; ;; esac&#125;main $1 $2 1.在/usr/local/zabbix/etc/zabbix_agentd.conf.d下创建all.conf [root@node04 zabbix_agentd.conf.d]# vim all.conf UserParameter=process_port[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/process_port_check.sh &quot;$1&quot; &quot;$2&quot; 2.修改agent.conf文件 [root@node04 zabbix_agentd.conf.d]# vim ../zabbix_agentd.conf Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf 3.在zabbix-web上添加process_port模板 如下图，测试只添加mysql的进程和端口 4.监控porthe process测试 如下图 –端口和进程监控.png 6.邮件报警通知功能1.修改成中文报警： 报警:{TRIGGER.STATUS} 报警服务器:{HOST.NAME},IP:{HOSTNAME1},详情{ITEM.NAME}:{ITEM.VALUE} 恢复:{TRIGGER.STATUS} 恢复服务器:{HOST.NAME},IP:{HOSTNAME1},详情{ITEM.NAME}:{ITEM.VALUE} 2.前三次报警发给运维，过了三次发给领导 前3分钟发给运维,且每分钟发一次 第4-8分钟发给运维部领导 第9--分钟发给开发部门领导 检查： 先检查网络问题 再检查服务是不是正常 –配置动作–配置操作–配置恢复动作–邮件提示 7.完善zabbix系统基础监控(CPU/内存/磁盘)模板由于zabbix自带的系统基础监控模板不是很全，所以需要在其基础上进行优化 编写脚本替代默认模板监控系统新建模板添加监控项根据原有模板添加自动发现规则、图形原形和触发值原形重启服务验证数据 12345678910111213141516171819202122232425262728#zabbix自带的Template OS Linux是没有监控磁盘读取和写入的，所以需要额外添加1.磁盘IO监控 服务器IO的写入速率和读取速率：iotop #尤其是web服务器受到攻击时，web日志会瞬间达到很大； [root@node04 ~]# vim /etc/sudoers #Defaults !visiblepw #允许zabbix用户登录tty执行命令 zabbix ALL = NOPASSWD: /sbin/iotop #允许zabbix用户执行iotop命令 vim iotop.sh #!/bin/bash disk_read()&#123; NUM=`/usr/bin/sudo iotop -b -n 1 | grep &quot;Total DISK READ&quot; | grep -v grep | awk -F &quot;|&quot; &apos;&#123;print $1&#125;&apos; | awk -F &quot;:&quot; &apos;&#123;print $2&#125;&apos; | awk &apos;&#123;print $1&#125;&apos; | awk -F &quot;.&quot; &apos;&#123;print $1&#125;&apos;` echo $&#123;NUM&#125; &#125; disk_write()&#123; NUM=`/usr/bin/sudo iotop -b -n 1 | grep &quot;Total DISK WRITE&quot; | grep -v grep | awk -F &quot;|&quot; &apos;&#123;print $2&#125;&apos; | awk -F &quot;:&quot; &apos;&#123;print $2&#125;&apos; | awk &apos;&#123;print $1&#125;&apos; | awk -F &quot;.&quot; &apos;&#123;print $1&#125;&apos;` echo $&#123;NUM&#125; &#125; main()&#123; case $1 in disk_read) disk_read; ;; disk_write) disk_write; ;; esac &#125; main $1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859##还需要做一个内存总大小，内存使用百分比，已用内存，剩余内存都监控到###监控脚本是把centos6和7分开来写的2.内存监控[root@node04 zabbix_agentd.conf.d]# vim memory.sh #!/bin/bash grep 7 /etc/redhat-release &amp;&gt; /dev/null if [ $? -eq 0 ];then mem_total()&#123; TOTAL=`free |grep -i mem |awk &apos;&#123;print $2&#125;&apos;` echo $&#123;TOTAL&#125; &#125; mem_use()&#123; USE=`free |grep -i mem | awk &apos;&#123;print $3&#125;&apos;` echo $&#123;USE&#125; &#125; mem_free()&#123; FREE=`free |grep -i mem |awk &apos;&#123;print ($4+$6)&#125;&apos;` echo $&#123;FREE&#125; &#125; mem_usage()&#123; USAGE=`free |grep -i mem | awk &apos;&#123;print ($3)/$2*100&#125;&apos; | awk -F &quot;.&quot; &apos;&#123;print $1&#125;&apos;` echo $&#123;USAGE&#125; &#125; else mem_total()&#123; TOTAL=`free |grep -i mem |awk &apos;&#123;print $2&#125;&apos;` echo $&#123;TOTAL&#125; &#125; mem_use()&#123; USE=`free |grep -i mem | awk &apos;&#123;print $3&#125;&apos;` echo $&#123;USE&#125; &#125; mem_free()&#123; #FREE=`free |grep -i mem |awk &apos;&#123;print $3+$5&#125;&apos;` FREE=`free |grep -i mem |awk &apos;&#123;print ($4+$6+$7)&#125;&apos;` echo $&#123;FREE&#125; &#125; mem_usage()&#123; USAGE=`free |grep -i mem | awk &apos;&#123;print ($3)/$2*100&#125;&apos; | awk -F &quot;.&quot; &apos;&#123;print $1&#125;&apos;` echo $&#123;USAGE&#125; &#125; fi main()&#123; case $1 in mem_total) mem_total; ;; mem_use) mem_use; ;; mem_free) mem_free; ;; mem_usage) mem_usage; ;; esac &#125; main $1 3.脚本准备好了(将脚本加权限)，需要准备配置文件 [root@node04 zabbix_agentd.conf.d]# vim all.conf UserParameter=disk_total[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/iotop.sh &quot;$1&quot; &quot;$2&quot; UserParameter=mem_status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/memory.sh &quot;$1&quot; &quot;$2&quot; 4.创建zabbix web监控模板 这次是将生成环境下的内存/cpu/磁盘的导入到这里了 zbx_export_Basic_system_monitor.xml.xml 将此模板关联到需要监控的主机上即可! 备注： 一：磁盘的寻道时间、旋转延迟和数据传输时间： 常见的机械磁盘平均寻道时间值： 7200转/分的磁盘平均物理寻道时间：9毫秒 10000转/分的磁盘平均物理寻道时间：6毫秒 15000转/分的磁盘平均物理寻道时间：4毫秒 常见磁盘的平均延迟时间： 7200转的机械盘平均延迟：60*1000/7200/2 = 4.17ms 10000转的机械盘平均延迟：60*1000/10000/2 = 3ms 15000转的机械盘平均延迟：60*1000/15000/2 = 2ms 每秒最大IOPS的计算方法： 7200转的磁盘IOPS计算方式：1000毫秒/(9毫秒的寻道时间+4.17毫秒的平均旋转延迟时 间)=1000/13.13=75.9 IOPS 10000转的磁盘的IOPS计算方式：1000毫秒/(6毫秒的寻道时间+3毫秒的平均旋转延迟时 间)=1000/9=111 IOPS 15000转的磁盘的IOPS计算方式：15000毫秒/(4毫秒的寻道时间+2毫秒的平均旋转延迟时 间)=1000/6=166.6 IOPS –内存使用率监控–磁盘读取和写入检测 8.监控nginx1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859601.[root@node04 zabbix_agentd.conf.d]# vim nginx_status.sh#!/bin/bashnginx_status_fun()&#123; NGINX_PORT=$1 #端口，函数的第一个参数是脚本的第二个参数，即脚本的第二个参数是端口号 NGINX_COMMAND=$2 #命令，函数的第二个参数是脚本的第三个参数，即脚本的第三个单数是命令 nginx_active()&#123; #获取nginx_active数量，以下相同，这是开启了nginx状态但是只能从本机看到 /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | grep &apos;Active&apos; | awk &apos;&#123;print $NF&#125;&apos; &#125; nginx_reading()&#123; #$获取nginx_reading状态的数量 /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | grep &apos;Reading&apos; | awk &apos;&#123;print $2&#125;&apos; &#125; nginx_writing()&#123; /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | grep &apos;Writing&apos; | awk &apos;&#123;print $4&#125;&apos; &#125; nginx_waiting()&#123; /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | grep &apos;Waiting&apos; | awk &apos;&#123;print $6&#125;&apos; &#125; nginx_accepts()&#123; /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | awk NR==3 | awk &apos;&#123;print $1&#125;&apos; &#125; nginx_handled()&#123; /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | awk NR==3 | awk &apos;&#123;print $2&#125;&apos; &#125; nginx_requests()&#123; /usr/bin/curl &quot;http://172.18.140.97:&quot;$NGINX_PORT&quot;/nginx-status/&quot; 2&gt;/dev/null | awk NR==3 | awk &apos;&#123;print $3&#125;&apos; &#125; case $NGINX_COMMAND in active) nginx_active; ;; reading) nginx_reading; ;; writing) nginx_writing; ;; waiting) nginx_waiting; ;; accepts) nginx_accepts; ;; handled) nginx_handled; ;; requests) nginx_requests; ;; esac&#125;main()&#123; #主函数内容 case $1 in #分支结构，用于判断用户的输入而进行响应的操作 nginx_status) #当输入nginx-status就调用nginx_status_fun,并第二和第三个参数 nginx_status_fun $2 $3; ;; *) #其他输入的打印帮助信息 echo $&quot;Usage: $0 &#123;tcp_status key|redis_status key | nginx_status key&#125;&quot; esac #分支结束符&#125;main $1 $2 $3 2.脚本准备好了(将脚本加权限)，需要准备配置文件 [root@node04 zabbix_agentd.conf.d]# vim all.conf UserParameter=nginx.status[*],/usr/local/zabbix/etc/zabbix_agentd.conf.d/nginx_status.sh &quot;$1&quot; &quot;$2&quot; &quot;$3&quot; 3.创建zabbix web监控模板 这次是将生成环境下的内存/cpu/磁盘的导入到这里了 nginx_status.xml 将此模板关联到需要监控的主机上即可! –nginx监控模板–nginx检测1–nginx检测2 9.编写脚本一键安装zabbix agent已上传网盘]]></content>
      <categories>
        <category>监控</category>
        <category>zabbix监控</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建内网yum源]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%90%AD%E5%BB%BA%E5%86%85%E7%BD%91yum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[创建文章的默认模板，可根据实际情况修改 Till I reach the end, then I’ll start again《Try Everything》 1 // 插入音乐 或者 // 表示图片在左边或者右边，中间(left，right，center) // markdown格式测试，就是要测试一下啊啊啊啊a 文本上带一条横线，表示错误 This is an H1 Red Green Blue This is a blockquoteinside a list item. http://example.com/ This is an H2// 插入图片并设置大小两种方法 // 颜色选择 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色 size定义字体大小，color定义颜色]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP三次握手、四次断开与十一种状态]]></title>
    <url>%2F2017%2F10%2F18%2FTCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E3%80%81%E5%9B%9B%E6%AC%A1%E6%96%AD%E5%BC%80%E4%B8%8E%E5%8D%81%E4%B8%80%E7%A7%8D%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[TCP三次握手、四次断开与十一种状态 OSI模型由下到上分别为物理层、数据链路层、网络层、传输层、会话层、表示层、应用层 1：第七层：应用层的功能： 为应用软件提供接口，使应用程序能够使用网络服务。常见的应用层协议： http(80)、ftp(20/21)、smtp(25)、pop3(110)、telnet(23)、dns(53)等 2：第六层：表示层的功能： 数据的编码和解码、数据的加密和解密、数据和压缩和解压缩，常见的标准有JPEG/ASCII等 3：第五层：会话层的功能： 建立、管理和终止表示层实体之间的会话连接，在设各或节点之间提供会话控制，它在系统之间协调通信过程,并提供3种 不同的方式来组织它们之间的通信:单工、半双工和全双工 4：第四层：传输层的功能： 负责建立端到端的连接，保证报文在端到端之间的传输。提供可靠TCP及不可靠UDP的传输机制,服务点编址、分段与重组 、连接控制、流量控制、差错控制。 5：第三层：网络层的功能： 定义逻辑地址,逻辑寻址，将数据分组从源传输到目的,路径选择、路由发现、维护路由表，功能是隔离广播域；隔离广播 ,路由选择；维护路由表,寻址及转发,流量管理并连接广域网 6：第二层：数据链路层的功能： 组帧、物理编址，将数据帧从链路上的一个节点传递到另一个节点，流量控制、差错控制、接入控制 7：第一层：物理层的功能： 在介质上传递比特流，定义接口和媒体的物理特性，定义比特的表示、数据传输速率、信号的传输模式（单工、半双工、全 双工），定义网络物理拓扑（网状、星型、环型、总线型等） TCP协议简介：TCP，全称Transfer Control Protocol，中文名为传输控制协议，它工作在OSI的传输层，提供面向连接的可靠传输服务，TCP的工作主要是建立连接，然后从应用层程序中接收数据并进行传输。TCP采用虚电路连接方式进行工作，在发送数据前它需要在发送方和接收方建立一个连接，数据在发送出去后，发送方会等待接收方给出一个确认性的应答，否则发送方将认为此数据丢失，并重新发送此数据。TCP的报文头部结构：-TCP的报文头部结构 TCP三次握手：在建立连接的时候，所谓的客户端与服务端是相对应的，即要看是谁主动连接的谁，如果A主动连接B那么A就是客户端 而B是服务端，如果返过来B主动连接A，那么B就是客户端而A就成了服务端。 1:连接过程： 第一次握手：客户端发送SYN标志位为1的请求到服务端，并随机生成一个seq 序列号x，其中seq是随机产生的数据包的序列号。 第二次握手：服务器收到客户端请求并返回SYN=1，ACK=1，seq=y，ack=x+1，其中ACK=1表示是响应报文，seq=y是 服务器随机产生的数据包序列号，ack=x+1是确认客户端序列号有效并返回给客户端确认。 第三次握手：客户端收到服务器的确认ack=x+1有效的验证信息，即在自己发送的序列号基础之上加了1表示服务器收到 并返回，表示第二次连接有效，然后客户端恢回复ACK=1，seq=x+1，ack=y+1，这是讲服务器发来+1后的序列号当做自 己的seq序列号，确认号ack使用服务器的随机号y再加1即ack=y+1，这样客户端就完成了第三次的验证在讲数据包发给 服务器，服务器收到后验证确认号是在自己的seq之上加了1，表示没有问题就开始传输数据。 注： ACK :TCP协议规定，只有ACK=1时有效，也规定连接建立后所有发送的报文的ACK必须为1 Seq:序号,4字节，范围为0^32—1^32,共4284967296，达到时重新开始计算 在第三次的时候SYN等于0，因为SYN(SYNchronization) 只i在连接建立时用来同步序号,当SYN=1而ACK=0时,表明这 是一个连接请求报文,对方若同意建立连接,则应在响应报文中使SYN=1和ACK=1. 因此, SYN置1就表示这是一个连接请求或连接接受报文，链路建立成功之后就将标志位置为0。 SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急) Sequence number(顺序号码) Acknowledge number(确认号码) -TCP三次握手 TCP的四次断开：TCP断开要四次是因为TCP传输数全双工的，即数据是在同一时间内两条数据链路双向互相传输的，因此每个方向都要单 独关闭一次，断开需要客户端到服务端断开一次，而服务端到客户端也需要断开一次，这样的断开才是完整的断开， 第一次断开：客户方发给服务器一个FIN为1的请求，FIN为1表示是一个断开连接的请求，即表示数据传输完毕请求断开 ，并发送seq序列号和Ack确认号。 第二次断开：服务器收到客户端请求并返回ACK标志位为1，Ack为Seq+1等于201，并将对方的Ack作为自己的Seq序列号 的确认数据包，biao 接收到请求同意断开。 第三次断开：服务器发送ACK=1，FIN=1，Seq等于客户端第一次请求断开的Ack确认号+1，即Seq等于501的断开请求给客户端。 第四次断开：客户端发送ACK=1，Ack在上一步Seq上+1等于502，并使用在第二次断开中服务器发送的Ack确号201作为 本次的序列号发给服务器表示同意断开，服务器收到后验证序列号是第二次的，验证Ack是第三次+1的，确认没有问题后 同意断开，然后将端口置为TIME_WAIT状态，等待2 MSL时间后置为关闭状态，被动方收到主动方的报文确认Ack确认号没有问题后将端口置为CLOSED，至此端口g。 SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急) Sequence number(顺序号码) Acknowledge number(确认号码) 四次断开的图形示意如下： -TCP四次挥手 TCP端口的十一种连接状态：TCP端口一共有十一种状态，CLOSE_WAIT表示是程序y关闭连接，而TIME_WAIT只占用一个socket连接，到时间之后会 释放，因此大量的CLOSE_WAIT是比大量的TIME_WAIT影响更大，另外还有FIN_WAIT1和FIN_WAIT2，如果有 FIN_WAIT2也表示服务有问题，以下是每个端口状态的含义： 1：CLOSED：端口默认是关闭状态。 2：LISTEN： 服务器程序开始监听一个端口，就是LISTEN状态。 3：SYN_RCVD：三次握手的第二次握手后的端口状态，是收到了客户端发送的SYN_SENT数据包之后的状态，这个状态很 短暂，正常在服务器上是很少看到的，除非服务器故意不发送最后一次握手数据包，服务器返回给客户端SYN确认之后就 会将在自己的端口置为SYN_RCVD。 4：SYN_SENT：SYN_SENT状态表示客户端已发送SYN=1的请求连接报文，发送之后客户端就会将自己的端口状态置为SYN_SENT。 5：ESTABLISHED：表示已经连接成功，客户端收到服务器的确认报文会回复服务器，然后就将端口置为ESTABLISHED， 服务器第三次收到客户端的Ack确认就会将端口置为ESTABLISHED并开始传输数据。 6：FIN_WAIT_1：出现在主动关闭方，FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，当任意一方想主动 关闭连接，向对方发送了FIN=1的断开连接请求报文，此时该SOCKET即 进入到FIN_WAIT_1状态。而当对方回应ACK报文 后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马 上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。 7：FIN_WAIT_2：出现在主动关闭方，当被动方回应FIN_WAIT_1的ACK报文后，则进入到FIN_WAIT_2状态 8：TIME_WAIT：出现在主动关闭方，表示收到了对方的FIN请求关闭报文，并发送出了ACK报文，就等2MSL后即可回到 CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到 TIME_WAIT状态，而无须经过FIN_WAIT_2状态。 9：CLOSING： 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送 FIN报文后，按理来说是应该先收到（或同时收到）对方的 ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你 发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什 么情况下会出现此种情况呢？其实细 想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报 文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。 10：CLOSE_WAIT： 表示在等待关闭端口，这种状态存在于被动关闭的一方。 11：LAST_ACK： 是被动关闭方在主动关闭一方在发送FIN报文后，最后等待对方的ACK报文，当再次收到ACK报文后，也即可以进入到CLOSED可用状态了。 12：区分主动断开和被动端口方的端口状态： 主动端口方：SYN_SENT、FIN_WAIT1、FIN_WAIT2、CLOSING、TIME_WAIT 。 被动断开方：LISTEN、SYN_RCVD、CLOSE_WAIT、LAST_ACK 。 都具有的：CLOSED 、ESTABLISHED 。 -TCP的11种状态 关于优化：socket就是一个TCP连接，包括源地址、源端口、目标地址、目标端口和协议(TCP|UDP),0端口是保留不能使用的， 因此服务器的最大端口使用数量为63353个，最大65536个端口是因为TCP报文头部有个端口长度为2^16次方等于 65536，查看当前打开的端口范围# cat /proc/sys/net/ipv4/ip_local_port_range，单个IP地址能接受的最大并 发为六万多，1万个TIME_WAIT大约使用1MB的内存CPU占用更小，因此资源使用很小可以忽略不计，但是会占用一个 socket，可以通过在负载上配置多个公网IP地址以提高高并发的问题， [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_recycle 0 #用于快速回收处于TIME_WAIT状态的socket以便重新分，在负载服务器不能打开，会导致通过nat上网的后续用户 无法打开网页，因为后面的访问用户时间戳小于前面的用户，会导致数据包被负载服务器丢弃，可以在内网使用，但是通常建议关闭。 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_reuse 0 #kernel会复用处于TIME_WAIT状态的socket，即允许将TIME_WAIT状态得socket用于直接新的TCP连接，负载服务器建议打开 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_timestamps 1 #记录数据包的时间戳，判断是新的数据包还是旧的，如果是旧的就丢弃，配合上面两个选项的时候一定要打开才生效。]]></content>
      <categories>
        <category>TCP协议</category>
      </categories>
      <tags>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下双网卡绑定及Bridge]]></title>
    <url>%2F2017%2F10%2F18%2FLinux%E4%B8%8B%E5%8F%8C%E7%BD%91%E5%8D%A1%E7%BB%91%E5%AE%9A%E5%8F%8ABridge%2F</url>
    <content type="text"><![CDATA[Linux的双网卡绑定及Bridge一：linux操作系统下双网卡绑定有七种模式。现在一般的企业都会使用双网卡接入，这样既能添加网络带宽，同时又能做相应的冗余，可以说是好处多多。而一般企业都会使用linux操作系统下自带的网卡绑定模式，当然现在网卡产商也会出一些针对windows操作系统网卡管理软件来做网卡绑定，一共有其中方式，其中比较长用的是0/1/6：二：windows操作系统没有网卡绑定功能需要第三方支持：DELLr720一般都是博科的网卡，Inter网卡，随机光盘和网上 有很多双网卡绑定的软件. 1：网卡绑定案例，先做绑定，然后再把绑定后的网卡配置成桥接： 1.1：第一组配置，将eth1和eth5绑定为bond0： 1.1.1：先创建bond0配置那文件步骤及内容如下： [root@linux-host1 ~]# cd /etc/sysconfig/network-scripts/ [root@linux-host1 network-scripts]# cp ifcfg-eth0 ifcfg-bond0 [root@linux-host1 network-scripts]# cat ifcfg-bond0 #内容如下： BOOTPROTO=static NAME=bond0 DEVICE=bond0 ONBOOT=yes BONDING_MASTER=yes BONDING_OPTS=&quot;mode=1 miimon=100&quot; #指定绑定类型为1及链路状态监测间隔时间 BRIDGE=br0 #桥接到br0 1.1.2：配置br0： TYPE=Bridge BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=br0 DEVICE=br0 ONBOOT=yes IPADDR=X.X.X.X NETMASK=255.255.255.0 GATEWAY=X.X.X.X 1.1.3：eth1配置： [root@linux-host1 network-scripts]# vim ifcfg-eth1 BOOTPROTO=static NAME=eth1 DEVICE=eth1 ONBOOT=yes NM_CONTROLLED=no MASTER=bond0 USERCTL=no SLAVE=yes 1.1.4：eth5的配置： [root@linux-host1 network-scripts]# cp ifcfg-eth1 ifcfg-eth5 [root@linux-host1 network-scripts]# vim ifcfg-eth5 BOOTPROTO=static NAME=eth5 DEVICE=eth5 ONBOOT=yes NM_CONTROLLED=no MASTER=bond0 USERCTL=no SLAVE=yes 1.1.5：重启网络服务： [root@linux-host1 network-scripts]# systemctl restart network 1.1.6：验证网络是否正常： [root@linux-host1 network-scripts]# ping www.baidu.com PING www.a.shifen.com (61.135.169.125) 56(84) bytes of data. 64 bytes from 61.135.169.125: icmp_seq=1 ttl=128 time=6.17 ms 64 bytes from 61.135.169.125: icmp_seq=2 ttl=128 time=10.3 ms 64 bytes from 61.135.169.125: icmp_seq=3 ttl=128 time=5.36 ms 64 bytes from 61.135.169.125: icmp_seq=4 ttl=128 time=6.74 ms 64 bytes from 61.135.169.125: icmp_seq=5 ttl=128 time=5.71 ms 1.1.:6：可以验证当前是绑定在哪一块网卡上的： [root@linux-host1 ~]# cat /proc/net/bonding/bond0 Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011) Bonding Mode: fault-tolerance (active-backup) Primary Slave: None Currently Active Slave: eth1 #备份链路网卡 MII Status: up MII Polling Interval (ms): 100 Up Delay (ms): 0 Down Delay (ms): 0 Slave Interface: eth1 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 18:66:da:f3:34:e5 Slave queue ID: 0 Slave Interface: eth5 MII Status: up Speed: 1000 Mbps Duplex: full Link Failure Count: 0 Permanent HW addr: 00:0a:f7:99:ba:d1 Slave queue ID: 0 1.2：第二组配置，将eth2和eth6绑定为bond1： 1.2.1：创建bond1配置文件： [root@linux-host1 network-scripts]# cp ifcfg-bond0 ifcfg-bond1 [root@linux-host1 network-scripts]# vim ifcfg-bond1 BOOTPROTO=static NAME=bond1 DEVICE=bond1 TYPE=Bond BONDING_MASTER=yes BOOTPROTO=static NAME=bond1 ONBOOT=yes BONDING_OPTS=&quot;mode=1 miimon=100&quot; BRIDGE=br1 1.2.2：配置br1： TYPE=Bridge BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=br1 DEVICE=br1 ONBOOT=yes IPADDR=X.X.X.X NETMASK=255.255.255.0 GATEWAY=X.X.X.X DNS1=X.X.X.X 1.2.3：eth2的配置： [root@linux-host1 network-scripts]# vim ifcfg-eth2 BOOTPROTO=static NAME=eth2 DEVICE=eth2 ONBOOT=yes NM_CONTROLLED=no MASTER=bond1 USERCTL=no SLAVE=yes 1.2.4：eth6的配置： [root@linux-host1 network-scripts]# vim ifcfg-eth6 BOOTPROTO=static NAME=eth6 DEVICE=eth6 ONBOOT=yes NM_CONTROLLED=no MASTER=bond1 USERCTL=no SLAVE=yes 1.2.5：重启网络服务： [root@linux-host1 network-scripts]# systemctl restart network 1.2.6：测试内网网络是否正常： [root@linux-host1 network-scripts]# ping 192.168.20.12 PING 192.168.20.12 (192.168.20.12) 56(84) bytes of data. 64 bytes from 192.168.20.12: icmp_seq=1 ttl=64 time=1.86 ms 64 bytes from 192.168.20.12: icmp_seq=2 ttl=64 time=0.570 ms 64 bytes from 192.168.20.12: icmp_seq=3 ttl=64 time=0.410 ms 1.3：设置开机启动： [root@linux-host1 network-scripts]# vim /etc/rc.d/rc.local ifenslave eth1 eth5 ifenslave eth2 eth6 [root@linux-host1 network-scripts]# chmod a+x /etc/rc.d/rc.local 1.4：重启系统后验证网络]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>linux网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpd]]></title>
    <url>%2F2017%2F10%2F18%2Fhttpd%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. 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]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本三剑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本三剑客之awk]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk%2F</url>
    <content type="text"><![CDATA[文本处理三剑客之awk Awk的用户使用指南awk用户指南 相关链接文章：正则表达式： 正则表达式grep文本编辑： grep用法sed文本编辑： sed用法 总结对比一下这三个剑客的特长之处grep、sed、awk被称为linux中的三剑客 grep更适合单纯的查找或匹配文件.sed更适合编辑皮匹配到的文本awk更适合格式化文本，对文本进行比较复杂格式处理 文本三剑客都是默认逐行处理，自带循环sed 可以对文本进行修改，而grep&amp;awk 只是对文本进行过滤,不进行内容修改 awk中的-F后面的分隔符,要用单引号’’,双引号””会产生弱引用,比如特殊符号’\\‘ ‘\\$’关于awk中的单引号和双引号的问题参照：awk中的输入分隔符单引号&amp;双引号 学习awk的一个重要知识点 先举两个例子： awk &apos;/^UUID/&apos; /etc/fstab = awk &apos;/^UUID/{print $0}&apos; /etc/fstab 其实是隐藏了{print $0}的写法 数组中的例子 awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6 实际上是隐藏了{print $0} 学习中遇到的混淆的问题：&apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印 而后面的数组里的是加了双括号{}，即用的patter的空模式，即文本中的每一行都处理 Awk基本用法和功能以及各个功能示例：awk介绍awk基本用法awk变量awk格式化-printfawk操作符awk条件判断awk循环awk数组awk函数调用系统命令 awk介绍：whatis awk？ awk：Aho, Weinberger, Kernighan，报告生成器，格式化文本输出，输出成报表格式 linux上默认使用 GNU awk(gawk) [root@centos7 data]which awk /usr/bin/awk [root@centos7 data]ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Sep 19 11:45 /usr/bin/awk -&gt; gawk which awk=/usr/bin/awk 是gawk的软链接 awk基本用法awk [options] &apos;program&apos; var=value file… awk [options] -f programfile var=value file… awk [options] &apos;BEGIN{action;… }pattern{action;… }END{action;… }&apos; file ... awk 程序可由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句 块，共3部分组成 program 通常是被放在单引号中 选项： -F “分隔符” 指明输入时用到的字段分隔符 -v var=value 变量赋值 基本格式：awk [options] &apos;program&apos; file… Program：pattern{action statements;..} 也就是说awk用法：awk [options] &apos;pattern{action statements;..}&apos; file… pattern和action • pattern部分决定动作语句何时触发及触发事件 BEGIN,END • action statements对数据进行处理，放在{}内指明 print, printf 分割符、域和记录 • awk执行时，由分隔符分隔的字段（域）标记$1,$2...$n称为域标识。$0 为所有域，注意：此时和shell中变量$符含义不同 • 文件的每一行称为记录 • 省略action，则默认执行 print $0 的操作 print格式：print item1, item2, ... 要点： (1) 逗号分隔符 (2) 输出item可以字符串，也可是数值；当前记录的字段、变量或awk的表达式 (3) 如省略item，相当于print $0 用法解析及示例：$0=代表处理的整行的内容 $1,$2,$3..代表每一列，也就域 BEGIN，END是为生成一个报表的头和尾准备的，用法通常为： BEGIN：为生成报告模式 添加表头;END:为生成的报告 进行信息汇总 awk &apos;BEGIN{print xxx}{print xxx}END{print xxx}&apos; 注意：BEGIN{print *xxx}处理文本前，打印一遍xxx的内容当成表头 END{print xxx},处理文本后，打印一遍xxx的内容作为表尾 BEGIN&amp;ENDBEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。 END：让用户在最后一条输入记录被读取之后发生的动作。 分隔符：awk默认使用空白符作为字段或列的分隔符；多个空白符被认为是一个，空白符包括空格，tab键/t，回车\n 也可以自定义-F&quot;分隔符&quot;自定义分隔符 print&amp;printf的区别：print命令只是单纯的把特定的内容进行打印，默认换行 printf命令可以把内容以灵活的格式进行显示,如左对齐,右对齐 示例1.awk支持标准输入输出，后面可以不跟文件 [root@centos7 ~]#awk &apos;{print $0}&apos; aaaa aaaa abcabc abcabc 2.打印/etc/passwd：对比几个输出结果 awk &apos;{print $0}&apos; /etc/passwd 把passwd文件全部打印出来 awk &apos;{print &quot;abc&quot;}&apos; /etc/passwd 读入的是passwd文件所有行，打印的是abc awk -v abc=1 &apos;{print abc}&apos; /etc/passwd 读入的是passwd文件所有行，打印的都是1 awk &apos;{print &quot;abc&quot;$0}&apos; /etc/passwd 把passwd文件所有行前都加一个abc,进行输出 所以在awk中不加双引号，abc被识别为变量，如果要引用变量，需要-v先定义值 如果只是想输出abc字符串，需要加双引号 3.awk{}中支持数字运算 awk &apos;{print 1+2}&apos; /etc/passwd 打印多行1+2=3的值 awk &apos;{print &quot;1+2&quot;}&apos; /etc/passwd 加双引号会把1+2当成字符串，输出多行1+2 4.取分区利用率df, df |awk &apos;{print $1,$5}&apos;| awk -F&quot;%&quot; &apos;{print $1}&apos; 5.以输入重定向方式，打印 passwd 文件的第1列，即获取当前系统中存在的所有用户和UID awk -F: &apos;{print $1,$3}&apos; &lt; /etc/passwd cat /etc/passwd | awk -F: &apos;{print $1,$3}&apos; awk -F: &apos;{print $1：$3}&apos; /etc/passwd 两列输出时，指定以：进行隔开，默认为空格隔开 awk -F: &apos;{print $1、$3}&apos; /etc/passwd 两列输出时，指定以：进行隔开，默认为空格隔开 cat /etc/passwd | awk -F: &apos;{print $1&quot;\n&quot; $3}&apos; 两列输出时,进行换行 cat /etc/passwd | awk -F: &apos;{print $1&quot;\t&quot; $3}&apos; 两列输出时,以tab键隔开 备注：多行输出时，可以在双引号之间加自定义的分隔符 格式：awk -F: &apos;{print $1&quot;=======&quot;$3}&apos; /etc/passwd Awk中的变量：变量分为：内置变量和自定义变量awk中的内置变量除了$0,$1,$2等，还有以下几种； 如果要使用这些变量需要加-v 选项先进行定义 FS：输入字段分隔符，默认为空白字符 =filed separator=域或列的分隔符 等于-F的选项，-F是选项，而FS是变量，实际作用是相等的 与-F的区别在于：可以下次调用FS变量 awk -v FS=&apos;:&apos; &apos;{print $1,$3}&apos; /etc/passwd = awk -F:&apos;{print $1,$3}&apos; /etc/passwd awk -v FS=&apos;:&apos; &apos;{print $1,FS$3}&apos; /etc/passwd 两列输出时以：做分隔符，调用变量FS awk -v FS=&apos;:&apos; &apos;{print $1,FS FS$3}&apos; /etc/passwd 两列输出时以：：做分隔符，调用2次变量FS 以空格隔开 可以先定义shell中的变量fs=:,awk再进行调用 fs=:;awk -v FS=$fs &apos;{print $1,FS,$3}&apos; /etc/passwd fs=:;awk –F$fs &apos;{print $1,$3,$7}&apos; /etc/passwd OFS：输出字段分隔符，默认为空白字符 =output filed separator 定义输出分隔符，不指定默认空空格做分隔符 awk -v FS=: -v OFS=+++ &apos;{print $1,$3,$7}&apos; /etc/passwd fs=+++;awk -v FS=: -v OFS=$fs &apos;{print $1,$3}&apos; /etc/passwd 调用shell变量做输出分隔符 RS：输入记录分隔符，指定输入时的换行符,自定义行的分隔符 =record记录 默认一行叫记录，行是以\n回车作为切割符的，RS可以自定义不用回车作为分隔符 awk -v RS=&apos; &apos; ‘{print }’ /etc/passwd awk -v RS=&apos;:&apos; &apos;{print NR,$0}&apos;/etc/passwd [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print $0}&apos; aa;xxx bb;bzzzz cc dd eex;zccc xxxx 以RS=：冒号自定义行的分隔符，输出结果如上 [root@centos7 ~]#cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; &apos;{print $1}&apos; aa bb cc dd eex xxxx 自定义FS&amp;RS，输出结果如上 ORS：输出记录分隔符，输出时用指定符号代替换行符 awk -v RS=&apos; &apos; -v ORS=&apos;###&apos;‘{print }’ /etc/passwd [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v FS=&quot;;&quot; -v RS=&quot;:&quot; -v ORS&quot;===&quot; &apos;{print $1}&apos; aa==bb==cc dd==eex==xxxx == 自定义FS,RS,ORS结果很明显 接下来是一个比较重要的变量 NF：字段数量,也就是域或列的总数量 awk -F: &apos;{print NF}&apos; /etc/passwd 以冒号做分隔符，显示每行的列的总数量 awk -F: &apos;{print $NF}&apos; /etc/passwd 显示以冒号做分隔符，每一行的最后一个字段即bash类型 awk -F：&apos;{print $(NF-1)}&apos; /etc/passwd 显示以冒号做分隔符，每一行的倒数第二个字段 统计光盘中所有安装包适用的cpu架构类型 root@centos7 mnt]#ls /mnt/Packages/*.rpm | awk -F&quot;.&quot; &apos;{print $(NF-1)}&apos;|sort|uniq -c 1371 noarch 2600 x86_64 NR：记录号，可以显示行数，如果有多个文件会合并后再统计总行 awk &apos;{print NR,$0}&apos; /etc/fstab 在每一行前加一个行号 awk BEGIN&apos;{print NR}&apos; /etc/fstab 输出结果为0 awk还没开始处理行，所以记录为0 awk END&apos;{print NR}&apos; /etc/fstab 输出结果为12 可以看出END是统计,awk处理的行数 1.通过加行号，可以很明显看出以冒号作为行的分隔符，每一行的都有什么；可以看出cc dd是一行的 [root@centos7 ~]cat f1 aa;xxx:bb;bzzzz:cc dd:eex;zccc:xxxx [root@centos7 ~]cat f1| awk -v RS=&quot;:&quot; &apos;{print NR$0}&apos; 1aa;xxx 2bb;bzzzz 3cc dd 4eex;zccc 5xxxx 2.备注：如果awk跟两个文件，awk会把两文件合并成一个文件，统计总行数，都取第一个字段的信息 如果需要分开显示统计，则用FNR [root@centos7 ~]awk -F: &apos;{print NR,$1}&apos; /etc/passwd /etc/group 1 root 2 bin 3 daemon 4 adm FNR：各文件分别计数,记录号 1.FNR:多个文件，每个分别统计显示第一个字段并列出来 awk &apos;{print FNR}&apos; /etc/fstab /etc/inittab [root@centos7 ~]awk -F: &apos;{print FNR,$1}&apos; /etc/passwd /etc/group 1 root 2 bin 3 daemon 48 quagga 49 httpd 1 root 2 bin FILENAME：当前文件名 1.统计时，加上变量可以显示文件名 awk &apos;{print FILENAME}&apos; /etc/fstab [root@centos7 ~]awk -F: &apos;{print FILENAME,FNR,$1}&apos; /etc/passwd /etc/passwd 1 root /etc/passwd 2 bin /etc/passwd 3 daemon ARGC：命令行参数的个数 awk &apos;{print ARGC}&apos; /etc/fstab /etc/inittab 结果为3 awk &apos;BEGIN {print ARGC}&apos; /etc/fstab /etc/inittab 结果为3 ARGC统计参数：awk单独算一个参数，后面的每个文件算一个参数,通过下面的数组可以体现出来 ARGV：数组，保存的是命令行所给定的各参数 1.显示awk的每个参数分别是哪个 [root@centos7 ~]awk &apos;{print ARGV[0]}&apos; /etc/fstab /etc/inittab awk [root@centos7 ~]awk &apos;{print ARGV[1]}&apos; /etc/fstab /etc/inittab /etc/fstab 示例：1.统计当前网络连接情况的ip地址是 ss -nt ss -nt | awk &apos;{print $5}&apos; 2.取/var/log/httpd/access_log的时间如下： root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; 分两步取： cat /var/log/httpd/access_log | awk &apos;{print $4}&apos;|awk -F&quot;[&quot; &apos;{print $2}&apos; 一步取： cat /var/log/httpd/access_log | awk -F &quot;[\[ ]&quot; &apos;{print $5}&apos; 原理分析：[\[ ]代表（转义）\[和空格都算是分隔符，正则表达式的写法,或的关系， 而以空格分隔符，时间段为$4,那为什么是$5?在空格的标准里，[算$4,所以时间段为$5 3.取出磁盘分区利用率 -这次只取出利用率 两步取出： df | awk -F% &apos;{print $1}&apos;|awk &apos;{print $5}&apos; 一步取出： df | awk -F&quot;[[:space:]]+|%&quot; &apos;{print $5}&apos; awk用的是扩展的正则表达式 面试题：3-1,取出fstab中挂载的目录 [root@centos7 ~]cat /etc/fstab # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data xfs defaults 0 0 UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap swap defaults 0 0 [root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos; boot data swap 或者 [root@centos7 ~]cat /etc/fstab | awk -F&quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos; boot data swap 4.面试题：将文件f3中的第一个点前的字符串取出再写进去 [root@centos7 ~]cat f3 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4.news.sina.com.cn [root@centos7 ~]cat f3 | awk -F&quot;[ .]&quot; &apos;{print $2}&apos; &gt;&gt; f3 [root@centos7 ~]cat f3 1 test.sina.com.cn 2 music.sina.com.cn 3 sports.sina.com.cn 4.news.sina.com.cn test music sports news 4-1,扩展 前面-F&quot;[ .]&quot;既然是表达或的意思，那么是否可以这么写-F&quot;[ ]|.&quot;？？？ 答案：不可以！ 原因：因为此处用的是正则表达式，在正则表达式中点(.)代表任意单个字符，会把空格后的字母当成分隔符！ 所以是不可以的，那么如何写？ 如果不是点而是%呢？%是可以的，因为在正则表达式中%就是代表%， 但是$,或其他在正则表达式中有特殊含义的不可以作为分隔符，如果一定要做分隔符，需要反斜线转义 如下： 此处用3个反斜线转义 [root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\.&quot; &apos;{print $2}&apos; test music sports news 那如果文本中的第一个点是$呢？ 此处是4个反斜线进行转义 [root@centos7 ~]cat f2 1 test$sina.com.cn 2 music$sina.com.cn 3 sports$sina.com.cn 4 news$sina.com.cn [root@centos7 ~]cat f2 | awk -F&quot;[ ]|\\\\$&quot; &apos;{print $2}&apos; test music sports news [root@centos7 ~]cat f2 | awk -F&quot;[ $]&quot; &apos;{print $2}&apos; test music sports news 当用一个空格和具有特殊含义的符号时，最好是写在中括号[]里的 AWK中自定义变量自定义变量(区分字符大小写) (1) -v var=value (2) 在program中直接定义 (2-1)program可以放到一个文本里,awk -f 直接调用即可 示例：自定义变量可以-v var定义，也可以放到program即{}里，变量要先定义，后使用 awk -F: &apos;{name=&quot;magedu&quot;;print $1,name}&apos; /etc/passwd awk -F: -v name=&quot;magedu&quot; &apos;{print $1,name}&apos; /etc/passwd 例如 cat awk.txt {print $1,$2,$6} awk -F： -f awk.txt /etc/passwd =awk -F: &apos;{print $1,$2,$6}&apos; /etc/passwd Awk中的格式化在介绍printf前，先对其进行总结：1.使用printf动作输出的文本不会换行，如果需要换行，可以在对应的格式替换符后加入”\n”进行转义2.使用printf动作时，指定的格式和被格式化的文本之间，需要用”逗号”隔开。3.使用printf动作时，格式中的格式替换符比喻与被格式化的文本一一对应 printf命令-类似于shell里的printfprintf命令可以把内容以灵活的格式进行显示，如左对齐,右对齐 格式化输出：printf &quot;FORMAT&quot;, item1, item2, ... (1) 必须指定FORMAT (2) 不会自动换行，需要显式给出换行控制符，\n (3) FORMAT中需要分别为后面每个item指定格式符 格式符：与item一一对应 %c：显示字符的ASCII码 %d, %i：显示十进制整数 -用的比较多 %e, %E：显示科学计数法数值 %f：显示为浮点数 %g, %G：以科学计数法或浮点形式显示数值 %s：显示字符串 -用的比较多 %u：无符号整数 -用的比较多 %%：显示%自身 修饰符 #[.#] 第一个数字控制显示的宽度；第二个#表示小数点后精度，%3.1f + 左对齐（默认右对齐） %-15s * 显示数值的正负符号 %+d printf示例：1.设置对齐格式以及字符数 [root@centos7 ~]awk -F: &apos;{printf &quot;%-20s %-5d\n&quot;,$1,$3}&apos; /etc/passwd root 0 bin 1 pulse 171 gdm 42 gnome-initial-setup 990 $1为字符串，所以设置左对齐为20s个字符，$3为数字所以设置左对齐为5d个字符 printf默认不换行，所以需要加一个换行符 2.打印一个完整的报表格式 root@centos7 ~]awk -F: &apos;BEGIN{print &quot;username |uid\n--------&quot;} {printf &quot;%-10s |%-5d\n&quot;,$1,$3}END{print &quot;-------------&quot;}&apos; /etc/passwd username |uid ----------------------- root |0 bin |1 daemon |2 memcached |987 ceshi |1009 quagga |92 httpd |80 ------------------------- awk生成报表格式大概就是这个样子，所以awk称为报表生成器 3. [root@centos7 ~]awk -F: &apos;{printf &quot;Username: %s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwd Username: root,UID:0 Username: bin,UID:1 Username: daemon,UID:2 Username: adm,UID:3 4. [root@centos7 ~]awk -F: &apos;{printf &quot;Username: %-15s,UID:%d\n&quot;,$1,$3}&apos; /etc/passwd Username: root ,UID:0 Username: bin ,UID:1 Username: daemon ,UID:2 awk操作符a.算术操作符： x+y, x-y, x*y, x/y, x^y, x%y - x：转换为负数 +x：将字符串转换为数值 字符串操作符：没有符号的操作符，字符串连接 赋值操作符： =, +=, -=, *=, /=, %=, ^=，++, --, b.比较操作符： ==, !=, &gt;, &gt;=, &lt;, &lt;= 模式匹配符： ~：左边是否和右边匹配包含 !~：是否不匹配 c.逻辑操作符：与&amp;&amp;，或||，非! d.条件表达式（三目表达式） selector?if-true-expression:if-false-expression 表达式；if-ture-xx:else-xxx eg:x&gt;y?var=x;var=y 操作符用法示例：1.下面两语句有何不同 • awk &apos;BEGIN{i=0;print ++i,i}&apos; 结果 1 1 • awk &apos;BEGIN{i=0;print i++,i}&apos; 结果 0 1 实际上AWK的语法是采用VC语言风格的 2.示例： awk中~&amp;!~是否包含的用法： [root@centos7 ~]awk -F: &apos;$0 ~ /root/{print $1}&apos; /etc/passwd root operator 意思是如果过滤的行中有包含root字符串的，则打印出这行的用户名 用到下文提到的patter模式，在这里是匹配是否包含root字符串 [root@centos7 ~]awk -F: &apos;$0 ~ &quot;/root&quot;{print $1}&apos; /etc/passwd root operator 区别上面的这个写法，在这里是包含/root字符串的行 [root@centos7 ~]awk -F: &apos;$0 !~ /root/{print $1}&apos; /etc/passwd bin daemon adm 和上面的命令刚好相反，如果行不包含字符串root，则打印该行用户名 [root@centos7 ~]awk -F: &apos;$3==0&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 意思：判断UID是否等于0，是则打印该行，判断是否为管理员 [root@centos7 ~]awk &apos;$0~&quot;^root&quot;&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 意思：判断该行是不是以root开头的行，是则打印 3.awk中的与&amp;&amp;，或|| 非!的使用示例： 示例： • awk –F: &apos;$3&gt;=0 &amp;&amp; $3&lt;=1000 {print $1}&apos; /etc/passwd 如果0&lt;=UID&lt;=1000，则打印出该用户 • awk -F: &apos;$3==0 || $3&gt;=1000 {print $1,$3}&apos; /etc/passwd 打印出UID等于0和UID&gt;=1000的用户名和他的UID • awk -F: &apos;!($3==0) {print $1}&apos; /etc/passwd -要加括号 打印出UID不等于0的用户名 • awk -F: &apos;!($3&gt;=500) {print $3}&apos; /etc/passwd 如果UID&lt;=500,时，打印出该用户的UID 4.AWK中的条件判断表达式 即三目表达式 相当于把shell中的if;then,else,fi的放到awk中 • 示例： [root@centos7 ~]awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd sys root 0 sys bin 1 sys tcpdump 72 common test 1000 common nginx 1008 判断用户是否为系统用户，是则打印并在开头加common,不是也打印在开头加sys awk中的PATTERN和action模式匹配和处理动作=sed的地址定界+修饰符功能：和sed中的pattern一样起到过滤的功能，=sed的地址定界 PATTERN:根据pattern条件，过滤匹配的行，再做处理(1)如果未指定：空模式，匹配每一行 (2) /regular expression/：仅处理能够模式匹配到的行，需要用/ /括起来 awk &apos;/^UUID/{print $1}&apos; /etc/fstab awk &apos;!/^UUID/{print $1}&apos; /etc/fstab awk的匹配模式支持的是扩展的正则表达式 注意：不支持直接给出数字格式，但是可以变向的打印输出，详见下面的示例 (3) relational expression: 关系表达式，结果为“真”才会被处理 真：结果为非0值，非空字符串 假：结果为空字符串或0值都是假 字符串为空或者0为假 (4) line ranges：行范围 startline,endline：/pat1/,/pat2/ 不支持直接给出数字格式 awk -F: &apos;/^root\&gt;/,/^nobody\&gt;/{print $1}&apos; /etc/passwd awk -F: &apos;(NR&gt;=10&amp;&amp;NR&lt;=20){print NR,$1}&apos; /etc/passwd NR表示行 (5) BEGIN/END模式 BEGIN{}: 仅在开始处理文件中的文本之前执行一次 END{}：仅在文本处理完成之后执行一次 模式：指定一个行的范围。该语法不能包括BEGIN和END模式。BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。END：让用户在最后一条输入记录被读取之后发生的动作。 patter用法示例：先写一个特殊的用法 1.当在awk命令中使用正则模式时，使用到的正则用法属于&quot;扩展的正则表达式&quot; 2.当使用{x,y}这种次数匹配正则表达式，需要配合--posix或者--re-interval选项 备注：这是网上找到一个示例，文中提到{x,y}必须加这个选项，然而不加选项也是可以过滤的 awk是是支持posix字符集的 [root@centos7 ~]cat f3 seex sex seeex seeeeex [root@centos7 ~]cat f3 | awk &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3 | awk -posix &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3 | awk --re-interval &apos;/se{2,3}x/{print $0}&apos; seex seeex [root@centos7 ~]cat f3|grep -E &quot;se{2,3}x&quot; seex seeex [root@centos7 ~]cat f3|sed -nr &apos;/se{2,3}x/p&apos; seex seeex 1.取系统磁盘分区空间利用率df,/dev/sd开头的分区(上文中虽然取出来了，但是没过滤) [root@centos7 ~]#df | awk -F&quot;[[:space:]]+|%&quot; &apos;/^\/dev\/sd/{print $1,$5}&apos; /dev/sda2 8 /dev/sda3 1 /dev/sda1 17 2.取当前连接主机的IP地址(上文中虽然取出来了，但是没过滤) [root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $6}&apos; 192.168.34.1 192.168.34.105 或者用NF的表达方式 [root@centos7 ~]ss -nt| awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos; 192.168.34.1 192.168.34.105 3.取登录当前系统失败（lastb）用户的IP [root@centos7 ~]#lastb root ssh:notty 192.168.34.105 Sun Nov 11 17:25 - 17:25 (00:00) root23 ssh:notty 192.168.34.1 Mon Nov 5 15:43 - 15:43 (00:00) btmp begins Fri Nov 2 09:58:52 2018 [root@centos7 ~]#lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c 3 192.168.34.1 1 192.168.34.101 因为最后一行有btmp这样的字样，只能通过包含的功能来过滤掉最后一行 如果要取失败连接次数大于3的扔到防火墙，可以先取出来 root@centos7 ~]lastb|awk &apos;$3 ~ /[[:digit:]]/{print $3}&apos;|sort|uniq -c| awk &apos;$1 &gt;=3{print $2}&apos; 192.168.34.1 4.patter中为关系表达式的示例 空字符串或0值都是假，其他为真 awk &apos;0{print $0}&apos; /etc/passwd -0为假，结果为空 awk &apos;&quot;&quot;{print $0}&apos; /etc/passwd -空也为假，结果为空 awk &apos;1{print $0}&apos; /etc/passwd -1为真 awk &apos;&quot; &quot;{print $0}&apos; /etc/passwd -空白符也为真 awk -v abc=&quot; &quot; &apos;abc{print $0}&apos; /etc/passwd -abc为空白,不是空字符串,也为真 awk -v abc=&quot; &quot; &apos;! abc{print $0}&apos; /etc/passwd -abc为空白,为真,对真取反，结果为假 5.awk中patter的地址定界 root@centos7 ~]#awk -F: &apos;/^root/,/^adm/{print $0}&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin 打印以root开头的行到以adm开头的行之间的所有行 等于 sed -nr &apos;/^root/,/^adm/p&apos; /etc/passwd 6.如何打印从多少行到多少行之间的行？？ [root@centos7 ~]#awk -F: &apos;NR&gt;=10 &amp;&amp; NR&lt;=12 {print NR,$0}&apos; /etc/passwd 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 通过变量NR变向的打印出行 7.取出/etc/fstab配置文件中以UUID开头的行 [root@centos7 ~]#cat /etc/fstab | awk &apos;/^UUID/{print $0}&apos; UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 效果等于 grep &quot;^UUID&quot; /etc/fstab 效果等于 sed -n &apos;/^UUID/p&apos; /etc/fstab 8. awk &apos;!0&apos; /etc/passwd =awk &apos;!0{print $0}&apos; /etc/passwd 省略了{print $0}的写法 结果为真，即打印全部行 root@centos7 ~]#awk -F: &apos;i=1;j=1{print i,j}&apos; /etc/passwd root:x:0:0:root:/root:/bin/bash 1 1 bin:x:1:1:bin:/bin:/sbin/nologin 1 1 ？？？ [root@centos7 ~]#awk -F: &apos;$NF ~ /bash$/{print $1,$NF}&apos; /etc/passwd root /bin/bash test /bin/bash 判断用户shell是否为/bin/bash，是则打印用户名和shell类型，此处用变量NF来实现 效果等于 awk -F: &apos;$NF==&quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd 效果等于 awk -F: &apos;$7 == &quot;/bin/bash&quot;{print $1,$NF}&apos; /etc/passwd 效果等于 awk -F: &apos;$0 ~ /bash$/{print $1,$NF}&apos; /etc/passwd 9.打印奇数行和偶数行 [root@centos7 ~]#seq 6 | awk &apos;i=!i&apos; 打印奇数行 1 3 5 原理：i初始值为空，为假，取反时，则打印第一行，此时i=1 i=1时，为真，取反为假，所以第二行不打印，然后i=0 依次类推所以只打印奇数行 [root@centos7 ~]#seq 6 | awk &apos;!(i=!i)&apos; 打印偶数行 2 4 6 效果等于 seq 10 |awk -v i=1 &apos;i=!i&apos; 原理：同上，只要先定义i=1，为真，第一行就不打印了 或者用sed打印奇数行和偶数行(用sed步进的方式) seq 6 | sed -n &apos;1~2p&apos; 打印奇数行 seq 6 | sed -n &apos;2~2p&apos; 打印偶数行 awk actionaction除了上文中支持的算术、条件判断，表达式，还支持循环，输入语句，输出语句、组合语句等功能• (1) Expressions:算术，比较表达式等 • (2) Control statements：if, while等 • (3) Compound statements：组合语句 • (4) input statements • (5) output statements：print等 下面专门研究awk的控制语句包含if,while,do,for,break,continue,数组，exit等控制语句awk中if-else控制语句的语法及用法语法： 双分支if if(condition){statement;…}(多条语句用;隔开)[else statement] 多分支if if(condition1){statement1}else if(condition2){statement2}else{statement3} 使用场景：对awk取得的整行或某个字段做条件判断 if-else示例：如判断考试分数，写法如下 [root@centos7 ~]awk -v score==80 &apos;BEGIN{if(score &lt;60){print &quot;no pass&quot;} else if(score &lt;=80){print &quot;soso&quot;}else {print good}}&apos; soso awk -F: &apos;{if($3&gt;=1000)print $1,$3}&apos; /etc/passwd 判断UID是否大于1000，是则打印用户名和UID awk -F: &apos;{if($NF==&quot;/bin/bash&quot;) print $1}&apos; /etc/passwd 判断用户shell是否为/bin/bash,是则打印用户名 awk &apos;{if(NF&gt;5) print $0}&apos; /etc/fstab 判断域或列个数是否大于5，是则打印该行 awk -F: &apos;{if($3&gt;=1000) {printf &quot;Common user: %s\n&quot;,$1} else {printf &quot;root or Sysuser: %s\n&quot;,$1}}&apos; /etc/passwd 等于上文中的 awk -F: &apos;{$3&gt;=1000?name=&quot;common&quot;:name=&quot;sys&quot;;print name,$1,$3}&apos; /etc/passwd 例如：随机生成1000个数字，用awk取出最大值和最小值(可以用shell写法) 1.生成1000个数字 for i in {1..1000};do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f1.txt;else echo -e &quot;,$RANDOM\c&quot; &gt;&gt; f1.txt ;fi;done 2.用awk取出最大值和最小值 awk -F&apos;,&apos; &apos;{i=2;max=$1,while(i&lt;=NF){if($i &gt; max){max=$i}else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; f1.txt 验证用awk是否取出的值为正确的： 方法一：用tr验证 tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | head -n1 tr &apos;,&apos; &apos;\n&apos; &lt; f1.txt | sort -nr | tail -n1 方法二：用shell脚本验证 #!/bin/bash for i in {1..1000};do awk中的循环不是对行的循环，因为awk本身就支持文本中行的循环，这里是指对每一行中的字段或域或列进行循环，分别对行中的每个字段进行循环处理awk中while循环控制语句的语法及用法语法：while(condition){statement;…} 条件“真”，进入循环；条件“假”，退出循环 使用场景： 对一行内的多个字段逐一类似处理时使用 对数组中的各元素逐一处理时使用 此时涉及到系统自带的一个函数length(函数在下面会有介绍) 示例： 1.统计每一行第一个字段的长度 root@centos7 ~]awk -F: &apos;{print length($1),$1}&apos; /etc/passwd 4 root 3 bin 6 daemon 3 adm 2.统计/etc/passwd第一行的每个字段的长度 [root@centos7 ~]awk -F: &apos;NR==1{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/passwd root 4 x 1 0 1 0 1 root 4 /root 5 /bin/bash 9 3.统计grub2.cfg文件中linux16那行的每个字段的长度 [root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){print $i,length($i);i++}}&apos; /etc/grub2.cfg linux16 7 /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 ro 2 crashkernel=auto 16 rhgb 4 quiet 5 LANG=en_US.UTF-8 16 linux16 7 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 ro 2 crashkernel=auto 16 rhgb 4 quiet 5 4.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用while循环 root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{i=1;while(i&lt;=NF){if(length($i)&gt;=10) {print $i,length($i)};i++}}&apos; /etc/grub2.cfg /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 LANG=en_US.UTF-8 16 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 5.面试题 用awk取出文本f5的最大值和最小值，需要先生成1000个随机数存到f5中 如何做？ 1.不用awk，可以通过脚本实现最大值和最小值 2.用awk如何来做？？ 先生成1000个随机数 [root@centos7 ~]for i in `seq 1000`;do if [ $i -eq 1 ];then echo -e &quot;$RANDOM\c&quot; &gt;&gt; f5; else echo -e &quot;,$aRANDOM\c&quot; &gt;&gt; f5 ;fi;done 生成了1000随机数，如何取最大值最小值？ [root@centos7 ~]awk -F&quot;,&quot; &apos;{i=2;max=$1;min=$1;while(i&lt;=NF){if($i &gt; max){max=$i} else if($i &lt; min){min=$i};i++}}END{print &quot;max=&quot;max,&quot;min=&quot;min}&apos; &lt; f5 max=32643 min=60 awk中do-while循环控制语句语法：do {statement;…}while(condition) 意义：无论真假，至少执行一次循环体 do-while使用示例：求1-100正整数的和 [root@centos7 ~]awk &apos;BEGIN{ total=0;i=0;do{ total+=i;i++;}while(i&lt;=100);print total}&apos; 5050 awk中for循环控制语句语法：for(expr1;expr2;expr3) {statement;…} 常见用法： for(variable assignment;condition;iteration process) {for-body} 特殊用法：能够遍历数组中的元素 语法：for(var in array) {for-body} for循环使用示例：1.求1-100正整数的和： [root@centos7 ~]awk &apos;BEGIN{for(i=1;i&lt;=100;i++)sum+=i;print sum}&apos; 5050 2.统计grub2.cfg文件中linux16那行的字段长度大于10的字段-用for循环 [root@centos7 ~]awk &apos;/^[[:space:]]*linux16/{for(i=1;i&lt;=NF;i++){if(length($i)&gt;=10){print $i,length($i)}}}&apos; /etc/grub2.cfg /vmlinuz-3.10.0-862.el7.x86_64 30 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 LANG=en_US.UTF-8 16 /vmlinuz-0-rescue-d874c9913a8e4f4f8b615f29c9a0388e 50 root=UUID=9612633f-e7f1-4b28-8813-403d209d7abc 46 crashkernel=auto 16 awk中的switch控制语句类似于shell中的case语句 语法：switch(expression) {case VALUE1 or /REGEXP/: statement1; caseVALUE2 or /REGEXP2/: statement2; ...; default: statementn} awk中的continue,break，next控制语句break和continuenext:提前结束对本行处理而直接进入下一行处理（awk自身循环） continue的示例求1000以内偶数的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==0)continue;sum+=i}print sum}&apos; 2500 求1000以内奇数的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i%2==1)continue;sum+=i}print sum}&apos; 2550 求1000以内除了66的所有数字的和 [root@centos7 ~]awk &apos;BEGIN{sum=0;for(i=1;i&lt;=100;i++){if(i==66)continue;sum+=i}print sum}&apos; 4984 break的示例：求1000数字中，当大于100时，跳出循环，即求100以内的和 [root@centos7 ~]#awk &apos;BEGIN{sum=0;for(i=1;i&lt;=1000;i++){if(i&gt;100)break;sum+=i}print sum}&apos; 5050 next的示例：因为提前结束对本行处理而直接进入下一行处理（因为awk本身就是循环行的功能），所以示例 打印/etc/passwd下的奇数行 [root@centos7 ~]awk -F: &apos;{if(NR%2==0)next;print NR,$0}&apos; /etc/passwd 1 root:x:0:0:root:/root:/bin/bash 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 还可以这样写：awk -F: &apos;NR%2==1{print NR,$0}&apos; /etc/passwd awk数组-一个非常使用的功能awk的数组全都是关联数组关联数组：array[index-expression] index-expression: • (1) 可使用任意字符串；字符串要使用双引号括起来 • (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值 初始化为“空串” • (3) 若要判断数组中是否存在某元素，要使用“index in array”格式进行遍历 数组的去重的效果示例：awk &apos;!arr[$0]++&apos; dupfile awk &apos;{!arr[$0]++;print $0, arr[$0]}&apos; dupfile echo abc abc ccc bcd ddd ddd abc abc &gt;&gt; f1.txt awk关联数组的遍历：若要遍历数组中的每个元素，要使用for循环:因为关联数组下标是无序性 for(var in array) {for-body} 注意：var会遍历array的每个索引 数组的使用示例：示例1.定义awk数组 [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;; title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]}&apos; zhang 可以用for循环把每一个数组的值都表示出来 [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;print title[&quot;ceo&quot;]; for(i in title){print i,title[i]}}&apos; zhang coo liu ceo zhang cto wang 但输出时数组元素时，是无序的，这就是关联数组的特性 示例2.awk数组中的重要功能 [root@centos7 ~]cat f6 abc abc ddd ccc aaa ccc ccc [root@centos7 ~]awk &apos;!line[$0]++&apos; f6 abc ddd ccc aaa 问题：为什么执行结果是这个？？ 原因： awk &apos;!line[$0]++&apos; f6 = awk &apos;!line[$0]++{print $0}&apos; f6 实际上是隐藏了{print $0}，这个隐藏功能在awk很重要！！！， 但是要和后面patter中的空模式区别开 &apos;!line[$0]++&apos;= &apos;!line[$0]++{print $0}&apos;是省略了写法，是patter的关系表达式中，先判断再打印 而后面的数组里的是加了双括号{}，{line[$0]++}即用的patter的空模式，即文本中的每一行都处理 这两个写法是不一样的，别混淆了 分析： 基于这个考虑进行分析 &apos;!line[$0]++&apos; = &apos;!line[$0]++{print $0}&apos; 当读取文本f6的第一行时=abc !line[&quot;abc&quot;]++，因为abc没有值，line[&quot;abc&quot;]=0为假，取反！line[&quot;abc&quot;]后为真 所以把第一行的abc打印了一次，打印第一行结束后line[&quot;abc&quot;]=1 当读取文本f6的第二行时=abc !line[&quot;abc&quot;]++，在之前基础上line[&quot;abc&quot;]=1为假，取反！line[&quot;abc&quot;]=0后为假 所以把第二行的abc不打印，结束后line[&quot;abc&quot;]=2 以此类推，发现后续出现abc都不会打印，但是line[&quot;abc&quot;]都会在之前的基础上+1，即达到去重并统计的目的 而处理第三行!line[&quot;ddd&quot;]++时，和上述abc一样，第一次出现则打印，后续也不会打印 所以，命令执行结果为去重的效果 从这个命令执行结果也可以明显看到上述的分析结果 可以看出abc的值是递增的，也就是abc出现的次数 [root@centos7 ~]awk &apos;{!line[$0]++;print $0, line[$0]}&apos; f6 abc 1 abc 2 ddd 1 ccc 1 aaa 1 ccc 2 awk数组中的重要功能之for循环遍历数组，很具有实用性在后面的统计服务的一些日志文件很有作用如果要理解遍历awk数组，需要深刻理解上述的示例2:awk &apos;!line[$0]++&apos; f6是怎么实现的 但还是有些和数组里的，遍历$2,把$2不同的值，当成数组的下标有些区别的 若要遍历数组中的每个元素，要使用for循环for(var in array) {for-body} 注意：var会遍历array的每个索引 为什么要通过特殊写法去遍历awk中的数组？如果是普通数组，用循环0,1,2,3做个循环即可；而awk的数组都是关联数组，[]中括号里的下标都不固定 所以要通过 for(var in array(数组名称)) {for-body}这样的特殊写法，var的值会从array数组元素 取其下标，相当于每次循环var的值是等于array数组的下标的 注意：当我们直接引用一个数组中不存在的元素时，awk会自动创建这个元素，并且为其赋值为&quot;空字符串&quot; for循环遍历数组使用示例：示例1： [root@centos7 ~]awk &apos;BEGIN{print test[&quot;ip&quot;];test[&quot;ip&quot;]++;print test[&quot;ip&quot;]}&apos; 1 第一次输出为空，第二次自动加1 示例2： 1. [root@centos7 ~]awk &apos;BEGIN{title[&quot;ceo&quot;]=&quot;zhang&quot;;title[&quot;coo&quot;]=&quot;liu&quot;;title[&quot;cto&quot;]=&quot;wang&quot;;for(i in title){print title[i]}}&apos; liu zhang wang 分析： for(i in title){print title[i]，i的值来自于title的下标，即i=ceo coo cto,而且是无序打印 示例3： [root@centos7 ~]netstat -tan Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN tcp 0 0 192.168.122.1:53 0.0.0.0:* ESTABLISTEN tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN tcp 0 52 192.168.34.103:22 192.168.34.1:8816 ESTABLISHED tcp 0 0 192.168.34.103:22 192.168.34.105:49746 ESTABLISHED tcp6 0 0 :::111 :::* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 ::1:631 :::* LISTEN tcp6 0 0 ::1:25 :::* LISTEN [root@centos7 ~]netstat -tan | awk &apos;/^tcp/{state[$NF]++}END{for(i in state) { print i,state[i]}}&apos; LISTEN 8 ESTABLISHED 3 分析： state[$NF]++以空白做分隔符，统计同一类型的状态有多少个 for(i in state) { print i,state[i]} 即统计了出现状态的多少种以及出现的次数 不明白的可以看上文中的示例2：awk数组中的重要功能 当然，看懂这个命令，需要知道两个知识点 1.空模式，即全文反复提到的{state[$NF]++}={state[$NF]++}{print $0} 2.END模式，END的模式是在前面动作结束之后，最后执行依次END模式中的命令，所以先不用考虑空模式 下面再一次对空模式中的处理过程，做详细的描述 空模式中，我们创建了一个state数组，并将状态值(LISTEN、ESTABLISHED)作为引用下标， 所以执行到第一行时，我们引用的是state[&quot;LISTEN&quot;],很明显，这个元素并不存在，所以，当第一行被空模式的动作处理完毕后 state[&quot;LISTEN&quot;]的值已经被赋值为1了。 这时，空模式中的动作继续处理下一行，而下一行的$NF=ESTABLISTEN；state[&quot;ESTABLISTEN&quot;] 所以，state[&quot;ESTABLISTEN&quot;]第一次参与运算过程与上一个原理相同 直到再次遇到相同的状态时，使用同样一个IP地址作为下标的元素将会再次被自加 直到处理完所有的行，开始执行END模式中的动作。 而END模式中，我们打印出state数组中的所有元素的下标，以及元素对应的值。 此刻，state数组中的下标即为各种状态，元素的值即为对应状态出现的次数， 最终，我们统计出每个状态出现的次数。 3.统计/var/log/httpd/access_log，每个IP链接的次数 root@centos7 ~]cat /var/log/httpd/access_log 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET / HTTP/1.1&quot; 403 4897 &quot;-&quot; &quot;Mozil&quot; 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; 192.168.34.103 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; 192.168.34.1 - - [15/Oct/2018:22:02:35 +0800] &quot;GET /noindex/css/bootstrap.min.css&quot; [root@centos7 ~]awk &apos;{ip[$1]++}END{for(i in ip){print i,ip[i]}}&apos; /var/log/httpd/access_log 192.168.34.101 9 192.168.34.103 13 ::1 4 192.168.34.1 88 效果等于： [root@centos7 ~]awk &apos;{print $1}&apos; /var/log/httpd/access_log |sort|uniq -c 4 ::1 88 192.168.34.1 9 192.168.34.101 13 192.168.34.103 4.统计ss -nt ip链接次数 [root@centos7 ~]ss -nt State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 52 192.168.34.103:22 192.168.34.1:8816 ESTAB 0 0 192.168.34.103:22 192.168.34.105:49746 [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{ip[$(NF-2)]++}END{for(i in ip){print i,ip[i]}}&apos; 192.168.34.105 1 192.168.34.1 1 效果等于： [root@centos7 ~]ss -nt|awk -F&quot;[[:space:]]+|:&quot; &apos;/^ESTAB/{print $(NF-2)}&apos;|sort|uniq -c 1 192.168.34.1 1 192.168.34.105 5.统计/etc/fstab文件系统类型分别有多少个 [root@centos7 ~]cat /etc/fstab # /etc/fstab # Created by anaconda on Wed Sep 19 11:44:48 2018 UUID=9612633f-e7f1-4b28-8813-403d209d7abc / xfs defaults 0 0 UUID=0eba9e52-43a4-4c64-89bd-3fb639f0a6c1 /boot xfs defaults 0 0 UUID=06fe63d1-9b57-436f-ad7d-1c01c7a60aee /data xfs defaults 0 0 UUID=48e92f06-6fcb-4a21-8ba0-e7d1c5c1af39 swap swap defaults 0 0 [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos; swap 1 xfs 3 6.求下表中的男生和女生的平均成绩 [root@centos7 ~]cat f9 name sex score a m 90 b f 80 c f 99 d m 88 e m 80 如何利用awk的数组功能来求？ 思路先求男的和和女的和？ 利用两个数组？ [root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3}END{for(i in sum){print i,sum[i]}}&apos; -求男女分的和 m 258 f 179 [root@centos7 ~]cat f9|awk &apos;!/^name/{sum[$2]+=$3;num[$2]++}END{for(i in sum){print i,sum[i]/num[i]}}&apos; m 86 f 89.5 7.统计下面每个名字出现的次数 [root@centos7 ~]cat f1 Allen Phillips Green Lee William Aiden Janmes Lee Angel Jack Jack Thomas Lucas Kevin Tyler Lee William Allen [root@centos7 ~]cat f1 | awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,cuont[j]}}&apos; Tyler Angel Lucas William Thomas Green Jack Phillips Kevin awk函数awk也包括内置函数和自定义函数内置函数包括 rand,length，sub,gsub,split，system数值处理： rand(i)：返回0和1之间一个随机数 awk &apos;BEGIN{srand(); for (i=1;i&lt;=10;i++)print int(rand()*100) }&apos; 字符串处理： • length([s])：返回指定字符串的长度 • sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,“-&quot;,$1)&apos; • gsub(r,s,[t])：对t字符串进行搜索r表示的模式匹配的内容，并全部替换为s所表 示的内容 echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; • split(s,array,[r])：以r为分隔符，切割字符串s，并将切割后的结果保存至array所 表示的数组中，第一个索引值为1,第二个索引值为2,… netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}&apos; END{for (i in count) {print i,count[i]} awk内置函数之sub、gsub、split实现搜索替换切割的用法示例1： sub(r,s,[t])：对t字符串搜索r表示模式匹配的内容，并将第一个匹配内容替换为s gsub(r,s,[t])表示全局替换 sub(r,s,[t])不是贪婪模式，默认值替换搜索出来的第一个 [root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;sub(/:/,&quot;-&quot;,$1)&apos; 2008-08:08 08:08:08 只替换$1 root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$1)&apos; 2008-08-08 08:08:08 全局替换$0 [root@centos7 ~]#echo &quot;2008:08:08 08:08:08&quot; | awk &apos;gsub(/:/,&quot;-&quot;,$0)&apos; 2008-08-08 08-08-08 示例2： 统计字符串中每个字母出现的次数abcdaabbccdd [root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 3 b 3 c 3 d 3 在文章最后会用另外一种写法进行过滤(文章最后会以以空位分隔符的特殊写法来表示) awk内置函数split的切割功能示例1: 统计链接本机的IP和端口号 [root@centos7 ~]#netstat -tn Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 52 192.168.34.103:22 192.168.34.1:8816 ESTABLISHED tcp 0 0 192.168.34.103:22 192.168.34.105:49746 ESTABLISHED [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[1]]++}END{for (i in count) {print i,count[i]}}&apos; 192.168.34.105 1 192.168.34.1 1 [root@centos7 ~]netstat -tn | awk &apos;/^tcp\&gt;/{split($5,ip,&quot;:&quot;);count[ip[2]]++}END{for (i in count) {print i,count[i]}}&apos; 8816 1 49746 1 分析： split($5,ip,&quot;:&quot;)将192.168.34.1:8816进行切割，数组ip的下标1放IP地址，下标2放端口号 count[ip[1]]++ 把ip下标为1也就是IP地址，把出现的IP个数，又给count当下标，就统计每个IP出现的次数 count[ip[2]]++ 把ip下标为2也就是端口号，把出现的端口号个数，又给count当下标，就统计每个端口号出现的次数 awk中的自定义函数格式：awk自定义函数是用正规开发语言的函数格式 function name ( parameter, parameter, ... ) { statements return expression } awk自定义函数的用法：cat fun.awk,把函数写到文件中 function max(x,y) { x&gt;y?var=x:var=y return var } BEGIN{print max(i,j)} awk -v i=10 -v j=20 -f fun.awk 调用函数即可，和shell中的函数类似 awk中很实用的内置函数system命令system函数作用：在awk可以反过来调用linux里的命令示例： 空格是awk中的字符串连接符，如果system中需要使用awk中的变量可以使用 空格分隔，或者说除了awk的变量外其他一律用&quot;&quot;引用起来 示例1: 显示/boot/grub2下的文件列表；调用命令时要加双引号 [root@centos7 ~]#awk &apos;BEGIN{system(&quot;ls /boot/grub2&quot;)}&apos; device.map fonts grub.cfg grubenv i386-pc locale 或者这么写，先定义变量等于路径，再调用变量 [root@centos7 ~]#awk &apos;BEGIN{dir=&quot;/boot/grub2&quot;;system(&quot;ls &quot;dir)}&apos; device.map fonts grub.cfg grubenv i386-pc locale 调用hostname命令，显示主机名 [root@centos7 ~]#awk &apos;BEGIN{system(&quot;hostname&quot;)}&apos; centos7.localdomain 示例2： 之前处理过lastb中登录失败的IP，如果失败登录次数大于3次，扔到防火墙里， 当时是先取出IP放到文件里，然后iptables再禁用； 现在可以在awk中先取出IP,然后通过system(&quot;iptables &quot; IP)就可以直接扔到防火墙中 具体实现？ awk脚本将awk程序写成脚本，直接调用或执行 awk脚本使用示例： 1.先写文本再调用 cat f1.awk {if($3&gt;=1000)print $1,$3} awk -F: -f f1.awk /etc/passwd 2.也可以写成脚本形式 先写再调用 [root@centos7 ~]vim f2.awk #!/bin/awk -f {if($3 &gt;=1000)print $1,$3} [root@centos7 ~]./f2.awk -F: /etc/passwd nfsnobody 65534 test 1000 gentoo 1007 nginx 1008 ceshi 1009 向awk脚本传递参数格式： awkfile var=value var2=value2... Inputfile 注意：在BEGIN过程中不可用。直到首行输入完成以后，变量才可用。可以通 过-v 参数，让awk在执行BEGIN之前得到变量的值。命令行中每一个指定的变 量都需要一个-v参数 awk脚本传参使用示例：cat test.awk #!/bin/awk –f {if($3 &gt;=min &amp;&amp; $3&lt;=max)print $1,$3} chmod +x test.awk test.awk -F: min=100 max=200 /etc/passwd 工作中遇到的常用awk文本解决案例：Linux Web服务器网站故障分析常用的命令系统连接状态篇： 1.查看TCP连接状态 netstat -nat |awk &apos;{print $6}&apos;|sort|uniq -c|sort -rn 每出现一被/^tcp/模式匹配到的行，数组S[$NF]就加1，NF为当前匹配到的行的最后一个字段，此处用其值做为数组S的元素索引； netstat -n | awk &apos;/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}&apos; 或 netstat -n | awk &apos;/^tcp/ {++state[$NF]}; END {for(key in state) print key,&quot;\t&quot;,state[key]}&apos; netstat -n | awk &apos;/^tcp/ {++arr[$NF]};END {for(k in arr) print k,&quot;t&quot;,arr[k]}&apos; netstat -n |awk &apos;/^tcp/ {print $NF}&apos;|sort|uniq -c|sort -rn netstat -ant | awk &apos;{print $NF}&apos; | grep -v &apos;[a-z]&apos; | sort | uniq -c 2.查找请求数请20个IP（常用于查找攻来源）： 方法一： netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20 方法二： netstat -ant |awk &apos;/:80/{split($5,ip,&quot;:&quot;);++A[ip[1]]}END{for(i in A) print A[i],i}&apos; |sort -rn|head -n20 3.用tcpdump嗅探80端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F&quot;.&quot; ‘{print $1&quot;.&quot;$2&quot;.&quot;$3&quot;.&quot;$4}’ | sort | uniq -c | sort -nr |head -20 4.查找较多time_wait连接 netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n20 5.找查较多的SYN连接 netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more 6.根据端口列进程 netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1 网站日志分析篇1（Apache）：1.获得访问前10位的ip地址 cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10 cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’ 2.访问次数最多的文件或页面,取前20 cat access.log|awk ‘{print $11}’|sort|uniq -c|sort -nr|head -20 3.列出传输最大的几个exe文件（分析下载站的时候常用） cat access.log |awk ‘($7~/.exe/){print $10 &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -20 4.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数 cat access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -100 5.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面 cat access.log |awk ‘($7~/.php/){print $NF &quot; &quot; $1 &quot; &quot; $4 &quot; &quot; $7}’|sort -nr|head -100 6.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数 cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100 7.列出传输时间超过 30 秒的文件 cat access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -20 8.统计网站流量（G) cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’ 9.统计404的连接 awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort 10. 统计http status cat access.log |awk &apos;{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}&apos; cat access.log |awk &apos;{print $9}&apos;|sort|uniq -c|sort -rn 10.蜘蛛分析，查看是哪些蜘蛛在抓取内容。 /usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E &apos;bot|crawler|slurp|spider&apos; 网站日分析2(Squid篇）按域统计流量cat squid_access.log.tar.gz| awk &apos;{print $10,$7}&apos; |awk &apos;BEGIN{FS=&quot;[ /]&quot;}{trfc[$4]+=$1}END{for(domain in trfc){printf &quot;%st%dn&quot;,domain,trfc[domain]}}&apos; 安全篇：(ssh lastb)ssh日志中失败登录的IP，取出来 /var/log/secure awk &apos;/Failed PASSWORD/{IP[$(NF-3)]++}END{for(i in IP){print i,IP[i]}&apos; /var/log/secure 1、文件ip_list.txt如下格式，请提取”.magedu.com”前面的主机名部分并写 入到回到该文件中 1 blog.magedu.com 2 www.magedu.com … 999 study.magedu.com 2、统计/etc/fstab文件中每个文件系统类型出现的次数 [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{print $3}&apos;|sort|uniq -c |sort -nr 3 xfs 1 swap [root@centos7 ~]cat /etc/fstab | awk &apos;/^UUID/{file[$3]++}END{for(i in file){print i,file[i]}}&apos; swap 1 xfs 3 3、统计/etc/fstab文件中每个单词出现的次数 root@centos7 ~]cat /etc/fstab |awk &apos;{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(j in count){print j,count[j]}}&apos; man 1 4、提取出字符串Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw中的所有数字 [root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|awk &apos;gsub(/[^0-9]/,&quot;&quot;,$0)&apos; 05973 [root@centos7 ~]echo &quot;Yd$C@M05MB%9&amp;Bdh7dq+YVixp3vpw&quot;|tr -dc &quot;[0-9]&quot; 05973 5、有一文件记录了1-100000之间随机的整数共5000个，存储的格式 100,50,35,89…请取出其中最大和最小的整数 6、解决DOS攻击生产案例：根据web日志或者或者网络连接数，监控当某个IP 并发连接数或者短时内PV达到100，即调用防火墙命令封掉对应的IP，监控频 率每隔5分钟。防火墙命令为：iptables -A INPUT -s IP -j REJECT [root@centos7 ~]awk &apos;{access[$1]++}END{for(i in access){if(access[i]&gt;=1){print i,access[i]}}}&apos; /var/log/httpd/access_log 192.168.34.101 9 192.168.34.103 13 只过滤出IP，监控任务可以写到计划任务里， 或者用内置函数system[&quot;iptables&quot;]调用？ 7、将以下文件内容中FQDN取出并根据其进行计数从高到低排序 http://mail.magedu.com/index.html http://www.magedu.com/test.html http://study.magedu.com/index.html http://blog.magedu.com/index.html http://www.magedu.com/images/logo.jpg http://blog.magedu.com/20080102.html [root@centos7 ~]#cat f5|sed -nr &apos;s@.*//([^/]+)/.*@\1@p&apos;|sort|uniq -c|sort -nr 2 www.magedu.com 2 blog.magedu.com 1 study.magedu.com 1 mail.magedu.com [root@centos7 ~]#cat f5|awk -F&quot;/&quot; &apos;{print $3}&apos;|sort|uniq -c|sort -nr 2 www.magedu.com 2 blog.magedu.com 1 study.magedu.com 1 mail.magedu.com 8、将以下文本以inode为标记，对inode相同的counts进行累加，并且统计出 同一inode中，beginnumber的最小值和endnumber的最大值 inode|beginnumber|endnumber|counts| 106|3363120000|3363129999|10000| 106|3368560000|3368579999|20000| 310|3337000000|3337000100|101| 310|3342950000|3342959999|10000| 310|3362120960|3362120961|2| 311|3313460102|3313469999|9898| 311|3313470000|3313499999|30000| 311|3362120962|3362120963|2| 输出的结果格式为： 310|3337000000|3362120961|10103| 311|3313460102|3362120963|39900| 106|3363120000|3368579999|30000| awk -F&apos;|&apos; &apos;NR==1{print;next}{a[$1]?(a[$1]&gt;$2?a[$1]=$2:0):(a[$1]=$2);b[$1]?(b[$1]&lt;$3?b[$1]=$3:0):(b[$1]=$3);c[$1]+=$4} END{l=asorti(a,d);for(i=1;i&lt;=l;i++)print d[i] FS a[d[i]] FS b[d[i]] FS c[d[i]] FS}&apos; file [解析] 第一行直接打印。从第2行开始以$1为下标，建立3个数组，比较出$2的最小值，$3的最大值，然后把$4进行累加，最后进行排序后依次取出各项值。 这其中运用了三目运算的嵌套，跟我们 if(){if(){}}else{} 的使用是一个道理，不要认为复杂，如果觉得模糊不清，仔细读懂流程控制。 9.统计字符串中每个字母出现的次数abcdaabbccdd [root@centos7 mnt]#echo abcdaabbccdd | awk &apos;gsub(//,&quot;.&quot;,$0)&apos;|awk -F&quot;.&quot; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 3 b 3 c 3 d 3 下面的写法在双引号前一定要加一个空格才能匹配出来 或者用单引号，但是也需要在前面几个空格 [root@centos7 mnt]#echo abcdaabbccdd|awk -F &quot;&quot; &apos;{for(i=1;i&lt;=NF;i++)x[$i]++}END{for(i in x){print i,x[i]}}&apos; a 3 此处一定有个空格 b 3 c 3 d 3 或者用单引号，但是也需要在前面几个空格 [root@mini7-1 ~]#echo abcdaabbccdd |awk -F &apos;&apos; &apos;{for(i=2;i&lt;=NF-1;i++)num[$i]++}END{for(j in num){print j,num[j]}}&apos; a 2 b 3 c 3 d 2 root@centos7 mnt]#echo abcdaabbccdd | grep -o &quot;[a-z]&quot;|sort|uniq -c 3 a 3 b 3 c 3 d 10.面试题：取出/etc/fstab中的挂载目录 [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/?&quot; &apos;/^UUID/{print $2}&apos; boot data swap [root@node7-1 data]#cat /etc/fstab | awk -F &quot;[ ]/|[ ]&quot; &apos;/^UUID/{print $2}&apos; boot data swap AWK中的输入分隔符我们可以使用两次awk -F命令，每次分别指定一个分隔符来进行操作，但是这样太麻烦，还有更简单的方法，即一次指定多个分隔符。要一次指定多个分隔符，需要将分隔符用中括号[]包裹起来，如果多个分隔符中有至少一个特殊字符，那么还需要在中括号外加上双引号或者单引号，并且使用两个或两个以上的\将其进行转义 $、^、(、)、[、]、?、.、| 示例1： [root@node7-1 data]cat b.txt ssh:user1@192.168.1.10 ssh:user2@192.168.1.11 ssh:user3@192.168.1.12 1.取user和IP [root@node7-1 data]awk -F [:@] &apos;{print $2,$3}&apos; b.txt user1 192.168.1.10 user2 192.168.1.11 user3 192.168.1.12 2.上面b.txt中的：和@换成^和|，又该怎么取？ [root@node7-1 data]awk -F &apos;[\\^\\|]&apos; &apos;{print $2,$3}&apos; b.txt user1 192.168.1.10 user2 192.168.1.11 user3 192.168.1.12 示例2： 示例1： george[walker]bush william[jefferson]clinton 如果要打印出由分隔符[和]分隔的三段数据，即可以分别使用两个或两个以上的\对[和]进行转义，如下所示 方法一： awk -F &apos;[\\[\\]]&apos; &apos;{ print $1,$2,$3}&apos; name.txt george walker bush william jefferson clinton 方法二： awk -F &apos;[][]&apos; &apos;{ print $1,$2,$3}&apos; name.txt george walker bush william jefferson clinton 11.取出文本中的姓名和FQDN，awk的方法参照文章最上面的链接文章 [root@node7-1 data]cat a.txt xiaoming\t20\thttp://sougou.com xiaohua\t25\thttp://www.baidu.com xiaodong\t30\thttp://www.jidong.com 方法一：用awk取，以\t做分隔符，但是在表示方法上比较特殊 root@node7-1 data]awk -F&apos;\\\\t&apos; &apos;{print $1,$3}&apos; a.txt xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析： 第一个给第二个转义，第三个给第四个转义，传给awk对就是\\t，awk再将\\解释成\t 方法二：用awk和sed取 [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )t(.*)@\1\2@&apos; xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 12.扩展11题的内容把t换成$,又该如何取？ [root@node7-1 data]cat a.txt xiaoming\$20\$http://sougou.com xiaohua\$25\$http://www.baidu.com xiaodong\$30\$http://www.jidong.com 方法一：还是只用awk来取 [root@node7-1 data]awk -F&apos;\\\\\\$&apos; &apos;{print $1,$3}&apos; a.txt xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析： 1.\\$是转义$的 2.前四个\\\\是转义\的 方法二：awk和sed取 [root@node7-1 data]awk -F&apos;\\&apos; &apos;{print $1,$3}&apos; a.txt |sed -r &apos;s@(.* )\$(.*)@\1\2@&apos; xiaoming http://sougou.com xiaohua http://www.baidu.com xiaodong http://www.jidong.com 分析：先用awk用\做分隔符来取，再用sed取，sed中的$需要转义]]></content>
      <categories>
        <category>linux基础</category>
      </categories>
      <tags>
        <tag>文本处理工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[旧事-大好河山]]></title>
    <url>%2F2017%2F10%2F01%2F%E6%97%A7%E4%BA%8B-%E5%A4%A7%E5%A5%BD%E6%B2%B3%E5%B1%B1%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. U2FsdGVkX1+Px6eFs6cGhvoaMIL5MRO6+5jLRY+ky8QjhjZqO+nyx8/TjDXPU8bZ7pyoaspFfxgS5cEjUZjh3zlIfqeQpphWKLXfB3H2TFoL1CDmM5RsbrGhs5aogfSflyrStjeE9LXHNEGwBtlx5rfXa8pCW10m/1mCGCKiiRgB0GMAL41PJjKkPvoB5DfFm1xbzZsbtQcN7lZGxHDiAMaOOBcHV1C6fWyjzKBTqctfngCszcc/QHsuZPKss5ML7A77C1QlA7phScvv0s7qWJwa5ZxXHT4uI1kRZnE2ekc39nuQWoZr/Ij+5pNrnI9wL8KD40cyJc+3cA6J0FCA8kr0SV5dECcoI2Q0jkovKQcLLAb5HXinj7V/ppuGeTdo]]></content>
      <categories>
        <category>旧事，杂记</category>
      </categories>
      <tags>
        <tag>旧事，杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis-cluster集群]]></title>
    <url>%2F2017%2F07%2F20%2Fredis-cluster%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[Redis cluster 1.redis主从架构的缺点： 1.当master出现redis服务异常、主机断电、磁盘损坏等问题导致master无法使用，而redis高可用无法实现自故障 转移(将slave提升为master)，需要手动执行slave noone将slave切换成master,而且时间很长; 2.不管是主从模式还是sentinel机制都只是保证了数据跨主机备份的安全性，并没有提升Redis服务的并行写入性能； 3.所以当单台Redis服务器性能无法满足业务写入需求的时候就必须需要一种方式解决以上的两个核心问题. 1.master和slave角色的无缝切换，让业务无感知从而不影响业务使用; 2.可以横向动态扩展Redis服务器，从而实现多台服务器并行写入以实现更高并发的目的; 2.Redis cluster集群实现方式：客户端分片、代理分片、Redis Cluster，但是各有区别； 1.客户端分区： 由客户端程序决定key写分配和写入的redis node，但是需要客户端自己处理写入 分配、高可用管理和故障转移等； 2.代理方案： 基于三方软件实现redis proxy，客户端先连接之代理层，由代理层实现key的写入分配，对客户端来说是有 比较简单，但是对于集群管节点增减相对比较麻烦，而且代理本身也是单点和性能瓶颈； 3.redis cluster Redis cluster主从实现原理为了解决单机的redis写入性能受限于单机的内存大小、并发数量、网卡速率等因素，因此redis官方在redis 3.0版本之后推出了无中心架构的redis cluster机制，在无中心的redis集群汇中，其每个节点保存当前节点数据和 整个集群状态,每个节点都和其他所有节点连接，特点如下： 1：所有Redis节点使用(PING-PING机制)互联 2：集群中某个节点的实效是整个集群中超过半数的节点监测都实效才算真正的实效 3：客户端不需要proxy即可直接连接redis，且客户端不需要连接集群中的所有节点，只要连接集群中的任何一个节点即可。 4：redis cluster把所有的redisnode映射到 0-16383个槽位(slot)上，读写需要到指定的redis node上 进行操作，因此有多少个reids node相当于redis 并发扩展了多少倍。 5：Redis集群预先分配16384个(slot)槽位，当需要在redis集群中写入一个key -value的时候， 会使用CRC16(key) mod 16384之后的值，决定将key写入值哪一个槽位从而决定写入哪一个Redis节点上， 从而有效解决单机瓶颈。 1.假设三个主节点分别是：A, B, C 三个节点，采用哈希槽 (hash slot)的方式来分配16384个slot的话，它们三个节点分别承担的slot 区间是： 节点A覆盖0－5460 节点B覆盖5461－10922 节点C覆盖10923－16383 2.Redis cluster的架构虽然解决了并发的问题，但是又引入了一个新的问题，因为每个 Redis master上数据都是不一样的，所以为了保证数据的安全，每个master都需要一个slave来实现数据的高可用. Redis cluster主从架构部署 1.环境准备： 1.每个redis node节点采用相同的硬件配置、相同的密码 2.每个节点必须开启参数 cluster-enabled yes #必须开启集群状态，开启后redis 进程会有cluster显示 cluster-config-file nodes-6380.conf #此文件有redis cluster集群自动创建和维护，不需要任何手动操作 2.为了实验方便，slave都是在master上以6380端口启动，使用不同的Unitfile和配置文件 只列出 redis node master A的操作，其他两台master一样即可 准备配置文件： [root@node02 ~]# vim /usr/local/redis/etc/redis.conf cluster-enabled yes cluster-config-file nodes-6379.conf #启用创建cluster集群的两项 [root@node02 ~]# cp /usr/local/redis/etc/redis /usr/local/redis/etc/redis-6380.conf [root@node02 ~]# vim /usr/local/redis/etc/redis-6380.conf ：%s/6379/6380/g #将6379端口全部替换成6380端口(此端口作为slave的端口) 准备启动服务： [root@node02 ~]# cd /usr/lib/systemd/system/ [root@node02 ~]# cp redis.service redis-6380.service [root@node02 ~]# vim redis-6380.service #修改slave的Unitfile中加载的配置文件redis-6380.conf [root@node02 ~]# systemctl start redis redis-6380 #将一台服务器上的master和slave都启动 #其他两台Redis Node Master{B,C}一样配置即可； –每一台redis上应该有一主一从 3.创建集群 redis-cli --cluster help #客户端命令可以创建管理集群 [root@node01 ~]# redis-cli -a root --cluster create 192.168.34.121:6379 192.168.34.121:6380 192.168.34.124:6379 192.168.34.124:6380 192.168.34.123:6379 192.168.34.123:6380 --cluster-replicas 1 – 4.检查集群状态 #Cluster info可以查看当前集群的状态，集群规模和是否有master节点出现故障以及槽位分配是否是完整且连续的. [root@node01 ~]# redis-cli -h 192.168.34.121 -p 6379 -a root 192.168.34.121:6379&gt; CLUSTER INFO cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 cluster_size:3 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:1474 cluster_stats_messages_pong_sent:1507 cluster_stats_messages_sent:2981 cluster_stats_messages_ping_received:1502 cluster_stats_messages_pong_received:1474 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:2981 5.查看集群node对应关系 #通过cluster nodes可以看到集群中的主从对应关系 [root@node01 ~]# redis-cli -h 192.168.34.121 -p 6380 -a root 192.168.34.121:6380&gt; cluster nodes 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545659135000 4 connected 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 myself,slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545659135000 6 conne ctedf4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545659135000 1 connected 0-5460 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545659136000 3 connected 5461-10922 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545659134000 5 connected 10923-16383 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545659135946 5 connected –cluster nodes 6.查看集群槽位和主从的具体关系 使用redis-cli -a root --cluster check 192.168.34.101:6379 随机一个master的IP和端口可以看到对应关系 –查看集群对应关系![查看集群对应关系]redis-cluster集群/(查看集群对应关系.png) 7.验证集群写入key 192.168.7.101:6379&gt; SET k1 v1 #经过算法计算，当前key的槽位需要写入指定的node (error) MOVED 9189 192.168.7.103:6379 #因为槽位不在当前node所以无法写入 192.168.7.102:6379&gt; SET k1 v1 (error) MOVED 9189 192.168.7.102:6379 192.168.7.103:6379&gt; SET k1 v1 #指定的node就可以写入 OK 192.168.7.103:6379&gt; KEYS * 1) &quot;k1&quot; 192.168.7.101:6379&gt; KEYS * (empty list or set) 192.168.7.102:6379&gt; KEYS * (empty list or set) 8.故障动态转移测试； 上一步已经将数据写入到192.168.7.103:6379的master上了现在关闭192.168.7.103上的master 6379的redis进程，测试192.168.7.103:6379的slave192.168.7.103:6380 是否能成为master，数据是否能查到. –103的slave–103的slave会切换成master 9.集群状态监控 # redis-cli -a 123456 --cluster check 192.168.7.101:6379 –集群状态监控 Redis cluster集群管理维护集群运行时间长久之后，难免由于硬件故障、网络规划、业务增长等原因对已有集群进行相应的调整， 比如增加Redis node节点、减少节点、节点迁移、更换服务器等。增加节点和删除节点会涉及到已有的槽位重新分配及数据迁移。 1.集群维护之动态添加节点1.增加Redis node节点，需要与之前的Redis node版本相同、配置一致，然后分别启动两台Redis node，因为一主一从;2.现有的三主三从redis cluster架构可能无法满足现有业务的并发写入需求，新增一台服务器192.168.34.122，需要将其动态添加到集群当中其不能影响业务使用和数据丢失，则添加过程如下: 1.同步配置文件 同步之前Redis node的配置文件到192.168.7.104 Redis编译安装目录， 注意配置文件的监听IP，这是在一台服务器上模拟一主一从redis； # scp redis.conf 192.168.34.104:/usr/local/redis/etc/ # scp redis_6380.conf 192.168.34.104:/usr/local/redis/etc/ 分别启动redis服务： # systemctl daemon-reload # systemctl restart redis # /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis_6380.conf 2.新增新节点到集群(先新增一台master节点) 使用命令：redis-cli -a 123456 --cluster add-node 192.168.34.104:6379 192.168.7.101:6379 #注意： 前面是新增加的的redis节点IP和端口后面是已经存在的集群中的master IP:端口(可以是任意一个master的IP和端口) 注意： 增加到集群很快，但是新加的节点是没有数据的，需要对集群进行槽位重新分片，数据重新划分； –添加新节点到集群 3.分配槽位 添加主机之后需要对添加至集群种的新主机重新分片否则其没有分片；将现有的三主三从上的数据重新分配到四主四从上； 重新分片机制： 将集群中的每个master抽出一部分给新增的节点使用； 命令： [root@redis ~]# redis-cli -a 123456 --cluster reshard 192.168.7.104:6379 –重新分配槽位 4.查看当前集群状态 查看重新划分之后集群是否是正常的. 此时因为只加入了一个master,没有把新的slave节点加进来，所以会有一个master没有slave –重新分配完成 5.将新的slave也加入集群 [root@node01 ~]# redis-cli -a 123456 --cluster add-node 192.168.34.104:6380 192.168.7.101:6379 #新的节点加入集群默认都是master节点，需要把它变成一个192.168.34.104:6379的slave 6.为新增的master192.168.34.104:6379添加slave192.168.34.104:6380节点 将新加slave192.168.34.104:6380，作为master192.168.34.104:6379的slave, 登录到192.168.34.104:6380上通过CLUSTER REPLICATE ID更改新节点状态为slave 1.需要先登录到要成为slave的节点上； 2.取出要成为master的ID(cluster nodes命令查看) –添加slave 7.验证当前集群状态 –当前集群状态 2.集群维护之动态删除节点添加节点的时候是先添加node节点到集群，然后分配槽位，删除节点的操作与添加节点的操作正好相反，是先将被删除的Redis node上的槽位迁移到集群中的其他Redis node节点上，然后再将其删除。 1.迁移master192.168.7.102:6379的槽位之其他master [root@redis-s1 ~]# redis-cli -a root --cluster reshard 192.168.7.102:6379 #指定要删除的master节点的IP+端口 –迁移节点 2.验证槽位迁移完成 –验证槽位迁移完成 3.从集群删除服务器 虽然槽位已经迁移完成，但是服务器IP信息还在集群当中，因此还需要将IP信息从集群删除 命令格式:redis-cli -a root --cluster del-node IP:Port ID 删除master： [root@redis1~]# redis-cli -a root --cluster del-node 192.168.7.101:6379 f4cfc5cf821c0d855016488d6fbfb62c03a14fda Warning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe. &gt;&gt;&gt; Removing node f4cfc5cf821c0d855016488d6fbfb62c03a14fda from cluster 192.168.7.101:6379 &gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster... &gt;&gt;&gt; SHUTDOWN the node. 删除slave： 该节点上如果还有其他节点上master 的slave，但是由于服务器下架也要一并删除，因此要提前把保证每个master至少有一个slave [root@redis-s1 ~]# redis-cli -a root --cluster del-node 192.168.7.101:6380 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 Warning: Using a password with &apos;-a&apos; or &apos;-u&apos; option on the command line interface may not be safe. &gt;&gt;&gt; Removing node 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 from cluster 192.168.7.101:6380 &gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster... &gt;&gt;&gt; SHUTDOWN the node. 4.验证node是否删除 发现192.168.7.101已经被删除，但是由于192.168.7.101:6380之前是192.168.7.103:6379的slave，所以删除 后会导致相应的master缺少slave，需要重新为没有slave的master分配slave。 可以发现下图的192.168.7.104有两个slave，分别是192.168.7.102:6380和192.168.7.104:6380，因此需要将 其中一个slave转移为192.168.7.103的slave。 –验证node是否删除 5.重新分配slave 将192.168.7.104:6380 转移为192.168.7.103的slave –重新分配slave 6.重新验证集群Master与Slave对应关系 Redis Slave节点一定不能和master在一个服务器，必须为跨主机交叉备份模式，避免主机故障后主备全部挂掉，如果出现Redis Slave与Redis master在同一台Redis node的情况，则需要安装以上步骤重新进行slave分配，直到不相互交叉备份为止。 –master和slave对应关系 3.集群维护之导入现有Redis数据将redis cluster部署完成之后，需要将之前的数据导入到Redis cluster集群，但是由于Redis cluster使用的分片保存key的机制，因此使用传统的AOF文件或RDB快照无法满足需求，因此需要使用集群数据导入命令完成。 注意： 导入数据需要redis cluster不能与被导入的数据有重复的key名称，否则导入不成功或中断。 1.环境准备： 1.导入数据之前需要关闭各redis 服务器的密码，包括集群中的各node和源Redis server，避免认证带来的 环境不一致从而无法导入，但是可以加参数--cluster-replace 强制替换Redis cluster已有的key 2.执行数据导入 将源Redis server的数据直接导入之redis cluster。 命令格式：#redis-cli --cluster import 集群服务器IP:PORT --cluster-from 外部Redis node-IP:PORT --cluster-copy --cluster-replace –数据导入]]></content>
      <categories>
        <category>缓存</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis高可用]]></title>
    <url>%2F2017%2F07%2F15%2Fredis%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Redis高可用 虽然Redis可以实现单机的数据持久化，但无论是RDB也好或者AOF也好，都解决不了单点宕机问题，即一旦redis服务器本身出现系统故障、硬件故障等问题后，就会直接造成数据的丢失，因此需要使用高可用和集群技术来解决单点问题. Redis主从实现主从复制过程 Redis支持主从复制分为全量同步和增量同步，首次同步是全量同步，主从同步可以让从服务器从主服务器备份数据，而且从 服务器还可与有从服务器，即另外一台redis服务器可以从一台从服务器进行数据同步，redis 的主从同步是非阻塞的， 其收到从服务器的sync(2.8版本之前是PSYNC)命令会fork一个子进程在后台执行bgsave命令，并将新写入的数据写入到 一个缓冲区里面，bgsave执行完成之后并生成的将RDB文件发送给客户端，客户端将收到后的RDB文件载入自己的内存， 然后主redis将缓冲区的内容在全部发送给从redis，之后的同步从服务器会发送一个offset的位置(等同于MySQL的binlog 的位置)给主服务器，主服务器检查后位置没有错误将此位置之后的数据包括写在缓冲区的积压数据发送给redis从服务 器，从服务器将主服务器发送的挤压数据写入内存，这样一次完整的数据同步，再之后再同步的时候从服务器只要发送 当前的offset位 置给主服务器，然后主服务器根据响应的位置将之后的数据发送给从服务器保存到其内存即可。 Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 1）从服务器连接主服务器，发送SYNC命令； 2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB快照文件并使用缓冲区记录此后执行的所有写命令； 3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 7）后期同步会先发送自己slave_repl_offset位置，只同步新增加的数据，不再全量同步。 主从同步优化：Redis在2.8版本之前没有提供增量部分复制的功能，当网络闪断或者slave Redis重启之后会导致主从之间的全量同步，即从2.8版本开始增加了部分复制的功能。 repl-diskless-sync no #yes为支持disk，master将RDB文件先保存到磁盘在发送给slave，no为maste直接将RDB文件发送给slave，默认 即为使用no，Master RDB文件不需要与磁盘交互。 repl-diskless-sync-delay 5 #Master准备好RDB文件后等等待传输时间 repl-ping-slave-period 10 #slave端向server端发送pings的时间区间设置，默认为10秒 repl-timeout 60 #设置超时时间 repl-disable-tcp-nodelay no #是否启用TCP_NODELAY，如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms）， 造成master与slave数据不一致，假如设置成no，则redis master会立即发送同步数据，没有延迟，前者关注性能，后者关注一致性 repl-backlog-size 1mb #master的写入数据缓冲区，用于记录自上一次同步后到下一次同步过程中间的写入命令，计算公式： b repl-backlog-size = 允许从节点最大中断时长 * 主实例offset每秒写入量，比如master每秒最大写入64mb， 最大允许60秒，那么就要设置为64mb*60秒=3840mb(3.8G)= repl-backlog-ttl 3600 #如果一段时间后没有slave连接到master，则backlog size的内存将会被释放。如果值为0则表示永远不释放这部份内存。 slave-priority 100 #slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端 进行恢复，如果值设置为0，则表示该slave永远不会被选择。 #min-slaves-to-write 0 #min-slaves-max-lag 10 #设置当一个master端的可用slave少于N个，延迟时间大于M秒时，不接收写操作。 Master的重启会导致master_replid发生变化，slave之前的master_replid就和master不一致从而会引发所有slave的全量同步。 配置redis一主二从 客户端连接redis: 1.主备模式，可以实现Redis数据的跨主机备份； 2.程序端连接到高可用负载的VIP，然后连接到负载服务器设置的Redis后端real server ，此模式不需要在程序里面配置Redis服务器的真实IP地址，当后期Redis服务器IP 地址发生变更只需要更改redis 相应的后端real server即可，可避免更改程序中的 IP地址设置. 1.配置2台slave： 1.Redis Slave也要开启数据持久化(RDB/AOF)并设置和master同样的连接密码， 因为后期slave会有提升为master的可能,Slave端切换master同步后会丢失之前的所有数据。 2.一旦某个Slave成为一个master的slave,Redis Slave服务会清空当前redis服务器上的所有数据并将master的 数据导入到自己的内存，但是断开同步关系后不会删除当前已经同步过的数据； redis早期的时候都是全量同步，后期支持增量同步 2.修改从redis服务器的redis.conf配置文件 [root@node02 redis]# vim etc/redis.conf replicaof 192.168.34.117 6379 #master的IP和端口 #注意：master的IP必须和master的bind监听的地址是一致的，如果有两个地址，而bind只监听在内网IP上，此 处只能写内网的IP，写外网的IP也不会同步成功的. masterauth root #master的验证密码 requirepass root #每个redis数据库的验证密码都要和master一样 3.重启从redis： 127.0.0.1:6379&gt; INFO # Replication role:slave #显示是从节点 master_host:192.168.34.117 #显示master的IP master_port:6379 #显示master的端口 master_link_status:up #显示是否为up状态，在此状态下才是正常的 master_last_io_seconds_ago:9 master_sync_in_progress:0 slave_repl_offset:462 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:1f0cd49a266eaacc5c6bdd14f5c793d065207166 #master的ID master_replid2:0000000000000000000000000000000000000000 #如果有主从故障转移，master_replid2就成了master_replid的编号 #而master_replid会重新生成一个编号 master_repl_offset:462 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:462 4.验证master上的信息 Replication role:master connected_slaves:2 #显示当前有几个slave和IP及是否正常 slave0:ip=192.168.34.118,port=6379,state=online,offset=630,lag=0 slave1:ip=172.18.0.1,port=6379,state=online,offset=630,lag=0 master_replid:1f0cd49a266eaacc5c6bdd14f5c793d065207166 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:630 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:630 5.验证Slave从节点上的数据 127.0.0.1:6379&gt; keys * 1) &quot;myeky&quot; 2) &quot;mykey1&quot; #显示已经从master上将数据同步成功了，如果slave上原来有数据，则会被清空！ 6.master和slave上的日志 在master和slave上的日志可以显示出是否同步成功，如果没有同步成功会显示原因，有时原因不会很清楚，需要将 redis.conf下的loglevel日志级别调整为debug模式. 主从复制常见问题汇总1.master和slave的防火墙要关闭 2.master密码不对 即配置的master密码不对，导致验证不通过而无法建立主从同步关系。 3.Redis版本不一致 不同的redis 版本之间存在兼容性问题，因此各master和slave之间必须保持版本一致 4.无法远程连接 在开启了安全模式情况下，没有设置bind地址和密码 应用程序如何连接redis？：1.java客户端连接redis是通过jedis来实现的，java代码用的时候只要创建jedis对象就可以建多个jedis连接池来连接 redis，应用程序再直接调用连接池即可连接Redis。 2.而Redis为了保障高可用,服务一般都是Sentinel部署方式，当Redis服务中的主服务挂掉之后,会仲裁出另外一台Slaves 服务充当Master。这个时候,我们的应用即使使用了Jedis连接池,Master服务挂了,我们的应用将还是无法连接新的Master服务 3.为了解决这个问题,Jedis也提供了相应的Sentinel实现,能够在Redis Sentinel主从切换时候,通知我们的应用, 把我们的应用连接到新的Master服务。 4.Jedis Sentinel的使用也是十分简单的,只是在JedisPool中添加了Sentinel和MasterName参数，Jedis Sentinel 底层基于Redis订阅实现Redis主从服务的切换通知，当Reids发生主从切换时，Sentinel会发送通知主动通知Jedis进行 连接的切换，JedisSentinelPool在每次 从连接池中获取链接对象的时候,都要对连接对象进行检测,如果此链接和Sentinel的Master 服务连接参数不一致,则会关闭此连接,重新获取新的Jedis连接对象。 redis Sentinel(哨兵)机制实现redis sentinel的作用： 1.redis主从架构中，master宕机之后，是需要人为执行slave noone将slave切换成 master的； 2.而sentinel进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候， 可以实现Master和Slave服务器的切换，保证系统的高可用 3.master切换后，sentinel进程会通知给JAVA程序上一个与redis通信的jar包，java程序就会与新的master建立 连接池进而正常工作. sentinel工作原理： 1.哨兵(Sentinel) 是一个分布式系统，你可以在一个架构中运行多个哨兵(sentinel) 进程，这些进程使用流言协议(gossipprotocols)来接收关于Master主服务器 是否下线的信息，并使用投票协议(Agreement Protocols)来决定是否执行自动 故障迁移,以及选择哪个Slave作为新的Master； 2.每个哨兵(Sentinel)进程会向其它哨兵(Sentinel)、Master、Slave定时发送消息， 以确认对方是否”活”着，如果发现对方在指定配置时间(可配置的)内未得到回应 ，则暂时认为对方已掉线，也就是所谓的”主观认为宕机” 简称SDOWN; 3.当“哨兵群”中的多数Sentinel进程在对Master主服务器做出SDOWN 的判断，并且 通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master Server下线判断，这种方式就是“客观宕机”，简称 ODOWN。 4.然后通过一定的vote算法，从剩下的slave从服务器节点中，选一台提升为Master服务 器节点，然后自动修改相关配置，并开启故障转移(failover); 注意： 哨兵只是解决了人为介入master和slave角色的切换问题，在Redis服务的并行写入性能上并没有任何作用. Sentinel实现哨兵可以不和Redis服务器部署在一起 1.准备Sentinel的配置文件 [root@node01 redis]# cp /usr/local/src/redis-5.0.3/sentinel.conf /usr/local/redis/etc/ 2.编辑sentinel.conf配置文件 bind 0.0.0.0 #修改监听的地址为0.0.0.0 port 26379 #sentinel的端口 daemonize yes #修改为以守护进程方式运行 pidfile /var/run/redis-sentinel_26379.pid #pid路径 logfile &quot;/usr/local/redis/logs/sentinel_26379.log&quot; #log日志路径 dir /usr/local/redis/sentinel #sentinel临时文件目录 sentinel monitor mymaster 172.18.140.6 6379 2 #master的IP和端口，以及几个哨兵人为down就是down sentinel auth-pass mymaster root #master的名(可同上一条)，和验证密码 sentinel down-after-milliseconds mymaster 15000 #检测时长 #将配置文件复制给主从架构中的其他redis服务器上 3.启动哨兵sentinel [root@node01 redis]# redis-sentinel /usr/local/redis/etc/sentinel.conf #因为没有sentinel的Unitfile,所以启动时指定配置文件路径即可; 备注： 只要sentinel都启动后，会在sentinel.conf配置文件中生成 sentinel myid 66a04f04a74bb7d728fe83dc0788582302e27f0c #每个sentinel服务上的配置文件都会生成各自的集群ID号 protected-mode no sentinel leader-epoch mymaster 1 sentinel known-replica mymaster 172.18.140.6 6379 sentinel known-sentinel mymaster 172.20.103.15 26379 72eb727c9130b47a4538a9b75bf10e6a55d0676f sentinel known-sentinel mymaster 172.18.140.5 26379 66a04f04a74bb7d728fe83dc0788582302e27f0c sentinel current-epoch 1 #配置文件会自动加载集群内部的sentinel群组和成员！！ 如果要重新设置sentinel，需要先把这些信息删除，重新创建sentinel群组！ 测试：将master上的redis服务关闭–故障转移时sentinel信息–故障转移后的redis配置文件故障转移后redis.conf中的replicaof行的master IP会被修改，sentinel.conf中的sentinel monitor IP会被修改。 查看一台slave: # Replication role:master connected_slaves:1 slave0:ip=172.18.140.6,port=6379,state=online,offset=335400,lag=0 master_replid:28c62ac13e6c57a7b3a11347bb3872d58da24e11 master_replid2:7d5355ccd2638b9647d5f3c7c96116fad55ed64f master_repl_offset:335400 second_repl_offset:178740 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:18272 repl_backlog_histlen:317129 ########可以看到slave1被选择为master了 前一个master启动后也会自动变成slave: # Replication role:slave master_host:172.18.140.5 master_port:6379 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_repl_offset:239591 slave_priority:100 slave_read_only:1 connected_slaves:1 slave0:ip=172.18.0.1,port=6379,state=online,offset=239591,lag=1 master_replid:28c62ac13e6c57a7b3a11347bb3872d58da24e11 master_replid2:0000000000000000000000000000000000000000 第二个slave: 需要手动修改文件，使其成为之前slave1的slave [root@master1 redis]# vim etc/redis.conf replicaof 172.18.140.5 6379 #将此处的IP给成新master的IP 然后新的master上就会有2个slave了; # Replication role:master connected_slaves:2 slave0:ip=172.18.140.6,port=6379,state=online,offset=403718,lag=0 slave1:ip=172.18.0.1,port=6379,state=online,offset=403718,lag=0 master_replid:28c62ac13e6c57a7b3a11347bb3872d58da24e11 master_replid2:7d5355ccd2638b9647d5f3c7c96116fad55ed64f master_repl_offset:403857 second_repl_offset:178740 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:18272 repl_backlog_histlen:385586 –当前redis状态]]></content>
      <categories>
        <category>缓存</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP和PXE]]></title>
    <url>%2F2017%2F07%2F06%2FDHCP%E5%92%8CPXE%2F</url>
    <content type="text"><![CDATA[PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobblercobbler实现系统自动化安装cobbler自动化系统安装 DHCP服务&amp;PXE自动化安装系统DHCP服务:(著名的Inter系统协会组织：研发的DHCP和DNS技术)DHCP官方文档：DHCP文档BIND官网文档：BIND文档DNS搭建的相关文档:DNS原理解析&amp;搭建 PXE安装只是实现BIOS系统的自动化安装，对于UEFI的不支持，对于UEFI的可以使用cobblercobbler实现系统自动化安装cobbler自动化系统安装 全文只有二个实验：搭建DHCP和在centos7实现基于PXE安装centos7和centos6(centos6上原理类似) 搭建DHCP服务器：基于UDP协议(dhcp服务器端口：67、dhcp客户端端口：68)DHCP: （Dynamic Host Configuration Protocol） 动态主机配置协议 局域网协议，UDP协议(67端口) 主要用途： 用于内部网络和网络服务供应商自动分配IP地址给用户 用于内部网络管理员作为对所有电脑作集中管理的手段 使用场景 自动化安装系统 解决IPV4资源不足问题 DHCP申请网络地址是通过四个过程实现的：四个数据报文DHCP共有八种报文 1.DHCP DISCOVER：客户端到服务器 2.DHCP OFFER ：服务器到客户端 3.DHCP REQUEST：客户端到服务器 4.DHCP ACK ：服务器到客户端 DHCP NAK：服务器到客户端,通知用户无法分配合适的IP 地址 DHCP DECLINE ：客户端到服务器，指示地址已被使用 DHCP RELEASE：客户端到服务器，放弃网络地址和取消 剩余的租约时间 DHCP INFORM：客户端到服务器, 客户端如果需要从DHCP 服务器端获取更为详细的配置信息，则发送Inform报文向 服务器进行请求，极少用到 同网段多DHCP服务 DHCP服务必须基于本地 先到先得的原则 跨网段 RFC 1542 Compliant Routers dhcrelay: 中继 相关协议 Arp rarp DHCP服务器的实现方式：搭建DHCP服务器Linux DHCP协议的实现程序：dhcp, dnsmasq（dhcp,dns） 1.实现DHCP的软件有两个：dnsmasp,这个软件是安装系统是默认的一个 可以同时提供dns和dhcp两种服务，不是很专业 如：ss -ntl 看到的默认就有dnsmasp服务 LISTEN 0 5 192.168.122.1:53 users:((&quot;dnsmasq&quot;,pid=1506,fd=6)) 2.DHCP更专业：下面主要介绍 实验：DHCP服务的搭建实验前提： 1.把vmware虚拟机的主机都设置成仅主机模式，要不然会影响所在的 工作中的DHCP服务器，其他人可能会获取到实验配置的DHCP服务 获取到一个不能上网的IP地址 2.编辑vmware的虚拟网络编辑器，将仅主机的DHCP服务关闭，这样当前 就只有自己配置的DHCP服务器了 Dhcp Server相关配置文件： /etc/dhcp/dhcpd.conf ---&gt;主要配置文件 /usr/lib/systemd/system/dhcpd.service ---&gt;服务名 /usr/sbin/dhcpd ---&gt;dhcp的主程序 /etc/dhcp/dhcpd.conf --&gt; /etc/rc.d/init.d/dhcpd /etc/dhcp/dhcpd6.conf--&gt; /etc/rc.d/init.d/dhcpd6 /var/lib/dhcpd/dhcpd.leases ---&gt;租出去的地址信息库文件 /usr/sbin/dhcrelay /etc/rc.d/init.d/dhcrelay dhcp server:67/udp dhcp client: 68/udp dhcpv6 client:546/udp Dhcp client dhclient 自动获取的IP信息： /var/lib/dhclient dhcp.conf配置文件内容设置：安装DHCP完,默认是启动不了的，因为配置文件dhcpd.conf是空的 1.先通过模板生成新的配置文件 cp /usr/share/doc/dhcp*/dhcpd.conf.example /etc/dhcp/dhcpd.conf 2.模板里的网段地址不对，需要修改，网段和IP范围 question：那么如何修改dhcd.conf配置文件？ answer：根据上面的模板文件中的信息自改自定义的一些值 该文件中定义了： 1.默认续租时间和最长租期 2.DHCP默认分配的网段和分配的IP地址范围 3.DHCP服务提供的默认网关地址和DNS地址 3.前两项设置其他主机只是通过DHCP自动获取地址的需求，如果通过dhcp实现系统的 自动化安装，就不仅仅获取到地址，还需要从DHCP获取能启动计算机的文件，即 dhcp的配置文件中要有配置的地址：类似于grub的文件 其它配置选项： filename: 指明引导文件名称 next-server：提供引导文件的服务器IP地址 示例： filename &quot;pxelinux.0&quot;; next-server 192.168.100.100; 网络中下载文件的主机地址，带有tftp功能 备注：如果网卡有pxe的功能即自带tftp的功能 所以具有完整的功能的dhcp配置文件dhcp.conf内容类似； default-lease-time 600; max-lease-time 7200; subnet 192.168.34.0 netmask 255.255.255.0 { range 192.168.34.20 192.168.34.100; option routers 192.168.34.1; option domain-name-servers 6.6.6.6; ext-server 192.168.34.103; filename &quot;pxelinux.0&quot;; PXE安装相关的配置 } 上面是主要配置内容，在dhcpd.conf中还可以把指定的mac地址与IP绑定 host passacaglia { hardware ethernet 00:0c:29:af:45:f7; fixed-address 192.168.34.80 } 安装tftp服务:(UDP协议：69端口) yum install tftp-server -y [root@node7-1 tftpboot]#rpm -ql tftp-server /etc/xinetd.d/tftp /usr/lib/systemd/system/tftp.service /usr/lib/systemd/system/tftp.socket /usr/sbin/in.tftpd /var/lib/tftpboot 存放下载上传的路径:系统所需要的文件 centos7和centos6上安装tftp是由区别的 centos7上需要安装tftp-server服务--&gt;UDP69端口 yum install tftp-server systemctl start tftp 在centos6上安装和telnet是一个道理，都依赖于xinetd chkconfig tftp on--&gt; /etc/xinetd.d/tftp配置文件 service restart xinted PXE介绍PXE： Preboot Excution Environment 预启动执行环境 Intel公司研发 基于Client/Server的网络模式，支持远程主机通过网络从远端服务器下载 映像，并由此支持通过网络启动操作系统 PXE可以引导和安装Windows,linux等多种操作系统 实验：在centos7实现基于PXE安装centos7和centos6自动化安装步骤： 1.安装前准备：关闭防火墙和SELINUX，DHCP服务器静态IP 2.安装软件包 httpd tftp-server dhcp syslinux system-config-kickstart httpd:实现yum源 tftp-server：实现网络下载的文件 syslinux: 准备pxelinux.0文件 备注：centos6上是安装syslinux-nonlinux system-config-kickstart制作kickstart软件，建议自己制作 3.配置文件共享服务： 准备centos7&amp;centos6的yum源 systemctl enable httpd systemctl start httpd mkdir -pv /var/www/html/centos/{6,7}/os/x86_64 mount /dev/sr0 /var/www/html/centos/7/os/x86_64 mount /dev/sr1 /var/www/html/centos/6/os/x86_64 4.准备kickstart文件 拷贝已经安装机器上的anaconda文件，按照自定义稍微修改，放到http目录下 注意：644权限 cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg cp anaconda-ks.cfg /var/www/html/ksdir/ks7-min.cfg ks应答文件的内容可以用system-config-kickstart或者anaconda修改就行了 最好是通过system-config-kickstart做一个应答文件，通过界面更深刻理解 每一项代表的意义 大概内容如下：(最后附件的有详细的ks文件内容) url --url=http://192.168.34.7/centos/7/os/x86_64/ text firewall --disabled selinux --disabled clearpart --all --initlabel zerombr reboot %packages @core %end 5.配置tftp服务 systemctl enable tftp.socket systemctl start tftp.socket 6.配置DHCP服务 cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcpd/dhcpd.conf vim /etc/dhcp/dhcpd.conf option domain-name &quot;example.com&quot;; default-lease-time 600; max-lease-time 7200; subnet 192.168.34.0 netmask 255.255.255.0 { range 192.168.34.20 192.168.34.100; option routers 192.168.34.1; option domain-name-servers 6.6.6.6; next-server 192.168.34.103; filename &quot;pxelinux.0&quot;; } systemctl enable dhcpd systemctl start dhcpd 7.准备PXE相关文件 放pxelinux.0的专用目录，启动菜单 mkdir /var/lib/tftpboot/pxelinux.cfg/ 分别存放6和7的vmliuz和initrd.img文件 mkdir linux{6,7} 拷贝6和7安装必要文件 cp /var/www/html/centos/6/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/linux6/ cp /var/www/html/centos/7/os/x86_64/isolinux/{vmlinuz,initrd.img} /var/lib/tftpboot/linux7/ cp /usr/share/syslinux/{pxelinux.0,menu.c32} /var/lib/tftpboot/ 将光盘里的启动菜单拷贝到并改名为default cp /var/www/html/centos/7/os/x86_64/isolinux.cfg /var/lib/tftpboot/ pxelinux.cfg/default 拷贝完所有文件,文件列表如下： /var/lib/tftpboot/ . ├── linux6 │ ├── initrd.img │ └── vmlinuz ├── linux7 │ ├── initrd.img │ └── vmlinuz ├── menu.c32 ├── pxelinux.0 └── pxelinux.cfg └── default 8.准备启动菜单 菜单项可以自定义多个，如只有mini7和mini6的，还有必须要有本地硬盘启动的菜单项 但是要在文件内把各个的linuz和initrd路径 vim /var/lib/tftpboot/pxelinux.cfg/default default menu.c32 timeout 100 menu title PXE Install CentOS label mini7 menu label ^Auto Install Mini CentOS 7 kernel linux7/vmlinuz append initrd=linux7/initrd.img ks=http://192.168.34.7/ksdir/ks7-mini.cfg label mini6 menu label ^Auto Install Mini CentOS 6 kernel linux6/vmlinuz append initrd=linux6/initrd.img ks=http://192.168.34.7/ksdir/ks6-mini.cfg label local menu default menu label Boot from ^local drive localboot 0xffff. 9.准备完所有的文件和软件后，启动所有的服务，就可以测试PXE安装了。 附带centos7和centos6的ks应答文件模板：建议通过ystem-config-kickstart做一个应答文件，通过界面更深刻理解每一项代表的意义，当然也可以修改anaconda-ks.cfg文件ks6-mini.cfginstall url --url=http://192.168.34.103/centos/6/os/x86_64/ #httpd的yum源路径 lang en_US.UTF-8 keyboard us text #纯文本安装 reboot #安装完重启 network --onboot yes --device eth0 --bootproto dhcp --noipv6 rootpw --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt JjA57WrZO0 firewall --service=ssh 关闭防火墙 authconfig --enableshadow --passalgo=sha512 selinux --enforcing 关闭selinux timezone Asia/Shanghai 时区信息 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work clearpart --all 清空分区信息 zerombr 清空mbr #自定义的分区信息 part /boot --fstype=ext4 --size=1024 part / --fstype=ext4 --size=50000 part /data --fstype=ext4 --size=30000 part swap --size=2048 #自定义的分区信息 %packages @core %end 只安装最基本的核心包，后面也可以加上安装后脚本 ks7-mini.cfg：类似centos6的只是稍微的区别auth --enableshadow --passalgo=sha512 url --url=http://192.168.34.103/centos/7/os/x86_64/ text firstboot --enable ignoredisk --only-use=sda keyboard --vckeymap=us --xlayouts=&apos;us&apos; lang en_US.UTF-8 network --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --activate network --hostname=centos7.localdomain rootpw --iscrypted $6$j2QVLmDO2xasQEW0$xEvr1jyj1mHs0HBtCc7jD73r6u4NrQCxwVoAu.SMXhwm8GiKBHq5ETZ2zFxP4rFsNavYbG0u6Gq13 Igxrn1Ry. firewall --disabled selinux --disabled services --enabled=&quot;chronyd&quot; timezone Asia/Shanghai --isUtc user --name=test --password=$6$Awcwirg.mougtUlL$Yr1a9e2Vfs2k/Nizdn/ZeiunlsU.rJAmI1vhp1iafeccRt48h3PVIlnVwGvKPPt4dVum a/W32jzYIsn1XCrva. --iscrypted --gecos=&quot;test&quot; bootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda clearpart --all --initlabel zerombr reboot part / --fstype=&quot;xfs&quot; --ondisk=sda --size=51200 part /boot --fstype=&quot;xfs&quot; --ondisk=sda --size=1024 part swap --fstype=&quot;swap&quot; --ondisk=sda --size=4096 part /data --fstype=&quot;xfs&quot; --ondisk=sda --size=30720 %packages @core %end]]></content>
      <categories>
        <category>系统安装</category>
      </categories>
      <tags>
        <tag>运维，linux，windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis基础]]></title>
    <url>%2F2017%2F06%2F26%2Fredis%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[缓存基础介绍 1.系统缓存：buffer与cachecentos6是分开的，centos7放到一起了. buffer： 缓冲也叫写缓冲，一般用于写操作，可以将数据先写入内存再写入磁盘，buffer 一般用于写缓冲，用于解决不同介质 的速度不一致的缓冲，先将数据临时写入到里自己最近的地方，以提高写入速度，CPU会把数据线写到内存的磁盘缓冲 区，然后就认为数据已经写入完成看，然后内核的线程在后面的时间在写入磁盘，所以服务器突然断电会丢失内存中的 部分数据。 buffer是在内存中还没写到磁盘上，即将写到磁盘上的数据！ cache： 缓存也叫读缓存，一般用于读操作，CPU读文件从内存读，如果内存没有就先从硬盘读到内存再读到CPU，将需要频繁读 取的数据放在里自己最近的缓存区域，下次读取的时候即可快速读取。 cache是vim/cat等打开的文件信息放到内存中的称为cache,是为了下次访问时加速的！ cache的保存位置： 客户端：浏览器(每个浏览器的默认过期时间不一样) 内存：本地服务器、远程服务器 硬盘：本机硬盘、远程服务器硬盘 速度对比： 客户端浏览器-CPU-内存-远程内存-硬盘-远程硬盘。 cache的特性: 1.过期时间 2.强制过期，源网站更新图片后CDN是不会更新的，需要强制是图片缓存过期 3.命中率，即缓存的读取命中率 在memcached中可以看到有多少缓存和缓存的命中率; Cache（缓存）位于CPU与内存之间的临时存储器，缓存容量比内存小的多但交换速度比内存要快得多。Cache通过缓存文件 数据块，解决CPU运算速度与内存读写速度不匹配的矛盾，提高CPU和内存之间的数据交换速度。Cache缓存越大，CPU处理速 度越快。 Buffer（缓冲）高速缓冲存储器，通过缓存磁盘（I/O设备）数据块，加快对磁盘上数据的访问，减少 I/O，提高内存和硬盘（或其他I/O设备）之间的数据交换速度。Buffer是即将要被写入磁盘的， 而Cache是被从磁盘中读出来的。 2.CDN缓存 CDN内容分发网络（Content Delivery Network），通过将服务内容分发至全网加速节点，利用全球调度系统使用户能够 就近获取，有效降低访问延迟，提升服务可用性. 1.CDN第一降低机房的使用带宽，因为很多资源通过CDN就直接返回用户了; 2.第二解决不同运营商之间的互联，因为可以让联通的网络访问联通让电信的网络访问电信，起到加速用户访问的目的; 3.第三解决用户访问的地域问题，就近返回用户资源; 用户请求CDN的流程： 提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数 据根据访问的热度不同而进行不同级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA，再其次的放在云存储，这样兼顾了速度与成本。 CDN的主要优势： 1.提前对静态内容进行预缓存，避免当地用户大量的请求回源，导致主站网络带宽被打满而导致数据无法更新,变向的 减小了存储、Web服务器、数据库的压力； 2.CDN还可以将数据根据访问的热度不通而进行不通级别的缓存，例如访问量最高的资源访问CDN边缘节点的内存，其次 的放在SSD(经常访问的数据放到SSD)或者SATA(不经常访问的放到SATA)，再其次的放在云存储，这样兼顾了速度与成 本。缓存-缓存到最快的地方如内存，缓存的数据准确命中率高，访问速度就快 3.将用户准确调度到最近的边缘节点性能优化，加快访问速度; 4.CDN还可以进行安全相关-抵御攻击 5.最主要的还是节省带宽； 3.应用层缓存Nginx、PHP、tomcat等web服务可以设置应用缓存以加速响应用户请求，另外有些解释性语言比如PHP/Python不能直接运行 ，需要先编译成字节码，但字节码需要解释器解释为机器码之后才能执行，因此字节码也是一种缓存，有时候会出现程序代 码上线后字节码没有更新的现象。 4.其他缓存CPU缓存(L1的数据缓存和L1的指令缓存)、二级缓存、三级缓存 磁盘缓存 RAID卡缓存 分布式缓存：redis、memcache # MegaCli64 -LDinfo -Lall -aAll 此命令可以监控到物理机的raid、磁盘等信息 Redis和Memcached 1.Redis和Memcached是非关系型数据库也称为NoSQL， 2.redis是一个开源的、遵循BSD协议的、基于内存的而且目前比较流行的键值数据库(key-value database)，是一个非关 系型数据库，redis提供将内存通过网络远程共享的一种服务，提供类似功能的还有memcache，但相比memcache，redis还 提供了易扩展、高性能、具备数据持久性等功能； 3.redis是单线程的，在高并发、低延迟环境要求比较高的环境使用量非常广泛，memcached是多进程的. redis和memcached的对比： 1.支持两种方式进行数据的持久化：可以将内存中的数据保持在磁盘中，重启redis服务或者服务器之后可以从备份文 件中恢复数据到内存继续使用。 2.支持更多的数据类型：支持string(字符串)、hash(哈希数据)、list(列表)、set(集合)、zet(有序集合) 3.支持数据的备份：可以实现类似于数据的master-slave模式的数据备份，另外也支持使用快照+AOF； 4.支持更大的value数据：memcache单个key value最大只支持1MB，而redis最大支持 512MB； 5.Redis 是单线程，而memcache是多线程，所以单机情况下没有memcache并发高，但redis 支持分布式集群以实现更高的并发，单Redis实例可以实现数万并发。 6.支持集群横向扩展：基于redis cluster的横向扩展，可以实现分布式集群，大幅提 升性能和数据安全性。 7.都是基于C语言开发。 redis的典型应用场景： Session共享：常见于web集群中的Tomcat或者PHP中多web服务器session共享 详见：tomcat的session cluster/server共享 消息队列：ELK的日志缓存、部分业务的订阅发布系统 计数器：访问排行榜、商品浏览数等和次数相关的场景 缓存：数据查询、电商网站商品信息、新闻内容 微博/微信社交场合：共同好友、点赞评论等 redis的主要功能： 1.Redis支持多种数据结构，包括字符串、哈希表、链表、集合、有序集合、位图、Hyperloglogs等; 2.Redis具备LRU淘汰、事务实现、以及不同级别的硬盘持久化等能力，并且支持副本集和 通过Redis Sentinel实现的高可用方案，同时还支持通过Redis Cluster实现的数 据自动分片能力; 3.Redis的主要功能都基于单线程模型实现，也就是说Redis使用一个线程来服务所有的 客户端请求，同时Redis采用了非阻塞式IO，并精细地优化各种命令的算法时间复杂度， 这些信息意味着： 1.Redis是线程安全的（因为只有一个线程），其所有操作都是原子的，不会因并发产生数据异常; 2.Redis的速度非常快（因为使用非阻塞式IO，且大部分命令的算法时间复杂度都是O(1)); 3.使用高耗时的Redis命令是很危险的，会占用唯一的一个线程的大量处理时间，导致所有的请求都被拖慢。 （例如时间复杂度为O(N)的KEYS命令，严格禁止在生产环境 中使用); Redis安装版本： 公司现在一般用的是3.X 4.X版本的，最新是5.3版本了 http://download.redis.io/releases/ epel源上的redis版本是3.2.12，这里进行编译安装redis-5.0.3版本； 编译安装： [root@node01 ~]# cd /usr/local/src [root@node01 src]# tar xf redis-5.0.3.tar.gz [root@node01 src]# cd redis-5.0.3 [root@node01 redis-5.0.3]# make PREFIX=/usr/local/redis install #将二进制命令放到/usr/local/redis下 编译安装的就不能使用systemctl进行启动了，可以根据yum安装的程序路径进行修改； [root@node01 redis]# mkdir /usr/local/redis/etc/ #创建配置文件目录 [root@node01 redis]# mkdir /usr/local/redis/data/ #创建数据目录 [root@node01 redis]# mkdir /usr/local/redis/logs/ #创建日志存放目录 [root@node01 redis]# mkdir /usr/local/redis/run/ ##创建pid目录 [root@node01 redis]# cp /usr/local/src/redis-5.0.3/redis.conf /usr/local/redis/etc/ #将原来目录下的redis.conf文件拷贝到二进制命令的目录下 redis相关命令: [root@node01 bin]# ll total 32672 -rwxr-xr-x. 1 root root 4366608 Mar 10 03:28 redis-benchmark -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-check-aof #用于检查aof文件异常状态 -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-check-rdb #用于检查rbd文件异常状态 -rwxr-xr-x. 1 root root 4801864 Mar 10 03:28 redis-cli #redis客户端命令 lrwxrwxrwx. 1 root root 12 Mar 10 03:28 redis-sentinel -&gt; redis-server #哨兵命令 -rwxr-xr-x. 1 root root 8090040 Mar 10 03:28 redis-server #redis主程序用于启动redis 启动： [root@node01 redis]# pwd /usr/local/redis [root@node01 redis]# /usr/local/redis/bin/redis-server etc/redis.conf #启动后会有三个警告信息一定要修改，不然运行后期会有错误 解决启动时三个报警信息： 1.backlog参数控制的是三次握手的时候server端收到client ack确认号之后的队列值。 net.core.somaxconn = 512 2.vm.overcommit_memory： 0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存 申请失败，并把错误返回给应用进程。 1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 2 表示内核允许分配超过所有物理内存和交换空间总和的内存 vm.overcommit_memory = 1 #因为memcached和redis是直接操作内存的，内存的参数不需要使用内核的参数来调了; 3.transparent hugepage： 开启大页内存动态分配，需要关闭让redis 负责内存管理。 echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled #如果是虚拟化的情况下，需要打开； 修改配置文件并开机自动生效： [root@node01 etc]# vim /etc/rc.d/rc.local echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled [root@node01 etc]# chmod +x /etc/rc.d/rc.local [root@node01 etc]# vim /etc/sysctl.conf net.core.somaxconn = 512 vm.overcommit_memory = 1 创建用户： [root@node01 redis]# useradd redis -s /sbin/nologin 设置目录权限： [root@node01 redis]# chown redis.redis /usr/local/redis/ -R #redis用户要对编译的路径有权限 创建软链接： [root@node01 bin]# ln -sv /usr/local/redis/bin/redis-* /usr/sbin/ 编辑redis服务启动脚本: # cat /usr/lib/systemd/system/redis.service [Unit] Description=Redis persistent key-value database After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf --supervised systemd ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target 启动： systemctl start redis Redis配置文件详解登录： [root@node01 bin]# redis-cli -h host (设置了bind就需要指定IP地址) info #查看redis信息 select #切换数据库，默认是16个库(编号0-15) redis配置文件主要配置项： ###########################基础信息配置##################################### bind 0.0.0.0 #监听地址，可以用空格隔开后多个监听IP #一般只监听在redis服务器的内网IP上,redis强烈建议内网使用 protected-mode yes #redis3.2 之后加入的新特性，在没有设置bind IP和密码的时候只允许访问127.0.0.1:6379 port 6379 #监听端口 tcp-backlog 511 #三次握手的时候server端收到client ack确认号之后的队列值。 timeout 0 #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时，生产环境下是600。 tcp-keepalive 300 #tcp 会话保持时间 daemonize no #认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes, 当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面 supervised no #和操作系统相关参数，可以设置通过upstart和systemd管理Redis守护进程，centos 7以后都使用systemd pidfile /usr/local/redis/redis_6379.pid #pid文件路径 #一般习惯放在编译的路径下(但是redis用户需要对此目录有读权限) loglevel notice #日志级别 #loglevel debug #如果日志显示不详细，可以开启debug模式，但是debug的日志会很大； logfile &quot;/usr/local/redis/redis_6379.log&quot; #日志路径 #一般习惯放在编译的路径下(但是redis用户需要对此目录有读权限) databases 16 #设置db 库数量，默认16个库 ##########################和快照相关的参数################################### ###快照时从redis主进程复制出一个专门的进程做快照，不会影响redis的读写 always-show-logo yes #在启动redis 时是否显示log save 900 1 #在900秒内有一个键内容发生更改就出就快照机制 save 300 10 save 60 10000 #也可以通过BGSAVE命令手工触发RDB快照保存。 stop-writes-on-bgsave-error yes #快照出错时是否禁止redis写入操作 #重要配置，一定要给成no,避免快照因为磁盘空间满了快照写不进去，使得redis 无法登陆； rdbcompression yes #持久化到RDB文件时，是否压缩，&quot;yes&quot;为压缩，&quot;no&quot;则反之 rdbchecksum yes #是否开启RC64校验，默认是开启 dbfilename dump.rdb #快照生成的文件名，一般给称redis_6379.rdb dir ./ #快照文件保存路径;一般放在二进制编译路径下/usr/loca/redis ##################### REPLICATION主从复制相关的参数#################### replicaof &lt;masterip&gt; &lt;masterport&gt; #修改为master的IP和端口 如： masterauth &lt;master-password&gt; #修改为master的验证密码 ####################和安全相关的参数配置#################################### requirepass root123456 #设置redis的登录密码 登录后，需要AUTH root23456验证后，才能set key 如果不设置密码，通过telnet就可以登录到redis进行删除等操作，所以生产环境下建议一定要设置密码. ####################和客户端相关的参数配置################################### maxclients 10000 #最大的客户端连接数 ####################内存管理与数据淘汰机制################################## maxmemory 8589934592 #单位是字节(8g*1024*1024*1024) 配置解析： 1.默认情况下，在32位OS中，Redis最大使用3GB的内存，在64位OS中则没有限制。 2.在使用Redis时，应该对数据占用的最大空间有一个基本准确的预估，并为Redis设定最大使用的内存。否则在64位 OS中Redis会无限制地占用内存（当物理内存被占满后会使用swap空间），容易引发各种各样的问题； 3.在内存占用达到了maxmemory后，再向Redis写入数据时，Redis会： 1.根据配置的数据淘汰策略尝试淘汰数据，释放空间 2.如果没有数据可以淘汰，或者没有配置数据淘汰策略，那么Redis会对所有写请求返回错误，但读请求仍然可以正常执行 4.在为Redis设置maxmemory时，需要注意： 1.如果采用了Redis的主从同步，主节点向从节点同步数据时，会占用掉一部分内存空间，如果maxmemory过于接 近主机的可用内存，导致数据同步时内存不足。所以设置的maxmemory不要过于接近主机可用的内存，留出一部分预留用作主从同步。 #################### AOF日志相关配置 ####################################### appendonly yes #启用aof日志，类似于mysql的bin-log,一定要改成yes #登录redis的select Set等操作就会被记录在此日志中 appendfilename &quot;appendonly.aof&quot; #aof日志的路径和名称 #注意这个路径是以上面的dir路径为根的 ----------------------------------------------------------- #AOF提供了三种fsync配置，always/everysec/no，通过配置项[appendfsync]指定： # appendfsync always #每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢 appendfsync everysec #折中的做法，交由后台线程每秒fsync一次 # appendfsync no #不进行fsync，将flush文件的时机交给OS决定，速度最快 ---------------------------------------------------------- #随着AOF不断地记录写操作日志，必定会出现一些无用的日志，例如某个时间点执行了命令SET key1 “abc”， 在之后某个时间点又执行了SET key1 “bcd”，那么第一条命令很显然是没有用的。大量的无用日志会 让AOF文件过大，也会让数据恢复的时间过长。 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb #触发aof日志rewrite #上面两行配置的含义是，Redis在每次AOF rewrite时，会记录完成rewrite后的AOF日志大小，当AOF日志大小在该基础上增长了100%后，自动进行 AOF rewrite。同时如果增长的大小没有达到64mb，则不会进行rewrite。 ############################# 慢日志查询相关配置 ########################## Slow log 是 Redis 用来记录查询执行时间的日志系统，slow log 保存在内存里面， 读写速度非常快，因此你可以放心地使用它，不必担心因为开启 slow log 而损害 Redis 的速度。 slowlog-log-slower-than 10000 #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作。 slowlog-max-len 128 #记录多少条慢日志保存在队列，超出后会删除最早的，以此滚动删除 Redis的数据结构和常用命令Key: 1.Redis采用Key-Value型的基本数据结构，任何二进制序列都可以作为Redis的Key使用（例如普通的字符串或一张JPEG图片） 2.关于Key的一些注意事项： 1.不要使用过长的Key。例如使用一个1024字节的key就不是一个好主意，不仅会消耗更多的内存，还会导致查找的效率降低 2.Key短到缺失了可读性也是不好的，例如”u1000flw”比起”user:1000:followers”来说，节省了寥寥的存储空间，却引发了可读性和可维护性上的麻烦 3.最好使用统一的规范来设计Key，比如”object-type:id:attr”，以这一规范设计出的Key可能是”user:1000″或 ”comment:1234:reply-to” 4.Redis允许的最大Key长度是512MB（对Value的长度限制也是512MB） 1.字符串:String1.String是Redis的基础数据类型，Redis没有Int、Float、Boolean等数据类型的概念，所有的基本类型在Redis中都以String体现; SET：为一个key设置value，可以配合EX/PX参数指定key的有效期，通过NX/XX参数针对 key是否存在的情况进行区别操作，时间复杂度O(1) GET：获取某个key对应的value，时间复杂度O(1) GETSET：为一个key设置value，并返回该key的原value，时间复杂度O(1) MSET：为多个key设置value，时间复杂度O(N) MSETNX：同MSET，如果指定的key中有任意一个已存在，则不进行任何操作，时间复杂度O(N) MGET：获取多个key对应的value，时间复杂度O(N) 2.redis的基本数据类型只有String，但Redis可以把String作为整型或浮点型数字来使用，主要体现在INCR、DECR类的命令上： 1.INCR：将key对应的value值自增1，并返回自增后的值。只对可以转换为整型的String 数据起作用。时间复杂度O(1) 2.INCRBY：将key对应的value值自增指定的整型数值，并返回自增后的值。只对可以转换 为整型的String数据起作用。时间复杂度O(1) 3.DECR/DECRBY：同INCR/INCRBY，自增改为自减。 备注： 1.INCR/DECR系列命令要求操作的value类型为String，并可以转换为64位带符号的整型 数字，否则会返回错误。 2.也就是说，进行INCR/DECR系列命令的value，必须在[-2^63 ~ 2^63 – 1]范围内。 3.前文提到过，Redis采用单线程模型，天然是线程安全的，这使得INCR/DECR命令可以 非常便利的实现高并发场景下的精确控制。 例1：库存控制 在高并发场景下实现库存余量的精准校验，确保不出现超卖的情况。 设置库存总量： SET inv:remain &quot;100&quot; 库存扣减+余量校验： DECR inv:remain 当DECR命令返回值大于等于0时，说明库存余量校验通过，如果返回小于0的值，则说明库存已耗尽。 假设同时有300个并发请求进行库存扣减，Redis能够确保这300个请求分别得到99到-200的返回值，每个请求得到的 返回值都是唯一的，绝对不会找出现两个请求得到一样的返回值的情况。 例2：自增序列生成 实现类似于RDBMS的Sequence功能，生成一系列唯一的序列号 设置序列起始值： SET sequence &quot;10000&quot; 获取一个序列值： INCR sequence 直接将返回值作为序列使用即可； 获取一批（如100个）序列值： INCRBY sequence 100 假设返回值为N，那么[N – 99 ~ N]的数值都是可用的序列值。 当多个客户端同时向Redis申请自增序列时，Redis能够确保每个客户端得到的序列值或序 列范围都是全局唯一的，绝对不会出现不同客户端得到了重复的序列值的情况。 2.列表：和ELK相关，基于管道插入多个数据Redis的List是链表型的数据结构，可以使用LPUSH/RPUSH/LPOP/RPOP等命令在List的两端执行插入元素和弹出元素的 操作。虽然List也支持在特定index上插入和读取元素的功能，但其时间复杂度较高（O(N)），应小心使用； 1.LPUSH：向指定List的左侧（即头部）插入1个或多个元素，返回插入后的List长度。 时间复杂度O(N)，N为插入元素的数量 2.RPUSH：同LPUSH，向指定List的右侧（即尾部）插入1或多个元素 3.LPOP：从指定List的左侧（即头部）移除一个元素并返回，时间复杂度O(1) 4.RPOP：同LPOP，从指定List的右侧（即尾部）移除1个元素并返回 5.LPUSHX/RPUSHX：与LPUSH/RPUSH类似，区别在于，LPUSHX/RPUSHX操作的key 如果不存在，则不会进行任何操作 6.LLEN：返回指定List的长度，时间复杂度O(1) 7.LRANGE：返回指定List中指定范围的元素（双端包含，即LRANGE key 0 10会返回 11个元素），时间复杂度O(N)。应尽可能控制一次获取的元素数量，一次获取过大范 围的List元素会导致延迟，同时对长度不可预知的List，避免使用LRANGE key 0 -1这样的完整遍历操作。 应谨慎使用的List相关命令： 1.LINDEX：返回指定List指定index上的元素，如果index越界，返回nil。index数值是 回环的，即-1代表List最后一个位置，-2代表List倒数第二个位置。时间复杂度O(N) 2.LSET：将指定List指定index上的元素设置为value，如果index越界则返回错误， 时间复杂度O(N)，如果操作的是头/尾部的元素，则时间复杂度为O(1) 3.LINSERT：向指定List中指定元素之前/之后插入一个新元素，并返回操作后的List长 度。如果指定的元素不存在，返回-1。如果指定key不存在，不会进行任何操作，时间复杂度O(N) 由于Redis的List是链表结构的，上述的三个命令的算法效率较低，需要对List进行遍历， 命令的耗时无法预估，在List长度大的情况下耗时会明显增加，应谨慎使用。 换句话说，Redis的List实际是设计来用于实现队列，而不是用于实现类似ArrayList这样的 列表的。如果你不是想要实现一个双端出入的队列，那么请尽量不要使用Redis的List数据结构 3.集合:SetRedis Set是无序的，集合成员是唯一的，不可重复的String集合. 与Set相关的常用命令： 1.SADD：向指定Set中添加1个或多个member，如果指定Set不存在，会自动创建一个。 时间复杂度O(N)，N为添加的member个数 2.SREM：从指定Set中移除1个或多个member，时间复杂度O(N)，N为移除的member个数 3.SRANDMEMBER：从指定Set中随机返回1个或多个member，时间复杂度O(N)，N为返回的 member个数; 4.SPOP：从指定Set中随机移除并返回count个member，时间复杂度O(N)，N为移除的 member个数; 5.SCARD：返回指定Set中的member个数，时间复杂度O(1) 6.SISMEMBER：判断指定的value是否存在于指定Set中，时间复杂度O(1) 7.SMOVE：将指定member从一个Set移至另一个Set SADD set1 v1 #生成集合key TYPE set1 #查询集合key SADD set1 v2 v3 v4 #追加数值，追加的时候不能追加已经存在的数值 SMEMBERS set1 #查看集合的所有数据 SDIFF set1 set2 #获取集合的差集 #差集：已属于A而不属于B的元素称为A与B的差（集） SINTER set1 set2 #获取集合的交集 #交集：已属于A且属于B的元素称为A与B的交（集） SUNION set1 set2 #获取集合的并集 #并集：已属于A或属于B的元素为称为A与B的并（集） 慎用的Set相关命令： 1.SMEMBERS：返回指定Hash中所有的member，时间复杂度O(N) 2.SUNION/SUNIONSTORE：计算多个Set的并集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数 3.SINTER/SINTERSTORE：计算多个Set的交集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数 4.SDIFF/SDIFFSTORE：计算1个Set与1或多个Set的差集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数 上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的Set尺寸不可知的情况下，应严格避免使用 4.有序集合：sorted set1.Sorted Set非常适合用于实现排名。 2.Redis Sorted Set和Set一样也是string类型元素的集合,且不允许重复的成员，不同的是 Sorted Set中的每个元素都会关联一个double(双精度浮点型)类型的分数(score)，Sorted Set会根据score对元素 进行升序排序。如果多个member拥有相同的score，则以字典序进行升序排序;序集合的成员是唯一的,但分数(score) 却可以重复，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)，集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员); Sorted Set的主要命令： 1.ZADD：向指定Sorted Set中添加1个或多个member，时间复杂度O(Mlog(N))，M为添加的member数量，N为Sorted Set中的member数量 2.ZREM：从指定Sorted Set中删除1个或多个member，时间复杂度O(Mlog(N))，M为删除的member数量，N为Sorted Set中的member数量 3.ZCOUNT：返回指定Sorted Set中指定score范围内的member数量，时间复杂度：O(log(N)) 4.ZCARD：返回指定Sorted Set中的member数量，时间复杂度O(1) 5.ZSCORE：返回指定Sorted Set中指定member的score，时间复杂度O(1) 6.ZRANK/ZREVRANK：返回指定member在Sorted Set中的排名，ZRANK返回按升序排序的排名，ZREVRANK则 返回按降序排序的排名。时间复杂度O(log(N)) 7.ZINCRBY：同INCRBY，对指定Sorted Set中的指定member的score进行自增， 时间复杂度O(log(N)); 慎用的Sorted Set相关命令： 1.ZRANGE/ZREVRANGE：返回指定Sorted Set中指定排名范围内的所有member，ZRANGE为按score升序排序， ZREVRANGE为按score降序排序，时间复杂度O(log(N)+M)，M为本次返回的member数 2.ZRANGEBYSCORE/ZREVRANGEBYSCORE：返回指定Sorted Set中指定score范围内的所有member，返回结果以 升序/降序排序，min和max可以指定为-inf和+inf，代表返回所有的member。时间复杂度O(log(N)+M) 3.ZREMRANGEBYRANK/ZREMRANGEBYSCORE：移除Sorted Set中指定排名范围/指定 score范围内的所有member。时间复杂度O(log(N)+M) 上述几个命令，应尽量避免传递[0 -1]或[-inf +inf]这样的参数，来对Sorted Set做 一次性的完整遍历，特别是在Sorted Set的尺寸不可预知的情况下。可以通过ZSCAN命令 来进行游标式的遍历. 5.Hash1.Hash即哈希表，Redis的Hash和传统的哈希表一样，是一种field-value型的数据结构，可以理解成将HashMap搬入Redis； 2.Hash非常适合用于表现对象类型的数据，用Hash中的field对应对象的field即可，hash特别适合用于存储对象, Redis 中每个hash可以存储 232-1键值对(40多亿). 1.HSET：将key对应的Hash中的field设置为value。如果该Hash不存在，会自动创建一个。时间复杂度O(1) 2.HGET：返回指定Hash中field字段的值，时间复杂度O(1) 3.HMSET/HMGET：同HSET和HGET，可以批量操作同一个key下的多个field，时间 复杂度：O(N)，N为一次操作的field数量 4.HSETNX：同HSET，但如field已经存在，HSETNX不会进行任何操作，时间复杂度O(1) 5.HEXISTS：判断指定Hash中field是否存在，存在返回1，不存在返回0，时间复杂度O (1)HDEL：删除指定Hash中的field（1个或多个），时间复杂度：O(N)，N为操作的field数量 6.HINCRBY：同INCRBY命令，对指定Hash中的一个field进行INCRBY，时间复杂度O(1) 应谨慎使用的Hash相关命令： 1.HGETALL：返回指定Hash中所有的field-value对。返回结果为数组，数组中field和value交替出现。时间复杂度O(N) 2.HKEYS/HVALS：返回指定Hash中所有的field/value，时间复杂度O(N) 上述三个命令都会对Hash进行完整遍历，Hash中的field数量与命令的耗时线性相关，对于尺寸不可预知的Hash， 应严格避免使用上面三个命令，而改为使用HSCAN命令进行游标式的遍历 消息队列redis除了支持数据类型之外还支持消息队列：生产者消费者模式和发布者订阅者模式. 生产者消费者模式: 1.微服务架构是将比如多个war包分开部署作为独立的小服务，这些服务之间存在着相互 调用的关系，他们是通过特殊的管道发送消息，其他服务也会监听这个管道，当有消息过 来时会读取处理完后再发送到管道给其他服务去完成整个过程，然后再返回给用户. 2.常用的软件还有RabbitMQ、Kafka、RocketMQ、ActiveMQ等. redis实现生产者消费者模式： 1.生产者发布消息 192.168.34.117:6379&gt; LPUSH channel1 msg1 #从管道的左侧写入 (integer) 1 192.168.34.117:6379&gt; LPUSH channel1 msg2 (integer) 2 192.168.34.117:6379&gt; LPUSH channel1 msg3 (integer) 3 2.查看队列所有消息 192.168.34.117:6379&gt; LRANGE channel1 0 -1 1) &quot;msg3&quot; 2) &quot;msg2&quot; 3) &quot;msg1&quot; 3.消费者消费消息 192.168.34.117:6379&gt; RPOP channel1 #从管道的右侧消费 &quot;msg1&quot; 4.再次验证队列消息 192.168.34.117:6379&gt; LRANGE channel1 0 -1 1) &quot;msg3&quot; 2) &quot;msg2&quot; #队列中的msg1消息已经被消费了，只剩两条消息了. 发布者订阅模式： 在发布者订阅者模式下，发布者将消息发布到指定的channel里面，凡是监听该channel的消费者都会收到 同样的一份消息，这种模式类似于是收音机模式，即凡是收听某个频道的听众都会收到主持人发布的相同的消息内容 redis实现发布者订阅模式： 1.订阅者监听频道 192.168.34.117:6379&gt; SUBSCRIBE channel2 #订阅消息 Reading messages... (press Ctrl-C to quit) 1) &quot;subscribe&quot; 2) &quot;channel2&quot; 3) (integer) 1 2.发布者发布消息 192.168.34.117:6379&gt; PUBLISH channel2 test1 #发布消息 (integer) 1 3.各订阅者得到验证消息 192.168.34.117:6379&gt; SUBSCRIBE channel2 Reading messages... (press Ctrl-C to quit) 1) &quot;subscribe&quot; 2) &quot;channel2&quot; 3) (integer) 1 1) &quot;message&quot; 2) &quot;channel2&quot; 3) &quot;test1&quot; #此时订阅此频道的就可以看到消息了 Redis常用命令1.CONFIG： config命令用于查看当前redis配置、以及不重启更改redis配置等。config可以完成绝大多数的redis.config文件中的配置. 示例：直接更改最大内存，而且是立即生效的 192.168.34.117:6379&gt; CONFIG set maxmemory 8589934592 OK 127.0.0.1:6379&gt; CONFIG get maxmemory 1) &quot;maxmemory&quot; 2) &quot;8589934592&quot; 示例：查看redis的配置信息 192.168.34.117:6379&gt; CONFIG GET * 1) &quot;dbfilename&quot; 2) &quot;redis_6379.rdb&quot; 3) &quot;requirepass&quot; 4) &quot;&quot; 5) &quot;masterauth&quot; 213) &quot;bind&quot; 214) &quot;192.168.34.117&quot; #ONFIG GET *看到的奇数行是配置，偶数行是它的值 示例:更改密码 192.168.34.117:6379&gt; CONFIG SET requirepass 123456 OK 2.INFO 显示当前节点redis运行状态信息 # Server #server端配置信息 # Clients #client端配置信息 # Memory #Memory配置信息 # Persistence #rbd和aof持久化配置信息 # Stats #当前状态 # Replication #集群相关信息(配置完集群查看是否正常) # CPU #CPU配置信息 # Cluster #集群信息 # Keyspace #redis的键时间通知 3.SELECT 切换数据库 192.168.34.117:6379&gt; SELECT 6 OK #redis是基于库做的隔离，不同的库是为了存放不同类型的key 4.keys 查看当前库下的所有key 注意： 在redis数据量大的时候，禁止使用keys *命令，严重情况下回造成redis服务器的 IO爆满而出现故障！可以先用DBSIZE看一下有多少个key! 5.BGSAVE：非阻塞 手动在后台执行RDB持久化操作，会立即启动一个后台进程做快照 192.168.34.117:6379[6]&gt; BGSAVE Background saving started 6.SAVE：阻塞 执行SAVE时，数据量比较大时，需要几秒甚至更长的时间将数据保存到磁盘上，如果再SAVE过程中，写入请求会中断 的，可能会造成数据丢失，所以一般用BGSAVE. 7.DBSIZE 显示当前库下的所有key数量 192.168.34.117:6379&gt; DBSIZE (integer) 2 8.FLUSHDB 强制清空当前库中的所有key,慎重使用！ 9.FLUSHALL 强制清空当前redis服务器所有数据库中的所有key，即删除所有数据,慎重使用！ Redis数据持久化redis虽然是一个内存级别的缓存程序，即redis是使用内存进行数据的缓存的，但是其可以将内存的数据按照一定的策略 保存到硬盘上，从而实现数据持久保存的目的，redis支持两种不同方式的数据持久化保存机制，分别是RDB和AOF. 必须使用数据持久化吗？ 但通常来说，仍然建议至少开启RDB方式的数据持久化，因为： 1.RDB方式的持久化几乎不损耗Redis本身的性能，在进行RDB持久化时，Redis主进 程唯一需要做的事情就是fork出一个子进程，所有持久化工作都由子进程完成 2.Redis无论因为什么原因crash掉之后，重启时能够自动恢复到上一次RDB快照中记 录的数据。这省去了手工从其他数据源（如DB）同步数据的过程，而且要比其他任何的数据恢复方式都要快 3.现在硬盘那么大，真的不缺那一点地方. AOF：类似于数据库的binlog，将文件拷贝走，放到另外一台redis的数据目录，自动恢复 AOF中记录的是每次在redis的操作，和mysql的bin-log类似; RBD:基于时间的快照技术，在save 900 1，在900秒内有一个键内容发生更改就快照机制； 在同时开启AOF和RBD时，因为AOF的级别比RBD高会使用AOF模式. 生产环境： 生产环境下，一般在Slave服务器上同时开启AOF和RDB，Master上只开启RBD.但是生产环境下是需要做集群来解决数据高可用的问题. RDB模式RDB：基于时间的快照，默认只保留当前最新的一次快照(会把上一次的快照切换掉)，特点 是执行速度比较快，缺点是可能会丢失从上次快照到当前快照未完成之间的数据(即在两次快照时间之间redis服务可能出现故障，数据会丢失);如果是AOF模式，则不会发生此问题. RDB实现的具体过程： 1.Redis从主进程先fork出一个子进程，使用写时复制机制，子进程将内存的数据保存为一个临时文件，比如 dump.rdb.temp，当数据保存完成之后再将上一次保存的RDB文件替换掉，然后关闭子进程，这样可以保存每一次做 RDB快照的时候保存的数据都是完整的，因为直接替换RDB文件的时候可能会出现突然断电等问题而导致RDB文件还没有 保存完整就突然关机停止保存而导致数据丢失的情况，可以手动将每次生成的RDB文件进程备份，这样可以最大化保存历史数据。 2.因为会单独开一个子进程负责做快照，所以不影响redis的读写请求. 3.通常连到redis之后，通过脚本执行BGSAVE,每隔多长时间执行一次手动RBD数据备份 RDB模式的优缺点： 优点： 1.RDB快照保存了某个时间点的数据，可以通过脚本执行bgsave(非阻塞)或者save(阻塞)命令自定义时间点备份，可以保留多个备份，当出现问题可以恢复到不同时间点的版本。 2.可以最大化o的性能，因为父进程在保存RDB 文件的时候唯一要做的是fork出一个子进程，然后的-操作都会有这个子进程操作，父进程无需任何的IO操作; 3.RDB在大量数据比如几个G的数据，恢复的速度比AOF的快； 因为RDB是直接将几个G的文件导入到内存中，AOF中记录的是几千上万行的操作命令， 在数据恢复时，需要逐行执行. 缺点： 1-不能实时的保存数据，会丢失自上一次执行RDB备份到当前的内存数据； 2-数据量非常大的时候，从父进程fork的时候需要一点时间，可能是毫秒或者秒； 生产环境下遇到的坑：redis RDB持久化模式有坑,因为我们使用的服务器是机械硬盘，读写性能和SSD固态硬盘相差很大，服务器内存是128G， 当时给redis分了最大内存是120G，每fork一次就出来一个新的进程，但是在此触发持久化的条件后又会fork一个进程出来 ，前一个还未写到硬盘中，后一个fork已经出现孙子辈的了，甚至重孙辈的，导致服务器资源耗尽，宕机。还有个redis强烈 建议内网使用，程序调用也是内网，程序调用也是内网，程序调用也是内网。因为有一次被黑就是redis在公网上跑，还没有设置密码,导致将近20台服务器被黑。 AOF模式AOF:按照用户或Web服务器的操作顺序依次将操作添加到指定的日志文件当中，特点是数据安全性相对较高，缺点是即使有些操作是重复的也会全部记录. AOF实现的具体过程: AOF和RDB一样使用了写时复制机制，AOF默认为每秒钟fsync一次，即将执行的命令保存到AOF文件当中，这样即使 redis服务器发生故障的话顶多也就丢失1秒钟之内的数据，也可以设置不同的fsync策略，或者设置每次执行命令的 时候执行fsync，fsync会在后台执行线程，所以主线程可以继续处理用户的正常请求而不受到写入AOF文件的IO影响 AOF的优点点： 1.最安全，在启用appendfsync always时(fsync是同步内存中redis所有已经修改的文件到存储设备) ，任何已写入的数据都不会丢失，使用在启用appendfsync everysec也至多只会丢失1秒的数据。 2.AOF文件在发生断电等问题时也不会损坏，即使出现了某条日志只写入了一半的情况， 也可以使用redis-check-aof工具轻松修复。 3.AOF文件易读，可修改，在进行了某些错误的数据清除操作后，只要AOF文件没有 rewrite，就可以把AOF文件备份出来，把错误的命令删除，然后恢复数据。 AOF模式缺点: 1.AOF文件通常比RDB文件更大 2.性能消耗比RDB高 3.数据恢复速度比RDB慢]]></content>
      <categories>
        <category>缓存</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql高可用]]></title>
    <url>%2F2017%2F05%2F20%2Fmysql%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[mysql的高可用 MHA:一主多从架构 1.对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点，基于主从复制实现 2.可以监控多组主从复制集群 MHA工作原理 1.从宕机崩溃的master保存二进制日志事件（binlog events） 2.识别含有最新更新的slave 3.应用差异的中继日志（relay log）到其他的slave 4.应用从master保存的二进制日志事件（binlog events） 5.提升一个slave为新的master 6.使其他的slave连接新的master进行复制 Galera Cluster：多主架构 1.任何一节点都可读写，不需要主从复制，实现多主读写，实现的是多主方案的实现 2.基于wsrep(MySQL extended with the Write Set Replication)通过wsrep协议在全局实现复制 MHA的实现 准备环境： 1.实现主从复制集群，并将忽略名称解析项启用 skip-name-resolv 2.各主机互相基于ssh-key验证 ssh-keygen ssh 10.10.0.5(自己的IP) scp /root/.ssh 10.10.0.3|6|7:/root/即可 3.各主机的时间需要同步 主节点： 1.修改配置文件： vim /etc/my.cnf [mysqld] log-bin server_id=1 skip_name_resolve=1 2.为MHA创建账户，用于管理和提升各节点作为新的主节点 grant all on *.* to mhauser@&apos;10.10.0.%&apos; identified by &apos;mha123&apos;; 从节点： 1.修改配置文件： vim /etc/my.cnf [mysqld] server-id=2|3|4|5 log_bin 启用二进制日志，因为每一台都可能成为一个主 relay_log_purge=0 不清除中继日志，用于补全主节点down机后丢失的信息 read_only skip_name_resolve=ON 安装软件包： 依赖于epel源，需启用 MHA管理节点：Manager工具包和Node工具包 数据库各节点：安装Node工具包 MHA管理节点上配置： vim /etc/mha/mysqlcluster1.cnf [server default] user=mhauser password=mha123 manager_workdir=/etc/mha/cluster1/ manager_log=/etc/mha/cluster1/manager.log remote_workdir=/etc/mha/cluster1/ ssh_user=root repl_user=repluser repl_password=root123 ping_interval=1 [server1] hostname=10.10.0.5 candidate_master=1 [server2] hostname=10.10.0.6 candidate_master=1 [server3] hostname=10.10.0.7 candidate_master=1 测试启动： 测试ssh-key验证是否成功 masterha_check_ssh --conf=/etc/mha/mysqlcluster1.cnf 测试mysqlcluster1配置文件是否能正常连接各个数据库： masterha_check_repl --conf=/etc/mha/mysqlcluster1.cnf 启用cluster masterha_manager --conf=/etc/mha/mysqlcluster1.cnf 故障测试： 1.把主节点down机 2.可以通过查询cat /etc/mha/cluster1/manager.log日志查看故障转移的节点信息 结论： 1.MHAcluster这里是以前台方式运行的，在生产环境下一定要以后台运行的 2.主节点down机后，MHA自动挑选一台从节点当主服务器： 所以show slave status\G和show variables like &apos;read_only&apos;; 都是空的或者是OFF状态，而且其他从节点的slave status看到的主节点 比变成了新的主节点了 3.对于前端的proxysql调度器还需要手动修改主节点信息 4.即使down机的&quot;主节点恢复正常了&quot;，也只是一台单机的服务器，不能再变成主节点 了，需要再进入到集群中，充当从节点 Galera Cluster的实现 Galera Cluster特点： 1.多主架构：真正的多点读写的集群，在任何时候读写数据，都是最新的 2.同步复制：集群不同节点之间数据同步，没有延迟，在数据库挂掉之后，数据 不会丢失 3.并发复制：从节点APPLY数据时，支持并行执行，更好的性能 4.故障切换：在出现数据库故障时，因支持多点写入，切换容易 5.热插拔：在服务期间，如果数据库挂了，只要监控程序发现的够快，不可服务 时间就会非常少。在节点故障期间，节点本身对集群的影响非常小 6.自动节点克隆：在新增节点，或者停机维护时，增量数据或者基础数据不需要 人工手动备份提供，Galera Cluster会自动拉取在线节点数据，最终集群会变为 一致 基于Mariadb Galera Cluster实现1.需要安装Mariadb Galera Cluster特定版本的数据库 配置过程： 1. 配置repo源 cat &gt; /etc/yum.repos.d/galera-cluster &lt;&lt;EOF [galera] name=&quot;galera-cluster&quot; baseurl=https://mirrors.tuna.tsinghua.edu.cn/mariadb//mariadb-10.0.37/yum/centos74-amd64/ enable=1 gpgcheck=0 EOF 2. 使用特定版本的数据库： yum install MariaDB-Galera-server -y 3. 在各节点都需要进行如下配置: vim /etc/my.cnf.d/server.cnf [galera] wsrep_provider=/usr/lib64/galera/libgalera_smm.so wsrep_cluster_address=&quot;gcomm://10.10.0.5,10.10.0.6,10.10.0.7&quot; binlog_format=row default_storage_engine=InnoDB innodb_autoinc_lock_mode=2 bind-address=0.0.0.0 4. 首次启动，需初始集群，在其中一个节点执行以下命令即可 /etc/init.d/mysql start --wsrep-new-cluster 5. 正常启动其它节点 service mysql start 6.查看集群中相关系统变量和状态变量 SHOW VARIABLES LIKE &apos;wsrep_%&apos;; SHOW STATUS LIKE &apos;wsrep_%&apos;; SHOW STATUS LIKE &apos;wsrep_cluster_size&apos;; 7.测试： 因为都是主节点，所以其中任何一个down机，其他节点也都是正常的 这样就实现了Mariadb Galera Cluster数据库集群的搭建 复制的问题和解决方案(1) 数据损坏或丢失 Master： MHA + semi repl 采用MHA+半同步复制的数据库集群 Slave： 重新复制 (2) 混合使用存储引擎 MyISAM：不支持事务 InnoDB： 支持事务 (3) 不惟一的server id 重新复制 (4) 复制延迟 需要额外的监控工具的辅助 一从多主:mariadb10版后支持 多线程复制：对多个数据库复制 Mysql的压力测试数据库服务衡量指标： qps:query per second，每秒钟支持多少个查询 tps:transaction per second，每秒钟支持多少个事务 压力测试工具： 1. Sysbench：功能强大 https://github.com/akopytov/sysbench 2.mysqlslap工具，默认安装mariadb时就会有这个工具 选项： --auto-generate-sql, -a 自动生成测试表和数据，表示用mysqlslap工具自己生成的SQL脚本来测试并发压力 --auto-generate-sql-load-type=type 测试语句的类型。代表要测试的环境是读操作还是写操作还是两者混合的。取值包括：read，key，write，update和mixed(默认) -engines engine_name 代表要测试的引擎，可以有多个，用分隔符隔开。例如：-engines=myisam,innodb --concurrency=N, -c N 表示并发量 --commint=N 如测试MyIsam和InnoDB的速度，虽然MyIsam的速度快，但是InnoDB的保证数据安全性更高，生产环境下一定要用InnoDB存储引擎]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cobbler]]></title>
    <url>%2F2017%2F05%2F06%2FCobbler%2F</url>
    <content type="text"><![CDATA[在服务器很多的情况下，用U盘或者光盘安装时，就显得有点吃力了，虽然可以用PXE进行安装，但是PXE不支持UEFI所以现在更多使用Cobbler来实现自动化部署. Cobbler工作原理 系统自动安装之-cobbler之前写过PXE自动化安装的文档，但是PXE只支持BIOS，不支持UEFI:PXE系统自动化部署Cobbler可以同时支持BIOS和UEFI两种：基于PXE技术为基础的整合 BIOS+MBR：分区最多支持2T的UEFI+GPT：分区可以支持大于2T的分区 在之前的工作中，需要建立大于2T的分区时，PXE安装就不合适了 cobbler:具有图形化管理界面的工具cobbler是什么？ 实际上是把PXE技术用python代码做了封装，形成了相对完整的自动化安装， 但是实现PXE的原有的httpd，DHCP，tftp服务还是需要提前安装的。 Cobbler: 快速网络安装linux操作系统的服务，支持众多的Linux发行版：Red Hat、 Fedora、CentOS、Debian、Ubuntu和SuSE，也可以支持网络安装windows PXE的二次封装，将多种安装参数封装到一个菜单 Python编写 提供了CLI和Web的管理形式 安装cobbler：EPEL源安装包 cobbler 基于EPEL源 cobbler 服务集成 前面说过因为是基于PXE的,安装cobbler因为有依赖性，会自动安装下面的服务 PXE DHCP rsync Httpd DNS Kickstart syslinux tftp-server IPMI 电源管理 启动cobbler:依赖于httpd，要想启动cobbler,必须先启动httpd systemctl start httpd tftp dhcp systemctl start cobblerd 然后再检查cobbler环境 cobbler check cobbler的相关配置文件安装：yum install cobbler dhcp 配置文件目录 /etc/cobbler /etc/cobbler/settings : cobbler 主配置文件(下文会对该文件修改4行) /etc/cobbler/iso/: iso模板配置文件 /etc/cobbler/pxe: pxe模板文件 /etc/cobbler/power: 电源配置文件 /etc/cobbler/user.conf: web服务授权配置文件 /etc/cobbler/users.digest: web访问的用户名密码配置文件 /etc/cobbler/dhcp.template : dhcp服务器的的配置末班 /etc/cobbler/dnsmasq.template : dns服务器的配置模板 /etc/cobbler/tftpd.template : tftp服务的配置模板 /etc/cobbler/modules.conf : 模块的配置文件 数据目录 /var/lib/cobbler/config/: 用于存放distros，system，profiles 等信息配置文件 /var/lib/cobbler/triggers/: 用于存放用户定义的cobbler命令 /var/lib/cobbler/kickstart/: 默认存放kickstart文件 /var/lib/cobbler/loaders/: 存放各种引导程序 镜像目录 /var/www/cobbler/ks_mirror/: 导入的发行版系统的所有数据 /var/www/cobbler/images/ : 导入发行版的kernel和initrd镜像用于远程网络启动 /var/www/cobbler/repo_mirror/: yum 仓库存储目录 日志目录 /var/log/cobbler/installing: 客户端安装日志 /var/log/cobbler/cobbler.log : cobbler日志 cobbler命令介绍cobbler commands介绍 cobbler check 核对当前设置是否有问题 cobbler list 列出所有的cobbler元素 cobbler report 列出元素的详细信息 cobbler sync 同步配置到数据目录,更改配置最好都要执行下 cobbler reposync 同步yum仓库 cobbler distro 查看导入的发行版系统信息 cobbler system 查看添加的系统信息 cobbler profile 查看配置信息 cobbler重要的参数:及下面需要修改的4行内容/etc/cobbler/settings中重要的参数设置 default_password_crypted: &quot;$1$gEc7ilpP$pg5iSOj/mlxTxEslhRvyp/&quot; server: 192.168.34.17 next_server: 192.168.34.17 server：&lt;cobbler服务器的 IP 地址&gt; manage_dhcp: 1 manage_tftpd：1 pxe_just_once：1 cobbler环境检查：先启动cobbler服务再检查1.先启动cobbler服务，再用cobbler check 进行检查 执行Cobbler check命令会报如下异常 1 : The ‘server’ field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it. 2 : For PXE to be functional, the ‘next_server’ field in /etc/cobbler/ settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 3 : some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run ‘cobbler get-loaders’ to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a recent version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The ‘cobbler get-loaders’ command is the easiest way to resolve these requirements. 4 : change ‘disable’ to ‘no’ in /etc/xinetd.d/rsync 5 : comment ‘dists’ on /etc/debmirror.conf for proper debian support 6 : comment ‘arches’ on /etc/debmirror.conf for proper debian support 7 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to ‘cobbler’ and should be changed, try: “openssl passwd -1 -salt ‘random-phrase-here’ ‘your-password-here’” to generate new one 8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them Cobbler的8项报错解决方法错误信息都是在/etc/cobbler/settings文件改了4行，在下文体现 执行Cobbler check报错解决方式 第一个错误解决方法： 1.修改/etc/cobbler/settings文件中的server参数的值为提供cobbler服务的主机相 应的IP地址或主机名：384行，然后重新启动cobbler server: 192.168.34.107 2.修改/etc/cobbler/settings文件中的next_server参数的值为提供PXE服务的主机 相应的IP地址:272行，指定的tftp的服务器地址 next_server: 192.168.34.107 3.执行cobbler get-loaders和cobbler sync； 如果当前节点可以访问互联网，执行&quot;cobbler get-loaders&quot;命令即可； cobbler会自动通过互联网把最小化的系统启动文件下载下来放到 /var/lib/cobbler/loaders/下，再通过&quot;cobbler sync&quot;命令同步到/var/lib/tftpboot/下 4.cobbler认为是在centos6上，tftp服务是依赖于xinetd的，提示启动xinetd,在 这里，由于是在cnetos7上安装的，这项可以忽略 5.执行“chkconfig rsync on”命令即可 4,5,6项如果是在centos7上安装的cobbler是不需要修改也可以启动的 7.第7项是说安装的操作系统密码cobbler事先已经帮忙设置好了，但是不安全，需要自己 去修改一个自定义的密码(通过openssl passwd -1)生成：101行 default_password_crypted：修改成自己设置的密码 备注：在这个提示里，还有一项建议修改，之前用PXE的时候，搭建的DHCP服务，dhcpd.conf 文件时通过模板生成的，但是在cobbler中，可以通过colbber来生成，但是需要改 /etc/cobbler/settings一项配置：242行 manage_dhcp: 0 改成 manage_dhcp: 1 再通过cobbler自带的dhcp模板：/etc/cobbler/dhcp.template，生成dhcpd.conf 只需要把这个模板改一下就行了，而不用想PXE那样通过模板生成dhcpd.conf文件 把dhcp.template里的网段地址改一下 subnet 192.168.34.0 netmask 255.255.255.0 { option subnet-mask 255.255.255.0; range dynamic-bootp 192.168.34.20 192.168.34.100; 再通过cobbler sync重新生成/etc/dhcp/dhcpd.conf,并且会开启DHCP服务 上面的报错全部解决之后，且httpd,tftp，dhcp,cobbler都启动之后，实际上就已经具备了雏形了/var/lib/tftpboot的目录结构:上面的第三步完成后就生成下面的所有文件了[root@mini7-1 tftpboot]#tree /var/lib/tftpboot /var/lib/tftpboot ├── boot │ └── grub │ └── menu.lst ├── etc ├── grub │ ├── efidefault │ ├── grub-x86_64.efi │ ├── grub-x86.efi │ └── images -&gt; ../images ├── images ├── images2 ├── memdisk ├── menu.c32 ├── ppc ├── pxelinux.0 ├── pxelinux.cfg │ └── default ├── s390x │ └── profile_list └── yaboot 接下来就要准备yum源了，只不过不用像PXE那样，不用自己搭建httpd服务，创建centos各个版本的目录了，通过cobbler集成命令将centos6和centos7的光盘文件导入，实际上就是拷贝到cobbler对应的目录下，查看一下磁盘空间，因为要导入两个光盘(centos6&amp;centos7)cobbler命令的选项： cobbler &lt;distro|profile|system|repo|image|mgmtclass|package|file&gt; ... [add|edit|copy|getks*|list|remove|rename|report] [options|--help] cobbler &lt;aclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink&gt; [options|--help] 这里用import选项将6和7的光盘导入cobbler的主机上 mount /dev/sr0 /mnt/ ---&gt;挂载centos7光盘 mount /dev/sr1 /media ---&gt;挂载centos6光盘 cobbler import --path=/mnt/ --name=Centos-7.5-x86_64 --arch=x86_64 cobbler import --path=/media/ --name=Centos-6.10-x86_64 --arch=x86_64 cobbler会把光盘拷贝到/var/www/cobbler/下分开存放，目录结构如下 [root@mini7-1 cobbler]#tree -d /var/www/cobbler /var/www/cobbler ├── images │ ├── Centos-6.10-x86_64 │ └── Centos-7.5-x86_64 ├── ks_mirror │ ├── Centos-6.10-x86_64 │ │ ├── EFI │ │ │ └── BOOT │ │ ├── images │ │ │ └── pxeboot │ │ ├── isolinux │ │ ├── Packages │ │ └── repodata │ ├── Centos-7.5-x86_64 │ │ ├── EFI │ │ │ └── BOOT │ │ │ └── fonts │ │ ├── images │ │ │ └── pxeboot │ │ ├── isolinux │ │ ├── LiveOS │ │ ├── Packages │ │ └── repodata │ └── config ├── links │ ├── Centos-6.10-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-6.10-x86_64 │ └── Centos-7.5-x86_64 -&gt; /var/www/cobbler/ks_mirror/Centos-7.5-x86_64 ├── localmirror ├── misc ├── pub ├── rendered ├── repo_mirror └── svc 拷贝完，cobbler sync再同步一次 然后cobbler会把/var/lib/tftpboot/pxelinux.cfg/default文件自动更新，生成新的菜单 DEFAULT menu PROMPT 0 MENU TITLE Cobbler | http://cobbler.github.io/ TIMEOUT 200 TOTALTIMEOUT 6000 ONTIMEOUT local LABEL local MENU LABEL (local) MENU DEFAULT LOCALBOOT -1 LABEL Centos-6.10-x86_64 kernel /images/Centos-6.10-x86_64/vmlinuz MENU LABEL Centos-6.10-x86_64 append initrd=/images/Centos-6.10-x86_64/initrd.img ksdevice=bootif lang= kssendmac text ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-6.10-x86_64 ipappend 2 LABEL Centos-7.5-x86_64 kernel /images/Centos-7.5-x86_64/vmlinuz MENU LABEL Centos-7.5-x86_64 append initrd=/images/Centos-7.5-x86_64/initrd.img ksdevice=bootif lang= kssendmac text ks=http://192.168.34.107/cblr/svc/op/ks/profile/Centos-7.5-x86_64 ipappend 2 MENU end 此时，就可以用cobbler实现自动化安装了，但是不能自定义ks应答文件安装，下面会讲解如何自定义cobbler的应答文件 Cobbler中自定义应答文件之前在PXE安装时，是自定义的kickstart应答文件，在cobbler中如何实现？ 1.在cobbler中，应答文件是放在/var/lib/cobbler/kickstarts/中 2.把之前制作的ks6-mini.cfg，ks7-mini.cfg拷贝到此目录，但是拷贝完，但cobbler是无 法识别这些应答文件是对应的那个发行版本的，所以要绑定 3.将自定义的应答文件和安装版本进行绑定 4.这两个应答文件有一项需要修改 即url --url=这一项，要改成cobbler的yum源路径，$tree 这里只显示ks6-mini.cfg的详细信息 install url --url=http://192.168.34.103/centos/6/os/x86_64/ (PXE下的源路径) #httpd的yum源路径，要改成$tree 或者改成具体的地址：即光盘拷贝到cobbler的具体路径 http://192.168.34.107/cobbler/ks_mirror/Centos-6.10-x86_64/ lang en_US.UTF-8 keyboard us text #纯文本安装 reboot #安装完重启 network --onboot yes --device eth0 --bootproto dhcp --noipv6 rootpw --iscrypted $6$6zeqEsKimGywyY3J$ngSoHUIrLaydTMIwnYX9tg4HOeOCXogU03miaQIc8sOwmq5N6.fPk3Jrmouns8VOekZkn0YQjQkt JjA57WrZO0 firewall --service=ssh 关闭防火墙 authconfig --enableshadow --passalgo=sha512 selinux --enforcing 关闭selinux timezone Asia/Shanghai 时区信息 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; # The following is the partition information you requested # Note that any partitions you deleted are not expressed # here so unless you clear all partitions first, this is # not guaranteed to work clearpart --all 清空分区信息 zerombr 清空mbr #自定义的分区信息 part /boot --fstype=ext4 --size=1024 part / --fstype=ext4 --size=50000 part /data --fstype=ext4 --size=30000 part swap --size=2048 #自定义的分区信息 %packages @core %end 只安装最基本的核心包，后面也可以加上安装后脚本 将KS和OS关联，生成启动新的菜单自定义的应答文件的绑定、删除、重命名、显示菜单栏对应的ks应答文件信息 在cobberl中 distro中记录的是cobbler中安装的发型版本对应的原文件的 [root@mini7-1 kickstarts]#cobbler distro list Centos-6.10-x86_64 Centos-7.5-x86_64 在cobberl中 profile是对应的各个发型版本的安装方法，就是安装启动界面的选择菜单栏，有多少个 就对应多少个菜单栏：如下图只有两个 [root@mini7-1 kickstarts]#cobbler profile list Centos-6.10-x86_64 Centos-7.5-x86_64 将自定义的应答文件和安装版本进行绑定：cobbler profile命令绑定 将ks6-mini.cfg和centos6进行绑定 cobbler profile add --name=centos-6.10-x86_64_mini --distro=Centos-6.10-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks6-mini.cfg cobbler profile add --name=centos-7.5-x86_64_mini --distro=Centos-7.5-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks7-mini.cfg 也可以删除应答文件： cobbler profile remove --name=Centos-6.10-x86_64 cobbler profile remove --name=Centos-7.5-x86_64 也可以修改带单名 cobbler profile rename --name=Centos-7.5-x86_64 --newname=centos-7.5-x86_64_desktop 查看菜单项对应的具体是哪个应答文件信息 cobbler profile report --name=centos-7.5-x86_64_mini /var/lib/tftpboot/pxelinux.cfg/default会自动生成新的菜单项，从cobbler profile list,也可以看出来 [root@mini7-1 tftpboot]#cobbler profile list Centos-6.10-x86_64 Centos-7.5-x86_64 centos-6.10-x86_64_mini centos-7.5-x86_64_mini cobbler的web管理实现此外cobbler是带有web管理界面的，不过需要安装web界面的包 yum install cobbler-web -y 配置文件： [root@mini7-1 kickstarts]#rpm -qf cobbler-web /etc/httpd/conf.d/cobbler_web.conf cobbler-web是经过http协议的，所以 安装完，需要重启httpd服务 然后看到对应的是443端口启动了 登录界面是，因为cobbler-web是https加密的/etc/cobbler/modules.conf 验证方法;/etc/cobbler/users.digest 记录的用户增加用户]]></content>
      <categories>
        <category>系统安装</category>
      </categories>
      <tags>
        <tag>运维，linux，windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql读写分离]]></title>
    <url>%2F2017%2F03%2F22%2Fmysql%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[Mysql的读写分离 ProxySQL官方网站:ProxySQL&amp;安装手册Mycat:基于Cobar研发的Mycat proxysql是一个高性能的mysql代理服务器，MYSQL中间件 多种方式的的读/写分离 定制基于用户、基于schema、基于语句的规则对SQL语句进行路由 缓存查询结果 后端节点监控 ProxySQL安装基于YUM仓库安装 vim /etc/yum.repos.d/proxysql.repo [proxysql_repo] name= ProxySQL YUM repository baseurl= http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\$releasever gpgcheck=1 gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key 基于RPM下载安装：https://github.com/sysown/proxysql/releases ProxySQL组成 服务脚本：/etc/init.d/proxysql 配置文件：/etc/proxysql.cnf 主程序：/usr/bin/proxysql proxysql使用： proxysql本身是个小型的数据库，启动后在数据库中配置即可 ProxySQL的读写分离实现1.实现读写分离前，先实现主从复制 注意：slave节点需要设置read_only=1 如果不加，proxysql是无法判断该服务器是负责读还是负责写的 2.启动ProxySQL：service proxysql start 启动后会监听两个默认端口 6032：ProxySQL的管理端口，也就是配置端口，在数据库中配置即可 6033：ProxySQL是读写分离的调度服务器发布在外网的端口 使用mysql客户端连接到ProxySQL的管理接口6032，默认管理员用户和密码都 是admin： mysql -uadmin -padmin -P6032 -h127.0.0.1 3.配置proxysql 在main和monitor数据库中的表： 1.runtime_开头的是运行时的配置，不能修改；即生效的表 2.mysql_开头的是配置的表，配置完生效的就是runtime_开头的表了 3.修改mysql_开头的表后必须执行LOAD … TO RUNTIME才能加载到RUNTIME生效； 4.执行save … to disk将配置持久化保存到磁盘 4.向ProxySQL中添加MySQL节点，以下操作不需要use main也可成功 MySQL &gt; select * from mysql_servers; MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;10.10.0.5&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port)values(10,&apos;10.10.0.6&apos;,3306); MySQL &gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,&apos;10.10.0.7&apos;,3306); MySQL &gt; load mysql servers to runtime; MySQL &gt; save mysql servers to disk; 意思是先把所有的服务器节点都加入到一个主机组中，然后proxysql会根据my.cnf配置文件中的read-only,自动区分哪些是只读的，哪些是只写的数据库服务器 5.配置监控账号： a.在主节点上，创建监控账号 grant replication client on *.* to monitor@&apos;10.10.0.%&apos; identified by &apos;root123&apos;; 备注：replication client权限是负责监控的，和replication slave是不同的权限 b.Proxysql上配置监控 实际上是保存在global_variables表中，可以查看是否修改成功 MySQL [main]&gt; set mysql-monitor_username=&apos;monitor&apos;; MySQL [main]&gt; set mysql-monitor_password=&apos;root123&apos;; c.使global_variables表生效 MySQL [mian]&gt; load mysql variables to runtime; MySQL [mian]&gt; save mysql variables to disk; 6.监控模块的指标保存在monitor库的log表中 MySQL [monitor]&gt; use monitor MySQL [monitor]&gt; select * from mysql_server_ping_log; 类似于ping命令，测试所有的数据库是不是连接成功的 mysql&gt; select * from mysql_server_connect_log; mysql&gt; select * from mysql_server_read_only_log; mysql&gt; select * from mysql_server_replication_lag_log; 查看read_only和replication_lag的监控日志 7.设置分组信息和读写规则 main库中的mysql_replication_hostgroups表是writer_hostgroup，reader_hostgroup，comment, 指定写组的id为10，读组的id为20 插入读写组的编号： insert into mysql_replication_hostgroups values(10,20,&quot;test&quot;); +------------------+------------------+---------+ | writer_hostgroup | reader_hostgroup | comment | +------------------+------------------+---------+ | 10 | 20 | test | +------------------+------------------+---------+ 生效和保存： MySQL [monitor]&gt; load mysql servers to runtime; MySQL [monitor]&gt; save mysql servers to disk; 再次查看 select hostgroup_id,hostname,port,status,weight from mysql_servers; +--------------+-----------+------+--------+--------+ | hostgroup_id | hostname | port | status | weight | +--------------+-----------+------+--------+--------+ | 10 | 10.10.0.5 | 3306 | ONLINE | 1 | | 20 | 10.10.0.6 | 3306 | ONLINE | 1 | | 20 | 10.10.0.7 | 3306 | ONLINE | 1 | +--------------+-----------+------+--------+--------+ 8.创建用于测试读写分离的账号 主节点上创建访问用户： grant all on *.* to sqluser2@&apos;10.10.0.%&apos; identified by &apos;root1234&apos;; 在ProxySQL配置，将用户sqluser添加到mysql_users表中： insert into mysql_users(username,password,default_hostgroup)values(&apos;sqluser2&apos;,&apos;root1234&apos;,10); 生效和保存： MySQL [monitor]&gt; load mysql users to runtime; MySQL [monitor]&gt; save mysql users to disk; 此时通过mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033可以测试 创建和读取数据库信息，但是读写没有分离出来 9.配置路由规则，实现读写分离 与规则相关的表：mysql_qeury_rules 插入路由规则,实现读写分离的规则 insert into mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply) VALUES(1,1,&apos;^SELECT.*FOR UPDATE$&apos;,10,1),(2,1,&apos;^SELECT&apos;,20,1); 分析： 将select语句分离到20的读组中, 但是在select语句中有一个特殊语句SELECT...FOR UPDATE它会申请写锁，应该属于写 组，所以应该排除在读组之外，放到写组中，放在前面是先匹配到后就放到写组了 (类似于iptables规则，谁在前，谁生效不看接下来的规则) 生效和保存到磁盘： load mysql query rules to runtime; save mysql query rules to disk; 10.用sqluser2测试读写分离效果 读： mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033 -e &apos;select @@server_id&apos; 因为是读操作会在2和3上随机选择 写： mysql -usqluser2 -proot1234 -h127.0.0.1 -P6033 -e &apos;begin;select @@server_id;commit&apos; 事务是非select开头的，所以查询的都是1上 11.路由的信息：查询stats库中的stats_mysql_query_digest表 MySQL [monitor]&gt; use stats MySQL [stats]&gt; SELECT hostgroup hg,sum_time, count_star, digest_text FROM stats_mysql_query_digest ORDER BY sum_time DESC; +----+----------+------------+-----------------------------------+ | hg | sum_time | count_star | digest_text | +----+----------+------------+-----------------------------------+ | 10 | 100685 | 5 | select @@server_id | | 10 | 39916 | 2 | select @@server_id | | 20 | 25787 | 23 | select @@server_id | +----+----------+------------+-----------------------------------+ 可以看到通过不同的命令具体被调度到哪个数据上的信息 复制的问题和解决方案1. 数据损坏或丢失 Master： MHA + semi repl Slave： 重新复制 2. 混合使用存储引擎 MyISAM：不支持事务 InnoDB： 支持事务 3. 不惟一的server id 重新复制 4. 复制延迟 需要额外的监控工具的辅助 一从多主:mariadb10版后支持 多线程复制：对多个数据库复制]]></content>
      <categories>
        <category>数据库</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux防火墙实现原理]]></title>
    <url>%2F2017%2F02%2F01%2Flinux%E9%98%B2%E7%81%AB%E5%A2%99%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[linux上的防火墙实现linux的防火墙是模仿OpenBSD实现的防火墙 1.纯软件实现 2.内核级实现的，只负责TCP协议的下4层的协议报文(传输层极其以下的层数)中工作和防护 也就是在前文所说的传输子网上进行工作和防护的]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables基本使用]]></title>
    <url>%2F2017%2F02%2F01%2Fiptables%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[iptables的命令使用格式 获取帮助： CentOS 7：man iptables-extensions CentOS 6：man iptables 规则的编写格式： iptables [-t table] COMMAND chain [rulesnum][-m matchname [per-match-options]] [-j targetname [per-target-options]] 表--&gt;命令--&gt;chain--&gt;对链 -t table： 默认为filter；其它可用的有raw, mangle, nat； 子命令COMMAND: 管理链： -P：policy，策略，定义链的默认策略； 一般有两种选择，ACCEPT和DROP； -N：new，新建一条自定义的规则链；被内建链上的规则调用才能生效；[-j chain_name]； -X：drop，删除自定义的、空的、或者引用计数为0的空链； -F：flush，清空指定的链； -E：重命名引用计数和为0的自定义链； -F：flush, 清空整条链 -Z：zero，计数器置零；改为零 iptables的每条规则和每个链都有专用的两个计数器： 每一个规则所匹配到的报文数量个数：pkts 和体积计数器之和：bytes 管理规则：增删改、插入 -A：append，追加，在指定链的尾部追加一条规则； -I：insert，插入，在指定的位置（省略位置时表示链首）插入一条规则； -D：delelte，删除，删除指定的规则； -R：replace，替换，将指定的规则替换为新规则；不能仅修改规则中的部分，而是整条规则完全替换； 查看：链上查看规则的动作，属于action的一种 -L：list，列出表中的链上的规则； -n：numeric，以数值格式显示； -v：verbose，显示详细格式信息； -vv, -vvv -x：exactly，计数器的精确结果； --line-numbers：显示链中的规则行号； 重置规则计数器： -Z：zero，置0； 计数器： 规则，以及默认策略有专用的计数器； 记录被当前规则所匹配到的： (1) 报文个数； (2) 字节总数； chain： (1) 内建链；INPUT OUTPUT FORWARD PREROUTING POSTROUTING (2) 自定义链； 自定义连只存在于iptables的上下文，只有被主链调用时，才会 存在于netfilter的上下文和5个hook挂上钩，才会生效。 匹配条件：matchname 多重条件：逻辑关系为“与”； 检查报文： TCP或UDP首部：源端口、目标端口、标记为ACK FSM: 有限状态机:TIME_WAIT,监听状态等 IP首部: SIP，DIP MAC首部：MAC地址 将防火墙规则保存下来 iptables-save &gt; /tmp/iptables-rules.v0.1 iptables-restore &lt; /tmp/iptables-rules.v0.1 开机自动加载iptables规则 yum install iptables-services -y 规则的保存和永久生效： 将iptables保存在文件 iptables-save iptables-restore iptables-server的service脚本 保存在/etc/sysconfig/iptables中，开启启动自动加载 firewalld,firewalld-cmd是不能调用iptables定义的规则，用iptables-server 必须先安装，不能并行 匹配条件又分为：通用匹配和扩展匹配 通用匹配条件： 检查的是下四层协议，对网络层的源地址-s，目标地址-d，协议类型-p进行检查 对数据链路层对从网卡的流入-i,流出-o进行检查 [!] -s, --sip,--source-ip报文源地址 其值可以是单个IP，或者连续IP，可以是网络地址，不能是离散的地址 [!] -d, --destination address[/mask][,...]：检查报文中的目标IP地址是否符合此处指定的地址或范围； [!] -i, --in-interface name：数据报文从哪个网卡接口进入； PREROUTING，INPUT, FORWARD 因为-i是数据报文流入的选项； 所以-i选项只能上面这三个链有关,用在前半部分相关的链上 [!] -o, --out-interface name：数据报文从哪个网卡接口出去； FORWARD, OUTPUT POSTROUTING 同理因为-o是数据报文流出的选项； 所以-o选项只能上面这三个链有关,用在后半部分相关的链上 [!] -p, --protocol protocol：四层协议 tcp|udp|icmp|sctp 这也是为什么iptables叫网络防火墙的原因，正常的工作只能工作在网络层， 检查网络层属性，但是-i -o和网络层属性没关系，和网络层下面的协议有关 正常情况下，网络防火墙是用来检查网络层首部来获得相关信息的 扩展匹配条件：又分为隐式扩展和显示扩展 扩展匹配是为了更精准的条件过滤，比如httpd传输时是需要资源压缩的， 而只有文本文件才适合压缩，所以在扩展中才能进行过滤。 /lib/modules/$(uname -r)/net/netfilter/下xt开头的就是扩展模块 默认没有载入到内核中，只有当用时才加载的，就叫隐式扩展 netfilter为了做深入的条件检查，通过特定的模块来实现检查功能 隐式扩展：不用-m选项指出matchname即可使用此match的专用选项进行匹配； -p tcp：隐含了-m tcp； [!] --source-port,--sport port[:port] 匹配报文中传输层的源端口； 可以使用单个端口或者连续端口，但是不能使用离散端口 [!] --destination-port,--dport port[:port]、 匹配报文中传输层的目标端口； 可以使用单个端口或者连续端口，但是不能使用离散端口 端口也只有2^16-1=65535个端口 [!] --tcp-flags mask comp SYN，ACK，FIN，RST，URG，PSH； mask：要检查的标志位列表，以逗号分隔； comp：必须为1的标志位列表，余下的出现在mask列表中的标志位则必须为0； --tcp-flags SYN,ACK,FIN,RST SYN 如果只定义SYN则代表tcp握手的第一次，一般只检查第一次 如果定义的是SYN，ACK代表tcp握手的第二次 如果是ACK，则代表tcp的正常通信过程 [!] --syn：因为检查tcp握手的第一次比较常用 所以系统内就设置这个选项代表下面这个选项 相当于--tcp-flags SYN,ACK,FIN,RST SYN -p udp：隐含了-m udp： [!] --source-port,--sport port[:port]：匹配报文中传输层的源端口； [!] --destination-port,--dport port[:port]：匹配报文中传输层的目标端口； -p icmp：隐含了-m icmp:互联控制消息协议 [!] --icmp-type {type[/code]|typename} icmp是有状态的 8：echo-request 0：echo-reply 显式扩展：必须使用-m选项指出matchname，有的match可能存在专用的选项； 显示扩展能帮我们更灵活的设置控制规则 获取帮助： CentOS 7：man iptables-extensions CentOS 6：man iptables 1、multiport扩展 离散方式的多端口匹配 离散最多为15个，以冒号隔开的算一个，所以连续的端口用冒号隔开 [!] --source-ports,--sports port[,port|,port:port]...：指定多个源端口； [!] --destination-ports,--dports port[,port|,port:port]...：指定多个目标端口； [!] --ports port[,port|,port:port]...：指定多个端口； 2、iprange扩展：连续的地址集 以连续的ip地址范围指明连续的多地址匹配条件； [!] --src-range from[-to]：源IP地址； [!] --dst-range from[-to]：目标IP地址； 3、set扩展：定义离散地址集 如果要开放的地址既不是连续的，也不是网络地址就需要使用set了 set依赖于ipset命令行工具；需要用ipset先定义一个地址集， 再用set调用地址集即可；需要先安装ipset安装包 yum install ipset ，重启iptables服务 set存在类型，常用的有两个： hash:net 网络地址的集合：两个网段剧哦多个网段 hash:ip IP地址的集合：离散地址集 使用方式： 先创建集合：ipset create NAME TYPE( hash:ip/hash:net) 向集合添加元素：ipset add NAME ELEMENT set再调用 --match-set NAME src --match-set NAME dst 4、string扩展：字串匹配， 借助string扩展，iptables把触角伸到了应用层 对报文中的应用层数据做字符串匹配检测； [!] --string pattern：要检测字符串模式； [!] --hex-string pattern：要检测的字符串模式，16进制编码； --algo {bm|kmp} 2组比较算法 5、time扩展 根据报文到达的时间与指定的时间范围进行匹配度检测； --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：起始日期时间； --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]]：结束日期时间； --timestart hh:mm[:ss] --timestop hh:mm[:ss] [!] --monthdays day[,day...] [!] --weekdays day[,day...] --kerneltz：使用内核中配置的时区 ~]# iptables -I INPUT -d 172.16.100.67 -p tcp --dport 23 -m time --timestart 09:00:00 --timestop 18:00:00 --weekdays Tue,Thu,Sat -j ACCEPT 6、connlimit扩展 根据每客户端IP做并发连接数匹配； --connlimit-upto n：连接数数量小于等于n，此时应该允许； --connlimit-above n：连接数数量大于n，此时应该拒绝； ~]# iptables -A INPUT -d 172.16.100.67 -p tcp --dport 23 -m connlimit --connlimit-upto 2 -j ACCEPT 7、limit扩展 基于收发报文的速率进行匹配； 基于令牌桶算法：bucket --limit rate[/second|/minute|/hour|/day]：平均速率 --limit-burst number：峰值速率,突发速率，最大速率 8、state扩展：有状态追踪的防火墙 stateful有状态；stateless无状态； 状态检测；连接追踪的状态监测机制（conntrack）； a.ip报文是无状态的，客户端向当前主机第一次发出请求，而第二次再发出请 求，对于服务器来说都当成第一次 b.对于服务器在IP层控制上来说，服务器响应报文和服务器主动发出请求报文 是没有区别的 c.基于以上两点，可以让第二次的报文和第一次关联起来，让IP报文有记忆功 能，让当前主机能识别一个新的连接请求是否和之前的连接有关联关系，记忆功能就是把之前的连接请求记录在内核的连接追踪表中，但是这个表是占用内核的 内存中，所以还需要进行连接数和时长的限制 d.因为需要查追踪表，所以效率是比之前慢的 e.然而是使用hash方式查找的，1w和10w查找时间是大概一致的，效率不会太低 f.对tcp,udp.icmp.stmp都是可以进行追踪的，和tcp的状态是没什么实际关系的. NEW：新连接；这个新连接是和协议无关的，独立于四层协议之外的 ESTABLISHED：已建立的连接； RELATED：相关联的连接；FTP INVALID：无法识别的状态； UNTRACKED：未追踪的连接； SNAT： DNAT： nf_conntrack内核模块；记忆是由内核空间的conntrack模块实现的 追踪到的连接：/proc/net/nf_conntrack文件中； 能追踪的最大连接数量定义在：/proc/sys/net/nf_conntrack_max 此值可自行定义，当主机作为网关网络防火墙时，更应该必要时调整到足够大； 要想永久保存修改的值需要保存到 vim /etc/sysctl.d/nf_conntrack_max.conf net.nf_conntrack_max = 1000000 再加载一次就行了 sysctl -p /etc/sysctl.d/nf_conntrack_max.conf 不同的协议的连接追踪的时长： /proc/sys/net/netfilter/ [!] --state STATE 如何开放被模式的ftp服务： 21端口是命令连接， (1) 装载追踪ftp协议的模块； modprobe nf_conntrack_ftp (2) 放行命令连接 ~] # iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT ~] # iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state NEW -j ACCEPT (3) 放行数据连接 ~] iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state RELATED -j ACCEPT 处理动作（目标） -j targetname [per-target-options] j是jump的意思，自定义链也可以放在target上，即主链跳转到自定义链 targetname： 简单： ACCEPT：接受； DROP：丢弃； 被请求的服务器数据报文丢弃了，请求端需要等待时间会消耗服务端和客户端资源 扩展： REJECT：--reject-with:icmp-port-unreachable默认 拒绝；适用内网，直接弹回报文请求 RETURN:当被调用的自定义链上没有规则则自动返回主链继续匹配; REDIRECT：端口重定向 SNAT：源地址转换 DNAT：目标地址转换 MASQURADE:地址伪装 LOG：日志 自定义链：可以先定义自定义链，再通过主链调用， 当自定义链被引用时，需要先删除引用，再清空自定义链，然后再删除 每个表对应控制的链，各不相同，记住对应关系网络层tcp协议的头部信息 2btye 2^16-1（0表示通用）2个半连接*2这里因为有两个半连接，请求和回应报文，所以防火墙要设置input接收请求和output回应报文，开启接收请求关闭回应报文，对方也是无法接收到回应报文的 生产环境下如何设置防火墙？：1.因为生产环境下，被管理的主机不在本地或者在其他省份，我们是通过ssh远程连接管理的! 2.防火墙规则一般是要设置白名单的，而默认策略是需要设置为DROP或者REJECT，这时，如果 不先把SSH或者VNC先设置白名单，我们就无法管理了！那就是给自己找麻烦了 3.所以要先为SSH服务设置白名单，再设置默认策略为DROP或者REJECT！！！ 4.默认策略可以用-P设置，也可以用自定义策略；自定义策略的好处 5.防火墙的检查机制,是按照顺序从上往下一个个匹配，如果最上面的一旦匹配即使下面有更 严格的条件，也会不生效，所以我们应该把检查严格的条件放到检查宽松的上面 比如：string检查规则(具体看示例)等 iptables的使用规范iptables -F 即清空filter表的所有链，因为默认是filter表 iptables -F INPUT，清空filter表上的INPUT链的所有规则 服务器要设置黑名单 极端清空下所有链都是drop的 如果主机有多个网卡，当网关来用的时，forward链就是用来当网络防火墙来用的 规则优化： (1) 注意规则的优先顺序，检查严格的要放到前面 (2) 可安全放行所有入站及出站，且状态为ESTABLISHED的连接； (3) 服务于同一类功能的规则，匹配条件严格的放前面，宽松放后面； (4) 服务于不同类功能的规则，匹配报文可能性较大扩前面，较小放后面； (5) 设置默认策略； (a) 最后一条规则设定； (b) 默认策略设定；可以使用-P或者-A ，建议使用-A (6)对于一类的规则限制，最好只写一条规则 隐式扩展示例：隐式扩展示例1：SSH服务 因为是ssh连接的，如果要设置默认策略为DROP，就一定要先开启SSH服务的请求和回应 iptables -A INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 22 -j ACCEPT 再设置默认INPUT链策略为DROP：两种写法：下文会表示自定义链的写法好处 iptables -P INPUT -j REJECT 设置默认策略是拒绝 或者用自定义写法： iptables -t filter -A INPUT -j REJECT，定义流入的默认策略 iptables -A OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 22 -j ACCEPT iptables -t filter -A OUTPUT -j REJECT(代替默认策略的写法) 设置自定义白名单的好处： 必要时，所有规则都可以通过自己明确给定的规则来定义 可以写一个脚本把自定义规则写进去，执行后就可以不受控于默认策略 因为管理的主机不在本地，如果再修改iptables规则时，把ssh也拒绝了，那么就有很大问题 可以把规则写在一个脚本里，在任务计划里创建一个清空防火墙规则的命令 即使脚本里的规则把自己拒绝了，可以等任务计划执行后，就可以登进去了，易于控制 隐式扩展示例2：http服务 在会前基础上开放80端口的访问 iptables -I INPUT -i ens33 -s 192.168.34.0/24 -d 192.168.34.103 -p tcp --dport 80 -j ACCEPT iptables -I OUTPUT -o ens33 -d 192.168.34.0/24 -s 192.168.34.103 -p tcp --sport 80 -j ACCEPT 隐式扩展示例3：lo网卡 将127.0.0.1设置不受控 在之前的基础上ping 127.0.0.1是受控的 之前的iptables -t filter -P INPUT DROP，是将0.0.0.0到0.0.0.0都拒绝了 本地127.0.0.1也被拒绝了，所以稍微修改为非lo网卡受控，lo网卡即不受控了 iptables -R INPUT 3 ! -i lo -j REJECT iptables -R OUTPUT 3 ! -o lo -j REJECT 隐式扩展示例4：-p icmp的隐式扩展；ping请求 如何设置当前主机可以ping其他主机，加在最后一条的前面 在之前的基础上此时主机主动ping其他主机也是受控的 icmp是有类型的,见下图，8 echo-request; 0 echo reply 当前主机主动ping其他主机： iptables -I OUTPUT 3 -p icmp --icmp-type 8 -j ACCEPT iptables -I INPUT 3 -p icmp --icmp-type 0 -j ACCEPT 其他主机ping防火请主机： iptables -I INPUT 3 -p icmp --icmp-type 8 -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 0 -j ACCEPT 隐式扩展示例5：DNS -p udp 如何设置开放本机可以通过DNS解析域名 从本机出去，到达互联的DNS服务器，再接收回应的报文 iptables -I OUTPUT -p udp --dport 53 -j ACCEPT 出去的报文 iptables -I INPUT -p udp --sport 53 -j ACCEPT 回来的报文 自定义链的使用示例(-N -E -X -F)以在自定义链中加入samba服务为例 -N：新建一条自定义的规则链 只不过在自定义链上是由计数器的 iptables -N new_rules 新建自定义链 iptables -E new_rules cifs_rules 改自定义链，必须要0引用的，0 references 自定义规则链的创建、调用、删除； 以在自定义链中加入samba服务;然后主链在调用自定义链为例 先设置入栈的规则 iptables -A cifs_rules -p tcp --dport 139 -j ACCEPT iptables -A cifs_rules -p tcp --dport 445 -j ACCEPT iptables -A cifs_rules -p udp --dport 137:138 -j ACCEPT iptables -A cifs_rules -j RETURN 还要加一条RETURN规则表示，当cifs_rules规则被主链调用时，如果自定义链上的规则 没有被匹配到，则return到主链上继续匹配主链上的后续规则. 在INPUT链去调用自定义链cifs_rules iptables -I INPUT 5 -s 192.168.34.0/24 -j cifs_rules 删除自定义链：需要先删除引用 iptables -D INPUT 5 iptables -F cifs_rules iptables -X cifs_rules 显示扩展示例必须使用-m选项指出matchname，有的match可能存在专用的选项 显示扩展示例1：multiport扩展 --多端口匹配 将21 22 80 139 445一起开启允许访问： iptables -I INPUT -p tcp -m multiport --dports 21:22,80,139,445 -j ACCEPT iptables -I OUTPUT -p tcp -m multiport --sports 21,22,80,139,445 -j ACCEPT 显示扩展示例2： ip-range:必须是连续的范围 允许ping的主机为192.168.34.100-192.168.34.106段的IP地址： iptables -I INPUT 3 -p icmp --icmp-type 8 -m iprange --src-range 192.168.34.100-192.168.34.106 -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 0 -m iprange --dst-range 192.168.34.100-192.168.34.106 -j ACCEPT 显示扩展示例3：set扩展 ipset先定义地址集: ipset create allowpinghosts hash:ip --先定义IP地址集 ipset add allowpinghosts 192.168.34.107 --向地址集添加IP地址 set再调用地址集： iptables -I INPUT 4 -p icmp --icmp-type 8 -m set --match-set allowpinghosts src -j ACCEPT iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m set --match-set allowpinghosts dst -j ACCEPT 显示扩展示例4：string扩展：字串匹配 比如：控制httpd服务的报文带有sex字串的都拒绝进入和访问 事先构建一个带有sex字串的html文件，然后设置规则 （因为这个规则比较严格，所以记得要放到允许访问httpd规则的前面！） iptables -I INPUT -p tcp --dport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT iptables -I OUTPUT -p tcp --sport 80 -m string --string &quot;sex&quot; --algo bm -j REJECT 但是如果httpd有多个页面，只有访问特定页面时才拒绝时，其他的页面还是需要能访问 iptables -A INPUT -p tcp --dport 80 -j ACCEPT iptables -A OUTPUT -p tcp --sport 80 -j ACCEPT 显示扩展示例5：time扩展 比如1：控制httpd服务访问时间为8:00-18:00 iptables -I INPUT 1 -p tcp --dport 80 -s 192.168.34.107 -m time --timestart 08:00:00 --timestop 20:00:00 --kerneltz -j ACCEPT iptables -I OUTPUT 1 -p tcp --sport 80 -d 192.168.34.107 -m time --timestart 08:00:00 --timestop 20:00:00 --kerneltz -j ACCEPT 比如2：控制对IP:192.168.34.107的ping命令访问时间为8:00-16:00 iptables -I INPUT 3 -p icmp --icmp-type 8 -s 192.168.34.107 -m time --timestart 08:00:00 --timestop 16:00:00 --kerneltz -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 0 -d 192.168.34.107 -m time --timestart 08:00:00 --timestop 16:00:00 --kerneltz -j ACCEPT 显示扩展示例6：connlimit扩展 以SSH服务为例，当当连接数大于3时，拒绝连接 iptables -I INPUT 1 -p tcp --dport 22 -m connlimit --connlimit-above 3 -j REJECT 对于一类的规则限制，最好只写一条规则 显示扩展示例7：limit扩展 比如：限制192.168.34.105ping防火墙主机为每分钟20个，最大峰值速率为5 iptables -R INPUT 3 -p icmp --icmp-type 8 -s 192.168.34.105 -m limit --limit 20/minute --limit-burst 5 -j ACCEPT iptables -I OUTPUT 2 -p icmp --icmp-type 0 -j ACCEPT 显示扩展示例8：state扩展 1.使用state就可以简化之前的所有规则了，这里对21,22,80,53,139,445做连接追踪功能 先建立入栈的ESTABLISHED的规则 iptables -A INPUT -m state --state ESTABLISHED -j ACCEPT 再建立出栈的ESTABLISHED的规则 iptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPT 再建立入栈的NEW的规则 iptables -A INPUT -p tcp -m multiport --dports 21:22,80,53,139,445 -m state --state NEW -j ACCEPT 2.对于FTP来说，因为是被动模式，服务端还开启一个随机端口，但是之前并没有建立 随机端口的NEW规则，也没有创建RELATED的规则，所以这里要新建一条RELATED规则 a.ftp的RELATD,依赖于nf_conntrack_ftp模块 b.创建FTP的RELATED规则 iptables -I INPUT 3 -p tcp -m state --state RELATED -j ACCEPT 因为端口是不确定的，所以用RELATED 这样就建立了FTP的访问限制了 通过state的显示扩展，可以看出上面所有的规则都可以简化成NEW,ESTABLISHED,RELATED的状态具体可以参考下面的各种服务进行规则控制写法示例 通过iptables规则对下面服务实现控制：基于连接追踪功能对下面服务进行控制 dns httpd：互联网 nfs samba vsftpd 仅允许loaclnet mysql:loaclhost ping :all 限制速率为10/min ssh:IP最大并发连接数3，工作时间的8:00-18:00允许连接 要求默认策略为拒绝 iptables -I INPUT 1 -m state --state ESTABLISHED -j ACCEPT iptables -I INPUT 2 -p tcp -m multiport --dports 53,80 -m state --state NEW -j ACCEPT iptables -I INPUT 3 -p udp --dport 53 -m state --state NEW -j ACCEPT iptables -I INPUT 4 -p tcp --dport 22 -m connlimit --connlimit-above 3 -m time --timestart 08:00:00 --timestop 18:00:00 --weekday 1,2,3,4,5 -j REJECT iptables -I INPUT 5 -p tcp -s 192.168.34.0/24 -m multiport --dports 21:22,2049,139,445 -m state --state NEW -j ACCEPT iptables -I INPUT 6 -p tcp -s 127.0.0.1 --dport 3306 -m state --state NEW -j ACCEPT modprobe nf_conntrack_ftp iptables -I INPUT 7 -p tcp -m state --state RELATED -j ACCEPT iptables - I INPUT 8 -p icmp --icmp-type 8 -m limit --limit 10/minute --limit-burst 1 -j ACCEPT iptables -I INPUT 9 -p icmp --icmp-type 0 -j ACCEPT iptables -A INPUT -j REJECT iptables -I OUTPUT 1 -m state --state ESTABLISHED -j ACCEPT iptables -A OUTPUT 2 -p tcp -m tcp --sport 10000:65535 -j ACCEPT iptables -I OUTPUT 3 -p icmp --icmp-type 8 -j ACCEPT iptables -A OUTPUT -j REJECT]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables-NAT表管理]]></title>
    <url>%2F2017%2F02%2F01%2Fiptables-NAT%E8%A1%A8%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[NAT表：网络防火墙原理及示例本地通信：两个主机在没有网关或者路由下进行通信，所有的本地通信是通过MAC地址进行通信的 name--&gt;IP--&gt;MAC地址基于广播机制 如果有交换机，交换机会查找MAC地址表(是通过源地址学习得到的), 将数据报文直接发送到连接到交换机的目标主机上 网络通信：其实就是多个本地通信实现的，由多个路由器进行中继转发最后到达目标主机的 而把linux服务器扮演成路由器的角色，则这台linux服务器充当是网关，就需要打开核心转发功能 FORWARD链 右边是生产环境 左边是研发测试环境： 隧道VPN 实验模拟：用linux服务器当做防火墙，需要先开启核心转发功能 sysctl -w net.ipv4.ip_forward=1 主机A上加路由: route add -net 192.168.10.10/24 gw 192.168.34.103 主机B上加路由: route add -net 192.168.34.0/24 gw 192.168.10.10 情景一：客户端确定服务端不确定；源地址确定，目标地址不确定 情景二：服务端确定，客户端不确定；源地址不确定，目标地址确定 对于情景一的情况： 客户端确定,服务端不确定；即源地址确定，目标地址不确定 示例1: 1.先在FORWARD链上默认为拒绝 如控制客户端只能访问httpd和ping操作，就可以在FORWARD链上添加如下规则 tcp:80端口限制: iptables -A FORWARD 1 -s 192.168.34.0/24 -p tcp --dport 80 -j ACCEPT iptables -I FORWARD 2 -d 192.168.34.0/24 -p tcp --sport 80 -j ACCEPT icmp的ping限制： iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -j ACCEPT iptables -I FORWARD 4 -d 192.168.34.0/24 -p icmp --icmp-type 0 -j ACCEPT 默认拒绝策略： iptables -I FORWARD 5 -j REJECT 2.因为之前介绍过state的状态追踪功能： 就可以简化成这样的规则： iptables -I FORWARD 1 -m state --state ESTABLISHED -j ACCEPT iptables -A FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -j ACCEPT iptables -I FORWARD 4 -j REJECT 3.情景一因为都是内网的服务器，是不能接收外网的请求的 所以对于ping和tcp只允许从内网出去的，外网是不能进来的，规则如下 iptables -I FORWARD 1 -m state --state ESTABLISHED -j ACCEPT iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCEPT iptables -I FORWARD 4 -j REJECT 示例2：控制访问ping,httpd：80,vsftp：21,dns：53 规则如下： iptables -I FORWARD 1 -m state --state ESTABLISHED -j ACCEPT iptables -R FORWARD 2 -s 192.168.34.0/24 -p tcp -m multiport --dport 80,21,53 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p udp --dport 53 -m state --state NEW -j ACCEPT iptables -I FORWARD 4 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCEPT iptables -I FORWARD 5 -s 192.168.34.0/24 -p tcp -m state --state RELATED -j ACCEPT iptables -I FORWARD 6 -j REJECT 在这里需要指定-s 源，不然外网向内网主动发送报文请求也是可以到达内网的！ 结论： 1.所以说有时服务器ping不通不代表服务不能访问，而且通过内网ping外网时，在外网服务器 进行抓包时，可以看出源地址是内网IP,非网关IP，目标地址是外网IP地址[root@centos7 data]# tcpdump -i ens33 -nn icmptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytes21:10:24.541810 IP 192.168.34.107 &gt; 192.168.10.10: ICMP echo request, id 1764, seq 3, length 6421:10:24.541877 IP 192.168.10.10 &gt; 192.168.34.107: ICMP echo reply, id 1764, seq 3, length 64 2.用linux防火墙做网关网络防火墙，有一个问题，内网的机器是保护了，但是这台linux服务 是没有防护的，所以还需要在这台网络防火墙上在INPUT和OUTPUT链上加上规则，来防护 这台linux网关网络防火墙！所以当用一台linux服务器做网络防火墙时，INPUT,OUTPUT FORWARD链是都需要设置规则的！ 对于情景二的情况： 右边的图则控制：源地址不确定，目标地址确定 示例3：控制允许互联网的主机访问ping,httpd：80,vsftp：21,dns：53 所以规则应该如下： iptables -I FORWARD 1 -p tcp -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -d 192.168.10.0/24 -p tcp -m multiport --dports 80,53,21 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -d 192.168.10.0/24 -p udp --dport 53 -j ACCEPT iptables -I FORWARD 4 -d 192.168.10.0/24 -p icmp --icmp-type 8 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 5 -d 192.168.10.0/24 -m state --state RELATED -j ACCEPT iptables -I 6 FORWARD -j REJECT NAT： 1.NAT规则是在FORWARD的基础上进行安全加固的，隐藏源地址和目标地址，达到保护内网的安全和提供服务的主机安全 2.当然NAT规则还是建立在FORWARD的基础上做地址转换，不能转发做NAT也没意义，所以放行和控制限制还是需要在FORWARD链上去做的 NAT: network address translation，地址转换 NAT技术的产生核心原因：隐藏本不需要公开的主机 1.请求报文的源地址地址转换是人为在NAT上加规则实现的 2.响应报文中的目标地址转换，是基于连接追踪功能实现的，不需要人为干预 比如内网的机器要访问互联网，就必然留下IP地址或者端口信息，则有些攻击木马通过真正的 地址来扫描这些内网机器，如果有漏洞，则可能就会被攻击，所以NAT的技术的出现，就 会隐藏我们内网机器访问互联网时的真正IP地址和端口。 实现隐藏的原理： 1.将数据报文中的源地址IP，修改为具有很强防护能力的IP地址，比如网关等,这样的话，互联网上的主机看到的源地址就会是网关的地址，即使被攻击也是攻击网关，而网关一般是具有很高的防护能力的，所以就达到了隐藏源地址的目的. 2.一般来说请求报文经过防火墙时，会拆掉以太网帧首部，看到目标地址不是自己时，会转发出去，但是对于NAT的情况，防火墙会修改数据报文的IP首部的源地址或者目标地址，然后重新封装数据报文，再到达目标主机，这样就会达到保护源主机和目标主机被攻击的风险，在这个过程中，请求报文由手动修改的，响应报文是由NAT连接追踪功能实现的。 NAT的方式：SNAT,DNAT,FullNAT,PortNAT NAT规则可加的链： 支持PREROUTING INPUT OUTPUT POSTROUTING,但是一般只在PREROUTING和 POSTROUTING上做NAT规则，INPUT和OUTPUT只有在特殊情况下才做NAT。 那么在netfilter上是如何实现的？ SNAT的实现 数据报文经过防火墙时，如上图示，只有当数据报文进入防火墙时，才知道目标地址不是 自己，还是需要转发，所以不适合在PREROUTING链上做地址转发，如果目标地址不是当前 主机，就要经由FORWARD链进行转发，而FORWARD链本身确不支持地址转换功能，所以只 有在离开本机再一次进行路由选择，路由完之后才扔给网卡发送队列中，所以只能在POSTROUTING链上加地址转换规则 DNAT的实现 SNAT：POSTROUTING源地址转换 原理： 请求报文发生了源地址修改：人为介入修改 响应报文经过防火墙的NAT规则时，同连接追踪机制自动修改目标地址 所以源地址转换适合隐藏服务端 作用： 1.隐藏内网主机的IP地址，防止被攻击 2.SNAT可以解决IPV4端口不够用的问题： IPV4的地址短缺的问题使得SNAT技术更加流行，因为私网地址使用一个公网地址， 所以通过SNAT地址转换，报文通过公网IP出去的时候，都会把源地址(私网地址)转 换成公网地址，才能与公网通信，响应报文回来的时候是发给公网IP的，则通过连接 追踪功能返回给原来的私网地址。 –实验原理图 SNAT实验： 192.168.34.0/24网段SNAT到192.168.10.11上，且只限制80和ping操作能进行 规则如下： NAT的POSTROUTING链规则： iptables -t nat -I POSTROUTING 1 -s 192.168.34.0/24 ! -d 192.168.34.0/24 -j SNAT --to-source 192.168.10.11 注意：这里的source是一个固定的地址，如果这个地址是变动的呢？ 那么可能下次这条规则就不生效了！--&gt; 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 验证：通过在192.168.10.10上抓icmp包和http日志也可以看出，确实是做了SNAT地址转换的 [root@node7-3 data]#tcpdump -i ens33 -nn icmp 14:56:14.315375 IP 192.168.10.11 &gt; 192.168.10.10: ICMP echo request, id 1373, seq 1, length 64 14:56:14.315473 IP 192.168.10.10 &gt; 192.168.10.11: ICMP echo reply, id 1373, seq 1, length 64 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.10.11 - - [29/Dec/2018:15:20:45 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; MASQUERADE：对SNAT的弥补，地址伪装只能作用在POSTROUTING链上，对SNAT的缺点弥补 外网地址是动态的就用MASQUERADE,如果是静态的就用SNAT； 因为MASQUERADE会消耗更多的系统资源，能用SNAT就用SNAT，特殊场景才使用MASQUERADE 只能作用在POSTROUTING链上，对SNAT的缺点弥补 比如： iptables -t nat -I POSTROUTING 1 -s 192.168.34.0/24 ! -d 192.168.34.0/24 -j SNAT --to-source 192.168.10.11 如果SNAT规则上的要访问的外网地址(192.168.10.11)是动态的，规则就失效了 这就要用到MASQUERADE了,如果是静态的就用SNAT； 当然能用SNAT还是要用SNAT的，特殊场景才使用MASQUERADE，因为MASQUERADE会消耗更多的系统资源 实验： 将SNAT的规则修改一下，不指定--to-source 192.168.10.10 规则如下： NAT的POSTROUTING链规则： iptables -t nat -A POSTROUTING -s 192.168.34.0/24 ! -d 192.168.34.10 -j MASQUERADE 验证：通过在192.168.10.10查看http日志也可以看出，确实是做了SNAT地址转换的，即使没指定source也是通过NAT服务器的随机端口进行访问的，达到地址伪装的目的 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.10.11 - - [29/Dec/2018:18:07:36 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; DNAT：PREROUTING和OUTPUT目标地址转换 原理: 请求报文的目标地址需要修改成真正的IP地址 响应报文经过防火墙的NAT规则，通过连接追踪机制，自动修改目标地址 作用： 1.隐藏提供服务的服务器的真实IP地址，防止被服务被劫持，如DNS劫持，http服务等 2.DNAT也通过PortNAT方式可以解决IPV4地址不够用的问题 缺点： 防火墙和目标主机必须在一个物理网络中 ，而且目标主机的网关必须指向防火墙的 IP地址，多以受限于传输范围，可以使用FULLNAT解决必须在同一物理网络的问题 DNAT实验： 访问192.168.10.10的http服务时，只需要访问防火墙NAT服务器的地址即可 即把192.168.10.10DNAT到192.168.34.103上，这里只做简单的DNAT不做portnat 规则如下： NAT的POSTROUTING链规则： iptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 验证：在192.168.34.107上获取192.168.10.10的页面信息：curl 192.168.10.10 因为DNAT是隐藏192.168.10.10的真实地址的，在互联网上只会暴露防火墙的192.168.34.103地址是提供http服务的，真正的地址得以保护，所以这里curl 192.168.34.103即可 [root@node7-2 data]#curl 192.168.34.103 haha 192.168.10.10 而在192.168.10.10查看http日志 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.34.107 - - [29/Dec/2018:17:24:20 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 192.168.34.107 - - [29/Dec/2018:17:26:42 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 从实验也可以看出DNAT的规则生效了，达到了隐藏真正提供服务的192.168.10.10地址 从而保证了服务器被攻击的风险 PortNAT:端口映射端口映射在docker容器中的实现方式更加方便，直接加-p选项即可,而且源端口和目标端口可以指定 进程与进程的通信，实际上就是端口号之间的通信 1.对于SNAT来说，因为访问是互联网的随机端口，所以都转换即可 2.而对于DNAT的情况来说： a.很多情况下，并不是说只要访问防火墙F的地址，都通过DNAT转换成主机A的IPA， 而是当访问主机A的某个服务特定端口时，才进行地址转换 b.而访问F的端口和要转换的IPA的端口不一定需要一样 即IPF：port1--&gt;IPA:port2，port1和port2可以不一样 3.DNAT也可以解决IPV4地址不够用的情况：如下图 那么就可以说地址转换可以发生在网络层，而且借助端口映射也可以发生在传输层首部(端口) DNAT端口映射实验：如上图 访问192.168.10.10：8080的http服务时，只需要访问防火墙NAT服务器的地址即可 即把192.168.10.10:8080DNAT到192.168.34.103:80上,在上面的DNAT基础上做修改即可 规则如下： NAT的POSTROUTING链规则： iptables -t nat -R PREROUTING 1 -d 192.168.34.103 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.10:8080 控制和放行还是需要在FORWARD链上做规则的 iptables -I FORWARD -s 192.168.34.0/24 -m state --state ESTABLISHED -j ACCEPT iptables -I FORWARD 2 -s 192.168.34.0/24 -p tcp --dport 80 -m state --state NEW -j ACCEPT iptables -I FORWARD 3 -s 192.168.34.0/24 -p icmp --icmp-type 8 -m state --state NEW -j ACCPET iptables -I FORWARD 4 -j REJECT 验证：curl 192.168.34.103:80查看是否能获取到192.168.10.10：8080的页面 [root@node7-2 data]#curl 192.168.34.103 haha 192.168.10.10 [root@node7-2 data]#curl 192.168.10.10:8080 haha 192.168.10.10 [root@node7-3 data]#tail /var/log/httpd/access_log 192.168.34.107 - - [29/Dec/2018:17:27:01 +0800] &quot;GET / HTTP/1.1&quot; 200 19 &quot;-&quot; &quot;curl/7.29.0&quot; 从实验也可以看出DNAT的端口映射规则生效了，映射的端口不一样也可以访问到页面 1.这里只模拟同一台服务器上的一个服务的DNAT端口映射情景 2.对于同一台服务上的多个服务DNAT端口映射也是同样道理，加上对应的PORTNAT规则即可 3.对于多台服务器上的多个服务DNAT端口映射同样是这样的，只需要在NAT服务器上添加多个地址，然后将对应地址进行多台服务器的服务映射即可 FullNAT：源地址和目标地址都修改 既是网关又是NAT fullnat能实现网关和主机不在同一个网段 FullNAT的存在是为了弥补SNAT和DNAT模式下，主机和NAT服务器必须在同一个网段的缺点 SNAT和DNAT都受限于NAT服务器和客户端都在一个网段 1.在SNAT中，主机的网关都是需要指向NAT服务器的，不然如果在主机和防火墙之间存在路由器的话，那么出去的请求报文就不一定经由NAT服务器了，也就达不到地址转换的目的 2.在DNAT中，如果提供服务器的主机和防火墙NAT服务器之间有路由器，那么响应的报文 也不一定经由NAT服务器，也达不到转换目标地址的目的。 3.所以FullNAT的存在就弥补了SNAT和DNAT的缺点 4.主要是为了解决DNAT的必须近距离传输的问题 FullNAT的地址转换原理： 如下图示 FullNAT实验： FullNAT的实验原理和SNAT,DNAT,PORTNAT实验方式一样，这里就不做演示了 REDIRECT:端口重定向作用于nat表的PREROUTING和OUTPUT redirect 只改端口，响应报文还是使用连接追踪功能,自动转换成原来端口]]></content>
      <categories>
        <category>iptables</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS类型及实现]]></title>
    <url>%2F2017%2F01%2F20%2FLVS%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[LVS LVS集群的4种网络模型LVS Type是指lvs工作的拓扑结构和转发机制 1.NAT:多目标DNAT，通过修改请求报文的目标IP和Port为经由调度算法挑选出的某后端RS的 RIP和PORT，再发送到POSTROUTING链上 2.DR:不动源IP、源端口、目标IP、目标端口，即传输层TCP/UDP首部保持不变，转发方式通过 先拆除帧首部再在IP报文外封装新的以太网帧首部(源MAC-DIPmac,目标MAC-RIPmac)扔回给交换机，由交换机通过MAC地址完成调度， 目标MAC是由调度算法挑选出的某后端 RS的MAC地址; 而MAC地址通信就意味着是在本地网络中，所以DR模型就限制了DIP和RIP在同一个二层网络设备中， 中间不能隔路由器和网关只能由交换机来进行交换，来实现调度. 3.TUN:IP隧道方式;转发方式： 不修改请求报文的IP首部（源IP为CIP，目标IP为VIP），而是在原IP报文之外再封装 一个新的IP首部（源IP是DIP，目标IP是RIP），这样报文就有两个IP首部(内部一个，外部还一个)，这就叫做IP隧道，将报文发往挑选出的目标 RS；RS直接响应给客户端（源IP是VIP，目标IP是CIP）,这样就弥补了DR模型必须在同 一个物理网络的限制，TUN模型不受限于网络. 4.FULLNAT:默认不支持，需要打内核补丁 通过修改请求报文的源IP和目标IP为经由调度算法挑选出的某后端的RS的RIP和PORT； 不过一般不修改源端口和目标端口。CIP--&gt;DIP;VIP--&gt;RIP、 LVS-NAT模式和特性 NAT:多目标DNAT，通过修改请求报文的目标IP和Port为经由调度算法挑选出的某后端RS的 RIP和PORT，再发送到POSTROUTING链上 1.DIP和各个RIP必须在同一个网段内； 2.RS应该使用私有地址，且RS的网关必须指向DIP;RIP:GW---&gt;DIP； 3.支持端口映射(转换)；VIP:80---&gt;RIP:8080,而后端有多个RS，所以也叫多目标IP的DNAT 4.请求和响应报文都必须经过Director Server转发,高负载场景中，Director Server易成为性能瓶颈； DNAT的工作原理： 请求报文中的源IP(CIP)--&gt;目标IP(VIP);而响应报文中的源IP(RIP)--&gt;目标IP(CIP), 对于客户端来说并未访问RIP，所以响应报文必须经由DIP(网关)，将源IP(RIP)改成VIP，对CIP来说才能接收 到正常的响应报文，这就是为什么RIP的网关必须指向DIP，而这个过程是由NAT内部的连接追踪功能自动完成的. 5.LVS必须是linux系统，因为LVS只支持linux,而RS可以使用任意操作系统,因为只是应用层协议的交互调度. 缺陷： 1.对Director Server压力会比较大，因为请求和响应都需经过director server 一般来说web应用的GET中用户的请求报文很轻，而响应报文中要承载用户资源数据(很大)，由于NAT模型的原因响应报文还必须经由Director Server, 那么Director Server服务器的压力就很大，后端的RS最多也就5、6个而已，这就是为什么有DR模型的存在了. 2.DIP和RIP必须在同一个IP网段，中间不能隔路由器，Director和RS的位置就不能距离太远，一般是在同一个机架上. lvs-nat： 设计要点： (1) RIP与DIP在同一IP网络, RIP的网关要指向DIP； (2) 支持端口映射； (3) Director要打开核心转发功能； 实践作业（博客）：负载均衡两个php应用（wordpress，discuzx）； 测试：(1) 是否需要会话保持；(2) 是否需要共享存储； LVS-DR模式和特性 1.DR模型是如何解决NAT模型中Director Server易成为性能瓶颈的问题的？ 响应报文是不需要不经由Director Server的，所以极大的缓解了 Director只需要有一个网卡和RS在同一个二层网络中(可以连不同交换机，交换机在连接) 特点： 1.Director Server和RS在同一个二层网络中(可以在同一个交换机也可以在不同 交换机，但交换机是相连的),中间是不能隔路由器的！ 2.Director Server只有VIP，没有DIP 3.响应报文由RS直接通过交换机--&gt;路由器发送给客户端，所以就要求各个RS有两个IP 一个是RIP，一个是VIP，而且响应报文发出时的源IP必须是VIP不能是RIP. 4.RS和Director必须在同一物理网络，因为需要MAC地址完成地址解析报文转发的; 5.RS的RIP可以使用私网地址，也可以是公网地址，RIP与DIP在同一IP网络(因为要apr的广播应答找到某一RS的MAC地址完成报文传输)， RIP的网关一定不能指向Director(一旦指定DIP，那么响应报文就会经由Director进行转发了!) 6.请求报文必须先经由Director，但响应报文不能经由Director(理由同上5)，而是由RS直接发往客户端; 7.不支持端口映射；因为报文是由RS直接发往客户端的，如果Director转发时将端口进行映射80:8080，那么RS的VIP响应时也是8080端口响应的！ LVS-DR模型必须要解决地址冲突问题： 1.Director Server和RS是在同一个网络中的，如何解决地址冲突问题的？ 由于ARP本地工作逻辑和地址解析协议，每个主机加入到网络中来时，一般来说会有两类ARP报文发送； 即通告和广播请求，但arp解析地址缓存有效时长是5min(IP和 MAC的对应关系)，再次需要通信时，就需要arp_request请求，而请求是广播式的， 由于本地有多个VIP，就会产生arp冲突。 解决arp冲突的办法： 1.在前端的路由器上把VIP和Director的MAC进行绑定，如果LVS使用keepalived做 高可用，备用的LVS的MAC地址肯定和主LVS的MAC地址不一样，所以切换时还需要重新绑定，这样可用性就很差了，无法实现. 2.让RS的VIP地址的ARP通告和广播应答出不去即可，而方式又有两种 a.arptables就是arp防火墙，但是依赖第三方工具. b.通过修改各个RS服务器的内核参数达到不让RS的VIP进行ARP通告和响应的目的；而linux内核从2.4.x， 2.6.x只要是linux系统都可以修改内核参数中的apr通告和应答方式就能做到加入到当前网络时， 不与通告apr信息,不与应答前端路由器和网关发送的apr路由信息; 2.RS是如何做到响应报文源IP是VIP而不是RIP的？ 因为Director将源报文(CIP-VIP)进行封装一次以太网帧首部(DIP-MAC--&gt;RIP-MAC),RS收到报文后拆除 以太网帧首部后看到的IP层的源IP是CIP，目标IP是本机的VIP，所以响应时的源IP是本机的VIP，目标IP是CIP，完成报文传输. 缺点： DR类型，DIP和RIP是通过MAC地址传输报文的，所以和NAT类型一样也需要在同一物理网络中，而且不能隔路由器，不易于异地容灾. lvs-dr： 设计要点： dr模型中，各主机上均需要配置VIP，解决地址冲突的方式有三种： (1) 在前端网关做静态绑定； (2) 在各RS使用arptables； (3) 在各RS修改内核参数，来限制arp响应和通告的级别； 限制响应级别：arp_ignore 0：默认值，表示可使用本地任意接口上配置的任意地址进行响应； 1: 仅在请求的目标IP配置在本地主机的接收到请求报文接口上时，才给予响应； 限制通告级别：arp_announce 0：默认值，把本机上的所有接口的所有信息向每个接口上的网络进行通告； 1：尽量避免向非直接连接网络进行通告； 2：必须避免向非本网络通告； 注意： arp_ignore和arp_announce这两个参数是接口级别的，应该在服务器所在的所有接口上都配置，避免出现问题； LVS-DR类型实现之-调整内核中的APR参数APR通告和应答： 1.如果服务器有多个网卡，当加入到某个网络，默认会把IP和MAC地址的对应关系通告给每一个网络； 2.2.4.x kernels和2.6.x kernels都支持修改内核中的apr参数来限制apr的通告和应答，避免各个RS的lo回环网卡在配置上VIP时通告给其他网络. 3.arp_ignore参数是关闭了前端直连网关的arp应答； 4.arp_announce参数，由于VIP是配置在lo上的，arp通告只是通告给其直接连接的所在网络，而lo所在网络是 专有网关不是直连网络所以不会进行arp通告. 注意： 1.为了避免出现问题，最好是在/proc/sys/net/ipv4/conf下的all和lo网卡上都对这两项参数做限制； 2.Director的VIP的设置需要注意的是使用255.255.255.255netmask，使用此掩码是为了避免与其他主机进行多余 通信，然后广播只发给自己broadcat VIP》 脚本实现： 各个RS都执行此脚本，方便关闭和启用： [root@node03 ~]# lvs_dr_rs.sh #!/bin/bash vip=172.18.140.10 #VIP地址 mask=&apos;255.255.255.255&apos; # interface=&quot;lo:0&quot; #rpm -q httpd &amp;&gt; /dev/null || yum -y install httpd &amp;&gt;/dev/null #service httpd start &amp;&gt; /dev/null &amp;&amp; echo &quot;The httpd Server is Ready!&quot; #echo &quot;&lt;h1&gt;`hostname`&lt;/h1&gt;&quot; &gt; /var/www/html/index.html case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $interface $vip netmask $mask broadcast $vip up route add -host $vip dev $interface #添加到达VIP的路由信息 echo &quot;The RS Server is Ready!&quot; ;; stop) ifconfig $interface down #VIPdown后，路由和IP也就没有了只需清楚内核参数即可 echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;The RS Server is Canceled!&quot; ;; *) echo &quot;Usage: $(basename $0) start|stop&quot; exit 1 ;; esac IPIP:LVS-TUN：异地容灾 目的： 不管是NAT还是DR类型，由于其特点限制必须在同一个机房中，不易于容灾，所以就需要有IP隧道(TUN)类型的. 转发方式： 1.Director不修改请求报文的IP首部(源IP为CIP，目标IP为VIP)，而在原IP报文之外再 封装一个IP首部(源IP是DIP，目标IP是RIP,将报文发往挑选出的目标RS； RS直接响应给客户端(源IP是VIP，目标IP是CIP); 2.当RS收到报文后，拆除第一层IP首部(VIP-RIP)看到的是(CIP-VIP),那么所有的RS都需要配置一个VIP, 但此时确不会出现DR模型的apr冲突的问题，因为这些服务器在不同的机房中，不存在这种情况. 特点： 1.DIP,VIP,RIP都需要是公网地址； 2.由于距离的限制，RS的网关也不能指向DIP的； 3.请求报文要经由Director，但响应报文不能经由Director(同DR模型)； 4.不支持端口映射(同DR模型原理)； 5.RS的操作系统需要支持IP隧道功能； 缺点： 由于MTU的最大值是1500字节，留给IP层、TCP层、传输层、首部的也就40字节，而IPIP类型则会多出一个IP层首部， 即1520字节，而很多路由器设备会将1520的传输单元进行切片才能进行传输,所以对于TUN类型的必须人为指定最大传 输单元，留出额外需要封装的IP首部大小而不超过1500. FullNatFullNat类型没有收录到linux内核中；需要打补丁; FullNAT工作原理： 为了弥补NAT类型的DNAT中的RS网关必须指向DIP，FullNAT则在转发给RS时的源IP和目标IP由CIP-&gt;VIP修改为 DIP-&gt;RIP,RS的响应报文则由RS直接响应给DIP，即使中间跨多个路由器，也会转发给Director,Director最终响应给CIP 优点： 既有DR模型中不受限于距离限制的，又可以通过NAT模型不直接将RS暴露在公网的完全有点. LVS的实现：ipvsadm1.ip_vs:先启用内核中的ip_vs模块，默认是没启用的 2.生成ipvs规则：使用ipvsadm工具 1.先定义集群服务：service 三种定义集群服务的方式： 1.TCP协议+端口 2.UDP协议+端口 3.FireWall Mark：混合上面两种方式 2.编辑管理集群服务的RS Server RIP+端口 3.安装ipvsadm， [root@node01 ~]# yum -y install ipvasdm [root@node01 ~]# rpm -ql ipvsadm /etc/sysconfig/ipvsadm-config /usr/lib/systemd/system/ipvsadm.service #Unitfile文件 /usr/sbin/ipvsadm #二进制主程序 /usr/sbin/ipvsadm-restore #重载规则 /usr/sbin/ipvsadm-save #保存现有规则 4.负载均衡集群设计时要注意的问题： (1) 是否需要会话保持； (2) 是否需要共享存储； 共享存储：NAS， SAN， DS（分布式存储） 数据同步： 课外作业：rsync+inotify实现数据同步 5.健康状态检测缺点： 1.LVS的Director不会对后端RS集群的健康状态做检测，不像Nginx或者HAproxy可以对后端集群对健康状态检测， 并根据检测结果动态的添加或移除某个RS，这也是LVS的极大缺陷. 2.但可以通过其他软件实现，如keepalived高可用IPVS，顺便为ipvs添加了多个checks检测器，从而周期性的检测 后端RS是否为健康的. FireWall Mark：防火墙标记为服务提供分类器，从而实现将多个服务归类一个服务； 1.比如对80和443端口的访问，如果不用防火墙标记的话，需要定义两个LVS集群;但是这两个端口对应的又是一个服务， 我们不希望区别对待,就可以对进来的报文进行标记; 2.iptables的mangle表(修改报文格式)，对报文进行分类，在PREROUTING链上对进来的报文进行标记，对80和443端口 的报文都定义为一类服务，然后再ipvsadm进行firewalld mark进行定义. 示例： 1.标记 iptables -t mangle -A PREROUTING -d 172.18.140.10 -p -m multiport --dports 80,443 -j MARK --set-mark 6 #在刚进入linux服务器时，对进来对172.18.140.10的80和8080的访问都归于6号mark中 2.添加集群： ipvsadm -A -f 6 -s wrr #对FWM为6的设置一个集群，因为FWM=6已经有IP了只需要指定算法就行了. 3.添加RS ipvsadm -a -f 6 172.18.140.5 -g -w 1 ipvsadm -a -f 6 172.18.140.6 -g -w 1 #因为访问的端口有80和8080，所以后端RS是不能写端口的 4.查看规则： [root@node01 data]# ipvsadm -Ln FWM 6 wrr -&gt; 172.18.140.5:0 Route 1 0 0 -&gt; 172.18.140.6:0 Route 1 0 0 #因为0端口代表通配，用于通配FWM 6中的80和8080端口 ipvsadm命令：核心功能： 集群服务管理：增、删、改； 集群服务的RS管理：增、删、改； 查看： ##大写的命令是用来管理集群服务的，后面必须跟集群服务地址 ##小写的命名是用来管理后端RS集群的； ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [--pe persistence_engine] [-b sched-flags] ipvsadm -D -t|u|f service-address ipvsadm -C ipvsadm -R ipvsadm -S [-n] ipvsadm -a|e -t|u|f service-address -r server-address [options] ipvsadm -d -t|u|f service-address -r server-address ipvsadm -L|l [options] ipvsadm -Z [-t|u|f service-address] #清空集群的连接数计算器 管理集群服务：增、改、删； 增、改： ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] 删： ipvsadm -D -t|u|f service-address service-address： -t|u|f： -t: TCP协议的端口，VIP:TCP_PORT -u: UDP协议的端口，VIP:UDP_PORT -f：firewall MARK，是一个数字； [-s scheduler]：指定集群的调度算法，默认为wlc； 管理集群上的RS：增、改、删； 增、改： ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 删： ipvsadm -d -t|u|f service-address -r server-address server-address： rip[:port] 选项： lvs类型： -g: gateway, DR类型 -i: ipip, TUN类型 -m: masquerade, NAT类型 -w weight：权重； 清空定义的所有内容： ipvsadm -C 查看： ipvsadm -L|l [options] --numeric, -n：numeric output of addresses and ports --exact：expand numbers (display exact values) --connection， -c：output of current IPVS connections --stats：统计计算器的总和值 --rate ：统计速率值 保存和重载： ipvs和iptables一样，规则写完是送到内核内存中保存的，内核一旦关闭，规则也就没有了，所以必要时一定要将规则保存起来. 保存： ipvsadm -S = ipvsadm-save &gt; /etc/sysconfig/ipvsadm 重载： ipvsadm -R = ipvsadm-restore 设置开机自启： systemctl enable ipvsadm #启动时自动加载保存好的规则 ##因为ipvsadm启动时加载的文件是/etc/sysconfig/ipvsadm，只需要将规则保 存到此文件中，就会启动时自动加载，规则就不会丢失了. [root@node01 data]# vim /usr/lib/systemd/system/ipvsadm.service [Service] Type=oneshot ExecStart=/bin/bash -c &quot;exec /sbin/ipvsadm-restore &lt; /etc/sysconfig/ipvsadm&quot; ExecStop=/bin/bash -c &quot;exec /sbin/ipvsadm-save -n &gt; /etc/sysconfig/ipvsadm&quot; LVS-NAT类型实验(Docker上实现)：1.先在docker上启动两个容器作为RS，为了方便区别，分别在web页面下创建index.html文件以示区别 [root@node01 ~]# docker run --name c1 -it -v /data/vols/vol1:/data/web/html busybox cd /data/web/html vim index.html nginx1 [root@node01 ~]# docker run --name c2 -it -v /data/vols/vol2:/data/web/html busybox cd /data/web/html vim index.html nginx2 2.定义集群，以宿主机的桥接IP为VIP [root@node01 vols]# ipvsadm -A -t 172.18.140.6:80 -s wrr #创建一个集群，并指定调度算法为wrr加权轮询 3.向集群添加两个RS #向集群添加RS，并指定-m为NAT类型，权重为都是1 [root@node01 vols]# ipvsadm -a -t 172.18.140.6:80 -r 172.17.0.2:80 -m -w 1 [root@node01 vols]# ipvsadm -a -t 172.18.140.6:80 -r 172.17.0.3:80 -m -w 1 #查看定义好的集群 [root@node01 vols]# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 172.18.140.6:80 wrr -&gt; 172.17.0.2:80 Masq 1 0 0 -&gt; 172.17.0.3:80 Masq 1 0 0 4.在其他服务器进行测试 [root@node02 ~]# while true;do curl 172.18.140.6; done nginx1 nginx2 nginx1 nginx2 nginx1 nginx2 #可以看到是根据wrr算法进行调度的 5.修改其中一个RS的权重： 修改： [root@node01 vols]# ipvsadm -e -t 172.18.140.6:80 -r 172.17.0.2:80 -m -w 2 #此时权重就为2： [root@node01 vols]# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 172.18.140.6:80 wrr -&gt; 172.17.0.2:80 Masq 2 0 37 -&gt; 172.17.0.3:80 Masq 1 0 36 测试： [root@node02 ~]# while true;do curl 172.18.140.6; done nginx2 nginx1 nginx1 nginx2 #可以看到权重比和调度的关系 6.终止其中一个后端RS： docker kill c2 #终止RS-c2 [root@node02 ~]# while true;do curl --connect-timeout 1 172.18.140.6 sleep .5; done curl: (28) Connection timed out after 1001 milliseconds curl: (28) Resolving timed out after 1517 milliseconds curl: (6) Could not resolve host: .5; Unknown error nginx2 curl: (28) Resolving timed out after 1517 milliseconds #因为LVS没有对后端RS健康状态检测的功能，所以即使后端的RSdown了，也会被调度上去,这也是LVS的一个重要缺点. LVS-DR类型实验：1.环境准备： 4台物理机： node01 172.18.140.6 node02 172.18.140.5 node03 172.18.140.7 #都关闭防火墙 [root@node01 ~]# systemctl stop firewalld.service [root@node01 ~]# systemctl disable firewalld.service 2.安装httpd [root@node01 ~]# yum install httpd -y [root@node01 ~]# systemctl start httpd 3.为node2和ndoe3进行内核参数设置 [root@node03 ~]# lvs_dr_rs.sh #!/bin/bash vip=172.18.140.10 #VIP地址 mask=&apos;255.255.255.255&apos; # interface=&quot;lo:0&quot; #rpm -q httpd &amp;&gt; /dev/null || yum -y install httpd &amp;&gt;/dev/null #service httpd start &amp;&gt; /dev/null &amp;&amp; echo &quot;The httpd Server is Ready!&quot; #echo &quot;&lt;h1&gt;`hostname`&lt;/h1&gt;&quot; &gt; /var/www/html/index.html case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $interface $vip netmask $mask broadcast $vip up route add -host $vip dev $interface #添加到达VIP的路由信息 echo &quot;The RS Server is Ready!&quot; ;; stop) ifconfig $interface down #VIPdown后，路由和IP也就没有了只需清楚内核参数即可 echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;The RS Server is Canceled!&quot; ;; *) echo &quot;Usage: $(basename $0) start|stop&quot; exit 1 ;; esac 4.为node1设置VIP ifconfig ens37:0 172.18.140.10 netmask 255.255.255.255 broadcast 172.18.140.10 5.添加集群和RS ipvsadm -A -t 172.18.140.10:80 -s wrr ipvsadm -a -t 172.18.140.10:80 -r 172.18.140.5 -g -w 1 ipvsadm -a -t 172.18.140.10:80 -r 172.18.140.7 -g -w 2 6.测试调度效果： [root@node04 ~]# while true; do curl 172.18.140.10 ; done node03 node03 node2 node03 node03 #显示轮询调度效果 7.修改调度算法： 修改为源地址sh的算法： [root@node01 data]# ipvsadm -E -t 172.18.140.10:80 -s sh 测试： [root@node04 ~]# while true; do curl 172.18.140.10 ; done node2 node2 node2 #可以看到同一个地址，始终会被调度到一个后端RS上. LVS的持久连接机制实现lvs persistence：持久连接 持久连接模板：实现无论使用任何调度算法，在一段时间内，能够实现将来自同一个地址的请求始终发往同一个RS； ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] port Affinity： 每端口持久：每个端口对应定义为一个集群服务，每集群服务单独调度； 每防火墙标记持久：基于防火墙标记定义集群服务；可实现将多个端口上的应用统一调度，即所谓的port Affinity； 每客户端持久：基于0端口定义集群服务，即将客户端对所有应用的请求统统调度至后端主机，必须定义为持久模式； 持久连接和算法无关系，和采用的持久连接方式有关！ session 绑定：对共享同一组RS的多个集群服务，需要统一进行绑定，lvs sh算法无法实现 对于sh的算法来说，某个IP地址的访问会通过hash PCC:所有端口 PFWM:持久防火墙标记 PPC:单个端口]]></content>
      <categories>
        <category>负载均衡</category>
        <category>LVS</category>
      </categories>
      <tags>
        <tag>LB负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS调度算法]]></title>
    <url>%2F2017%2F01%2F10%2FLVS%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[LVS Cluster的集群的概念Cluster：集群,为解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster集群的类型： LB：Load Balancing，负载均衡 HA：High Availiablity，高可用，SPOF（single Point Of failure） MTBF:Mean Time Between Failure 平均无故障时间 MTTR:Mean Time To Restoration（ repair）平均恢复前时间 A=MTBF/（MTBF+MTTR） (0,1)：99%, 99.5%, 99.9%, 99.99%, 99.999% HPC：High-performance computing，高性能 www.top500.org 调度算法： 分布式系统： 作用：因为seesion和cookie的 LB Cluster的实现根据工作的网络层次ISO模型可以分： 通信子网和资源子网 四层调度器：在内核级中，即ISO模型的下四层，完成请求报文的分析 转发，交换 LVS(ipvs),nginx(stream模块),HAProxy(mode tcp) 七层调度器：在用户空间中，即ISO模型的应用层上的 代理：proxy nginx(http_upstream)，HAProxy,ATS,Envoy,Traefik 硬负载：F5,BigIP,Netscaler,Citrix 四层调度的工作过程： 因为tcp/ip协议栈是在内核中的，四层调度是工作在下四层的,四层调度器只需要分析用 户的请求报文中的网络层(目标IP)和传输(目标端口)是什么，就可以做出调度决策，这个 请求报文就不会进入到调度器的用户空间中，而只是在内核空间中分析进而又通过内核进 行转发传输出去了.而用户的请求报文是没有被更改过的，因为调度是在内核中完成的，所以四层调度也叫内核级调度. 四层调度不受限于客户端套接字，最大支持400w个并发 七层调度的工作原理： 详见nginx七层调度工作原理 七层调度因为要与后端服务器进行通信，就需要使用套接字，则最大能使用4W个socket 而绝大多数的网站最多也就4W个并发，即使七层调度最大支持4w个并发，如果是使用短连接，长连接默认60s， 所以网站一天也可以有4w*2*86400个请求，弹性计算可以支持峰值 过去之后的服务器资源伸缩. 负载均衡和会话保持只要提到负载均衡那么会话保持也是必然要提到的问题 有状态的负载均衡服务器就必然要保持会话粘性，而会话保持的方式又分三种 session保持的三种方式： session sticky:seesion粘性 1.基于客户端IP做hash将seesion保存在一台服务器上，如果是SNAT网络则IP是 一样的，seesion的颗粒度过于粗糙.(SH算法) 2.cookie机制即使是在通过SNAT网络中，不同的浏览器客户端也会被识别为不同 客户端，seesion的颗粒度精细的多.nginx可以识别应用层的cookie信息， 完全可以基于cookie信息做会话绑定的.而cookie是应用层数据，工作在四层的LVS是识别不了的， 而七层的nginx只有商业版支持.但是同样是七层的HAproxy可以实现！！！ seesion既损害负载均衡效果，又可能造成seesion丢失(后端服务器down机) seesion replication server(cluster):seesion复制集群 在同一集群中，session是共享的，但是对内存的消耗比较大,但传输是由延迟的 把自己的seesion复制给集群的其他主机，这样seesion集群中的每个主机都会拥有 集群中所有服务器的seesion. 只适合于网站架构初创阶段！！！ session server: 把用户访问的seesion保存单独的一台服务器，通过api调用这个服务器，如redis, memcached，squid等，还是做redis集群保证seesion的安全 但是session的冗余实现比较麻烦和cookie(seesion sticky的另外一种表现) LVS的模型原理:Linux Virtual Server 1.LVS是工作四层，也就是内核中完成调度的,而且源代码也被整合到内核中，就像iptables的 netfilter一样，需要把写的规则送到内核中才能够生效. 2.依赖于内核中的LVS模块和LVS的调度算法模块，需要将集群的定义发送到内核中，并指明 使用哪种调度算法. 3.ipvs在内核中类似netfilter的框架，而ipvsadm是工作在用户空间用来生成规则的命令行 工具，然后送到内核的ipvs上，进而生效的 4.ipvs是工作在INPUT链上的，因为客户端请求的是调度器的VIP地址，必然会被送到INPUT链 而ipvs发现请求的是某个集群服务的，会强行将请求报文送到FORWARD链上，这样就实现 了转发的效果，而不进入LVS的用户空间. 5.所以需要事先在ipvs上放置一些集群的规则，才能实现转发FORWARD或者POSTROUTING链 所以iptables和ipvs在INPUT最好不要同时存在规则. LVS是通过在内核中的netfilter的INPUT链上内置了ipvs的框架并且根据请求报文中的目标IP和端口来判别是否为用户 此前定义过的集群服务，如果是就根据用户定义的调度算法来完成调度的，而每一个调度算法都是内嵌在内核中的内核模块(常用的10种). LVS的组成和相关术语LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。 1.ipvs(ip virtual server)：一段代码工作在内核空间，叫ipvs， 是真正生效实现调度的代码。 2. ipvsadm：另外一段是工作在用户空间，叫ipvsadm，负责为ipvs内核框架编写规则， 定义谁是集群服务，而谁是后端真实的服务器(Real Server) 相关术语： 1. DS：Director Server。指的是前端负载均衡器节点。 2. RS：Real Server。后端真实的工作服务器。 3. VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 4. DIP：Director Server IP，主要用于和内部主机通讯的IP地址。 5. RIP：Real Server IP，后端服务器的IP地址。 6. CIP：Client IP，访问客户端的IP地址。 LVS的调度算法WLC是LVS的默认调度算法 [root@node01 ~]# grep -i &quot;ip_vs&quot; /boot/config-3.10.0-862.el7.x86_64 CONFIG_IP_VS=m CONFIG_IP_VS_IPV6=y # CONFIG_IP_VS_DEBUG is not set CONFIG_IP_VS_TAB_BITS=12 CONFIG_IP_VS_PROTO_TCP=y CONFIG_IP_VS_PROTO_UDP=y CONFIG_IP_VS_PROTO_AH_ESP=y CONFIG_IP_VS_PROTO_ESP=y CONFIG_IP_VS_PROTO_AH=y CONFIG_IP_VS_PROTO_SCTP=y CONFIG_IP_VS_RR=m CONFIG_IP_VS_WRR=m CONFIG_IP_VS_LC=m CONFIG_IP_VS_WLC=m CONFIG_IP_VS_LBLC=m CONFIG_IP_VS_LBLCR=m CONFIG_IP_VS_DH=m CONFIG_IP_VS_SH=m CONFIG_IP_VS_SED=m CONFIG_IP_VS_NQ=m CONFIG_IP_VS_SH_TAB_BITS=8 CONFIG_IP_VS_FTP=m CONFIG_IP_VS_NFCT=y CONFIG_IP_VS_PE_SIP=m 在定义调度算法时，要根据实际情况使用合适的调度算法. lsmod | grep ipvs modinfo ip_vs 静态算法和动态算法的区别： 动态算法对系统资源消耗更多，调度效果更慢，但调度效果要好的多.原因在于动态算法 讲究结果公平，静态算法讲究起点公平 静态算法： 区别： 1.仅根据算法本身和请求报文特征进行调度，实现短连接 静态算法的实现： 1.RR:round-robin, 是对RS群的轮询，按依次循环的方式将请求调度到不同的服务器上,该算法最大的特点就是实现简单且假设 所有的服务器处理请求的能力都一样，调度器会将所有的请求平均分配给每个RS,只关注RS群的个数. 2.WRR:weighted rr,权重/加权轮询， 加权轮调是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1， 服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。 静态算法中的hash算法 对源地址/目标地址进行hash(md5,sha1等)计算然后对后端服务器集群的权重取模，模是 多少，就被调度到哪台后端服务器上. 3.SH: source ip hashing 源地址hash 地址绑定：对访问的源地址进行hash值计算(所谓hash就是IP的MD5或者SHA计算的值)，而只要访问的IP地址 不变那么hash的结果对权重之和取模的结果一定也是不变的，如果再次访问时就会再被调度到RS上， 所以地址绑定机制实现了session的sticky的会话保持。 缺点： 对于SNAT网络来说，地址绑定的机制会对LVS的工作造成极大的问题在权重模型下的工作逻辑是一样的 适用场景： 在没有使用会话共享的又需要保存会话的环境下（如电子商务网站），建议使用此算法。 4.DH: destination ip hashing 目标地址hash sh是为了追踪并保持会话的，而DH 对访问的解析的地址，进行hash值计算/权重，根据权重分配到某个RS上 动态算法： 区别： 1.不仅根据算法本身和请求报文特征进行调度 2.还要额外考虑后端各RS服务器当前的负载状态，消耗的资源更多 3.动态算法需要对后端服务集群的状态进行采样,考虑到后端每一台服务器的活动连接和非活动连接数以及空闲连 接数，统计的值叫overhead=value较小的RS将被调度，这样就实现资源的均衡调度 负载(overhead)的计算公式: overhead=activeconn(服务器当前活动连接数)*256+inactiveconns 正常情况下我们认为活动连接数消耗的资源是非活动连接的256倍，所以要乘以256，这样就可以得出后端服务器的当前负载情况了。 动态算法的实现： 5.LC:least connections 适用于长连接应用 Overhead=activeconns*256+inactiveconns 把新的连接请求分配到当前连接数最小的服务器，通过服务器当前活跃的连接数来估计服务器的情况。 调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1； 当连接中断或者超时，其连接数减1。 当然实际情况下，后端服务器的权重有可能是不一样的，所以就引入了WLC算法 6.WLC：Weighted LC，LVS的默认调度方法 叫加权最少连接，算法是： Overhead=(activeconns*256+inactiveconns)/weight 加权最少连接数是最小连接调度的优化，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1， 系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数 和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。 7.SED：Shortest Expection Delay,初始连接高权重优先，最短期望延迟 Overhead=(activeconns+1)*256/weight WLC算法表面上是合理的，但是当出现计算的overhead值(权重一样)是一样的或者集群刚刚启动时(此时activeconn和inactiveconn都是0， 那么overhead也都是0,那么第一个请求应该发给哪个后端服务器？ 如果权重一样可以自上而下发送给后端服务器即可，如果权重不一样，而且刚好权重最小的在最上面， 如果把请求分配给它，那么处理速度就会慢 而我们期望的是由权重大的是处理第一个请求，所有就有了SED算法的出现. SED是如何实现让权重最大的接收处理第一个请求的？ Overhead=(activeconns+1)*256/weight SED算法不再考虑非活动连接状态，把当前活动连接的数目+1除以服务器的权值，此时的计算方法会因为 权重大的值反而overhead值越小，这样就实现了让权重大的优先处理请求的目的. 缺点： 如果权重比较大(1:9),那么前8个请求都是让权重为9的服务器来处理的， 如果刚好只有7个请求，那么权重为1的又会闲着，但是我们又不期望有服务器空闲，就有了nq算法. 8.nq:Never Queue，第一轮均匀分配，后续SED,SED的增强版 nq算法是对SED算法的弥补，第一轮都需要处理一个请求，后面再进来的请求再进行权重进行分配， 这样所有的服务器都不会空闲,也叫永不排队算法 9.lblc:locality-Base LC，基于本地的最少连接算法，是DH算法的动态版 正向代理情形下的cache server的调度，该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器 ，若该服务器是可用的且没有超载，将请求发送到该服务器;若服务器不存在，或者该服务器超载且有服务器 处于一半的工作负载，则用“最少链接”的原则选出一个可用的服务器，将请求发送到该服务器｡ 10.lblcr：Locality-Based Least-Connection with Replication 带复制功能的LBLC算法，它与LBLC算法的不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护 从一个目标IP地址到一台服务器的映射｡该算法根据请求的目标IP地址找出该目标IP地址对应的服务器组，按”最小连接”原则从 服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接” 原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器｡同时，当该服务器组有一段时间没有被修改， 将最忙的服务器从服务器组中删除，以降低复制的程度。 具体使用：不同的服务器集群的算法应该怎么选择？ 1.算法的选择和与后端服务是短连接和长连接有着重要关系 短连接使用静态算法，长连接使用动态算法，因为如果是长连接，那么计算后端服务器集群的overhead负载状态是很有必要， 如果是短连接，计算的过程中可能连接就已经断开了，所以短连接不用考虑动态算法。长连接必须要考虑动态。 2.与服务所使用的协议是否有状态有关系 3.与静态内容和动态内容有关系 示例： 1.一组纯静态内容的web服务站点： 因为都是是静态内容、http协议是无状态且是短连接的，最好的算法就是rr或者wrr 2.mysql主从服务器： 1.LVS是四层调度，无法识别mysql的读写命令操作，所以mysql是不能使用LVS来调度的； 2.如果一定要在mysql上用LVS，可以用到proxysql后端的多个从服务器上，因为proxysql的轮询调度功能有限 ，可以使用LVS代理多个从服务器实现轮询调度，这是两个概念，和mysql主从能不能使用LVS调度是完全不同的思想. 3.如果是fpm服务器,运行电商等应用服务站点 电商站点最大的特点就是要追踪用户身份而且是状态的，有状态就需要有seesion，所以要进行seesion会话 保持，最好是使用sh源地址hash算法，但是由于SNAT网络的原因，IPhash太过于粗糙. 当然这里只是举例说明算法的选择，实际情况是需要进行seesion relication cluster或者 seesion server来解决用户身份追踪的，这就和算法没有直接关系了. 4.如果是https服务，能不能用LVS？ http是可以用LVS的，但是https的ssl是工作在OSI协议的第五层(TCP协议的应用层)，LVS是无法识别并建立ssl会话，而SSL证书的subject主体应该是 后端RS的FQDN的主机名，而不是Director(因为LVS无法识别)； 1.但是ssl会话既贵且慢，为了使得更快一般是在服务器上做ssl缓存的，以便命中加速访问， 如果LVS轮询调度，那么ssl缓存是有可能失效的无法命中的; 2.Diector和RS应该是在一个机房的，局域网内的通信使用ssl无疑是多次一举的， 互联网上的通信只是在客户端和负载均衡间采用ssl通信的.这样一来也就nginx、haproxy这样的七层调度器才能够实现.]]></content>
      <categories>
        <category>负载均衡</category>
        <category>LVS</category>
      </categories>
      <tags>
        <tag>LB负载均衡</tag>
      </tags>
  </entry>
</search>
